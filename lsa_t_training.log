2025-09-20 19:15:06,107 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-20 19:15:06,107 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-20 19:15:06,107 - __main__ - INFO - Starting training pipeline
2025-09-20 19:15:06,207 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-20 19:15:06,234 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-20 19:15:06,234 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-20 19:15:06,234 - __main__ - INFO - Loading training data...
2025-09-20 19:16:39,345 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-20 19:16:39,346 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-20 19:16:39,346 - __main__ - INFO - Starting training pipeline
2025-09-20 19:16:39,443 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-20 19:16:39,465 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-20 19:16:39,465 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-20 19:16:39,466 - __main__ - INFO - Loading training data...
2025-09-20 19:16:47,005 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-20 19:16:47,006 - __main__ - INFO - Processing train split...
2025-09-20 19:16:47,091 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-20 19:16:47,091 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-20 19:17:15,074 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-20 19:17:46,807 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-20 19:18:19,545 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-20 19:18:51,369 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-20 19:19:23,325 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-20 19:19:54,219 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-20 19:20:18,068 - __main__ - INFO - Processing val split...
2025-09-20 19:20:18,315 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-20 19:20:18,315 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-20 19:20:44,192 - __main__ - INFO - Processing test split...
2025-09-20 19:20:44,401 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-20 19:20:44,401 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-20 19:21:10,883 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-20 19:21:10,883 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-20 19:21:11,055 - __main__ - INFO - ‚úÖ Vocabulary created successfully with 13664 words
2025-09-20 19:21:11,055 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-20 19:21:11,055 - __main__ - INFO - Creating model architecture...
2025-09-20 19:21:11,550 - __main__ - INFO - ‚úÖ Model created successfully
2025-09-20 19:21:11,551 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-20 19:21:11,551 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-20 19:21:11,551 - __main__ - INFO - üñ•Ô∏è  Using device: cuda
2025-09-20 19:21:11,551 - __main__ - INFO - Creating trainer...
2025-09-20 19:21:11,551 - __main__ - INFO - üîÑ Moving model to cuda...
2025-09-20 19:21:11,981 - __main__ - INFO - ‚úÖ Model moved to cuda
2025-09-20 19:21:11,981 - __main__ - INFO - üìç Model parameters are on: cuda:0
2025-09-20 19:21:14,279 - __main__ - INFO - ‚úÖ Trainer created successfully
2025-09-20 19:21:14,279 - __main__ - INFO - üìç Trainer model parameters are on: cuda:0
2025-09-20 19:21:14,279 - __main__ - INFO - üöÄ Starting training...
2025-09-20 19:21:14,279 - __main__ - INFO - Training configuration:
2025-09-20 19:21:14,279 - __main__ - INFO -   - Epochs: 100
2025-09-20 19:21:14,279 - __main__ - INFO -   - Batch size: 8
2025-09-20 19:21:14,279 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-20 19:21:14,280 - __main__ - INFO -   - Training samples: 6765
2025-09-20 19:21:14,280 - __main__ - INFO -   - Validation samples: 845
2025-09-20 19:21:14,280 - training.trainer - INFO - Starting training for 100 epochs
2025-09-20 19:21:14,280 - training.trainer - INFO - Model parameters: 16,669,280
2025-09-20 19:21:14,280 - training.trainer - INFO - Training on device: cuda
2025-09-20 19:21:27,012 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.6683, Acc=0.043, PPL=5815.82
2025-09-20 19:21:36,202 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.1398, Acc=0.056, PPL=3428.39
2025-09-20 19:21:44,516 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.5955, Acc=0.079, PPL=1989.31
2025-09-20 19:21:52,596 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.1194, Acc=0.041, PPL=1235.68
2025-09-20 19:22:00,971 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.7749, Acc=0.082, PPL=875.60
2025-09-20 19:22:09,302 - training.trainer - INFO - Epoch 0, Step 599: Loss=6.8587, Acc=0.069, PPL=952.17
2025-09-20 19:22:17,902 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.6117, Acc=0.082, PPL=743.77
2025-09-20 19:22:26,572 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.8436, Acc=0.128, PPL=937.87
2025-09-20 19:22:37,045 - training.trainer - INFO - Epoch 1/100 completed in 82.76s - Train Loss: 7.5177, Train Acc: 0.062, Val Loss: 6.7832, Val Acc: 0.098
2025-09-20 19:22:37,951 - training.trainer - INFO - New best model saved with validation loss: 6.7832
2025-09-20 19:22:37,951 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-20 19:22:47,742 - training.trainer - INFO - Epoch 1, Step 945: Loss=7.0829, Acc=0.095, PPL=1191.38
2025-09-20 19:22:56,933 - training.trainer - INFO - Epoch 1, Step 1045: Loss=6.7368, Acc=0.122, PPL=842.89
2025-09-20 19:23:06,611 - training.trainer - INFO - Epoch 1, Step 1145: Loss=6.6279, Acc=0.096, PPL=755.90
2025-09-20 19:23:15,797 - training.trainer - INFO - Epoch 1, Step 1245: Loss=6.4754, Acc=0.141, PPL=649.01
2025-09-20 19:23:24,976 - training.trainer - INFO - Epoch 1, Step 1345: Loss=6.5316, Acc=0.158, PPL=686.51
2025-09-20 19:23:34,010 - training.trainer - INFO - Epoch 1, Step 1445: Loss=6.7839, Acc=0.127, PPL=883.48
2025-09-20 19:23:43,103 - training.trainer - INFO - Epoch 1, Step 1545: Loss=6.3255, Acc=0.163, PPL=558.61
2025-09-20 19:23:52,007 - training.trainer - INFO - Epoch 1, Step 1645: Loss=6.5891, Acc=0.179, PPL=727.15
2025-09-20 19:24:03,142 - training.trainer - INFO - Epoch 2/100 completed in 85.19s - Train Loss: 6.6817, Train Acc: 0.124, Val Loss: 6.6132, Val Acc: 0.132
2025-09-20 19:24:04,021 - training.trainer - INFO - New best model saved with validation loss: 6.6132
2025-09-20 19:24:04,022 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-20 19:24:13,887 - training.trainer - INFO - Epoch 2, Step 1791: Loss=6.6116, Acc=0.176, PPL=743.70
2025-09-20 19:24:22,879 - training.trainer - INFO - Epoch 2, Step 1891: Loss=6.5789, Acc=0.182, PPL=719.76
2025-09-20 19:24:31,811 - training.trainer - INFO - Epoch 2, Step 1991: Loss=6.6313, Acc=0.129, PPL=758.47
2025-09-20 19:24:40,815 - training.trainer - INFO - Epoch 2, Step 2091: Loss=6.6145, Acc=0.132, PPL=745.87
2025-09-20 19:24:49,694 - training.trainer - INFO - Epoch 2, Step 2191: Loss=6.5915, Acc=0.107, PPL=728.87
2025-09-20 19:24:59,056 - training.trainer - INFO - Epoch 2, Step 2291: Loss=6.7092, Acc=0.094, PPL=819.95
2025-09-20 19:25:08,052 - training.trainer - INFO - Epoch 2, Step 2391: Loss=6.7075, Acc=0.132, PPL=818.54
2025-09-20 19:25:16,957 - training.trainer - INFO - Epoch 2, Step 2491: Loss=6.7162, Acc=0.108, PPL=825.65
2025-09-20 19:25:27,645 - training.trainer - INFO - Epoch 3/100 completed in 83.62s - Train Loss: 6.5768, Train Acc: 0.132, Val Loss: 6.4944, Val Acc: 0.149
2025-09-20 19:25:28,259 - training.trainer - INFO - New best model saved with validation loss: 6.4944
2025-09-20 19:25:28,259 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-20 19:25:36,958 - training.trainer - INFO - Epoch 3, Step 2637: Loss=6.2188, Acc=0.129, PPL=502.09
2025-09-20 19:25:44,769 - training.trainer - INFO - Epoch 3, Step 2737: Loss=6.1448, Acc=0.194, PPL=466.28
2025-09-20 19:25:52,593 - training.trainer - INFO - Epoch 3, Step 2837: Loss=6.6548, Acc=0.132, PPL=776.52
2025-09-20 19:26:00,608 - training.trainer - INFO - Epoch 3, Step 2937: Loss=6.4719, Acc=0.150, PPL=646.74
2025-09-20 19:26:08,613 - training.trainer - INFO - Epoch 3, Step 3037: Loss=6.4225, Acc=0.165, PPL=615.52
2025-09-20 19:26:16,942 - training.trainer - INFO - Epoch 3, Step 3137: Loss=6.2828, Acc=0.178, PPL=535.29
2025-09-20 19:26:25,177 - training.trainer - INFO - Epoch 3, Step 3237: Loss=6.3794, Acc=0.147, PPL=589.59
2025-09-20 19:26:33,185 - training.trainer - INFO - Epoch 3, Step 3337: Loss=6.6389, Acc=0.127, PPL=764.27
2025-09-20 19:26:43,689 - training.trainer - INFO - Epoch 4/100 completed in 75.43s - Train Loss: 6.4556, Train Acc: 0.148, Val Loss: 6.3854, Val Acc: 0.157
2025-09-20 19:26:44,428 - training.trainer - INFO - New best model saved with validation loss: 6.3854
2025-09-20 19:26:44,429 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-20 19:26:53,837 - training.trainer - INFO - Epoch 4, Step 3483: Loss=5.9796, Acc=0.173, PPL=395.27
2025-09-20 19:27:02,346 - training.trainer - INFO - Epoch 4, Step 3583: Loss=6.3198, Acc=0.163, PPL=555.48
2025-09-20 19:27:10,275 - training.trainer - INFO - Epoch 4, Step 3683: Loss=6.3204, Acc=0.173, PPL=555.82
2025-09-20 19:27:18,720 - training.trainer - INFO - Epoch 4, Step 3783: Loss=6.2626, Acc=0.137, PPL=524.58
2025-09-20 19:27:26,538 - training.trainer - INFO - Epoch 4, Step 3883: Loss=6.4111, Acc=0.157, PPL=608.57
2025-09-20 19:27:34,628 - training.trainer - INFO - Epoch 4, Step 3983: Loss=6.0781, Acc=0.161, PPL=436.22
2025-09-20 19:27:42,599 - training.trainer - INFO - Epoch 4, Step 4083: Loss=6.2466, Acc=0.160, PPL=516.23
2025-09-20 19:27:50,977 - training.trainer - INFO - Epoch 4, Step 4183: Loss=6.1947, Acc=0.152, PPL=490.13
2025-09-20 19:28:01,651 - training.trainer - INFO - Epoch 5/100 completed in 77.22s - Train Loss: 6.3608, Train Acc: 0.155, Val Loss: 6.3092, Val Acc: 0.161
2025-09-20 19:28:02,012 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-20 19:28:02,850 - training.trainer - INFO - New best model saved with validation loss: 6.3092
2025-09-20 19:28:02,850 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-20 19:28:12,306 - training.trainer - INFO - Epoch 5, Step 4329: Loss=6.0285, Acc=0.184, PPL=415.11
2025-09-20 19:28:21,214 - training.trainer - INFO - Epoch 5, Step 4429: Loss=6.1467, Acc=0.168, PPL=467.19
2025-09-20 19:28:30,762 - training.trainer - INFO - Epoch 5, Step 4529: Loss=6.4426, Acc=0.147, PPL=628.03
2025-09-20 19:28:40,088 - training.trainer - INFO - Epoch 5, Step 4629: Loss=5.9852, Acc=0.150, PPL=397.50
2025-09-20 19:28:49,012 - training.trainer - INFO - Epoch 5, Step 4729: Loss=6.0616, Acc=0.175, PPL=429.06
2025-09-20 19:28:58,299 - training.trainer - INFO - Epoch 5, Step 4829: Loss=6.5779, Acc=0.130, PPL=719.06
2025-09-20 19:29:07,669 - training.trainer - INFO - Epoch 5, Step 4929: Loss=6.4729, Acc=0.130, PPL=647.37
2025-09-20 19:29:16,601 - training.trainer - INFO - Epoch 5, Step 5029: Loss=6.6659, Acc=0.176, PPL=785.20
2025-09-20 19:29:27,808 - training.trainer - INFO - Epoch 6/100 completed in 84.96s - Train Loss: 6.2884, Train Acc: 0.158, Val Loss: 6.2428, Val Acc: 0.162
2025-09-20 19:29:28,601 - training.trainer - INFO - New best model saved with validation loss: 6.2428
2025-09-20 19:29:28,602 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-20 19:29:38,610 - training.trainer - INFO - Epoch 6, Step 5175: Loss=6.2345, Acc=0.161, PPL=510.04
2025-09-20 19:29:47,622 - training.trainer - INFO - Epoch 6, Step 5275: Loss=6.6189, Acc=0.126, PPL=749.12
2025-09-20 19:29:56,523 - training.trainer - INFO - Epoch 6, Step 5375: Loss=6.1880, Acc=0.175, PPL=486.85
2025-09-20 19:30:05,354 - training.trainer - INFO - Epoch 6, Step 5475: Loss=6.4677, Acc=0.176, PPL=644.00
2025-09-20 19:30:14,583 - training.trainer - INFO - Epoch 6, Step 5575: Loss=6.3968, Acc=0.151, PPL=599.90
2025-09-20 19:30:23,569 - training.trainer - INFO - Epoch 6, Step 5675: Loss=6.2146, Acc=0.182, PPL=500.01
2025-09-20 19:30:32,806 - training.trainer - INFO - Epoch 6, Step 5775: Loss=5.8535, Acc=0.171, PPL=348.45
2025-09-20 19:30:41,762 - training.trainer - INFO - Epoch 6, Step 5875: Loss=6.2048, Acc=0.189, PPL=495.13
2025-09-20 19:30:52,930 - training.trainer - INFO - Epoch 7/100 completed in 84.33s - Train Loss: 6.2314, Train Acc: 0.163, Val Loss: 6.2039, Val Acc: 0.165
2025-09-20 19:30:53,678 - training.trainer - INFO - New best model saved with validation loss: 6.2039
2025-09-20 19:30:53,679 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-20 19:31:02,490 - training.trainer - INFO - Epoch 7, Step 6021: Loss=6.0255, Acc=0.179, PPL=413.86
2025-09-20 19:31:10,950 - training.trainer - INFO - Epoch 7, Step 6121: Loss=6.3937, Acc=0.126, PPL=598.08
2025-09-20 19:31:18,947 - training.trainer - INFO - Epoch 7, Step 6221: Loss=6.1889, Acc=0.197, PPL=487.33
2025-09-20 19:31:27,919 - training.trainer - INFO - Epoch 7, Step 6321: Loss=6.3328, Acc=0.111, PPL=562.75
2025-09-20 19:31:36,891 - training.trainer - INFO - Epoch 7, Step 6421: Loss=6.4740, Acc=0.173, PPL=648.04
2025-09-20 19:31:45,700 - training.trainer - INFO - Epoch 7, Step 6521: Loss=6.2934, Acc=0.169, PPL=540.98
2025-09-20 19:31:54,888 - training.trainer - INFO - Epoch 7, Step 6621: Loss=5.9291, Acc=0.197, PPL=375.82
2025-09-20 19:32:03,831 - training.trainer - INFO - Epoch 7, Step 6721: Loss=6.1311, Acc=0.146, PPL=459.92
2025-09-20 19:32:14,812 - training.trainer - INFO - Epoch 8/100 completed in 81.13s - Train Loss: 6.1864, Train Acc: 0.166, Val Loss: 6.1645, Val Acc: 0.167
2025-09-20 19:32:15,576 - training.trainer - INFO - New best model saved with validation loss: 6.1645
2025-09-20 19:32:15,577 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-09-20 19:32:25,078 - training.trainer - INFO - Epoch 8, Step 6867: Loss=5.8152, Acc=0.181, PPL=335.36
2025-09-20 19:32:34,124 - training.trainer - INFO - Epoch 8, Step 6967: Loss=6.1062, Acc=0.160, PPL=448.65
2025-09-20 19:32:43,278 - training.trainer - INFO - Epoch 8, Step 7067: Loss=6.5271, Acc=0.144, PPL=683.39
2025-09-20 19:32:52,033 - training.trainer - INFO - Epoch 8, Step 7167: Loss=6.4615, Acc=0.185, PPL=640.00
2025-09-20 19:33:01,203 - training.trainer - INFO - Epoch 8, Step 7267: Loss=6.6144, Acc=0.143, PPL=745.78
2025-09-20 19:33:10,203 - training.trainer - INFO - Epoch 8, Step 7367: Loss=6.1884, Acc=0.179, PPL=487.04
2025-09-20 19:33:18,912 - training.trainer - INFO - Epoch 8, Step 7467: Loss=6.3144, Acc=0.152, PPL=552.48
2025-09-20 19:33:27,811 - training.trainer - INFO - Epoch 8, Step 7567: Loss=5.8387, Acc=0.220, PPL=343.32
2025-09-20 19:33:38,771 - training.trainer - INFO - Epoch 9/100 completed in 83.19s - Train Loss: 6.1486, Train Acc: 0.169, Val Loss: 6.1355, Val Acc: 0.169
2025-09-20 19:33:39,457 - training.trainer - INFO - New best model saved with validation loss: 6.1355
2025-09-20 19:33:39,458 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-20 19:33:47,824 - training.trainer - INFO - Epoch 9, Step 7713: Loss=6.2795, Acc=0.141, PPL=533.53
2025-09-20 19:33:55,802 - training.trainer - INFO - Epoch 9, Step 7813: Loss=5.9450, Acc=0.182, PPL=381.84
2025-09-20 19:34:03,494 - training.trainer - INFO - Epoch 9, Step 7913: Loss=6.5467, Acc=0.191, PPL=696.93
2025-09-20 19:34:12,007 - training.trainer - INFO - Epoch 9, Step 8013: Loss=6.6130, Acc=0.155, PPL=744.69
2025-09-20 19:34:20,172 - training.trainer - INFO - Epoch 9, Step 8113: Loss=5.7674, Acc=0.199, PPL=319.71
2025-09-20 19:34:28,043 - training.trainer - INFO - Epoch 9, Step 8213: Loss=5.7070, Acc=0.196, PPL=300.97
2025-09-20 19:34:35,918 - training.trainer - INFO - Epoch 9, Step 8313: Loss=5.9496, Acc=0.201, PPL=383.59
2025-09-20 19:34:44,290 - training.trainer - INFO - Epoch 9, Step 8413: Loss=5.9501, Acc=0.173, PPL=383.80
2025-09-20 19:34:54,866 - training.trainer - INFO - Epoch 10/100 completed in 75.41s - Train Loss: 6.1164, Train Acc: 0.171, Val Loss: 6.0989, Val Acc: 0.173
2025-09-20 19:34:55,268 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-20 19:34:56,044 - training.trainer - INFO - New best model saved with validation loss: 6.0989
2025-09-20 19:34:56,044 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-20 19:35:05,485 - training.trainer - INFO - Epoch 10, Step 8559: Loss=6.0641, Acc=0.142, PPL=430.13
2025-09-20 19:35:14,443 - training.trainer - INFO - Epoch 10, Step 8659: Loss=6.2732, Acc=0.121, PPL=530.18
2025-09-20 19:35:23,243 - training.trainer - INFO - Epoch 10, Step 8759: Loss=6.4604, Acc=0.142, PPL=639.33
2025-09-20 19:35:32,096 - training.trainer - INFO - Epoch 10, Step 8859: Loss=6.2769, Acc=0.175, PPL=532.15
2025-09-20 19:35:41,592 - training.trainer - INFO - Epoch 10, Step 8959: Loss=5.8986, Acc=0.233, PPL=364.52
2025-09-20 19:35:50,384 - training.trainer - INFO - Epoch 10, Step 9059: Loss=6.1455, Acc=0.137, PPL=466.59
2025-09-20 19:35:59,301 - training.trainer - INFO - Epoch 10, Step 9159: Loss=6.0829, Acc=0.215, PPL=438.29
2025-09-20 19:36:08,192 - training.trainer - INFO - Epoch 10, Step 9259: Loss=6.2989, Acc=0.190, PPL=543.95
2025-09-20 19:36:19,028 - training.trainer - INFO - Epoch 11/100 completed in 82.98s - Train Loss: 6.0871, Train Acc: 0.175, Val Loss: 6.0633, Val Acc: 0.177
2025-09-20 19:36:19,867 - training.trainer - INFO - New best model saved with validation loss: 6.0633
2025-09-20 19:36:19,868 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-20 19:36:29,415 - training.trainer - INFO - Epoch 11, Step 9405: Loss=5.9665, Acc=0.153, PPL=390.14
2025-09-20 19:36:37,529 - training.trainer - INFO - Epoch 11, Step 9505: Loss=6.0415, Acc=0.186, PPL=420.52
2025-09-20 19:36:45,560 - training.trainer - INFO - Epoch 11, Step 9605: Loss=5.8030, Acc=0.185, PPL=331.28
2025-09-20 19:36:53,780 - training.trainer - INFO - Epoch 11, Step 9705: Loss=5.8629, Acc=0.220, PPL=351.76
2025-09-20 19:37:01,848 - training.trainer - INFO - Epoch 11, Step 9805: Loss=6.2437, Acc=0.203, PPL=514.78
2025-09-20 19:37:09,590 - training.trainer - INFO - Epoch 11, Step 9905: Loss=6.2980, Acc=0.163, PPL=543.47
2025-09-20 19:37:17,517 - training.trainer - INFO - Epoch 11, Step 10005: Loss=5.9572, Acc=0.157, PPL=386.53
2025-09-20 19:37:25,811 - training.trainer - INFO - Epoch 11, Step 10105: Loss=6.6711, Acc=0.123, PPL=789.24
2025-09-20 19:37:36,409 - training.trainer - INFO - Epoch 12/100 completed in 76.54s - Train Loss: 6.0606, Train Acc: 0.176, Val Loss: 6.0502, Val Acc: 0.180
2025-09-20 19:37:37,096 - training.trainer - INFO - New best model saved with validation loss: 6.0502
2025-09-20 19:37:37,096 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-09-20 19:37:45,388 - training.trainer - INFO - Epoch 12, Step 10251: Loss=6.0999, Acc=0.189, PPL=445.80
2025-09-20 19:37:54,025 - training.trainer - INFO - Epoch 12, Step 10351: Loss=5.7917, Acc=0.181, PPL=327.57
2025-09-20 19:38:01,959 - training.trainer - INFO - Epoch 12, Step 10451: Loss=5.8610, Acc=0.181, PPL=351.08
2025-09-20 19:38:09,643 - training.trainer - INFO - Epoch 12, Step 10551: Loss=6.1843, Acc=0.171, PPL=485.09
2025-09-20 19:38:17,500 - training.trainer - INFO - Epoch 12, Step 10651: Loss=5.8862, Acc=0.237, PPL=360.05
2025-09-20 19:38:25,658 - training.trainer - INFO - Epoch 12, Step 10751: Loss=6.2601, Acc=0.140, PPL=523.28
2025-09-20 19:38:33,787 - training.trainer - INFO - Epoch 12, Step 10851: Loss=5.9697, Acc=0.172, PPL=391.39
2025-09-20 19:38:42,127 - training.trainer - INFO - Epoch 12, Step 10951: Loss=5.8753, Acc=0.231, PPL=356.14
2025-09-20 19:38:52,850 - training.trainer - INFO - Epoch 13/100 completed in 75.75s - Train Loss: 6.0357, Train Acc: 0.179, Val Loss: 6.0333, Val Acc: 0.183
2025-09-20 19:38:53,613 - training.trainer - INFO - New best model saved with validation loss: 6.0333
2025-09-20 19:38:53,613 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-20 19:39:03,088 - training.trainer - INFO - Epoch 13, Step 11097: Loss=6.1414, Acc=0.176, PPL=464.69
2025-09-20 19:39:11,912 - training.trainer - INFO - Epoch 13, Step 11197: Loss=6.1754, Acc=0.167, PPL=480.78
2025-09-20 19:39:20,930 - training.trainer - INFO - Epoch 13, Step 11297: Loss=6.0806, Acc=0.166, PPL=437.27
2025-09-20 19:39:29,769 - training.trainer - INFO - Epoch 13, Step 11397: Loss=6.3245, Acc=0.121, PPL=558.10
2025-09-20 19:39:39,062 - training.trainer - INFO - Epoch 13, Step 11497: Loss=6.0410, Acc=0.176, PPL=420.30
2025-09-20 19:39:48,196 - training.trainer - INFO - Epoch 13, Step 11597: Loss=5.7941, Acc=0.180, PPL=328.35
2025-09-20 19:39:57,089 - training.trainer - INFO - Epoch 13, Step 11697: Loss=5.7598, Acc=0.178, PPL=317.30
2025-09-20 19:40:06,714 - training.trainer - INFO - Epoch 13, Step 11797: Loss=6.2203, Acc=0.186, PPL=502.86
2025-09-20 19:40:17,851 - training.trainer - INFO - Epoch 14/100 completed in 84.24s - Train Loss: 6.0131, Train Acc: 0.181, Val Loss: 6.0046, Val Acc: 0.185
2025-09-20 19:40:18,616 - training.trainer - INFO - New best model saved with validation loss: 6.0046
2025-09-20 19:40:18,616 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-20 19:40:28,048 - training.trainer - INFO - Epoch 14, Step 11943: Loss=5.9118, Acc=0.215, PPL=369.39
2025-09-20 19:40:37,756 - training.trainer - INFO - Epoch 14, Step 12043: Loss=6.0688, Acc=0.168, PPL=432.16
2025-09-20 19:40:46,875 - training.trainer - INFO - Epoch 14, Step 12143: Loss=5.7940, Acc=0.206, PPL=328.33
2025-09-20 19:40:55,607 - training.trainer - INFO - Epoch 14, Step 12243: Loss=5.5417, Acc=0.240, PPL=255.11
2025-09-20 19:41:04,520 - training.trainer - INFO - Epoch 14, Step 12343: Loss=5.8441, Acc=0.125, PPL=345.21
2025-09-20 19:41:13,349 - training.trainer - INFO - Epoch 14, Step 12443: Loss=6.1873, Acc=0.164, PPL=486.55
2025-09-20 19:41:22,182 - training.trainer - INFO - Epoch 14, Step 12543: Loss=6.3013, Acc=0.157, PPL=545.26
2025-09-20 19:41:31,089 - training.trainer - INFO - Epoch 14, Step 12643: Loss=6.4059, Acc=0.123, PPL=605.44
2025-09-20 19:41:42,112 - training.trainer - INFO - Epoch 15/100 completed in 83.50s - Train Loss: 5.9901, Train Acc: 0.184, Val Loss: 5.9890, Val Acc: 0.189
2025-09-20 19:41:42,502 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-20 19:41:43,320 - training.trainer - INFO - New best model saved with validation loss: 5.9890
2025-09-20 19:41:43,320 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-20 19:41:52,832 - training.trainer - INFO - Epoch 15, Step 12789: Loss=5.8776, Acc=0.179, PPL=356.96
2025-09-20 19:42:01,722 - training.trainer - INFO - Epoch 15, Step 12889: Loss=6.1213, Acc=0.210, PPL=455.44
2025-09-20 19:42:10,481 - training.trainer - INFO - Epoch 15, Step 12989: Loss=6.1084, Acc=0.175, PPL=449.62
2025-09-20 19:42:19,282 - training.trainer - INFO - Epoch 15, Step 13089: Loss=5.9101, Acc=0.174, PPL=368.73
2025-09-20 19:42:28,598 - training.trainer - INFO - Epoch 15, Step 13189: Loss=5.8653, Acc=0.196, PPL=352.61
2025-09-20 19:42:37,483 - training.trainer - INFO - Epoch 15, Step 13289: Loss=6.3328, Acc=0.173, PPL=562.71
2025-09-20 19:42:46,396 - training.trainer - INFO - Epoch 15, Step 13389: Loss=6.0878, Acc=0.163, PPL=440.46
2025-09-20 19:42:56,019 - training.trainer - INFO - Epoch 15, Step 13489: Loss=5.7190, Acc=0.185, PPL=304.60
2025-09-20 19:43:07,079 - training.trainer - INFO - Epoch 16/100 completed in 83.76s - Train Loss: 5.9702, Train Acc: 0.186, Val Loss: 5.9754, Val Acc: 0.189
2025-09-20 19:43:07,868 - training.trainer - INFO - New best model saved with validation loss: 5.9754
2025-09-20 19:43:07,869 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-20 19:43:17,375 - training.trainer - INFO - Epoch 16, Step 13635: Loss=6.0687, Acc=0.209, PPL=432.10
2025-09-20 19:43:26,344 - training.trainer - INFO - Epoch 16, Step 13735: Loss=5.9672, Acc=0.147, PPL=390.39
2025-09-20 19:43:35,572 - training.trainer - INFO - Epoch 16, Step 13835: Loss=5.8429, Acc=0.205, PPL=344.78
2025-09-20 19:43:44,949 - training.trainer - INFO - Epoch 16, Step 13935: Loss=5.8159, Acc=0.155, PPL=335.61
2025-09-20 19:43:54,330 - training.trainer - INFO - Epoch 16, Step 14035: Loss=5.8868, Acc=0.200, PPL=360.25
2025-09-20 19:44:03,441 - training.trainer - INFO - Epoch 16, Step 14135: Loss=5.6102, Acc=0.244, PPL=273.19
2025-09-20 19:44:12,284 - training.trainer - INFO - Epoch 16, Step 14235: Loss=6.1253, Acc=0.140, PPL=457.27
2025-09-20 19:44:21,486 - training.trainer - INFO - Epoch 16, Step 14335: Loss=6.2973, Acc=0.150, PPL=543.08
2025-09-20 19:44:32,753 - training.trainer - INFO - Epoch 17/100 completed in 84.88s - Train Loss: 5.9518, Train Acc: 0.188, Val Loss: 5.9530, Val Acc: 0.195
2025-09-20 19:44:33,611 - training.trainer - INFO - New best model saved with validation loss: 5.9530
2025-09-20 19:44:33,611 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-20 19:44:43,153 - training.trainer - INFO - Epoch 17, Step 14481: Loss=6.0117, Acc=0.146, PPL=408.19
2025-09-20 19:44:52,036 - training.trainer - INFO - Epoch 17, Step 14581: Loss=6.0195, Acc=0.155, PPL=411.38
2025-09-20 19:45:00,906 - training.trainer - INFO - Epoch 17, Step 14681: Loss=5.3929, Acc=0.291, PPL=219.85
2025-09-20 19:45:09,859 - training.trainer - INFO - Epoch 17, Step 14781: Loss=5.9570, Acc=0.187, PPL=386.44
2025-09-20 19:45:18,825 - training.trainer - INFO - Epoch 17, Step 14881: Loss=6.0619, Acc=0.184, PPL=429.20
2025-09-20 19:45:27,572 - training.trainer - INFO - Epoch 17, Step 14981: Loss=6.0865, Acc=0.165, PPL=439.88
2025-09-20 19:45:36,660 - training.trainer - INFO - Epoch 17, Step 15081: Loss=5.7310, Acc=0.225, PPL=308.28
2025-09-20 19:45:45,852 - training.trainer - INFO - Epoch 17, Step 15181: Loss=5.9259, Acc=0.206, PPL=374.62
2025-09-20 19:45:57,222 - training.trainer - INFO - Epoch 18/100 completed in 83.61s - Train Loss: 5.9282, Train Acc: 0.191, Val Loss: 5.9359, Val Acc: 0.194
2025-09-20 19:45:58,104 - training.trainer - INFO - New best model saved with validation loss: 5.9359
2025-09-20 19:45:58,104 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-20 19:46:07,645 - training.trainer - INFO - Epoch 18, Step 15327: Loss=6.0428, Acc=0.182, PPL=421.08
2025-09-20 19:46:16,576 - training.trainer - INFO - Epoch 18, Step 15427: Loss=5.5053, Acc=0.215, PPL=246.00
2025-09-20 19:46:25,660 - training.trainer - INFO - Epoch 18, Step 15527: Loss=5.5141, Acc=0.257, PPL=248.16
2025-09-20 19:46:34,492 - training.trainer - INFO - Epoch 18, Step 15627: Loss=6.3642, Acc=0.167, PPL=580.66
2025-09-20 19:46:43,657 - training.trainer - INFO - Epoch 18, Step 15727: Loss=5.8436, Acc=0.188, PPL=345.03
2025-09-20 19:46:52,760 - training.trainer - INFO - Epoch 18, Step 15827: Loss=6.1300, Acc=0.169, PPL=459.43
2025-09-20 19:47:02,121 - training.trainer - INFO - Epoch 18, Step 15927: Loss=5.9040, Acc=0.165, PPL=366.52
2025-09-20 19:47:11,268 - training.trainer - INFO - Epoch 18, Step 16027: Loss=6.2175, Acc=0.213, PPL=501.47
2025-09-20 19:47:22,372 - training.trainer - INFO - Epoch 19/100 completed in 84.27s - Train Loss: 5.9102, Train Acc: 0.193, Val Loss: 5.9190, Val Acc: 0.196
2025-09-20 19:47:23,202 - training.trainer - INFO - New best model saved with validation loss: 5.9190
2025-09-20 19:47:23,202 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-20 19:47:32,857 - training.trainer - INFO - Epoch 19, Step 16173: Loss=5.9339, Acc=0.206, PPL=377.63
2025-09-20 19:47:40,701 - training.trainer - INFO - Epoch 19, Step 16273: Loss=5.8872, Acc=0.161, PPL=360.41
2025-09-20 19:47:48,515 - training.trainer - INFO - Epoch 19, Step 16373: Loss=5.8614, Acc=0.244, PPL=351.23
2025-09-20 19:47:56,399 - training.trainer - INFO - Epoch 19, Step 16473: Loss=5.1599, Acc=0.330, PPL=174.14
2025-09-20 19:48:04,604 - training.trainer - INFO - Epoch 19, Step 16573: Loss=5.9664, Acc=0.205, PPL=390.12
2025-09-20 19:48:12,880 - training.trainer - INFO - Epoch 19, Step 16673: Loss=6.2306, Acc=0.196, PPL=508.05
2025-09-20 19:48:20,857 - training.trainer - INFO - Epoch 19, Step 16773: Loss=6.1249, Acc=0.233, PPL=457.08
2025-09-20 19:48:28,728 - training.trainer - INFO - Epoch 19, Step 16873: Loss=6.0649, Acc=0.168, PPL=430.46
2025-09-20 19:48:39,295 - training.trainer - INFO - Epoch 20/100 completed in 76.09s - Train Loss: 5.8909, Train Acc: 0.195, Val Loss: 5.8998, Val Acc: 0.198
2025-09-20 19:48:39,695 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-20 19:48:40,420 - training.trainer - INFO - New best model saved with validation loss: 5.8998
2025-09-20 19:48:40,420 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-20 19:48:49,683 - training.trainer - INFO - Epoch 20, Step 17019: Loss=6.1271, Acc=0.203, PPL=458.10
2025-09-20 19:48:58,119 - training.trainer - INFO - Epoch 20, Step 17119: Loss=5.6569, Acc=0.214, PPL=286.27
2025-09-20 19:49:06,882 - training.trainer - INFO - Epoch 20, Step 17219: Loss=5.8593, Acc=0.192, PPL=350.49
2025-09-20 19:49:15,479 - training.trainer - INFO - Epoch 20, Step 17319: Loss=5.8935, Acc=0.190, PPL=362.67
2025-09-20 19:49:23,372 - training.trainer - INFO - Epoch 20, Step 17419: Loss=5.7851, Acc=0.176, PPL=325.42
2025-09-20 19:49:31,419 - training.trainer - INFO - Epoch 20, Step 17519: Loss=5.7821, Acc=0.214, PPL=324.43
2025-09-20 19:49:39,759 - training.trainer - INFO - Epoch 20, Step 17619: Loss=5.6846, Acc=0.188, PPL=294.29
2025-09-20 19:49:47,754 - training.trainer - INFO - Epoch 20, Step 17719: Loss=6.2343, Acc=0.166, PPL=509.96
2025-09-20 19:49:58,525 - training.trainer - INFO - Epoch 21/100 completed in 78.10s - Train Loss: 5.8695, Train Acc: 0.198, Val Loss: 5.8901, Val Acc: 0.200
2025-09-20 19:49:59,364 - training.trainer - INFO - New best model saved with validation loss: 5.8901
2025-09-20 19:49:59,364 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-09-20 19:50:08,999 - training.trainer - INFO - Epoch 21, Step 17865: Loss=6.1226, Acc=0.162, PPL=456.07
2025-09-20 19:50:18,146 - training.trainer - INFO - Epoch 21, Step 17965: Loss=6.1638, Acc=0.158, PPL=475.22
2025-09-20 19:50:27,431 - training.trainer - INFO - Epoch 21, Step 18065: Loss=5.8849, Acc=0.162, PPL=359.58
2025-09-20 19:50:36,222 - training.trainer - INFO - Epoch 21, Step 18165: Loss=6.0995, Acc=0.163, PPL=445.61
2025-09-20 19:50:45,246 - training.trainer - INFO - Epoch 21, Step 18265: Loss=5.8341, Acc=0.254, PPL=341.76
2025-09-20 19:50:54,330 - training.trainer - INFO - Epoch 21, Step 18365: Loss=5.8026, Acc=0.223, PPL=331.14
2025-09-20 19:51:03,224 - training.trainer - INFO - Epoch 21, Step 18465: Loss=5.8145, Acc=0.176, PPL=335.11
2025-09-20 19:51:12,321 - training.trainer - INFO - Epoch 21, Step 18565: Loss=6.0577, Acc=0.220, PPL=427.38
2025-09-20 19:51:23,389 - training.trainer - INFO - Epoch 22/100 completed in 84.02s - Train Loss: 5.8529, Train Acc: 0.201, Val Loss: 5.8722, Val Acc: 0.202
2025-09-20 19:51:24,100 - training.trainer - INFO - New best model saved with validation loss: 5.8722
2025-09-20 19:51:24,100 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-09-20 19:51:33,449 - training.trainer - INFO - Epoch 22, Step 18711: Loss=5.6094, Acc=0.259, PPL=272.98
2025-09-20 19:51:41,915 - training.trainer - INFO - Epoch 22, Step 18811: Loss=6.1341, Acc=0.203, PPL=461.33
2025-09-20 19:51:50,433 - training.trainer - INFO - Epoch 22, Step 18911: Loss=5.5528, Acc=0.189, PPL=257.97
2025-09-20 19:51:58,537 - training.trainer - INFO - Epoch 22, Step 19011: Loss=5.6165, Acc=0.252, PPL=274.92
2025-09-20 19:52:06,568 - training.trainer - INFO - Epoch 22, Step 19111: Loss=6.0378, Acc=0.163, PPL=418.98
2025-09-20 19:52:14,567 - training.trainer - INFO - Epoch 22, Step 19211: Loss=5.7313, Acc=0.213, PPL=308.37
2025-09-20 19:52:22,743 - training.trainer - INFO - Epoch 22, Step 19311: Loss=5.5827, Acc=0.152, PPL=265.78
2025-09-20 19:52:30,427 - training.trainer - INFO - Epoch 22, Step 19411: Loss=6.0088, Acc=0.162, PPL=407.00
2025-09-20 19:52:40,594 - training.trainer - INFO - Epoch 23/100 completed in 76.49s - Train Loss: 5.8374, Train Acc: 0.203, Val Loss: 5.8529, Val Acc: 0.206
2025-09-20 19:52:41,286 - training.trainer - INFO - New best model saved with validation loss: 5.8529
2025-09-20 19:52:41,287 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-09-20 19:52:50,565 - training.trainer - INFO - Epoch 23, Step 19557: Loss=6.1676, Acc=0.156, PPL=477.02
2025-09-20 19:53:00,061 - training.trainer - INFO - Epoch 23, Step 19657: Loss=5.8698, Acc=0.203, PPL=354.17
2025-09-20 19:53:09,048 - training.trainer - INFO - Epoch 23, Step 19757: Loss=6.0747, Acc=0.199, PPL=434.73
2025-09-20 19:53:18,379 - training.trainer - INFO - Epoch 23, Step 19857: Loss=5.6568, Acc=0.197, PPL=286.24
2025-09-20 19:53:27,272 - training.trainer - INFO - Epoch 23, Step 19957: Loss=5.9476, Acc=0.195, PPL=382.82
2025-09-20 19:53:36,183 - training.trainer - INFO - Epoch 23, Step 20057: Loss=5.4270, Acc=0.224, PPL=227.46
2025-09-20 19:53:45,151 - training.trainer - INFO - Epoch 23, Step 20157: Loss=5.8709, Acc=0.214, PPL=354.56
2025-09-20 19:53:54,023 - training.trainer - INFO - Epoch 23, Step 20257: Loss=6.0501, Acc=0.224, PPL=424.14
2025-09-20 19:54:05,162 - training.trainer - INFO - Epoch 24/100 completed in 83.87s - Train Loss: 5.8158, Train Acc: 0.205, Val Loss: 5.8496, Val Acc: 0.206
2025-09-20 19:54:05,977 - training.trainer - INFO - New best model saved with validation loss: 5.8496
2025-09-20 19:54:05,978 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-09-20 19:54:15,646 - training.trainer - INFO - Epoch 24, Step 20403: Loss=5.2438, Acc=0.310, PPL=189.40
2025-09-20 19:54:24,605 - training.trainer - INFO - Epoch 24, Step 20503: Loss=5.7959, Acc=0.229, PPL=328.94
2025-09-20 19:54:33,608 - training.trainer - INFO - Epoch 24, Step 20603: Loss=5.9015, Acc=0.175, PPL=365.58
2025-09-20 19:54:41,886 - training.trainer - INFO - Epoch 24, Step 20703: Loss=5.8440, Acc=0.202, PPL=345.17
2025-09-20 19:54:50,134 - training.trainer - INFO - Epoch 24, Step 20803: Loss=6.0214, Acc=0.181, PPL=412.15
2025-09-20 19:54:58,158 - training.trainer - INFO - Epoch 24, Step 20903: Loss=5.7843, Acc=0.201, PPL=325.15
2025-09-20 19:55:05,913 - training.trainer - INFO - Epoch 24, Step 21003: Loss=5.5823, Acc=0.248, PPL=265.67
2025-09-20 19:55:14,521 - training.trainer - INFO - Epoch 24, Step 21103: Loss=5.8569, Acc=0.175, PPL=349.64
2025-09-20 19:55:25,307 - training.trainer - INFO - Epoch 25/100 completed in 79.33s - Train Loss: 5.8002, Train Acc: 0.207, Val Loss: 5.8418, Val Acc: 0.206
2025-09-20 19:55:25,706 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-20 19:55:26,532 - training.trainer - INFO - New best model saved with validation loss: 5.8418
2025-09-20 19:55:26,532 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-20 19:55:36,474 - training.trainer - INFO - Epoch 25, Step 21249: Loss=5.5547, Acc=0.189, PPL=258.45
2025-09-20 19:55:44,511 - training.trainer - INFO - Epoch 25, Step 21349: Loss=5.5402, Acc=0.266, PPL=254.72
2025-09-20 19:55:52,876 - training.trainer - INFO - Epoch 25, Step 21449: Loss=5.3954, Acc=0.227, PPL=220.38
2025-09-20 19:56:01,802 - training.trainer - INFO - Epoch 25, Step 21549: Loss=5.7938, Acc=0.211, PPL=328.26
2025-09-20 19:56:10,658 - training.trainer - INFO - Epoch 25, Step 21649: Loss=5.3728, Acc=0.246, PPL=215.46
2025-09-20 19:56:20,095 - training.trainer - INFO - Epoch 25, Step 21749: Loss=5.3405, Acc=0.287, PPL=208.61
2025-09-20 19:56:29,063 - training.trainer - INFO - Epoch 25, Step 21849: Loss=6.5983, Acc=0.166, PPL=733.84
2025-09-20 19:56:37,743 - training.trainer - INFO - Epoch 25, Step 21949: Loss=5.9735, Acc=0.171, PPL=392.86
2025-09-20 19:56:48,815 - training.trainer - INFO - Epoch 26/100 completed in 82.28s - Train Loss: 5.7828, Train Acc: 0.209, Val Loss: 5.8175, Val Acc: 0.211
2025-09-20 19:56:49,700 - training.trainer - INFO - New best model saved with validation loss: 5.8175
2025-09-20 19:56:49,701 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_26.pt
2025-09-20 19:56:58,913 - training.trainer - INFO - Epoch 26, Step 22095: Loss=5.8753, Acc=0.201, PPL=356.13
2025-09-20 19:57:08,059 - training.trainer - INFO - Epoch 26, Step 22195: Loss=5.8908, Acc=0.206, PPL=361.71
2025-09-20 19:57:17,091 - training.trainer - INFO - Epoch 26, Step 22295: Loss=5.7800, Acc=0.208, PPL=323.75
2025-09-20 19:57:26,531 - training.trainer - INFO - Epoch 26, Step 22395: Loss=5.6276, Acc=0.248, PPL=278.00
2025-09-20 19:57:35,442 - training.trainer - INFO - Epoch 26, Step 22495: Loss=5.4568, Acc=0.231, PPL=234.34
2025-09-20 19:57:44,151 - training.trainer - INFO - Epoch 26, Step 22595: Loss=6.1775, Acc=0.179, PPL=481.80
2025-09-20 19:57:53,175 - training.trainer - INFO - Epoch 26, Step 22695: Loss=5.8275, Acc=0.220, PPL=339.52
2025-09-20 19:58:01,877 - training.trainer - INFO - Epoch 26, Step 22795: Loss=5.4303, Acc=0.239, PPL=228.23
2025-09-20 19:58:12,402 - training.trainer - INFO - Epoch 27/100 completed in 82.70s - Train Loss: 5.7706, Train Acc: 0.212, Val Loss: 5.8074, Val Acc: 0.214
2025-09-20 19:58:13,208 - training.trainer - INFO - New best model saved with validation loss: 5.8074
2025-09-20 19:58:13,208 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_27.pt
2025-09-20 19:58:22,522 - training.trainer - INFO - Epoch 27, Step 22941: Loss=6.1006, Acc=0.155, PPL=446.13
2025-09-20 19:58:31,523 - training.trainer - INFO - Epoch 27, Step 23041: Loss=6.0642, Acc=0.192, PPL=430.17
2025-09-20 19:58:40,420 - training.trainer - INFO - Epoch 27, Step 23141: Loss=6.1951, Acc=0.234, PPL=490.34
2025-09-20 19:58:49,624 - training.trainer - INFO - Epoch 27, Step 23241: Loss=6.1344, Acc=0.205, PPL=461.44
2025-09-20 19:58:58,540 - training.trainer - INFO - Epoch 27, Step 23341: Loss=5.2245, Acc=0.293, PPL=185.77
2025-09-20 19:59:07,795 - training.trainer - INFO - Epoch 27, Step 23441: Loss=5.6610, Acc=0.214, PPL=287.42
2025-09-20 19:59:16,845 - training.trainer - INFO - Epoch 27, Step 23541: Loss=5.8358, Acc=0.206, PPL=342.34
2025-09-20 19:59:25,880 - training.trainer - INFO - Epoch 27, Step 23641: Loss=5.6064, Acc=0.227, PPL=272.16
2025-09-20 19:59:36,766 - training.trainer - INFO - Epoch 28/100 completed in 83.56s - Train Loss: 5.7530, Train Acc: 0.213, Val Loss: 5.8105, Val Acc: 0.212
2025-09-20 19:59:46,137 - training.trainer - INFO - Epoch 28, Step 23787: Loss=6.0086, Acc=0.210, PPL=406.91
2025-09-20 19:59:54,998 - training.trainer - INFO - Epoch 28, Step 23887: Loss=5.8891, Acc=0.216, PPL=361.07
2025-09-20 20:00:03,913 - training.trainer - INFO - Epoch 28, Step 23987: Loss=5.6673, Acc=0.232, PPL=289.24
2025-09-20 20:00:12,300 - training.trainer - INFO - Epoch 28, Step 24087: Loss=5.8868, Acc=0.174, PPL=360.25
2025-09-20 20:00:21,056 - training.trainer - INFO - Epoch 28, Step 24187: Loss=5.6846, Acc=0.186, PPL=294.31
2025-09-20 20:00:30,022 - training.trainer - INFO - Epoch 28, Step 24287: Loss=5.8879, Acc=0.182, PPL=360.63
2025-09-20 20:00:37,677 - training.trainer - INFO - Epoch 28, Step 24387: Loss=5.5369, Acc=0.241, PPL=253.88
2025-09-20 20:00:45,558 - training.trainer - INFO - Epoch 28, Step 24487: Loss=6.1040, Acc=0.179, PPL=447.66
2025-09-20 20:00:56,078 - training.trainer - INFO - Epoch 29/100 completed in 79.31s - Train Loss: 5.7374, Train Acc: 0.215, Val Loss: 5.7767, Val Acc: 0.216
2025-09-20 20:00:56,977 - training.trainer - INFO - New best model saved with validation loss: 5.7767
2025-09-20 20:00:56,978 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_29.pt
2025-09-20 20:01:06,853 - training.trainer - INFO - Epoch 29, Step 24633: Loss=5.4999, Acc=0.203, PPL=244.68
2025-09-20 20:01:15,517 - training.trainer - INFO - Epoch 29, Step 24733: Loss=6.0339, Acc=0.201, PPL=417.35
2025-09-20 20:01:24,124 - training.trainer - INFO - Epoch 29, Step 24833: Loss=5.2634, Acc=0.259, PPL=193.13
2025-09-20 20:01:32,633 - training.trainer - INFO - Epoch 29, Step 24933: Loss=6.2527, Acc=0.160, PPL=519.41
2025-09-20 20:01:41,607 - training.trainer - INFO - Epoch 29, Step 25033: Loss=5.8067, Acc=0.250, PPL=332.52
2025-09-20 20:01:50,602 - training.trainer - INFO - Epoch 29, Step 25133: Loss=5.9976, Acc=0.178, PPL=402.47
2025-09-20 20:02:00,007 - training.trainer - INFO - Epoch 29, Step 25233: Loss=5.7884, Acc=0.217, PPL=326.48
2025-09-20 20:02:08,924 - training.trainer - INFO - Epoch 29, Step 25333: Loss=5.5080, Acc=0.269, PPL=246.65
2025-09-20 20:02:19,730 - training.trainer - INFO - Epoch 30/100 completed in 82.75s - Train Loss: 5.7225, Train Acc: 0.217, Val Loss: 5.7823, Val Acc: 0.215
2025-09-20 20:02:20,145 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-20 20:02:30,164 - training.trainer - INFO - Epoch 30, Step 25479: Loss=5.9116, Acc=0.196, PPL=369.29
2025-09-20 20:02:39,292 - training.trainer - INFO - Epoch 30, Step 25579: Loss=5.6179, Acc=0.252, PPL=275.31
2025-09-20 20:02:48,127 - training.trainer - INFO - Epoch 30, Step 25679: Loss=6.0807, Acc=0.157, PPL=437.31
2025-09-20 20:02:56,696 - training.trainer - INFO - Epoch 30, Step 25779: Loss=5.8160, Acc=0.215, PPL=335.62
2025-09-20 20:03:05,678 - training.trainer - INFO - Epoch 30, Step 25879: Loss=6.0594, Acc=0.209, PPL=428.12
2025-09-20 20:03:14,781 - training.trainer - INFO - Epoch 30, Step 25979: Loss=5.7820, Acc=0.188, PPL=324.39
2025-09-20 20:03:24,038 - training.trainer - INFO - Epoch 30, Step 26079: Loss=5.5969, Acc=0.202, PPL=269.58
2025-09-20 20:03:32,869 - training.trainer - INFO - Epoch 30, Step 26179: Loss=5.8484, Acc=0.169, PPL=346.66
2025-09-20 20:03:44,152 - training.trainer - INFO - Epoch 31/100 completed in 84.01s - Train Loss: 5.7134, Train Acc: 0.219, Val Loss: 5.7719, Val Acc: 0.219
2025-09-20 20:03:44,987 - training.trainer - INFO - New best model saved with validation loss: 5.7719
2025-09-20 20:03:44,988 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_31.pt
2025-09-20 20:03:54,452 - training.trainer - INFO - Epoch 31, Step 26325: Loss=5.1679, Acc=0.248, PPL=175.54
2025-09-20 20:04:03,602 - training.trainer - INFO - Epoch 31, Step 26425: Loss=5.9068, Acc=0.247, PPL=367.54
2025-09-20 20:04:12,336 - training.trainer - INFO - Epoch 31, Step 26525: Loss=5.5620, Acc=0.281, PPL=260.33
2025-09-20 20:04:21,099 - training.trainer - INFO - Epoch 31, Step 26625: Loss=5.9216, Acc=0.183, PPL=373.00
2025-09-20 20:04:29,906 - training.trainer - INFO - Epoch 31, Step 26725: Loss=5.6247, Acc=0.227, PPL=277.20
2025-09-20 20:04:39,076 - training.trainer - INFO - Epoch 31, Step 26825: Loss=6.1418, Acc=0.174, PPL=464.91
2025-09-20 20:04:47,725 - training.trainer - INFO - Epoch 31, Step 26925: Loss=5.9761, Acc=0.163, PPL=393.90
2025-09-20 20:04:57,007 - training.trainer - INFO - Epoch 31, Step 27025: Loss=5.6445, Acc=0.231, PPL=282.73
2025-09-20 20:05:08,099 - training.trainer - INFO - Epoch 32/100 completed in 83.11s - Train Loss: 5.6961, Train Acc: 0.221, Val Loss: 5.7647, Val Acc: 0.219
2025-09-20 20:05:08,991 - training.trainer - INFO - New best model saved with validation loss: 5.7647
2025-09-20 20:05:08,991 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_32.pt
2025-09-20 20:05:18,586 - training.trainer - INFO - Epoch 32, Step 27171: Loss=5.8271, Acc=0.200, PPL=339.36
2025-09-20 20:05:27,488 - training.trainer - INFO - Epoch 32, Step 27271: Loss=5.7272, Acc=0.222, PPL=307.12
2025-09-20 20:05:36,442 - training.trainer - INFO - Epoch 32, Step 27371: Loss=5.8617, Acc=0.206, PPL=351.33
2025-09-20 20:05:45,746 - training.trainer - INFO - Epoch 32, Step 27471: Loss=5.4374, Acc=0.235, PPL=229.84
2025-09-20 20:05:55,061 - training.trainer - INFO - Epoch 32, Step 27571: Loss=5.9028, Acc=0.217, PPL=366.07
2025-09-20 20:06:04,349 - training.trainer - INFO - Epoch 32, Step 27671: Loss=5.6041, Acc=0.235, PPL=271.54
2025-09-20 20:06:13,145 - training.trainer - INFO - Epoch 32, Step 27771: Loss=5.6853, Acc=0.195, PPL=294.51
2025-09-20 20:06:22,050 - training.trainer - INFO - Epoch 32, Step 27871: Loss=6.0273, Acc=0.194, PPL=414.61
2025-09-20 20:06:33,129 - training.trainer - INFO - Epoch 33/100 completed in 84.14s - Train Loss: 5.6841, Train Acc: 0.222, Val Loss: 5.7549, Val Acc: 0.222
2025-09-20 20:06:33,976 - training.trainer - INFO - New best model saved with validation loss: 5.7549
2025-09-20 20:06:33,977 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_33.pt
2025-09-20 20:06:43,476 - training.trainer - INFO - Epoch 33, Step 28017: Loss=5.9777, Acc=0.183, PPL=394.54
2025-09-20 20:06:52,360 - training.trainer - INFO - Epoch 33, Step 28117: Loss=5.5521, Acc=0.256, PPL=257.78
2025-09-20 20:07:01,420 - training.trainer - INFO - Epoch 33, Step 28217: Loss=5.4388, Acc=0.255, PPL=230.16
2025-09-20 20:07:10,863 - training.trainer - INFO - Epoch 33, Step 28317: Loss=5.7030, Acc=0.210, PPL=299.75
2025-09-20 20:07:20,178 - training.trainer - INFO - Epoch 33, Step 28417: Loss=5.9118, Acc=0.191, PPL=369.39
2025-09-20 20:07:29,308 - training.trainer - INFO - Epoch 33, Step 28517: Loss=5.1240, Acc=0.226, PPL=168.01
2025-09-20 20:07:38,394 - training.trainer - INFO - Epoch 33, Step 28617: Loss=5.3591, Acc=0.259, PPL=212.53
2025-09-20 20:07:47,306 - training.trainer - INFO - Epoch 33, Step 28717: Loss=5.6486, Acc=0.220, PPL=283.90
2025-09-20 20:07:58,605 - training.trainer - INFO - Epoch 34/100 completed in 84.63s - Train Loss: 5.6710, Train Acc: 0.224, Val Loss: 5.7654, Val Acc: 0.218
2025-09-20 20:08:08,433 - training.trainer - INFO - Epoch 34, Step 28863: Loss=5.8992, Acc=0.190, PPL=364.75
2025-09-20 20:08:17,885 - training.trainer - INFO - Epoch 34, Step 28963: Loss=5.7422, Acc=0.218, PPL=311.76
2025-09-20 20:08:26,163 - training.trainer - INFO - Epoch 34, Step 29063: Loss=6.0198, Acc=0.207, PPL=411.48
2025-09-20 20:08:34,653 - training.trainer - INFO - Epoch 34, Step 29163: Loss=5.7899, Acc=0.228, PPL=326.99
2025-09-20 20:08:42,928 - training.trainer - INFO - Epoch 34, Step 29263: Loss=5.2041, Acc=0.281, PPL=182.01
2025-09-20 20:08:50,791 - training.trainer - INFO - Epoch 34, Step 29363: Loss=5.9639, Acc=0.188, PPL=389.12
2025-09-20 20:08:59,070 - training.trainer - INFO - Epoch 34, Step 29463: Loss=5.6577, Acc=0.235, PPL=286.49
2025-09-20 20:09:07,607 - training.trainer - INFO - Epoch 34, Step 29563: Loss=5.4582, Acc=0.227, PPL=234.66
2025-09-20 20:09:18,613 - training.trainer - INFO - Epoch 35/100 completed in 80.01s - Train Loss: 5.6654, Train Acc: 0.225, Val Loss: 5.7526, Val Acc: 0.221
2025-09-20 20:09:19,000 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-20 20:09:19,720 - training.trainer - INFO - New best model saved with validation loss: 5.7526
2025-09-20 20:09:19,720 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-20 20:09:29,632 - training.trainer - INFO - Epoch 35, Step 29709: Loss=6.1500, Acc=0.158, PPL=468.71
2025-09-20 20:09:38,479 - training.trainer - INFO - Epoch 35, Step 29809: Loss=5.3458, Acc=0.277, PPL=209.73
2025-09-20 20:09:47,249 - training.trainer - INFO - Epoch 35, Step 29909: Loss=5.9324, Acc=0.221, PPL=377.07
2025-09-20 20:09:56,206 - training.trainer - INFO - Epoch 35, Step 30009: Loss=5.7665, Acc=0.185, PPL=319.41
2025-09-20 20:10:05,533 - training.trainer - INFO - Epoch 35, Step 30109: Loss=5.4324, Acc=0.232, PPL=228.69
2025-09-20 20:10:14,375 - training.trainer - INFO - Epoch 35, Step 30209: Loss=5.5092, Acc=0.248, PPL=246.95
2025-09-20 20:10:23,349 - training.trainer - INFO - Epoch 35, Step 30309: Loss=5.6990, Acc=0.233, PPL=298.57
2025-09-20 20:10:32,633 - training.trainer - INFO - Epoch 35, Step 30409: Loss=5.7338, Acc=0.191, PPL=309.13
2025-09-20 20:10:44,071 - training.trainer - INFO - Epoch 36/100 completed in 84.35s - Train Loss: 5.6516, Train Acc: 0.227, Val Loss: 5.7399, Val Acc: 0.224
2025-09-20 20:10:44,900 - training.trainer - INFO - New best model saved with validation loss: 5.7399
2025-09-20 20:10:44,900 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_36.pt
2025-09-20 20:10:54,453 - training.trainer - INFO - Epoch 36, Step 30555: Loss=6.1680, Acc=0.172, PPL=477.24
2025-09-20 20:11:03,627 - training.trainer - INFO - Epoch 36, Step 30655: Loss=5.3606, Acc=0.214, PPL=212.85
2025-09-20 20:11:12,672 - training.trainer - INFO - Epoch 36, Step 30755: Loss=5.9284, Acc=0.192, PPL=375.55
2025-09-20 20:11:21,726 - training.trainer - INFO - Epoch 36, Step 30855: Loss=5.1496, Acc=0.265, PPL=172.35
2025-09-20 20:11:30,949 - training.trainer - INFO - Epoch 36, Step 30955: Loss=5.7424, Acc=0.200, PPL=311.80
2025-09-20 20:11:40,220 - training.trainer - INFO - Epoch 36, Step 31055: Loss=5.4797, Acc=0.231, PPL=239.78
2025-09-20 20:11:49,311 - training.trainer - INFO - Epoch 36, Step 31155: Loss=5.0695, Acc=0.344, PPL=159.10
2025-09-20 20:11:58,516 - training.trainer - INFO - Epoch 36, Step 31255: Loss=5.6425, Acc=0.261, PPL=282.17
2025-09-20 20:12:09,579 - training.trainer - INFO - Epoch 37/100 completed in 84.68s - Train Loss: 5.6399, Train Acc: 0.228, Val Loss: 5.7424, Val Acc: 0.221
2025-09-20 20:12:18,928 - training.trainer - INFO - Epoch 37, Step 31401: Loss=5.1358, Acc=0.290, PPL=170.00
2025-09-20 20:12:27,871 - training.trainer - INFO - Epoch 37, Step 31501: Loss=6.1287, Acc=0.214, PPL=458.82
2025-09-20 20:12:35,520 - training.trainer - INFO - Epoch 37, Step 31601: Loss=5.6768, Acc=0.244, PPL=292.02
2025-09-20 20:12:43,968 - training.trainer - INFO - Epoch 37, Step 31701: Loss=6.0181, Acc=0.180, PPL=410.81
2025-09-20 20:12:51,752 - training.trainer - INFO - Epoch 37, Step 31801: Loss=5.9589, Acc=0.160, PPL=387.18
2025-09-20 20:12:59,480 - training.trainer - INFO - Epoch 37, Step 31901: Loss=5.7296, Acc=0.209, PPL=307.85
2025-09-20 20:13:07,337 - training.trainer - INFO - Epoch 37, Step 32001: Loss=5.2597, Acc=0.273, PPL=192.42
2025-09-20 20:13:15,453 - training.trainer - INFO - Epoch 37, Step 32101: Loss=5.6258, Acc=0.232, PPL=277.51
2025-09-20 20:13:26,062 - training.trainer - INFO - Epoch 38/100 completed in 76.48s - Train Loss: 5.6273, Train Acc: 0.230, Val Loss: 5.7296, Val Acc: 0.224
2025-09-20 20:13:26,694 - training.trainer - INFO - New best model saved with validation loss: 5.7296
2025-09-20 20:13:26,694 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_38.pt
2025-09-20 20:13:34,937 - training.trainer - INFO - Epoch 38, Step 32247: Loss=5.5711, Acc=0.250, PPL=262.74
2025-09-20 20:13:42,814 - training.trainer - INFO - Epoch 38, Step 32347: Loss=5.7414, Acc=0.207, PPL=311.49
2025-09-20 20:13:50,743 - training.trainer - INFO - Epoch 38, Step 32447: Loss=5.2724, Acc=0.273, PPL=194.89
2025-09-20 20:13:59,543 - training.trainer - INFO - Epoch 38, Step 32547: Loss=5.5511, Acc=0.282, PPL=257.53
2025-09-20 20:14:08,318 - training.trainer - INFO - Epoch 38, Step 32647: Loss=5.4822, Acc=0.235, PPL=240.38
2025-09-20 20:14:16,374 - training.trainer - INFO - Epoch 38, Step 32747: Loss=5.5615, Acc=0.255, PPL=260.21
2025-09-20 20:14:24,483 - training.trainer - INFO - Epoch 38, Step 32847: Loss=5.6734, Acc=0.202, PPL=291.02
2025-09-20 20:14:32,570 - training.trainer - INFO - Epoch 38, Step 32947: Loss=5.9564, Acc=0.186, PPL=386.22
2025-09-20 20:14:43,553 - training.trainer - INFO - Epoch 39/100 completed in 76.86s - Train Loss: 5.6159, Train Acc: 0.232, Val Loss: 5.7291, Val Acc: 0.223
2025-09-20 20:14:44,421 - training.trainer - INFO - New best model saved with validation loss: 5.7291
2025-09-20 20:14:44,421 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_39.pt
2025-09-20 20:14:53,819 - training.trainer - INFO - Epoch 39, Step 33093: Loss=5.7033, Acc=0.231, PPL=299.85
2025-09-20 20:15:03,282 - training.trainer - INFO - Epoch 39, Step 33193: Loss=5.5928, Acc=0.258, PPL=268.49
2025-09-20 20:15:12,168 - training.trainer - INFO - Epoch 39, Step 33293: Loss=5.7582, Acc=0.203, PPL=316.77
2025-09-20 20:15:21,251 - training.trainer - INFO - Epoch 39, Step 33393: Loss=5.9498, Acc=0.220, PPL=383.68
2025-09-20 20:15:30,741 - training.trainer - INFO - Epoch 39, Step 33493: Loss=5.7520, Acc=0.203, PPL=314.83
2025-09-20 20:15:39,849 - training.trainer - INFO - Epoch 39, Step 33593: Loss=5.7577, Acc=0.196, PPL=316.63
2025-09-20 20:15:48,875 - training.trainer - INFO - Epoch 39, Step 33693: Loss=5.5441, Acc=0.255, PPL=255.71
2025-09-20 20:15:57,740 - training.trainer - INFO - Epoch 39, Step 33793: Loss=5.7953, Acc=0.199, PPL=328.77
2025-09-20 20:16:08,749 - training.trainer - INFO - Epoch 40/100 completed in 84.33s - Train Loss: 5.6116, Train Acc: 0.231, Val Loss: 5.7211, Val Acc: 0.225
2025-09-20 20:16:09,177 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-20 20:16:10,006 - training.trainer - INFO - New best model saved with validation loss: 5.7211
2025-09-20 20:16:10,006 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-20 20:16:19,743 - training.trainer - INFO - Epoch 40, Step 33939: Loss=5.6691, Acc=0.225, PPL=289.77
2025-09-20 20:16:28,883 - training.trainer - INFO - Epoch 40, Step 34039: Loss=5.7390, Acc=0.211, PPL=310.77
2025-09-20 20:16:37,931 - training.trainer - INFO - Epoch 40, Step 34139: Loss=5.7332, Acc=0.231, PPL=308.94
2025-09-20 20:16:46,969 - training.trainer - INFO - Epoch 40, Step 34239: Loss=5.2623, Acc=0.235, PPL=192.93
2025-09-20 20:16:56,242 - training.trainer - INFO - Epoch 40, Step 34339: Loss=5.8735, Acc=0.171, PPL=355.49
2025-09-20 20:17:05,396 - training.trainer - INFO - Epoch 40, Step 34439: Loss=5.7534, Acc=0.203, PPL=315.26
2025-09-20 20:17:14,493 - training.trainer - INFO - Epoch 40, Step 34539: Loss=5.6756, Acc=0.240, PPL=291.68
2025-09-20 20:17:23,535 - training.trainer - INFO - Epoch 40, Step 34639: Loss=5.7243, Acc=0.249, PPL=306.21
2025-09-20 20:17:34,980 - training.trainer - INFO - Epoch 41/100 completed in 84.97s - Train Loss: 5.5983, Train Acc: 0.234, Val Loss: 5.7183, Val Acc: 0.227
2025-09-20 20:17:35,778 - training.trainer - INFO - New best model saved with validation loss: 5.7183
2025-09-20 20:17:35,778 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_41.pt
2025-09-20 20:17:45,395 - training.trainer - INFO - Epoch 41, Step 34785: Loss=5.1845, Acc=0.299, PPL=178.49
2025-09-20 20:17:54,236 - training.trainer - INFO - Epoch 41, Step 34885: Loss=5.8543, Acc=0.221, PPL=348.74
2025-09-20 20:18:03,027 - training.trainer - INFO - Epoch 41, Step 34985: Loss=5.6359, Acc=0.252, PPL=280.31
2025-09-20 20:18:11,532 - training.trainer - INFO - Epoch 41, Step 35085: Loss=5.6508, Acc=0.254, PPL=284.53
2025-09-20 20:18:20,580 - training.trainer - INFO - Epoch 41, Step 35185: Loss=5.6511, Acc=0.268, PPL=284.61
2025-09-20 20:18:29,510 - training.trainer - INFO - Epoch 41, Step 35285: Loss=5.3791, Acc=0.271, PPL=216.84
2025-09-20 20:18:38,247 - training.trainer - INFO - Epoch 41, Step 35385: Loss=5.5485, Acc=0.252, PPL=256.85
2025-09-20 20:18:47,520 - training.trainer - INFO - Epoch 41, Step 35485: Loss=5.1872, Acc=0.277, PPL=178.97
2025-09-20 20:18:58,290 - training.trainer - INFO - Epoch 42/100 completed in 82.51s - Train Loss: 5.5923, Train Acc: 0.233, Val Loss: 5.7040, Val Acc: 0.226
2025-09-20 20:18:59,057 - training.trainer - INFO - New best model saved with validation loss: 5.7040
2025-09-20 20:18:59,057 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_42.pt
2025-09-20 20:19:07,514 - training.trainer - INFO - Epoch 42, Step 35631: Loss=5.6250, Acc=0.209, PPL=277.27
2025-09-20 20:19:15,715 - training.trainer - INFO - Epoch 42, Step 35731: Loss=6.0130, Acc=0.203, PPL=408.70
2025-09-20 20:19:23,907 - training.trainer - INFO - Epoch 42, Step 35831: Loss=4.8842, Acc=0.314, PPL=132.18
2025-09-20 20:19:32,131 - training.trainer - INFO - Epoch 42, Step 35931: Loss=5.4815, Acc=0.234, PPL=240.21
2025-09-20 20:19:40,396 - training.trainer - INFO - Epoch 42, Step 36031: Loss=5.4665, Acc=0.243, PPL=236.63
2025-09-20 20:19:48,123 - training.trainer - INFO - Epoch 42, Step 36131: Loss=5.1522, Acc=0.242, PPL=172.80
2025-09-20 20:19:56,073 - training.trainer - INFO - Epoch 42, Step 36231: Loss=5.1867, Acc=0.242, PPL=178.88
2025-09-20 20:20:04,475 - training.trainer - INFO - Epoch 42, Step 36331: Loss=6.0259, Acc=0.205, PPL=414.03
2025-09-20 20:20:15,188 - training.trainer - INFO - Epoch 43/100 completed in 76.13s - Train Loss: 5.5782, Train Acc: 0.236, Val Loss: 5.7102, Val Acc: 0.225
2025-09-20 20:20:24,810 - training.trainer - INFO - Epoch 43, Step 36477: Loss=5.7039, Acc=0.208, PPL=300.03
2025-09-20 20:20:33,903 - training.trainer - INFO - Epoch 43, Step 36577: Loss=5.5238, Acc=0.230, PPL=250.60
2025-09-20 20:20:42,294 - training.trainer - INFO - Epoch 43, Step 36677: Loss=5.6435, Acc=0.239, PPL=282.46
2025-09-20 20:20:51,121 - training.trainer - INFO - Epoch 43, Step 36777: Loss=5.3445, Acc=0.242, PPL=209.46
2025-09-20 20:21:00,379 - training.trainer - INFO - Epoch 43, Step 36877: Loss=5.7665, Acc=0.205, PPL=319.42
2025-09-20 20:21:09,713 - training.trainer - INFO - Epoch 43, Step 36977: Loss=5.9094, Acc=0.196, PPL=368.48
2025-09-20 20:21:18,834 - training.trainer - INFO - Epoch 43, Step 37077: Loss=5.8946, Acc=0.242, PPL=363.07
2025-09-20 20:21:27,530 - training.trainer - INFO - Epoch 43, Step 37177: Loss=5.0174, Acc=0.377, PPL=151.02
2025-09-20 20:21:38,508 - training.trainer - INFO - Epoch 44/100 completed in 83.32s - Train Loss: 5.5696, Train Acc: 0.238, Val Loss: 5.7091, Val Acc: 0.227
2025-09-20 20:21:48,303 - training.trainer - INFO - Epoch 44, Step 37323: Loss=5.2838, Acc=0.229, PPL=197.11
2025-09-20 20:21:57,294 - training.trainer - INFO - Epoch 44, Step 37423: Loss=5.8987, Acc=0.218, PPL=364.55
2025-09-20 20:22:06,589 - training.trainer - INFO - Epoch 44, Step 37523: Loss=5.2607, Acc=0.236, PPL=192.62
2025-09-20 20:22:15,500 - training.trainer - INFO - Epoch 44, Step 37623: Loss=5.4571, Acc=0.204, PPL=234.41
2025-09-20 20:22:24,460 - training.trainer - INFO - Epoch 44, Step 37723: Loss=5.5599, Acc=0.216, PPL=259.81
2025-09-20 20:22:33,590 - training.trainer - INFO - Epoch 44, Step 37823: Loss=6.0972, Acc=0.235, PPL=444.62
2025-09-20 20:22:42,429 - training.trainer - INFO - Epoch 44, Step 37923: Loss=5.6929, Acc=0.216, PPL=296.75
2025-09-20 20:22:51,281 - training.trainer - INFO - Epoch 44, Step 38023: Loss=6.0145, Acc=0.176, PPL=409.31
2025-09-20 20:23:02,559 - training.trainer - INFO - Epoch 45/100 completed in 84.05s - Train Loss: 5.5643, Train Acc: 0.238, Val Loss: 5.6959, Val Acc: 0.228
2025-09-20 20:23:02,984 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-20 20:23:03,682 - training.trainer - INFO - New best model saved with validation loss: 5.6959
2025-09-20 20:23:03,683 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-20 20:23:13,203 - training.trainer - INFO - Epoch 45, Step 38169: Loss=5.5341, Acc=0.244, PPL=253.19
2025-09-20 20:23:22,664 - training.trainer - INFO - Epoch 45, Step 38269: Loss=5.6443, Acc=0.246, PPL=282.68
2025-09-20 20:23:31,690 - training.trainer - INFO - Epoch 45, Step 38369: Loss=5.5375, Acc=0.269, PPL=254.04
2025-09-20 20:23:40,732 - training.trainer - INFO - Epoch 45, Step 38469: Loss=5.6222, Acc=0.250, PPL=276.49
2025-09-20 20:23:49,639 - training.trainer - INFO - Epoch 45, Step 38569: Loss=5.6737, Acc=0.248, PPL=291.12
2025-09-20 20:23:58,626 - training.trainer - INFO - Epoch 45, Step 38669: Loss=5.3913, Acc=0.225, PPL=219.49
2025-09-20 20:24:06,699 - training.trainer - INFO - Epoch 45, Step 38769: Loss=5.5245, Acc=0.259, PPL=250.76
2025-09-20 20:24:14,637 - training.trainer - INFO - Epoch 45, Step 38869: Loss=5.5280, Acc=0.244, PPL=251.63
2025-09-20 20:24:25,305 - training.trainer - INFO - Epoch 46/100 completed in 81.62s - Train Loss: 5.5559, Train Acc: 0.237, Val Loss: 5.6896, Val Acc: 0.231
2025-09-20 20:24:26,121 - training.trainer - INFO - New best model saved with validation loss: 5.6896
2025-09-20 20:24:26,122 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_46.pt
2025-09-20 20:24:34,828 - training.trainer - INFO - Epoch 46, Step 39015: Loss=5.3269, Acc=0.293, PPL=205.80
2025-09-20 20:24:43,509 - training.trainer - INFO - Epoch 46, Step 39115: Loss=5.5761, Acc=0.205, PPL=264.04
2025-09-20 20:24:52,173 - training.trainer - INFO - Epoch 46, Step 39215: Loss=5.2224, Acc=0.232, PPL=185.38
2025-09-20 20:25:00,968 - training.trainer - INFO - Epoch 46, Step 39315: Loss=5.9591, Acc=0.205, PPL=387.27
2025-09-20 20:25:09,232 - training.trainer - INFO - Epoch 46, Step 39415: Loss=5.5458, Acc=0.229, PPL=256.16
2025-09-20 20:25:18,120 - training.trainer - INFO - Epoch 46, Step 39515: Loss=5.4431, Acc=0.271, PPL=231.16
2025-09-20 20:25:27,267 - training.trainer - INFO - Epoch 46, Step 39615: Loss=5.5608, Acc=0.209, PPL=260.03
2025-09-20 20:25:36,446 - training.trainer - INFO - Epoch 46, Step 39715: Loss=5.6808, Acc=0.232, PPL=293.17
2025-09-20 20:25:48,149 - training.trainer - INFO - Epoch 47/100 completed in 82.03s - Train Loss: 5.5453, Train Acc: 0.240, Val Loss: 5.6987, Val Acc: 0.225
2025-09-20 20:25:57,853 - training.trainer - INFO - Epoch 47, Step 39861: Loss=5.6714, Acc=0.216, PPL=290.44
2025-09-20 20:26:06,740 - training.trainer - INFO - Epoch 47, Step 39961: Loss=5.6519, Acc=0.230, PPL=284.82
2025-09-20 20:26:15,357 - training.trainer - INFO - Epoch 47, Step 40061: Loss=5.9636, Acc=0.159, PPL=389.00
2025-09-20 20:26:24,130 - training.trainer - INFO - Epoch 47, Step 40161: Loss=5.5941, Acc=0.204, PPL=268.83
2025-09-20 20:26:33,162 - training.trainer - INFO - Epoch 47, Step 40261: Loss=5.0124, Acc=0.289, PPL=150.26
2025-09-20 20:26:41,922 - training.trainer - INFO - Epoch 47, Step 40361: Loss=5.6724, Acc=0.217, PPL=290.74
2025-09-20 20:26:50,921 - training.trainer - INFO - Epoch 47, Step 40461: Loss=6.0709, Acc=0.186, PPL=433.09
2025-09-20 20:26:59,271 - training.trainer - INFO - Epoch 47, Step 40561: Loss=5.1427, Acc=0.261, PPL=171.17
2025-09-20 20:27:10,014 - training.trainer - INFO - Epoch 48/100 completed in 81.86s - Train Loss: 5.5382, Train Acc: 0.241, Val Loss: 5.6964, Val Acc: 0.226
2025-09-20 20:27:19,578 - training.trainer - INFO - Epoch 48, Step 40707: Loss=5.5492, Acc=0.230, PPL=257.02
2025-09-20 20:27:28,783 - training.trainer - INFO - Epoch 48, Step 40807: Loss=5.4625, Acc=0.242, PPL=235.68
2025-09-20 20:27:37,854 - training.trainer - INFO - Epoch 48, Step 40907: Loss=5.4314, Acc=0.292, PPL=228.46
2025-09-20 20:27:47,205 - training.trainer - INFO - Epoch 48, Step 41007: Loss=5.6097, Acc=0.211, PPL=273.06
2025-09-20 20:27:56,025 - training.trainer - INFO - Epoch 48, Step 41107: Loss=5.7025, Acc=0.233, PPL=299.62
2025-09-20 20:28:04,980 - training.trainer - INFO - Epoch 48, Step 41207: Loss=5.2210, Acc=0.302, PPL=185.12
2025-09-20 20:28:13,763 - training.trainer - INFO - Epoch 48, Step 41307: Loss=5.9115, Acc=0.228, PPL=369.25
2025-09-20 20:28:22,539 - training.trainer - INFO - Epoch 48, Step 41407: Loss=5.5967, Acc=0.194, PPL=269.55
2025-09-20 20:28:33,625 - training.trainer - INFO - Epoch 49/100 completed in 83.61s - Train Loss: 5.5302, Train Acc: 0.242, Val Loss: 5.6878, Val Acc: 0.230
2025-09-20 20:28:34,484 - training.trainer - INFO - New best model saved with validation loss: 5.6878
2025-09-20 20:28:34,484 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_49.pt
2025-09-20 20:28:44,508 - training.trainer - INFO - Epoch 49, Step 41553: Loss=5.8412, Acc=0.208, PPL=344.18
2025-09-20 20:28:53,068 - training.trainer - INFO - Epoch 49, Step 41653: Loss=5.1369, Acc=0.246, PPL=170.20
2025-09-20 20:29:01,836 - training.trainer - INFO - Epoch 49, Step 41753: Loss=5.4773, Acc=0.221, PPL=239.19
2025-09-20 20:29:10,320 - training.trainer - INFO - Epoch 49, Step 41853: Loss=4.9304, Acc=0.258, PPL=138.43
2025-09-20 20:29:19,173 - training.trainer - INFO - Epoch 49, Step 41953: Loss=5.3160, Acc=0.258, PPL=203.56
2025-09-20 20:29:28,160 - training.trainer - INFO - Epoch 49, Step 42053: Loss=5.7173, Acc=0.231, PPL=304.09
2025-09-20 20:29:37,560 - training.trainer - INFO - Epoch 49, Step 42153: Loss=5.1860, Acc=0.260, PPL=178.76
2025-09-20 20:29:46,524 - training.trainer - INFO - Epoch 49, Step 42253: Loss=6.1439, Acc=0.196, PPL=465.87
2025-09-20 20:29:57,296 - training.trainer - INFO - Epoch 50/100 completed in 82.81s - Train Loss: 5.5223, Train Acc: 0.242, Val Loss: 5.6766, Val Acc: 0.232
2025-09-20 20:29:57,627 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-20 20:29:58,299 - training.trainer - INFO - New best model saved with validation loss: 5.6766
2025-09-20 20:29:58,299 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-20 20:30:07,977 - training.trainer - INFO - Epoch 50, Step 42399: Loss=5.5231, Acc=0.216, PPL=250.40
2025-09-20 20:30:16,929 - training.trainer - INFO - Epoch 50, Step 42499: Loss=5.2094, Acc=0.254, PPL=182.98
2025-09-20 20:30:25,829 - training.trainer - INFO - Epoch 50, Step 42599: Loss=5.3898, Acc=0.269, PPL=219.16
2025-09-20 20:30:34,636 - training.trainer - INFO - Epoch 50, Step 42699: Loss=5.8641, Acc=0.216, PPL=352.16
2025-09-20 20:30:42,467 - training.trainer - INFO - Epoch 50, Step 42799: Loss=5.0188, Acc=0.309, PPL=151.23
2025-09-20 20:30:50,138 - training.trainer - INFO - Epoch 50, Step 42899: Loss=5.8129, Acc=0.196, PPL=334.60
2025-09-20 20:30:58,006 - training.trainer - INFO - Epoch 50, Step 42999: Loss=5.2608, Acc=0.238, PPL=192.64
2025-09-20 20:31:05,842 - training.trainer - INFO - Epoch 50, Step 43099: Loss=5.2521, Acc=0.236, PPL=190.97
2025-09-20 20:31:16,632 - training.trainer - INFO - Epoch 51/100 completed in 78.33s - Train Loss: 5.5160, Train Acc: 0.242, Val Loss: 5.6773, Val Acc: 0.230
2025-09-20 20:31:26,596 - training.trainer - INFO - Epoch 51, Step 43245: Loss=5.6143, Acc=0.223, PPL=274.31
2025-09-20 20:31:35,813 - training.trainer - INFO - Epoch 51, Step 43345: Loss=5.4695, Acc=0.250, PPL=237.34
2025-09-20 20:31:44,472 - training.trainer - INFO - Epoch 51, Step 43445: Loss=5.8871, Acc=0.239, PPL=360.34
2025-09-20 20:31:52,349 - training.trainer - INFO - Epoch 51, Step 43545: Loss=5.5198, Acc=0.252, PPL=249.59
2025-09-20 20:32:00,168 - training.trainer - INFO - Epoch 51, Step 43645: Loss=5.3967, Acc=0.278, PPL=220.68
2025-09-20 20:32:08,175 - training.trainer - INFO - Epoch 51, Step 43745: Loss=5.0996, Acc=0.293, PPL=163.95
2025-09-20 20:32:15,762 - training.trainer - INFO - Epoch 51, Step 43845: Loss=5.3702, Acc=0.268, PPL=214.90
2025-09-20 20:32:23,608 - training.trainer - INFO - Epoch 51, Step 43945: Loss=5.8570, Acc=0.208, PPL=349.67
2025-09-20 20:32:34,410 - training.trainer - INFO - Epoch 52/100 completed in 77.78s - Train Loss: 5.5085, Train Acc: 0.245, Val Loss: 5.6714, Val Acc: 0.234
2025-09-20 20:32:35,131 - training.trainer - INFO - New best model saved with validation loss: 5.6714
2025-09-20 20:32:35,132 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_52.pt
2025-09-20 20:32:44,769 - training.trainer - INFO - Epoch 52, Step 44091: Loss=4.9905, Acc=0.320, PPL=147.01
2025-09-20 20:32:53,808 - training.trainer - INFO - Epoch 52, Step 44191: Loss=4.9571, Acc=0.275, PPL=142.19
2025-09-20 20:33:02,701 - training.trainer - INFO - Epoch 52, Step 44291: Loss=5.6856, Acc=0.240, PPL=294.58
2025-09-20 20:33:11,463 - training.trainer - INFO - Epoch 52, Step 44391: Loss=5.6814, Acc=0.192, PPL=293.37
2025-09-20 20:33:20,147 - training.trainer - INFO - Epoch 52, Step 44491: Loss=5.3939, Acc=0.261, PPL=220.06
2025-09-20 20:33:29,394 - training.trainer - INFO - Epoch 52, Step 44591: Loss=5.4309, Acc=0.227, PPL=228.35
2025-09-20 20:33:38,302 - training.trainer - INFO - Epoch 52, Step 44691: Loss=5.7269, Acc=0.255, PPL=307.02
2025-09-20 20:33:47,233 - training.trainer - INFO - Epoch 52, Step 44791: Loss=5.5903, Acc=0.183, PPL=267.82
2025-09-20 20:33:58,346 - training.trainer - INFO - Epoch 53/100 completed in 83.21s - Train Loss: 5.5044, Train Acc: 0.244, Val Loss: 5.6756, Val Acc: 0.232
2025-09-20 20:34:08,406 - training.trainer - INFO - Epoch 53, Step 44937: Loss=5.5273, Acc=0.291, PPL=251.47
2025-09-20 20:34:17,281 - training.trainer - INFO - Epoch 53, Step 45037: Loss=5.5277, Acc=0.190, PPL=251.58
2025-09-20 20:34:26,706 - training.trainer - INFO - Epoch 53, Step 45137: Loss=5.5338, Acc=0.252, PPL=253.10
2025-09-20 20:34:35,594 - training.trainer - INFO - Epoch 53, Step 45237: Loss=5.5192, Acc=0.261, PPL=249.44
2025-09-20 20:34:44,460 - training.trainer - INFO - Epoch 53, Step 45337: Loss=5.4715, Acc=0.231, PPL=237.82
2025-09-20 20:34:53,346 - training.trainer - INFO - Epoch 53, Step 45437: Loss=5.6932, Acc=0.187, PPL=296.84
2025-09-20 20:35:02,282 - training.trainer - INFO - Epoch 53, Step 45537: Loss=5.5029, Acc=0.263, PPL=245.41
2025-09-20 20:35:11,250 - training.trainer - INFO - Epoch 53, Step 45637: Loss=5.5721, Acc=0.224, PPL=262.99
2025-09-20 20:35:22,765 - training.trainer - INFO - Epoch 54/100 completed in 84.42s - Train Loss: 5.4961, Train Acc: 0.245, Val Loss: 5.6734, Val Acc: 0.232
2025-09-20 20:35:32,298 - training.trainer - INFO - Epoch 54, Step 45783: Loss=5.0582, Acc=0.304, PPL=157.31
2025-09-20 20:35:41,320 - training.trainer - INFO - Epoch 54, Step 45883: Loss=5.4138, Acc=0.218, PPL=224.47
2025-09-20 20:35:50,417 - training.trainer - INFO - Epoch 54, Step 45983: Loss=5.1511, Acc=0.290, PPL=172.62
2025-09-20 20:35:59,323 - training.trainer - INFO - Epoch 54, Step 46083: Loss=5.5100, Acc=0.241, PPL=247.15
2025-09-20 20:36:07,888 - training.trainer - INFO - Epoch 54, Step 46183: Loss=5.4592, Acc=0.218, PPL=234.90
2025-09-20 20:36:16,714 - training.trainer - INFO - Epoch 54, Step 46283: Loss=5.9073, Acc=0.209, PPL=367.70
2025-09-20 20:36:25,843 - training.trainer - INFO - Epoch 54, Step 46383: Loss=5.3805, Acc=0.290, PPL=217.14
2025-09-20 20:36:34,562 - training.trainer - INFO - Epoch 54, Step 46483: Loss=5.7190, Acc=0.208, PPL=304.60
2025-09-20 20:36:45,975 - training.trainer - INFO - Epoch 55/100 completed in 83.21s - Train Loss: 5.4883, Train Acc: 0.247, Val Loss: 5.6724, Val Acc: 0.233
2025-09-20 20:36:46,329 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_55.pt
2025-09-20 20:36:55,846 - training.trainer - INFO - Epoch 55, Step 46629: Loss=5.5799, Acc=0.225, PPL=265.06
2025-09-20 20:37:03,905 - training.trainer - INFO - Epoch 55, Step 46729: Loss=5.4499, Acc=0.243, PPL=232.74
2025-09-20 20:37:11,913 - training.trainer - INFO - Epoch 55, Step 46829: Loss=5.7365, Acc=0.227, PPL=309.97
2025-09-20 20:37:19,748 - training.trainer - INFO - Epoch 55, Step 46929: Loss=5.5465, Acc=0.211, PPL=256.33
2025-09-20 20:37:27,857 - training.trainer - INFO - Epoch 55, Step 47029: Loss=5.5457, Acc=0.263, PPL=256.13
2025-09-20 20:37:36,832 - training.trainer - INFO - Epoch 55, Step 47129: Loss=5.5545, Acc=0.257, PPL=258.40
2025-09-20 20:37:44,897 - training.trainer - INFO - Epoch 55, Step 47229: Loss=5.7871, Acc=0.187, PPL=326.06
2025-09-20 20:37:53,344 - training.trainer - INFO - Epoch 55, Step 47329: Loss=5.1584, Acc=0.328, PPL=173.89
2025-09-20 20:38:05,551 - training.trainer - INFO - Epoch 56/100 completed in 79.22s - Train Loss: 5.4861, Train Acc: 0.247, Val Loss: 5.6707, Val Acc: 0.232
2025-09-20 20:38:06,253 - training.trainer - INFO - New best model saved with validation loss: 5.6707
2025-09-20 20:38:06,254 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_56.pt
2025-09-20 20:38:16,146 - training.trainer - INFO - Epoch 56, Step 47475: Loss=5.7955, Acc=0.250, PPL=328.81
2025-09-20 20:38:25,319 - training.trainer - INFO - Epoch 56, Step 47575: Loss=5.9359, Acc=0.223, PPL=378.37
2025-09-20 20:38:34,320 - training.trainer - INFO - Epoch 56, Step 47675: Loss=5.6310, Acc=0.222, PPL=278.93
2025-09-20 20:38:43,432 - training.trainer - INFO - Epoch 56, Step 47775: Loss=5.4861, Acc=0.258, PPL=241.31
2025-09-20 20:38:52,315 - training.trainer - INFO - Epoch 56, Step 47875: Loss=5.1202, Acc=0.303, PPL=167.37
2025-09-20 20:39:01,399 - training.trainer - INFO - Epoch 56, Step 47975: Loss=5.3560, Acc=0.288, PPL=211.88
2025-09-20 20:39:10,157 - training.trainer - INFO - Epoch 56, Step 48075: Loss=5.8964, Acc=0.206, PPL=363.71
2025-09-20 20:39:18,810 - training.trainer - INFO - Epoch 56, Step 48175: Loss=5.5903, Acc=0.257, PPL=267.81
2025-09-20 20:39:30,083 - training.trainer - INFO - Epoch 57/100 completed in 83.83s - Train Loss: 5.4769, Train Acc: 0.248, Val Loss: 5.6651, Val Acc: 0.233
2025-09-20 20:39:30,873 - training.trainer - INFO - New best model saved with validation loss: 5.6651
2025-09-20 20:39:30,874 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_57.pt
2025-09-20 20:39:40,567 - training.trainer - INFO - Epoch 57, Step 48321: Loss=5.1561, Acc=0.300, PPL=173.48
2025-09-20 20:39:49,713 - training.trainer - INFO - Epoch 57, Step 48421: Loss=5.3642, Acc=0.234, PPL=213.63
2025-09-20 20:39:59,215 - training.trainer - INFO - Epoch 57, Step 48521: Loss=5.2772, Acc=0.281, PPL=195.83
2025-09-20 20:40:07,966 - training.trainer - INFO - Epoch 57, Step 48621: Loss=5.8477, Acc=0.232, PPL=346.42
2025-09-20 20:40:16,710 - training.trainer - INFO - Epoch 57, Step 48721: Loss=5.4046, Acc=0.234, PPL=222.42
2025-09-20 20:40:25,503 - training.trainer - INFO - Epoch 57, Step 48821: Loss=5.7643, Acc=0.212, PPL=318.71
2025-09-20 20:40:34,421 - training.trainer - INFO - Epoch 57, Step 48921: Loss=5.5086, Acc=0.288, PPL=246.80
2025-09-20 20:40:43,580 - training.trainer - INFO - Epoch 57, Step 49021: Loss=5.9823, Acc=0.183, PPL=396.35
2025-09-20 20:40:54,760 - training.trainer - INFO - Epoch 58/100 completed in 83.89s - Train Loss: 5.4738, Train Acc: 0.249, Val Loss: 5.6593, Val Acc: 0.232
2025-09-20 20:40:55,667 - training.trainer - INFO - New best model saved with validation loss: 5.6593
2025-09-20 20:40:55,667 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_58.pt
2025-09-20 20:41:04,918 - training.trainer - INFO - Epoch 58, Step 49167: Loss=5.6989, Acc=0.256, PPL=298.53
2025-09-20 20:41:13,742 - training.trainer - INFO - Epoch 58, Step 49267: Loss=5.6629, Acc=0.230, PPL=287.99
2025-09-20 20:41:22,395 - training.trainer - INFO - Epoch 58, Step 49367: Loss=5.6777, Acc=0.211, PPL=292.29
2025-09-20 20:41:31,354 - training.trainer - INFO - Epoch 58, Step 49467: Loss=5.5083, Acc=0.209, PPL=246.73
2025-09-20 20:41:40,045 - training.trainer - INFO - Epoch 58, Step 49567: Loss=5.1699, Acc=0.322, PPL=175.90
2025-09-20 20:41:48,833 - training.trainer - INFO - Epoch 58, Step 49667: Loss=5.0941, Acc=0.277, PPL=163.05
2025-09-20 20:41:57,946 - training.trainer - INFO - Epoch 58, Step 49767: Loss=5.4283, Acc=0.261, PPL=227.76
2025-09-20 20:42:06,745 - training.trainer - INFO - Epoch 58, Step 49867: Loss=5.4855, Acc=0.265, PPL=241.16
2025-09-20 20:42:17,963 - training.trainer - INFO - Epoch 59/100 completed in 82.30s - Train Loss: 5.4678, Train Acc: 0.248, Val Loss: 5.6608, Val Acc: 0.237
2025-09-20 20:42:27,509 - training.trainer - INFO - Epoch 59, Step 50013: Loss=5.4810, Acc=0.242, PPL=240.09
2025-09-20 20:42:36,317 - training.trainer - INFO - Epoch 59, Step 50113: Loss=5.2463, Acc=0.284, PPL=189.86
2025-09-20 20:42:45,508 - training.trainer - INFO - Epoch 59, Step 50213: Loss=5.3876, Acc=0.255, PPL=218.69
2025-09-20 20:42:54,273 - training.trainer - INFO - Epoch 59, Step 50313: Loss=5.6356, Acc=0.237, PPL=280.21
2025-09-20 20:43:03,211 - training.trainer - INFO - Epoch 59, Step 50413: Loss=5.5577, Acc=0.259, PPL=259.21
2025-09-20 20:43:12,461 - training.trainer - INFO - Epoch 59, Step 50513: Loss=5.0146, Acc=0.318, PPL=150.59
2025-09-20 20:43:21,622 - training.trainer - INFO - Epoch 59, Step 50613: Loss=5.7453, Acc=0.247, PPL=312.72
2025-09-20 20:43:30,301 - training.trainer - INFO - Epoch 59, Step 50713: Loss=6.0587, Acc=0.197, PPL=427.80
2025-09-20 20:43:41,555 - training.trainer - INFO - Epoch 60/100 completed in 83.59s - Train Loss: 5.4607, Train Acc: 0.250, Val Loss: 5.6596, Val Acc: 0.233
2025-09-20 20:43:41,925 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_60.pt
2025-09-20 20:43:51,224 - training.trainer - INFO - Epoch 60, Step 50859: Loss=5.2193, Acc=0.317, PPL=184.80
2025-09-20 20:44:00,043 - training.trainer - INFO - Epoch 60, Step 50959: Loss=5.8321, Acc=0.223, PPL=341.06
2025-09-20 20:44:09,011 - training.trainer - INFO - Epoch 60, Step 51059: Loss=5.4814, Acc=0.253, PPL=240.19
2025-09-20 20:44:18,010 - training.trainer - INFO - Epoch 60, Step 51159: Loss=5.2218, Acc=0.271, PPL=185.26
2025-09-20 20:44:26,900 - training.trainer - INFO - Epoch 60, Step 51259: Loss=5.6705, Acc=0.236, PPL=290.17
2025-09-20 20:44:35,776 - training.trainer - INFO - Epoch 60, Step 51359: Loss=4.8050, Acc=0.291, PPL=122.12
2025-09-20 20:44:44,802 - training.trainer - INFO - Epoch 60, Step 51459: Loss=5.3341, Acc=0.280, PPL=207.28
2025-09-20 20:44:53,724 - training.trainer - INFO - Epoch 60, Step 51559: Loss=4.9719, Acc=0.234, PPL=144.30
2025-09-20 20:45:07,082 - training.trainer - INFO - Epoch 61/100 completed in 85.16s - Train Loss: 5.4551, Train Acc: 0.250, Val Loss: 5.6612, Val Acc: 0.234
2025-09-20 20:45:16,808 - training.trainer - INFO - Epoch 61, Step 51705: Loss=5.4594, Acc=0.255, PPL=234.96
2025-09-20 20:45:26,210 - training.trainer - INFO - Epoch 61, Step 51805: Loss=5.8613, Acc=0.213, PPL=351.19
2025-09-20 20:45:35,239 - training.trainer - INFO - Epoch 61, Step 51905: Loss=5.7259, Acc=0.221, PPL=306.70
2025-09-20 20:45:44,435 - training.trainer - INFO - Epoch 61, Step 52005: Loss=5.6935, Acc=0.188, PPL=296.93
2025-09-20 20:45:53,749 - training.trainer - INFO - Epoch 61, Step 52105: Loss=5.5330, Acc=0.216, PPL=252.90
2025-09-20 20:46:02,669 - training.trainer - INFO - Epoch 61, Step 52205: Loss=5.2816, Acc=0.231, PPL=196.68
2025-09-20 20:46:11,540 - training.trainer - INFO - Epoch 61, Step 52305: Loss=5.1439, Acc=0.269, PPL=171.38
2025-09-20 20:46:20,613 - training.trainer - INFO - Epoch 61, Step 52405: Loss=5.6199, Acc=0.252, PPL=275.86
2025-09-20 20:46:31,789 - training.trainer - INFO - Epoch 62/100 completed in 84.71s - Train Loss: 5.4523, Train Acc: 0.252, Val Loss: 5.6616, Val Acc: 0.234
2025-09-20 20:46:41,639 - training.trainer - INFO - Epoch 62, Step 52551: Loss=5.0752, Acc=0.248, PPL=160.01
2025-09-20 20:46:50,820 - training.trainer - INFO - Epoch 62, Step 52651: Loss=5.4939, Acc=0.250, PPL=243.20
2025-09-20 20:46:59,703 - training.trainer - INFO - Epoch 62, Step 52751: Loss=5.2200, Acc=0.304, PPL=184.93
2025-09-20 20:47:08,838 - training.trainer - INFO - Epoch 62, Step 52851: Loss=5.5429, Acc=0.259, PPL=255.41
2025-09-20 20:47:17,897 - training.trainer - INFO - Epoch 62, Step 52951: Loss=4.5134, Acc=0.309, PPL=91.23
2025-09-20 20:47:27,048 - training.trainer - INFO - Epoch 62, Step 53051: Loss=5.3560, Acc=0.236, PPL=211.88
2025-09-20 20:47:35,984 - training.trainer - INFO - Epoch 62, Step 53151: Loss=5.5298, Acc=0.218, PPL=252.09
2025-09-20 20:47:44,876 - training.trainer - INFO - Epoch 62, Step 53251: Loss=5.4161, Acc=0.276, PPL=225.00
2025-09-20 20:47:55,652 - training.trainer - INFO - Epoch 63/100 completed in 83.86s - Train Loss: 5.4489, Train Acc: 0.251, Val Loss: 5.6557, Val Acc: 0.237
2025-09-20 20:47:56,466 - training.trainer - INFO - New best model saved with validation loss: 5.6557
2025-09-20 20:47:56,466 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_63.pt
2025-09-20 20:48:06,094 - training.trainer - INFO - Epoch 63, Step 53397: Loss=5.2857, Acc=0.259, PPL=197.50
2025-09-20 20:48:15,334 - training.trainer - INFO - Epoch 63, Step 53497: Loss=5.4192, Acc=0.273, PPL=225.69
2025-09-20 20:48:24,427 - training.trainer - INFO - Epoch 63, Step 53597: Loss=5.8662, Acc=0.217, PPL=352.91
2025-09-20 20:48:33,401 - training.trainer - INFO - Epoch 63, Step 53697: Loss=5.1532, Acc=0.272, PPL=172.99
2025-09-20 20:48:42,939 - training.trainer - INFO - Epoch 63, Step 53797: Loss=5.4450, Acc=0.260, PPL=231.60
2025-09-20 20:48:51,881 - training.trainer - INFO - Epoch 63, Step 53897: Loss=5.2228, Acc=0.256, PPL=185.45
2025-09-20 20:49:00,767 - training.trainer - INFO - Epoch 63, Step 53997: Loss=5.2555, Acc=0.283, PPL=191.61
2025-09-20 20:49:09,477 - training.trainer - INFO - Epoch 63, Step 54097: Loss=5.0451, Acc=0.291, PPL=155.26
2025-09-20 20:49:20,495 - training.trainer - INFO - Epoch 64/100 completed in 84.03s - Train Loss: 5.4473, Train Acc: 0.251, Val Loss: 5.6600, Val Acc: 0.234
2025-09-20 20:49:30,114 - training.trainer - INFO - Epoch 64, Step 54243: Loss=5.0615, Acc=0.274, PPL=157.83
2025-09-20 20:49:39,083 - training.trainer - INFO - Epoch 64, Step 54343: Loss=5.5152, Acc=0.254, PPL=248.45
2025-09-20 20:49:47,917 - training.trainer - INFO - Epoch 64, Step 54443: Loss=5.5989, Acc=0.233, PPL=270.12
2025-09-20 20:49:56,523 - training.trainer - INFO - Epoch 64, Step 54543: Loss=5.5912, Acc=0.226, PPL=268.07
2025-09-20 20:50:05,383 - training.trainer - INFO - Epoch 64, Step 54643: Loss=5.3000, Acc=0.260, PPL=200.33
2025-09-20 20:50:14,270 - training.trainer - INFO - Epoch 64, Step 54743: Loss=5.5358, Acc=0.258, PPL=253.60
2025-09-20 20:50:23,459 - training.trainer - INFO - Epoch 64, Step 54843: Loss=5.2067, Acc=0.303, PPL=182.48
2025-09-20 20:50:32,562 - training.trainer - INFO - Epoch 64, Step 54943: Loss=4.8883, Acc=0.327, PPL=132.72
2025-09-20 20:50:44,140 - training.trainer - INFO - Epoch 65/100 completed in 83.64s - Train Loss: 5.4396, Train Acc: 0.252, Val Loss: 5.6576, Val Acc: 0.234
2025-09-20 20:50:44,501 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_65.pt
2025-09-20 20:50:54,010 - training.trainer - INFO - Epoch 65, Step 55089: Loss=4.7812, Acc=0.314, PPL=119.25
2025-09-20 20:51:03,027 - training.trainer - INFO - Epoch 65, Step 55189: Loss=5.6313, Acc=0.202, PPL=279.02
2025-09-20 20:51:11,647 - training.trainer - INFO - Epoch 65, Step 55289: Loss=5.7587, Acc=0.269, PPL=316.94
2025-09-20 20:51:20,809 - training.trainer - INFO - Epoch 65, Step 55389: Loss=5.6568, Acc=0.223, PPL=286.24
2025-09-20 20:51:29,849 - training.trainer - INFO - Epoch 65, Step 55489: Loss=5.4444, Acc=0.242, PPL=231.47
2025-09-20 20:51:38,833 - training.trainer - INFO - Epoch 65, Step 55589: Loss=5.4509, Acc=0.244, PPL=232.97
2025-09-20 20:51:48,000 - training.trainer - INFO - Epoch 65, Step 55689: Loss=5.9257, Acc=0.166, PPL=374.53
2025-09-20 20:51:57,096 - training.trainer - INFO - Epoch 65, Step 55789: Loss=5.3314, Acc=0.269, PPL=206.73
2025-09-20 20:52:08,470 - training.trainer - INFO - Epoch 66/100 completed in 83.97s - Train Loss: 5.4390, Train Acc: 0.251, Val Loss: 5.6559, Val Acc: 0.234
2025-09-20 20:52:18,084 - training.trainer - INFO - Epoch 66, Step 55935: Loss=5.0637, Acc=0.306, PPL=158.17
2025-09-20 20:52:27,122 - training.trainer - INFO - Epoch 66, Step 56035: Loss=5.3941, Acc=0.205, PPL=220.10
2025-09-20 20:52:36,009 - training.trainer - INFO - Epoch 66, Step 56135: Loss=5.5278, Acc=0.196, PPL=251.59
2025-09-20 20:52:45,194 - training.trainer - INFO - Epoch 66, Step 56235: Loss=5.3372, Acc=0.229, PPL=207.94
2025-09-20 20:52:54,226 - training.trainer - INFO - Epoch 66, Step 56335: Loss=5.5150, Acc=0.239, PPL=248.40
2025-09-20 20:53:02,844 - training.trainer - INFO - Epoch 66, Step 56435: Loss=5.4343, Acc=0.286, PPL=229.13
2025-09-20 20:53:11,501 - training.trainer - INFO - Epoch 66, Step 56535: Loss=5.5542, Acc=0.235, PPL=258.31
2025-09-20 20:53:20,325 - training.trainer - INFO - Epoch 66, Step 56635: Loss=5.8107, Acc=0.233, PPL=333.86
2025-09-20 20:53:31,482 - training.trainer - INFO - Epoch 67/100 completed in 83.01s - Train Loss: 5.4307, Train Acc: 0.253, Val Loss: 5.6560, Val Acc: 0.236
2025-09-20 20:53:41,203 - training.trainer - INFO - Epoch 67, Step 56781: Loss=5.5030, Acc=0.238, PPL=245.42
2025-09-20 20:53:50,355 - training.trainer - INFO - Epoch 67, Step 56881: Loss=5.5607, Acc=0.212, PPL=259.99
2025-09-20 20:53:59,526 - training.trainer - INFO - Epoch 67, Step 56981: Loss=5.8267, Acc=0.190, PPL=339.25
2025-09-20 20:54:08,521 - training.trainer - INFO - Epoch 67, Step 57081: Loss=5.5121, Acc=0.255, PPL=247.66
2025-09-20 20:54:17,054 - training.trainer - INFO - Epoch 67, Step 57181: Loss=5.5473, Acc=0.266, PPL=256.54
2025-09-20 20:54:24,859 - training.trainer - INFO - Epoch 67, Step 57281: Loss=5.3661, Acc=0.268, PPL=214.03
2025-09-20 20:54:33,485 - training.trainer - INFO - Epoch 67, Step 57381: Loss=5.1309, Acc=0.283, PPL=169.17
2025-09-20 20:54:41,392 - training.trainer - INFO - Epoch 67, Step 57481: Loss=5.0681, Acc=0.321, PPL=158.87
2025-09-20 20:54:52,376 - training.trainer - INFO - Epoch 68/100 completed in 80.89s - Train Loss: 5.4258, Train Acc: 0.252, Val Loss: 5.6518, Val Acc: 0.237
2025-09-20 20:54:53,208 - training.trainer - INFO - New best model saved with validation loss: 5.6518
2025-09-20 20:54:53,208 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_68.pt
2025-09-20 20:55:02,663 - training.trainer - INFO - Epoch 68, Step 57627: Loss=5.5371, Acc=0.241, PPL=253.95
2025-09-20 20:55:11,617 - training.trainer - INFO - Epoch 68, Step 57727: Loss=5.2369, Acc=0.253, PPL=188.08
2025-09-20 20:55:20,868 - training.trainer - INFO - Epoch 68, Step 57827: Loss=4.8889, Acc=0.333, PPL=132.80
2025-09-20 20:55:29,771 - training.trainer - INFO - Epoch 68, Step 57927: Loss=5.1802, Acc=0.311, PPL=177.71
2025-09-20 20:55:38,976 - training.trainer - INFO - Epoch 68, Step 58027: Loss=5.2731, Acc=0.234, PPL=195.02
2025-09-20 20:55:47,491 - training.trainer - INFO - Epoch 68, Step 58127: Loss=5.3552, Acc=0.257, PPL=211.71
2025-09-20 20:55:55,807 - training.trainer - INFO - Epoch 68, Step 58227: Loss=5.6360, Acc=0.210, PPL=280.33
2025-09-20 20:56:04,196 - training.trainer - INFO - Epoch 68, Step 58327: Loss=5.7273, Acc=0.180, PPL=307.14
2025-09-20 20:56:15,432 - training.trainer - INFO - Epoch 69/100 completed in 82.22s - Train Loss: 5.4260, Train Acc: 0.254, Val Loss: 5.6504, Val Acc: 0.236
2025-09-20 20:56:16,314 - training.trainer - INFO - New best model saved with validation loss: 5.6504
2025-09-20 20:56:16,315 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_69.pt
2025-09-20 20:56:26,087 - training.trainer - INFO - Epoch 69, Step 58473: Loss=5.3914, Acc=0.271, PPL=219.50
2025-09-20 20:56:35,221 - training.trainer - INFO - Epoch 69, Step 58573: Loss=5.5381, Acc=0.186, PPL=254.19
2025-09-20 20:56:44,228 - training.trainer - INFO - Epoch 69, Step 58673: Loss=5.1448, Acc=0.267, PPL=171.53
2025-09-20 20:56:53,307 - training.trainer - INFO - Epoch 69, Step 58773: Loss=4.6436, Acc=0.369, PPL=103.91
2025-09-20 20:57:02,294 - training.trainer - INFO - Epoch 69, Step 58873: Loss=5.7954, Acc=0.250, PPL=328.79
2025-09-20 20:57:11,504 - training.trainer - INFO - Epoch 69, Step 58973: Loss=5.5532, Acc=0.235, PPL=258.06
2025-09-20 20:57:20,312 - training.trainer - INFO - Epoch 69, Step 59073: Loss=5.1641, Acc=0.345, PPL=174.89
2025-09-20 20:57:29,572 - training.trainer - INFO - Epoch 69, Step 59173: Loss=5.3809, Acc=0.310, PPL=217.22
2025-09-20 20:57:40,846 - training.trainer - INFO - Epoch 70/100 completed in 84.53s - Train Loss: 5.4220, Train Acc: 0.255, Val Loss: 5.6508, Val Acc: 0.238
2025-09-20 20:57:41,251 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_70.pt
2025-09-20 20:57:50,953 - training.trainer - INFO - Epoch 70, Step 59319: Loss=5.2401, Acc=0.237, PPL=188.70
2025-09-20 20:57:59,957 - training.trainer - INFO - Epoch 70, Step 59419: Loss=5.7839, Acc=0.220, PPL=325.04
2025-09-20 20:58:08,952 - training.trainer - INFO - Epoch 70, Step 59519: Loss=5.2436, Acc=0.299, PPL=189.34
2025-09-20 20:58:17,442 - training.trainer - INFO - Epoch 70, Step 59619: Loss=5.4019, Acc=0.233, PPL=221.83
2025-09-20 20:58:25,494 - training.trainer - INFO - Epoch 70, Step 59719: Loss=5.8516, Acc=0.203, PPL=347.78
2025-09-20 20:58:33,723 - training.trainer - INFO - Epoch 70, Step 59819: Loss=5.4706, Acc=0.269, PPL=237.61
2025-09-20 20:58:41,402 - training.trainer - INFO - Epoch 70, Step 59919: Loss=5.8061, Acc=0.191, PPL=332.31
2025-09-20 20:58:49,432 - training.trainer - INFO - Epoch 70, Step 60019: Loss=4.9935, Acc=0.403, PPL=147.45
2025-09-20 20:58:59,809 - training.trainer - INFO - Epoch 71/100 completed in 78.56s - Train Loss: 5.4138, Train Acc: 0.254, Val Loss: 5.6520, Val Acc: 0.235
2025-09-20 20:59:08,123 - training.trainer - INFO - Epoch 71, Step 60165: Loss=5.7352, Acc=0.247, PPL=309.59
2025-09-20 20:59:15,991 - training.trainer - INFO - Epoch 71, Step 60265: Loss=5.6255, Acc=0.225, PPL=277.41
2025-09-20 20:59:24,237 - training.trainer - INFO - Epoch 71, Step 60365: Loss=5.4796, Acc=0.236, PPL=239.76
2025-09-20 20:59:32,130 - training.trainer - INFO - Epoch 71, Step 60465: Loss=5.7510, Acc=0.203, PPL=314.51
2025-09-20 20:59:40,169 - training.trainer - INFO - Epoch 71, Step 60565: Loss=4.9876, Acc=0.302, PPL=146.58
2025-09-20 20:59:48,312 - training.trainer - INFO - Epoch 71, Step 60665: Loss=5.3616, Acc=0.272, PPL=213.06
2025-09-20 20:59:55,973 - training.trainer - INFO - Epoch 71, Step 60765: Loss=5.5925, Acc=0.235, PPL=268.40
2025-09-20 21:00:04,398 - training.trainer - INFO - Epoch 71, Step 60865: Loss=5.5842, Acc=0.229, PPL=266.18
2025-09-20 21:00:15,071 - training.trainer - INFO - Epoch 72/100 completed in 75.26s - Train Loss: 5.4156, Train Acc: 0.255, Val Loss: 5.6485, Val Acc: 0.239
2025-09-20 21:00:15,782 - training.trainer - INFO - New best model saved with validation loss: 5.6485
2025-09-20 21:00:15,783 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_72.pt
2025-09-20 21:00:25,196 - training.trainer - INFO - Epoch 72, Step 61011: Loss=4.9851, Acc=0.296, PPL=146.21
2025-09-20 21:00:34,563 - training.trainer - INFO - Epoch 72, Step 61111: Loss=5.4483, Acc=0.238, PPL=232.37
2025-09-20 21:00:43,667 - training.trainer - INFO - Epoch 72, Step 61211: Loss=4.4523, Acc=0.383, PPL=85.82
2025-09-20 21:00:53,050 - training.trainer - INFO - Epoch 72, Step 61311: Loss=5.3994, Acc=0.288, PPL=221.28
2025-09-20 21:01:01,963 - training.trainer - INFO - Epoch 72, Step 61411: Loss=5.1624, Acc=0.283, PPL=174.58
2025-09-20 21:01:10,633 - training.trainer - INFO - Epoch 72, Step 61511: Loss=5.3908, Acc=0.292, PPL=219.39
2025-09-20 21:01:19,931 - training.trainer - INFO - Epoch 72, Step 61611: Loss=5.2742, Acc=0.276, PPL=195.23
2025-09-20 21:01:28,856 - training.trainer - INFO - Epoch 72, Step 61711: Loss=5.2312, Acc=0.234, PPL=187.01
2025-09-20 21:01:40,179 - training.trainer - INFO - Epoch 73/100 completed in 84.40s - Train Loss: 5.4150, Train Acc: 0.255, Val Loss: 5.6507, Val Acc: 0.236
2025-09-20 21:01:49,741 - training.trainer - INFO - Epoch 73, Step 61857: Loss=5.1496, Acc=0.281, PPL=172.37
2025-09-20 21:01:58,793 - training.trainer - INFO - Epoch 73, Step 61957: Loss=5.2659, Acc=0.232, PPL=193.63
2025-09-20 21:02:07,826 - training.trainer - INFO - Epoch 73, Step 62057: Loss=5.7828, Acc=0.229, PPL=324.66
2025-09-20 21:02:16,864 - training.trainer - INFO - Epoch 73, Step 62157: Loss=5.6316, Acc=0.214, PPL=279.12
2025-09-20 21:02:26,137 - training.trainer - INFO - Epoch 73, Step 62257: Loss=5.7477, Acc=0.179, PPL=313.47
2025-09-20 21:02:35,079 - training.trainer - INFO - Epoch 73, Step 62357: Loss=5.2109, Acc=0.250, PPL=183.27
2025-09-20 21:02:44,356 - training.trainer - INFO - Epoch 73, Step 62457: Loss=5.3174, Acc=0.259, PPL=203.85
2025-09-20 21:02:53,523 - training.trainer - INFO - Epoch 73, Step 62557: Loss=5.7397, Acc=0.201, PPL=310.97
2025-09-20 21:03:04,386 - training.trainer - INFO - Epoch 74/100 completed in 84.21s - Train Loss: 5.4119, Train Acc: 0.255, Val Loss: 5.6444, Val Acc: 0.239
2025-09-20 21:03:05,072 - training.trainer - INFO - New best model saved with validation loss: 5.6444
2025-09-20 21:03:05,072 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_74.pt
2025-09-20 21:03:14,743 - training.trainer - INFO - Epoch 74, Step 62703: Loss=5.5927, Acc=0.216, PPL=268.46
2025-09-20 21:03:23,326 - training.trainer - INFO - Epoch 74, Step 62803: Loss=5.2605, Acc=0.279, PPL=192.59
2025-09-20 21:03:31,942 - training.trainer - INFO - Epoch 74, Step 62903: Loss=5.1334, Acc=0.260, PPL=169.60
2025-09-20 21:03:40,540 - training.trainer - INFO - Epoch 74, Step 63003: Loss=5.1370, Acc=0.331, PPL=170.21
2025-09-20 21:03:49,416 - training.trainer - INFO - Epoch 74, Step 63103: Loss=5.1855, Acc=0.288, PPL=178.67
2025-09-20 21:03:58,298 - training.trainer - INFO - Epoch 74, Step 63203: Loss=5.2963, Acc=0.255, PPL=199.61
2025-09-20 21:04:07,138 - training.trainer - INFO - Epoch 74, Step 63303: Loss=5.5067, Acc=0.275, PPL=246.33
2025-09-20 21:04:16,028 - training.trainer - INFO - Epoch 74, Step 63403: Loss=5.7388, Acc=0.237, PPL=310.68
2025-09-20 21:04:27,135 - training.trainer - INFO - Epoch 75/100 completed in 82.06s - Train Loss: 5.4079, Train Acc: 0.256, Val Loss: 5.6481, Val Acc: 0.237
2025-09-20 21:04:27,527 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_75.pt
2025-09-20 21:04:36,624 - training.trainer - INFO - Epoch 75, Step 63549: Loss=4.9136, Acc=0.300, PPL=136.13
2025-09-20 21:04:45,441 - training.trainer - INFO - Epoch 75, Step 63649: Loss=4.8821, Acc=0.272, PPL=131.91
2025-09-20 21:04:54,598 - training.trainer - INFO - Epoch 75, Step 63749: Loss=5.4731, Acc=0.263, PPL=238.20
2025-09-20 21:05:03,327 - training.trainer - INFO - Epoch 75, Step 63849: Loss=5.5248, Acc=0.242, PPL=250.83
2025-09-20 21:05:12,471 - training.trainer - INFO - Epoch 75, Step 63949: Loss=5.6325, Acc=0.184, PPL=279.36
2025-09-20 21:05:21,455 - training.trainer - INFO - Epoch 75, Step 64049: Loss=5.6203, Acc=0.218, PPL=275.96
2025-09-20 21:05:30,425 - training.trainer - INFO - Epoch 75, Step 64149: Loss=5.3793, Acc=0.282, PPL=216.86
2025-09-20 21:05:39,257 - training.trainer - INFO - Epoch 75, Step 64249: Loss=5.5537, Acc=0.259, PPL=258.20
2025-09-20 21:05:50,519 - training.trainer - INFO - Epoch 76/100 completed in 82.99s - Train Loss: 5.4081, Train Acc: 0.255, Val Loss: 5.6439, Val Acc: 0.238
2025-09-20 21:05:51,245 - training.trainer - INFO - New best model saved with validation loss: 5.6439
2025-09-20 21:05:51,246 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_76.pt
2025-09-20 21:06:00,813 - training.trainer - INFO - Epoch 76, Step 64395: Loss=5.1808, Acc=0.317, PPL=177.83
2025-09-20 21:06:09,663 - training.trainer - INFO - Epoch 76, Step 64495: Loss=4.9565, Acc=0.283, PPL=142.09
2025-09-20 21:06:17,780 - training.trainer - INFO - Epoch 76, Step 64595: Loss=5.6916, Acc=0.247, PPL=296.35
2025-09-20 21:06:25,695 - training.trainer - INFO - Epoch 76, Step 64695: Loss=5.4072, Acc=0.349, PPL=223.00
2025-09-20 21:06:33,823 - training.trainer - INFO - Epoch 76, Step 64795: Loss=5.1721, Acc=0.255, PPL=176.29
2025-09-20 21:06:42,845 - training.trainer - INFO - Epoch 76, Step 64895: Loss=5.5271, Acc=0.250, PPL=251.41
2025-09-20 21:06:51,611 - training.trainer - INFO - Epoch 76, Step 64995: Loss=5.8346, Acc=0.238, PPL=341.93
2025-09-20 21:07:00,933 - training.trainer - INFO - Epoch 76, Step 65095: Loss=5.0464, Acc=0.278, PPL=155.46
2025-09-20 21:07:12,239 - training.trainer - INFO - Epoch 77/100 completed in 80.99s - Train Loss: 5.4002, Train Acc: 0.257, Val Loss: 5.6467, Val Acc: 0.238
2025-09-20 21:07:22,090 - training.trainer - INFO - Epoch 77, Step 65241: Loss=5.3940, Acc=0.250, PPL=220.07
2025-09-20 21:07:30,723 - training.trainer - INFO - Epoch 77, Step 65341: Loss=5.5512, Acc=0.236, PPL=257.54
2025-09-20 21:07:39,863 - training.trainer - INFO - Epoch 77, Step 65441: Loss=5.3804, Acc=0.248, PPL=217.11
2025-09-20 21:07:48,559 - training.trainer - INFO - Epoch 77, Step 65541: Loss=5.2191, Acc=0.277, PPL=184.77
2025-09-20 21:07:57,131 - training.trainer - INFO - Epoch 77, Step 65641: Loss=5.7667, Acc=0.208, PPL=319.49
2025-09-20 21:08:05,651 - training.trainer - INFO - Epoch 77, Step 65741: Loss=5.5604, Acc=0.240, PPL=259.93
2025-09-20 21:08:14,504 - training.trainer - INFO - Epoch 77, Step 65841: Loss=5.2638, Acc=0.231, PPL=193.22
2025-09-20 21:08:23,269 - training.trainer - INFO - Epoch 77, Step 65941: Loss=5.4919, Acc=0.233, PPL=242.73
2025-09-20 21:08:34,510 - training.trainer - INFO - Epoch 78/100 completed in 82.27s - Train Loss: 5.4034, Train Acc: 0.256, Val Loss: 5.6455, Val Acc: 0.239
2025-09-20 21:08:43,992 - training.trainer - INFO - Epoch 78, Step 66087: Loss=5.0344, Acc=0.318, PPL=153.61
2025-09-20 21:08:52,869 - training.trainer - INFO - Epoch 78, Step 66187: Loss=5.5085, Acc=0.251, PPL=246.78
2025-09-20 21:09:01,417 - training.trainer - INFO - Epoch 78, Step 66287: Loss=5.3991, Acc=0.248, PPL=221.21
2025-09-20 21:09:10,104 - training.trainer - INFO - Epoch 78, Step 66387: Loss=5.6064, Acc=0.204, PPL=272.16
2025-09-20 21:09:19,004 - training.trainer - INFO - Epoch 78, Step 66487: Loss=5.6424, Acc=0.206, PPL=282.13
2025-09-20 21:09:27,804 - training.trainer - INFO - Epoch 78, Step 66587: Loss=5.5920, Acc=0.220, PPL=268.28
2025-09-20 21:09:36,908 - training.trainer - INFO - Epoch 78, Step 66687: Loss=5.6085, Acc=0.212, PPL=272.73
2025-09-20 21:09:45,995 - training.trainer - INFO - Epoch 78, Step 66787: Loss=5.2446, Acc=0.281, PPL=189.53
2025-09-20 21:09:57,020 - training.trainer - INFO - Epoch 79/100 completed in 82.51s - Train Loss: 5.3970, Train Acc: 0.257, Val Loss: 5.6512, Val Acc: 0.237
2025-09-20 21:10:06,265 - training.trainer - INFO - Epoch 79, Step 66933: Loss=5.3469, Acc=0.220, PPL=209.97
2025-09-20 21:10:15,510 - training.trainer - INFO - Epoch 79, Step 67033: Loss=5.4245, Acc=0.243, PPL=226.91
2025-09-20 21:10:24,680 - training.trainer - INFO - Epoch 79, Step 67133: Loss=5.4426, Acc=0.225, PPL=231.04
2025-09-20 21:10:33,556 - training.trainer - INFO - Epoch 79, Step 67233: Loss=5.3717, Acc=0.237, PPL=215.24
2025-09-20 21:10:42,065 - training.trainer - INFO - Epoch 79, Step 67333: Loss=5.3096, Acc=0.301, PPL=202.27
2025-09-20 21:10:50,035 - training.trainer - INFO - Epoch 79, Step 67433: Loss=5.5149, Acc=0.258, PPL=248.36
2025-09-20 21:10:57,962 - training.trainer - INFO - Epoch 79, Step 67533: Loss=5.6924, Acc=0.206, PPL=296.60
2025-09-20 21:11:05,773 - training.trainer - INFO - Epoch 79, Step 67633: Loss=5.6578, Acc=0.181, PPL=286.52
2025-09-20 21:11:16,462 - training.trainer - INFO - Epoch 80/100 completed in 79.44s - Train Loss: 5.4007, Train Acc: 0.257, Val Loss: 5.6462, Val Acc: 0.238
2025-09-20 21:11:16,867 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_80.pt
2025-09-20 21:11:26,142 - training.trainer - INFO - Epoch 80, Step 67779: Loss=6.0422, Acc=0.207, PPL=420.81
2025-09-20 21:11:34,604 - training.trainer - INFO - Epoch 80, Step 67879: Loss=5.0805, Acc=0.375, PPL=160.86
2025-09-20 21:11:43,239 - training.trainer - INFO - Epoch 80, Step 67979: Loss=5.3935, Acc=0.287, PPL=219.98
2025-09-20 21:11:51,703 - training.trainer - INFO - Epoch 80, Step 68079: Loss=5.3843, Acc=0.281, PPL=217.95
2025-09-20 21:12:00,828 - training.trainer - INFO - Epoch 80, Step 68179: Loss=5.7504, Acc=0.217, PPL=314.33
2025-09-20 21:12:09,739 - training.trainer - INFO - Epoch 80, Step 68279: Loss=5.6360, Acc=0.194, PPL=280.34
2025-09-20 21:12:18,946 - training.trainer - INFO - Epoch 80, Step 68379: Loss=5.3592, Acc=0.261, PPL=212.55
2025-09-20 21:12:27,816 - training.trainer - INFO - Epoch 80, Step 68479: Loss=4.6078, Acc=0.370, PPL=100.27
2025-09-20 21:12:38,876 - training.trainer - INFO - Epoch 81/100 completed in 82.01s - Train Loss: 5.3927, Train Acc: 0.259, Val Loss: 5.6433, Val Acc: 0.239
2025-09-20 21:12:39,761 - training.trainer - INFO - New best model saved with validation loss: 5.6433
2025-09-20 21:12:39,761 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_81.pt
2025-09-20 21:12:48,536 - training.trainer - INFO - Epoch 81, Step 68625: Loss=5.3690, Acc=0.235, PPL=214.66
2025-09-20 21:12:56,752 - training.trainer - INFO - Epoch 81, Step 68725: Loss=5.5557, Acc=0.236, PPL=258.70
2025-09-20 21:13:04,591 - training.trainer - INFO - Epoch 81, Step 68825: Loss=5.8606, Acc=0.193, PPL=350.93
2025-09-20 21:13:12,548 - training.trainer - INFO - Epoch 81, Step 68925: Loss=5.2710, Acc=0.248, PPL=194.62
2025-09-20 21:13:21,209 - training.trainer - INFO - Epoch 81, Step 69025: Loss=5.2963, Acc=0.252, PPL=199.59
2025-09-20 21:13:29,080 - training.trainer - INFO - Epoch 81, Step 69125: Loss=4.8464, Acc=0.391, PPL=127.29
2025-09-20 21:13:37,499 - training.trainer - INFO - Epoch 81, Step 69225: Loss=5.4781, Acc=0.248, PPL=239.39
2025-09-20 21:13:45,252 - training.trainer - INFO - Epoch 81, Step 69325: Loss=5.3676, Acc=0.242, PPL=214.35
2025-09-20 21:13:55,885 - training.trainer - INFO - Epoch 82/100 completed in 76.12s - Train Loss: 5.3932, Train Acc: 0.258, Val Loss: 5.6476, Val Acc: 0.239
2025-09-20 21:14:05,612 - training.trainer - INFO - Epoch 82, Step 69471: Loss=5.4844, Acc=0.257, PPL=240.91
2025-09-20 21:14:14,717 - training.trainer - INFO - Epoch 82, Step 69571: Loss=4.8746, Acc=0.301, PPL=130.92
2025-09-20 21:14:23,294 - training.trainer - INFO - Epoch 82, Step 69671: Loss=5.1960, Acc=0.278, PPL=180.54
2025-09-20 21:14:32,162 - training.trainer - INFO - Epoch 82, Step 69771: Loss=5.0695, Acc=0.298, PPL=159.09
2025-09-20 21:14:41,099 - training.trainer - INFO - Epoch 82, Step 69871: Loss=5.8537, Acc=0.213, PPL=348.51
2025-09-20 21:14:50,418 - training.trainer - INFO - Epoch 82, Step 69971: Loss=5.2638, Acc=0.303, PPL=193.22
2025-09-20 21:14:59,187 - training.trainer - INFO - Epoch 82, Step 70071: Loss=5.5877, Acc=0.184, PPL=267.11
2025-09-20 21:15:07,959 - training.trainer - INFO - Epoch 82, Step 70171: Loss=5.9172, Acc=0.197, PPL=371.37
2025-09-20 21:15:19,098 - training.trainer - INFO - Epoch 83/100 completed in 83.21s - Train Loss: 5.3910, Train Acc: 0.259, Val Loss: 5.6472, Val Acc: 0.238
2025-09-20 21:15:28,913 - training.trainer - INFO - Epoch 83, Step 70317: Loss=4.4901, Acc=0.357, PPL=89.13
2025-09-20 21:15:37,793 - training.trainer - INFO - Epoch 83, Step 70417: Loss=4.9944, Acc=0.283, PPL=147.58
2025-09-20 21:15:46,858 - training.trainer - INFO - Epoch 83, Step 70517: Loss=5.0276, Acc=0.302, PPL=152.56
2025-09-20 21:15:55,840 - training.trainer - INFO - Epoch 83, Step 70617: Loss=5.6010, Acc=0.223, PPL=270.70
2025-09-20 21:16:04,685 - training.trainer - INFO - Epoch 83, Step 70717: Loss=4.8522, Acc=0.305, PPL=128.02
2025-09-20 21:16:13,430 - training.trainer - INFO - Epoch 83, Step 70817: Loss=5.9581, Acc=0.175, PPL=386.89
2025-09-20 21:16:22,355 - training.trainer - INFO - Epoch 83, Step 70917: Loss=5.7170, Acc=0.215, PPL=304.00
2025-09-20 21:16:31,250 - training.trainer - INFO - Epoch 83, Step 71017: Loss=5.4360, Acc=0.276, PPL=229.53
2025-09-20 21:16:42,456 - training.trainer - INFO - Epoch 84/100 completed in 83.36s - Train Loss: 5.3924, Train Acc: 0.258, Val Loss: 5.6419, Val Acc: 0.239
2025-09-20 21:16:43,207 - training.trainer - INFO - New best model saved with validation loss: 5.6419
2025-09-20 21:16:43,208 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_84.pt
2025-09-20 21:16:51,749 - training.trainer - INFO - Epoch 84, Step 71163: Loss=5.1478, Acc=0.252, PPL=172.05
2025-09-20 21:16:59,848 - training.trainer - INFO - Epoch 84, Step 71263: Loss=4.5867, Acc=0.356, PPL=98.17
2025-09-20 21:17:07,965 - training.trainer - INFO - Epoch 84, Step 71363: Loss=5.1904, Acc=0.265, PPL=179.55
2025-09-20 21:17:15,839 - training.trainer - INFO - Epoch 84, Step 71463: Loss=5.4156, Acc=0.270, PPL=224.89
2025-09-20 21:17:23,998 - training.trainer - INFO - Epoch 84, Step 71563: Loss=5.6363, Acc=0.272, PPL=280.42
2025-09-20 21:17:32,587 - training.trainer - INFO - Epoch 84, Step 71663: Loss=5.2399, Acc=0.238, PPL=188.65
2025-09-20 21:17:40,359 - training.trainer - INFO - Epoch 84, Step 71763: Loss=5.2323, Acc=0.289, PPL=187.22
2025-09-20 21:17:47,969 - training.trainer - INFO - Epoch 84, Step 71863: Loss=5.0490, Acc=0.339, PPL=155.87
2025-09-20 21:17:58,959 - training.trainer - INFO - Epoch 85/100 completed in 75.75s - Train Loss: 5.3876, Train Acc: 0.258, Val Loss: 5.6472, Val Acc: 0.239
2025-09-20 21:17:59,340 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_85.pt
2025-09-20 21:18:08,805 - training.trainer - INFO - Epoch 85, Step 72009: Loss=5.9666, Acc=0.215, PPL=390.18
2025-09-20 21:18:17,848 - training.trainer - INFO - Epoch 85, Step 72109: Loss=5.6783, Acc=0.230, PPL=292.44
2025-09-20 21:18:26,867 - training.trainer - INFO - Epoch 85, Step 72209: Loss=5.4570, Acc=0.312, PPL=234.39
2025-09-20 21:18:36,073 - training.trainer - INFO - Epoch 85, Step 72309: Loss=5.5041, Acc=0.263, PPL=245.70
2025-09-20 21:18:44,831 - training.trainer - INFO - Epoch 85, Step 72409: Loss=4.9437, Acc=0.347, PPL=140.30
2025-09-20 21:18:53,756 - training.trainer - INFO - Epoch 85, Step 72509: Loss=5.9391, Acc=0.214, PPL=379.58
2025-09-20 21:19:02,551 - training.trainer - INFO - Epoch 85, Step 72609: Loss=5.7480, Acc=0.244, PPL=313.56
2025-09-20 21:19:11,530 - training.trainer - INFO - Epoch 85, Step 72709: Loss=5.5749, Acc=0.198, PPL=263.71
2025-09-20 21:19:22,360 - training.trainer - INFO - Epoch 86/100 completed in 83.02s - Train Loss: 5.3884, Train Acc: 0.258, Val Loss: 5.6450, Val Acc: 0.240
2025-09-20 21:19:31,784 - training.trainer - INFO - Epoch 86, Step 72855: Loss=5.0309, Acc=0.336, PPL=153.07
2025-09-20 21:19:40,530 - training.trainer - INFO - Epoch 86, Step 72955: Loss=4.9690, Acc=0.303, PPL=143.89
2025-09-20 21:19:49,392 - training.trainer - INFO - Epoch 86, Step 73055: Loss=5.1232, Acc=0.273, PPL=167.87
2025-09-20 21:19:58,493 - training.trainer - INFO - Epoch 86, Step 73155: Loss=5.0622, Acc=0.310, PPL=157.93
2025-09-20 21:20:07,336 - training.trainer - INFO - Epoch 86, Step 73255: Loss=5.3272, Acc=0.289, PPL=205.85
2025-09-20 21:20:16,247 - training.trainer - INFO - Epoch 86, Step 73355: Loss=5.0736, Acc=0.279, PPL=159.76
2025-09-20 21:20:25,250 - training.trainer - INFO - Epoch 86, Step 73455: Loss=5.7316, Acc=0.226, PPL=308.46
2025-09-20 21:20:34,249 - training.trainer - INFO - Epoch 86, Step 73555: Loss=5.7467, Acc=0.169, PPL=313.17
2025-09-20 21:20:45,434 - training.trainer - INFO - Epoch 87/100 completed in 83.07s - Train Loss: 5.3915, Train Acc: 0.258, Val Loss: 5.6449, Val Acc: 0.238
2025-09-20 21:20:54,647 - training.trainer - INFO - Epoch 87, Step 73701: Loss=5.1882, Acc=0.290, PPL=179.14
2025-09-20 21:21:03,979 - training.trainer - INFO - Epoch 87, Step 73801: Loss=5.1076, Acc=0.289, PPL=165.27
2025-09-20 21:21:13,216 - training.trainer - INFO - Epoch 87, Step 73901: Loss=5.2176, Acc=0.237, PPL=184.50
2025-09-20 21:21:22,409 - training.trainer - INFO - Epoch 87, Step 74001: Loss=5.7824, Acc=0.190, PPL=324.53
2025-09-20 21:21:31,679 - training.trainer - INFO - Epoch 87, Step 74101: Loss=5.6182, Acc=0.250, PPL=275.39
2025-09-20 21:21:40,580 - training.trainer - INFO - Epoch 87, Step 74201: Loss=5.7423, Acc=0.245, PPL=311.77
2025-09-20 21:21:49,884 - training.trainer - INFO - Epoch 87, Step 74301: Loss=5.4937, Acc=0.293, PPL=243.15
2025-09-20 21:21:58,881 - training.trainer - INFO - Epoch 87, Step 74401: Loss=5.4925, Acc=0.210, PPL=242.85
2025-09-20 21:22:10,117 - training.trainer - INFO - Epoch 88/100 completed in 84.68s - Train Loss: 5.3879, Train Acc: 0.258, Val Loss: 5.6433, Val Acc: 0.238
2025-09-20 21:22:19,244 - training.trainer - INFO - Epoch 88, Step 74547: Loss=5.4691, Acc=0.237, PPL=237.25
2025-09-20 21:22:28,341 - training.trainer - INFO - Epoch 88, Step 74647: Loss=5.2659, Acc=0.315, PPL=193.63
2025-09-20 21:22:37,387 - training.trainer - INFO - Epoch 88, Step 74747: Loss=5.7932, Acc=0.251, PPL=328.05
2025-09-20 21:22:46,361 - training.trainer - INFO - Epoch 88, Step 74847: Loss=5.3724, Acc=0.268, PPL=215.38
2025-09-20 21:22:55,400 - training.trainer - INFO - Epoch 88, Step 74947: Loss=5.6088, Acc=0.221, PPL=272.82
2025-09-20 21:23:04,407 - training.trainer - INFO - Epoch 88, Step 75047: Loss=5.2621, Acc=0.242, PPL=192.88
2025-09-20 21:23:13,755 - training.trainer - INFO - Epoch 88, Step 75147: Loss=5.5361, Acc=0.247, PPL=253.68
2025-09-20 21:23:22,959 - training.trainer - INFO - Epoch 88, Step 75247: Loss=5.6306, Acc=0.220, PPL=278.84
2025-09-20 21:23:33,583 - training.trainer - INFO - Epoch 89/100 completed in 83.46s - Train Loss: 5.3873, Train Acc: 0.258, Val Loss: 5.6439, Val Acc: 0.238
2025-09-20 21:23:43,444 - training.trainer - INFO - Epoch 89, Step 75393: Loss=5.4337, Acc=0.251, PPL=229.00
2025-09-20 21:23:52,656 - training.trainer - INFO - Epoch 89, Step 75493: Loss=5.8251, Acc=0.198, PPL=338.69
2025-09-20 21:24:01,503 - training.trainer - INFO - Epoch 89, Step 75593: Loss=5.5517, Acc=0.203, PPL=257.67
2025-09-20 21:24:10,330 - training.trainer - INFO - Epoch 89, Step 75693: Loss=5.3269, Acc=0.309, PPL=205.79
2025-09-20 21:24:19,084 - training.trainer - INFO - Epoch 89, Step 75793: Loss=5.2741, Acc=0.241, PPL=195.22
2025-09-20 21:24:27,606 - training.trainer - INFO - Epoch 89, Step 75893: Loss=5.4015, Acc=0.239, PPL=221.73
2025-09-20 21:24:36,500 - training.trainer - INFO - Epoch 89, Step 75993: Loss=5.5361, Acc=0.244, PPL=253.68
2025-09-20 21:24:44,882 - training.trainer - INFO - Epoch 89, Step 76093: Loss=5.5290, Acc=0.251, PPL=251.90
2025-09-20 21:24:55,907 - training.trainer - INFO - Epoch 90/100 completed in 82.32s - Train Loss: 5.3836, Train Acc: 0.257, Val Loss: 5.6424, Val Acc: 0.239
2025-09-20 21:24:56,277 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_90.pt
2025-09-20 21:25:06,165 - training.trainer - INFO - Epoch 90, Step 76239: Loss=5.4123, Acc=0.279, PPL=224.15
2025-09-20 21:25:15,368 - training.trainer - INFO - Epoch 90, Step 76339: Loss=5.2643, Acc=0.291, PPL=193.31
2025-09-20 21:25:24,306 - training.trainer - INFO - Epoch 90, Step 76439: Loss=5.6582, Acc=0.252, PPL=286.64
2025-09-20 21:25:33,625 - training.trainer - INFO - Epoch 90, Step 76539: Loss=5.5396, Acc=0.270, PPL=254.57
2025-09-20 21:25:42,432 - training.trainer - INFO - Epoch 90, Step 76639: Loss=5.0972, Acc=0.277, PPL=163.57
2025-09-20 21:25:51,042 - training.trainer - INFO - Epoch 90, Step 76739: Loss=4.7886, Acc=0.310, PPL=120.14
2025-09-20 21:25:59,847 - training.trainer - INFO - Epoch 90, Step 76839: Loss=5.6265, Acc=0.191, PPL=277.69
2025-09-20 21:26:09,007 - training.trainer - INFO - Epoch 90, Step 76939: Loss=5.7784, Acc=0.213, PPL=323.23
2025-09-20 21:26:20,030 - training.trainer - INFO - Epoch 91/100 completed in 83.75s - Train Loss: 5.3900, Train Acc: 0.257, Val Loss: 5.6447, Val Acc: 0.239
2025-09-20 21:26:29,911 - training.trainer - INFO - Epoch 91, Step 77085: Loss=5.4454, Acc=0.236, PPL=231.68
2025-09-20 21:26:38,989 - training.trainer - INFO - Epoch 91, Step 77185: Loss=5.3534, Acc=0.224, PPL=211.32
2025-09-20 21:26:47,963 - training.trainer - INFO - Epoch 91, Step 77285: Loss=5.4253, Acc=0.246, PPL=227.08
2025-09-20 21:26:56,714 - training.trainer - INFO - Epoch 91, Step 77385: Loss=5.6795, Acc=0.241, PPL=292.79
2025-09-20 21:27:05,792 - training.trainer - INFO - Epoch 91, Step 77485: Loss=5.6421, Acc=0.250, PPL=282.06
2025-09-20 21:27:14,923 - training.trainer - INFO - Epoch 91, Step 77585: Loss=5.6790, Acc=0.253, PPL=292.66
2025-09-20 21:27:23,697 - training.trainer - INFO - Epoch 91, Step 77685: Loss=5.8078, Acc=0.270, PPL=332.89
2025-09-20 21:27:32,492 - training.trainer - INFO - Epoch 91, Step 77785: Loss=5.3494, Acc=0.287, PPL=210.48
2025-09-20 21:27:43,550 - training.trainer - INFO - Epoch 92/100 completed in 83.52s - Train Loss: 5.3861, Train Acc: 0.258, Val Loss: 5.6442, Val Acc: 0.239
2025-09-20 21:27:52,929 - training.trainer - INFO - Epoch 92, Step 77931: Loss=5.2830, Acc=0.261, PPL=196.95
2025-09-20 21:28:01,769 - training.trainer - INFO - Epoch 92, Step 78031: Loss=5.7015, Acc=0.250, PPL=299.32
2025-09-20 21:28:10,659 - training.trainer - INFO - Epoch 92, Step 78131: Loss=5.7208, Acc=0.212, PPL=305.15
2025-09-20 21:28:19,405 - training.trainer - INFO - Epoch 92, Step 78231: Loss=5.6389, Acc=0.217, PPL=281.16
2025-09-20 21:28:28,433 - training.trainer - INFO - Epoch 92, Step 78331: Loss=4.8729, Acc=0.278, PPL=130.69
2025-09-20 21:28:37,815 - training.trainer - INFO - Epoch 92, Step 78431: Loss=5.5478, Acc=0.231, PPL=256.68
2025-09-20 21:28:46,932 - training.trainer - INFO - Epoch 92, Step 78531: Loss=5.4735, Acc=0.261, PPL=238.29
2025-09-20 21:28:55,753 - training.trainer - INFO - Epoch 92, Step 78631: Loss=5.6697, Acc=0.268, PPL=289.94
2025-09-20 21:29:06,856 - training.trainer - INFO - Epoch 93/100 completed in 83.31s - Train Loss: 5.3841, Train Acc: 0.259, Val Loss: 5.6444, Val Acc: 0.239
2025-09-20 21:29:16,291 - training.trainer - INFO - Epoch 93, Step 78777: Loss=5.1371, Acc=0.308, PPL=170.22
2025-09-20 21:29:24,994 - training.trainer - INFO - Epoch 93, Step 78877: Loss=5.4400, Acc=0.232, PPL=230.45
2025-09-20 21:29:33,111 - training.trainer - INFO - Epoch 93, Step 78977: Loss=5.5363, Acc=0.283, PPL=253.74
2025-09-20 21:29:40,928 - training.trainer - INFO - Epoch 93, Step 79077: Loss=5.1321, Acc=0.305, PPL=169.36
2025-09-20 21:29:48,766 - training.trainer - INFO - Epoch 93, Step 79177: Loss=5.3261, Acc=0.227, PPL=205.64
2025-09-20 21:29:56,566 - training.trainer - INFO - Epoch 93, Step 79277: Loss=5.4717, Acc=0.223, PPL=237.87
2025-09-20 21:30:04,580 - training.trainer - INFO - Epoch 93, Step 79377: Loss=4.8599, Acc=0.327, PPL=129.01
2025-09-20 21:30:12,414 - training.trainer - INFO - Epoch 93, Step 79477: Loss=5.6239, Acc=0.239, PPL=276.96
2025-09-20 21:30:22,922 - training.trainer - INFO - Epoch 94/100 completed in 76.07s - Train Loss: 5.3878, Train Acc: 0.258, Val Loss: 5.6435, Val Acc: 0.239
2025-09-20 21:30:31,176 - training.trainer - INFO - Epoch 94, Step 79623: Loss=5.5868, Acc=0.286, PPL=266.89
2025-09-20 21:30:39,211 - training.trainer - INFO - Epoch 94, Step 79723: Loss=5.0141, Acc=0.351, PPL=150.52
2025-09-20 21:30:47,872 - training.trainer - INFO - Epoch 94, Step 79823: Loss=5.5571, Acc=0.208, PPL=259.07
2025-09-20 21:30:56,417 - training.trainer - INFO - Epoch 94, Step 79923: Loss=5.4381, Acc=0.233, PPL=230.01
2025-09-20 21:31:04,417 - training.trainer - INFO - Epoch 94, Step 80023: Loss=5.7319, Acc=0.189, PPL=308.57
2025-09-20 21:31:12,302 - training.trainer - INFO - Epoch 94, Step 80123: Loss=4.9966, Acc=0.300, PPL=147.92
2025-09-20 21:31:20,173 - training.trainer - INFO - Epoch 94, Step 80223: Loss=5.6942, Acc=0.228, PPL=297.15
2025-09-20 21:31:28,862 - training.trainer - INFO - Epoch 94, Step 80323: Loss=5.3452, Acc=0.275, PPL=209.61
2025-09-20 21:31:39,571 - training.trainer - INFO - Epoch 95/100 completed in 76.65s - Train Loss: 5.3851, Train Acc: 0.258, Val Loss: 5.6440, Val Acc: 0.239
2025-09-20 21:31:39,949 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_95.pt
2025-09-20 21:31:49,475 - training.trainer - INFO - Epoch 95, Step 80469: Loss=5.6361, Acc=0.243, PPL=280.37
2025-09-20 21:31:58,358 - training.trainer - INFO - Epoch 95, Step 80569: Loss=5.3402, Acc=0.264, PPL=208.55
2025-09-20 21:32:06,443 - training.trainer - INFO - Epoch 95, Step 80669: Loss=5.2514, Acc=0.279, PPL=190.84
2025-09-20 21:32:14,734 - training.trainer - INFO - Epoch 95, Step 80769: Loss=5.3728, Acc=0.262, PPL=215.47
2025-09-20 21:32:22,296 - training.trainer - INFO - Epoch 95, Step 80869: Loss=5.3645, Acc=0.227, PPL=213.68
2025-09-20 21:32:30,256 - training.trainer - INFO - Epoch 95, Step 80969: Loss=5.4057, Acc=0.263, PPL=222.67
2025-09-20 21:32:38,218 - training.trainer - INFO - Epoch 95, Step 81069: Loss=5.5804, Acc=0.221, PPL=265.17
2025-09-20 21:32:45,946 - training.trainer - INFO - Epoch 95, Step 81169: Loss=5.5345, Acc=0.236, PPL=253.28
2025-09-20 21:32:56,546 - training.trainer - INFO - Epoch 96/100 completed in 76.60s - Train Loss: 5.3846, Train Acc: 0.258, Val Loss: 5.6440, Val Acc: 0.239
2025-09-20 21:33:06,107 - training.trainer - INFO - Epoch 96, Step 81315: Loss=5.5823, Acc=0.230, PPL=265.68
2025-09-20 21:33:14,832 - training.trainer - INFO - Epoch 96, Step 81415: Loss=5.5679, Acc=0.265, PPL=261.88
2025-09-20 21:33:24,020 - training.trainer - INFO - Epoch 96, Step 81515: Loss=5.6934, Acc=0.222, PPL=296.90
2025-09-20 21:33:33,177 - training.trainer - INFO - Epoch 96, Step 81615: Loss=5.2662, Acc=0.246, PPL=193.68
2025-09-20 21:33:42,506 - training.trainer - INFO - Epoch 96, Step 81715: Loss=5.5000, Acc=0.269, PPL=244.69
2025-09-20 21:33:51,191 - training.trainer - INFO - Epoch 96, Step 81815: Loss=4.4335, Acc=0.387, PPL=84.22
2025-09-20 21:34:00,126 - training.trainer - INFO - Epoch 96, Step 81915: Loss=5.5595, Acc=0.302, PPL=259.70
2025-09-20 21:34:09,102 - training.trainer - INFO - Epoch 96, Step 82015: Loss=5.4436, Acc=0.227, PPL=231.28
2025-09-20 21:34:20,080 - training.trainer - INFO - Epoch 97/100 completed in 83.53s - Train Loss: 5.3858, Train Acc: 0.259, Val Loss: 5.6442, Val Acc: 0.239
2025-09-20 21:34:30,069 - training.trainer - INFO - Epoch 97, Step 82161: Loss=5.4811, Acc=0.254, PPL=240.11
2025-09-20 21:34:39,180 - training.trainer - INFO - Epoch 97, Step 82261: Loss=5.4446, Acc=0.232, PPL=231.50
2025-09-20 21:34:47,894 - training.trainer - INFO - Epoch 97, Step 82361: Loss=5.3227, Acc=0.280, PPL=204.93
2025-09-20 21:34:56,850 - training.trainer - INFO - Epoch 97, Step 82461: Loss=5.3337, Acc=0.268, PPL=207.21
2025-09-20 21:35:05,649 - training.trainer - INFO - Epoch 97, Step 82561: Loss=5.5321, Acc=0.242, PPL=252.66
2025-09-20 21:35:14,479 - training.trainer - INFO - Epoch 97, Step 82661: Loss=5.4628, Acc=0.212, PPL=235.76
2025-09-20 21:35:23,255 - training.trainer - INFO - Epoch 97, Step 82761: Loss=5.4004, Acc=0.279, PPL=221.50
2025-09-20 21:35:31,879 - training.trainer - INFO - Epoch 97, Step 82861: Loss=5.0946, Acc=0.304, PPL=163.14
2025-09-20 21:35:43,121 - training.trainer - INFO - Epoch 98/100 completed in 83.04s - Train Loss: 5.3846, Train Acc: 0.259, Val Loss: 5.6443, Val Acc: 0.239
2025-09-20 21:35:53,057 - training.trainer - INFO - Epoch 98, Step 83007: Loss=5.5855, Acc=0.280, PPL=266.53
2025-09-20 21:36:01,924 - training.trainer - INFO - Epoch 98, Step 83107: Loss=4.9808, Acc=0.309, PPL=145.59
2025-09-20 21:36:10,900 - training.trainer - INFO - Epoch 98, Step 83207: Loss=5.2929, Acc=0.227, PPL=198.93
2025-09-20 21:36:19,767 - training.trainer - INFO - Epoch 98, Step 83307: Loss=5.1877, Acc=0.259, PPL=179.05
2025-09-20 21:36:28,482 - training.trainer - INFO - Epoch 98, Step 83407: Loss=5.7761, Acc=0.174, PPL=322.49
2025-09-20 21:36:37,378 - training.trainer - INFO - Epoch 98, Step 83507: Loss=5.1313, Acc=0.330, PPL=169.24
2025-09-20 21:36:46,309 - training.trainer - INFO - Epoch 98, Step 83607: Loss=5.2860, Acc=0.253, PPL=197.56
2025-09-20 21:36:55,048 - training.trainer - INFO - Epoch 98, Step 83707: Loss=5.7875, Acc=0.213, PPL=326.20
2025-09-20 21:37:06,135 - training.trainer - INFO - Epoch 99/100 completed in 83.01s - Train Loss: 5.3839, Train Acc: 0.259, Val Loss: 5.6445, Val Acc: 0.239
2025-09-20 21:37:06,136 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-09-20 21:37:06,136 - training.trainer - INFO - Training completed!
2025-09-20 21:37:06,136 - __main__ - INFO - Training completed successfully!
2025-09-20 21:37:06,252 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-20 21:37:06,273 - __main__ - INFO - Process completed!
2025-09-20 21:37:28,808 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-20 21:37:28,808 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-20 21:37:28,808 - __main__ - INFO - Starting model evaluation
2025-09-20 21:37:29,759 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-20 22:05:08,191 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-20 22:05:08,214 - __main__ - INFO - Process completed!
2025-09-20 22:31:07,894 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-20 22:31:07,895 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-20 22:31:07,895 - __main__ - INFO - Starting model evaluation
2025-09-20 22:31:08,463 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-20 22:33:15,736 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-20 22:33:15,752 - __main__ - INFO - Process completed!
2025-09-20 22:59:39,818 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-20 22:59:39,818 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-20 22:59:39,818 - __main__ - INFO - Starting training pipeline
2025-09-20 22:59:39,921 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-20 22:59:39,946 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-20 22:59:39,946 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-20 22:59:39,946 - __main__ - INFO - Loading training data...
2025-09-20 22:59:47,651 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-20 22:59:47,651 - __main__ - INFO - Processing train split...
2025-09-20 22:59:47,737 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-20 22:59:47,737 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-20 23:00:16,043 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-20 23:00:45,151 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-20 23:01:14,216 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-20 23:01:42,462 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-20 23:02:10,829 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-20 23:02:38,479 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-20 23:02:59,765 - __main__ - INFO - Processing val split...
2025-09-20 23:03:00,013 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-20 23:03:00,013 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-20 23:03:23,064 - __main__ - INFO - Processing test split...
2025-09-20 23:03:23,293 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-20 23:03:23,293 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-20 23:03:47,196 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-20 23:03:47,196 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-20 23:03:47,215 - __main__ - INFO - ‚úÖ Vocabulary created successfully with 13664 words
2025-09-20 23:03:47,215 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-20 23:03:47,215 - __main__ - INFO - Creating model architecture...
2025-09-20 23:03:47,585 - __main__ - INFO - ‚úÖ Model created successfully
2025-09-20 23:03:47,585 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-20 23:03:47,585 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-20 23:03:47,586 - __main__ - INFO - üñ•Ô∏è  Using device: cuda
2025-09-20 23:03:47,586 - __main__ - INFO - Creating trainer...
2025-09-20 23:03:47,586 - __main__ - INFO - üîÑ Moving model to cuda...
2025-09-20 23:03:47,913 - __main__ - INFO - ‚úÖ Model moved to cuda
2025-09-20 23:03:47,914 - __main__ - INFO - üìç Model parameters are on: cuda:0
2025-09-20 23:03:49,508 - __main__ - INFO - ‚úÖ Trainer created successfully
2025-09-20 23:03:49,508 - __main__ - INFO - üìç Trainer model parameters are on: cuda:0
2025-09-20 23:03:49,508 - __main__ - INFO - üöÄ Starting training...
2025-09-20 23:03:49,508 - __main__ - INFO - Training configuration:
2025-09-20 23:03:49,508 - __main__ - INFO -   - Epochs: 100
2025-09-20 23:03:49,509 - __main__ - INFO -   - Batch size: 8
2025-09-20 23:03:49,509 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-20 23:03:49,509 - __main__ - INFO -   - Training samples: 6765
2025-09-20 23:03:49,509 - __main__ - INFO -   - Validation samples: 845
2025-09-20 23:03:49,509 - training.trainer - INFO - Starting training for 100 epochs
2025-09-20 23:03:49,509 - training.trainer - INFO - Model parameters: 16,669,280
2025-09-20 23:03:49,510 - training.trainer - INFO - Training on device: cuda
2025-09-20 23:04:00,801 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.7058, Acc=0.061, PPL=6037.58
2025-09-20 23:04:10,541 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.0072, Acc=0.063, PPL=3002.48
2025-09-20 23:04:20,078 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.4980, Acc=0.052, PPL=1804.51
2025-09-20 23:04:29,871 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.3065, Acc=0.040, PPL=1489.98
2025-09-20 23:04:39,944 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.8254, Acc=0.067, PPL=920.98
2025-09-20 23:04:49,358 - training.trainer - INFO - Epoch 0, Step 599: Loss=6.8598, Acc=0.086, PPL=953.17
2025-09-20 23:04:59,446 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.5686, Acc=0.115, PPL=712.40
2025-09-20 23:05:09,133 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.7562, Acc=0.125, PPL=859.34
2025-09-20 23:05:20,123 - training.trainer - INFO - Epoch 1/100 completed in 90.61s - Train Loss: 7.5196, Train Acc: 0.068, Val Loss: 6.7276, Val Acc: 0.122
2025-09-20 23:05:20,971 - training.trainer - INFO - New best model saved with validation loss: 6.7276
2025-09-20 23:05:20,972 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-20 23:05:30,657 - training.trainer - INFO - Epoch 1, Step 945: Loss=6.2807, Acc=0.117, PPL=534.17
2025-09-20 23:05:40,358 - training.trainer - INFO - Epoch 1, Step 1045: Loss=6.6362, Acc=0.154, PPL=762.20
2025-09-20 23:05:49,294 - training.trainer - INFO - Epoch 1, Step 1145: Loss=6.4786, Acc=0.098, PPL=651.04
2025-09-20 23:05:58,109 - training.trainer - INFO - Epoch 1, Step 1245: Loss=6.7843, Acc=0.132, PPL=883.85
2025-09-20 23:06:07,079 - training.trainer - INFO - Epoch 1, Step 1345: Loss=6.7743, Acc=0.117, PPL=875.10
2025-09-20 23:06:16,326 - training.trainer - INFO - Epoch 1, Step 1445: Loss=6.7403, Acc=0.102, PPL=845.85
2025-09-20 23:06:25,512 - training.trainer - INFO - Epoch 1, Step 1545: Loss=6.7343, Acc=0.135, PPL=840.77
2025-09-20 23:06:34,406 - training.trainer - INFO - Epoch 1, Step 1645: Loss=6.8284, Acc=0.112, PPL=923.72
2025-09-20 23:06:45,615 - training.trainer - INFO - Epoch 2/100 completed in 84.64s - Train Loss: 6.6638, Train Acc: 0.126, Val Loss: 6.5901, Val Acc: 0.135
2025-09-20 23:06:46,476 - training.trainer - INFO - New best model saved with validation loss: 6.5901
2025-09-20 23:06:46,476 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-20 23:06:56,566 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-20 23:06:56,566 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-20 23:06:56,566 - __main__ - INFO - Starting model evaluation
2025-09-20 23:06:57,334 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-20 23:07:14,461 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-20 23:07:14,461 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-20 23:07:14,461 - __main__ - INFO - Starting training pipeline
2025-09-20 23:07:14,560 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-20 23:07:14,582 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-20 23:07:14,583 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-20 23:07:14,583 - __main__ - INFO - Loading training data...
2025-09-20 23:07:22,290 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-20 23:07:22,290 - __main__ - INFO - Processing train split...
2025-09-20 23:07:22,376 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-20 23:07:22,377 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-20 23:07:51,074 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-20 23:08:20,039 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-20 23:08:49,251 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-20 23:09:17,490 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-20 23:09:45,772 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-20 23:10:13,494 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-20 23:10:34,790 - __main__ - INFO - Processing val split...
2025-09-20 23:10:35,053 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-20 23:10:35,054 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-20 23:10:58,112 - __main__ - INFO - Processing test split...
2025-09-20 23:10:58,350 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-20 23:10:58,350 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-20 23:11:23,453 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-20 23:11:23,454 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-20 23:11:23,472 - __main__ - INFO - ‚úÖ Vocabulary created successfully with 13664 words
2025-09-20 23:11:23,472 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-20 23:11:23,472 - __main__ - INFO - Creating model architecture...
2025-09-20 23:11:23,843 - __main__ - INFO - ‚úÖ Model created successfully
2025-09-20 23:11:23,843 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-20 23:11:23,844 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-20 23:11:23,844 - __main__ - INFO - üñ•Ô∏è  Using device: cuda
2025-09-20 23:11:23,844 - __main__ - INFO - Creating trainer...
2025-09-20 23:11:23,844 - __main__ - INFO - üîÑ Moving model to cuda...
2025-09-20 23:11:24,175 - __main__ - INFO - ‚úÖ Model moved to cuda
2025-09-20 23:11:24,175 - __main__ - INFO - üìç Model parameters are on: cuda:0
2025-09-20 23:11:25,156 - __main__ - INFO - ‚úÖ Trainer created successfully
2025-09-20 23:11:25,157 - __main__ - INFO - üìç Trainer model parameters are on: cuda:0
2025-09-20 23:11:25,157 - __main__ - INFO - üöÄ Starting training...
2025-09-20 23:11:25,157 - __main__ - INFO - Training configuration:
2025-09-20 23:11:25,157 - __main__ - INFO -   - Epochs: 100
2025-09-20 23:11:25,157 - __main__ - INFO -   - Batch size: 2
2025-09-20 23:11:25,157 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-20 23:11:25,157 - __main__ - INFO -   - Training samples: 6765
2025-09-20 23:11:25,157 - __main__ - INFO -   - Validation samples: 845
2025-09-20 23:11:25,157 - training.trainer - INFO - Starting training for 100 epochs
2025-09-20 23:11:25,158 - training.trainer - INFO - Model parameters: 16,669,280
2025-09-20 23:11:25,158 - training.trainer - INFO - Training on device: cuda
2025-09-20 23:11:34,139 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.8441, Acc=0.029, PPL=6933.64
2025-09-20 23:11:42,139 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.1707, Acc=0.047, PPL=3535.88
2025-09-20 23:11:50,773 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.8609, Acc=0.033, PPL=2593.87
2025-09-20 23:11:59,671 - training.trainer - INFO - Epoch 0, Step 399: Loss=6.7512, Acc=0.095, PPL=855.12
2025-09-20 23:12:08,307 - training.trainer - INFO - Epoch 0, Step 499: Loss=7.2767, Acc=0.077, PPL=1446.21
2025-09-20 23:12:16,862 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.0218, Acc=0.050, PPL=1120.79
2025-09-20 23:12:25,274 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.7051, Acc=0.158, PPL=816.59
2025-09-20 23:12:33,684 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.9553, Acc=0.075, PPL=1048.67
2025-09-20 23:12:41,919 - training.trainer - INFO - Epoch 0, Step 899: Loss=7.1097, Acc=0.108, PPL=1223.80
2025-09-20 23:12:50,272 - training.trainer - INFO - Epoch 0, Step 999: Loss=6.6743, Acc=0.047, PPL=791.77
2025-09-20 23:12:58,599 - training.trainer - INFO - Epoch 0, Step 1099: Loss=7.1775, Acc=0.109, PPL=1309.57
2025-09-20 23:13:06,770 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.5415, Acc=0.000, PPL=693.30
2025-09-20 23:13:14,981 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.1877, Acc=0.150, PPL=486.71
2025-09-20 23:13:23,138 - training.trainer - INFO - Epoch 0, Step 1399: Loss=7.0002, Acc=0.017, PPL=1096.86
2025-09-20 23:13:31,372 - training.trainer - INFO - Epoch 0, Step 1499: Loss=7.2265, Acc=0.079, PPL=1375.40
2025-09-20 23:13:39,556 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.8757, Acc=0.065, PPL=968.42
2025-09-20 23:13:47,783 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.3715, Acc=0.156, PPL=584.95
2025-09-20 23:13:55,924 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.8859, Acc=0.093, PPL=978.41
2025-09-20 23:14:04,083 - training.trainer - INFO - Epoch 0, Step 1899: Loss=7.1816, Acc=0.174, PPL=1314.98
2025-09-20 23:14:12,165 - training.trainer - INFO - Epoch 0, Step 1999: Loss=7.2184, Acc=0.075, PPL=1364.25
2025-09-20 23:14:20,442 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.6330, Acc=0.092, PPL=759.79
2025-09-20 23:14:28,494 - training.trainer - INFO - Epoch 0, Step 2199: Loss=7.0368, Acc=0.089, PPL=1137.78
2025-09-20 23:14:36,659 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.9183, Acc=0.069, PPL=1010.63
2025-09-20 23:14:44,721 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.6100, Acc=0.263, PPL=742.48
2025-09-20 23:14:52,778 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.8518, Acc=0.067, PPL=945.54
2025-09-20 23:15:00,813 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.6225, Acc=0.214, PPL=751.84
2025-09-20 23:15:08,895 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.3321, Acc=0.172, PPL=562.36
2025-09-20 23:15:16,892 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.5019, Acc=0.100, PPL=666.40
2025-09-20 23:15:24,954 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.6817, Acc=0.107, PPL=797.70
2025-09-20 23:15:33,015 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.6197, Acc=0.122, PPL=749.74
2025-09-20 23:15:41,205 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.6678, Acc=0.296, PPL=786.63
2025-09-20 23:15:49,329 - training.trainer - INFO - Epoch 0, Step 3199: Loss=7.2858, Acc=0.128, PPL=1459.49
2025-09-20 23:15:57,588 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.3440, Acc=0.167, PPL=569.05
2025-09-20 23:16:15,785 - training.trainer - INFO - Epoch 1/100 completed in 290.63s - Train Loss: 6.9537, Train Acc: 0.098, Val Loss: 6.5775, Val Acc: 0.131
2025-09-20 23:16:16,706 - training.trainer - INFO - New best model saved with validation loss: 6.5775
2025-09-20 23:16:16,706 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-20 23:16:25,174 - training.trainer - INFO - Epoch 1, Step 3482: Loss=6.6449, Acc=0.128, PPL=768.86
2025-09-20 23:16:33,242 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.3124, Acc=0.115, PPL=551.35
2025-09-20 23:16:41,386 - training.trainer - INFO - Epoch 1, Step 3682: Loss=7.0144, Acc=0.125, PPL=1112.49
2025-09-20 23:16:49,431 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.2152, Acc=0.087, PPL=500.28
2025-09-20 23:16:57,565 - training.trainer - INFO - Epoch 1, Step 3882: Loss=5.3473, Acc=0.231, PPL=210.05
2025-09-20 23:17:05,606 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.2829, Acc=0.129, PPL=535.32
2025-09-20 23:17:13,554 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.9912, Acc=0.154, PPL=1087.06
2025-09-20 23:17:21,562 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.7826, Acc=0.152, PPL=882.35
2025-09-20 23:17:29,600 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.4611, Acc=0.273, PPL=639.74
2025-09-20 23:17:37,596 - training.trainer - INFO - Epoch 1, Step 4382: Loss=7.0022, Acc=0.108, PPL=1099.05
2025-09-20 23:17:45,524 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.5675, Acc=0.167, PPL=711.61
2025-09-20 23:17:53,518 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.5798, Acc=0.114, PPL=720.37
2025-09-20 23:18:01,476 - training.trainer - INFO - Epoch 1, Step 4682: Loss=6.5332, Acc=0.111, PPL=687.58
2025-09-20 23:18:09,503 - training.trainer - INFO - Epoch 1, Step 4782: Loss=6.7008, Acc=0.074, PPL=813.07
2025-09-20 23:18:17,481 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.2648, Acc=0.115, PPL=525.75
2025-09-20 23:18:25,477 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.4840, Acc=0.148, PPL=654.60
2025-09-20 23:18:33,448 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.4209, Acc=0.190, PPL=614.58
2025-09-20 23:18:41,497 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.8476, Acc=0.143, PPL=941.62
2025-09-20 23:18:49,689 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.3395, Acc=0.167, PPL=566.51
2025-09-20 23:18:57,896 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.4661, Acc=0.179, PPL=643.00
2025-09-20 23:19:05,957 - training.trainer - INFO - Epoch 1, Step 5482: Loss=5.4229, Acc=0.167, PPL=226.52
2025-09-20 23:19:14,017 - training.trainer - INFO - Epoch 1, Step 5582: Loss=5.4754, Acc=0.286, PPL=238.76
2025-09-20 23:19:21,985 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.3924, Acc=0.087, PPL=597.27
2025-09-20 23:19:29,980 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.4705, Acc=0.200, PPL=645.83
2025-09-20 23:19:38,036 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.8421, Acc=0.077, PPL=936.47
2025-09-20 23:19:46,096 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.2123, Acc=0.182, PPL=498.83
2025-09-20 23:19:54,134 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.4299, Acc=0.263, PPL=620.12
2025-09-20 23:20:02,204 - training.trainer - INFO - Epoch 1, Step 6182: Loss=5.8648, Acc=0.111, PPL=352.40
2025-09-20 23:20:10,295 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.0766, Acc=0.208, PPL=435.53
2025-09-20 23:20:18,344 - training.trainer - INFO - Epoch 1, Step 6382: Loss=5.8258, Acc=0.162, PPL=338.94
2025-09-20 23:20:26,362 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.6484, Acc=0.160, PPL=771.59
2025-09-20 23:20:34,390 - training.trainer - INFO - Epoch 1, Step 6582: Loss=7.0272, Acc=0.143, PPL=1126.86
2025-09-20 23:20:42,559 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.5265, Acc=0.146, PPL=683.03
2025-09-20 23:20:59,934 - training.trainer - INFO - Epoch 2/100 completed in 283.23s - Train Loss: 6.5119, Train Acc: 0.143, Val Loss: 6.3989, Val Acc: 0.157
2025-09-20 23:21:00,628 - training.trainer - INFO - New best model saved with validation loss: 6.3989
2025-09-20 23:21:00,628 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-20 23:21:08,905 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.7297, Acc=0.167, PPL=836.86
2025-09-20 23:21:17,124 - training.trainer - INFO - Epoch 2, Step 6965: Loss=7.0244, Acc=0.093, PPL=1123.75
2025-09-20 23:21:25,255 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.9029, Acc=0.111, PPL=995.20
2025-09-20 23:21:33,441 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.4791, Acc=0.188, PPL=651.39
2025-09-20 23:21:41,588 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.0625, Acc=0.185, PPL=429.44
2025-09-20 23:21:49,684 - training.trainer - INFO - Epoch 2, Step 7365: Loss=5.9193, Acc=0.071, PPL=372.15
2025-09-20 23:21:57,837 - training.trainer - INFO - Epoch 2, Step 7465: Loss=6.5937, Acc=0.093, PPL=730.51
2025-09-20 23:22:05,952 - training.trainer - INFO - Epoch 2, Step 7565: Loss=5.8895, Acc=0.174, PPL=361.24
2025-09-20 23:22:14,176 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.1862, Acc=0.121, PPL=485.98
2025-09-20 23:22:22,437 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.3469, Acc=0.120, PPL=570.69
2025-09-20 23:22:30,674 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.5073, Acc=0.094, PPL=670.01
2025-09-20 23:22:38,802 - training.trainer - INFO - Epoch 2, Step 7965: Loss=6.3911, Acc=0.167, PPL=596.53
2025-09-20 23:22:46,978 - training.trainer - INFO - Epoch 2, Step 8065: Loss=7.0815, Acc=0.133, PPL=1189.79
2025-09-20 23:22:55,078 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.3163, Acc=0.190, PPL=553.53
2025-09-20 23:23:03,059 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.1759, Acc=0.088, PPL=480.99
2025-09-20 23:23:11,085 - training.trainer - INFO - Epoch 2, Step 8365: Loss=6.2152, Acc=0.160, PPL=500.29
2025-09-20 23:23:19,055 - training.trainer - INFO - Epoch 2, Step 8465: Loss=5.9905, Acc=0.161, PPL=399.63
2025-09-20 23:23:26,999 - training.trainer - INFO - Epoch 2, Step 8565: Loss=5.0912, Acc=0.273, PPL=162.58
2025-09-20 23:23:34,930 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.5022, Acc=0.148, PPL=666.58
2025-09-20 23:23:42,946 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.4703, Acc=0.125, PPL=645.65
2025-09-20 23:23:50,850 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.5493, Acc=0.093, PPL=698.75
2025-09-20 23:23:58,773 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.1550, Acc=0.154, PPL=471.04
2025-09-20 23:24:06,724 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.4919, Acc=0.121, PPL=659.78
2025-09-20 23:24:14,748 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.2590, Acc=0.188, PPL=522.70
2025-09-20 23:24:22,853 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.2320, Acc=0.138, PPL=508.77
2025-09-20 23:24:30,952 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.7732, Acc=0.079, PPL=874.09
2025-09-20 23:24:39,103 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.4594, Acc=0.061, PPL=638.67
2025-09-20 23:24:47,209 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.2145, Acc=0.120, PPL=499.94
2025-09-20 23:24:55,359 - training.trainer - INFO - Epoch 2, Step 9665: Loss=6.9030, Acc=0.095, PPL=995.23
2025-09-20 23:25:03,442 - training.trainer - INFO - Epoch 2, Step 9765: Loss=7.3083, Acc=0.053, PPL=1492.65
2025-09-20 23:25:11,565 - training.trainer - INFO - Epoch 2, Step 9865: Loss=7.1205, Acc=0.133, PPL=1237.03
2025-09-20 23:25:19,728 - training.trainer - INFO - Epoch 2, Step 9965: Loss=6.6347, Acc=0.115, PPL=761.07
2025-09-20 23:25:27,831 - training.trainer - INFO - Epoch 2, Step 10065: Loss=5.8163, Acc=0.176, PPL=335.73
2025-09-20 23:25:44,533 - training.trainer - INFO - Epoch 3/100 completed in 283.90s - Train Loss: 6.3654, Train Acc: 0.158, Val Loss: 6.2655, Val Acc: 0.162
2025-09-20 23:25:45,238 - training.trainer - INFO - New best model saved with validation loss: 6.2655
2025-09-20 23:25:45,238 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-20 23:25:53,602 - training.trainer - INFO - Epoch 3, Step 10248: Loss=5.8417, Acc=0.269, PPL=344.38
2025-09-20 23:26:01,796 - training.trainer - INFO - Epoch 3, Step 10348: Loss=6.5562, Acc=0.121, PPL=703.57
2025-09-20 23:26:09,978 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.8175, Acc=0.182, PPL=913.69
2025-09-20 23:26:18,078 - training.trainer - INFO - Epoch 3, Step 10548: Loss=6.4660, Acc=0.200, PPL=642.93
2025-09-20 23:26:26,170 - training.trainer - INFO - Epoch 3, Step 10648: Loss=5.9616, Acc=0.179, PPL=388.22
2025-09-20 23:26:34,092 - training.trainer - INFO - Epoch 3, Step 10748: Loss=7.0138, Acc=0.161, PPL=1111.86
2025-09-20 23:26:42,088 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.4506, Acc=0.103, PPL=633.05
2025-09-20 23:26:49,997 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.6272, Acc=0.108, PPL=755.39
2025-09-20 23:26:57,892 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.3794, Acc=0.128, PPL=589.57
2025-09-20 23:27:05,721 - training.trainer - INFO - Epoch 3, Step 11148: Loss=5.8880, Acc=0.158, PPL=360.68
2025-09-20 23:27:13,532 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.5649, Acc=0.107, PPL=709.71
2025-09-20 23:27:21,410 - training.trainer - INFO - Epoch 3, Step 11348: Loss=5.6009, Acc=0.226, PPL=270.67
2025-09-20 23:27:29,287 - training.trainer - INFO - Epoch 3, Step 11448: Loss=5.3672, Acc=0.267, PPL=214.27
2025-09-20 23:27:37,191 - training.trainer - INFO - Epoch 3, Step 11548: Loss=6.0411, Acc=0.222, PPL=420.38
2025-09-20 23:27:45,044 - training.trainer - INFO - Epoch 3, Step 11648: Loss=6.0258, Acc=0.182, PPL=413.99
2025-09-20 23:27:52,988 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.6937, Acc=0.250, PPL=296.98
2025-09-20 23:28:00,917 - training.trainer - INFO - Epoch 3, Step 11848: Loss=6.3667, Acc=0.103, PPL=582.14
2025-09-20 23:28:08,798 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.4953, Acc=0.250, PPL=662.00
2025-09-20 23:28:16,700 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.4466, Acc=0.167, PPL=630.54
2025-09-20 23:28:24,618 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.4141, Acc=0.206, PPL=610.40
2025-09-20 23:28:32,537 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.7065, Acc=0.167, PPL=817.73
2025-09-20 23:28:40,480 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.4529, Acc=0.130, PPL=634.52
2025-09-20 23:28:48,448 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.6488, Acc=0.097, PPL=771.88
2025-09-20 23:28:56,332 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.2337, Acc=0.200, PPL=509.62
2025-09-20 23:29:04,180 - training.trainer - INFO - Epoch 3, Step 12648: Loss=6.3311, Acc=0.154, PPL=561.78
2025-09-20 23:29:12,072 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.2806, Acc=0.200, PPL=534.12
2025-09-20 23:29:19,941 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.8974, Acc=0.141, PPL=989.68
2025-09-20 23:29:27,923 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.4007, Acc=0.147, PPL=602.28
2025-09-20 23:29:35,868 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.5670, Acc=0.240, PPL=711.22
2025-09-20 23:29:43,691 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.1331, Acc=0.164, PPL=460.86
2025-09-20 23:29:51,597 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.3722, Acc=0.154, PPL=585.36
2025-09-20 23:29:59,551 - training.trainer - INFO - Epoch 3, Step 13348: Loss=5.9386, Acc=0.231, PPL=379.41
2025-09-20 23:30:07,422 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.3152, Acc=0.111, PPL=552.91
2025-09-20 23:30:24,018 - training.trainer - INFO - Epoch 4/100 completed in 278.78s - Train Loss: 6.2740, Train Acc: 0.166, Val Loss: 6.2005, Val Acc: 0.167
2025-09-20 23:30:24,612 - training.trainer - INFO - New best model saved with validation loss: 6.2005
2025-09-20 23:30:24,612 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-20 23:30:33,072 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.2616, Acc=0.115, PPL=524.04
2025-09-20 23:30:41,099 - training.trainer - INFO - Epoch 4, Step 13731: Loss=6.4601, Acc=0.179, PPL=639.15
2025-09-20 23:30:49,144 - training.trainer - INFO - Epoch 4, Step 13831: Loss=5.2730, Acc=0.308, PPL=195.00
2025-09-20 23:30:57,130 - training.trainer - INFO - Epoch 4, Step 13931: Loss=6.2067, Acc=0.240, PPL=496.04
2025-09-20 23:31:05,075 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.7466, Acc=0.125, PPL=313.11
2025-09-20 23:31:12,945 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.3338, Acc=0.102, PPL=563.31
2025-09-20 23:31:20,801 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.4156, Acc=0.106, PPL=611.34
2025-09-20 23:31:28,673 - training.trainer - INFO - Epoch 4, Step 14331: Loss=5.1102, Acc=0.158, PPL=165.70
2025-09-20 23:31:36,553 - training.trainer - INFO - Epoch 4, Step 14431: Loss=6.2504, Acc=0.240, PPL=518.21
2025-09-20 23:31:44,517 - training.trainer - INFO - Epoch 4, Step 14531: Loss=6.4116, Acc=0.083, PPL=608.85
2025-09-20 23:31:52,427 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.7922, Acc=0.131, PPL=890.90
2025-09-20 23:32:00,363 - training.trainer - INFO - Epoch 4, Step 14731: Loss=5.7222, Acc=0.250, PPL=305.58
2025-09-20 23:32:08,313 - training.trainer - INFO - Epoch 4, Step 14831: Loss=6.3599, Acc=0.139, PPL=578.17
2025-09-20 23:32:16,327 - training.trainer - INFO - Epoch 4, Step 14931: Loss=6.5784, Acc=0.129, PPL=719.39
2025-09-20 23:32:24,291 - training.trainer - INFO - Epoch 4, Step 15031: Loss=6.1338, Acc=0.167, PPL=461.16
2025-09-20 23:32:32,201 - training.trainer - INFO - Epoch 4, Step 15131: Loss=6.3107, Acc=0.077, PPL=550.41
2025-09-20 23:32:40,071 - training.trainer - INFO - Epoch 4, Step 15231: Loss=6.0875, Acc=0.139, PPL=440.33
2025-09-20 23:32:48,038 - training.trainer - INFO - Epoch 4, Step 15331: Loss=5.9854, Acc=0.212, PPL=397.60
2025-09-20 23:32:56,034 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.6480, Acc=0.321, PPL=771.22
2025-09-20 23:33:03,933 - training.trainer - INFO - Epoch 4, Step 15531: Loss=5.3791, Acc=0.333, PPL=216.83
2025-09-20 23:33:11,833 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.2315, Acc=0.200, PPL=508.50
2025-09-20 23:33:19,852 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.5337, Acc=0.136, PPL=687.95
2025-09-20 23:33:27,734 - training.trainer - INFO - Epoch 4, Step 15831: Loss=6.2972, Acc=0.273, PPL=543.07
2025-09-20 23:33:35,611 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.0668, Acc=0.119, PPL=431.29
2025-09-20 23:33:43,510 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.1353, Acc=0.171, PPL=461.89
2025-09-20 23:33:51,488 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.6074, Acc=0.120, PPL=740.52
2025-09-20 23:33:59,380 - training.trainer - INFO - Epoch 4, Step 16231: Loss=6.9196, Acc=0.101, PPL=1011.96
2025-09-20 23:34:07,250 - training.trainer - INFO - Epoch 4, Step 16331: Loss=6.3430, Acc=0.095, PPL=568.51
2025-09-20 23:34:15,107 - training.trainer - INFO - Epoch 4, Step 16431: Loss=6.3677, Acc=0.133, PPL=582.69
2025-09-20 23:34:23,005 - training.trainer - INFO - Epoch 4, Step 16531: Loss=5.9741, Acc=0.280, PPL=393.13
2025-09-20 23:34:30,870 - training.trainer - INFO - Epoch 4, Step 16631: Loss=6.5987, Acc=0.176, PPL=734.16
2025-09-20 23:34:38,713 - training.trainer - INFO - Epoch 4, Step 16731: Loss=5.9006, Acc=0.171, PPL=365.27
2025-09-20 23:34:46,571 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.1299, Acc=0.138, PPL=459.38
2025-09-20 23:35:03,061 - training.trainer - INFO - Epoch 5/100 completed in 278.45s - Train Loss: 6.2211, Train Acc: 0.170, Val Loss: 6.1607, Val Acc: 0.174
2025-09-20 23:35:03,452 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-20 23:35:04,210 - training.trainer - INFO - New best model saved with validation loss: 6.1607
2025-09-20 23:35:04,210 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-20 23:35:12,381 - training.trainer - INFO - Epoch 5, Step 17014: Loss=5.5506, Acc=0.097, PPL=257.40
2025-09-20 23:35:20,255 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.0448, Acc=0.188, PPL=421.93
2025-09-20 23:35:28,185 - training.trainer - INFO - Epoch 5, Step 17214: Loss=6.7050, Acc=0.125, PPL=816.50
2025-09-20 23:35:36,041 - training.trainer - INFO - Epoch 5, Step 17314: Loss=6.5060, Acc=0.211, PPL=669.12
2025-09-20 23:35:43,914 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.1017, Acc=0.194, PPL=446.60
2025-09-20 23:35:51,771 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.2067, Acc=0.139, PPL=496.08
2025-09-20 23:35:59,560 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.8101, Acc=0.103, PPL=906.93
2025-09-20 23:36:07,481 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.7702, Acc=0.094, PPL=871.45
2025-09-20 23:36:15,390 - training.trainer - INFO - Epoch 5, Step 17814: Loss=6.2982, Acc=0.185, PPL=543.58
2025-09-20 23:36:23,210 - training.trainer - INFO - Epoch 5, Step 17914: Loss=5.1150, Acc=0.353, PPL=166.50
2025-09-20 23:36:31,090 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.0780, Acc=0.094, PPL=436.14
2025-09-20 23:36:39,121 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.6480, Acc=0.170, PPL=771.22
2025-09-20 23:36:46,959 - training.trainer - INFO - Epoch 5, Step 18214: Loss=5.9220, Acc=0.136, PPL=373.17
2025-09-20 23:36:54,875 - training.trainer - INFO - Epoch 5, Step 18314: Loss=6.2184, Acc=0.184, PPL=501.88
2025-09-20 23:37:02,770 - training.trainer - INFO - Epoch 5, Step 18414: Loss=6.0442, Acc=0.100, PPL=421.66
2025-09-20 23:37:10,685 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.2045, Acc=0.154, PPL=494.95
2025-09-20 23:37:18,669 - training.trainer - INFO - Epoch 5, Step 18614: Loss=5.5973, Acc=0.091, PPL=269.70
2025-09-20 23:37:26,624 - training.trainer - INFO - Epoch 5, Step 18714: Loss=6.3811, Acc=0.128, PPL=590.55
2025-09-20 23:37:34,648 - training.trainer - INFO - Epoch 5, Step 18814: Loss=6.2155, Acc=0.269, PPL=500.47
2025-09-20 23:37:42,750 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.4625, Acc=0.122, PPL=640.65
2025-09-20 23:37:50,764 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.0904, Acc=0.163, PPL=441.59
2025-09-20 23:37:58,792 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.3916, Acc=0.243, PPL=596.81
2025-09-20 23:38:06,759 - training.trainer - INFO - Epoch 5, Step 19214: Loss=6.6185, Acc=0.227, PPL=748.81
2025-09-20 23:38:14,776 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.1207, Acc=0.085, PPL=455.16
2025-09-20 23:38:22,766 - training.trainer - INFO - Epoch 5, Step 19414: Loss=6.3995, Acc=0.079, PPL=601.55
2025-09-20 23:38:30,622 - training.trainer - INFO - Epoch 5, Step 19514: Loss=6.2779, Acc=0.153, PPL=532.66
2025-09-20 23:38:38,554 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.1091, Acc=0.111, PPL=449.94
2025-09-20 23:38:46,454 - training.trainer - INFO - Epoch 5, Step 19714: Loss=6.5500, Acc=0.134, PPL=699.25
2025-09-20 23:38:54,309 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.4468, Acc=0.182, PPL=630.69
2025-09-20 23:39:02,282 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.6937, Acc=0.276, PPL=296.99
2025-09-20 23:39:10,309 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.1420, Acc=0.148, PPL=464.97
2025-09-20 23:39:18,279 - training.trainer - INFO - Epoch 5, Step 20114: Loss=5.8266, Acc=0.174, PPL=339.20
2025-09-20 23:39:26,161 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.6586, Acc=0.077, PPL=779.45
2025-09-20 23:39:43,296 - training.trainer - INFO - Epoch 6/100 completed in 279.09s - Train Loss: 6.1807, Train Acc: 0.174, Val Loss: 6.1377, Val Acc: 0.179
2025-09-20 23:39:44,218 - training.trainer - INFO - New best model saved with validation loss: 6.1377
2025-09-20 23:39:44,219 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-20 23:39:52,763 - training.trainer - INFO - Epoch 6, Step 20397: Loss=5.8647, Acc=0.250, PPL=352.37
2025-09-20 23:40:00,754 - training.trainer - INFO - Epoch 6, Step 20497: Loss=5.6344, Acc=0.167, PPL=279.89
2025-09-20 23:40:08,768 - training.trainer - INFO - Epoch 6, Step 20597: Loss=5.7437, Acc=0.204, PPL=312.22
2025-09-20 23:40:16,825 - training.trainer - INFO - Epoch 6, Step 20697: Loss=6.5829, Acc=0.125, PPL=722.67
2025-09-20 23:40:24,935 - training.trainer - INFO - Epoch 6, Step 20797: Loss=5.7461, Acc=0.214, PPL=312.96
2025-09-20 23:40:33,071 - training.trainer - INFO - Epoch 6, Step 20897: Loss=5.0779, Acc=0.235, PPL=160.43
2025-09-20 23:40:41,223 - training.trainer - INFO - Epoch 6, Step 20997: Loss=5.7725, Acc=0.250, PPL=321.34
2025-09-20 23:40:49,390 - training.trainer - INFO - Epoch 6, Step 21097: Loss=5.5979, Acc=0.333, PPL=269.85
2025-09-20 23:40:57,483 - training.trainer - INFO - Epoch 6, Step 21197: Loss=6.6013, Acc=0.132, PPL=736.04
2025-09-20 23:41:05,610 - training.trainer - INFO - Epoch 6, Step 21297: Loss=6.8932, Acc=0.136, PPL=985.53
2025-09-20 23:41:13,719 - training.trainer - INFO - Epoch 6, Step 21397: Loss=6.3262, Acc=0.152, PPL=559.05
2025-09-20 23:41:21,749 - training.trainer - INFO - Epoch 6, Step 21497: Loss=6.9265, Acc=0.161, PPL=1018.93
2025-09-20 23:41:29,793 - training.trainer - INFO - Epoch 6, Step 21597: Loss=6.6642, Acc=0.167, PPL=783.83
2025-09-20 23:41:37,782 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.3682, Acc=0.203, PPL=583.02
2025-09-20 23:41:45,786 - training.trainer - INFO - Epoch 6, Step 21797: Loss=5.5634, Acc=0.132, PPL=260.70
2025-09-20 23:41:53,845 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.3289, Acc=0.167, PPL=560.54
2025-09-20 23:42:01,880 - training.trainer - INFO - Epoch 6, Step 21997: Loss=5.7713, Acc=0.233, PPL=320.95
2025-09-20 23:42:10,060 - training.trainer - INFO - Epoch 6, Step 22097: Loss=6.0744, Acc=0.117, PPL=434.60
2025-09-20 23:42:18,141 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.7382, Acc=0.143, PPL=844.03
2025-09-20 23:42:26,143 - training.trainer - INFO - Epoch 6, Step 22297: Loss=7.1442, Acc=0.098, PPL=1266.73
2025-09-20 23:42:34,234 - training.trainer - INFO - Epoch 6, Step 22397: Loss=6.3472, Acc=0.189, PPL=570.91
2025-09-20 23:42:42,344 - training.trainer - INFO - Epoch 6, Step 22497: Loss=5.6190, Acc=0.226, PPL=275.62
2025-09-20 23:42:50,376 - training.trainer - INFO - Epoch 6, Step 22597: Loss=6.7334, Acc=0.167, PPL=840.02
2025-09-20 23:42:58,385 - training.trainer - INFO - Epoch 6, Step 22697: Loss=6.2694, Acc=0.113, PPL=528.15
2025-09-20 23:43:06,322 - training.trainer - INFO - Epoch 6, Step 22797: Loss=5.8205, Acc=0.211, PPL=337.14
2025-09-20 23:43:14,285 - training.trainer - INFO - Epoch 6, Step 22897: Loss=6.1688, Acc=0.196, PPL=477.62
2025-09-20 23:43:22,125 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.0861, Acc=0.118, PPL=439.70
2025-09-20 23:43:30,015 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.6434, Acc=0.184, PPL=767.67
2025-09-20 23:43:37,983 - training.trainer - INFO - Epoch 6, Step 23197: Loss=6.5149, Acc=0.143, PPL=675.12
2025-09-20 23:43:45,934 - training.trainer - INFO - Epoch 6, Step 23297: Loss=6.0259, Acc=0.207, PPL=414.01
2025-09-20 23:43:53,854 - training.trainer - INFO - Epoch 6, Step 23397: Loss=5.8372, Acc=0.154, PPL=342.82
2025-09-20 23:44:01,704 - training.trainer - INFO - Epoch 6, Step 23497: Loss=5.9996, Acc=0.167, PPL=403.27
2025-09-20 23:44:09,591 - training.trainer - INFO - Epoch 6, Step 23597: Loss=5.4312, Acc=0.286, PPL=228.43
2025-09-20 23:44:27,026 - training.trainer - INFO - Epoch 7/100 completed in 282.80s - Train Loss: 6.1510, Train Acc: 0.181, Val Loss: 6.1095, Val Acc: 0.183
2025-09-20 23:44:27,732 - training.trainer - INFO - New best model saved with validation loss: 6.1095
2025-09-20 23:44:27,732 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-20 23:44:36,142 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.1208, Acc=0.111, PPL=455.22
2025-09-20 23:44:44,350 - training.trainer - INFO - Epoch 7, Step 23880: Loss=6.6303, Acc=0.259, PPL=757.71
2025-09-20 23:44:52,385 - training.trainer - INFO - Epoch 7, Step 23980: Loss=6.6884, Acc=0.105, PPL=803.05
2025-09-20 23:45:00,375 - training.trainer - INFO - Epoch 7, Step 24080: Loss=5.3528, Acc=0.227, PPL=211.20
2025-09-20 23:45:08,297 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.5061, Acc=0.273, PPL=246.19
2025-09-20 23:45:16,402 - training.trainer - INFO - Epoch 7, Step 24280: Loss=5.3860, Acc=0.250, PPL=218.33
2025-09-20 23:45:24,550 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.2708, Acc=0.172, PPL=528.91
2025-09-20 23:45:32,627 - training.trainer - INFO - Epoch 7, Step 24480: Loss=6.2111, Acc=0.116, PPL=498.26
2025-09-20 23:45:40,640 - training.trainer - INFO - Epoch 7, Step 24580: Loss=6.5707, Acc=0.111, PPL=713.85
2025-09-20 23:45:48,698 - training.trainer - INFO - Epoch 7, Step 24680: Loss=6.3030, Acc=0.176, PPL=546.22
2025-09-20 23:45:56,774 - training.trainer - INFO - Epoch 7, Step 24780: Loss=5.5205, Acc=0.318, PPL=249.76
2025-09-20 23:46:04,785 - training.trainer - INFO - Epoch 7, Step 24880: Loss=5.9408, Acc=0.192, PPL=380.24
2025-09-20 23:46:12,811 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.9230, Acc=0.128, PPL=373.54
2025-09-20 23:46:20,802 - training.trainer - INFO - Epoch 7, Step 25080: Loss=6.3693, Acc=0.200, PPL=583.62
2025-09-20 23:46:28,840 - training.trainer - INFO - Epoch 7, Step 25180: Loss=6.4228, Acc=0.143, PPL=615.73
2025-09-20 23:46:36,854 - training.trainer - INFO - Epoch 7, Step 25280: Loss=6.3342, Acc=0.149, PPL=563.49
2025-09-20 23:46:45,007 - training.trainer - INFO - Epoch 7, Step 25380: Loss=6.0024, Acc=0.212, PPL=404.38
2025-09-20 23:46:52,994 - training.trainer - INFO - Epoch 7, Step 25480: Loss=5.7808, Acc=0.237, PPL=324.03
2025-09-20 23:47:01,074 - training.trainer - INFO - Epoch 7, Step 25580: Loss=5.9309, Acc=0.152, PPL=376.51
2025-09-20 23:47:09,285 - training.trainer - INFO - Epoch 7, Step 25680: Loss=6.7286, Acc=0.131, PPL=836.00
2025-09-20 23:47:17,323 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.0442, Acc=0.167, PPL=421.65
2025-09-20 23:47:25,224 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.3904, Acc=0.286, PPL=596.07
2025-09-20 23:47:33,170 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.9213, Acc=0.133, PPL=1013.66
2025-09-20 23:47:41,068 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.1514, Acc=0.171, PPL=469.39
2025-09-20 23:47:48,952 - training.trainer - INFO - Epoch 7, Step 26180: Loss=6.3369, Acc=0.171, PPL=565.02
2025-09-20 23:47:56,877 - training.trainer - INFO - Epoch 7, Step 26280: Loss=5.1664, Acc=0.364, PPL=175.28
2025-09-20 23:48:04,801 - training.trainer - INFO - Epoch 7, Step 26380: Loss=6.4705, Acc=0.071, PPL=645.83
2025-09-20 23:48:12,712 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.5778, Acc=0.107, PPL=718.96
2025-09-20 23:48:20,829 - training.trainer - INFO - Epoch 7, Step 26580: Loss=6.1354, Acc=0.278, PPL=461.94
2025-09-20 23:48:28,914 - training.trainer - INFO - Epoch 7, Step 26680: Loss=6.3036, Acc=0.160, PPL=546.51
2025-09-20 23:48:36,992 - training.trainer - INFO - Epoch 7, Step 26780: Loss=5.7099, Acc=0.292, PPL=301.85
2025-09-20 23:48:45,125 - training.trainer - INFO - Epoch 7, Step 26880: Loss=6.2625, Acc=0.194, PPL=524.54
2025-09-20 23:48:53,178 - training.trainer - INFO - Epoch 7, Step 26980: Loss=6.2203, Acc=0.172, PPL=502.83
2025-09-20 23:49:10,694 - training.trainer - INFO - Epoch 8/100 completed in 282.96s - Train Loss: 6.1221, Train Acc: 0.185, Val Loss: 6.0641, Val Acc: 0.188
2025-09-20 23:49:11,484 - training.trainer - INFO - New best model saved with validation loss: 6.0641
2025-09-20 23:49:11,484 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-09-20 23:49:19,690 - training.trainer - INFO - Epoch 8, Step 27163: Loss=6.2432, Acc=0.151, PPL=514.49
2025-09-20 23:49:27,560 - training.trainer - INFO - Epoch 8, Step 27263: Loss=6.1704, Acc=0.171, PPL=478.39
2025-09-20 23:49:35,456 - training.trainer - INFO - Epoch 8, Step 27363: Loss=6.2009, Acc=0.278, PPL=493.19
2025-09-20 23:49:43,395 - training.trainer - INFO - Epoch 8, Step 27463: Loss=5.9923, Acc=0.181, PPL=400.34
2025-09-20 23:49:51,358 - training.trainer - INFO - Epoch 8, Step 27563: Loss=4.8939, Acc=0.200, PPL=133.48
2025-09-20 23:49:59,270 - training.trainer - INFO - Epoch 8, Step 27663: Loss=6.7139, Acc=0.158, PPL=823.79
2025-09-20 23:50:07,176 - training.trainer - INFO - Epoch 8, Step 27763: Loss=6.9390, Acc=0.147, PPL=1031.72
2025-09-20 23:50:15,124 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.1483, Acc=0.162, PPL=467.91
2025-09-20 23:50:23,021 - training.trainer - INFO - Epoch 8, Step 27963: Loss=5.8755, Acc=0.120, PPL=356.22
2025-09-20 23:50:30,921 - training.trainer - INFO - Epoch 8, Step 28063: Loss=6.4887, Acc=0.119, PPL=657.69
2025-09-20 23:50:38,832 - training.trainer - INFO - Epoch 8, Step 28163: Loss=6.8950, Acc=0.190, PPL=987.36
2025-09-20 23:50:46,794 - training.trainer - INFO - Epoch 8, Step 28263: Loss=5.8443, Acc=0.208, PPL=345.28
2025-09-20 23:50:54,700 - training.trainer - INFO - Epoch 8, Step 28363: Loss=6.1229, Acc=0.226, PPL=456.17
2025-09-20 23:51:02,619 - training.trainer - INFO - Epoch 8, Step 28463: Loss=5.7306, Acc=0.270, PPL=308.16
2025-09-20 23:51:10,499 - training.trainer - INFO - Epoch 8, Step 28563: Loss=6.5220, Acc=0.133, PPL=679.92
2025-09-20 23:51:18,476 - training.trainer - INFO - Epoch 8, Step 28663: Loss=6.3225, Acc=0.147, PPL=556.96
2025-09-20 23:51:26,245 - training.trainer - INFO - Epoch 8, Step 28763: Loss=4.6640, Acc=0.323, PPL=106.06
2025-09-20 23:51:34,067 - training.trainer - INFO - Epoch 8, Step 28863: Loss=5.9268, Acc=0.100, PPL=374.97
2025-09-20 23:51:41,952 - training.trainer - INFO - Epoch 8, Step 28963: Loss=5.5935, Acc=0.158, PPL=268.68
2025-09-20 23:51:49,778 - training.trainer - INFO - Epoch 8, Step 29063: Loss=5.9790, Acc=0.174, PPL=395.03
2025-09-20 23:51:57,666 - training.trainer - INFO - Epoch 8, Step 29163: Loss=6.2436, Acc=0.119, PPL=514.71
2025-09-20 23:52:05,577 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.4006, Acc=0.241, PPL=602.23
2025-09-20 23:52:13,448 - training.trainer - INFO - Epoch 8, Step 29363: Loss=6.5024, Acc=0.152, PPL=666.73
2025-09-20 23:52:21,352 - training.trainer - INFO - Epoch 8, Step 29463: Loss=5.9180, Acc=0.308, PPL=371.68
2025-09-20 23:52:29,315 - training.trainer - INFO - Epoch 8, Step 29563: Loss=6.8952, Acc=0.105, PPL=987.54
2025-09-20 23:52:37,220 - training.trainer - INFO - Epoch 8, Step 29663: Loss=6.4981, Acc=0.150, PPL=663.90
2025-09-20 23:52:45,123 - training.trainer - INFO - Epoch 8, Step 29763: Loss=5.9525, Acc=0.137, PPL=384.72
2025-09-20 23:52:53,052 - training.trainer - INFO - Epoch 8, Step 29863: Loss=5.0002, Acc=0.276, PPL=148.45
2025-09-20 23:53:00,932 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.7355, Acc=0.161, PPL=841.79
2025-09-20 23:53:08,762 - training.trainer - INFO - Epoch 8, Step 30063: Loss=6.5933, Acc=0.162, PPL=730.17
2025-09-20 23:53:16,615 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.7707, Acc=0.188, PPL=320.76
2025-09-20 23:53:24,442 - training.trainer - INFO - Epoch 8, Step 30263: Loss=5.9854, Acc=0.216, PPL=397.58
2025-09-20 23:53:32,377 - training.trainer - INFO - Epoch 8, Step 30363: Loss=5.5452, Acc=0.238, PPL=256.00
2025-09-20 23:53:48,635 - training.trainer - INFO - Epoch 9/100 completed in 277.15s - Train Loss: 6.0977, Train Acc: 0.189, Val Loss: 6.0376, Val Acc: 0.194
2025-09-20 23:53:49,238 - training.trainer - INFO - New best model saved with validation loss: 6.0376
2025-09-20 23:53:49,238 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-20 23:53:57,444 - training.trainer - INFO - Epoch 9, Step 30546: Loss=6.2906, Acc=0.275, PPL=539.46
2025-09-20 23:54:05,345 - training.trainer - INFO - Epoch 9, Step 30646: Loss=6.2612, Acc=0.117, PPL=523.86
2025-09-20 23:54:13,167 - training.trainer - INFO - Epoch 9, Step 30746: Loss=5.8114, Acc=0.194, PPL=334.10
2025-09-20 23:54:21,053 - training.trainer - INFO - Epoch 9, Step 30846: Loss=4.7000, Acc=0.400, PPL=109.94
2025-09-20 23:54:28,888 - training.trainer - INFO - Epoch 9, Step 30946: Loss=6.7171, Acc=0.103, PPL=826.44
2025-09-20 23:54:36,792 - training.trainer - INFO - Epoch 9, Step 31046: Loss=6.6145, Acc=0.162, PPL=745.82
2025-09-20 23:54:44,646 - training.trainer - INFO - Epoch 9, Step 31146: Loss=5.3892, Acc=0.200, PPL=219.02
2025-09-20 23:54:52,495 - training.trainer - INFO - Epoch 9, Step 31246: Loss=6.3799, Acc=0.195, PPL=589.87
2025-09-20 23:55:00,358 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.2207, Acc=0.171, PPL=503.05
2025-09-20 23:55:08,266 - training.trainer - INFO - Epoch 9, Step 31446: Loss=5.3087, Acc=0.238, PPL=202.08
2025-09-20 23:55:16,146 - training.trainer - INFO - Epoch 9, Step 31546: Loss=6.2472, Acc=0.098, PPL=516.54
2025-09-20 23:55:24,047 - training.trainer - INFO - Epoch 9, Step 31646: Loss=5.4053, Acc=0.237, PPL=222.58
2025-09-20 23:55:31,892 - training.trainer - INFO - Epoch 9, Step 31746: Loss=6.1039, Acc=0.209, PPL=447.60
2025-09-20 23:55:39,886 - training.trainer - INFO - Epoch 9, Step 31846: Loss=5.4394, Acc=0.385, PPL=230.30
2025-09-20 23:55:47,746 - training.trainer - INFO - Epoch 9, Step 31946: Loss=6.0207, Acc=0.175, PPL=411.87
2025-09-20 23:55:55,922 - training.trainer - INFO - Epoch 9, Step 32046: Loss=6.1901, Acc=0.200, PPL=487.90
2025-09-20 23:56:04,057 - training.trainer - INFO - Epoch 9, Step 32146: Loss=6.2734, Acc=0.111, PPL=530.26
2025-09-20 23:56:12,158 - training.trainer - INFO - Epoch 9, Step 32246: Loss=5.8761, Acc=0.143, PPL=356.43
2025-09-20 23:56:20,393 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.1164, Acc=0.297, PPL=166.73
2025-09-20 23:56:28,236 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.4187, Acc=0.300, PPL=225.59
2025-09-20 23:56:36,086 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.9696, Acc=0.146, PPL=391.34
2025-09-20 23:56:44,024 - training.trainer - INFO - Epoch 9, Step 32646: Loss=5.6449, Acc=0.184, PPL=282.85
2025-09-20 23:56:51,889 - training.trainer - INFO - Epoch 9, Step 32746: Loss=5.8813, Acc=0.250, PPL=358.26
2025-09-20 23:56:59,947 - training.trainer - INFO - Epoch 9, Step 32846: Loss=6.3488, Acc=0.102, PPL=571.79
2025-09-20 23:57:08,119 - training.trainer - INFO - Epoch 9, Step 32946: Loss=6.2091, Acc=0.119, PPL=497.23
2025-09-20 23:57:16,245 - training.trainer - INFO - Epoch 9, Step 33046: Loss=6.3179, Acc=0.167, PPL=554.39
2025-09-20 23:57:24,442 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.2447, Acc=0.170, PPL=515.25
2025-09-20 23:57:32,608 - training.trainer - INFO - Epoch 9, Step 33246: Loss=5.8792, Acc=0.176, PPL=357.54
2025-09-20 23:57:40,668 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.0072, Acc=0.212, PPL=406.33
2025-09-20 23:57:48,516 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.4241, Acc=0.128, PPL=616.55
2025-09-20 23:57:56,514 - training.trainer - INFO - Epoch 9, Step 33546: Loss=6.7607, Acc=0.136, PPL=863.23
2025-09-20 23:58:04,419 - training.trainer - INFO - Epoch 9, Step 33646: Loss=5.9485, Acc=0.192, PPL=383.18
2025-09-20 23:58:12,247 - training.trainer - INFO - Epoch 9, Step 33746: Loss=6.4519, Acc=0.152, PPL=633.90
2025-09-20 23:58:28,757 - training.trainer - INFO - Epoch 10/100 completed in 279.52s - Train Loss: 6.0719, Train Acc: 0.192, Val Loss: 6.0197, Val Acc: 0.198
2025-09-20 23:58:29,138 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-20 23:58:29,855 - training.trainer - INFO - New best model saved with validation loss: 6.0197
2025-09-20 23:58:29,856 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-20 23:58:37,925 - training.trainer - INFO - Epoch 10, Step 33929: Loss=6.5453, Acc=0.174, PPL=695.93
2025-09-20 23:58:45,961 - training.trainer - INFO - Epoch 10, Step 34029: Loss=6.3870, Acc=0.091, PPL=594.06
2025-09-20 23:58:54,076 - training.trainer - INFO - Epoch 10, Step 34129: Loss=6.4140, Acc=0.106, PPL=610.34
2025-09-20 23:59:02,154 - training.trainer - INFO - Epoch 10, Step 34229: Loss=5.8553, Acc=0.294, PPL=349.08
2025-09-20 23:59:10,255 - training.trainer - INFO - Epoch 10, Step 34329: Loss=6.3325, Acc=0.188, PPL=562.57
2025-09-20 23:59:18,109 - training.trainer - INFO - Epoch 10, Step 34429: Loss=5.3915, Acc=0.211, PPL=219.53
2025-09-20 23:59:26,037 - training.trainer - INFO - Epoch 10, Step 34529: Loss=4.0672, Acc=0.273, PPL=58.39
2025-09-20 23:59:33,993 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.0514, Acc=0.182, PPL=156.23
2025-09-20 23:59:41,885 - training.trainer - INFO - Epoch 10, Step 34729: Loss=6.1585, Acc=0.159, PPL=472.71
2025-09-20 23:59:49,704 - training.trainer - INFO - Epoch 10, Step 34829: Loss=6.3537, Acc=0.167, PPL=574.60
2025-09-20 23:59:57,573 - training.trainer - INFO - Epoch 10, Step 34929: Loss=6.1864, Acc=0.214, PPL=486.08
2025-09-21 00:00:05,461 - training.trainer - INFO - Epoch 10, Step 35029: Loss=6.7802, Acc=0.184, PPL=880.23
2025-09-21 00:00:13,349 - training.trainer - INFO - Epoch 10, Step 35129: Loss=5.0700, Acc=0.286, PPL=159.18
2025-09-21 00:00:21,207 - training.trainer - INFO - Epoch 10, Step 35229: Loss=5.3324, Acc=0.207, PPL=206.93
2025-09-21 00:00:29,093 - training.trainer - INFO - Epoch 10, Step 35329: Loss=5.7264, Acc=0.172, PPL=306.86
2025-09-21 00:00:37,056 - training.trainer - INFO - Epoch 10, Step 35429: Loss=6.3536, Acc=0.200, PPL=574.56
2025-09-21 00:00:45,143 - training.trainer - INFO - Epoch 10, Step 35529: Loss=5.6244, Acc=0.257, PPL=277.11
2025-09-21 00:00:53,082 - training.trainer - INFO - Epoch 10, Step 35629: Loss=6.4035, Acc=0.150, PPL=603.98
2025-09-21 00:01:00,981 - training.trainer - INFO - Epoch 10, Step 35729: Loss=6.2614, Acc=0.123, PPL=523.96
2025-09-21 00:01:08,935 - training.trainer - INFO - Epoch 10, Step 35829: Loss=5.9725, Acc=0.143, PPL=392.49
2025-09-21 00:01:17,021 - training.trainer - INFO - Epoch 10, Step 35929: Loss=6.1568, Acc=0.161, PPL=471.93
2025-09-21 00:01:25,059 - training.trainer - INFO - Epoch 10, Step 36029: Loss=6.1683, Acc=0.135, PPL=477.37
2025-09-21 00:01:33,053 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.4935, Acc=0.211, PPL=243.10
2025-09-21 00:01:41,165 - training.trainer - INFO - Epoch 10, Step 36229: Loss=6.1350, Acc=0.231, PPL=461.73
2025-09-21 00:01:49,382 - training.trainer - INFO - Epoch 10, Step 36329: Loss=7.1284, Acc=0.091, PPL=1246.83
2025-09-21 00:01:57,673 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.5660, Acc=0.175, PPL=710.56
2025-09-21 00:02:05,602 - training.trainer - INFO - Epoch 10, Step 36529: Loss=6.8015, Acc=0.235, PPL=899.18
2025-09-21 00:02:13,503 - training.trainer - INFO - Epoch 10, Step 36629: Loss=5.2168, Acc=0.333, PPL=184.34
2025-09-21 00:02:21,548 - training.trainer - INFO - Epoch 10, Step 36729: Loss=5.5682, Acc=0.195, PPL=261.97
2025-09-21 00:02:29,575 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.7468, Acc=0.333, PPL=313.19
2025-09-21 00:02:37,478 - training.trainer - INFO - Epoch 10, Step 36929: Loss=6.0600, Acc=0.173, PPL=428.38
2025-09-21 00:02:45,424 - training.trainer - INFO - Epoch 10, Step 37029: Loss=6.3663, Acc=0.158, PPL=581.90
2025-09-21 00:02:53,385 - training.trainer - INFO - Epoch 10, Step 37129: Loss=6.0285, Acc=0.182, PPL=415.10
2025-09-21 00:03:10,504 - training.trainer - INFO - Epoch 11/100 completed in 280.65s - Train Loss: 6.0528, Train Acc: 0.195, Val Loss: 5.9979, Val Acc: 0.202
2025-09-21 00:03:11,108 - training.trainer - INFO - New best model saved with validation loss: 5.9979
2025-09-21 00:03:11,108 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-21 00:03:19,327 - training.trainer - INFO - Epoch 11, Step 37312: Loss=6.5948, Acc=0.138, PPL=731.31
2025-09-21 00:03:27,338 - training.trainer - INFO - Epoch 11, Step 37412: Loss=4.8482, Acc=0.290, PPL=127.51
2025-09-21 00:03:35,207 - training.trainer - INFO - Epoch 11, Step 37512: Loss=5.9038, Acc=0.227, PPL=366.44
2025-09-21 00:03:43,099 - training.trainer - INFO - Epoch 11, Step 37612: Loss=6.0798, Acc=0.148, PPL=436.95
2025-09-21 00:03:51,064 - training.trainer - INFO - Epoch 11, Step 37712: Loss=6.3299, Acc=0.217, PPL=561.09
2025-09-21 00:03:59,074 - training.trainer - INFO - Epoch 11, Step 37812: Loss=6.5789, Acc=0.182, PPL=719.72
2025-09-21 00:04:06,974 - training.trainer - INFO - Epoch 11, Step 37912: Loss=6.1126, Acc=0.172, PPL=451.52
2025-09-21 00:04:14,870 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.9074, Acc=0.160, PPL=367.75
2025-09-21 00:04:22,766 - training.trainer - INFO - Epoch 11, Step 38112: Loss=5.9368, Acc=0.227, PPL=378.73
2025-09-21 00:04:30,731 - training.trainer - INFO - Epoch 11, Step 38212: Loss=6.2393, Acc=0.208, PPL=512.50
2025-09-21 00:04:38,523 - training.trainer - INFO - Epoch 11, Step 38312: Loss=5.6651, Acc=0.290, PPL=288.62
2025-09-21 00:04:46,363 - training.trainer - INFO - Epoch 11, Step 38412: Loss=6.3448, Acc=0.238, PPL=569.54
2025-09-21 00:04:54,204 - training.trainer - INFO - Epoch 11, Step 38512: Loss=5.5596, Acc=0.267, PPL=259.71
2025-09-21 00:05:02,038 - training.trainer - INFO - Epoch 11, Step 38612: Loss=5.2044, Acc=0.240, PPL=182.06
2025-09-21 00:05:09,800 - training.trainer - INFO - Epoch 11, Step 38712: Loss=6.0742, Acc=0.157, PPL=434.51
2025-09-21 00:05:17,704 - training.trainer - INFO - Epoch 11, Step 38812: Loss=6.4011, Acc=0.208, PPL=602.54
2025-09-21 00:05:25,538 - training.trainer - INFO - Epoch 11, Step 38912: Loss=6.1799, Acc=0.226, PPL=482.93
2025-09-21 00:05:33,294 - training.trainer - INFO - Epoch 11, Step 39012: Loss=6.0978, Acc=0.167, PPL=444.88
2025-09-21 00:05:41,092 - training.trainer - INFO - Epoch 11, Step 39112: Loss=6.4212, Acc=0.235, PPL=614.75
2025-09-21 00:05:48,900 - training.trainer - INFO - Epoch 11, Step 39212: Loss=5.9937, Acc=0.135, PPL=400.88
2025-09-21 00:05:56,672 - training.trainer - INFO - Epoch 11, Step 39312: Loss=6.4298, Acc=0.200, PPL=620.06
2025-09-21 00:06:04,518 - training.trainer - INFO - Epoch 11, Step 39412: Loss=6.3023, Acc=0.149, PPL=545.80
2025-09-21 00:06:12,331 - training.trainer - INFO - Epoch 11, Step 39512: Loss=6.2154, Acc=0.253, PPL=500.38
2025-09-21 00:06:20,123 - training.trainer - INFO - Epoch 11, Step 39612: Loss=6.1917, Acc=0.128, PPL=488.66
2025-09-21 00:06:27,897 - training.trainer - INFO - Epoch 11, Step 39712: Loss=6.1966, Acc=0.222, PPL=491.07
2025-09-21 00:06:35,727 - training.trainer - INFO - Epoch 11, Step 39812: Loss=5.8190, Acc=0.231, PPL=336.62
2025-09-21 00:06:43,512 - training.trainer - INFO - Epoch 11, Step 39912: Loss=6.2031, Acc=0.204, PPL=494.26
2025-09-21 00:06:51,301 - training.trainer - INFO - Epoch 11, Step 40012: Loss=6.3820, Acc=0.174, PPL=591.11
2025-09-21 00:06:59,029 - training.trainer - INFO - Epoch 11, Step 40112: Loss=6.1709, Acc=0.200, PPL=478.62
2025-09-21 00:07:06,777 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.9268, Acc=0.185, PPL=374.96
2025-09-21 00:07:14,646 - training.trainer - INFO - Epoch 11, Step 40312: Loss=5.3774, Acc=0.231, PPL=216.46
2025-09-21 00:07:22,509 - training.trainer - INFO - Epoch 11, Step 40412: Loss=6.3588, Acc=0.226, PPL=577.53
2025-09-21 00:07:30,247 - training.trainer - INFO - Epoch 11, Step 40512: Loss=6.1121, Acc=0.182, PPL=451.27
2025-09-21 00:07:47,716 - training.trainer - INFO - Epoch 12/100 completed in 276.61s - Train Loss: 6.0314, Train Acc: 0.198, Val Loss: 5.9690, Val Acc: 0.202
2025-09-21 00:07:48,354 - training.trainer - INFO - New best model saved with validation loss: 5.9690
2025-09-21 00:07:48,355 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-09-21 00:07:56,510 - training.trainer - INFO - Epoch 12, Step 40695: Loss=6.3439, Acc=0.217, PPL=569.03
2025-09-21 00:08:04,335 - training.trainer - INFO - Epoch 12, Step 40795: Loss=6.1074, Acc=0.200, PPL=449.16
2025-09-21 00:08:12,129 - training.trainer - INFO - Epoch 12, Step 40895: Loss=5.4342, Acc=0.244, PPL=229.11
2025-09-21 00:08:19,970 - training.trainer - INFO - Epoch 12, Step 40995: Loss=5.6518, Acc=0.222, PPL=284.82
2025-09-21 00:08:27,771 - training.trainer - INFO - Epoch 12, Step 41095: Loss=5.8638, Acc=0.185, PPL=352.07
2025-09-21 00:08:35,673 - training.trainer - INFO - Epoch 12, Step 41195: Loss=6.2484, Acc=0.175, PPL=517.19
2025-09-21 00:08:43,543 - training.trainer - INFO - Epoch 12, Step 41295: Loss=5.7481, Acc=0.154, PPL=313.60
2025-09-21 00:08:51,397 - training.trainer - INFO - Epoch 12, Step 41395: Loss=6.3018, Acc=0.212, PPL=545.55
2025-09-21 00:08:59,428 - training.trainer - INFO - Epoch 12, Step 41495: Loss=6.8738, Acc=0.160, PPL=966.65
2025-09-21 00:09:07,561 - training.trainer - INFO - Epoch 12, Step 41595: Loss=6.5042, Acc=0.157, PPL=667.96
2025-09-21 00:09:15,501 - training.trainer - INFO - Epoch 12, Step 41695: Loss=5.6104, Acc=0.286, PPL=273.24
2025-09-21 00:09:23,452 - training.trainer - INFO - Epoch 12, Step 41795: Loss=5.2894, Acc=0.200, PPL=198.22
2025-09-21 00:09:31,446 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.0223, Acc=0.179, PPL=412.51
2025-09-21 00:09:39,346 - training.trainer - INFO - Epoch 12, Step 41995: Loss=6.0045, Acc=0.200, PPL=405.25
2025-09-21 00:09:47,232 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.6916, Acc=0.123, PPL=805.64
2025-09-21 00:09:55,137 - training.trainer - INFO - Epoch 12, Step 42195: Loss=5.5996, Acc=0.143, PPL=270.31
2025-09-21 00:10:03,225 - training.trainer - INFO - Epoch 12, Step 42295: Loss=6.4703, Acc=0.190, PPL=645.68
2025-09-21 00:10:11,336 - training.trainer - INFO - Epoch 12, Step 42395: Loss=6.8666, Acc=0.094, PPL=959.65
2025-09-21 00:10:19,488 - training.trainer - INFO - Epoch 12, Step 42495: Loss=5.2995, Acc=0.188, PPL=200.25
2025-09-21 00:10:27,563 - training.trainer - INFO - Epoch 12, Step 42595: Loss=5.9786, Acc=0.259, PPL=394.87
2025-09-21 00:10:35,597 - training.trainer - INFO - Epoch 12, Step 42695: Loss=5.8432, Acc=0.194, PPL=344.89
2025-09-21 00:10:43,696 - training.trainer - INFO - Epoch 12, Step 42795: Loss=7.0836, Acc=0.111, PPL=1192.26
2025-09-21 00:10:51,777 - training.trainer - INFO - Epoch 12, Step 42895: Loss=6.6390, Acc=0.231, PPL=764.30
2025-09-21 00:10:59,854 - training.trainer - INFO - Epoch 12, Step 42995: Loss=6.2314, Acc=0.171, PPL=508.48
2025-09-21 00:11:07,909 - training.trainer - INFO - Epoch 12, Step 43095: Loss=6.0418, Acc=0.118, PPL=420.65
2025-09-21 00:11:15,900 - training.trainer - INFO - Epoch 12, Step 43195: Loss=5.6766, Acc=0.240, PPL=291.95
2025-09-21 00:11:23,787 - training.trainer - INFO - Epoch 12, Step 43295: Loss=5.9897, Acc=0.238, PPL=399.28
2025-09-21 00:11:31,703 - training.trainer - INFO - Epoch 12, Step 43395: Loss=6.3261, Acc=0.138, PPL=558.95
2025-09-21 00:11:39,624 - training.trainer - INFO - Epoch 12, Step 43495: Loss=5.8722, Acc=0.171, PPL=355.02
2025-09-21 00:11:47,582 - training.trainer - INFO - Epoch 12, Step 43595: Loss=6.2269, Acc=0.176, PPL=506.17
2025-09-21 00:11:55,486 - training.trainer - INFO - Epoch 12, Step 43695: Loss=6.8444, Acc=0.179, PPL=938.62
2025-09-21 00:12:03,507 - training.trainer - INFO - Epoch 12, Step 43795: Loss=6.5476, Acc=0.067, PPL=697.60
2025-09-21 00:12:11,440 - training.trainer - INFO - Epoch 12, Step 43895: Loss=5.8705, Acc=0.279, PPL=354.42
2025-09-21 00:12:28,868 - training.trainer - INFO - Epoch 13/100 completed in 280.51s - Train Loss: 6.0129, Train Acc: 0.201, Val Loss: 5.9452, Val Acc: 0.208
2025-09-21 00:12:29,657 - training.trainer - INFO - New best model saved with validation loss: 5.9452
2025-09-21 00:12:29,657 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-21 00:12:38,293 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.4106, Acc=0.133, PPL=608.24
2025-09-21 00:12:46,396 - training.trainer - INFO - Epoch 13, Step 44178: Loss=6.3592, Acc=0.185, PPL=577.77
2025-09-21 00:12:54,390 - training.trainer - INFO - Epoch 13, Step 44278: Loss=6.6762, Acc=0.120, PPL=793.33
2025-09-21 00:13:02,461 - training.trainer - INFO - Epoch 13, Step 44378: Loss=6.4040, Acc=0.088, PPL=604.28
2025-09-21 00:13:10,497 - training.trainer - INFO - Epoch 13, Step 44478: Loss=5.8984, Acc=0.195, PPL=364.47
2025-09-21 00:13:18,514 - training.trainer - INFO - Epoch 13, Step 44578: Loss=6.4843, Acc=0.135, PPL=654.76
2025-09-21 00:13:26,599 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.9037, Acc=0.229, PPL=366.40
2025-09-21 00:13:34,622 - training.trainer - INFO - Epoch 13, Step 44778: Loss=6.5147, Acc=0.182, PPL=674.97
2025-09-21 00:13:42,616 - training.trainer - INFO - Epoch 13, Step 44878: Loss=6.1231, Acc=0.098, PPL=456.25
2025-09-21 00:13:50,652 - training.trainer - INFO - Epoch 13, Step 44978: Loss=5.0892, Acc=0.500, PPL=162.26
2025-09-21 00:13:58,621 - training.trainer - INFO - Epoch 13, Step 45078: Loss=6.2041, Acc=0.191, PPL=494.77
2025-09-21 00:14:06,604 - training.trainer - INFO - Epoch 13, Step 45178: Loss=5.8150, Acc=0.225, PPL=335.28
2025-09-21 00:14:14,627 - training.trainer - INFO - Epoch 13, Step 45278: Loss=5.7880, Acc=0.286, PPL=326.37
2025-09-21 00:14:22,591 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.6324, Acc=0.273, PPL=759.28
2025-09-21 00:14:30,604 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.5346, Acc=0.318, PPL=253.30
2025-09-21 00:14:38,604 - training.trainer - INFO - Epoch 13, Step 45578: Loss=6.8517, Acc=0.108, PPL=945.48
2025-09-21 00:14:46,696 - training.trainer - INFO - Epoch 13, Step 45678: Loss=6.4266, Acc=0.222, PPL=618.09
2025-09-21 00:14:54,683 - training.trainer - INFO - Epoch 13, Step 45778: Loss=5.9533, Acc=0.151, PPL=385.01
2025-09-21 00:15:02,759 - training.trainer - INFO - Epoch 13, Step 45878: Loss=5.6752, Acc=0.245, PPL=291.55
2025-09-21 00:15:10,760 - training.trainer - INFO - Epoch 13, Step 45978: Loss=5.8167, Acc=0.235, PPL=335.88
2025-09-21 00:15:18,738 - training.trainer - INFO - Epoch 13, Step 46078: Loss=5.9139, Acc=0.195, PPL=370.15
2025-09-21 00:15:26,763 - training.trainer - INFO - Epoch 13, Step 46178: Loss=5.8627, Acc=0.286, PPL=351.67
2025-09-21 00:15:34,770 - training.trainer - INFO - Epoch 13, Step 46278: Loss=6.7644, Acc=0.110, PPL=866.41
2025-09-21 00:15:42,735 - training.trainer - INFO - Epoch 13, Step 46378: Loss=6.0692, Acc=0.164, PPL=432.33
2025-09-21 00:15:50,741 - training.trainer - INFO - Epoch 13, Step 46478: Loss=5.8911, Acc=0.258, PPL=361.80
2025-09-21 00:15:58,784 - training.trainer - INFO - Epoch 13, Step 46578: Loss=6.6737, Acc=0.132, PPL=791.28
2025-09-21 00:16:06,753 - training.trainer - INFO - Epoch 13, Step 46678: Loss=6.4548, Acc=0.133, PPL=635.74
2025-09-21 00:16:14,663 - training.trainer - INFO - Epoch 13, Step 46778: Loss=6.4783, Acc=0.185, PPL=650.85
2025-09-21 00:16:22,554 - training.trainer - INFO - Epoch 13, Step 46878: Loss=6.0214, Acc=0.241, PPL=412.17
2025-09-21 00:16:30,601 - training.trainer - INFO - Epoch 13, Step 46978: Loss=5.5561, Acc=0.280, PPL=258.81
2025-09-21 00:16:38,523 - training.trainer - INFO - Epoch 13, Step 47078: Loss=6.0759, Acc=0.173, PPL=435.22
2025-09-21 00:16:46,459 - training.trainer - INFO - Epoch 13, Step 47178: Loss=7.4017, Acc=0.129, PPL=1638.80
2025-09-21 00:16:54,407 - training.trainer - INFO - Epoch 13, Step 47278: Loss=6.4173, Acc=0.278, PPL=612.38
2025-09-21 00:17:11,289 - training.trainer - INFO - Epoch 14/100 completed in 281.63s - Train Loss: 5.9895, Train Acc: 0.204, Val Loss: 5.9448, Val Acc: 0.207
2025-09-21 00:17:11,972 - training.trainer - INFO - New best model saved with validation loss: 5.9448
2025-09-21 00:17:11,972 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-21 00:17:20,412 - training.trainer - INFO - Epoch 14, Step 47461: Loss=4.4385, Acc=0.400, PPL=84.65
2025-09-21 00:17:28,377 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.7479, Acc=0.290, PPL=313.53
2025-09-21 00:17:36,396 - training.trainer - INFO - Epoch 14, Step 47661: Loss=4.6578, Acc=0.429, PPL=105.40
2025-09-21 00:17:44,382 - training.trainer - INFO - Epoch 14, Step 47761: Loss=6.0670, Acc=0.125, PPL=431.37
2025-09-21 00:17:52,459 - training.trainer - INFO - Epoch 14, Step 47861: Loss=5.6216, Acc=0.239, PPL=276.34
2025-09-21 00:18:00,601 - training.trainer - INFO - Epoch 14, Step 47961: Loss=6.4221, Acc=0.196, PPL=615.28
2025-09-21 00:18:08,555 - training.trainer - INFO - Epoch 14, Step 48061: Loss=6.3163, Acc=0.183, PPL=553.53
2025-09-21 00:18:16,650 - training.trainer - INFO - Epoch 14, Step 48161: Loss=5.6692, Acc=0.273, PPL=289.79
2025-09-21 00:18:24,690 - training.trainer - INFO - Epoch 14, Step 48261: Loss=5.6615, Acc=0.233, PPL=287.59
2025-09-21 00:18:32,776 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.2108, Acc=0.167, PPL=183.24
2025-09-21 00:18:41,017 - training.trainer - INFO - Epoch 14, Step 48461: Loss=5.9667, Acc=0.286, PPL=390.23
2025-09-21 00:18:49,072 - training.trainer - INFO - Epoch 14, Step 48561: Loss=5.8951, Acc=0.200, PPL=363.24
2025-09-21 00:18:57,066 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.6212, Acc=0.174, PPL=276.22
2025-09-21 00:19:05,175 - training.trainer - INFO - Epoch 14, Step 48761: Loss=5.6257, Acc=0.294, PPL=277.47
2025-09-21 00:19:13,161 - training.trainer - INFO - Epoch 14, Step 48861: Loss=5.8342, Acc=0.182, PPL=341.79
2025-09-21 00:19:21,199 - training.trainer - INFO - Epoch 14, Step 48961: Loss=6.4058, Acc=0.283, PPL=605.35
2025-09-21 00:19:29,191 - training.trainer - INFO - Epoch 14, Step 49061: Loss=6.3731, Acc=0.106, PPL=585.87
2025-09-21 00:19:37,153 - training.trainer - INFO - Epoch 14, Step 49161: Loss=6.2346, Acc=0.225, PPL=510.11
2025-09-21 00:19:45,113 - training.trainer - INFO - Epoch 14, Step 49261: Loss=6.4045, Acc=0.137, PPL=604.58
2025-09-21 00:19:53,227 - training.trainer - INFO - Epoch 14, Step 49361: Loss=6.5922, Acc=0.167, PPL=729.39
2025-09-21 00:20:01,392 - training.trainer - INFO - Epoch 14, Step 49461: Loss=5.9862, Acc=0.178, PPL=397.91
2025-09-21 00:20:09,511 - training.trainer - INFO - Epoch 14, Step 49561: Loss=6.0732, Acc=0.182, PPL=434.05
2025-09-21 00:20:17,473 - training.trainer - INFO - Epoch 14, Step 49661: Loss=6.0916, Acc=0.139, PPL=442.12
2025-09-21 00:20:25,423 - training.trainer - INFO - Epoch 14, Step 49761: Loss=5.8324, Acc=0.192, PPL=341.19
2025-09-21 00:20:33,467 - training.trainer - INFO - Epoch 14, Step 49861: Loss=5.9145, Acc=0.167, PPL=370.37
2025-09-21 00:20:41,643 - training.trainer - INFO - Epoch 14, Step 49961: Loss=5.9546, Acc=0.172, PPL=385.54
2025-09-21 00:20:49,711 - training.trainer - INFO - Epoch 14, Step 50061: Loss=5.1676, Acc=0.333, PPL=175.48
2025-09-21 00:20:57,756 - training.trainer - INFO - Epoch 14, Step 50161: Loss=6.1215, Acc=0.128, PPL=455.57
2025-09-21 00:21:05,866 - training.trainer - INFO - Epoch 14, Step 50261: Loss=6.1976, Acc=0.157, PPL=491.57
2025-09-21 00:21:13,932 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.7277, Acc=0.300, PPL=307.27
2025-09-21 00:21:22,075 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.0803, Acc=0.238, PPL=160.82
2025-09-21 00:21:30,129 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.7434, Acc=0.244, PPL=312.11
2025-09-21 00:21:38,080 - training.trainer - INFO - Epoch 14, Step 50661: Loss=6.5823, Acc=0.143, PPL=722.18
2025-09-21 00:21:55,483 - training.trainer - INFO - Epoch 15/100 completed in 283.51s - Train Loss: 5.9636, Train Acc: 0.208, Val Loss: 5.9333, Val Acc: 0.211
2025-09-21 00:21:55,830 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-21 00:21:56,488 - training.trainer - INFO - New best model saved with validation loss: 5.9333
2025-09-21 00:21:56,488 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-21 00:22:05,078 - training.trainer - INFO - Epoch 15, Step 50844: Loss=6.0392, Acc=0.194, PPL=419.56
2025-09-21 00:22:13,140 - training.trainer - INFO - Epoch 15, Step 50944: Loss=4.0002, Acc=0.500, PPL=54.61
2025-09-21 00:22:21,270 - training.trainer - INFO - Epoch 15, Step 51044: Loss=6.3861, Acc=0.184, PPL=593.52
2025-09-21 00:22:29,294 - training.trainer - INFO - Epoch 15, Step 51144: Loss=5.6281, Acc=0.220, PPL=278.14
2025-09-21 00:22:37,251 - training.trainer - INFO - Epoch 15, Step 51244: Loss=6.1283, Acc=0.178, PPL=458.63
2025-09-21 00:22:45,290 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.9823, Acc=0.238, PPL=396.35
2025-09-21 00:22:53,560 - training.trainer - INFO - Epoch 15, Step 51444: Loss=5.7637, Acc=0.229, PPL=318.52
2025-09-21 00:23:01,590 - training.trainer - INFO - Epoch 15, Step 51544: Loss=6.3419, Acc=0.172, PPL=567.87
2025-09-21 00:23:09,727 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.5203, Acc=0.250, PPL=249.72
2025-09-21 00:23:17,819 - training.trainer - INFO - Epoch 15, Step 51744: Loss=6.0246, Acc=0.173, PPL=413.46
2025-09-21 00:23:25,924 - training.trainer - INFO - Epoch 15, Step 51844: Loss=6.1110, Acc=0.237, PPL=450.77
2025-09-21 00:23:33,924 - training.trainer - INFO - Epoch 15, Step 51944: Loss=6.0601, Acc=0.250, PPL=428.43
2025-09-21 00:23:41,959 - training.trainer - INFO - Epoch 15, Step 52044: Loss=5.6037, Acc=0.312, PPL=271.42
2025-09-21 00:23:50,132 - training.trainer - INFO - Epoch 15, Step 52144: Loss=6.2535, Acc=0.292, PPL=519.84
2025-09-21 00:23:58,194 - training.trainer - INFO - Epoch 15, Step 52244: Loss=6.3139, Acc=0.125, PPL=552.22
2025-09-21 00:24:06,177 - training.trainer - INFO - Epoch 15, Step 52344: Loss=5.7683, Acc=0.222, PPL=319.99
2025-09-21 00:24:14,137 - training.trainer - INFO - Epoch 15, Step 52444: Loss=6.4662, Acc=0.156, PPL=643.06
2025-09-21 00:24:22,158 - training.trainer - INFO - Epoch 15, Step 52544: Loss=6.5172, Acc=0.106, PPL=676.69
2025-09-21 00:24:30,220 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.6494, Acc=0.237, PPL=284.13
2025-09-21 00:24:38,197 - training.trainer - INFO - Epoch 15, Step 52744: Loss=6.7045, Acc=0.136, PPL=816.06
2025-09-21 00:24:46,213 - training.trainer - INFO - Epoch 15, Step 52844: Loss=6.9537, Acc=0.117, PPL=1047.04
2025-09-21 00:24:54,263 - training.trainer - INFO - Epoch 15, Step 52944: Loss=6.1048, Acc=0.185, PPL=448.02
2025-09-21 00:25:02,169 - training.trainer - INFO - Epoch 15, Step 53044: Loss=4.5225, Acc=0.250, PPL=92.07
2025-09-21 00:25:10,097 - training.trainer - INFO - Epoch 15, Step 53144: Loss=6.1929, Acc=0.206, PPL=489.28
2025-09-21 00:25:18,334 - training.trainer - INFO - Epoch 15, Step 53244: Loss=5.4646, Acc=0.300, PPL=236.18
2025-09-21 00:25:26,504 - training.trainer - INFO - Epoch 15, Step 53344: Loss=6.2277, Acc=0.174, PPL=506.58
2025-09-21 00:25:34,699 - training.trainer - INFO - Epoch 15, Step 53444: Loss=6.6592, Acc=0.107, PPL=779.89
2025-09-21 00:25:42,869 - training.trainer - INFO - Epoch 15, Step 53544: Loss=6.4753, Acc=0.086, PPL=648.95
2025-09-21 00:25:50,938 - training.trainer - INFO - Epoch 15, Step 53644: Loss=5.8963, Acc=0.192, PPL=363.68
2025-09-21 00:25:59,121 - training.trainer - INFO - Epoch 15, Step 53744: Loss=6.3048, Acc=0.156, PPL=547.20
2025-09-21 00:26:07,163 - training.trainer - INFO - Epoch 15, Step 53844: Loss=6.0131, Acc=0.200, PPL=408.75
2025-09-21 00:26:15,285 - training.trainer - INFO - Epoch 15, Step 53944: Loss=5.9755, Acc=0.228, PPL=393.68
2025-09-21 00:26:23,474 - training.trainer - INFO - Epoch 15, Step 54044: Loss=6.4366, Acc=0.151, PPL=624.30
2025-09-21 00:26:40,902 - training.trainer - INFO - Epoch 16/100 completed in 284.41s - Train Loss: 5.9497, Train Acc: 0.209, Val Loss: 5.9127, Val Acc: 0.214
2025-09-21 00:26:41,768 - training.trainer - INFO - New best model saved with validation loss: 5.9127
2025-09-21 00:26:41,768 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-21 00:26:50,246 - training.trainer - INFO - Epoch 16, Step 54227: Loss=6.1763, Acc=0.233, PPL=481.23
2025-09-21 00:26:58,414 - training.trainer - INFO - Epoch 16, Step 54327: Loss=6.4340, Acc=0.179, PPL=622.69
2025-09-21 00:27:06,388 - training.trainer - INFO - Epoch 16, Step 54427: Loss=5.6396, Acc=0.286, PPL=281.36
2025-09-21 00:27:14,344 - training.trainer - INFO - Epoch 16, Step 54527: Loss=6.0678, Acc=0.200, PPL=431.75
2025-09-21 00:27:22,204 - training.trainer - INFO - Epoch 16, Step 54627: Loss=6.1369, Acc=0.119, PPL=462.60
2025-09-21 00:27:30,215 - training.trainer - INFO - Epoch 16, Step 54727: Loss=5.8580, Acc=0.262, PPL=350.01
2025-09-21 00:27:38,179 - training.trainer - INFO - Epoch 16, Step 54827: Loss=5.6592, Acc=0.259, PPL=286.91
2025-09-21 00:27:46,392 - training.trainer - INFO - Epoch 16, Step 54927: Loss=5.7344, Acc=0.162, PPL=309.32
2025-09-21 00:27:54,503 - training.trainer - INFO - Epoch 16, Step 55027: Loss=6.1354, Acc=0.241, PPL=461.93
2025-09-21 00:28:02,660 - training.trainer - INFO - Epoch 16, Step 55127: Loss=6.2874, Acc=0.140, PPL=537.77
2025-09-21 00:28:10,697 - training.trainer - INFO - Epoch 16, Step 55227: Loss=5.8161, Acc=0.174, PPL=335.65
2025-09-21 00:28:18,681 - training.trainer - INFO - Epoch 16, Step 55327: Loss=5.7855, Acc=0.235, PPL=325.54
2025-09-21 00:28:26,693 - training.trainer - INFO - Epoch 16, Step 55427: Loss=5.4050, Acc=0.304, PPL=222.52
2025-09-21 00:28:34,671 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.7928, Acc=0.184, PPL=327.93
2025-09-21 00:28:42,585 - training.trainer - INFO - Epoch 16, Step 55627: Loss=4.7304, Acc=0.409, PPL=113.35
2025-09-21 00:28:50,543 - training.trainer - INFO - Epoch 16, Step 55727: Loss=6.4401, Acc=0.200, PPL=626.45
2025-09-21 00:28:58,546 - training.trainer - INFO - Epoch 16, Step 55827: Loss=6.1936, Acc=0.214, PPL=489.60
2025-09-21 00:29:06,440 - training.trainer - INFO - Epoch 16, Step 55927: Loss=5.4716, Acc=0.216, PPL=237.84
2025-09-21 00:29:14,388 - training.trainer - INFO - Epoch 16, Step 56027: Loss=4.9321, Acc=0.240, PPL=138.67
2025-09-21 00:29:22,496 - training.trainer - INFO - Epoch 16, Step 56127: Loss=6.2213, Acc=0.259, PPL=503.35
2025-09-21 00:29:30,726 - training.trainer - INFO - Epoch 16, Step 56227: Loss=6.0766, Acc=0.145, PPL=435.56
2025-09-21 00:29:38,890 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.7943, Acc=0.214, PPL=328.42
2025-09-21 00:29:47,011 - training.trainer - INFO - Epoch 16, Step 56427: Loss=5.6232, Acc=0.222, PPL=276.77
2025-09-21 00:29:55,066 - training.trainer - INFO - Epoch 16, Step 56527: Loss=6.1869, Acc=0.209, PPL=486.34
2025-09-21 00:30:03,118 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.2499, Acc=0.318, PPL=190.54
2025-09-21 00:30:11,083 - training.trainer - INFO - Epoch 16, Step 56727: Loss=6.1311, Acc=0.121, PPL=459.93
2025-09-21 00:30:19,112 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.2820, Acc=0.294, PPL=196.77
2025-09-21 00:30:27,052 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.9140, Acc=0.194, PPL=370.17
2025-09-21 00:30:35,122 - training.trainer - INFO - Epoch 16, Step 57027: Loss=6.5560, Acc=0.239, PPL=703.44
2025-09-21 00:30:43,114 - training.trainer - INFO - Epoch 16, Step 57127: Loss=5.6475, Acc=0.217, PPL=283.59
2025-09-21 00:30:51,100 - training.trainer - INFO - Epoch 16, Step 57227: Loss=6.2805, Acc=0.162, PPL=534.04
2025-09-21 00:30:59,079 - training.trainer - INFO - Epoch 16, Step 57327: Loss=5.9306, Acc=0.200, PPL=376.39
2025-09-21 00:31:07,051 - training.trainer - INFO - Epoch 16, Step 57427: Loss=6.2150, Acc=0.173, PPL=500.20
2025-09-21 00:31:24,503 - training.trainer - INFO - Epoch 17/100 completed in 282.73s - Train Loss: 5.9296, Train Acc: 0.213, Val Loss: 5.8919, Val Acc: 0.216
2025-09-21 00:31:25,293 - training.trainer - INFO - New best model saved with validation loss: 5.8919
2025-09-21 00:31:25,293 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-21 00:31:33,812 - training.trainer - INFO - Epoch 17, Step 57610: Loss=6.0853, Acc=0.172, PPL=439.34
2025-09-21 00:31:42,038 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.6365, Acc=0.222, PPL=280.47
2025-09-21 00:31:50,154 - training.trainer - INFO - Epoch 17, Step 57810: Loss=5.2347, Acc=0.297, PPL=187.68
2025-09-21 00:31:58,290 - training.trainer - INFO - Epoch 17, Step 57910: Loss=6.0662, Acc=0.212, PPL=431.03
2025-09-21 00:32:06,326 - training.trainer - INFO - Epoch 17, Step 58010: Loss=6.4176, Acc=0.112, PPL=612.55
2025-09-21 00:32:14,374 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.9028, Acc=0.273, PPL=366.07
2025-09-21 00:32:22,328 - training.trainer - INFO - Epoch 17, Step 58210: Loss=5.8974, Acc=0.186, PPL=364.09
2025-09-21 00:32:30,275 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.3523, Acc=0.273, PPL=211.09
2025-09-21 00:32:38,268 - training.trainer - INFO - Epoch 17, Step 58410: Loss=6.2297, Acc=0.205, PPL=507.58
2025-09-21 00:32:46,234 - training.trainer - INFO - Epoch 17, Step 58510: Loss=5.9442, Acc=0.167, PPL=381.54
2025-09-21 00:32:54,293 - training.trainer - INFO - Epoch 17, Step 58610: Loss=5.5691, Acc=0.280, PPL=262.19
2025-09-21 00:33:02,193 - training.trainer - INFO - Epoch 17, Step 58710: Loss=6.1435, Acc=0.200, PPL=465.66
2025-09-21 00:33:10,145 - training.trainer - INFO - Epoch 17, Step 58810: Loss=5.7842, Acc=0.280, PPL=325.13
2025-09-21 00:33:18,069 - training.trainer - INFO - Epoch 17, Step 58910: Loss=6.0796, Acc=0.333, PPL=436.87
2025-09-21 00:33:26,009 - training.trainer - INFO - Epoch 17, Step 59010: Loss=6.1077, Acc=0.101, PPL=449.31
2025-09-21 00:33:34,069 - training.trainer - INFO - Epoch 17, Step 59110: Loss=6.1329, Acc=0.169, PPL=460.79
2025-09-21 00:33:42,130 - training.trainer - INFO - Epoch 17, Step 59210: Loss=6.1788, Acc=0.200, PPL=482.39
2025-09-21 00:33:50,092 - training.trainer - INFO - Epoch 17, Step 59310: Loss=6.4997, Acc=0.132, PPL=664.92
2025-09-21 00:33:58,057 - training.trainer - INFO - Epoch 17, Step 59410: Loss=5.9089, Acc=0.267, PPL=368.30
2025-09-21 00:34:06,059 - training.trainer - INFO - Epoch 17, Step 59510: Loss=4.2451, Acc=0.360, PPL=69.76
2025-09-21 00:34:14,021 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.8145, Acc=0.185, PPL=335.11
2025-09-21 00:34:22,088 - training.trainer - INFO - Epoch 17, Step 59710: Loss=6.6558, Acc=0.138, PPL=777.26
2025-09-21 00:34:30,202 - training.trainer - INFO - Epoch 17, Step 59810: Loss=5.1068, Acc=0.333, PPL=165.14
2025-09-21 00:34:38,302 - training.trainer - INFO - Epoch 17, Step 59910: Loss=6.1015, Acc=0.167, PPL=446.54
2025-09-21 00:34:46,349 - training.trainer - INFO - Epoch 17, Step 60010: Loss=5.7545, Acc=0.171, PPL=315.60
2025-09-21 00:34:54,381 - training.trainer - INFO - Epoch 17, Step 60110: Loss=5.6633, Acc=0.318, PPL=288.09
2025-09-21 00:35:02,443 - training.trainer - INFO - Epoch 17, Step 60210: Loss=6.4264, Acc=0.154, PPL=617.92
2025-09-21 00:35:10,483 - training.trainer - INFO - Epoch 17, Step 60310: Loss=6.2496, Acc=0.225, PPL=517.82
2025-09-21 00:35:18,487 - training.trainer - INFO - Epoch 17, Step 60410: Loss=6.4747, Acc=0.175, PPL=648.51
2025-09-21 00:35:26,516 - training.trainer - INFO - Epoch 17, Step 60510: Loss=6.0319, Acc=0.140, PPL=416.49
2025-09-21 00:35:34,525 - training.trainer - INFO - Epoch 17, Step 60610: Loss=6.4089, Acc=0.111, PPL=607.23
2025-09-21 00:35:42,553 - training.trainer - INFO - Epoch 17, Step 60710: Loss=5.2650, Acc=0.219, PPL=193.45
2025-09-21 00:35:50,564 - training.trainer - INFO - Epoch 17, Step 60810: Loss=6.5727, Acc=0.148, PPL=715.28
2025-09-21 00:36:07,358 - training.trainer - INFO - Epoch 18/100 completed in 282.06s - Train Loss: 5.9107, Train Acc: 0.216, Val Loss: 5.8693, Val Acc: 0.219
2025-09-21 00:36:08,048 - training.trainer - INFO - New best model saved with validation loss: 5.8693
2025-09-21 00:36:08,048 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-21 00:36:16,313 - training.trainer - INFO - Epoch 18, Step 60993: Loss=6.1682, Acc=0.187, PPL=477.31
2025-09-21 00:36:24,432 - training.trainer - INFO - Epoch 18, Step 61093: Loss=5.3842, Acc=0.259, PPL=217.94
2025-09-21 00:36:32,422 - training.trainer - INFO - Epoch 18, Step 61193: Loss=4.9417, Acc=0.333, PPL=140.00
2025-09-21 00:36:40,436 - training.trainer - INFO - Epoch 18, Step 61293: Loss=5.9694, Acc=0.132, PPL=391.26
2025-09-21 00:36:48,414 - training.trainer - INFO - Epoch 18, Step 61393: Loss=5.9134, Acc=0.250, PPL=369.95
2025-09-21 00:36:56,312 - training.trainer - INFO - Epoch 18, Step 61493: Loss=6.5300, Acc=0.128, PPL=685.41
2025-09-21 00:37:04,187 - training.trainer - INFO - Epoch 18, Step 61593: Loss=6.5438, Acc=0.197, PPL=694.94
2025-09-21 00:37:12,164 - training.trainer - INFO - Epoch 18, Step 61693: Loss=5.3830, Acc=0.360, PPL=217.68
2025-09-21 00:37:20,150 - training.trainer - INFO - Epoch 18, Step 61793: Loss=5.9161, Acc=0.163, PPL=370.94
2025-09-21 00:37:28,076 - training.trainer - INFO - Epoch 18, Step 61893: Loss=5.3290, Acc=0.258, PPL=206.23
2025-09-21 00:37:36,010 - training.trainer - INFO - Epoch 18, Step 61993: Loss=5.2371, Acc=0.278, PPL=188.12
2025-09-21 00:37:44,013 - training.trainer - INFO - Epoch 18, Step 62093: Loss=6.2935, Acc=0.161, PPL=541.05
2025-09-21 00:37:51,969 - training.trainer - INFO - Epoch 18, Step 62193: Loss=6.4939, Acc=0.163, PPL=661.10
2025-09-21 00:37:59,898 - training.trainer - INFO - Epoch 18, Step 62293: Loss=6.7426, Acc=0.125, PPL=847.77
2025-09-21 00:38:07,823 - training.trainer - INFO - Epoch 18, Step 62393: Loss=6.4953, Acc=0.156, PPL=662.03
2025-09-21 00:38:15,780 - training.trainer - INFO - Epoch 18, Step 62493: Loss=5.4790, Acc=0.216, PPL=239.60
2025-09-21 00:38:23,678 - training.trainer - INFO - Epoch 18, Step 62593: Loss=6.1638, Acc=0.158, PPL=475.23
2025-09-21 00:38:31,636 - training.trainer - INFO - Epoch 18, Step 62693: Loss=6.4629, Acc=0.200, PPL=640.89
2025-09-21 00:38:39,620 - training.trainer - INFO - Epoch 18, Step 62793: Loss=6.2045, Acc=0.206, PPL=494.96
2025-09-21 00:38:47,579 - training.trainer - INFO - Epoch 18, Step 62893: Loss=6.8801, Acc=0.200, PPL=972.70
2025-09-21 00:38:55,537 - training.trainer - INFO - Epoch 18, Step 62993: Loss=5.8475, Acc=0.171, PPL=346.37
2025-09-21 00:39:03,451 - training.trainer - INFO - Epoch 18, Step 63093: Loss=5.8650, Acc=0.206, PPL=352.46
2025-09-21 00:39:11,457 - training.trainer - INFO - Epoch 18, Step 63193: Loss=4.9274, Acc=0.278, PPL=138.02
2025-09-21 00:39:19,399 - training.trainer - INFO - Epoch 18, Step 63293: Loss=6.4167, Acc=0.167, PPL=612.00
2025-09-21 00:39:27,388 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.6503, Acc=0.238, PPL=284.39
2025-09-21 00:39:35,436 - training.trainer - INFO - Epoch 18, Step 63493: Loss=5.7639, Acc=0.240, PPL=318.58
2025-09-21 00:39:43,585 - training.trainer - INFO - Epoch 18, Step 63593: Loss=5.6703, Acc=0.310, PPL=290.12
2025-09-21 00:39:51,769 - training.trainer - INFO - Epoch 18, Step 63693: Loss=5.7221, Acc=0.333, PPL=305.53
2025-09-21 00:39:59,800 - training.trainer - INFO - Epoch 18, Step 63793: Loss=6.6168, Acc=0.127, PPL=747.58
2025-09-21 00:40:07,847 - training.trainer - INFO - Epoch 18, Step 63893: Loss=4.7178, Acc=0.241, PPL=111.92
2025-09-21 00:40:15,873 - training.trainer - INFO - Epoch 18, Step 63993: Loss=5.6260, Acc=0.231, PPL=277.55
2025-09-21 00:40:23,868 - training.trainer - INFO - Epoch 18, Step 64093: Loss=4.4449, Acc=0.348, PPL=85.19
2025-09-21 00:40:31,880 - training.trainer - INFO - Epoch 18, Step 64193: Loss=6.8638, Acc=0.135, PPL=956.96
2025-09-21 00:40:49,010 - training.trainer - INFO - Epoch 19/100 completed in 280.96s - Train Loss: 5.8891, Train Acc: 0.220, Val Loss: 5.8689, Val Acc: 0.222
2025-09-21 00:40:49,920 - training.trainer - INFO - New best model saved with validation loss: 5.8689
2025-09-21 00:40:49,921 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-21 00:40:58,297 - training.trainer - INFO - Epoch 19, Step 64376: Loss=5.3752, Acc=0.261, PPL=215.98
2025-09-21 00:41:06,484 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.2613, Acc=0.300, PPL=192.72
2025-09-21 00:41:14,518 - training.trainer - INFO - Epoch 19, Step 64576: Loss=4.8238, Acc=0.375, PPL=124.44
2025-09-21 00:41:22,591 - training.trainer - INFO - Epoch 19, Step 64676: Loss=7.0771, Acc=0.147, PPL=1184.53
2025-09-21 00:41:30,594 - training.trainer - INFO - Epoch 19, Step 64776: Loss=6.4065, Acc=0.135, PPL=605.74
2025-09-21 00:41:38,662 - training.trainer - INFO - Epoch 19, Step 64876: Loss=6.1215, Acc=0.176, PPL=455.54
2025-09-21 00:41:46,783 - training.trainer - INFO - Epoch 19, Step 64976: Loss=6.3581, Acc=0.207, PPL=577.15
2025-09-21 00:41:54,796 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.8205, Acc=0.200, PPL=337.15
2025-09-21 00:42:02,799 - training.trainer - INFO - Epoch 19, Step 65176: Loss=6.8910, Acc=0.152, PPL=983.40
2025-09-21 00:42:10,777 - training.trainer - INFO - Epoch 19, Step 65276: Loss=5.7939, Acc=0.245, PPL=328.28
2025-09-21 00:42:18,757 - training.trainer - INFO - Epoch 19, Step 65376: Loss=6.1293, Acc=0.167, PPL=459.13
2025-09-21 00:42:26,718 - training.trainer - INFO - Epoch 19, Step 65476: Loss=4.6460, Acc=0.263, PPL=104.17
2025-09-21 00:42:34,604 - training.trainer - INFO - Epoch 19, Step 65576: Loss=6.2079, Acc=0.214, PPL=496.68
2025-09-21 00:42:42,717 - training.trainer - INFO - Epoch 19, Step 65676: Loss=5.6257, Acc=0.261, PPL=277.47
2025-09-21 00:42:50,784 - training.trainer - INFO - Epoch 19, Step 65776: Loss=6.5093, Acc=0.138, PPL=671.37
2025-09-21 00:42:58,865 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.9285, Acc=0.164, PPL=375.59
2025-09-21 00:43:06,962 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.5980, Acc=0.333, PPL=269.89
2025-09-21 00:43:15,039 - training.trainer - INFO - Epoch 19, Step 66076: Loss=5.7194, Acc=0.316, PPL=304.71
2025-09-21 00:43:23,003 - training.trainer - INFO - Epoch 19, Step 66176: Loss=6.1685, Acc=0.296, PPL=477.49
2025-09-21 00:43:31,106 - training.trainer - INFO - Epoch 19, Step 66276: Loss=5.0329, Acc=0.360, PPL=153.38
2025-09-21 00:43:39,195 - training.trainer - INFO - Epoch 19, Step 66376: Loss=6.5487, Acc=0.152, PPL=698.32
2025-09-21 00:43:47,234 - training.trainer - INFO - Epoch 19, Step 66476: Loss=6.6395, Acc=0.127, PPL=764.71
2025-09-21 00:43:55,232 - training.trainer - INFO - Epoch 19, Step 66576: Loss=5.6598, Acc=0.273, PPL=287.08
2025-09-21 00:44:03,294 - training.trainer - INFO - Epoch 19, Step 66676: Loss=4.7501, Acc=0.344, PPL=115.60
2025-09-21 00:44:11,247 - training.trainer - INFO - Epoch 19, Step 66776: Loss=6.3042, Acc=0.100, PPL=546.86
2025-09-21 00:44:19,153 - training.trainer - INFO - Epoch 19, Step 66876: Loss=6.1583, Acc=0.129, PPL=472.61
2025-09-21 00:44:27,068 - training.trainer - INFO - Epoch 19, Step 66976: Loss=5.0762, Acc=0.291, PPL=160.16
2025-09-21 00:44:35,033 - training.trainer - INFO - Epoch 19, Step 67076: Loss=4.5522, Acc=0.300, PPL=94.84
2025-09-21 00:44:42,999 - training.trainer - INFO - Epoch 19, Step 67176: Loss=6.1964, Acc=0.276, PPL=490.97
2025-09-21 00:44:50,938 - training.trainer - INFO - Epoch 19, Step 67276: Loss=6.5640, Acc=0.194, PPL=709.07
2025-09-21 00:44:58,867 - training.trainer - INFO - Epoch 19, Step 67376: Loss=5.7486, Acc=0.263, PPL=313.76
2025-09-21 00:45:06,752 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.8584, Acc=0.171, PPL=350.16
2025-09-21 00:45:14,677 - training.trainer - INFO - Epoch 19, Step 67576: Loss=5.5477, Acc=0.229, PPL=256.65
2025-09-21 00:45:32,268 - training.trainer - INFO - Epoch 20/100 completed in 282.35s - Train Loss: 5.8736, Train Acc: 0.221, Val Loss: 5.8556, Val Acc: 0.228
2025-09-21 00:45:32,628 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-21 00:45:33,334 - training.trainer - INFO - New best model saved with validation loss: 5.8556
2025-09-21 00:45:33,335 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-21 00:45:41,757 - training.trainer - INFO - Epoch 20, Step 67759: Loss=6.5346, Acc=0.229, PPL=688.58
2025-09-21 00:45:49,962 - training.trainer - INFO - Epoch 20, Step 67859: Loss=5.8053, Acc=0.219, PPL=332.05
2025-09-21 00:45:58,002 - training.trainer - INFO - Epoch 20, Step 67959: Loss=6.0827, Acc=0.263, PPL=438.20
2025-09-21 00:46:06,016 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.8859, Acc=0.152, PPL=359.94
2025-09-21 00:46:14,096 - training.trainer - INFO - Epoch 20, Step 68159: Loss=6.5423, Acc=0.214, PPL=693.91
2025-09-21 00:46:22,115 - training.trainer - INFO - Epoch 20, Step 68259: Loss=6.3176, Acc=0.122, PPL=554.24
2025-09-21 00:46:30,067 - training.trainer - INFO - Epoch 20, Step 68359: Loss=6.2085, Acc=0.122, PPL=496.94
2025-09-21 00:46:38,018 - training.trainer - INFO - Epoch 20, Step 68459: Loss=5.3681, Acc=0.306, PPL=214.46
2025-09-21 00:46:45,989 - training.trainer - INFO - Epoch 20, Step 68559: Loss=6.1519, Acc=0.241, PPL=469.59
2025-09-21 00:46:53,974 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.5850, Acc=0.200, PPL=266.39
2025-09-21 00:47:01,965 - training.trainer - INFO - Epoch 20, Step 68759: Loss=6.0192, Acc=0.225, PPL=411.25
2025-09-21 00:47:09,905 - training.trainer - INFO - Epoch 20, Step 68859: Loss=5.6716, Acc=0.231, PPL=290.49
2025-09-21 00:47:17,874 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.8927, Acc=0.229, PPL=362.40
2025-09-21 00:47:25,828 - training.trainer - INFO - Epoch 20, Step 69059: Loss=5.5433, Acc=0.268, PPL=255.52
2025-09-21 00:47:33,805 - training.trainer - INFO - Epoch 20, Step 69159: Loss=6.6509, Acc=0.212, PPL=773.45
2025-09-21 00:47:41,818 - training.trainer - INFO - Epoch 20, Step 69259: Loss=5.7628, Acc=0.167, PPL=318.23
2025-09-21 00:47:49,807 - training.trainer - INFO - Epoch 20, Step 69359: Loss=5.5470, Acc=0.262, PPL=256.47
2025-09-21 00:47:57,790 - training.trainer - INFO - Epoch 20, Step 69459: Loss=5.9027, Acc=0.195, PPL=366.02
2025-09-21 00:48:05,724 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.4414, Acc=0.270, PPL=230.76
2025-09-21 00:48:13,709 - training.trainer - INFO - Epoch 20, Step 69659: Loss=6.1495, Acc=0.210, PPL=468.51
2025-09-21 00:48:21,648 - training.trainer - INFO - Epoch 20, Step 69759: Loss=5.7356, Acc=0.208, PPL=309.69
2025-09-21 00:48:29,590 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.5890, Acc=0.194, PPL=267.48
2025-09-21 00:48:37,512 - training.trainer - INFO - Epoch 20, Step 69959: Loss=5.5204, Acc=0.280, PPL=249.73
2025-09-21 00:48:45,377 - training.trainer - INFO - Epoch 20, Step 70059: Loss=6.3339, Acc=0.195, PPL=563.36
2025-09-21 00:48:53,380 - training.trainer - INFO - Epoch 20, Step 70159: Loss=5.3241, Acc=0.200, PPL=205.23
2025-09-21 00:49:01,299 - training.trainer - INFO - Epoch 20, Step 70259: Loss=7.1976, Acc=0.114, PPL=1336.25
2025-09-21 00:49:09,262 - training.trainer - INFO - Epoch 20, Step 70359: Loss=5.1731, Acc=0.294, PPL=176.45
2025-09-21 00:49:17,149 - training.trainer - INFO - Epoch 20, Step 70459: Loss=6.7178, Acc=0.137, PPL=826.97
2025-09-21 00:49:25,107 - training.trainer - INFO - Epoch 20, Step 70559: Loss=6.4756, Acc=0.114, PPL=649.13
2025-09-21 00:49:33,014 - training.trainer - INFO - Epoch 20, Step 70659: Loss=4.8391, Acc=0.360, PPL=126.35
2025-09-21 00:49:40,955 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.3388, Acc=0.310, PPL=208.27
2025-09-21 00:49:48,915 - training.trainer - INFO - Epoch 20, Step 70859: Loss=5.9829, Acc=0.270, PPL=396.58
2025-09-21 00:49:57,022 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.1914, Acc=0.190, PPL=179.73
2025-09-21 00:50:14,636 - training.trainer - INFO - Epoch 21/100 completed in 281.30s - Train Loss: 5.8614, Train Acc: 0.224, Val Loss: 5.8414, Val Acc: 0.226
2025-09-21 00:50:15,368 - training.trainer - INFO - New best model saved with validation loss: 5.8414
2025-09-21 00:50:15,369 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-09-21 00:50:23,925 - training.trainer - INFO - Epoch 21, Step 71142: Loss=5.7536, Acc=0.224, PPL=315.32
2025-09-21 00:50:31,857 - training.trainer - INFO - Epoch 21, Step 71242: Loss=4.8445, Acc=0.464, PPL=127.03
2025-09-21 00:50:39,756 - training.trainer - INFO - Epoch 21, Step 71342: Loss=5.6903, Acc=0.303, PPL=295.99
2025-09-21 00:50:47,626 - training.trainer - INFO - Epoch 21, Step 71442: Loss=6.2680, Acc=0.170, PPL=527.42
2025-09-21 00:50:55,522 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.5134, Acc=0.250, PPL=247.99
2025-09-21 00:51:03,454 - training.trainer - INFO - Epoch 21, Step 71642: Loss=5.0837, Acc=0.320, PPL=161.37
2025-09-21 00:51:11,417 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.9175, Acc=0.206, PPL=371.48
2025-09-21 00:51:19,327 - training.trainer - INFO - Epoch 21, Step 71842: Loss=6.4420, Acc=0.171, PPL=627.69
2025-09-21 00:51:27,363 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.5724, Acc=0.228, PPL=263.07
2025-09-21 00:51:35,311 - training.trainer - INFO - Epoch 21, Step 72042: Loss=6.0374, Acc=0.206, PPL=418.81
2025-09-21 00:51:43,258 - training.trainer - INFO - Epoch 21, Step 72142: Loss=6.3353, Acc=0.159, PPL=564.12
2025-09-21 00:51:51,215 - training.trainer - INFO - Epoch 21, Step 72242: Loss=5.3017, Acc=0.258, PPL=200.67
2025-09-21 00:51:59,180 - training.trainer - INFO - Epoch 21, Step 72342: Loss=3.0879, Acc=0.552, PPL=21.93
2025-09-21 00:52:07,129 - training.trainer - INFO - Epoch 21, Step 72442: Loss=6.1011, Acc=0.163, PPL=446.37
2025-09-21 00:52:15,071 - training.trainer - INFO - Epoch 21, Step 72542: Loss=6.3409, Acc=0.188, PPL=567.30
2025-09-21 00:52:22,941 - training.trainer - INFO - Epoch 21, Step 72642: Loss=6.1260, Acc=0.220, PPL=457.61
2025-09-21 00:52:30,822 - training.trainer - INFO - Epoch 21, Step 72742: Loss=6.0391, Acc=0.250, PPL=419.51
2025-09-21 00:52:38,745 - training.trainer - INFO - Epoch 21, Step 72842: Loss=6.2393, Acc=0.171, PPL=512.50
2025-09-21 00:52:46,778 - training.trainer - INFO - Epoch 21, Step 72942: Loss=5.9158, Acc=0.222, PPL=370.85
2025-09-21 00:52:54,829 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.4036, Acc=0.333, PPL=222.21
2025-09-21 00:53:02,933 - training.trainer - INFO - Epoch 21, Step 73142: Loss=5.8825, Acc=0.303, PPL=358.70
2025-09-21 00:53:10,978 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.8776, Acc=0.240, PPL=356.94
2025-09-21 00:53:19,031 - training.trainer - INFO - Epoch 21, Step 73342: Loss=5.2849, Acc=0.433, PPL=197.34
2025-09-21 00:53:27,017 - training.trainer - INFO - Epoch 21, Step 73442: Loss=6.2806, Acc=0.163, PPL=534.09
2025-09-21 00:53:34,974 - training.trainer - INFO - Epoch 21, Step 73542: Loss=5.4930, Acc=0.226, PPL=243.00
2025-09-21 00:53:42,875 - training.trainer - INFO - Epoch 21, Step 73642: Loss=5.8813, Acc=0.238, PPL=358.27
2025-09-21 00:53:50,811 - training.trainer - INFO - Epoch 21, Step 73742: Loss=6.2976, Acc=0.140, PPL=543.24
2025-09-21 00:53:58,716 - training.trainer - INFO - Epoch 21, Step 73842: Loss=6.0346, Acc=0.250, PPL=417.63
2025-09-21 00:54:06,606 - training.trainer - INFO - Epoch 21, Step 73942: Loss=5.4589, Acc=0.279, PPL=234.85
2025-09-21 00:54:14,471 - training.trainer - INFO - Epoch 21, Step 74042: Loss=6.3505, Acc=0.214, PPL=572.79
2025-09-21 00:54:22,370 - training.trainer - INFO - Epoch 21, Step 74142: Loss=6.0794, Acc=0.177, PPL=436.75
2025-09-21 00:54:30,254 - training.trainer - INFO - Epoch 21, Step 74242: Loss=5.2080, Acc=0.310, PPL=182.73
2025-09-21 00:54:38,262 - training.trainer - INFO - Epoch 21, Step 74342: Loss=6.7126, Acc=0.143, PPL=822.70
2025-09-21 00:54:55,063 - training.trainer - INFO - Epoch 22/100 completed in 279.69s - Train Loss: 5.8478, Train Acc: 0.225, Val Loss: 5.8406, Val Acc: 0.223
2025-09-21 00:54:55,726 - training.trainer - INFO - New best model saved with validation loss: 5.8406
2025-09-21 00:54:55,726 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-09-21 00:55:03,922 - training.trainer - INFO - Epoch 22, Step 74525: Loss=4.2562, Acc=0.455, PPL=70.54
2025-09-21 00:55:11,849 - training.trainer - INFO - Epoch 22, Step 74625: Loss=5.7058, Acc=0.211, PPL=300.61
2025-09-21 00:55:19,809 - training.trainer - INFO - Epoch 22, Step 74725: Loss=5.0631, Acc=0.370, PPL=158.08
2025-09-21 00:55:27,744 - training.trainer - INFO - Epoch 22, Step 74825: Loss=6.3483, Acc=0.167, PPL=571.52
2025-09-21 00:55:35,737 - training.trainer - INFO - Epoch 22, Step 74925: Loss=6.3872, Acc=0.160, PPL=594.19
2025-09-21 00:55:43,695 - training.trainer - INFO - Epoch 22, Step 75025: Loss=6.0056, Acc=0.240, PPL=405.71
2025-09-21 00:55:51,683 - training.trainer - INFO - Epoch 22, Step 75125: Loss=5.8972, Acc=0.143, PPL=364.01
2025-09-21 00:55:59,835 - training.trainer - INFO - Epoch 22, Step 75225: Loss=6.6414, Acc=0.182, PPL=766.14
2025-09-21 00:56:07,972 - training.trainer - INFO - Epoch 22, Step 75325: Loss=5.4781, Acc=0.240, PPL=239.39
2025-09-21 00:56:16,138 - training.trainer - INFO - Epoch 22, Step 75425: Loss=5.6607, Acc=0.286, PPL=287.36
2025-09-21 00:56:24,266 - training.trainer - INFO - Epoch 22, Step 75525: Loss=6.6735, Acc=0.119, PPL=791.13
2025-09-21 00:56:32,452 - training.trainer - INFO - Epoch 22, Step 75625: Loss=6.2830, Acc=0.233, PPL=535.41
2025-09-21 00:56:40,515 - training.trainer - INFO - Epoch 22, Step 75725: Loss=6.3718, Acc=0.147, PPL=585.13
2025-09-21 00:56:48,507 - training.trainer - INFO - Epoch 22, Step 75825: Loss=6.4252, Acc=0.127, PPL=617.18
2025-09-21 00:56:56,516 - training.trainer - INFO - Epoch 22, Step 75925: Loss=6.3797, Acc=0.225, PPL=589.76
2025-09-21 00:57:04,584 - training.trainer - INFO - Epoch 22, Step 76025: Loss=6.4140, Acc=0.159, PPL=610.31
2025-09-21 00:57:12,560 - training.trainer - INFO - Epoch 22, Step 76125: Loss=5.0554, Acc=0.421, PPL=156.86
2025-09-21 00:57:20,590 - training.trainer - INFO - Epoch 22, Step 76225: Loss=6.8622, Acc=0.150, PPL=955.49
2025-09-21 00:57:28,596 - training.trainer - INFO - Epoch 22, Step 76325: Loss=6.5630, Acc=0.184, PPL=708.39
2025-09-21 00:57:36,584 - training.trainer - INFO - Epoch 22, Step 76425: Loss=5.8196, Acc=0.266, PPL=336.83
2025-09-21 00:57:44,567 - training.trainer - INFO - Epoch 22, Step 76525: Loss=5.1827, Acc=0.222, PPL=178.17
2025-09-21 00:57:52,588 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.9665, Acc=0.200, PPL=390.12
2025-09-21 00:58:00,576 - training.trainer - INFO - Epoch 22, Step 76725: Loss=6.5179, Acc=0.162, PPL=677.18
2025-09-21 00:58:08,699 - training.trainer - INFO - Epoch 22, Step 76825: Loss=6.0681, Acc=0.176, PPL=431.86
2025-09-21 00:58:16,885 - training.trainer - INFO - Epoch 22, Step 76925: Loss=5.9595, Acc=0.241, PPL=387.42
2025-09-21 00:58:24,947 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.4084, Acc=0.208, PPL=223.27
2025-09-21 00:58:32,990 - training.trainer - INFO - Epoch 22, Step 77125: Loss=6.4963, Acc=0.162, PPL=662.67
2025-09-21 00:58:40,930 - training.trainer - INFO - Epoch 22, Step 77225: Loss=5.9547, Acc=0.289, PPL=385.56
2025-09-21 00:58:48,995 - training.trainer - INFO - Epoch 22, Step 77325: Loss=6.1615, Acc=0.150, PPL=474.14
2025-09-21 00:58:57,112 - training.trainer - INFO - Epoch 22, Step 77425: Loss=6.7052, Acc=0.136, PPL=816.64
2025-09-21 00:59:05,266 - training.trainer - INFO - Epoch 22, Step 77525: Loss=6.3155, Acc=0.182, PPL=553.06
2025-09-21 00:59:13,450 - training.trainer - INFO - Epoch 22, Step 77625: Loss=5.9758, Acc=0.146, PPL=393.78
2025-09-21 00:59:21,582 - training.trainer - INFO - Epoch 22, Step 77725: Loss=5.2157, Acc=0.250, PPL=184.13
2025-09-21 00:59:38,688 - training.trainer - INFO - Epoch 23/100 completed in 282.96s - Train Loss: 5.8216, Train Acc: 0.230, Val Loss: 5.8067, Val Acc: 0.231
2025-09-21 00:59:39,274 - training.trainer - INFO - New best model saved with validation loss: 5.8067
2025-09-21 00:59:39,274 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-09-21 00:59:47,785 - training.trainer - INFO - Epoch 23, Step 77908: Loss=6.2334, Acc=0.150, PPL=509.48
2025-09-21 00:59:55,861 - training.trainer - INFO - Epoch 23, Step 78008: Loss=5.9870, Acc=0.200, PPL=398.22
2025-09-21 01:00:03,914 - training.trainer - INFO - Epoch 23, Step 78108: Loss=6.0127, Acc=0.179, PPL=408.58
2025-09-21 01:00:12,079 - training.trainer - INFO - Epoch 23, Step 78208: Loss=5.4940, Acc=0.226, PPL=243.23
2025-09-21 01:00:20,231 - training.trainer - INFO - Epoch 23, Step 78308: Loss=5.5334, Acc=0.276, PPL=253.01
2025-09-21 01:00:28,156 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.7471, Acc=0.238, PPL=313.27
2025-09-21 01:00:36,107 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.6760, Acc=0.300, PPL=291.77
2025-09-21 01:00:44,051 - training.trainer - INFO - Epoch 23, Step 78608: Loss=5.7229, Acc=0.300, PPL=305.79
2025-09-21 01:00:52,036 - training.trainer - INFO - Epoch 23, Step 78708: Loss=5.8869, Acc=0.167, PPL=360.30
2025-09-21 01:01:00,067 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.9408, Acc=0.095, PPL=380.26
2025-09-21 01:01:07,925 - training.trainer - INFO - Epoch 23, Step 78908: Loss=5.8576, Acc=0.242, PPL=349.89
2025-09-21 01:01:15,877 - training.trainer - INFO - Epoch 23, Step 79008: Loss=5.6178, Acc=0.194, PPL=275.29
2025-09-21 01:01:23,902 - training.trainer - INFO - Epoch 23, Step 79108: Loss=4.5791, Acc=0.400, PPL=97.42
2025-09-21 01:01:31,913 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.5559, Acc=0.318, PPL=258.77
2025-09-21 01:01:39,925 - training.trainer - INFO - Epoch 23, Step 79308: Loss=5.5789, Acc=0.263, PPL=264.78
2025-09-21 01:01:47,995 - training.trainer - INFO - Epoch 23, Step 79408: Loss=5.1233, Acc=0.389, PPL=167.88
2025-09-21 01:01:55,912 - training.trainer - INFO - Epoch 23, Step 79508: Loss=6.2677, Acc=0.134, PPL=527.27
2025-09-21 01:02:03,874 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.4940, Acc=0.216, PPL=243.23
2025-09-21 01:02:11,727 - training.trainer - INFO - Epoch 23, Step 79708: Loss=4.9106, Acc=0.312, PPL=135.72
2025-09-21 01:02:19,725 - training.trainer - INFO - Epoch 23, Step 79808: Loss=5.6822, Acc=0.235, PPL=293.59
2025-09-21 01:02:27,741 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.3332, Acc=0.226, PPL=207.11
2025-09-21 01:02:35,668 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.3308, Acc=0.359, PPL=206.60
2025-09-21 01:02:43,657 - training.trainer - INFO - Epoch 23, Step 80108: Loss=6.1347, Acc=0.206, PPL=461.62
2025-09-21 01:02:51,851 - training.trainer - INFO - Epoch 23, Step 80208: Loss=5.5285, Acc=0.250, PPL=251.78
2025-09-21 01:03:00,025 - training.trainer - INFO - Epoch 23, Step 80308: Loss=5.6909, Acc=0.240, PPL=296.17
2025-09-21 01:03:08,020 - training.trainer - INFO - Epoch 23, Step 80408: Loss=6.4421, Acc=0.211, PPL=627.72
2025-09-21 01:03:16,116 - training.trainer - INFO - Epoch 23, Step 80508: Loss=5.7080, Acc=0.275, PPL=301.26
2025-09-21 01:03:24,132 - training.trainer - INFO - Epoch 23, Step 80608: Loss=5.7740, Acc=0.171, PPL=321.81
2025-09-21 01:03:32,176 - training.trainer - INFO - Epoch 23, Step 80708: Loss=6.1764, Acc=0.180, PPL=481.28
2025-09-21 01:03:40,160 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.6412, Acc=0.226, PPL=281.81
2025-09-21 01:03:48,168 - training.trainer - INFO - Epoch 23, Step 80908: Loss=5.6375, Acc=0.214, PPL=280.76
2025-09-21 01:03:56,151 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.5165, Acc=0.263, PPL=248.76
2025-09-21 01:04:03,972 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.7254, Acc=0.250, PPL=306.54
2025-09-21 01:04:20,936 - training.trainer - INFO - Epoch 24/100 completed in 281.66s - Train Loss: 5.8155, Train Acc: 0.230, Val Loss: 5.8186, Val Acc: 0.228
2025-09-21 01:04:29,476 - training.trainer - INFO - Epoch 24, Step 81291: Loss=4.9775, Acc=0.346, PPL=145.11
2025-09-21 01:04:37,653 - training.trainer - INFO - Epoch 24, Step 81391: Loss=5.9944, Acc=0.183, PPL=401.16
2025-09-21 01:04:45,577 - training.trainer - INFO - Epoch 24, Step 81491: Loss=6.1139, Acc=0.233, PPL=452.12
2025-09-21 01:04:53,460 - training.trainer - INFO - Epoch 24, Step 81591: Loss=6.0489, Acc=0.185, PPL=423.64
2025-09-21 01:05:01,504 - training.trainer - INFO - Epoch 24, Step 81691: Loss=5.7572, Acc=0.253, PPL=316.47
2025-09-21 01:05:09,424 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.6054, Acc=0.185, PPL=271.90
2025-09-21 01:05:17,446 - training.trainer - INFO - Epoch 24, Step 81891: Loss=5.5416, Acc=0.381, PPL=255.08
2025-09-21 01:05:25,540 - training.trainer - INFO - Epoch 24, Step 81991: Loss=5.0156, Acc=0.257, PPL=150.74
2025-09-21 01:05:33,584 - training.trainer - INFO - Epoch 24, Step 82091: Loss=6.4935, Acc=0.233, PPL=660.81
2025-09-21 01:05:41,653 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.3213, Acc=0.357, PPL=204.64
2025-09-21 01:05:49,659 - training.trainer - INFO - Epoch 24, Step 82291: Loss=6.1412, Acc=0.143, PPL=464.59
2025-09-21 01:05:57,666 - training.trainer - INFO - Epoch 24, Step 82391: Loss=6.4191, Acc=0.238, PPL=613.46
2025-09-21 01:06:05,524 - training.trainer - INFO - Epoch 24, Step 82491: Loss=5.1181, Acc=0.318, PPL=167.02
2025-09-21 01:06:13,397 - training.trainer - INFO - Epoch 24, Step 82591: Loss=5.9379, Acc=0.222, PPL=379.15
2025-09-21 01:06:21,307 - training.trainer - INFO - Epoch 24, Step 82691: Loss=6.3002, Acc=0.190, PPL=544.69
2025-09-21 01:06:29,213 - training.trainer - INFO - Epoch 24, Step 82791: Loss=6.0001, Acc=0.143, PPL=403.45
2025-09-21 01:06:37,067 - training.trainer - INFO - Epoch 24, Step 82891: Loss=5.8570, Acc=0.225, PPL=349.68
2025-09-21 01:06:44,994 - training.trainer - INFO - Epoch 24, Step 82991: Loss=6.5727, Acc=0.152, PPL=715.27
2025-09-21 01:06:52,957 - training.trainer - INFO - Epoch 24, Step 83091: Loss=5.9528, Acc=0.255, PPL=384.84
2025-09-21 01:07:00,869 - training.trainer - INFO - Epoch 24, Step 83191: Loss=6.1482, Acc=0.250, PPL=467.86
2025-09-21 01:07:08,738 - training.trainer - INFO - Epoch 24, Step 83291: Loss=5.3091, Acc=0.302, PPL=202.17
2025-09-21 01:07:16,682 - training.trainer - INFO - Epoch 24, Step 83391: Loss=5.7185, Acc=0.235, PPL=304.44
2025-09-21 01:07:24,570 - training.trainer - INFO - Epoch 24, Step 83491: Loss=6.4065, Acc=0.151, PPL=605.78
2025-09-21 01:07:32,388 - training.trainer - INFO - Epoch 24, Step 83591: Loss=5.6475, Acc=0.304, PPL=283.58
2025-09-21 01:07:40,351 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.6717, Acc=0.368, PPL=290.54
2025-09-21 01:07:48,186 - training.trainer - INFO - Epoch 24, Step 83791: Loss=6.0606, Acc=0.183, PPL=428.65
2025-09-21 01:07:56,086 - training.trainer - INFO - Epoch 24, Step 83891: Loss=5.2354, Acc=0.261, PPL=187.80
2025-09-21 01:08:04,074 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.5533, Acc=0.222, PPL=258.08
2025-09-21 01:08:11,998 - training.trainer - INFO - Epoch 24, Step 84091: Loss=5.3583, Acc=0.222, PPL=212.36
2025-09-21 01:08:19,864 - training.trainer - INFO - Epoch 24, Step 84191: Loss=6.5283, Acc=0.129, PPL=684.26
2025-09-21 01:08:27,753 - training.trainer - INFO - Epoch 24, Step 84291: Loss=5.7756, Acc=0.314, PPL=322.33
2025-09-21 01:08:35,730 - training.trainer - INFO - Epoch 24, Step 84391: Loss=5.3703, Acc=0.200, PPL=214.93
2025-09-21 01:08:43,814 - training.trainer - INFO - Epoch 24, Step 84491: Loss=6.0690, Acc=0.093, PPL=432.25
2025-09-21 01:09:00,521 - training.trainer - INFO - Epoch 25/100 completed in 279.58s - Train Loss: 5.8004, Train Acc: 0.233, Val Loss: 5.8039, Val Acc: 0.232
2025-09-21 01:09:00,876 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-21 01:09:01,573 - training.trainer - INFO - New best model saved with validation loss: 5.8039
2025-09-21 01:09:01,574 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-21 01:09:10,016 - training.trainer - INFO - Epoch 25, Step 84674: Loss=5.7827, Acc=0.231, PPL=324.64
2025-09-21 01:09:18,032 - training.trainer - INFO - Epoch 25, Step 84774: Loss=6.1310, Acc=0.189, PPL=459.91
2025-09-21 01:09:25,885 - training.trainer - INFO - Epoch 25, Step 84874: Loss=6.3501, Acc=0.222, PPL=572.57
2025-09-21 01:09:33,990 - training.trainer - INFO - Epoch 25, Step 84974: Loss=6.0025, Acc=0.250, PPL=404.44
2025-09-21 01:09:42,031 - training.trainer - INFO - Epoch 25, Step 85074: Loss=5.8566, Acc=0.271, PPL=349.55
2025-09-21 01:09:50,096 - training.trainer - INFO - Epoch 25, Step 85174: Loss=5.8800, Acc=0.250, PPL=357.79
2025-09-21 01:09:57,951 - training.trainer - INFO - Epoch 25, Step 85274: Loss=5.5898, Acc=0.206, PPL=267.69
2025-09-21 01:10:05,835 - training.trainer - INFO - Epoch 25, Step 85374: Loss=4.9677, Acc=0.312, PPL=143.69
2025-09-21 01:10:13,741 - training.trainer - INFO - Epoch 25, Step 85474: Loss=5.9546, Acc=0.167, PPL=385.52
2025-09-21 01:10:21,706 - training.trainer - INFO - Epoch 25, Step 85574: Loss=6.7058, Acc=0.170, PPL=817.16
2025-09-21 01:10:29,584 - training.trainer - INFO - Epoch 25, Step 85674: Loss=6.4014, Acc=0.114, PPL=602.69
2025-09-21 01:10:37,613 - training.trainer - INFO - Epoch 25, Step 85774: Loss=5.2708, Acc=0.328, PPL=194.56
2025-09-21 01:10:45,758 - training.trainer - INFO - Epoch 25, Step 85874: Loss=6.1522, Acc=0.166, PPL=469.74
2025-09-21 01:10:53,971 - training.trainer - INFO - Epoch 25, Step 85974: Loss=6.2429, Acc=0.255, PPL=514.34
2025-09-21 01:11:02,050 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.8584, Acc=0.245, PPL=350.18
2025-09-21 01:11:10,143 - training.trainer - INFO - Epoch 25, Step 86174: Loss=5.7701, Acc=0.267, PPL=320.56
2025-09-21 01:11:18,218 - training.trainer - INFO - Epoch 25, Step 86274: Loss=6.1004, Acc=0.197, PPL=446.04
2025-09-21 01:11:26,337 - training.trainer - INFO - Epoch 25, Step 86374: Loss=5.8515, Acc=0.185, PPL=347.75
2025-09-21 01:11:34,493 - training.trainer - INFO - Epoch 25, Step 86474: Loss=6.5096, Acc=0.200, PPL=671.55
2025-09-21 01:11:42,657 - training.trainer - INFO - Epoch 25, Step 86574: Loss=5.8949, Acc=0.269, PPL=363.19
2025-09-21 01:11:50,816 - training.trainer - INFO - Epoch 25, Step 86674: Loss=6.7797, Acc=0.154, PPL=879.80
2025-09-21 01:11:58,678 - training.trainer - INFO - Epoch 25, Step 86774: Loss=4.8062, Acc=0.353, PPL=122.26
2025-09-21 01:12:06,602 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.4138, Acc=0.155, PPL=610.22
2025-09-21 01:12:14,556 - training.trainer - INFO - Epoch 25, Step 86974: Loss=6.0936, Acc=0.268, PPL=443.03
2025-09-21 01:12:22,412 - training.trainer - INFO - Epoch 25, Step 87074: Loss=5.7614, Acc=0.238, PPL=317.79
2025-09-21 01:12:30,274 - training.trainer - INFO - Epoch 25, Step 87174: Loss=4.9089, Acc=0.423, PPL=135.49
2025-09-21 01:12:38,239 - training.trainer - INFO - Epoch 25, Step 87274: Loss=5.6752, Acc=0.185, PPL=291.53
2025-09-21 01:12:46,032 - training.trainer - INFO - Epoch 25, Step 87374: Loss=6.3480, Acc=0.262, PPL=571.34
2025-09-21 01:12:53,859 - training.trainer - INFO - Epoch 25, Step 87474: Loss=5.4267, Acc=0.237, PPL=227.40
2025-09-21 01:13:01,645 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.0776, Acc=0.350, PPL=160.39
2025-09-21 01:13:09,524 - training.trainer - INFO - Epoch 25, Step 87674: Loss=6.3510, Acc=0.180, PPL=573.09
2025-09-21 01:13:17,304 - training.trainer - INFO - Epoch 25, Step 87774: Loss=5.9037, Acc=0.176, PPL=366.40
2025-09-21 01:13:25,142 - training.trainer - INFO - Epoch 25, Step 87874: Loss=5.5752, Acc=0.213, PPL=263.80
2025-09-21 01:13:41,819 - training.trainer - INFO - Epoch 26/100 completed in 280.25s - Train Loss: 5.7827, Train Acc: 0.235, Val Loss: 5.8023, Val Acc: 0.235
2025-09-21 01:13:42,619 - training.trainer - INFO - New best model saved with validation loss: 5.8023
2025-09-21 01:13:42,620 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_26.pt
2025-09-21 01:13:50,592 - training.trainer - INFO - Epoch 26, Step 88057: Loss=5.5941, Acc=0.306, PPL=268.83
2025-09-21 01:13:58,518 - training.trainer - INFO - Epoch 26, Step 88157: Loss=6.1584, Acc=0.226, PPL=472.69
2025-09-21 01:14:06,387 - training.trainer - INFO - Epoch 26, Step 88257: Loss=4.9395, Acc=0.246, PPL=139.69
2025-09-21 01:14:14,313 - training.trainer - INFO - Epoch 26, Step 88357: Loss=6.1142, Acc=0.158, PPL=452.25
2025-09-21 01:14:22,201 - training.trainer - INFO - Epoch 26, Step 88457: Loss=6.2604, Acc=0.183, PPL=523.42
2025-09-21 01:14:30,066 - training.trainer - INFO - Epoch 26, Step 88557: Loss=6.0693, Acc=0.147, PPL=432.38
2025-09-21 01:14:37,936 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.8752, Acc=0.240, PPL=356.10
2025-09-21 01:14:45,819 - training.trainer - INFO - Epoch 26, Step 88757: Loss=6.5766, Acc=0.233, PPL=718.06
2025-09-21 01:14:53,777 - training.trainer - INFO - Epoch 26, Step 88857: Loss=5.3264, Acc=0.292, PPL=205.71
2025-09-21 01:15:01,599 - training.trainer - INFO - Epoch 26, Step 88957: Loss=6.0576, Acc=0.150, PPL=427.35
2025-09-21 01:15:09,788 - training.trainer - INFO - Epoch 26, Step 89057: Loss=4.7796, Acc=0.417, PPL=119.06
2025-09-21 01:15:17,766 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.4090, Acc=0.190, PPL=223.41
2025-09-21 01:15:25,668 - training.trainer - INFO - Epoch 26, Step 89257: Loss=6.2056, Acc=0.229, PPL=495.50
2025-09-21 01:15:33,561 - training.trainer - INFO - Epoch 26, Step 89357: Loss=5.5270, Acc=0.185, PPL=251.38
2025-09-21 01:15:41,499 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.6903, Acc=0.207, PPL=295.99
2025-09-21 01:15:49,477 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.5551, Acc=0.225, PPL=258.55
2025-09-21 01:15:57,476 - training.trainer - INFO - Epoch 26, Step 89657: Loss=6.2077, Acc=0.152, PPL=496.54
2025-09-21 01:16:05,492 - training.trainer - INFO - Epoch 26, Step 89757: Loss=6.1406, Acc=0.196, PPL=464.32
2025-09-21 01:16:13,425 - training.trainer - INFO - Epoch 26, Step 89857: Loss=6.3713, Acc=0.209, PPL=584.81
2025-09-21 01:16:21,352 - training.trainer - INFO - Epoch 26, Step 89957: Loss=5.6928, Acc=0.350, PPL=296.72
2025-09-21 01:16:29,313 - training.trainer - INFO - Epoch 26, Step 90057: Loss=6.4802, Acc=0.193, PPL=652.13
2025-09-21 01:16:37,438 - training.trainer - INFO - Epoch 26, Step 90157: Loss=5.8838, Acc=0.151, PPL=359.16
2025-09-21 01:16:45,594 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.5576, Acc=0.229, PPL=259.19
2025-09-21 01:16:53,772 - training.trainer - INFO - Epoch 26, Step 90357: Loss=6.4359, Acc=0.159, PPL=623.83
2025-09-21 01:17:01,753 - training.trainer - INFO - Epoch 26, Step 90457: Loss=5.6379, Acc=0.167, PPL=280.86
2025-09-21 01:17:09,655 - training.trainer - INFO - Epoch 26, Step 90557: Loss=6.2980, Acc=0.196, PPL=543.50
2025-09-21 01:17:17,784 - training.trainer - INFO - Epoch 26, Step 90657: Loss=6.0445, Acc=0.236, PPL=421.80
2025-09-21 01:17:25,784 - training.trainer - INFO - Epoch 26, Step 90757: Loss=6.6264, Acc=0.122, PPL=754.74
2025-09-21 01:17:33,660 - training.trainer - INFO - Epoch 26, Step 90857: Loss=3.8788, Acc=0.389, PPL=48.36
2025-09-21 01:17:41,556 - training.trainer - INFO - Epoch 26, Step 90957: Loss=6.6030, Acc=0.205, PPL=737.30
2025-09-21 01:17:49,498 - training.trainer - INFO - Epoch 26, Step 91057: Loss=6.8754, Acc=0.188, PPL=968.19
2025-09-21 01:17:57,487 - training.trainer - INFO - Epoch 26, Step 91157: Loss=6.5092, Acc=0.189, PPL=671.32
2025-09-21 01:18:05,342 - training.trainer - INFO - Epoch 26, Step 91257: Loss=6.2064, Acc=0.200, PPL=495.93
2025-09-21 01:18:21,895 - training.trainer - INFO - Epoch 27/100 completed in 279.27s - Train Loss: 5.7743, Train Acc: 0.237, Val Loss: 5.7746, Val Acc: 0.238
2025-09-21 01:18:22,547 - training.trainer - INFO - New best model saved with validation loss: 5.7746
2025-09-21 01:18:22,547 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_27.pt
2025-09-21 01:18:30,840 - training.trainer - INFO - Epoch 27, Step 91440: Loss=6.0198, Acc=0.194, PPL=411.49
2025-09-21 01:18:39,024 - training.trainer - INFO - Epoch 27, Step 91540: Loss=5.6615, Acc=0.233, PPL=287.58
2025-09-21 01:18:47,196 - training.trainer - INFO - Epoch 27, Step 91640: Loss=4.5986, Acc=0.360, PPL=99.35
2025-09-21 01:18:55,042 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.4204, Acc=0.333, PPL=225.96
2025-09-21 01:19:03,041 - training.trainer - INFO - Epoch 27, Step 91840: Loss=5.2740, Acc=0.286, PPL=195.20
2025-09-21 01:19:10,933 - training.trainer - INFO - Epoch 27, Step 91940: Loss=5.8774, Acc=0.170, PPL=356.88
2025-09-21 01:19:18,784 - training.trainer - INFO - Epoch 27, Step 92040: Loss=5.9297, Acc=0.167, PPL=376.05
2025-09-21 01:19:26,655 - training.trainer - INFO - Epoch 27, Step 92140: Loss=5.6615, Acc=0.182, PPL=287.58
2025-09-21 01:19:34,564 - training.trainer - INFO - Epoch 27, Step 92240: Loss=5.7594, Acc=0.176, PPL=317.15
2025-09-21 01:19:42,443 - training.trainer - INFO - Epoch 27, Step 92340: Loss=6.7227, Acc=0.345, PPL=831.08
2025-09-21 01:19:50,292 - training.trainer - INFO - Epoch 27, Step 92440: Loss=4.0516, Acc=0.395, PPL=57.49
2025-09-21 01:19:58,218 - training.trainer - INFO - Epoch 27, Step 92540: Loss=5.7487, Acc=0.323, PPL=313.80
2025-09-21 01:20:06,135 - training.trainer - INFO - Epoch 27, Step 92640: Loss=5.5761, Acc=0.186, PPL=264.04
2025-09-21 01:20:14,067 - training.trainer - INFO - Epoch 27, Step 92740: Loss=5.8137, Acc=0.200, PPL=334.85
2025-09-21 01:20:21,986 - training.trainer - INFO - Epoch 27, Step 92840: Loss=6.2772, Acc=0.167, PPL=532.30
2025-09-21 01:20:29,889 - training.trainer - INFO - Epoch 27, Step 92940: Loss=6.4181, Acc=0.140, PPL=612.85
2025-09-21 01:20:37,829 - training.trainer - INFO - Epoch 27, Step 93040: Loss=5.7880, Acc=0.273, PPL=326.37
2025-09-21 01:20:46,001 - training.trainer - INFO - Epoch 27, Step 93140: Loss=5.9098, Acc=0.216, PPL=368.64
2025-09-21 01:20:54,050 - training.trainer - INFO - Epoch 27, Step 93240: Loss=5.2217, Acc=0.364, PPL=185.24
2025-09-21 01:21:01,995 - training.trainer - INFO - Epoch 27, Step 93340: Loss=5.9214, Acc=0.211, PPL=372.95
2025-09-21 01:21:09,858 - training.trainer - INFO - Epoch 27, Step 93440: Loss=6.2216, Acc=0.195, PPL=503.50
2025-09-21 01:21:17,754 - training.trainer - INFO - Epoch 27, Step 93540: Loss=6.5366, Acc=0.211, PPL=689.92
2025-09-21 01:21:25,657 - training.trainer - INFO - Epoch 27, Step 93640: Loss=3.9218, Acc=0.448, PPL=50.49
2025-09-21 01:21:33,486 - training.trainer - INFO - Epoch 27, Step 93740: Loss=5.4360, Acc=0.263, PPL=229.52
2025-09-21 01:21:41,301 - training.trainer - INFO - Epoch 27, Step 93840: Loss=4.7380, Acc=0.286, PPL=114.21
2025-09-21 01:21:49,269 - training.trainer - INFO - Epoch 27, Step 93940: Loss=5.7038, Acc=0.245, PPL=300.00
2025-09-21 01:21:57,206 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.1262, Acc=0.396, PPL=168.37
2025-09-21 01:22:05,209 - training.trainer - INFO - Epoch 27, Step 94140: Loss=5.7176, Acc=0.231, PPL=304.19
2025-09-21 01:22:13,093 - training.trainer - INFO - Epoch 27, Step 94240: Loss=5.1541, Acc=0.190, PPL=173.13
2025-09-21 01:22:20,988 - training.trainer - INFO - Epoch 27, Step 94340: Loss=6.2931, Acc=0.179, PPL=540.81
2025-09-21 01:22:28,887 - training.trainer - INFO - Epoch 27, Step 94440: Loss=6.3307, Acc=0.179, PPL=561.56
2025-09-21 01:22:36,843 - training.trainer - INFO - Epoch 27, Step 94540: Loss=6.4467, Acc=0.257, PPL=630.64
2025-09-21 01:22:44,759 - training.trainer - INFO - Epoch 27, Step 94640: Loss=6.3017, Acc=0.143, PPL=545.52
2025-09-21 01:23:01,441 - training.trainer - INFO - Epoch 28/100 completed in 278.89s - Train Loss: 5.7604, Train Acc: 0.239, Val Loss: 5.7688, Val Acc: 0.238
2025-09-21 01:23:02,224 - training.trainer - INFO - New best model saved with validation loss: 5.7688
2025-09-21 01:23:02,224 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_28.pt
2025-09-21 01:23:10,434 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.9207, Acc=0.250, PPL=372.69
2025-09-21 01:23:18,487 - training.trainer - INFO - Epoch 28, Step 94923: Loss=3.9681, Acc=0.444, PPL=52.88
2025-09-21 01:23:26,411 - training.trainer - INFO - Epoch 28, Step 95023: Loss=6.4784, Acc=0.185, PPL=650.94
2025-09-21 01:23:34,381 - training.trainer - INFO - Epoch 28, Step 95123: Loss=6.4908, Acc=0.157, PPL=659.06
2025-09-21 01:23:42,253 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.6288, Acc=0.152, PPL=278.31
2025-09-21 01:23:50,070 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.0349, Acc=0.324, PPL=153.69
2025-09-21 01:23:57,981 - training.trainer - INFO - Epoch 28, Step 95423: Loss=6.1781, Acc=0.118, PPL=482.09
2025-09-21 01:24:05,933 - training.trainer - INFO - Epoch 28, Step 95523: Loss=4.8982, Acc=0.344, PPL=134.05
2025-09-21 01:24:13,837 - training.trainer - INFO - Epoch 28, Step 95623: Loss=6.4459, Acc=0.333, PPL=630.14
2025-09-21 01:24:21,586 - training.trainer - INFO - Epoch 28, Step 95723: Loss=5.8828, Acc=0.246, PPL=358.81
2025-09-21 01:24:29,438 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.1793, Acc=0.269, PPL=177.56
2025-09-21 01:24:37,334 - training.trainer - INFO - Epoch 28, Step 95923: Loss=5.6228, Acc=0.200, PPL=276.65
2025-09-21 01:24:45,216 - training.trainer - INFO - Epoch 28, Step 96023: Loss=6.1689, Acc=0.130, PPL=477.64
2025-09-21 01:24:53,284 - training.trainer - INFO - Epoch 28, Step 96123: Loss=6.1198, Acc=0.130, PPL=454.77
2025-09-21 01:25:01,390 - training.trainer - INFO - Epoch 28, Step 96223: Loss=4.1253, Acc=0.375, PPL=61.88
2025-09-21 01:25:09,550 - training.trainer - INFO - Epoch 28, Step 96323: Loss=6.4894, Acc=0.143, PPL=658.13
2025-09-21 01:25:17,719 - training.trainer - INFO - Epoch 28, Step 96423: Loss=6.4967, Acc=0.220, PPL=662.92
2025-09-21 01:25:25,858 - training.trainer - INFO - Epoch 28, Step 96523: Loss=5.8242, Acc=0.269, PPL=338.39
2025-09-21 01:25:34,013 - training.trainer - INFO - Epoch 28, Step 96623: Loss=5.7031, Acc=0.219, PPL=299.80
2025-09-21 01:25:42,117 - training.trainer - INFO - Epoch 28, Step 96723: Loss=6.7323, Acc=0.132, PPL=839.12
2025-09-21 01:25:50,109 - training.trainer - INFO - Epoch 28, Step 96823: Loss=5.2875, Acc=0.255, PPL=197.84
2025-09-21 01:25:58,181 - training.trainer - INFO - Epoch 28, Step 96923: Loss=5.2529, Acc=0.259, PPL=191.12
2025-09-21 01:26:06,065 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.9043, Acc=0.146, PPL=366.61
2025-09-21 01:26:14,114 - training.trainer - INFO - Epoch 28, Step 97123: Loss=6.0939, Acc=0.235, PPL=443.13
2025-09-21 01:26:22,218 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.8692, Acc=0.197, PPL=353.96
2025-09-21 01:26:30,360 - training.trainer - INFO - Epoch 28, Step 97323: Loss=4.4852, Acc=0.455, PPL=88.69
2025-09-21 01:26:38,431 - training.trainer - INFO - Epoch 28, Step 97423: Loss=5.9461, Acc=0.191, PPL=382.26
2025-09-21 01:26:46,619 - training.trainer - INFO - Epoch 28, Step 97523: Loss=6.2380, Acc=0.256, PPL=511.85
2025-09-21 01:26:54,687 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.4816, Acc=0.229, PPL=240.22
2025-09-21 01:27:02,779 - training.trainer - INFO - Epoch 28, Step 97723: Loss=5.8346, Acc=0.156, PPL=341.93
2025-09-21 01:27:10,834 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.5733, Acc=0.269, PPL=263.30
2025-09-21 01:27:18,934 - training.trainer - INFO - Epoch 28, Step 97923: Loss=5.8326, Acc=0.172, PPL=341.24
2025-09-21 01:27:27,052 - training.trainer - INFO - Epoch 28, Step 98023: Loss=6.0064, Acc=0.357, PPL=406.03
2025-09-21 01:27:44,491 - training.trainer - INFO - Epoch 29/100 completed in 282.27s - Train Loss: 5.7535, Train Acc: 0.241, Val Loss: 5.7571, Val Acc: 0.240
2025-09-21 01:27:45,061 - training.trainer - INFO - New best model saved with validation loss: 5.7571
2025-09-21 01:27:45,062 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_29.pt
2025-09-21 01:27:53,391 - training.trainer - INFO - Epoch 29, Step 98206: Loss=3.8705, Acc=0.526, PPL=47.97
2025-09-21 01:28:01,442 - training.trainer - INFO - Epoch 29, Step 98306: Loss=5.8960, Acc=0.222, PPL=363.57
2025-09-21 01:28:09,584 - training.trainer - INFO - Epoch 29, Step 98406: Loss=5.5663, Acc=0.173, PPL=261.47
2025-09-21 01:28:17,726 - training.trainer - INFO - Epoch 29, Step 98506: Loss=6.4767, Acc=0.158, PPL=649.83
2025-09-21 01:28:25,861 - training.trainer - INFO - Epoch 29, Step 98606: Loss=6.0535, Acc=0.159, PPL=425.61
2025-09-21 01:28:33,941 - training.trainer - INFO - Epoch 29, Step 98706: Loss=4.3379, Acc=0.250, PPL=76.55
2025-09-21 01:28:42,044 - training.trainer - INFO - Epoch 29, Step 98806: Loss=5.8968, Acc=0.250, PPL=363.87
2025-09-21 01:28:50,179 - training.trainer - INFO - Epoch 29, Step 98906: Loss=5.4848, Acc=0.188, PPL=241.01
2025-09-21 01:28:58,354 - training.trainer - INFO - Epoch 29, Step 99006: Loss=5.6433, Acc=0.271, PPL=282.38
2025-09-21 01:29:06,505 - training.trainer - INFO - Epoch 29, Step 99106: Loss=5.3716, Acc=0.326, PPL=215.21
2025-09-21 01:29:14,746 - training.trainer - INFO - Epoch 29, Step 99206: Loss=5.3390, Acc=0.346, PPL=208.31
2025-09-21 01:29:22,987 - training.trainer - INFO - Epoch 29, Step 99306: Loss=5.7757, Acc=0.220, PPL=322.37
2025-09-21 01:29:31,197 - training.trainer - INFO - Epoch 29, Step 99406: Loss=5.6305, Acc=0.172, PPL=278.80
2025-09-21 01:29:39,521 - training.trainer - INFO - Epoch 29, Step 99506: Loss=5.3372, Acc=0.291, PPL=207.93
2025-09-21 01:29:47,800 - training.trainer - INFO - Epoch 29, Step 99606: Loss=5.2020, Acc=0.216, PPL=181.64
2025-09-21 01:29:56,079 - training.trainer - INFO - Epoch 29, Step 99706: Loss=5.9185, Acc=0.226, PPL=371.85
2025-09-21 01:30:04,419 - training.trainer - INFO - Epoch 29, Step 99806: Loss=4.7398, Acc=0.316, PPL=114.41
2025-09-21 01:30:12,653 - training.trainer - INFO - Epoch 29, Step 99906: Loss=5.6938, Acc=0.158, PPL=297.01
2025-09-21 01:30:20,883 - training.trainer - INFO - Epoch 29, Step 100006: Loss=4.9037, Acc=0.440, PPL=134.78
2025-09-21 01:30:29,042 - training.trainer - INFO - Epoch 29, Step 100106: Loss=6.1842, Acc=0.243, PPL=485.04
2025-09-21 01:30:37,166 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.9670, Acc=0.188, PPL=390.34
2025-09-21 01:30:45,311 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.8461, Acc=0.273, PPL=345.87
2025-09-21 01:30:53,339 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.8157, Acc=0.122, PPL=335.52
2025-09-21 01:31:01,362 - training.trainer - INFO - Epoch 29, Step 100506: Loss=5.5463, Acc=0.174, PPL=256.28
2025-09-21 01:31:09,267 - training.trainer - INFO - Epoch 29, Step 100606: Loss=6.0481, Acc=0.194, PPL=423.32
2025-09-21 01:31:17,295 - training.trainer - INFO - Epoch 29, Step 100706: Loss=6.1238, Acc=0.183, PPL=456.59
2025-09-21 01:31:25,294 - training.trainer - INFO - Epoch 29, Step 100806: Loss=6.3048, Acc=0.136, PPL=547.18
2025-09-21 01:31:33,209 - training.trainer - INFO - Epoch 29, Step 100906: Loss=6.4390, Acc=0.140, PPL=625.80
2025-09-21 01:31:41,105 - training.trainer - INFO - Epoch 29, Step 101006: Loss=5.6557, Acc=0.163, PPL=285.92
2025-09-21 01:31:49,169 - training.trainer - INFO - Epoch 29, Step 101106: Loss=6.1358, Acc=0.269, PPL=462.10
2025-09-21 01:31:56,991 - training.trainer - INFO - Epoch 29, Step 101206: Loss=6.1503, Acc=0.212, PPL=468.85
2025-09-21 01:32:04,914 - training.trainer - INFO - Epoch 29, Step 101306: Loss=6.3316, Acc=0.114, PPL=562.05
2025-09-21 01:32:12,948 - training.trainer - INFO - Epoch 29, Step 101406: Loss=6.0293, Acc=0.205, PPL=415.44
2025-09-21 01:32:30,294 - training.trainer - INFO - Epoch 30/100 completed in 285.23s - Train Loss: 5.7341, Train Acc: 0.243, Val Loss: 5.7453, Val Acc: 0.240
2025-09-21 01:32:30,683 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-21 01:32:31,379 - training.trainer - INFO - New best model saved with validation loss: 5.7453
2025-09-21 01:32:31,379 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-21 01:32:39,786 - training.trainer - INFO - Epoch 30, Step 101589: Loss=6.3047, Acc=0.185, PPL=547.16
2025-09-21 01:32:47,821 - training.trainer - INFO - Epoch 30, Step 101689: Loss=6.0901, Acc=0.160, PPL=441.49
2025-09-21 01:32:55,750 - training.trainer - INFO - Epoch 30, Step 101789: Loss=4.2669, Acc=0.421, PPL=71.30
2025-09-21 01:33:03,672 - training.trainer - INFO - Epoch 30, Step 101889: Loss=5.8543, Acc=0.179, PPL=348.72
2025-09-21 01:33:11,563 - training.trainer - INFO - Epoch 30, Step 101989: Loss=6.2713, Acc=0.116, PPL=529.15
2025-09-21 01:33:19,445 - training.trainer - INFO - Epoch 30, Step 102089: Loss=5.0688, Acc=0.364, PPL=158.98
2025-09-21 01:33:27,325 - training.trainer - INFO - Epoch 30, Step 102189: Loss=5.3467, Acc=0.310, PPL=209.91
2025-09-21 01:33:35,223 - training.trainer - INFO - Epoch 30, Step 102289: Loss=6.2931, Acc=0.193, PPL=540.81
2025-09-21 01:33:43,296 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.7774, Acc=0.250, PPL=322.93
2025-09-21 01:33:51,339 - training.trainer - INFO - Epoch 30, Step 102489: Loss=6.1881, Acc=0.204, PPL=486.94
2025-09-21 01:33:59,195 - training.trainer - INFO - Epoch 30, Step 102589: Loss=6.2203, Acc=0.216, PPL=502.87
2025-09-21 01:34:07,083 - training.trainer - INFO - Epoch 30, Step 102689: Loss=5.3692, Acc=0.282, PPL=214.69
2025-09-21 01:34:14,971 - training.trainer - INFO - Epoch 30, Step 102789: Loss=5.5173, Acc=0.226, PPL=248.97
2025-09-21 01:34:22,875 - training.trainer - INFO - Epoch 30, Step 102889: Loss=5.6527, Acc=0.216, PPL=285.06
2025-09-21 01:34:30,765 - training.trainer - INFO - Epoch 30, Step 102989: Loss=6.0789, Acc=0.114, PPL=436.55
2025-09-21 01:34:38,686 - training.trainer - INFO - Epoch 30, Step 103089: Loss=5.8821, Acc=0.265, PPL=358.57
2025-09-21 01:34:46,607 - training.trainer - INFO - Epoch 30, Step 103189: Loss=6.1879, Acc=0.132, PPL=486.83
2025-09-21 01:34:54,446 - training.trainer - INFO - Epoch 30, Step 103289: Loss=5.7096, Acc=0.179, PPL=301.76
2025-09-21 01:35:02,340 - training.trainer - INFO - Epoch 30, Step 103389: Loss=6.2622, Acc=0.167, PPL=524.40
2025-09-21 01:35:10,236 - training.trainer - INFO - Epoch 30, Step 103489: Loss=4.8655, Acc=0.286, PPL=129.73
2025-09-21 01:35:18,228 - training.trainer - INFO - Epoch 30, Step 103589: Loss=5.7305, Acc=0.300, PPL=308.13
2025-09-21 01:35:26,229 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.2402, Acc=0.158, PPL=188.70
2025-09-21 01:35:34,109 - training.trainer - INFO - Epoch 30, Step 103789: Loss=6.1982, Acc=0.283, PPL=491.85
2025-09-21 01:35:41,931 - training.trainer - INFO - Epoch 30, Step 103889: Loss=6.2278, Acc=0.244, PPL=506.63
2025-09-21 01:35:49,783 - training.trainer - INFO - Epoch 30, Step 103989: Loss=4.6461, Acc=0.353, PPL=104.18
2025-09-21 01:35:57,690 - training.trainer - INFO - Epoch 30, Step 104089: Loss=6.3505, Acc=0.154, PPL=572.76
2025-09-21 01:36:05,677 - training.trainer - INFO - Epoch 30, Step 104189: Loss=6.0932, Acc=0.190, PPL=442.82
2025-09-21 01:36:13,774 - training.trainer - INFO - Epoch 30, Step 104289: Loss=4.1744, Acc=0.600, PPL=65.00
2025-09-21 01:36:21,936 - training.trainer - INFO - Epoch 30, Step 104389: Loss=5.2898, Acc=0.264, PPL=198.30
2025-09-21 01:36:29,983 - training.trainer - INFO - Epoch 30, Step 104489: Loss=6.2295, Acc=0.190, PPL=507.52
2025-09-21 01:36:38,003 - training.trainer - INFO - Epoch 30, Step 104589: Loss=6.5276, Acc=0.229, PPL=683.73
2025-09-21 01:36:45,891 - training.trainer - INFO - Epoch 30, Step 104689: Loss=6.1426, Acc=0.300, PPL=465.27
2025-09-21 01:36:53,959 - training.trainer - INFO - Epoch 30, Step 104789: Loss=6.1828, Acc=0.174, PPL=484.33
2025-09-21 01:37:11,714 - training.trainer - INFO - Epoch 31/100 completed in 280.33s - Train Loss: 5.7255, Train Acc: 0.244, Val Loss: 5.7502, Val Acc: 0.242
2025-09-21 01:37:20,185 - training.trainer - INFO - Epoch 31, Step 104972: Loss=6.2265, Acc=0.203, PPL=505.99
2025-09-21 01:37:28,222 - training.trainer - INFO - Epoch 31, Step 105072: Loss=5.2822, Acc=0.412, PPL=196.81
2025-09-21 01:37:36,097 - training.trainer - INFO - Epoch 31, Step 105172: Loss=5.4431, Acc=0.200, PPL=231.16
2025-09-21 01:37:43,873 - training.trainer - INFO - Epoch 31, Step 105272: Loss=5.2683, Acc=0.286, PPL=194.09
2025-09-21 01:37:51,726 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.6148, Acc=0.333, PPL=274.46
2025-09-21 01:37:59,577 - training.trainer - INFO - Epoch 31, Step 105472: Loss=5.7539, Acc=0.257, PPL=315.42
2025-09-21 01:38:07,481 - training.trainer - INFO - Epoch 31, Step 105572: Loss=5.7969, Acc=0.230, PPL=329.28
2025-09-21 01:38:15,267 - training.trainer - INFO - Epoch 31, Step 105672: Loss=6.2625, Acc=0.200, PPL=524.51
2025-09-21 01:38:23,120 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.8722, Acc=0.222, PPL=355.02
2025-09-21 01:38:30,946 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.9568, Acc=0.167, PPL=386.39
2025-09-21 01:38:39,121 - training.trainer - INFO - Epoch 31, Step 105972: Loss=5.9287, Acc=0.286, PPL=375.67
2025-09-21 01:38:47,050 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.3209, Acc=0.273, PPL=204.58
2025-09-21 01:38:54,898 - training.trainer - INFO - Epoch 31, Step 106172: Loss=6.6165, Acc=0.209, PPL=747.29
2025-09-21 01:39:02,837 - training.trainer - INFO - Epoch 31, Step 106272: Loss=5.4097, Acc=0.286, PPL=223.57
2025-09-21 01:39:10,719 - training.trainer - INFO - Epoch 31, Step 106372: Loss=5.7013, Acc=0.255, PPL=299.26
2025-09-21 01:39:18,746 - training.trainer - INFO - Epoch 31, Step 106472: Loss=5.1988, Acc=0.300, PPL=181.05
2025-09-21 01:39:26,946 - training.trainer - INFO - Epoch 31, Step 106572: Loss=4.8681, Acc=0.308, PPL=130.08
2025-09-21 01:39:35,094 - training.trainer - INFO - Epoch 31, Step 106672: Loss=6.6610, Acc=0.133, PPL=781.36
2025-09-21 01:39:42,958 - training.trainer - INFO - Epoch 31, Step 106772: Loss=6.1752, Acc=0.235, PPL=480.70
2025-09-21 01:39:50,844 - training.trainer - INFO - Epoch 31, Step 106872: Loss=4.6847, Acc=0.333, PPL=108.27
2025-09-21 01:39:58,780 - training.trainer - INFO - Epoch 31, Step 106972: Loss=6.6526, Acc=0.182, PPL=774.77
2025-09-21 01:40:06,753 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.8175, Acc=0.157, PPL=336.15
2025-09-21 01:40:14,685 - training.trainer - INFO - Epoch 31, Step 107172: Loss=5.2298, Acc=0.200, PPL=186.76
2025-09-21 01:40:22,732 - training.trainer - INFO - Epoch 31, Step 107272: Loss=5.6763, Acc=0.234, PPL=291.87
2025-09-21 01:40:30,661 - training.trainer - INFO - Epoch 31, Step 107372: Loss=5.3304, Acc=0.245, PPL=206.52
2025-09-21 01:40:38,594 - training.trainer - INFO - Epoch 31, Step 107472: Loss=5.4846, Acc=0.237, PPL=240.96
2025-09-21 01:40:46,454 - training.trainer - INFO - Epoch 31, Step 107572: Loss=5.7733, Acc=0.294, PPL=321.60
2025-09-21 01:40:54,392 - training.trainer - INFO - Epoch 31, Step 107672: Loss=6.4205, Acc=0.170, PPL=614.31
2025-09-21 01:41:02,226 - training.trainer - INFO - Epoch 31, Step 107772: Loss=6.2711, Acc=0.140, PPL=529.08
2025-09-21 01:41:10,168 - training.trainer - INFO - Epoch 31, Step 107872: Loss=6.0713, Acc=0.200, PPL=433.26
2025-09-21 01:41:18,128 - training.trainer - INFO - Epoch 31, Step 107972: Loss=6.0089, Acc=0.209, PPL=407.03
2025-09-21 01:41:25,992 - training.trainer - INFO - Epoch 31, Step 108072: Loss=5.7319, Acc=0.237, PPL=308.56
2025-09-21 01:41:33,874 - training.trainer - INFO - Epoch 31, Step 108172: Loss=5.2004, Acc=0.222, PPL=181.34
2025-09-21 01:41:50,564 - training.trainer - INFO - Epoch 32/100 completed in 278.85s - Train Loss: 5.7093, Train Acc: 0.247, Val Loss: 5.7477, Val Acc: 0.241
2025-09-21 01:41:58,467 - training.trainer - INFO - Epoch 32, Step 108355: Loss=5.9383, Acc=0.156, PPL=379.30
2025-09-21 01:42:06,383 - training.trainer - INFO - Epoch 32, Step 108455: Loss=5.2008, Acc=0.286, PPL=181.42
2025-09-21 01:42:14,290 - training.trainer - INFO - Epoch 32, Step 108555: Loss=6.8439, Acc=0.154, PPL=938.11
2025-09-21 01:42:22,185 - training.trainer - INFO - Epoch 32, Step 108655: Loss=6.1829, Acc=0.231, PPL=484.42
2025-09-21 01:42:30,175 - training.trainer - INFO - Epoch 32, Step 108755: Loss=6.0244, Acc=0.152, PPL=413.38
2025-09-21 01:42:38,248 - training.trainer - INFO - Epoch 32, Step 108855: Loss=5.6780, Acc=0.188, PPL=292.37
2025-09-21 01:42:46,120 - training.trainer - INFO - Epoch 32, Step 108955: Loss=5.7007, Acc=0.259, PPL=299.09
2025-09-21 01:42:53,954 - training.trainer - INFO - Epoch 32, Step 109055: Loss=6.1326, Acc=0.225, PPL=460.63
2025-09-21 01:43:01,734 - training.trainer - INFO - Epoch 32, Step 109155: Loss=6.6384, Acc=0.227, PPL=763.84
2025-09-21 01:43:09,605 - training.trainer - INFO - Epoch 32, Step 109255: Loss=6.3990, Acc=0.203, PPL=601.24
2025-09-21 01:43:17,728 - training.trainer - INFO - Epoch 32, Step 109355: Loss=6.0888, Acc=0.125, PPL=440.88
2025-09-21 01:43:25,992 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.1369, Acc=0.244, PPL=170.19
2025-09-21 01:43:33,979 - training.trainer - INFO - Epoch 32, Step 109555: Loss=6.3833, Acc=0.152, PPL=591.88
2025-09-21 01:43:42,166 - training.trainer - INFO - Epoch 32, Step 109655: Loss=6.3318, Acc=0.239, PPL=562.18
2025-09-21 01:43:50,353 - training.trainer - INFO - Epoch 32, Step 109755: Loss=5.9776, Acc=0.270, PPL=394.48
2025-09-21 01:43:58,347 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.4066, Acc=0.247, PPL=222.87
2025-09-21 01:44:06,446 - training.trainer - INFO - Epoch 32, Step 109955: Loss=4.0082, Acc=0.375, PPL=55.05
2025-09-21 01:44:14,562 - training.trainer - INFO - Epoch 32, Step 110055: Loss=5.6218, Acc=0.286, PPL=276.40
2025-09-21 01:44:22,599 - training.trainer - INFO - Epoch 32, Step 110155: Loss=6.2696, Acc=0.167, PPL=528.28
2025-09-21 01:44:30,544 - training.trainer - INFO - Epoch 32, Step 110255: Loss=6.2195, Acc=0.143, PPL=502.47
2025-09-21 01:44:38,496 - training.trainer - INFO - Epoch 32, Step 110355: Loss=6.0000, Acc=0.300, PPL=403.43
2025-09-21 01:44:46,544 - training.trainer - INFO - Epoch 32, Step 110455: Loss=5.6869, Acc=0.241, PPL=294.98
2025-09-21 01:44:54,623 - training.trainer - INFO - Epoch 32, Step 110555: Loss=5.7430, Acc=0.226, PPL=311.99
2025-09-21 01:45:02,680 - training.trainer - INFO - Epoch 32, Step 110655: Loss=7.0672, Acc=0.188, PPL=1172.91
2025-09-21 01:45:10,882 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.7837, Acc=0.196, PPL=324.96
2025-09-21 01:45:19,025 - training.trainer - INFO - Epoch 32, Step 110855: Loss=6.0348, Acc=0.250, PPL=417.71
2025-09-21 01:45:27,060 - training.trainer - INFO - Epoch 32, Step 110955: Loss=5.0775, Acc=0.293, PPL=160.37
2025-09-21 01:45:35,019 - training.trainer - INFO - Epoch 32, Step 111055: Loss=6.3426, Acc=0.200, PPL=568.27
2025-09-21 01:45:42,876 - training.trainer - INFO - Epoch 32, Step 111155: Loss=5.1931, Acc=0.304, PPL=180.03
2025-09-21 01:45:50,884 - training.trainer - INFO - Epoch 32, Step 111255: Loss=5.0806, Acc=0.375, PPL=160.87
2025-09-21 01:45:58,684 - training.trainer - INFO - Epoch 32, Step 111355: Loss=6.3189, Acc=0.237, PPL=554.96
2025-09-21 01:46:06,653 - training.trainer - INFO - Epoch 32, Step 111455: Loss=3.0886, Acc=0.645, PPL=21.95
2025-09-21 01:46:14,704 - training.trainer - INFO - Epoch 32, Step 111555: Loss=5.5890, Acc=0.308, PPL=267.48
2025-09-21 01:46:32,397 - training.trainer - INFO - Epoch 33/100 completed in 281.83s - Train Loss: 5.6985, Train Acc: 0.248, Val Loss: 5.7317, Val Acc: 0.241
2025-09-21 01:46:33,228 - training.trainer - INFO - New best model saved with validation loss: 5.7317
2025-09-21 01:46:33,228 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_33.pt
2025-09-21 01:46:41,434 - training.trainer - INFO - Epoch 33, Step 111738: Loss=5.4924, Acc=0.292, PPL=242.85
2025-09-21 01:46:49,500 - training.trainer - INFO - Epoch 33, Step 111838: Loss=5.9434, Acc=0.219, PPL=381.22
2025-09-21 01:46:57,460 - training.trainer - INFO - Epoch 33, Step 111938: Loss=3.3989, Acc=0.643, PPL=29.93
2025-09-21 01:47:05,345 - training.trainer - INFO - Epoch 33, Step 112038: Loss=5.4977, Acc=0.205, PPL=244.12
2025-09-21 01:47:13,603 - training.trainer - INFO - Epoch 33, Step 112138: Loss=5.1961, Acc=0.267, PPL=180.56
2025-09-21 01:47:21,806 - training.trainer - INFO - Epoch 33, Step 112238: Loss=4.5548, Acc=0.333, PPL=95.09
2025-09-21 01:47:29,992 - training.trainer - INFO - Epoch 33, Step 112338: Loss=6.2667, Acc=0.154, PPL=526.76
2025-09-21 01:47:37,849 - training.trainer - INFO - Epoch 33, Step 112438: Loss=5.9027, Acc=0.231, PPL=366.04
2025-09-21 01:47:45,766 - training.trainer - INFO - Epoch 33, Step 112538: Loss=5.5581, Acc=0.286, PPL=259.34
2025-09-21 01:47:53,671 - training.trainer - INFO - Epoch 33, Step 112638: Loss=5.8301, Acc=0.300, PPL=340.39
2025-09-21 01:48:01,557 - training.trainer - INFO - Epoch 33, Step 112738: Loss=5.4810, Acc=0.358, PPL=240.08
2025-09-21 01:48:09,506 - training.trainer - INFO - Epoch 33, Step 112838: Loss=6.3415, Acc=0.176, PPL=567.64
2025-09-21 01:48:17,623 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.5009, Acc=0.208, PPL=244.92
2025-09-21 01:48:25,672 - training.trainer - INFO - Epoch 33, Step 113038: Loss=5.6268, Acc=0.294, PPL=277.76
2025-09-21 01:48:33,745 - training.trainer - INFO - Epoch 33, Step 113138: Loss=4.3245, Acc=0.463, PPL=75.53
2025-09-21 01:48:41,626 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.5680, Acc=0.231, PPL=261.91
2025-09-21 01:48:49,728 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.4053, Acc=0.250, PPL=222.58
2025-09-21 01:48:57,661 - training.trainer - INFO - Epoch 33, Step 113438: Loss=6.4442, Acc=0.107, PPL=629.06
2025-09-21 01:49:05,609 - training.trainer - INFO - Epoch 33, Step 113538: Loss=5.4866, Acc=0.291, PPL=241.43
2025-09-21 01:49:13,498 - training.trainer - INFO - Epoch 33, Step 113638: Loss=5.6609, Acc=0.171, PPL=287.40
2025-09-21 01:49:21,402 - training.trainer - INFO - Epoch 33, Step 113738: Loss=5.5905, Acc=0.222, PPL=267.86
2025-09-21 01:49:29,341 - training.trainer - INFO - Epoch 33, Step 113838: Loss=5.9916, Acc=0.280, PPL=400.05
2025-09-21 01:49:37,220 - training.trainer - INFO - Epoch 33, Step 113938: Loss=6.6570, Acc=0.137, PPL=778.23
2025-09-21 01:49:45,087 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.9379, Acc=0.189, PPL=379.12
2025-09-21 01:49:52,937 - training.trainer - INFO - Epoch 33, Step 114138: Loss=6.2652, Acc=0.148, PPL=525.94
2025-09-21 01:50:00,870 - training.trainer - INFO - Epoch 33, Step 114238: Loss=5.1373, Acc=0.257, PPL=170.25
2025-09-21 01:50:08,919 - training.trainer - INFO - Epoch 33, Step 114338: Loss=5.2374, Acc=0.321, PPL=188.18
2025-09-21 01:50:17,027 - training.trainer - INFO - Epoch 33, Step 114438: Loss=4.7704, Acc=0.364, PPL=117.97
2025-09-21 01:50:24,930 - training.trainer - INFO - Epoch 33, Step 114538: Loss=5.8878, Acc=0.310, PPL=360.60
2025-09-21 01:50:32,898 - training.trainer - INFO - Epoch 33, Step 114638: Loss=6.1731, Acc=0.256, PPL=479.67
2025-09-21 01:50:41,044 - training.trainer - INFO - Epoch 33, Step 114738: Loss=4.8491, Acc=0.302, PPL=127.62
2025-09-21 01:50:49,165 - training.trainer - INFO - Epoch 33, Step 114838: Loss=5.6864, Acc=0.209, PPL=294.84
2025-09-21 01:50:57,254 - training.trainer - INFO - Epoch 33, Step 114938: Loss=6.0908, Acc=0.190, PPL=441.79
2025-09-21 01:51:14,816 - training.trainer - INFO - Epoch 34/100 completed in 281.59s - Train Loss: 5.6865, Train Acc: 0.250, Val Loss: 5.7382, Val Acc: 0.242
2025-09-21 01:51:23,138 - training.trainer - INFO - Epoch 34, Step 115121: Loss=5.2200, Acc=0.222, PPL=184.94
2025-09-21 01:51:31,220 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.6896, Acc=0.188, PPL=295.78
2025-09-21 01:51:39,242 - training.trainer - INFO - Epoch 34, Step 115321: Loss=4.4168, Acc=0.379, PPL=82.83
2025-09-21 01:51:47,168 - training.trainer - INFO - Epoch 34, Step 115421: Loss=4.9404, Acc=0.188, PPL=139.82
2025-09-21 01:51:55,155 - training.trainer - INFO - Epoch 34, Step 115521: Loss=5.8534, Acc=0.195, PPL=348.42
2025-09-21 01:52:03,325 - training.trainer - INFO - Epoch 34, Step 115621: Loss=5.8998, Acc=0.211, PPL=364.97
2025-09-21 01:52:11,251 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.9566, Acc=0.204, PPL=386.31
2025-09-21 01:52:19,211 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.8291, Acc=0.256, PPL=340.06
2025-09-21 01:52:27,124 - training.trainer - INFO - Epoch 34, Step 115921: Loss=5.4190, Acc=0.158, PPL=225.65
2025-09-21 01:52:35,081 - training.trainer - INFO - Epoch 34, Step 116021: Loss=5.4388, Acc=0.190, PPL=230.16
2025-09-21 01:52:42,996 - training.trainer - INFO - Epoch 34, Step 116121: Loss=6.1666, Acc=0.143, PPL=476.58
2025-09-21 01:52:50,911 - training.trainer - INFO - Epoch 34, Step 116221: Loss=5.6951, Acc=0.239, PPL=297.39
2025-09-21 01:52:58,845 - training.trainer - INFO - Epoch 34, Step 116321: Loss=6.3487, Acc=0.229, PPL=571.78
2025-09-21 01:53:07,021 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.7921, Acc=0.333, PPL=327.71
2025-09-21 01:53:14,938 - training.trainer - INFO - Epoch 34, Step 116521: Loss=5.8563, Acc=0.136, PPL=349.44
2025-09-21 01:53:22,781 - training.trainer - INFO - Epoch 34, Step 116621: Loss=6.0839, Acc=0.120, PPL=438.75
2025-09-21 01:53:30,618 - training.trainer - INFO - Epoch 34, Step 116721: Loss=6.2961, Acc=0.237, PPL=542.45
2025-09-21 01:53:38,465 - training.trainer - INFO - Epoch 34, Step 116821: Loss=5.5337, Acc=0.125, PPL=253.07
2025-09-21 01:53:46,321 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.4616, Acc=0.218, PPL=235.48
2025-09-21 01:53:54,182 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.2175, Acc=0.357, PPL=184.48
2025-09-21 01:54:01,994 - training.trainer - INFO - Epoch 34, Step 117121: Loss=4.1437, Acc=0.435, PPL=63.04
2025-09-21 01:54:09,843 - training.trainer - INFO - Epoch 34, Step 117221: Loss=5.5835, Acc=0.300, PPL=265.99
2025-09-21 01:54:17,719 - training.trainer - INFO - Epoch 34, Step 117321: Loss=5.8660, Acc=0.184, PPL=352.82
2025-09-21 01:54:25,628 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.6613, Acc=0.143, PPL=287.53
2025-09-21 01:54:33,577 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.6417, Acc=0.350, PPL=281.93
2025-09-21 01:54:41,398 - training.trainer - INFO - Epoch 34, Step 117621: Loss=6.2326, Acc=0.108, PPL=509.09
2025-09-21 01:54:49,290 - training.trainer - INFO - Epoch 34, Step 117721: Loss=6.2816, Acc=0.111, PPL=534.66
2025-09-21 01:54:57,162 - training.trainer - INFO - Epoch 34, Step 117821: Loss=5.9187, Acc=0.212, PPL=371.92
2025-09-21 01:55:05,016 - training.trainer - INFO - Epoch 34, Step 117921: Loss=5.9901, Acc=0.276, PPL=399.44
2025-09-21 01:55:12,902 - training.trainer - INFO - Epoch 34, Step 118021: Loss=6.2601, Acc=0.250, PPL=523.27
2025-09-21 01:55:20,740 - training.trainer - INFO - Epoch 34, Step 118121: Loss=6.0246, Acc=0.167, PPL=413.46
2025-09-21 01:55:28,659 - training.trainer - INFO - Epoch 34, Step 118221: Loss=6.0749, Acc=0.175, PPL=434.81
2025-09-21 01:55:36,566 - training.trainer - INFO - Epoch 34, Step 118321: Loss=5.7878, Acc=0.250, PPL=326.30
2025-09-21 01:55:53,742 - training.trainer - INFO - Epoch 35/100 completed in 278.92s - Train Loss: 5.6783, Train Acc: 0.252, Val Loss: 5.7269, Val Acc: 0.245
2025-09-21 01:55:54,080 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-21 01:55:54,836 - training.trainer - INFO - New best model saved with validation loss: 5.7269
2025-09-21 01:55:54,837 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-21 01:56:03,062 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.9544, Acc=0.267, PPL=385.45
2025-09-21 01:56:11,004 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.6516, Acc=0.295, PPL=284.74
2025-09-21 01:56:19,094 - training.trainer - INFO - Epoch 35, Step 118704: Loss=5.6658, Acc=0.273, PPL=288.81
2025-09-21 01:56:27,219 - training.trainer - INFO - Epoch 35, Step 118804: Loss=6.5085, Acc=0.170, PPL=670.80
2025-09-21 01:56:35,323 - training.trainer - INFO - Epoch 35, Step 118904: Loss=5.5592, Acc=0.233, PPL=259.62
2025-09-21 01:56:43,235 - training.trainer - INFO - Epoch 35, Step 119004: Loss=6.2261, Acc=0.182, PPL=505.76
2025-09-21 01:56:51,062 - training.trainer - INFO - Epoch 35, Step 119104: Loss=5.7495, Acc=0.333, PPL=314.03
2025-09-21 01:56:58,935 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.2975, Acc=0.233, PPL=199.83
2025-09-21 01:57:06,747 - training.trainer - INFO - Epoch 35, Step 119304: Loss=5.8161, Acc=0.400, PPL=335.67
2025-09-21 01:57:14,605 - training.trainer - INFO - Epoch 35, Step 119404: Loss=6.1940, Acc=0.214, PPL=489.80
2025-09-21 01:57:22,538 - training.trainer - INFO - Epoch 35, Step 119504: Loss=5.8236, Acc=0.263, PPL=338.20
2025-09-21 01:57:30,420 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.9403, Acc=0.222, PPL=380.05
2025-09-21 01:57:38,357 - training.trainer - INFO - Epoch 35, Step 119704: Loss=6.2166, Acc=0.150, PPL=500.98
2025-09-21 01:57:46,343 - training.trainer - INFO - Epoch 35, Step 119804: Loss=6.0384, Acc=0.235, PPL=419.22
2025-09-21 01:57:54,146 - training.trainer - INFO - Epoch 35, Step 119904: Loss=5.8592, Acc=0.222, PPL=350.43
2025-09-21 01:58:01,973 - training.trainer - INFO - Epoch 35, Step 120004: Loss=6.6307, Acc=0.186, PPL=758.02
2025-09-21 01:58:09,824 - training.trainer - INFO - Epoch 35, Step 120104: Loss=5.0368, Acc=0.324, PPL=153.97
2025-09-21 01:58:17,739 - training.trainer - INFO - Epoch 35, Step 120204: Loss=6.0965, Acc=0.200, PPL=444.30
2025-09-21 01:58:25,552 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.1021, Acc=0.333, PPL=164.37
2025-09-21 01:58:33,425 - training.trainer - INFO - Epoch 35, Step 120404: Loss=5.4685, Acc=0.359, PPL=237.11
2025-09-21 01:58:41,250 - training.trainer - INFO - Epoch 35, Step 120504: Loss=4.7368, Acc=0.296, PPL=114.07
2025-09-21 01:58:49,141 - training.trainer - INFO - Epoch 35, Step 120604: Loss=4.8605, Acc=0.296, PPL=129.08
2025-09-21 01:58:56,981 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.1377, Acc=0.286, PPL=170.33
2025-09-21 01:59:04,825 - training.trainer - INFO - Epoch 35, Step 120804: Loss=5.3172, Acc=0.324, PPL=203.81
2025-09-21 01:59:12,688 - training.trainer - INFO - Epoch 35, Step 120904: Loss=5.9040, Acc=0.263, PPL=366.50
2025-09-21 01:59:20,841 - training.trainer - INFO - Epoch 35, Step 121004: Loss=5.7283, Acc=0.267, PPL=307.46
2025-09-21 01:59:28,920 - training.trainer - INFO - Epoch 35, Step 121104: Loss=5.5595, Acc=0.241, PPL=259.69
2025-09-21 01:59:36,997 - training.trainer - INFO - Epoch 35, Step 121204: Loss=4.7722, Acc=0.417, PPL=118.18
2025-09-21 01:59:44,954 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.4452, Acc=0.263, PPL=231.65
2025-09-21 01:59:52,917 - training.trainer - INFO - Epoch 35, Step 121404: Loss=5.3621, Acc=0.324, PPL=213.17
2025-09-21 02:00:00,811 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.6605, Acc=0.231, PPL=287.29
2025-09-21 02:00:08,708 - training.trainer - INFO - Epoch 35, Step 121604: Loss=6.3565, Acc=0.154, PPL=576.20
2025-09-21 02:00:16,643 - training.trainer - INFO - Epoch 35, Step 121704: Loss=4.3226, Acc=0.421, PPL=75.39
2025-09-21 02:00:33,163 - training.trainer - INFO - Epoch 36/100 completed in 278.33s - Train Loss: 5.6653, Train Acc: 0.255, Val Loss: 5.7314, Val Acc: 0.246
2025-09-21 02:00:41,786 - training.trainer - INFO - Epoch 36, Step 121887: Loss=5.5900, Acc=0.250, PPL=267.75
2025-09-21 02:00:49,962 - training.trainer - INFO - Epoch 36, Step 121987: Loss=5.9862, Acc=0.226, PPL=397.91
2025-09-21 02:00:58,030 - training.trainer - INFO - Epoch 36, Step 122087: Loss=6.4939, Acc=0.163, PPL=661.09
2025-09-21 02:01:06,094 - training.trainer - INFO - Epoch 36, Step 122187: Loss=4.7584, Acc=0.370, PPL=116.56
2025-09-21 02:01:14,235 - training.trainer - INFO - Epoch 36, Step 122287: Loss=4.9348, Acc=0.300, PPL=139.04
2025-09-21 02:01:22,299 - training.trainer - INFO - Epoch 36, Step 122387: Loss=5.1916, Acc=0.293, PPL=179.76
2025-09-21 02:01:30,290 - training.trainer - INFO - Epoch 36, Step 122487: Loss=6.3336, Acc=0.245, PPL=563.17
2025-09-21 02:01:38,478 - training.trainer - INFO - Epoch 36, Step 122587: Loss=5.8358, Acc=0.222, PPL=342.35
2025-09-21 02:01:46,374 - training.trainer - INFO - Epoch 36, Step 122687: Loss=5.6880, Acc=0.200, PPL=295.31
2025-09-21 02:01:54,205 - training.trainer - INFO - Epoch 36, Step 122787: Loss=5.9920, Acc=0.074, PPL=400.21
2025-09-21 02:02:02,063 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.4812, Acc=0.200, PPL=240.13
2025-09-21 02:02:09,930 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.9045, Acc=0.231, PPL=366.70
2025-09-21 02:02:17,866 - training.trainer - INFO - Epoch 36, Step 123087: Loss=5.0480, Acc=0.421, PPL=155.71
2025-09-21 02:02:25,774 - training.trainer - INFO - Epoch 36, Step 123187: Loss=5.7303, Acc=0.238, PPL=308.06
2025-09-21 02:02:33,760 - training.trainer - INFO - Epoch 36, Step 123287: Loss=4.6546, Acc=0.348, PPL=105.07
2025-09-21 02:02:41,613 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.5448, Acc=0.203, PPL=255.89
2025-09-21 02:02:49,467 - training.trainer - INFO - Epoch 36, Step 123487: Loss=5.4378, Acc=0.233, PPL=229.93
2025-09-21 02:02:57,316 - training.trainer - INFO - Epoch 36, Step 123587: Loss=5.8898, Acc=0.150, PPL=361.32
2025-09-21 02:03:05,200 - training.trainer - INFO - Epoch 36, Step 123687: Loss=5.8190, Acc=0.268, PPL=336.64
2025-09-21 02:03:13,098 - training.trainer - INFO - Epoch 36, Step 123787: Loss=5.9011, Acc=0.184, PPL=365.45
2025-09-21 02:03:21,115 - training.trainer - INFO - Epoch 36, Step 123887: Loss=5.1470, Acc=0.154, PPL=171.91
2025-09-21 02:03:29,020 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.7952, Acc=0.250, PPL=328.71
2025-09-21 02:03:37,036 - training.trainer - INFO - Epoch 36, Step 124087: Loss=6.3964, Acc=0.189, PPL=599.70
2025-09-21 02:03:44,982 - training.trainer - INFO - Epoch 36, Step 124187: Loss=6.1773, Acc=0.214, PPL=481.69
2025-09-21 02:03:52,828 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.3882, Acc=0.231, PPL=218.81
2025-09-21 02:04:00,801 - training.trainer - INFO - Epoch 36, Step 124387: Loss=4.4048, Acc=0.333, PPL=81.84
2025-09-21 02:04:08,691 - training.trainer - INFO - Epoch 36, Step 124487: Loss=6.1481, Acc=0.179, PPL=467.83
2025-09-21 02:04:16,605 - training.trainer - INFO - Epoch 36, Step 124587: Loss=6.9132, Acc=0.177, PPL=1005.43
2025-09-21 02:04:24,545 - training.trainer - INFO - Epoch 36, Step 124687: Loss=5.6024, Acc=0.267, PPL=271.09
2025-09-21 02:04:32,419 - training.trainer - INFO - Epoch 36, Step 124787: Loss=6.1324, Acc=0.200, PPL=460.56
2025-09-21 02:04:40,343 - training.trainer - INFO - Epoch 36, Step 124887: Loss=6.2538, Acc=0.200, PPL=520.00
2025-09-21 02:04:48,238 - training.trainer - INFO - Epoch 36, Step 124987: Loss=5.8624, Acc=0.286, PPL=351.58
2025-09-21 02:04:56,108 - training.trainer - INFO - Epoch 36, Step 125087: Loss=5.6167, Acc=0.239, PPL=274.98
2025-09-21 02:05:12,723 - training.trainer - INFO - Epoch 37/100 completed in 279.56s - Train Loss: 5.6617, Train Acc: 0.254, Val Loss: 5.7201, Val Acc: 0.244
2025-09-21 02:05:13,412 - training.trainer - INFO - New best model saved with validation loss: 5.7201
2025-09-21 02:05:13,412 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_37.pt
2025-09-21 02:05:21,710 - training.trainer - INFO - Epoch 37, Step 125270: Loss=5.9298, Acc=0.194, PPL=376.08
2025-09-21 02:05:29,561 - training.trainer - INFO - Epoch 37, Step 125370: Loss=5.9454, Acc=0.267, PPL=381.98
2025-09-21 02:05:37,426 - training.trainer - INFO - Epoch 37, Step 125470: Loss=6.5491, Acc=0.158, PPL=698.62
2025-09-21 02:05:45,277 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.3023, Acc=0.236, PPL=200.80
2025-09-21 02:05:53,176 - training.trainer - INFO - Epoch 37, Step 125670: Loss=5.0709, Acc=0.389, PPL=159.32
2025-09-21 02:06:01,102 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.7065, Acc=0.313, PPL=300.82
2025-09-21 02:06:08,966 - training.trainer - INFO - Epoch 37, Step 125870: Loss=4.2746, Acc=0.357, PPL=71.85
2025-09-21 02:06:16,845 - training.trainer - INFO - Epoch 37, Step 125970: Loss=4.0258, Acc=0.412, PPL=56.02
2025-09-21 02:06:24,793 - training.trainer - INFO - Epoch 37, Step 126070: Loss=6.1261, Acc=0.180, PPL=457.63
2025-09-21 02:06:32,716 - training.trainer - INFO - Epoch 37, Step 126170: Loss=6.1472, Acc=0.148, PPL=467.41
2025-09-21 02:06:40,636 - training.trainer - INFO - Epoch 37, Step 126270: Loss=5.7019, Acc=0.186, PPL=299.44
2025-09-21 02:06:48,539 - training.trainer - INFO - Epoch 37, Step 126370: Loss=4.3609, Acc=0.333, PPL=78.33
2025-09-21 02:06:56,439 - training.trainer - INFO - Epoch 37, Step 126470: Loss=6.7108, Acc=0.075, PPL=821.20
2025-09-21 02:07:04,326 - training.trainer - INFO - Epoch 37, Step 126570: Loss=5.1862, Acc=0.270, PPL=178.80
2025-09-21 02:07:12,171 - training.trainer - INFO - Epoch 37, Step 126670: Loss=5.6925, Acc=0.276, PPL=296.63
2025-09-21 02:07:20,230 - training.trainer - INFO - Epoch 37, Step 126770: Loss=5.7369, Acc=0.269, PPL=310.09
2025-09-21 02:07:28,226 - training.trainer - INFO - Epoch 37, Step 126870: Loss=5.5707, Acc=0.268, PPL=262.63
2025-09-21 02:07:36,346 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.5737, Acc=0.214, PPL=263.40
2025-09-21 02:07:44,226 - training.trainer - INFO - Epoch 37, Step 127070: Loss=5.2680, Acc=0.278, PPL=194.04
2025-09-21 02:07:52,087 - training.trainer - INFO - Epoch 37, Step 127170: Loss=5.3240, Acc=0.462, PPL=205.21
2025-09-21 02:08:00,025 - training.trainer - INFO - Epoch 37, Step 127270: Loss=5.0229, Acc=0.351, PPL=151.84
2025-09-21 02:08:07,917 - training.trainer - INFO - Epoch 37, Step 127370: Loss=5.6551, Acc=0.241, PPL=285.76
2025-09-21 02:08:15,814 - training.trainer - INFO - Epoch 37, Step 127470: Loss=5.6991, Acc=0.241, PPL=298.61
2025-09-21 02:08:23,776 - training.trainer - INFO - Epoch 37, Step 127570: Loss=6.1817, Acc=0.167, PPL=483.83
2025-09-21 02:08:31,623 - training.trainer - INFO - Epoch 37, Step 127670: Loss=4.5683, Acc=0.393, PPL=96.38
2025-09-21 02:08:39,514 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.3947, Acc=0.289, PPL=220.23
2025-09-21 02:08:47,315 - training.trainer - INFO - Epoch 37, Step 127870: Loss=4.3807, Acc=0.393, PPL=79.89
2025-09-21 02:08:55,177 - training.trainer - INFO - Epoch 37, Step 127970: Loss=4.8271, Acc=0.333, PPL=124.85
2025-09-21 02:09:03,016 - training.trainer - INFO - Epoch 37, Step 128070: Loss=5.7835, Acc=0.264, PPL=324.89
2025-09-21 02:09:10,879 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.7844, Acc=0.250, PPL=325.19
2025-09-21 02:09:18,916 - training.trainer - INFO - Epoch 37, Step 128270: Loss=5.4582, Acc=0.281, PPL=234.68
2025-09-21 02:09:26,770 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.8052, Acc=0.316, PPL=332.03
2025-09-21 02:09:34,587 - training.trainer - INFO - Epoch 37, Step 128470: Loss=6.2005, Acc=0.206, PPL=493.01
2025-09-21 02:09:51,446 - training.trainer - INFO - Epoch 38/100 completed in 278.03s - Train Loss: 5.6493, Train Acc: 0.256, Val Loss: 5.7263, Val Acc: 0.245
2025-09-21 02:09:59,966 - training.trainer - INFO - Epoch 38, Step 128653: Loss=6.2469, Acc=0.250, PPL=516.43
2025-09-21 02:10:08,112 - training.trainer - INFO - Epoch 38, Step 128753: Loss=6.4432, Acc=0.182, PPL=628.44
2025-09-21 02:10:16,221 - training.trainer - INFO - Epoch 38, Step 128853: Loss=6.2747, Acc=0.176, PPL=530.95
2025-09-21 02:10:24,240 - training.trainer - INFO - Epoch 38, Step 128953: Loss=5.8315, Acc=0.224, PPL=340.86
2025-09-21 02:10:32,189 - training.trainer - INFO - Epoch 38, Step 129053: Loss=6.4384, Acc=0.234, PPL=625.40
2025-09-21 02:10:40,211 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.6281, Acc=0.244, PPL=278.15
2025-09-21 02:10:48,241 - training.trainer - INFO - Epoch 38, Step 129253: Loss=6.3205, Acc=0.196, PPL=555.84
2025-09-21 02:10:56,281 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.4134, Acc=0.222, PPL=224.40
2025-09-21 02:11:04,202 - training.trainer - INFO - Epoch 38, Step 129453: Loss=4.4737, Acc=0.409, PPL=87.68
2025-09-21 02:11:12,175 - training.trainer - INFO - Epoch 38, Step 129553: Loss=5.7013, Acc=0.244, PPL=299.25
2025-09-21 02:11:20,091 - training.trainer - INFO - Epoch 38, Step 129653: Loss=6.0607, Acc=0.222, PPL=428.67
2025-09-21 02:11:28,079 - training.trainer - INFO - Epoch 38, Step 129753: Loss=6.0885, Acc=0.190, PPL=440.77
2025-09-21 02:11:35,984 - training.trainer - INFO - Epoch 38, Step 129853: Loss=6.3512, Acc=0.200, PPL=573.16
2025-09-21 02:11:43,960 - training.trainer - INFO - Epoch 38, Step 129953: Loss=6.3092, Acc=0.211, PPL=549.59
2025-09-21 02:11:51,961 - training.trainer - INFO - Epoch 38, Step 130053: Loss=4.6272, Acc=0.333, PPL=102.23
2025-09-21 02:11:59,979 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.3905, Acc=0.297, PPL=219.32
2025-09-21 02:12:07,959 - training.trainer - INFO - Epoch 38, Step 130253: Loss=5.6176, Acc=0.279, PPL=275.24
2025-09-21 02:12:15,879 - training.trainer - INFO - Epoch 38, Step 130353: Loss=5.8006, Acc=0.286, PPL=330.51
2025-09-21 02:12:23,865 - training.trainer - INFO - Epoch 38, Step 130453: Loss=4.3611, Acc=0.476, PPL=78.34
2025-09-21 02:12:31,774 - training.trainer - INFO - Epoch 38, Step 130553: Loss=6.2152, Acc=0.130, PPL=500.28
2025-09-21 02:12:39,691 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.5543, Acc=0.312, PPL=258.36
2025-09-21 02:12:47,620 - training.trainer - INFO - Epoch 38, Step 130753: Loss=5.6380, Acc=0.225, PPL=280.91
2025-09-21 02:12:55,522 - training.trainer - INFO - Epoch 38, Step 130853: Loss=6.0369, Acc=0.286, PPL=418.61
2025-09-21 02:13:03,551 - training.trainer - INFO - Epoch 38, Step 130953: Loss=5.7173, Acc=0.222, PPL=304.10
2025-09-21 02:13:11,528 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.9963, Acc=0.125, PPL=401.95
2025-09-21 02:13:19,411 - training.trainer - INFO - Epoch 38, Step 131153: Loss=6.1657, Acc=0.186, PPL=476.14
2025-09-21 02:13:27,484 - training.trainer - INFO - Epoch 38, Step 131253: Loss=6.2875, Acc=0.203, PPL=537.80
2025-09-21 02:13:35,357 - training.trainer - INFO - Epoch 38, Step 131353: Loss=4.9736, Acc=0.385, PPL=144.54
2025-09-21 02:13:43,298 - training.trainer - INFO - Epoch 38, Step 131453: Loss=5.8204, Acc=0.208, PPL=337.12
2025-09-21 02:13:51,179 - training.trainer - INFO - Epoch 38, Step 131553: Loss=6.5356, Acc=0.189, PPL=689.22
2025-09-21 02:13:59,039 - training.trainer - INFO - Epoch 38, Step 131653: Loss=6.0651, Acc=0.241, PPL=430.57
2025-09-21 02:14:06,994 - training.trainer - INFO - Epoch 38, Step 131753: Loss=5.8970, Acc=0.170, PPL=363.94
2025-09-21 02:14:15,142 - training.trainer - INFO - Epoch 38, Step 131853: Loss=5.2233, Acc=0.250, PPL=185.54
2025-09-21 02:14:32,858 - training.trainer - INFO - Epoch 39/100 completed in 281.41s - Train Loss: 5.6381, Train Acc: 0.258, Val Loss: 5.7137, Val Acc: 0.246
2025-09-21 02:14:33,670 - training.trainer - INFO - New best model saved with validation loss: 5.7137
2025-09-21 02:14:33,670 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_39.pt
2025-09-21 02:14:42,118 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.7296, Acc=0.333, PPL=307.84
2025-09-21 02:14:50,349 - training.trainer - INFO - Epoch 39, Step 132136: Loss=6.2468, Acc=0.240, PPL=516.36
2025-09-21 02:14:58,451 - training.trainer - INFO - Epoch 39, Step 132236: Loss=5.1181, Acc=0.357, PPL=167.02
2025-09-21 02:15:06,395 - training.trainer - INFO - Epoch 39, Step 132336: Loss=3.9666, Acc=0.357, PPL=52.80
2025-09-21 02:15:14,359 - training.trainer - INFO - Epoch 39, Step 132436: Loss=6.1091, Acc=0.192, PPL=449.91
2025-09-21 02:15:22,307 - training.trainer - INFO - Epoch 39, Step 132536: Loss=5.3482, Acc=0.355, PPL=210.24
2025-09-21 02:15:30,247 - training.trainer - INFO - Epoch 39, Step 132636: Loss=5.0500, Acc=0.359, PPL=156.02
2025-09-21 02:15:38,168 - training.trainer - INFO - Epoch 39, Step 132736: Loss=4.7631, Acc=0.321, PPL=117.11
2025-09-21 02:15:46,055 - training.trainer - INFO - Epoch 39, Step 132836: Loss=6.2606, Acc=0.183, PPL=523.54
2025-09-21 02:15:53,974 - training.trainer - INFO - Epoch 39, Step 132936: Loss=6.1828, Acc=0.182, PPL=484.37
2025-09-21 02:16:01,848 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.5471, Acc=0.294, PPL=256.49
2025-09-21 02:16:09,760 - training.trainer - INFO - Epoch 39, Step 133136: Loss=5.7596, Acc=0.278, PPL=317.23
2025-09-21 02:16:17,641 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.8801, Acc=0.220, PPL=357.84
2025-09-21 02:16:25,697 - training.trainer - INFO - Epoch 39, Step 133336: Loss=4.8261, Acc=0.364, PPL=124.72
2025-09-21 02:16:33,628 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.8367, Acc=0.375, PPL=342.65
2025-09-21 02:16:41,538 - training.trainer - INFO - Epoch 39, Step 133536: Loss=5.5738, Acc=0.306, PPL=263.44
2025-09-21 02:16:49,460 - training.trainer - INFO - Epoch 39, Step 133636: Loss=5.3331, Acc=0.236, PPL=207.09
2025-09-21 02:16:57,387 - training.trainer - INFO - Epoch 39, Step 133736: Loss=6.5570, Acc=0.170, PPL=704.12
2025-09-21 02:17:05,330 - training.trainer - INFO - Epoch 39, Step 133836: Loss=4.7824, Acc=0.250, PPL=119.39
2025-09-21 02:17:13,221 - training.trainer - INFO - Epoch 39, Step 133936: Loss=4.6345, Acc=0.435, PPL=102.98
2025-09-21 02:17:21,121 - training.trainer - INFO - Epoch 39, Step 134036: Loss=5.7525, Acc=0.300, PPL=314.97
2025-09-21 02:17:29,000 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.8045, Acc=0.282, PPL=331.78
2025-09-21 02:17:36,877 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.7482, Acc=0.160, PPL=313.62
2025-09-21 02:17:44,833 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.7430, Acc=0.195, PPL=311.99
2025-09-21 02:17:52,711 - training.trainer - INFO - Epoch 39, Step 134436: Loss=5.9555, Acc=0.263, PPL=385.89
2025-09-21 02:18:00,592 - training.trainer - INFO - Epoch 39, Step 134536: Loss=6.0216, Acc=0.173, PPL=412.24
2025-09-21 02:18:08,497 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.5719, Acc=0.222, PPL=262.93
2025-09-21 02:18:16,387 - training.trainer - INFO - Epoch 39, Step 134736: Loss=4.2691, Acc=0.444, PPL=71.46
2025-09-21 02:18:24,244 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.4809, Acc=0.217, PPL=240.06
2025-09-21 02:18:32,095 - training.trainer - INFO - Epoch 39, Step 134936: Loss=5.9127, Acc=0.213, PPL=369.71
2025-09-21 02:18:39,971 - training.trainer - INFO - Epoch 39, Step 135036: Loss=5.9290, Acc=0.219, PPL=375.78
2025-09-21 02:18:47,834 - training.trainer - INFO - Epoch 39, Step 135136: Loss=3.8693, Acc=0.536, PPL=47.91
2025-09-21 02:18:55,688 - training.trainer - INFO - Epoch 39, Step 135236: Loss=6.2438, Acc=0.219, PPL=514.81
2025-09-21 02:19:12,431 - training.trainer - INFO - Epoch 40/100 completed in 278.76s - Train Loss: 5.6261, Train Acc: 0.260, Val Loss: 5.7009, Val Acc: 0.248
2025-09-21 02:19:12,837 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-21 02:19:13,588 - training.trainer - INFO - New best model saved with validation loss: 5.7009
2025-09-21 02:19:13,588 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-21 02:19:21,745 - training.trainer - INFO - Epoch 40, Step 135419: Loss=5.8960, Acc=0.256, PPL=363.58
2025-09-21 02:19:29,621 - training.trainer - INFO - Epoch 40, Step 135519: Loss=4.2892, Acc=0.455, PPL=72.91
2025-09-21 02:19:37,499 - training.trainer - INFO - Epoch 40, Step 135619: Loss=4.9530, Acc=0.435, PPL=141.59
2025-09-21 02:19:45,397 - training.trainer - INFO - Epoch 40, Step 135719: Loss=6.0651, Acc=0.211, PPL=430.55
2025-09-21 02:19:53,293 - training.trainer - INFO - Epoch 40, Step 135819: Loss=6.4690, Acc=0.167, PPL=644.87
2025-09-21 02:20:01,236 - training.trainer - INFO - Epoch 40, Step 135919: Loss=5.4327, Acc=0.306, PPL=228.77
2025-09-21 02:20:09,090 - training.trainer - INFO - Epoch 40, Step 136019: Loss=5.0966, Acc=0.333, PPL=163.47
2025-09-21 02:20:16,967 - training.trainer - INFO - Epoch 40, Step 136119: Loss=5.6736, Acc=0.273, PPL=291.07
2025-09-21 02:20:25,122 - training.trainer - INFO - Epoch 40, Step 136219: Loss=6.7329, Acc=0.053, PPL=839.59
2025-09-21 02:20:33,187 - training.trainer - INFO - Epoch 40, Step 136319: Loss=5.8048, Acc=0.211, PPL=331.90
2025-09-21 02:20:41,204 - training.trainer - INFO - Epoch 40, Step 136419: Loss=5.5329, Acc=0.229, PPL=252.89
2025-09-21 02:20:49,187 - training.trainer - INFO - Epoch 40, Step 136519: Loss=6.4299, Acc=0.182, PPL=620.12
2025-09-21 02:20:57,072 - training.trainer - INFO - Epoch 40, Step 136619: Loss=4.9476, Acc=0.222, PPL=140.84
2025-09-21 02:21:04,936 - training.trainer - INFO - Epoch 40, Step 136719: Loss=5.9698, Acc=0.161, PPL=391.44
2025-09-21 02:21:12,757 - training.trainer - INFO - Epoch 40, Step 136819: Loss=5.4826, Acc=0.196, PPL=240.48
2025-09-21 02:21:20,565 - training.trainer - INFO - Epoch 40, Step 136919: Loss=5.3278, Acc=0.273, PPL=205.98
2025-09-21 02:21:28,417 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.3126, Acc=0.241, PPL=202.88
2025-09-21 02:21:36,374 - training.trainer - INFO - Epoch 40, Step 137119: Loss=4.9947, Acc=0.308, PPL=147.64
2025-09-21 02:21:44,355 - training.trainer - INFO - Epoch 40, Step 137219: Loss=5.2705, Acc=0.300, PPL=194.51
2025-09-21 02:21:52,274 - training.trainer - INFO - Epoch 40, Step 137319: Loss=5.4165, Acc=0.267, PPL=225.09
2025-09-21 02:22:00,146 - training.trainer - INFO - Epoch 40, Step 137419: Loss=5.9985, Acc=0.227, PPL=402.83
2025-09-21 02:22:08,100 - training.trainer - INFO - Epoch 40, Step 137519: Loss=5.5785, Acc=0.293, PPL=264.67
2025-09-21 02:22:16,003 - training.trainer - INFO - Epoch 40, Step 137619: Loss=5.4660, Acc=0.215, PPL=236.50
2025-09-21 02:22:23,870 - training.trainer - INFO - Epoch 40, Step 137719: Loss=5.9956, Acc=0.231, PPL=401.68
2025-09-21 02:22:31,739 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.8370, Acc=0.207, PPL=342.75
2025-09-21 02:22:39,614 - training.trainer - INFO - Epoch 40, Step 137919: Loss=5.7829, Acc=0.239, PPL=324.70
2025-09-21 02:22:47,484 - training.trainer - INFO - Epoch 40, Step 138019: Loss=5.0787, Acc=0.371, PPL=160.57
2025-09-21 02:22:55,347 - training.trainer - INFO - Epoch 40, Step 138119: Loss=6.0463, Acc=0.200, PPL=422.56
2025-09-21 02:23:03,245 - training.trainer - INFO - Epoch 40, Step 138219: Loss=5.4071, Acc=0.176, PPL=222.98
2025-09-21 02:23:11,104 - training.trainer - INFO - Epoch 40, Step 138319: Loss=5.6281, Acc=0.269, PPL=278.14
2025-09-21 02:23:18,989 - training.trainer - INFO - Epoch 40, Step 138419: Loss=4.2770, Acc=0.405, PPL=72.02
2025-09-21 02:23:26,949 - training.trainer - INFO - Epoch 40, Step 138519: Loss=4.8221, Acc=0.300, PPL=124.22
2025-09-21 02:23:34,771 - training.trainer - INFO - Epoch 40, Step 138619: Loss=6.0558, Acc=0.182, PPL=426.57
2025-09-21 02:23:52,163 - training.trainer - INFO - Epoch 41/100 completed in 278.58s - Train Loss: 5.6114, Train Acc: 0.261, Val Loss: 5.7043, Val Acc: 0.246
2025-09-21 02:24:00,110 - training.trainer - INFO - Epoch 41, Step 138802: Loss=5.2168, Acc=0.294, PPL=184.34
2025-09-21 02:24:07,973 - training.trainer - INFO - Epoch 41, Step 138902: Loss=5.0334, Acc=0.250, PPL=153.45
2025-09-21 02:24:15,808 - training.trainer - INFO - Epoch 41, Step 139002: Loss=6.3983, Acc=0.206, PPL=600.83
2025-09-21 02:24:23,735 - training.trainer - INFO - Epoch 41, Step 139102: Loss=5.2949, Acc=0.341, PPL=199.32
2025-09-21 02:24:31,576 - training.trainer - INFO - Epoch 41, Step 139202: Loss=5.5534, Acc=0.292, PPL=258.11
2025-09-21 02:24:39,437 - training.trainer - INFO - Epoch 41, Step 139302: Loss=6.5260, Acc=0.176, PPL=682.69
2025-09-21 02:24:47,298 - training.trainer - INFO - Epoch 41, Step 139402: Loss=5.5183, Acc=0.268, PPL=249.21
2025-09-21 02:24:55,104 - training.trainer - INFO - Epoch 41, Step 139502: Loss=5.4582, Acc=0.200, PPL=234.68
2025-09-21 02:25:03,019 - training.trainer - INFO - Epoch 41, Step 139602: Loss=6.5953, Acc=0.226, PPL=731.68
2025-09-21 02:25:10,891 - training.trainer - INFO - Epoch 41, Step 139702: Loss=6.2817, Acc=0.121, PPL=534.70
2025-09-21 02:25:18,737 - training.trainer - INFO - Epoch 41, Step 139802: Loss=6.7577, Acc=0.156, PPL=860.67
2025-09-21 02:25:26,565 - training.trainer - INFO - Epoch 41, Step 139902: Loss=3.8444, Acc=0.529, PPL=46.73
2025-09-21 02:25:34,463 - training.trainer - INFO - Epoch 41, Step 140002: Loss=6.5090, Acc=0.294, PPL=671.18
2025-09-21 02:25:42,478 - training.trainer - INFO - Epoch 41, Step 140102: Loss=5.9910, Acc=0.306, PPL=399.82
2025-09-21 02:25:50,433 - training.trainer - INFO - Epoch 41, Step 140202: Loss=6.5069, Acc=0.135, PPL=669.72
2025-09-21 02:25:58,312 - training.trainer - INFO - Epoch 41, Step 140302: Loss=5.6915, Acc=0.190, PPL=296.33
2025-09-21 02:26:06,429 - training.trainer - INFO - Epoch 41, Step 140402: Loss=5.2282, Acc=0.333, PPL=186.45
2025-09-21 02:26:14,657 - training.trainer - INFO - Epoch 41, Step 140502: Loss=5.2399, Acc=0.375, PPL=188.65
2025-09-21 02:26:22,525 - training.trainer - INFO - Epoch 41, Step 140602: Loss=5.3711, Acc=0.205, PPL=215.10
2025-09-21 02:26:30,441 - training.trainer - INFO - Epoch 41, Step 140702: Loss=5.6779, Acc=0.292, PPL=292.34
2025-09-21 02:26:38,334 - training.trainer - INFO - Epoch 41, Step 140802: Loss=5.8401, Acc=0.195, PPL=343.80
2025-09-21 02:26:46,336 - training.trainer - INFO - Epoch 41, Step 140902: Loss=5.9053, Acc=0.259, PPL=367.00
2025-09-21 02:26:54,324 - training.trainer - INFO - Epoch 41, Step 141002: Loss=5.7722, Acc=0.194, PPL=321.25
2025-09-21 02:27:02,164 - training.trainer - INFO - Epoch 41, Step 141102: Loss=6.3284, Acc=0.225, PPL=560.25
2025-09-21 02:27:10,136 - training.trainer - INFO - Epoch 41, Step 141202: Loss=5.4385, Acc=0.299, PPL=230.09
2025-09-21 02:27:18,302 - training.trainer - INFO - Epoch 41, Step 141302: Loss=5.3163, Acc=0.273, PPL=203.62
2025-09-21 02:27:26,507 - training.trainer - INFO - Epoch 41, Step 141402: Loss=6.0528, Acc=0.171, PPL=425.32
2025-09-21 02:27:34,635 - training.trainer - INFO - Epoch 41, Step 141502: Loss=6.0286, Acc=0.176, PPL=415.15
2025-09-21 02:27:42,763 - training.trainer - INFO - Epoch 41, Step 141602: Loss=5.6775, Acc=0.250, PPL=292.21
2025-09-21 02:27:50,917 - training.trainer - INFO - Epoch 41, Step 141702: Loss=5.9505, Acc=0.250, PPL=383.95
2025-09-21 02:27:58,964 - training.trainer - INFO - Epoch 41, Step 141802: Loss=5.9311, Acc=0.219, PPL=376.58
2025-09-21 02:28:06,858 - training.trainer - INFO - Epoch 41, Step 141902: Loss=6.4688, Acc=0.229, PPL=644.73
2025-09-21 02:28:14,753 - training.trainer - INFO - Epoch 41, Step 142002: Loss=4.5915, Acc=0.333, PPL=98.64
2025-09-21 02:28:31,558 - training.trainer - INFO - Epoch 42/100 completed in 279.39s - Train Loss: 5.6035, Train Acc: 0.262, Val Loss: 5.7043, Val Acc: 0.242
2025-09-21 02:28:39,658 - training.trainer - INFO - Epoch 42, Step 142185: Loss=5.3224, Acc=0.190, PPL=204.87
2025-09-21 02:28:47,591 - training.trainer - INFO - Epoch 42, Step 142285: Loss=6.0350, Acc=0.182, PPL=417.79
2025-09-21 02:28:55,577 - training.trainer - INFO - Epoch 42, Step 142385: Loss=5.7540, Acc=0.192, PPL=315.45
2025-09-21 02:29:03,547 - training.trainer - INFO - Epoch 42, Step 142485: Loss=4.5732, Acc=0.375, PPL=96.85
2025-09-21 02:29:11,422 - training.trainer - INFO - Epoch 42, Step 142585: Loss=5.7450, Acc=0.241, PPL=312.61
2025-09-21 02:29:19,417 - training.trainer - INFO - Epoch 42, Step 142685: Loss=5.3734, Acc=0.342, PPL=215.60
2025-09-21 02:29:27,296 - training.trainer - INFO - Epoch 42, Step 142785: Loss=5.5141, Acc=0.216, PPL=248.16
2025-09-21 02:29:35,147 - training.trainer - INFO - Epoch 42, Step 142885: Loss=5.8609, Acc=0.213, PPL=351.04
2025-09-21 02:29:43,013 - training.trainer - INFO - Epoch 42, Step 142985: Loss=5.4207, Acc=0.270, PPL=226.05
2025-09-21 02:29:50,965 - training.trainer - INFO - Epoch 42, Step 143085: Loss=5.9490, Acc=0.256, PPL=383.37
2025-09-21 02:29:58,826 - training.trainer - INFO - Epoch 42, Step 143185: Loss=5.8807, Acc=0.174, PPL=358.06
2025-09-21 02:30:06,696 - training.trainer - INFO - Epoch 42, Step 143285: Loss=4.6984, Acc=0.343, PPL=109.77
2025-09-21 02:30:14,614 - training.trainer - INFO - Epoch 42, Step 143385: Loss=3.9245, Acc=0.484, PPL=50.63
2025-09-21 02:30:22,595 - training.trainer - INFO - Epoch 42, Step 143485: Loss=6.2751, Acc=0.189, PPL=531.17
2025-09-21 02:30:30,829 - training.trainer - INFO - Epoch 42, Step 143585: Loss=5.5156, Acc=0.211, PPL=248.53
2025-09-21 02:30:38,799 - training.trainer - INFO - Epoch 42, Step 143685: Loss=3.3613, Acc=0.478, PPL=28.83
2025-09-21 02:30:46,787 - training.trainer - INFO - Epoch 42, Step 143785: Loss=5.5310, Acc=0.294, PPL=252.40
2025-09-21 02:30:54,802 - training.trainer - INFO - Epoch 42, Step 143885: Loss=5.6361, Acc=0.283, PPL=280.36
2025-09-21 02:31:03,045 - training.trainer - INFO - Epoch 42, Step 143985: Loss=5.6219, Acc=0.219, PPL=276.40
2025-09-21 02:31:11,170 - training.trainer - INFO - Epoch 42, Step 144085: Loss=6.0725, Acc=0.191, PPL=433.74
2025-09-21 02:31:19,164 - training.trainer - INFO - Epoch 42, Step 144185: Loss=5.3095, Acc=0.191, PPL=202.24
2025-09-21 02:31:27,186 - training.trainer - INFO - Epoch 42, Step 144285: Loss=5.4979, Acc=0.211, PPL=244.18
2025-09-21 02:31:35,299 - training.trainer - INFO - Epoch 42, Step 144385: Loss=6.0135, Acc=0.197, PPL=408.92
2025-09-21 02:31:43,420 - training.trainer - INFO - Epoch 42, Step 144485: Loss=5.6058, Acc=0.250, PPL=272.00
2025-09-21 02:31:51,555 - training.trainer - INFO - Epoch 42, Step 144585: Loss=5.3106, Acc=0.346, PPL=202.48
2025-09-21 02:31:59,632 - training.trainer - INFO - Epoch 42, Step 144685: Loss=4.9436, Acc=0.241, PPL=140.28
2025-09-21 02:32:07,808 - training.trainer - INFO - Epoch 42, Step 144785: Loss=5.1450, Acc=0.348, PPL=171.56
2025-09-21 02:32:15,973 - training.trainer - INFO - Epoch 42, Step 144885: Loss=5.3703, Acc=0.311, PPL=214.93
2025-09-21 02:32:24,156 - training.trainer - INFO - Epoch 42, Step 144985: Loss=5.7324, Acc=0.250, PPL=308.71
2025-09-21 02:32:32,252 - training.trainer - INFO - Epoch 42, Step 145085: Loss=6.4356, Acc=0.240, PPL=623.65
2025-09-21 02:32:40,363 - training.trainer - INFO - Epoch 42, Step 145185: Loss=5.8190, Acc=0.292, PPL=336.63
2025-09-21 02:32:48,327 - training.trainer - INFO - Epoch 42, Step 145285: Loss=5.9773, Acc=0.235, PPL=394.39
2025-09-21 02:32:56,282 - training.trainer - INFO - Epoch 42, Step 145385: Loss=5.7601, Acc=0.219, PPL=317.37
2025-09-21 02:33:13,942 - training.trainer - INFO - Epoch 43/100 completed in 282.38s - Train Loss: 5.5971, Train Acc: 0.263, Val Loss: 5.7008, Val Acc: 0.250
2025-09-21 02:33:14,529 - training.trainer - INFO - New best model saved with validation loss: 5.7008
2025-09-21 02:33:14,529 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_43.pt
2025-09-21 02:33:22,982 - training.trainer - INFO - Epoch 43, Step 145568: Loss=5.4906, Acc=0.233, PPL=242.40
2025-09-21 02:33:31,057 - training.trainer - INFO - Epoch 43, Step 145668: Loss=6.0390, Acc=0.194, PPL=419.47
2025-09-21 02:33:39,219 - training.trainer - INFO - Epoch 43, Step 145768: Loss=5.1372, Acc=0.185, PPL=170.23
2025-09-21 02:33:47,267 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.7980, Acc=0.242, PPL=329.63
2025-09-21 02:33:55,198 - training.trainer - INFO - Epoch 43, Step 145968: Loss=5.2740, Acc=0.312, PPL=195.20
2025-09-21 02:34:03,146 - training.trainer - INFO - Epoch 43, Step 146068: Loss=5.8414, Acc=0.214, PPL=344.27
2025-09-21 02:34:11,130 - training.trainer - INFO - Epoch 43, Step 146168: Loss=6.0305, Acc=0.286, PPL=415.94
2025-09-21 02:34:19,120 - training.trainer - INFO - Epoch 43, Step 146268: Loss=6.4349, Acc=0.204, PPL=623.23
2025-09-21 02:34:27,154 - training.trainer - INFO - Epoch 43, Step 146368: Loss=4.6860, Acc=0.389, PPL=108.42
2025-09-21 02:34:35,107 - training.trainer - INFO - Epoch 43, Step 146468: Loss=4.3669, Acc=0.524, PPL=78.80
2025-09-21 02:34:43,110 - training.trainer - INFO - Epoch 43, Step 146568: Loss=6.0872, Acc=0.213, PPL=440.20
2025-09-21 02:34:51,111 - training.trainer - INFO - Epoch 43, Step 146668: Loss=4.9854, Acc=0.355, PPL=146.27
2025-09-21 02:34:59,064 - training.trainer - INFO - Epoch 43, Step 146768: Loss=4.9637, Acc=0.286, PPL=143.12
2025-09-21 02:35:07,014 - training.trainer - INFO - Epoch 43, Step 146868: Loss=5.2195, Acc=0.227, PPL=184.84
2025-09-21 02:35:15,240 - training.trainer - INFO - Epoch 43, Step 146968: Loss=5.7421, Acc=0.263, PPL=311.71
2025-09-21 02:35:23,379 - training.trainer - INFO - Epoch 43, Step 147068: Loss=6.1109, Acc=0.306, PPL=450.74
2025-09-21 02:35:31,565 - training.trainer - INFO - Epoch 43, Step 147168: Loss=5.9155, Acc=0.250, PPL=370.73
2025-09-21 02:35:39,712 - training.trainer - INFO - Epoch 43, Step 147268: Loss=6.0841, Acc=0.250, PPL=438.81
2025-09-21 02:35:47,839 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.1254, Acc=0.324, PPL=168.24
2025-09-21 02:35:55,893 - training.trainer - INFO - Epoch 43, Step 147468: Loss=6.2278, Acc=0.265, PPL=506.65
2025-09-21 02:36:03,807 - training.trainer - INFO - Epoch 43, Step 147568: Loss=5.4736, Acc=0.226, PPL=238.32
2025-09-21 02:36:11,763 - training.trainer - INFO - Epoch 43, Step 147668: Loss=5.8003, Acc=0.241, PPL=330.38
2025-09-21 02:36:19,712 - training.trainer - INFO - Epoch 43, Step 147768: Loss=5.8139, Acc=0.219, PPL=334.93
2025-09-21 02:36:27,648 - training.trainer - INFO - Epoch 43, Step 147868: Loss=5.1927, Acc=0.400, PPL=179.96
2025-09-21 02:36:35,639 - training.trainer - INFO - Epoch 43, Step 147968: Loss=5.5097, Acc=0.283, PPL=247.09
2025-09-21 02:36:43,869 - training.trainer - INFO - Epoch 43, Step 148068: Loss=5.6361, Acc=0.303, PPL=280.37
2025-09-21 02:36:51,999 - training.trainer - INFO - Epoch 43, Step 148168: Loss=5.5421, Acc=0.259, PPL=255.21
2025-09-21 02:37:00,193 - training.trainer - INFO - Epoch 43, Step 148268: Loss=5.7556, Acc=0.234, PPL=315.95
2025-09-21 02:37:08,311 - training.trainer - INFO - Epoch 43, Step 148368: Loss=5.0666, Acc=0.320, PPL=158.63
2025-09-21 02:37:16,292 - training.trainer - INFO - Epoch 43, Step 148468: Loss=6.6451, Acc=0.229, PPL=769.03
2025-09-21 02:37:24,257 - training.trainer - INFO - Epoch 43, Step 148568: Loss=5.3995, Acc=0.225, PPL=221.30
2025-09-21 02:37:32,265 - training.trainer - INFO - Epoch 43, Step 148668: Loss=6.3607, Acc=0.240, PPL=578.65
2025-09-21 02:37:40,280 - training.trainer - INFO - Epoch 43, Step 148768: Loss=5.6988, Acc=0.259, PPL=298.52
2025-09-21 02:37:57,202 - training.trainer - INFO - Epoch 44/100 completed in 282.67s - Train Loss: 5.5853, Train Acc: 0.266, Val Loss: 5.7004, Val Acc: 0.248
2025-09-21 02:37:57,941 - training.trainer - INFO - New best model saved with validation loss: 5.7004
2025-09-21 02:37:57,941 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_44.pt
2025-09-21 02:38:06,261 - training.trainer - INFO - Epoch 44, Step 148951: Loss=5.7730, Acc=0.172, PPL=321.51
2025-09-21 02:38:14,249 - training.trainer - INFO - Epoch 44, Step 149051: Loss=5.7666, Acc=0.224, PPL=319.46
2025-09-21 02:38:22,293 - training.trainer - INFO - Epoch 44, Step 149151: Loss=6.2381, Acc=0.161, PPL=511.88
2025-09-21 02:38:30,306 - training.trainer - INFO - Epoch 44, Step 149251: Loss=4.0124, Acc=0.464, PPL=55.28
2025-09-21 02:38:38,433 - training.trainer - INFO - Epoch 44, Step 149351: Loss=5.8056, Acc=0.200, PPL=332.15
2025-09-21 02:38:46,552 - training.trainer - INFO - Epoch 44, Step 149451: Loss=5.1581, Acc=0.312, PPL=173.84
2025-09-21 02:38:54,675 - training.trainer - INFO - Epoch 44, Step 149551: Loss=5.2186, Acc=0.311, PPL=184.67
2025-09-21 02:39:02,717 - training.trainer - INFO - Epoch 44, Step 149651: Loss=4.5687, Acc=0.391, PPL=96.42
2025-09-21 02:39:10,844 - training.trainer - INFO - Epoch 44, Step 149751: Loss=5.6420, Acc=0.222, PPL=282.02
2025-09-21 02:39:18,909 - training.trainer - INFO - Epoch 44, Step 149851: Loss=6.0128, Acc=0.156, PPL=408.63
2025-09-21 02:39:26,985 - training.trainer - INFO - Epoch 44, Step 149951: Loss=6.4986, Acc=0.206, PPL=664.19
2025-09-21 02:39:35,013 - training.trainer - INFO - Epoch 44, Step 150051: Loss=6.5335, Acc=0.138, PPL=687.78
2025-09-21 02:39:43,097 - training.trainer - INFO - Epoch 44, Step 150151: Loss=5.8539, Acc=0.231, PPL=348.58
2025-09-21 02:39:51,216 - training.trainer - INFO - Epoch 44, Step 150251: Loss=5.6056, Acc=0.222, PPL=271.95
2025-09-21 02:39:59,314 - training.trainer - INFO - Epoch 44, Step 150351: Loss=5.9941, Acc=0.208, PPL=401.05
2025-09-21 02:40:07,357 - training.trainer - INFO - Epoch 44, Step 150451: Loss=5.0108, Acc=0.233, PPL=150.02
2025-09-21 02:40:15,442 - training.trainer - INFO - Epoch 44, Step 150551: Loss=5.7267, Acc=0.154, PPL=306.96
2025-09-21 02:40:23,581 - training.trainer - INFO - Epoch 44, Step 150651: Loss=5.5071, Acc=0.318, PPL=246.43
2025-09-21 02:40:31,734 - training.trainer - INFO - Epoch 44, Step 150751: Loss=5.9091, Acc=0.197, PPL=368.36
2025-09-21 02:40:39,817 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.1475, Acc=0.368, PPL=172.00
2025-09-21 02:40:47,785 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.7786, Acc=0.333, PPL=323.30
2025-09-21 02:40:55,697 - training.trainer - INFO - Epoch 44, Step 151051: Loss=5.5032, Acc=0.311, PPL=245.48
2025-09-21 02:41:03,665 - training.trainer - INFO - Epoch 44, Step 151151: Loss=6.0842, Acc=0.232, PPL=438.89
2025-09-21 02:41:11,632 - training.trainer - INFO - Epoch 44, Step 151251: Loss=5.3154, Acc=0.281, PPL=203.45
2025-09-21 02:41:19,639 - training.trainer - INFO - Epoch 44, Step 151351: Loss=4.4753, Acc=0.300, PPL=87.82
2025-09-21 02:41:27,635 - training.trainer - INFO - Epoch 44, Step 151451: Loss=4.7672, Acc=0.391, PPL=117.59
2025-09-21 02:41:35,558 - training.trainer - INFO - Epoch 44, Step 151551: Loss=5.5913, Acc=0.186, PPL=268.09
2025-09-21 02:41:43,370 - training.trainer - INFO - Epoch 44, Step 151651: Loss=6.1689, Acc=0.180, PPL=477.66
2025-09-21 02:41:51,254 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.3702, Acc=0.256, PPL=214.90
2025-09-21 02:41:59,343 - training.trainer - INFO - Epoch 44, Step 151851: Loss=5.3516, Acc=0.268, PPL=210.96
2025-09-21 02:42:07,541 - training.trainer - INFO - Epoch 44, Step 151951: Loss=5.2225, Acc=0.378, PPL=185.39
2025-09-21 02:42:15,520 - training.trainer - INFO - Epoch 44, Step 152051: Loss=6.2550, Acc=0.160, PPL=520.59
2025-09-21 02:42:23,491 - training.trainer - INFO - Epoch 44, Step 152151: Loss=6.3682, Acc=0.277, PPL=583.00
2025-09-21 02:42:40,949 - training.trainer - INFO - Epoch 45/100 completed in 283.01s - Train Loss: 5.5821, Train Acc: 0.266, Val Loss: 5.7061, Val Acc: 0.250
2025-09-21 02:42:41,330 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-21 02:42:49,761 - training.trainer - INFO - Epoch 45, Step 152334: Loss=5.6341, Acc=0.265, PPL=279.79
2025-09-21 02:42:57,639 - training.trainer - INFO - Epoch 45, Step 152434: Loss=4.9410, Acc=0.294, PPL=139.90
2025-09-21 02:43:05,545 - training.trainer - INFO - Epoch 45, Step 152534: Loss=5.4459, Acc=0.240, PPL=231.81
2025-09-21 02:43:13,387 - training.trainer - INFO - Epoch 45, Step 152634: Loss=5.9600, Acc=0.233, PPL=387.61
2025-09-21 02:43:21,236 - training.trainer - INFO - Epoch 45, Step 152734: Loss=5.5556, Acc=0.241, PPL=258.67
2025-09-21 02:43:29,107 - training.trainer - INFO - Epoch 45, Step 152834: Loss=5.2419, Acc=0.250, PPL=189.03
2025-09-21 02:43:36,927 - training.trainer - INFO - Epoch 45, Step 152934: Loss=4.7280, Acc=0.372, PPL=113.07
2025-09-21 02:43:44,840 - training.trainer - INFO - Epoch 45, Step 153034: Loss=6.3489, Acc=0.188, PPL=571.84
2025-09-21 02:43:52,691 - training.trainer - INFO - Epoch 45, Step 153134: Loss=5.7156, Acc=0.233, PPL=303.58
2025-09-21 02:44:00,559 - training.trainer - INFO - Epoch 45, Step 153234: Loss=5.8502, Acc=0.250, PPL=347.31
2025-09-21 02:44:08,374 - training.trainer - INFO - Epoch 45, Step 153334: Loss=5.6816, Acc=0.111, PPL=293.43
2025-09-21 02:44:16,204 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.9868, Acc=0.220, PPL=398.14
2025-09-21 02:44:24,162 - training.trainer - INFO - Epoch 45, Step 153534: Loss=6.2246, Acc=0.241, PPL=505.01
2025-09-21 02:44:32,060 - training.trainer - INFO - Epoch 45, Step 153634: Loss=6.2065, Acc=0.111, PPL=495.98
2025-09-21 02:44:39,880 - training.trainer - INFO - Epoch 45, Step 153734: Loss=5.0522, Acc=0.185, PPL=156.37
2025-09-21 02:44:47,747 - training.trainer - INFO - Epoch 45, Step 153834: Loss=6.1165, Acc=0.205, PPL=453.27
2025-09-21 02:44:55,580 - training.trainer - INFO - Epoch 45, Step 153934: Loss=5.3081, Acc=0.258, PPL=201.96
2025-09-21 02:45:03,498 - training.trainer - INFO - Epoch 45, Step 154034: Loss=5.7052, Acc=0.278, PPL=300.43
2025-09-21 02:45:11,354 - training.trainer - INFO - Epoch 45, Step 154134: Loss=5.9563, Acc=0.238, PPL=386.19
2025-09-21 02:45:19,218 - training.trainer - INFO - Epoch 45, Step 154234: Loss=4.9301, Acc=0.364, PPL=138.40
2025-09-21 02:45:27,045 - training.trainer - INFO - Epoch 45, Step 154334: Loss=6.2227, Acc=0.188, PPL=504.08
2025-09-21 02:45:34,860 - training.trainer - INFO - Epoch 45, Step 154434: Loss=5.5970, Acc=0.224, PPL=269.63
2025-09-21 02:45:42,694 - training.trainer - INFO - Epoch 45, Step 154534: Loss=6.1702, Acc=0.235, PPL=478.30
2025-09-21 02:45:50,513 - training.trainer - INFO - Epoch 45, Step 154634: Loss=5.5668, Acc=0.206, PPL=261.59
2025-09-21 02:45:58,361 - training.trainer - INFO - Epoch 45, Step 154734: Loss=5.4485, Acc=0.324, PPL=232.41
2025-09-21 02:46:06,275 - training.trainer - INFO - Epoch 45, Step 154834: Loss=5.3673, Acc=0.250, PPL=214.28
2025-09-21 02:46:14,234 - training.trainer - INFO - Epoch 45, Step 154934: Loss=5.1566, Acc=0.364, PPL=173.57
2025-09-21 02:46:22,083 - training.trainer - INFO - Epoch 45, Step 155034: Loss=5.4208, Acc=0.283, PPL=226.06
2025-09-21 02:46:29,919 - training.trainer - INFO - Epoch 45, Step 155134: Loss=5.7608, Acc=0.174, PPL=317.61
2025-09-21 02:46:37,767 - training.trainer - INFO - Epoch 45, Step 155234: Loss=5.4263, Acc=0.323, PPL=227.32
2025-09-21 02:46:45,568 - training.trainer - INFO - Epoch 45, Step 155334: Loss=4.9241, Acc=0.333, PPL=137.56
2025-09-21 02:46:53,375 - training.trainer - INFO - Epoch 45, Step 155434: Loss=5.0396, Acc=0.345, PPL=154.41
2025-09-21 02:47:01,196 - training.trainer - INFO - Epoch 45, Step 155534: Loss=5.7974, Acc=0.176, PPL=329.45
2025-09-21 02:47:18,916 - training.trainer - INFO - Epoch 46/100 completed in 277.58s - Train Loss: 5.5722, Train Acc: 0.266, Val Loss: 5.6970, Val Acc: 0.250
2025-09-21 02:47:19,696 - training.trainer - INFO - New best model saved with validation loss: 5.6970
2025-09-21 02:47:19,697 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_46.pt
2025-09-21 02:47:28,265 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.5811, Acc=0.310, PPL=265.35
2025-09-21 02:47:36,443 - training.trainer - INFO - Epoch 46, Step 155817: Loss=5.5443, Acc=0.191, PPL=255.77
2025-09-21 02:47:44,501 - training.trainer - INFO - Epoch 46, Step 155917: Loss=6.3270, Acc=0.219, PPL=559.47
2025-09-21 02:47:52,497 - training.trainer - INFO - Epoch 46, Step 156017: Loss=6.2208, Acc=0.159, PPL=503.08
2025-09-21 02:48:00,652 - training.trainer - INFO - Epoch 46, Step 156117: Loss=5.0546, Acc=0.355, PPL=156.74
2025-09-21 02:48:08,774 - training.trainer - INFO - Epoch 46, Step 156217: Loss=5.2114, Acc=0.365, PPL=183.34
2025-09-21 02:48:16,863 - training.trainer - INFO - Epoch 46, Step 156317: Loss=6.0494, Acc=0.235, PPL=423.86
2025-09-21 02:48:25,017 - training.trainer - INFO - Epoch 46, Step 156417: Loss=5.8725, Acc=0.224, PPL=355.12
2025-09-21 02:48:33,111 - training.trainer - INFO - Epoch 46, Step 156517: Loss=5.6465, Acc=0.458, PPL=283.30
2025-09-21 02:48:41,253 - training.trainer - INFO - Epoch 46, Step 156617: Loss=5.3207, Acc=0.259, PPL=204.52
2025-09-21 02:48:49,473 - training.trainer - INFO - Epoch 46, Step 156717: Loss=4.4547, Acc=0.368, PPL=86.03
2025-09-21 02:48:57,551 - training.trainer - INFO - Epoch 46, Step 156817: Loss=5.0413, Acc=0.319, PPL=154.66
2025-09-21 02:49:05,571 - training.trainer - INFO - Epoch 46, Step 156917: Loss=6.4055, Acc=0.111, PPL=605.16
2025-09-21 02:49:13,573 - training.trainer - INFO - Epoch 46, Step 157017: Loss=5.8327, Acc=0.250, PPL=341.28
2025-09-21 02:49:21,740 - training.trainer - INFO - Epoch 46, Step 157117: Loss=5.4116, Acc=0.212, PPL=223.99
2025-09-21 02:49:29,916 - training.trainer - INFO - Epoch 46, Step 157217: Loss=4.8218, Acc=0.296, PPL=124.19
2025-09-21 02:49:38,081 - training.trainer - INFO - Epoch 46, Step 157317: Loss=6.2077, Acc=0.175, PPL=496.55
2025-09-21 02:49:46,230 - training.trainer - INFO - Epoch 46, Step 157417: Loss=6.4247, Acc=0.128, PPL=616.93
2025-09-21 02:49:54,267 - training.trainer - INFO - Epoch 46, Step 157517: Loss=5.8609, Acc=0.196, PPL=351.04
2025-09-21 02:50:02,303 - training.trainer - INFO - Epoch 46, Step 157617: Loss=4.7053, Acc=0.385, PPL=110.53
2025-09-21 02:50:10,401 - training.trainer - INFO - Epoch 46, Step 157717: Loss=5.6000, Acc=0.257, PPL=270.43
2025-09-21 02:50:18,594 - training.trainer - INFO - Epoch 46, Step 157817: Loss=5.6094, Acc=0.375, PPL=272.98
2025-09-21 02:50:26,726 - training.trainer - INFO - Epoch 46, Step 157917: Loss=5.3015, Acc=0.250, PPL=200.63
2025-09-21 02:50:34,794 - training.trainer - INFO - Epoch 46, Step 158017: Loss=6.1779, Acc=0.200, PPL=482.00
2025-09-21 02:50:42,913 - training.trainer - INFO - Epoch 46, Step 158117: Loss=5.2323, Acc=0.286, PPL=187.22
2025-09-21 02:50:51,002 - training.trainer - INFO - Epoch 46, Step 158217: Loss=5.8048, Acc=0.308, PPL=331.88
2025-09-21 02:50:59,090 - training.trainer - INFO - Epoch 46, Step 158317: Loss=5.9538, Acc=0.273, PPL=385.20
2025-09-21 02:51:07,092 - training.trainer - INFO - Epoch 46, Step 158417: Loss=5.3618, Acc=0.240, PPL=213.10
2025-09-21 02:51:15,035 - training.trainer - INFO - Epoch 46, Step 158517: Loss=4.0972, Acc=0.500, PPL=60.17
2025-09-21 02:51:22,993 - training.trainer - INFO - Epoch 46, Step 158617: Loss=5.5527, Acc=0.312, PPL=257.93
2025-09-21 02:51:30,906 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.7465, Acc=0.222, PPL=313.10
2025-09-21 02:51:38,842 - training.trainer - INFO - Epoch 46, Step 158817: Loss=5.4268, Acc=0.435, PPL=227.43
2025-09-21 02:51:46,758 - training.trainer - INFO - Epoch 46, Step 158917: Loss=6.2119, Acc=0.189, PPL=498.66
2025-09-21 02:52:04,313 - training.trainer - INFO - Epoch 47/100 completed in 284.62s - Train Loss: 5.5597, Train Acc: 0.270, Val Loss: 5.7089, Val Acc: 0.252
2025-09-21 02:52:12,781 - training.trainer - INFO - Epoch 47, Step 159100: Loss=5.1902, Acc=0.273, PPL=179.50
2025-09-21 02:52:21,109 - training.trainer - INFO - Epoch 47, Step 159200: Loss=5.2648, Acc=0.357, PPL=193.41
2025-09-21 02:52:29,314 - training.trainer - INFO - Epoch 47, Step 159300: Loss=6.5826, Acc=0.256, PPL=722.39
2025-09-21 02:52:37,460 - training.trainer - INFO - Epoch 47, Step 159400: Loss=6.1323, Acc=0.280, PPL=460.49
2025-09-21 02:52:45,484 - training.trainer - INFO - Epoch 47, Step 159500: Loss=5.2107, Acc=0.312, PPL=183.22
2025-09-21 02:52:53,461 - training.trainer - INFO - Epoch 47, Step 159600: Loss=6.1200, Acc=0.211, PPL=454.88
2025-09-21 02:53:01,413 - training.trainer - INFO - Epoch 47, Step 159700: Loss=5.5462, Acc=0.200, PPL=256.25
2025-09-21 02:53:09,455 - training.trainer - INFO - Epoch 47, Step 159800: Loss=5.8373, Acc=0.258, PPL=342.85
2025-09-21 02:53:17,451 - training.trainer - INFO - Epoch 47, Step 159900: Loss=5.7229, Acc=0.156, PPL=305.80
2025-09-21 02:53:25,435 - training.trainer - INFO - Epoch 47, Step 160000: Loss=5.8170, Acc=0.217, PPL=335.98
2025-09-21 02:53:33,456 - training.trainer - INFO - Epoch 47, Step 160100: Loss=6.0878, Acc=0.158, PPL=440.46
2025-09-21 02:53:41,436 - training.trainer - INFO - Epoch 47, Step 160200: Loss=5.7024, Acc=0.182, PPL=299.59
2025-09-21 02:53:49,404 - training.trainer - INFO - Epoch 47, Step 160300: Loss=6.1614, Acc=0.237, PPL=474.11
2025-09-21 02:53:57,310 - training.trainer - INFO - Epoch 47, Step 160400: Loss=6.2997, Acc=0.188, PPL=544.43
2025-09-21 02:54:05,211 - training.trainer - INFO - Epoch 47, Step 160500: Loss=5.7880, Acc=0.271, PPL=326.35
2025-09-21 02:54:13,177 - training.trainer - INFO - Epoch 47, Step 160600: Loss=5.7032, Acc=0.263, PPL=299.82
2025-09-21 02:54:21,138 - training.trainer - INFO - Epoch 47, Step 160700: Loss=6.4479, Acc=0.224, PPL=631.37
2025-09-21 02:54:29,113 - training.trainer - INFO - Epoch 47, Step 160800: Loss=6.0585, Acc=0.250, PPL=427.73
2025-09-21 02:54:37,032 - training.trainer - INFO - Epoch 47, Step 160900: Loss=5.6538, Acc=0.407, PPL=285.37
2025-09-21 02:54:44,941 - training.trainer - INFO - Epoch 47, Step 161000: Loss=5.8855, Acc=0.182, PPL=359.78
2025-09-21 02:54:53,029 - training.trainer - INFO - Epoch 47, Step 161100: Loss=5.9381, Acc=0.198, PPL=379.21
2025-09-21 02:55:01,029 - training.trainer - INFO - Epoch 47, Step 161200: Loss=5.3102, Acc=0.279, PPL=202.40
2025-09-21 02:55:08,956 - training.trainer - INFO - Epoch 47, Step 161300: Loss=4.8408, Acc=0.345, PPL=126.56
2025-09-21 02:55:16,923 - training.trainer - INFO - Epoch 47, Step 161400: Loss=5.7767, Acc=0.188, PPL=322.70
2025-09-21 02:55:24,909 - training.trainer - INFO - Epoch 47, Step 161500: Loss=5.5908, Acc=0.269, PPL=267.94
2025-09-21 02:55:32,862 - training.trainer - INFO - Epoch 47, Step 161600: Loss=5.7703, Acc=0.270, PPL=320.64
2025-09-21 02:55:40,855 - training.trainer - INFO - Epoch 47, Step 161700: Loss=6.2279, Acc=0.219, PPL=506.70
2025-09-21 02:55:48,763 - training.trainer - INFO - Epoch 47, Step 161800: Loss=4.9109, Acc=0.333, PPL=135.76
2025-09-21 02:55:56,727 - training.trainer - INFO - Epoch 47, Step 161900: Loss=5.0784, Acc=0.281, PPL=160.52
2025-09-21 02:56:04,722 - training.trainer - INFO - Epoch 47, Step 162000: Loss=5.5675, Acc=0.209, PPL=261.78
2025-09-21 02:56:12,694 - training.trainer - INFO - Epoch 47, Step 162100: Loss=5.8515, Acc=0.318, PPL=347.75
2025-09-21 02:56:20,674 - training.trainer - INFO - Epoch 47, Step 162200: Loss=6.3450, Acc=0.267, PPL=569.61
2025-09-21 02:56:28,622 - training.trainer - INFO - Epoch 47, Step 162300: Loss=5.9275, Acc=0.265, PPL=375.20
2025-09-21 02:56:46,153 - training.trainer - INFO - Epoch 48/100 completed in 281.84s - Train Loss: 5.5530, Train Acc: 0.270, Val Loss: 5.6937, Val Acc: 0.252
2025-09-21 02:56:46,865 - training.trainer - INFO - New best model saved with validation loss: 5.6937
2025-09-21 02:56:46,866 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_48.pt
2025-09-21 02:56:55,204 - training.trainer - INFO - Epoch 48, Step 162483: Loss=5.8543, Acc=0.300, PPL=348.72
2025-09-21 02:57:03,131 - training.trainer - INFO - Epoch 48, Step 162583: Loss=6.0528, Acc=0.207, PPL=425.30
2025-09-21 02:57:11,026 - training.trainer - INFO - Epoch 48, Step 162683: Loss=6.3829, Acc=0.172, PPL=591.63
2025-09-21 02:57:18,941 - training.trainer - INFO - Epoch 48, Step 162783: Loss=5.9512, Acc=0.213, PPL=384.22
2025-09-21 02:57:26,877 - training.trainer - INFO - Epoch 48, Step 162883: Loss=5.6159, Acc=0.250, PPL=274.76
2025-09-21 02:57:34,788 - training.trainer - INFO - Epoch 48, Step 162983: Loss=5.4316, Acc=0.286, PPL=228.52
2025-09-21 02:57:42,772 - training.trainer - INFO - Epoch 48, Step 163083: Loss=5.7341, Acc=0.244, PPL=309.25
2025-09-21 02:57:50,741 - training.trainer - INFO - Epoch 48, Step 163183: Loss=6.1303, Acc=0.205, PPL=459.55
2025-09-21 02:57:58,603 - training.trainer - INFO - Epoch 48, Step 163283: Loss=3.7364, Acc=0.440, PPL=41.95
2025-09-21 02:58:06,752 - training.trainer - INFO - Epoch 48, Step 163383: Loss=6.0688, Acc=0.207, PPL=432.18
2025-09-21 02:58:14,759 - training.trainer - INFO - Epoch 48, Step 163483: Loss=4.9864, Acc=0.333, PPL=146.41
2025-09-21 02:58:22,821 - training.trainer - INFO - Epoch 48, Step 163583: Loss=5.8395, Acc=0.196, PPL=343.61
2025-09-21 02:58:30,825 - training.trainer - INFO - Epoch 48, Step 163683: Loss=5.6671, Acc=0.291, PPL=289.21
2025-09-21 02:58:38,794 - training.trainer - INFO - Epoch 48, Step 163783: Loss=6.1594, Acc=0.247, PPL=473.14
2025-09-21 02:58:46,711 - training.trainer - INFO - Epoch 48, Step 163883: Loss=5.4882, Acc=0.250, PPL=241.82
2025-09-21 02:58:54,628 - training.trainer - INFO - Epoch 48, Step 163983: Loss=5.8838, Acc=0.175, PPL=359.15
2025-09-21 02:59:02,552 - training.trainer - INFO - Epoch 48, Step 164083: Loss=5.1882, Acc=0.308, PPL=179.14
2025-09-21 02:59:10,499 - training.trainer - INFO - Epoch 48, Step 164183: Loss=5.5199, Acc=0.261, PPL=249.60
2025-09-21 02:59:18,478 - training.trainer - INFO - Epoch 48, Step 164283: Loss=6.1074, Acc=0.173, PPL=449.15
2025-09-21 02:59:26,400 - training.trainer - INFO - Epoch 48, Step 164383: Loss=6.2474, Acc=0.222, PPL=516.67
2025-09-21 02:59:34,269 - training.trainer - INFO - Epoch 48, Step 164483: Loss=4.3355, Acc=0.486, PPL=76.36
2025-09-21 02:59:42,246 - training.trainer - INFO - Epoch 48, Step 164583: Loss=5.3461, Acc=0.250, PPL=209.79
2025-09-21 02:59:50,294 - training.trainer - INFO - Epoch 48, Step 164683: Loss=4.5741, Acc=0.484, PPL=96.94
2025-09-21 02:59:58,278 - training.trainer - INFO - Epoch 48, Step 164783: Loss=5.5780, Acc=0.308, PPL=264.55
2025-09-21 03:00:06,215 - training.trainer - INFO - Epoch 48, Step 164883: Loss=4.3632, Acc=0.300, PPL=78.51
2025-09-21 03:00:14,245 - training.trainer - INFO - Epoch 48, Step 164983: Loss=4.9477, Acc=0.312, PPL=140.86
2025-09-21 03:00:22,193 - training.trainer - INFO - Epoch 48, Step 165083: Loss=5.3755, Acc=0.267, PPL=216.04
2025-09-21 03:00:30,165 - training.trainer - INFO - Epoch 48, Step 165183: Loss=5.8694, Acc=0.306, PPL=354.05
2025-09-21 03:00:38,091 - training.trainer - INFO - Epoch 48, Step 165283: Loss=6.3860, Acc=0.214, PPL=593.51
2025-09-21 03:00:46,078 - training.trainer - INFO - Epoch 48, Step 165383: Loss=6.1887, Acc=0.216, PPL=487.23
2025-09-21 03:00:53,996 - training.trainer - INFO - Epoch 48, Step 165483: Loss=5.7675, Acc=0.256, PPL=319.73
2025-09-21 03:01:01,901 - training.trainer - INFO - Epoch 48, Step 165583: Loss=5.0278, Acc=0.270, PPL=152.60
2025-09-21 03:01:09,828 - training.trainer - INFO - Epoch 48, Step 165683: Loss=6.2254, Acc=0.223, PPL=505.45
2025-09-21 03:01:26,407 - training.trainer - INFO - Epoch 49/100 completed in 279.54s - Train Loss: 5.5472, Train Acc: 0.271, Val Loss: 5.6904, Val Acc: 0.251
2025-09-21 03:01:27,167 - training.trainer - INFO - New best model saved with validation loss: 5.6904
2025-09-21 03:01:27,167 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_49.pt
2025-09-21 03:01:35,313 - training.trainer - INFO - Epoch 49, Step 165866: Loss=5.7241, Acc=0.273, PPL=306.15
2025-09-21 03:01:43,302 - training.trainer - INFO - Epoch 49, Step 165966: Loss=6.5686, Acc=0.093, PPL=712.35
2025-09-21 03:01:51,247 - training.trainer - INFO - Epoch 49, Step 166066: Loss=4.9806, Acc=0.255, PPL=145.56
2025-09-21 03:01:59,140 - training.trainer - INFO - Epoch 49, Step 166166: Loss=5.8122, Acc=0.203, PPL=334.36
2025-09-21 03:02:07,072 - training.trainer - INFO - Epoch 49, Step 166266: Loss=5.1814, Acc=0.444, PPL=177.93
2025-09-21 03:02:15,288 - training.trainer - INFO - Epoch 49, Step 166366: Loss=5.9173, Acc=0.308, PPL=371.39
2025-09-21 03:02:23,178 - training.trainer - INFO - Epoch 49, Step 166466: Loss=5.4985, Acc=0.156, PPL=244.32
2025-09-21 03:02:31,087 - training.trainer - INFO - Epoch 49, Step 166566: Loss=4.9411, Acc=0.367, PPL=139.93
2025-09-21 03:02:39,213 - training.trainer - INFO - Epoch 49, Step 166666: Loss=5.5253, Acc=0.325, PPL=250.97
2025-09-21 03:02:47,382 - training.trainer - INFO - Epoch 49, Step 166766: Loss=4.3328, Acc=0.455, PPL=76.16
2025-09-21 03:02:55,618 - training.trainer - INFO - Epoch 49, Step 166866: Loss=6.5184, Acc=0.205, PPL=677.51
2025-09-21 03:03:03,706 - training.trainer - INFO - Epoch 49, Step 166966: Loss=5.7289, Acc=0.333, PPL=307.62
2025-09-21 03:03:11,700 - training.trainer - INFO - Epoch 49, Step 167066: Loss=5.0608, Acc=0.304, PPL=157.71
2025-09-21 03:03:19,723 - training.trainer - INFO - Epoch 49, Step 167166: Loss=5.4743, Acc=0.274, PPL=238.48
2025-09-21 03:03:27,780 - training.trainer - INFO - Epoch 49, Step 167266: Loss=5.2702, Acc=0.268, PPL=194.45
2025-09-21 03:03:35,857 - training.trainer - INFO - Epoch 49, Step 167366: Loss=5.5622, Acc=0.270, PPL=260.38
2025-09-21 03:03:43,905 - training.trainer - INFO - Epoch 49, Step 167466: Loss=6.2979, Acc=0.207, PPL=543.45
2025-09-21 03:03:52,049 - training.trainer - INFO - Epoch 49, Step 167566: Loss=5.6746, Acc=0.256, PPL=291.37
2025-09-21 03:04:00,254 - training.trainer - INFO - Epoch 49, Step 167666: Loss=5.5499, Acc=0.270, PPL=257.21
2025-09-21 03:04:08,399 - training.trainer - INFO - Epoch 49, Step 167766: Loss=6.0357, Acc=0.315, PPL=418.08
2025-09-21 03:04:16,498 - training.trainer - INFO - Epoch 49, Step 167866: Loss=5.3988, Acc=0.236, PPL=221.14
2025-09-21 03:04:24,606 - training.trainer - INFO - Epoch 49, Step 167966: Loss=5.9952, Acc=0.200, PPL=401.50
2025-09-21 03:04:32,708 - training.trainer - INFO - Epoch 49, Step 168066: Loss=5.3340, Acc=0.184, PPL=207.27
2025-09-21 03:04:40,818 - training.trainer - INFO - Epoch 49, Step 168166: Loss=4.0639, Acc=0.545, PPL=58.20
2025-09-21 03:04:48,840 - training.trainer - INFO - Epoch 49, Step 168266: Loss=5.5073, Acc=0.296, PPL=246.50
2025-09-21 03:04:56,877 - training.trainer - INFO - Epoch 49, Step 168366: Loss=5.6954, Acc=0.286, PPL=297.51
2025-09-21 03:05:04,998 - training.trainer - INFO - Epoch 49, Step 168466: Loss=5.2866, Acc=0.176, PPL=197.67
2025-09-21 03:05:13,078 - training.trainer - INFO - Epoch 49, Step 168566: Loss=4.9550, Acc=0.370, PPL=141.88
2025-09-21 03:05:21,187 - training.trainer - INFO - Epoch 49, Step 168666: Loss=5.6949, Acc=0.250, PPL=297.35
2025-09-21 03:05:29,203 - training.trainer - INFO - Epoch 49, Step 168766: Loss=5.4236, Acc=0.296, PPL=226.68
2025-09-21 03:05:37,187 - training.trainer - INFO - Epoch 49, Step 168866: Loss=5.4757, Acc=0.273, PPL=238.82
2025-09-21 03:05:45,137 - training.trainer - INFO - Epoch 49, Step 168966: Loss=5.3954, Acc=0.225, PPL=220.39
2025-09-21 03:05:53,079 - training.trainer - INFO - Epoch 49, Step 169066: Loss=6.1398, Acc=0.174, PPL=463.95
2025-09-21 03:06:10,735 - training.trainer - INFO - Epoch 50/100 completed in 283.57s - Train Loss: 5.5439, Train Acc: 0.271, Val Loss: 5.6829, Val Acc: 0.253
2025-09-21 03:06:11,130 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-21 03:06:11,995 - training.trainer - INFO - New best model saved with validation loss: 5.6829
2025-09-21 03:06:11,995 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-21 03:06:20,224 - training.trainer - INFO - Epoch 50, Step 169249: Loss=5.7813, Acc=0.290, PPL=324.18
2025-09-21 03:06:28,199 - training.trainer - INFO - Epoch 50, Step 169349: Loss=4.7124, Acc=0.500, PPL=111.32
2025-09-21 03:06:36,181 - training.trainer - INFO - Epoch 50, Step 169449: Loss=5.8826, Acc=0.282, PPL=358.72
2025-09-21 03:06:44,097 - training.trainer - INFO - Epoch 50, Step 169549: Loss=5.9938, Acc=0.203, PPL=400.92
2025-09-21 03:06:52,031 - training.trainer - INFO - Epoch 50, Step 169649: Loss=4.7759, Acc=0.364, PPL=118.61
2025-09-21 03:06:59,976 - training.trainer - INFO - Epoch 50, Step 169749: Loss=4.8983, Acc=0.450, PPL=134.06
2025-09-21 03:07:07,980 - training.trainer - INFO - Epoch 50, Step 169849: Loss=4.4665, Acc=0.400, PPL=87.05
2025-09-21 03:07:15,940 - training.trainer - INFO - Epoch 50, Step 169949: Loss=4.4368, Acc=0.345, PPL=84.50
2025-09-21 03:07:23,957 - training.trainer - INFO - Epoch 50, Step 170049: Loss=3.7311, Acc=0.519, PPL=41.73
2025-09-21 03:07:31,989 - training.trainer - INFO - Epoch 50, Step 170149: Loss=5.9180, Acc=0.167, PPL=371.67
2025-09-21 03:07:39,931 - training.trainer - INFO - Epoch 50, Step 170249: Loss=5.7773, Acc=0.200, PPL=322.88
2025-09-21 03:07:47,927 - training.trainer - INFO - Epoch 50, Step 170349: Loss=6.0765, Acc=0.244, PPL=435.52
2025-09-21 03:07:55,876 - training.trainer - INFO - Epoch 50, Step 170449: Loss=6.3830, Acc=0.257, PPL=591.72
2025-09-21 03:08:03,823 - training.trainer - INFO - Epoch 50, Step 170549: Loss=6.3395, Acc=0.225, PPL=566.52
2025-09-21 03:08:11,774 - training.trainer - INFO - Epoch 50, Step 170649: Loss=4.5608, Acc=0.407, PPL=95.66
2025-09-21 03:08:19,801 - training.trainer - INFO - Epoch 50, Step 170749: Loss=5.7161, Acc=0.273, PPL=303.73
2025-09-21 03:08:27,730 - training.trainer - INFO - Epoch 50, Step 170849: Loss=6.2132, Acc=0.237, PPL=499.28
2025-09-21 03:08:35,635 - training.trainer - INFO - Epoch 50, Step 170949: Loss=5.7530, Acc=0.231, PPL=315.14
2025-09-21 03:08:43,550 - training.trainer - INFO - Epoch 50, Step 171049: Loss=6.2438, Acc=0.333, PPL=514.81
2025-09-21 03:08:51,408 - training.trainer - INFO - Epoch 50, Step 171149: Loss=5.2014, Acc=0.324, PPL=181.52
2025-09-21 03:08:59,300 - training.trainer - INFO - Epoch 50, Step 171249: Loss=5.8156, Acc=0.225, PPL=335.49
2025-09-21 03:09:07,208 - training.trainer - INFO - Epoch 50, Step 171349: Loss=5.7341, Acc=0.212, PPL=309.24
2025-09-21 03:09:15,190 - training.trainer - INFO - Epoch 50, Step 171449: Loss=4.2765, Acc=0.385, PPL=71.99
2025-09-21 03:09:23,138 - training.trainer - INFO - Epoch 50, Step 171549: Loss=5.9673, Acc=0.217, PPL=390.46
2025-09-21 03:09:31,060 - training.trainer - INFO - Epoch 50, Step 171649: Loss=5.4316, Acc=0.355, PPL=228.51
2025-09-21 03:09:38,932 - training.trainer - INFO - Epoch 50, Step 171749: Loss=5.2237, Acc=0.282, PPL=185.62
2025-09-21 03:09:46,874 - training.trainer - INFO - Epoch 50, Step 171849: Loss=6.3965, Acc=0.273, PPL=599.77
2025-09-21 03:09:54,769 - training.trainer - INFO - Epoch 50, Step 171949: Loss=5.9482, Acc=0.238, PPL=383.08
2025-09-21 03:10:02,678 - training.trainer - INFO - Epoch 50, Step 172049: Loss=5.1746, Acc=0.206, PPL=176.73
2025-09-21 03:10:10,598 - training.trainer - INFO - Epoch 50, Step 172149: Loss=4.8725, Acc=0.343, PPL=130.65
2025-09-21 03:10:18,559 - training.trainer - INFO - Epoch 50, Step 172249: Loss=5.1748, Acc=0.292, PPL=176.77
2025-09-21 03:10:26,511 - training.trainer - INFO - Epoch 50, Step 172349: Loss=5.7648, Acc=0.250, PPL=318.86
2025-09-21 03:10:34,505 - training.trainer - INFO - Epoch 50, Step 172449: Loss=5.9051, Acc=0.262, PPL=366.90
2025-09-21 03:10:51,917 - training.trainer - INFO - Epoch 51/100 completed in 279.92s - Train Loss: 5.5354, Train Acc: 0.273, Val Loss: 5.6819, Val Acc: 0.254
2025-09-21 03:10:52,793 - training.trainer - INFO - New best model saved with validation loss: 5.6819
2025-09-21 03:10:52,794 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_51.pt
2025-09-21 03:11:01,255 - training.trainer - INFO - Epoch 51, Step 172632: Loss=5.5441, Acc=0.167, PPL=255.73
2025-09-21 03:11:09,417 - training.trainer - INFO - Epoch 51, Step 172732: Loss=5.6357, Acc=0.278, PPL=280.26
2025-09-21 03:11:17,513 - training.trainer - INFO - Epoch 51, Step 172832: Loss=4.9303, Acc=0.333, PPL=138.42
2025-09-21 03:11:25,631 - training.trainer - INFO - Epoch 51, Step 172932: Loss=6.2388, Acc=0.239, PPL=512.23
2025-09-21 03:11:33,753 - training.trainer - INFO - Epoch 51, Step 173032: Loss=5.5453, Acc=0.296, PPL=256.03
2025-09-21 03:11:41,775 - training.trainer - INFO - Epoch 51, Step 173132: Loss=5.2664, Acc=0.351, PPL=193.72
2025-09-21 03:11:49,853 - training.trainer - INFO - Epoch 51, Step 173232: Loss=5.4030, Acc=0.241, PPL=222.08
2025-09-21 03:11:57,875 - training.trainer - INFO - Epoch 51, Step 173332: Loss=5.5599, Acc=0.300, PPL=259.80
2025-09-21 03:12:05,883 - training.trainer - INFO - Epoch 51, Step 173432: Loss=5.5921, Acc=0.300, PPL=268.31
2025-09-21 03:12:13,870 - training.trainer - INFO - Epoch 51, Step 173532: Loss=6.1797, Acc=0.235, PPL=482.84
2025-09-21 03:12:21,825 - training.trainer - INFO - Epoch 51, Step 173632: Loss=4.1057, Acc=0.412, PPL=60.68
2025-09-21 03:12:29,883 - training.trainer - INFO - Epoch 51, Step 173732: Loss=5.0985, Acc=0.286, PPL=163.77
2025-09-21 03:12:37,854 - training.trainer - INFO - Epoch 51, Step 173832: Loss=5.9409, Acc=0.263, PPL=380.28
2025-09-21 03:12:45,839 - training.trainer - INFO - Epoch 51, Step 173932: Loss=5.0962, Acc=0.273, PPL=163.40
2025-09-21 03:12:53,781 - training.trainer - INFO - Epoch 51, Step 174032: Loss=5.0962, Acc=0.333, PPL=163.40
2025-09-21 03:13:01,737 - training.trainer - INFO - Epoch 51, Step 174132: Loss=5.6301, Acc=0.268, PPL=278.68
2025-09-21 03:13:09,787 - training.trainer - INFO - Epoch 51, Step 174232: Loss=5.7186, Acc=0.269, PPL=304.48
2025-09-21 03:13:17,767 - training.trainer - INFO - Epoch 51, Step 174332: Loss=6.0875, Acc=0.208, PPL=440.32
2025-09-21 03:13:25,686 - training.trainer - INFO - Epoch 51, Step 174432: Loss=5.6230, Acc=0.296, PPL=276.72
2025-09-21 03:13:33,692 - training.trainer - INFO - Epoch 51, Step 174532: Loss=5.8935, Acc=0.333, PPL=362.68
2025-09-21 03:13:41,681 - training.trainer - INFO - Epoch 51, Step 174632: Loss=6.3995, Acc=0.190, PPL=601.56
2025-09-21 03:13:49,846 - training.trainer - INFO - Epoch 51, Step 174732: Loss=6.0579, Acc=0.394, PPL=427.48
2025-09-21 03:13:57,990 - training.trainer - INFO - Epoch 51, Step 174832: Loss=5.9087, Acc=0.167, PPL=368.23
2025-09-21 03:14:05,963 - training.trainer - INFO - Epoch 51, Step 174932: Loss=6.0810, Acc=0.190, PPL=437.47
2025-09-21 03:14:14,024 - training.trainer - INFO - Epoch 51, Step 175032: Loss=5.8680, Acc=0.267, PPL=353.54
2025-09-21 03:14:21,941 - training.trainer - INFO - Epoch 51, Step 175132: Loss=5.7510, Acc=0.295, PPL=314.51
2025-09-21 03:14:29,937 - training.trainer - INFO - Epoch 51, Step 175232: Loss=4.7303, Acc=0.273, PPL=113.32
2025-09-21 03:14:37,906 - training.trainer - INFO - Epoch 51, Step 175332: Loss=5.7551, Acc=0.222, PPL=315.80
2025-09-21 03:14:45,898 - training.trainer - INFO - Epoch 51, Step 175432: Loss=5.6727, Acc=0.242, PPL=290.82
2025-09-21 03:14:53,856 - training.trainer - INFO - Epoch 51, Step 175532: Loss=5.3685, Acc=0.250, PPL=214.54
2025-09-21 03:15:01,833 - training.trainer - INFO - Epoch 51, Step 175632: Loss=5.1884, Acc=0.409, PPL=179.18
2025-09-21 03:15:09,848 - training.trainer - INFO - Epoch 51, Step 175732: Loss=5.9519, Acc=0.262, PPL=384.49
2025-09-21 03:15:17,831 - training.trainer - INFO - Epoch 51, Step 175832: Loss=6.0157, Acc=0.263, PPL=409.81
2025-09-21 03:15:34,803 - training.trainer - INFO - Epoch 52/100 completed in 282.01s - Train Loss: 5.5238, Train Acc: 0.275, Val Loss: 5.6887, Val Acc: 0.252
2025-09-21 03:15:42,776 - training.trainer - INFO - Epoch 52, Step 176015: Loss=5.5551, Acc=0.222, PPL=258.55
2025-09-21 03:15:50,803 - training.trainer - INFO - Epoch 52, Step 176115: Loss=3.7327, Acc=0.571, PPL=41.79
2025-09-21 03:15:58,727 - training.trainer - INFO - Epoch 52, Step 176215: Loss=5.8412, Acc=0.176, PPL=344.18
2025-09-21 03:16:06,671 - training.trainer - INFO - Epoch 52, Step 176315: Loss=6.1543, Acc=0.200, PPL=470.73
2025-09-21 03:16:14,640 - training.trainer - INFO - Epoch 52, Step 176415: Loss=5.3871, Acc=0.359, PPL=218.56
2025-09-21 03:16:22,837 - training.trainer - INFO - Epoch 52, Step 176515: Loss=5.5341, Acc=0.308, PPL=253.19
2025-09-21 03:16:30,927 - training.trainer - INFO - Epoch 52, Step 176615: Loss=5.8747, Acc=0.273, PPL=355.91
2025-09-21 03:16:39,077 - training.trainer - INFO - Epoch 52, Step 176715: Loss=5.9413, Acc=0.149, PPL=380.44
2025-09-21 03:16:47,109 - training.trainer - INFO - Epoch 52, Step 176815: Loss=5.3080, Acc=0.289, PPL=201.95
2025-09-21 03:16:55,343 - training.trainer - INFO - Epoch 52, Step 176915: Loss=4.9484, Acc=0.208, PPL=140.96
2025-09-21 03:17:03,505 - training.trainer - INFO - Epoch 52, Step 177015: Loss=5.4110, Acc=0.265, PPL=223.86
2025-09-21 03:17:11,787 - training.trainer - INFO - Epoch 52, Step 177115: Loss=5.2543, Acc=0.185, PPL=191.39
2025-09-21 03:17:19,945 - training.trainer - INFO - Epoch 52, Step 177215: Loss=5.1994, Acc=0.350, PPL=181.17
2025-09-21 03:17:28,049 - training.trainer - INFO - Epoch 52, Step 177315: Loss=5.1067, Acc=0.444, PPL=165.12
2025-09-21 03:17:36,013 - training.trainer - INFO - Epoch 52, Step 177415: Loss=6.1767, Acc=0.228, PPL=481.40
2025-09-21 03:17:43,956 - training.trainer - INFO - Epoch 52, Step 177515: Loss=5.8217, Acc=0.262, PPL=337.55
2025-09-21 03:17:52,081 - training.trainer - INFO - Epoch 52, Step 177615: Loss=5.7322, Acc=0.189, PPL=308.66
2025-09-21 03:18:00,071 - training.trainer - INFO - Epoch 52, Step 177715: Loss=4.7055, Acc=0.412, PPL=110.56
2025-09-21 03:18:08,174 - training.trainer - INFO - Epoch 52, Step 177815: Loss=4.5178, Acc=0.300, PPL=91.63
2025-09-21 03:18:16,418 - training.trainer - INFO - Epoch 52, Step 177915: Loss=5.1672, Acc=0.400, PPL=175.42
2025-09-21 03:18:24,617 - training.trainer - INFO - Epoch 52, Step 178015: Loss=6.2891, Acc=0.224, PPL=538.66
2025-09-21 03:18:32,782 - training.trainer - INFO - Epoch 52, Step 178115: Loss=6.2822, Acc=0.215, PPL=534.94
2025-09-21 03:18:40,904 - training.trainer - INFO - Epoch 52, Step 178215: Loss=4.4691, Acc=0.390, PPL=87.28
2025-09-21 03:18:48,932 - training.trainer - INFO - Epoch 52, Step 178315: Loss=5.2235, Acc=0.286, PPL=185.58
2025-09-21 03:18:56,975 - training.trainer - INFO - Epoch 52, Step 178415: Loss=6.1277, Acc=0.295, PPL=458.39
2025-09-21 03:19:05,042 - training.trainer - INFO - Epoch 52, Step 178515: Loss=4.8318, Acc=0.364, PPL=125.44
2025-09-21 03:19:13,109 - training.trainer - INFO - Epoch 52, Step 178615: Loss=5.3804, Acc=0.263, PPL=217.10
2025-09-21 03:19:21,011 - training.trainer - INFO - Epoch 52, Step 178715: Loss=5.5178, Acc=0.235, PPL=249.08
2025-09-21 03:19:29,076 - training.trainer - INFO - Epoch 52, Step 178815: Loss=6.0283, Acc=0.300, PPL=414.99
2025-09-21 03:19:37,007 - training.trainer - INFO - Epoch 52, Step 178915: Loss=6.3286, Acc=0.169, PPL=560.38
2025-09-21 03:19:44,961 - training.trainer - INFO - Epoch 52, Step 179015: Loss=4.5539, Acc=0.312, PPL=95.00
2025-09-21 03:19:52,934 - training.trainer - INFO - Epoch 52, Step 179115: Loss=5.3236, Acc=0.304, PPL=205.11
2025-09-21 03:20:00,859 - training.trainer - INFO - Epoch 52, Step 179215: Loss=5.9981, Acc=0.189, PPL=402.67
2025-09-21 03:20:18,009 - training.trainer - INFO - Epoch 53/100 completed in 283.21s - Train Loss: 5.5195, Train Acc: 0.274, Val Loss: 5.6799, Val Acc: 0.254
2025-09-21 03:20:18,788 - training.trainer - INFO - New best model saved with validation loss: 5.6799
2025-09-21 03:20:18,788 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_53.pt
2025-09-21 03:20:27,227 - training.trainer - INFO - Epoch 53, Step 179398: Loss=4.8051, Acc=0.250, PPL=122.14
2025-09-21 03:20:35,334 - training.trainer - INFO - Epoch 53, Step 179498: Loss=5.1041, Acc=0.245, PPL=164.70
2025-09-21 03:20:43,604 - training.trainer - INFO - Epoch 53, Step 179598: Loss=4.9939, Acc=0.367, PPL=147.52
2025-09-21 03:20:51,807 - training.trainer - INFO - Epoch 53, Step 179698: Loss=6.5930, Acc=0.222, PPL=729.99
2025-09-21 03:21:00,069 - training.trainer - INFO - Epoch 53, Step 179798: Loss=5.8937, Acc=0.204, PPL=362.76
2025-09-21 03:21:08,263 - training.trainer - INFO - Epoch 53, Step 179898: Loss=5.7395, Acc=0.231, PPL=310.92
2025-09-21 03:21:16,341 - training.trainer - INFO - Epoch 53, Step 179998: Loss=6.2913, Acc=0.224, PPL=539.85
2025-09-21 03:21:24,479 - training.trainer - INFO - Epoch 53, Step 180098: Loss=5.7437, Acc=0.304, PPL=312.22
2025-09-21 03:21:32,486 - training.trainer - INFO - Epoch 53, Step 180198: Loss=6.1400, Acc=0.140, PPL=464.07
2025-09-21 03:21:40,471 - training.trainer - INFO - Epoch 53, Step 180298: Loss=5.4962, Acc=0.190, PPL=243.76
2025-09-21 03:21:48,487 - training.trainer - INFO - Epoch 53, Step 180398: Loss=6.1638, Acc=0.200, PPL=475.22
2025-09-21 03:21:56,446 - training.trainer - INFO - Epoch 53, Step 180498: Loss=4.8401, Acc=0.233, PPL=126.48
2025-09-21 03:22:04,332 - training.trainer - INFO - Epoch 53, Step 180598: Loss=5.4026, Acc=0.200, PPL=221.98
2025-09-21 03:22:12,354 - training.trainer - INFO - Epoch 53, Step 180698: Loss=5.2365, Acc=0.261, PPL=188.01
2025-09-21 03:22:20,397 - training.trainer - INFO - Epoch 53, Step 180798: Loss=6.3351, Acc=0.171, PPL=564.04
2025-09-21 03:22:28,384 - training.trainer - INFO - Epoch 53, Step 180898: Loss=6.1184, Acc=0.222, PPL=454.14
2025-09-21 03:22:36,458 - training.trainer - INFO - Epoch 53, Step 180998: Loss=5.6995, Acc=0.212, PPL=298.71
2025-09-21 03:22:44,387 - training.trainer - INFO - Epoch 53, Step 181098: Loss=5.2943, Acc=0.345, PPL=199.19
2025-09-21 03:22:52,332 - training.trainer - INFO - Epoch 53, Step 181198: Loss=5.2463, Acc=0.320, PPL=189.86
2025-09-21 03:23:00,340 - training.trainer - INFO - Epoch 53, Step 181298: Loss=5.5569, Acc=0.217, PPL=259.02
2025-09-21 03:23:08,338 - training.trainer - INFO - Epoch 53, Step 181398: Loss=4.3296, Acc=0.438, PPL=75.92
2025-09-21 03:23:16,335 - training.trainer - INFO - Epoch 53, Step 181498: Loss=4.4614, Acc=0.429, PPL=86.61
2025-09-21 03:23:24,312 - training.trainer - INFO - Epoch 53, Step 181598: Loss=5.0398, Acc=0.429, PPL=154.44
2025-09-21 03:23:32,299 - training.trainer - INFO - Epoch 53, Step 181698: Loss=5.1575, Acc=0.219, PPL=173.73
2025-09-21 03:23:40,294 - training.trainer - INFO - Epoch 53, Step 181798: Loss=5.8184, Acc=0.250, PPL=336.42
2025-09-21 03:23:48,265 - training.trainer - INFO - Epoch 53, Step 181898: Loss=5.8125, Acc=0.243, PPL=334.46
2025-09-21 03:23:56,198 - training.trainer - INFO - Epoch 53, Step 181998: Loss=6.0182, Acc=0.200, PPL=410.83
2025-09-21 03:24:04,172 - training.trainer - INFO - Epoch 53, Step 182098: Loss=4.3835, Acc=0.303, PPL=80.12
2025-09-21 03:24:12,161 - training.trainer - INFO - Epoch 53, Step 182198: Loss=5.6396, Acc=0.316, PPL=281.35
2025-09-21 03:24:20,123 - training.trainer - INFO - Epoch 53, Step 182298: Loss=6.1095, Acc=0.214, PPL=450.09
2025-09-21 03:24:28,170 - training.trainer - INFO - Epoch 53, Step 182398: Loss=5.1704, Acc=0.400, PPL=175.99
2025-09-21 03:24:36,117 - training.trainer - INFO - Epoch 53, Step 182498: Loss=5.7991, Acc=0.158, PPL=330.01
2025-09-21 03:24:44,033 - training.trainer - INFO - Epoch 53, Step 182598: Loss=5.0360, Acc=0.300, PPL=153.85
2025-09-21 03:25:01,345 - training.trainer - INFO - Epoch 54/100 completed in 282.56s - Train Loss: 5.5098, Train Acc: 0.276, Val Loss: 5.6850, Val Acc: 0.251
2025-09-21 03:25:09,228 - training.trainer - INFO - Epoch 54, Step 182781: Loss=5.9260, Acc=0.263, PPL=374.64
2025-09-21 03:25:17,304 - training.trainer - INFO - Epoch 54, Step 182881: Loss=5.4935, Acc=0.300, PPL=243.11
2025-09-21 03:25:25,406 - training.trainer - INFO - Epoch 54, Step 182981: Loss=5.6782, Acc=0.260, PPL=292.44
2025-09-21 03:25:33,495 - training.trainer - INFO - Epoch 54, Step 183081: Loss=4.9171, Acc=0.346, PPL=136.61
2025-09-21 03:25:41,551 - training.trainer - INFO - Epoch 54, Step 183181: Loss=5.7846, Acc=0.294, PPL=325.25
2025-09-21 03:25:49,602 - training.trainer - INFO - Epoch 54, Step 183281: Loss=4.6329, Acc=0.370, PPL=102.82
2025-09-21 03:25:57,683 - training.trainer - INFO - Epoch 54, Step 183381: Loss=6.1718, Acc=0.280, PPL=479.02
2025-09-21 03:26:05,908 - training.trainer - INFO - Epoch 54, Step 183481: Loss=3.1622, Acc=0.526, PPL=23.62
2025-09-21 03:26:14,029 - training.trainer - INFO - Epoch 54, Step 183581: Loss=4.8119, Acc=0.304, PPL=122.96
2025-09-21 03:26:22,047 - training.trainer - INFO - Epoch 54, Step 183681: Loss=5.3355, Acc=0.259, PPL=207.57
2025-09-21 03:26:30,248 - training.trainer - INFO - Epoch 54, Step 183781: Loss=6.5610, Acc=0.128, PPL=706.96
2025-09-21 03:26:38,411 - training.trainer - INFO - Epoch 54, Step 183881: Loss=5.6411, Acc=0.227, PPL=281.78
2025-09-21 03:26:46,388 - training.trainer - INFO - Epoch 54, Step 183981: Loss=4.9226, Acc=0.308, PPL=137.36
2025-09-21 03:26:54,323 - training.trainer - INFO - Epoch 54, Step 184081: Loss=5.4831, Acc=0.190, PPL=240.60
2025-09-21 03:27:02,273 - training.trainer - INFO - Epoch 54, Step 184181: Loss=6.0651, Acc=0.197, PPL=430.56
2025-09-21 03:27:10,226 - training.trainer - INFO - Epoch 54, Step 184281: Loss=5.2222, Acc=0.306, PPL=185.34
2025-09-21 03:27:18,138 - training.trainer - INFO - Epoch 54, Step 184381: Loss=5.0181, Acc=0.222, PPL=151.12
2025-09-21 03:27:26,027 - training.trainer - INFO - Epoch 54, Step 184481: Loss=3.1255, Acc=0.611, PPL=22.77
2025-09-21 03:27:34,023 - training.trainer - INFO - Epoch 54, Step 184581: Loss=6.2830, Acc=0.167, PPL=535.41
2025-09-21 03:27:42,079 - training.trainer - INFO - Epoch 54, Step 184681: Loss=5.1630, Acc=0.459, PPL=174.69
2025-09-21 03:27:50,129 - training.trainer - INFO - Epoch 54, Step 184781: Loss=6.2264, Acc=0.211, PPL=505.91
2025-09-21 03:27:58,128 - training.trainer - INFO - Epoch 54, Step 184881: Loss=5.3982, Acc=0.298, PPL=221.00
2025-09-21 03:28:06,120 - training.trainer - INFO - Epoch 54, Step 184981: Loss=6.2540, Acc=0.222, PPL=520.10
2025-09-21 03:28:14,095 - training.trainer - INFO - Epoch 54, Step 185081: Loss=5.8904, Acc=0.218, PPL=361.54
2025-09-21 03:28:22,095 - training.trainer - INFO - Epoch 54, Step 185181: Loss=5.9955, Acc=0.250, PPL=401.61
2025-09-21 03:28:30,078 - training.trainer - INFO - Epoch 54, Step 185281: Loss=6.0968, Acc=0.240, PPL=444.42
2025-09-21 03:28:38,044 - training.trainer - INFO - Epoch 54, Step 185381: Loss=4.9993, Acc=0.375, PPL=148.31
2025-09-21 03:28:46,019 - training.trainer - INFO - Epoch 54, Step 185481: Loss=4.8575, Acc=0.417, PPL=128.70
2025-09-21 03:28:54,022 - training.trainer - INFO - Epoch 54, Step 185581: Loss=5.7706, Acc=0.229, PPL=320.73
2025-09-21 03:29:02,011 - training.trainer - INFO - Epoch 54, Step 185681: Loss=5.8531, Acc=0.250, PPL=348.30
2025-09-21 03:29:09,972 - training.trainer - INFO - Epoch 54, Step 185781: Loss=5.9374, Acc=0.221, PPL=378.95
2025-09-21 03:29:17,934 - training.trainer - INFO - Epoch 54, Step 185881: Loss=5.4780, Acc=0.275, PPL=239.36
2025-09-21 03:29:25,928 - training.trainer - INFO - Epoch 54, Step 185981: Loss=5.1931, Acc=0.381, PPL=180.02
2025-09-21 03:29:43,231 - training.trainer - INFO - Epoch 55/100 completed in 281.89s - Train Loss: 5.5008, Train Acc: 0.277, Val Loss: 5.6728, Val Acc: 0.255
2025-09-21 03:29:43,600 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_55.pt
2025-09-21 03:29:44,386 - training.trainer - INFO - New best model saved with validation loss: 5.6728
2025-09-21 03:29:44,386 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_55.pt
2025-09-21 03:29:52,516 - training.trainer - INFO - Epoch 55, Step 186164: Loss=6.5774, Acc=0.265, PPL=718.70
2025-09-21 03:30:00,582 - training.trainer - INFO - Epoch 55, Step 186264: Loss=5.1891, Acc=0.269, PPL=179.31
2025-09-21 03:30:08,618 - training.trainer - INFO - Epoch 55, Step 186364: Loss=5.2607, Acc=0.391, PPL=192.61
2025-09-21 03:30:16,601 - training.trainer - INFO - Epoch 55, Step 186464: Loss=6.3770, Acc=0.200, PPL=588.19
2025-09-21 03:30:24,555 - training.trainer - INFO - Epoch 55, Step 186564: Loss=5.2602, Acc=0.278, PPL=192.52
2025-09-21 03:30:32,507 - training.trainer - INFO - Epoch 55, Step 186664: Loss=5.3780, Acc=0.326, PPL=216.59
2025-09-21 03:30:40,427 - training.trainer - INFO - Epoch 55, Step 186764: Loss=4.2761, Acc=0.438, PPL=71.96
2025-09-21 03:30:48,383 - training.trainer - INFO - Epoch 55, Step 186864: Loss=5.4679, Acc=0.300, PPL=236.96
2025-09-21 03:30:56,336 - training.trainer - INFO - Epoch 55, Step 186964: Loss=5.3459, Acc=0.167, PPL=209.74
2025-09-21 03:31:04,318 - training.trainer - INFO - Epoch 55, Step 187064: Loss=5.7038, Acc=0.375, PPL=300.00
2025-09-21 03:31:12,284 - training.trainer - INFO - Epoch 55, Step 187164: Loss=5.5277, Acc=0.243, PPL=251.56
2025-09-21 03:31:20,218 - training.trainer - INFO - Epoch 55, Step 187264: Loss=6.1551, Acc=0.133, PPL=471.13
2025-09-21 03:31:28,206 - training.trainer - INFO - Epoch 55, Step 187364: Loss=6.0404, Acc=0.257, PPL=420.06
2025-09-21 03:31:36,125 - training.trainer - INFO - Epoch 55, Step 187464: Loss=5.7895, Acc=0.204, PPL=326.86
2025-09-21 03:31:44,135 - training.trainer - INFO - Epoch 55, Step 187564: Loss=5.8529, Acc=0.250, PPL=348.25
2025-09-21 03:31:52,083 - training.trainer - INFO - Epoch 55, Step 187664: Loss=5.9440, Acc=0.220, PPL=381.44
2025-09-21 03:32:00,056 - training.trainer - INFO - Epoch 55, Step 187764: Loss=5.4643, Acc=0.312, PPL=236.12
2025-09-21 03:32:08,029 - training.trainer - INFO - Epoch 55, Step 187864: Loss=5.9942, Acc=0.172, PPL=401.08
2025-09-21 03:32:16,016 - training.trainer - INFO - Epoch 55, Step 187964: Loss=5.5134, Acc=0.259, PPL=248.00
2025-09-21 03:32:24,146 - training.trainer - INFO - Epoch 55, Step 188064: Loss=5.7236, Acc=0.220, PPL=306.01
2025-09-21 03:32:32,157 - training.trainer - INFO - Epoch 55, Step 188164: Loss=5.5328, Acc=0.290, PPL=252.86
2025-09-21 03:32:40,161 - training.trainer - INFO - Epoch 55, Step 188264: Loss=5.8116, Acc=0.195, PPL=334.15
2025-09-21 03:32:48,091 - training.trainer - INFO - Epoch 55, Step 188364: Loss=5.9398, Acc=0.205, PPL=379.87
2025-09-21 03:32:56,054 - training.trainer - INFO - Epoch 55, Step 188464: Loss=5.9953, Acc=0.196, PPL=401.54
2025-09-21 03:33:04,015 - training.trainer - INFO - Epoch 55, Step 188564: Loss=5.7471, Acc=0.200, PPL=313.29
2025-09-21 03:33:12,008 - training.trainer - INFO - Epoch 55, Step 188664: Loss=5.5338, Acc=0.367, PPL=253.10
2025-09-21 03:33:19,995 - training.trainer - INFO - Epoch 55, Step 188764: Loss=5.4371, Acc=0.353, PPL=229.77
2025-09-21 03:33:27,967 - training.trainer - INFO - Epoch 55, Step 188864: Loss=6.1182, Acc=0.145, PPL=454.05
2025-09-21 03:33:36,247 - training.trainer - INFO - Epoch 55, Step 188964: Loss=5.6352, Acc=0.370, PPL=280.12
2025-09-21 03:33:44,234 - training.trainer - INFO - Epoch 55, Step 189064: Loss=5.4623, Acc=0.292, PPL=235.63
2025-09-21 03:33:52,320 - training.trainer - INFO - Epoch 55, Step 189164: Loss=5.1716, Acc=0.269, PPL=176.20
2025-09-21 03:34:00,438 - training.trainer - INFO - Epoch 55, Step 189264: Loss=5.4479, Acc=0.235, PPL=232.28
2025-09-21 03:34:08,465 - training.trainer - INFO - Epoch 55, Step 189364: Loss=4.2982, Acc=0.464, PPL=73.57
2025-09-21 03:34:25,241 - training.trainer - INFO - Epoch 56/100 completed in 280.85s - Train Loss: 5.4976, Train Acc: 0.278, Val Loss: 5.6828, Val Acc: 0.251
2025-09-21 03:34:33,349 - training.trainer - INFO - Epoch 56, Step 189547: Loss=6.0253, Acc=0.237, PPL=413.78
2025-09-21 03:34:41,341 - training.trainer - INFO - Epoch 56, Step 189647: Loss=5.8337, Acc=0.207, PPL=341.62
2025-09-21 03:34:49,358 - training.trainer - INFO - Epoch 56, Step 189747: Loss=4.6225, Acc=0.321, PPL=101.75
2025-09-21 03:34:57,387 - training.trainer - INFO - Epoch 56, Step 189847: Loss=5.3774, Acc=0.296, PPL=216.47
2025-09-21 03:35:05,392 - training.trainer - INFO - Epoch 56, Step 189947: Loss=5.9633, Acc=0.213, PPL=388.89
2025-09-21 03:35:13,366 - training.trainer - INFO - Epoch 56, Step 190047: Loss=5.6038, Acc=0.231, PPL=271.44
2025-09-21 03:35:21,314 - training.trainer - INFO - Epoch 56, Step 190147: Loss=4.8451, Acc=0.327, PPL=127.12
2025-09-21 03:35:29,318 - training.trainer - INFO - Epoch 56, Step 190247: Loss=4.8431, Acc=0.333, PPL=126.86
2025-09-21 03:35:37,261 - training.trainer - INFO - Epoch 56, Step 190347: Loss=5.9940, Acc=0.188, PPL=401.03
2025-09-21 03:35:45,510 - training.trainer - INFO - Epoch 56, Step 190447: Loss=5.2323, Acc=0.361, PPL=187.23
2025-09-21 03:35:53,565 - training.trainer - INFO - Epoch 56, Step 190547: Loss=4.7871, Acc=0.357, PPL=119.96
2025-09-21 03:36:01,699 - training.trainer - INFO - Epoch 56, Step 190647: Loss=5.5617, Acc=0.239, PPL=260.27
2025-09-21 03:36:09,772 - training.trainer - INFO - Epoch 56, Step 190747: Loss=3.4224, Acc=0.429, PPL=30.64
2025-09-21 03:36:17,779 - training.trainer - INFO - Epoch 56, Step 190847: Loss=6.1985, Acc=0.192, PPL=492.01
2025-09-21 03:36:25,828 - training.trainer - INFO - Epoch 56, Step 190947: Loss=5.5998, Acc=0.243, PPL=270.37
2025-09-21 03:36:33,774 - training.trainer - INFO - Epoch 56, Step 191047: Loss=6.5460, Acc=0.143, PPL=696.44
2025-09-21 03:36:41,671 - training.trainer - INFO - Epoch 56, Step 191147: Loss=5.5275, Acc=0.243, PPL=251.50
2025-09-21 03:36:49,566 - training.trainer - INFO - Epoch 56, Step 191247: Loss=5.3818, Acc=0.262, PPL=217.41
2025-09-21 03:36:57,542 - training.trainer - INFO - Epoch 56, Step 191347: Loss=4.9728, Acc=0.353, PPL=144.43
2025-09-21 03:37:05,539 - training.trainer - INFO - Epoch 56, Step 191447: Loss=4.3973, Acc=0.300, PPL=81.23
2025-09-21 03:37:13,478 - training.trainer - INFO - Epoch 56, Step 191547: Loss=5.1810, Acc=0.294, PPL=177.87
2025-09-21 03:37:21,464 - training.trainer - INFO - Epoch 56, Step 191647: Loss=4.8796, Acc=0.429, PPL=131.57
2025-09-21 03:37:29,408 - training.trainer - INFO - Epoch 56, Step 191747: Loss=5.2219, Acc=0.476, PPL=185.28
2025-09-21 03:37:37,349 - training.trainer - INFO - Epoch 56, Step 191847: Loss=5.8701, Acc=0.275, PPL=354.28
2025-09-21 03:37:45,305 - training.trainer - INFO - Epoch 56, Step 191947: Loss=5.6358, Acc=0.217, PPL=280.29
2025-09-21 03:37:53,311 - training.trainer - INFO - Epoch 56, Step 192047: Loss=4.5012, Acc=0.417, PPL=90.13
2025-09-21 03:38:01,298 - training.trainer - INFO - Epoch 56, Step 192147: Loss=5.2828, Acc=0.371, PPL=196.92
2025-09-21 03:38:09,291 - training.trainer - INFO - Epoch 56, Step 192247: Loss=5.4770, Acc=0.231, PPL=239.13
2025-09-21 03:38:17,293 - training.trainer - INFO - Epoch 56, Step 192347: Loss=5.2854, Acc=0.333, PPL=197.44
2025-09-21 03:38:25,330 - training.trainer - INFO - Epoch 56, Step 192447: Loss=4.8329, Acc=0.333, PPL=125.58
2025-09-21 03:38:33,316 - training.trainer - INFO - Epoch 56, Step 192547: Loss=5.2842, Acc=0.230, PPL=197.20
2025-09-21 03:38:41,345 - training.trainer - INFO - Epoch 56, Step 192647: Loss=6.0692, Acc=0.213, PPL=432.35
2025-09-21 03:38:49,513 - training.trainer - INFO - Epoch 56, Step 192747: Loss=5.3986, Acc=0.333, PPL=221.09
2025-09-21 03:39:06,793 - training.trainer - INFO - Epoch 57/100 completed in 281.55s - Train Loss: 5.4916, Train Acc: 0.279, Val Loss: 5.6823, Val Acc: 0.253
2025-09-21 03:39:15,241 - training.trainer - INFO - Epoch 57, Step 192930: Loss=5.9594, Acc=0.189, PPL=387.37
2025-09-21 03:39:23,306 - training.trainer - INFO - Epoch 57, Step 193030: Loss=5.8291, Acc=0.278, PPL=340.04
2025-09-21 03:39:31,339 - training.trainer - INFO - Epoch 57, Step 193130: Loss=5.6442, Acc=0.273, PPL=282.66
2025-09-21 03:39:39,337 - training.trainer - INFO - Epoch 57, Step 193230: Loss=5.7413, Acc=0.278, PPL=311.47
2025-09-21 03:39:47,357 - training.trainer - INFO - Epoch 57, Step 193330: Loss=5.7585, Acc=0.286, PPL=316.87
2025-09-21 03:39:55,468 - training.trainer - INFO - Epoch 57, Step 193430: Loss=5.7132, Acc=0.178, PPL=302.84
2025-09-21 03:40:03,571 - training.trainer - INFO - Epoch 57, Step 193530: Loss=5.5482, Acc=0.222, PPL=256.76
2025-09-21 03:40:11,532 - training.trainer - INFO - Epoch 57, Step 193630: Loss=5.3517, Acc=0.216, PPL=210.96
2025-09-21 03:40:19,588 - training.trainer - INFO - Epoch 57, Step 193730: Loss=5.4148, Acc=0.217, PPL=224.72
2025-09-21 03:40:27,677 - training.trainer - INFO - Epoch 57, Step 193830: Loss=5.7156, Acc=0.192, PPL=303.55
2025-09-21 03:40:35,891 - training.trainer - INFO - Epoch 57, Step 193930: Loss=6.1539, Acc=0.213, PPL=470.55
2025-09-21 03:40:44,011 - training.trainer - INFO - Epoch 57, Step 194030: Loss=5.5145, Acc=0.259, PPL=248.27
2025-09-21 03:40:52,154 - training.trainer - INFO - Epoch 57, Step 194130: Loss=5.7216, Acc=0.227, PPL=305.39
2025-09-21 03:41:00,249 - training.trainer - INFO - Epoch 57, Step 194230: Loss=5.3086, Acc=0.255, PPL=202.07
2025-09-21 03:41:08,371 - training.trainer - INFO - Epoch 57, Step 194330: Loss=5.0560, Acc=0.348, PPL=156.96
2025-09-21 03:41:16,410 - training.trainer - INFO - Epoch 57, Step 194430: Loss=5.6875, Acc=0.293, PPL=295.14
2025-09-21 03:41:24,520 - training.trainer - INFO - Epoch 57, Step 194530: Loss=5.7556, Acc=0.200, PPL=315.95
2025-09-21 03:41:32,626 - training.trainer - INFO - Epoch 57, Step 194630: Loss=5.7970, Acc=0.239, PPL=329.32
2025-09-21 03:41:40,655 - training.trainer - INFO - Epoch 57, Step 194730: Loss=5.9600, Acc=0.156, PPL=387.60
2025-09-21 03:41:48,678 - training.trainer - INFO - Epoch 57, Step 194830: Loss=5.6930, Acc=0.258, PPL=296.79
2025-09-21 03:41:56,688 - training.trainer - INFO - Epoch 57, Step 194930: Loss=6.2149, Acc=0.237, PPL=500.17
2025-09-21 03:42:04,712 - training.trainer - INFO - Epoch 57, Step 195030: Loss=4.8784, Acc=0.273, PPL=131.42
2025-09-21 03:42:12,736 - training.trainer - INFO - Epoch 57, Step 195130: Loss=5.2231, Acc=0.238, PPL=185.51
2025-09-21 03:42:20,782 - training.trainer - INFO - Epoch 57, Step 195230: Loss=6.3150, Acc=0.122, PPL=552.81
2025-09-21 03:42:28,787 - training.trainer - INFO - Epoch 57, Step 195330: Loss=5.7145, Acc=0.219, PPL=303.23
2025-09-21 03:42:36,785 - training.trainer - INFO - Epoch 57, Step 195430: Loss=4.8935, Acc=0.333, PPL=133.42
2025-09-21 03:42:44,791 - training.trainer - INFO - Epoch 57, Step 195530: Loss=5.8001, Acc=0.345, PPL=330.33
2025-09-21 03:42:52,747 - training.trainer - INFO - Epoch 57, Step 195630: Loss=5.7526, Acc=0.164, PPL=315.01
2025-09-21 03:43:00,747 - training.trainer - INFO - Epoch 57, Step 195730: Loss=6.0194, Acc=0.138, PPL=411.35
2025-09-21 03:43:08,804 - training.trainer - INFO - Epoch 57, Step 195830: Loss=5.0383, Acc=0.259, PPL=154.21
2025-09-21 03:43:16,796 - training.trainer - INFO - Epoch 57, Step 195930: Loss=4.7404, Acc=0.500, PPL=114.48
2025-09-21 03:43:24,859 - training.trainer - INFO - Epoch 57, Step 196030: Loss=5.9589, Acc=0.326, PPL=387.17
2025-09-21 03:43:32,910 - training.trainer - INFO - Epoch 57, Step 196130: Loss=3.5600, Acc=0.444, PPL=35.16
2025-09-21 03:43:49,734 - training.trainer - INFO - Epoch 58/100 completed in 282.94s - Train Loss: 5.4857, Train Acc: 0.281, Val Loss: 5.6740, Val Acc: 0.256
2025-09-21 03:43:57,829 - training.trainer - INFO - Epoch 58, Step 196313: Loss=5.6840, Acc=0.233, PPL=294.12
2025-09-21 03:44:05,876 - training.trainer - INFO - Epoch 58, Step 196413: Loss=5.5367, Acc=0.200, PPL=253.85
2025-09-21 03:44:14,007 - training.trainer - INFO - Epoch 58, Step 196513: Loss=5.8918, Acc=0.179, PPL=362.05
2025-09-21 03:44:21,972 - training.trainer - INFO - Epoch 58, Step 196613: Loss=6.2242, Acc=0.162, PPL=504.84
2025-09-21 03:44:30,003 - training.trainer - INFO - Epoch 58, Step 196713: Loss=5.9927, Acc=0.241, PPL=400.48
2025-09-21 03:44:37,948 - training.trainer - INFO - Epoch 58, Step 196813: Loss=5.5431, Acc=0.243, PPL=255.46
2025-09-21 03:44:45,881 - training.trainer - INFO - Epoch 58, Step 196913: Loss=6.2187, Acc=0.220, PPL=502.05
2025-09-21 03:44:53,808 - training.trainer - INFO - Epoch 58, Step 197013: Loss=6.1617, Acc=0.182, PPL=474.26
2025-09-21 03:45:01,739 - training.trainer - INFO - Epoch 58, Step 197113: Loss=5.5698, Acc=0.261, PPL=262.39
2025-09-21 03:45:09,665 - training.trainer - INFO - Epoch 58, Step 197213: Loss=5.0941, Acc=0.360, PPL=163.05
2025-09-21 03:45:17,596 - training.trainer - INFO - Epoch 58, Step 197313: Loss=6.1925, Acc=0.195, PPL=489.06
2025-09-21 03:45:25,571 - training.trainer - INFO - Epoch 58, Step 197413: Loss=6.1524, Acc=0.194, PPL=469.84
2025-09-21 03:45:33,470 - training.trainer - INFO - Epoch 58, Step 197513: Loss=5.8982, Acc=0.192, PPL=364.37
2025-09-21 03:45:41,493 - training.trainer - INFO - Epoch 58, Step 197613: Loss=5.5944, Acc=0.114, PPL=268.92
2025-09-21 03:45:49,519 - training.trainer - INFO - Epoch 58, Step 197713: Loss=5.8794, Acc=0.280, PPL=357.60
2025-09-21 03:45:57,767 - training.trainer - INFO - Epoch 58, Step 197813: Loss=5.3879, Acc=0.295, PPL=218.75
2025-09-21 03:46:06,050 - training.trainer - INFO - Epoch 58, Step 197913: Loss=5.1961, Acc=0.256, PPL=180.56
2025-09-21 03:46:14,099 - training.trainer - INFO - Epoch 58, Step 198013: Loss=6.2472, Acc=0.193, PPL=516.58
2025-09-21 03:46:22,112 - training.trainer - INFO - Epoch 58, Step 198113: Loss=4.9260, Acc=0.273, PPL=137.82
2025-09-21 03:46:30,137 - training.trainer - INFO - Epoch 58, Step 198213: Loss=5.5504, Acc=0.196, PPL=257.35
2025-09-21 03:46:38,150 - training.trainer - INFO - Epoch 58, Step 198313: Loss=4.7592, Acc=0.360, PPL=116.65
2025-09-21 03:46:46,202 - training.trainer - INFO - Epoch 58, Step 198413: Loss=5.6175, Acc=0.200, PPL=275.20
2025-09-21 03:46:54,204 - training.trainer - INFO - Epoch 58, Step 198513: Loss=6.0283, Acc=0.213, PPL=415.00
2025-09-21 03:47:02,187 - training.trainer - INFO - Epoch 58, Step 198613: Loss=5.9084, Acc=0.306, PPL=368.11
2025-09-21 03:47:10,190 - training.trainer - INFO - Epoch 58, Step 198713: Loss=5.7768, Acc=0.250, PPL=322.72
2025-09-21 03:47:18,214 - training.trainer - INFO - Epoch 58, Step 198813: Loss=5.9357, Acc=0.263, PPL=378.30
2025-09-21 03:47:26,207 - training.trainer - INFO - Epoch 58, Step 198913: Loss=5.7392, Acc=0.310, PPL=310.82
2025-09-21 03:47:34,191 - training.trainer - INFO - Epoch 58, Step 199013: Loss=6.3416, Acc=0.182, PPL=567.72
2025-09-21 03:47:42,186 - training.trainer - INFO - Epoch 58, Step 199113: Loss=4.8238, Acc=0.417, PPL=124.43
2025-09-21 03:47:50,172 - training.trainer - INFO - Epoch 58, Step 199213: Loss=5.6146, Acc=0.250, PPL=274.42
2025-09-21 03:47:58,157 - training.trainer - INFO - Epoch 58, Step 199313: Loss=5.2627, Acc=0.333, PPL=192.99
2025-09-21 03:48:06,150 - training.trainer - INFO - Epoch 58, Step 199413: Loss=5.7177, Acc=0.233, PPL=304.20
2025-09-21 03:48:14,134 - training.trainer - INFO - Epoch 58, Step 199513: Loss=5.6343, Acc=0.250, PPL=279.86
2025-09-21 03:48:31,945 - training.trainer - INFO - Epoch 59/100 completed in 282.21s - Train Loss: 5.4753, Train Acc: 0.281, Val Loss: 5.6769, Val Acc: 0.255
2025-09-21 03:48:40,271 - training.trainer - INFO - Epoch 59, Step 199696: Loss=5.6704, Acc=0.259, PPL=290.16
2025-09-21 03:48:48,257 - training.trainer - INFO - Epoch 59, Step 199796: Loss=6.2574, Acc=0.184, PPL=521.84
2025-09-21 03:48:56,326 - training.trainer - INFO - Epoch 59, Step 199896: Loss=5.7014, Acc=0.244, PPL=299.30
2025-09-21 03:49:04,259 - training.trainer - INFO - Epoch 59, Step 199996: Loss=4.3915, Acc=0.366, PPL=80.77
2025-09-21 03:49:12,159 - training.trainer - INFO - Epoch 59, Step 200096: Loss=5.4243, Acc=0.297, PPL=226.84
2025-09-21 03:49:20,122 - training.trainer - INFO - Epoch 59, Step 200196: Loss=5.5708, Acc=0.224, PPL=262.63
2025-09-21 03:49:28,135 - training.trainer - INFO - Epoch 59, Step 200296: Loss=4.8803, Acc=0.190, PPL=131.67
2025-09-21 03:49:36,098 - training.trainer - INFO - Epoch 59, Step 200396: Loss=5.4657, Acc=0.229, PPL=236.45
2025-09-21 03:49:44,041 - training.trainer - INFO - Epoch 59, Step 200496: Loss=5.1115, Acc=0.400, PPL=165.92
2025-09-21 03:49:51,954 - training.trainer - INFO - Epoch 59, Step 200596: Loss=6.0592, Acc=0.242, PPL=428.04
2025-09-21 03:49:59,936 - training.trainer - INFO - Epoch 59, Step 200696: Loss=5.1115, Acc=0.325, PPL=165.92
2025-09-21 03:50:07,923 - training.trainer - INFO - Epoch 59, Step 200796: Loss=2.2354, Acc=0.710, PPL=9.35
2025-09-21 03:50:15,902 - training.trainer - INFO - Epoch 59, Step 200896: Loss=4.7572, Acc=0.417, PPL=116.42
2025-09-21 03:50:23,862 - training.trainer - INFO - Epoch 59, Step 200996: Loss=6.5135, Acc=0.161, PPL=674.20
2025-09-21 03:50:31,784 - training.trainer - INFO - Epoch 59, Step 201096: Loss=5.3467, Acc=0.214, PPL=209.91
2025-09-21 03:50:39,778 - training.trainer - INFO - Epoch 59, Step 201196: Loss=5.5531, Acc=0.310, PPL=258.04
2025-09-21 03:50:47,788 - training.trainer - INFO - Epoch 59, Step 201296: Loss=4.3645, Acc=0.429, PPL=78.61
2025-09-21 03:50:55,731 - training.trainer - INFO - Epoch 59, Step 201396: Loss=5.0328, Acc=0.300, PPL=153.36
2025-09-21 03:51:03,760 - training.trainer - INFO - Epoch 59, Step 201496: Loss=5.5788, Acc=0.286, PPL=264.75
2025-09-21 03:51:11,891 - training.trainer - INFO - Epoch 59, Step 201596: Loss=3.1861, Acc=0.444, PPL=24.20
2025-09-21 03:51:19,854 - training.trainer - INFO - Epoch 59, Step 201696: Loss=5.6413, Acc=0.280, PPL=281.82
2025-09-21 03:51:27,766 - training.trainer - INFO - Epoch 59, Step 201796: Loss=5.1994, Acc=0.391, PPL=181.16
2025-09-21 03:51:35,752 - training.trainer - INFO - Epoch 59, Step 201896: Loss=5.5305, Acc=0.250, PPL=252.26
2025-09-21 03:51:43,862 - training.trainer - INFO - Epoch 59, Step 201996: Loss=5.8116, Acc=0.227, PPL=334.15
2025-09-21 03:51:51,908 - training.trainer - INFO - Epoch 59, Step 202096: Loss=5.6478, Acc=0.233, PPL=283.67
2025-09-21 03:52:00,052 - training.trainer - INFO - Epoch 59, Step 202196: Loss=5.4560, Acc=0.316, PPL=234.15
2025-09-21 03:52:08,170 - training.trainer - INFO - Epoch 59, Step 202296: Loss=5.4328, Acc=0.333, PPL=228.78
2025-09-21 03:52:16,182 - training.trainer - INFO - Epoch 59, Step 202396: Loss=5.9414, Acc=0.333, PPL=380.46
2025-09-21 03:52:24,188 - training.trainer - INFO - Epoch 59, Step 202496: Loss=6.0872, Acc=0.157, PPL=440.20
2025-09-21 03:52:32,174 - training.trainer - INFO - Epoch 59, Step 202596: Loss=5.1280, Acc=0.324, PPL=168.67
2025-09-21 03:52:40,097 - training.trainer - INFO - Epoch 59, Step 202696: Loss=5.8128, Acc=0.179, PPL=334.54
2025-09-21 03:52:48,091 - training.trainer - INFO - Epoch 59, Step 202796: Loss=5.0749, Acc=0.304, PPL=159.95
2025-09-21 03:52:56,105 - training.trainer - INFO - Epoch 59, Step 202896: Loss=5.7998, Acc=0.192, PPL=330.24
2025-09-21 03:53:13,975 - training.trainer - INFO - Epoch 60/100 completed in 282.03s - Train Loss: 5.4696, Train Acc: 0.282, Val Loss: 5.6757, Val Acc: 0.255
2025-09-21 03:53:14,338 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_60.pt
2025-09-21 03:53:22,774 - training.trainer - INFO - Epoch 60, Step 203079: Loss=6.0309, Acc=0.196, PPL=416.10
2025-09-21 03:53:30,843 - training.trainer - INFO - Epoch 60, Step 203179: Loss=5.7750, Acc=0.179, PPL=322.13
2025-09-21 03:53:38,803 - training.trainer - INFO - Epoch 60, Step 203279: Loss=6.0882, Acc=0.216, PPL=440.61
2025-09-21 03:53:46,719 - training.trainer - INFO - Epoch 60, Step 203379: Loss=5.5480, Acc=0.185, PPL=256.71
2025-09-21 03:53:54,674 - training.trainer - INFO - Epoch 60, Step 203479: Loss=6.2053, Acc=0.196, PPL=495.38
2025-09-21 03:54:02,653 - training.trainer - INFO - Epoch 60, Step 203579: Loss=5.8021, Acc=0.250, PPL=330.98
2025-09-21 03:54:10,597 - training.trainer - INFO - Epoch 60, Step 203679: Loss=5.7589, Acc=0.294, PPL=317.00
2025-09-21 03:54:18,517 - training.trainer - INFO - Epoch 60, Step 203779: Loss=5.5365, Acc=0.206, PPL=253.79
2025-09-21 03:54:26,482 - training.trainer - INFO - Epoch 60, Step 203879: Loss=6.4804, Acc=0.179, PPL=652.24
2025-09-21 03:54:34,440 - training.trainer - INFO - Epoch 60, Step 203979: Loss=4.8191, Acc=0.406, PPL=123.86
2025-09-21 03:54:42,384 - training.trainer - INFO - Epoch 60, Step 204079: Loss=5.6023, Acc=0.200, PPL=271.05
2025-09-21 03:54:50,282 - training.trainer - INFO - Epoch 60, Step 204179: Loss=6.0352, Acc=0.229, PPL=417.87
2025-09-21 03:54:58,166 - training.trainer - INFO - Epoch 60, Step 204279: Loss=6.1885, Acc=0.206, PPL=487.11
2025-09-21 03:55:06,135 - training.trainer - INFO - Epoch 60, Step 204379: Loss=5.1352, Acc=0.250, PPL=169.90
2025-09-21 03:55:14,071 - training.trainer - INFO - Epoch 60, Step 204479: Loss=5.6467, Acc=0.250, PPL=283.37
2025-09-21 03:55:22,020 - training.trainer - INFO - Epoch 60, Step 204579: Loss=6.1490, Acc=0.237, PPL=468.26
2025-09-21 03:55:29,900 - training.trainer - INFO - Epoch 60, Step 204679: Loss=5.8818, Acc=0.215, PPL=358.46
2025-09-21 03:55:37,807 - training.trainer - INFO - Epoch 60, Step 204779: Loss=4.9421, Acc=0.324, PPL=140.06
2025-09-21 03:55:45,692 - training.trainer - INFO - Epoch 60, Step 204879: Loss=5.4403, Acc=0.172, PPL=230.50
2025-09-21 03:55:53,602 - training.trainer - INFO - Epoch 60, Step 204979: Loss=5.6997, Acc=0.261, PPL=298.78
2025-09-21 03:56:01,529 - training.trainer - INFO - Epoch 60, Step 205079: Loss=5.6646, Acc=0.291, PPL=288.48
2025-09-21 03:56:09,460 - training.trainer - INFO - Epoch 60, Step 205179: Loss=5.4425, Acc=0.224, PPL=231.01
2025-09-21 03:56:17,392 - training.trainer - INFO - Epoch 60, Step 205279: Loss=5.4956, Acc=0.385, PPL=243.62
2025-09-21 03:56:25,398 - training.trainer - INFO - Epoch 60, Step 205379: Loss=5.0638, Acc=0.287, PPL=158.19
2025-09-21 03:56:33,315 - training.trainer - INFO - Epoch 60, Step 205479: Loss=6.1850, Acc=0.200, PPL=485.42
2025-09-21 03:56:41,227 - training.trainer - INFO - Epoch 60, Step 205579: Loss=5.9446, Acc=0.200, PPL=381.69
2025-09-21 03:56:49,119 - training.trainer - INFO - Epoch 60, Step 205679: Loss=5.2609, Acc=0.381, PPL=192.66
2025-09-21 03:56:56,998 - training.trainer - INFO - Epoch 60, Step 205779: Loss=5.5270, Acc=0.267, PPL=251.40
2025-09-21 03:57:04,854 - training.trainer - INFO - Epoch 60, Step 205879: Loss=5.8049, Acc=0.231, PPL=331.93
2025-09-21 03:57:12,803 - training.trainer - INFO - Epoch 60, Step 205979: Loss=4.5549, Acc=0.355, PPL=95.10
2025-09-21 03:57:20,655 - training.trainer - INFO - Epoch 60, Step 206079: Loss=5.3541, Acc=0.316, PPL=211.48
2025-09-21 03:57:28,548 - training.trainer - INFO - Epoch 60, Step 206179: Loss=5.6737, Acc=0.214, PPL=291.11
2025-09-21 03:57:36,445 - training.trainer - INFO - Epoch 60, Step 206279: Loss=5.3284, Acc=0.333, PPL=206.10
2025-09-21 03:57:53,166 - training.trainer - INFO - Epoch 61/100 completed in 278.83s - Train Loss: 5.4690, Train Acc: 0.282, Val Loss: 5.6684, Val Acc: 0.254
2025-09-21 03:57:53,890 - training.trainer - INFO - New best model saved with validation loss: 5.6684
2025-09-21 03:57:53,891 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_61.pt
2025-09-21 03:58:02,183 - training.trainer - INFO - Epoch 61, Step 206462: Loss=5.1938, Acc=0.219, PPL=180.16
2025-09-21 03:58:10,254 - training.trainer - INFO - Epoch 61, Step 206562: Loss=5.6684, Acc=0.211, PPL=289.56
2025-09-21 03:58:18,335 - training.trainer - INFO - Epoch 61, Step 206662: Loss=5.9546, Acc=0.259, PPL=385.52
2025-09-21 03:58:26,334 - training.trainer - INFO - Epoch 61, Step 206762: Loss=6.0179, Acc=0.271, PPL=410.71
2025-09-21 03:58:34,336 - training.trainer - INFO - Epoch 61, Step 206862: Loss=5.9029, Acc=0.190, PPL=366.09
2025-09-21 03:58:42,285 - training.trainer - INFO - Epoch 61, Step 206962: Loss=5.5612, Acc=0.204, PPL=260.14
2025-09-21 03:58:50,305 - training.trainer - INFO - Epoch 61, Step 207062: Loss=5.2075, Acc=0.295, PPL=182.63
2025-09-21 03:58:58,305 - training.trainer - INFO - Epoch 61, Step 207162: Loss=6.4401, Acc=0.179, PPL=626.46
2025-09-21 03:59:06,302 - training.trainer - INFO - Epoch 61, Step 207262: Loss=5.2288, Acc=0.267, PPL=186.57
2025-09-21 03:59:14,347 - training.trainer - INFO - Epoch 61, Step 207362: Loss=5.9099, Acc=0.389, PPL=368.66
2025-09-21 03:59:22,288 - training.trainer - INFO - Epoch 61, Step 207462: Loss=4.6383, Acc=0.357, PPL=103.37
2025-09-21 03:59:30,242 - training.trainer - INFO - Epoch 61, Step 207562: Loss=5.3017, Acc=0.308, PPL=200.68
2025-09-21 03:59:38,262 - training.trainer - INFO - Epoch 61, Step 207662: Loss=4.9237, Acc=0.348, PPL=137.51
2025-09-21 03:59:46,298 - training.trainer - INFO - Epoch 61, Step 207762: Loss=5.6385, Acc=0.303, PPL=281.03
2025-09-21 03:59:54,256 - training.trainer - INFO - Epoch 61, Step 207862: Loss=4.4798, Acc=0.227, PPL=88.22
2025-09-21 04:00:02,270 - training.trainer - INFO - Epoch 61, Step 207962: Loss=5.7759, Acc=0.213, PPL=322.45
2025-09-21 04:00:10,294 - training.trainer - INFO - Epoch 61, Step 208062: Loss=5.5297, Acc=0.269, PPL=252.06
2025-09-21 04:00:18,307 - training.trainer - INFO - Epoch 61, Step 208162: Loss=5.1520, Acc=0.333, PPL=172.78
2025-09-21 04:00:26,337 - training.trainer - INFO - Epoch 61, Step 208262: Loss=5.7377, Acc=0.260, PPL=310.35
2025-09-21 04:00:34,323 - training.trainer - INFO - Epoch 61, Step 208362: Loss=5.6165, Acc=0.273, PPL=274.92
2025-09-21 04:00:42,338 - training.trainer - INFO - Epoch 61, Step 208462: Loss=5.6355, Acc=0.333, PPL=280.19
2025-09-21 04:00:50,308 - training.trainer - INFO - Epoch 61, Step 208562: Loss=4.3776, Acc=0.451, PPL=79.64
2025-09-21 04:00:58,299 - training.trainer - INFO - Epoch 61, Step 208662: Loss=6.0201, Acc=0.297, PPL=411.61
2025-09-21 04:01:06,302 - training.trainer - INFO - Epoch 61, Step 208762: Loss=5.6470, Acc=0.204, PPL=283.43
2025-09-21 04:01:14,317 - training.trainer - INFO - Epoch 61, Step 208862: Loss=7.0819, Acc=0.200, PPL=1190.19
2025-09-21 04:01:22,217 - training.trainer - INFO - Epoch 61, Step 208962: Loss=4.1177, Acc=0.375, PPL=61.42
2025-09-21 04:01:30,179 - training.trainer - INFO - Epoch 61, Step 209062: Loss=5.5534, Acc=0.259, PPL=258.11
2025-09-21 04:01:38,167 - training.trainer - INFO - Epoch 61, Step 209162: Loss=4.8011, Acc=0.381, PPL=121.64
2025-09-21 04:01:46,156 - training.trainer - INFO - Epoch 61, Step 209262: Loss=5.8616, Acc=0.267, PPL=351.30
2025-09-21 04:01:54,141 - training.trainer - INFO - Epoch 61, Step 209362: Loss=6.1135, Acc=0.213, PPL=451.93
2025-09-21 04:02:02,128 - training.trainer - INFO - Epoch 61, Step 209462: Loss=6.4233, Acc=0.185, PPL=616.06
2025-09-21 04:02:10,409 - training.trainer - INFO - Epoch 61, Step 209562: Loss=5.9179, Acc=0.286, PPL=371.62
2025-09-21 04:02:18,435 - training.trainer - INFO - Epoch 61, Step 209662: Loss=6.4158, Acc=0.268, PPL=611.46
2025-09-21 04:02:36,066 - training.trainer - INFO - Epoch 62/100 completed in 282.17s - Train Loss: 5.4575, Train Acc: 0.284, Val Loss: 5.6820, Val Acc: 0.253
2025-09-21 04:02:44,290 - training.trainer - INFO - Epoch 62, Step 209845: Loss=5.8117, Acc=0.194, PPL=334.18
2025-09-21 04:02:52,267 - training.trainer - INFO - Epoch 62, Step 209945: Loss=5.3510, Acc=0.333, PPL=210.82
2025-09-21 04:03:00,269 - training.trainer - INFO - Epoch 62, Step 210045: Loss=6.0721, Acc=0.271, PPL=433.59
2025-09-21 04:03:08,277 - training.trainer - INFO - Epoch 62, Step 210145: Loss=6.3269, Acc=0.216, PPL=559.44
2025-09-21 04:03:16,252 - training.trainer - INFO - Epoch 62, Step 210245: Loss=4.7439, Acc=0.375, PPL=114.89
2025-09-21 04:03:24,199 - training.trainer - INFO - Epoch 62, Step 210345: Loss=5.2691, Acc=0.306, PPL=194.24
2025-09-21 04:03:32,145 - training.trainer - INFO - Epoch 62, Step 210445: Loss=4.5162, Acc=0.231, PPL=91.49
2025-09-21 04:03:40,119 - training.trainer - INFO - Epoch 62, Step 210545: Loss=6.1205, Acc=0.238, PPL=455.08
2025-09-21 04:03:48,098 - training.trainer - INFO - Epoch 62, Step 210645: Loss=5.3144, Acc=0.357, PPL=203.23
2025-09-21 04:03:56,050 - training.trainer - INFO - Epoch 62, Step 210745: Loss=5.5619, Acc=0.368, PPL=260.33
2025-09-21 04:04:03,972 - training.trainer - INFO - Epoch 62, Step 210845: Loss=6.6644, Acc=0.133, PPL=783.98
2025-09-21 04:04:11,993 - training.trainer - INFO - Epoch 62, Step 210945: Loss=5.5287, Acc=0.262, PPL=251.83
2025-09-21 04:04:20,018 - training.trainer - INFO - Epoch 62, Step 211045: Loss=4.1787, Acc=0.400, PPL=65.28
2025-09-21 04:04:27,959 - training.trainer - INFO - Epoch 62, Step 211145: Loss=5.9992, Acc=0.222, PPL=403.10
2025-09-21 04:04:35,877 - training.trainer - INFO - Epoch 62, Step 211245: Loss=5.6758, Acc=0.160, PPL=291.72
2025-09-21 04:04:43,868 - training.trainer - INFO - Epoch 62, Step 211345: Loss=5.0599, Acc=0.367, PPL=157.58
2025-09-21 04:04:51,848 - training.trainer - INFO - Epoch 62, Step 211445: Loss=5.5897, Acc=0.237, PPL=267.66
2025-09-21 04:04:59,838 - training.trainer - INFO - Epoch 62, Step 211545: Loss=5.7490, Acc=0.259, PPL=313.87
2025-09-21 04:05:07,739 - training.trainer - INFO - Epoch 62, Step 211645: Loss=5.4382, Acc=0.247, PPL=230.04
2025-09-21 04:05:15,593 - training.trainer - INFO - Epoch 62, Step 211745: Loss=5.7007, Acc=0.214, PPL=299.08
2025-09-21 04:05:23,524 - training.trainer - INFO - Epoch 62, Step 211845: Loss=5.1213, Acc=0.308, PPL=167.55
2025-09-21 04:05:31,395 - training.trainer - INFO - Epoch 62, Step 211945: Loss=5.4976, Acc=0.324, PPL=244.10
2025-09-21 04:05:39,242 - training.trainer - INFO - Epoch 62, Step 212045: Loss=5.2134, Acc=0.265, PPL=183.73
2025-09-21 04:05:47,164 - training.trainer - INFO - Epoch 62, Step 212145: Loss=4.2301, Acc=0.500, PPL=68.73
2025-09-21 04:05:55,137 - training.trainer - INFO - Epoch 62, Step 212245: Loss=6.6052, Acc=0.190, PPL=738.90
2025-09-21 04:06:03,114 - training.trainer - INFO - Epoch 62, Step 212345: Loss=5.6534, Acc=0.290, PPL=285.26
2025-09-21 04:06:11,048 - training.trainer - INFO - Epoch 62, Step 212445: Loss=5.9494, Acc=0.400, PPL=383.52
2025-09-21 04:06:19,064 - training.trainer - INFO - Epoch 62, Step 212545: Loss=5.8122, Acc=0.243, PPL=334.34
2025-09-21 04:06:27,053 - training.trainer - INFO - Epoch 62, Step 212645: Loss=6.4527, Acc=0.222, PPL=634.43
2025-09-21 04:06:34,968 - training.trainer - INFO - Epoch 62, Step 212745: Loss=5.7538, Acc=0.311, PPL=315.38
2025-09-21 04:06:42,946 - training.trainer - INFO - Epoch 62, Step 212845: Loss=5.4670, Acc=0.391, PPL=236.74
2025-09-21 04:06:50,908 - training.trainer - INFO - Epoch 62, Step 212945: Loss=6.5570, Acc=0.239, PPL=704.15
2025-09-21 04:06:58,927 - training.trainer - INFO - Epoch 62, Step 213045: Loss=4.3006, Acc=0.444, PPL=73.74
2025-09-21 04:07:16,438 - training.trainer - INFO - Epoch 63/100 completed in 280.37s - Train Loss: 5.4588, Train Acc: 0.283, Val Loss: 5.6744, Val Acc: 0.256
2025-09-21 04:07:24,938 - training.trainer - INFO - Epoch 63, Step 213228: Loss=5.4789, Acc=0.276, PPL=239.59
2025-09-21 04:07:33,050 - training.trainer - INFO - Epoch 63, Step 213328: Loss=5.3352, Acc=0.243, PPL=207.52
2025-09-21 04:07:41,054 - training.trainer - INFO - Epoch 63, Step 213428: Loss=5.2434, Acc=0.300, PPL=189.30
2025-09-21 04:07:49,286 - training.trainer - INFO - Epoch 63, Step 213528: Loss=5.7662, Acc=0.213, PPL=319.33
2025-09-21 04:07:57,285 - training.trainer - INFO - Epoch 63, Step 213628: Loss=5.8006, Acc=0.222, PPL=330.49
2025-09-21 04:08:05,315 - training.trainer - INFO - Epoch 63, Step 213728: Loss=5.6661, Acc=0.216, PPL=288.91
2025-09-21 04:08:13,302 - training.trainer - INFO - Epoch 63, Step 213828: Loss=5.3129, Acc=0.367, PPL=202.94
2025-09-21 04:08:21,322 - training.trainer - INFO - Epoch 63, Step 213928: Loss=5.2646, Acc=0.235, PPL=193.37
2025-09-21 04:08:29,339 - training.trainer - INFO - Epoch 63, Step 214028: Loss=6.9122, Acc=0.163, PPL=1004.49
2025-09-21 04:08:37,285 - training.trainer - INFO - Epoch 63, Step 214128: Loss=6.2588, Acc=0.290, PPL=522.59
2025-09-21 04:08:45,286 - training.trainer - INFO - Epoch 63, Step 214228: Loss=5.8509, Acc=0.200, PPL=347.56
2025-09-21 04:08:53,235 - training.trainer - INFO - Epoch 63, Step 214328: Loss=3.8340, Acc=0.500, PPL=46.25
2025-09-21 04:09:01,225 - training.trainer - INFO - Epoch 63, Step 214428: Loss=4.5717, Acc=0.333, PPL=96.71
2025-09-21 04:09:09,166 - training.trainer - INFO - Epoch 63, Step 214528: Loss=5.7219, Acc=0.308, PPL=305.48
2025-09-21 04:09:17,090 - training.trainer - INFO - Epoch 63, Step 214628: Loss=4.5741, Acc=0.421, PPL=96.94
2025-09-21 04:09:24,968 - training.trainer - INFO - Epoch 63, Step 214728: Loss=5.6080, Acc=0.375, PPL=272.59
2025-09-21 04:09:32,877 - training.trainer - INFO - Epoch 63, Step 214828: Loss=5.1380, Acc=0.333, PPL=170.38
2025-09-21 04:09:40,902 - training.trainer - INFO - Epoch 63, Step 214928: Loss=6.0977, Acc=0.222, PPL=444.83
2025-09-21 04:09:48,868 - training.trainer - INFO - Epoch 63, Step 215028: Loss=5.7054, Acc=0.303, PPL=300.49
2025-09-21 04:09:56,864 - training.trainer - INFO - Epoch 63, Step 215128: Loss=5.4989, Acc=0.283, PPL=244.43
2025-09-21 04:10:04,835 - training.trainer - INFO - Epoch 63, Step 215228: Loss=5.7917, Acc=0.192, PPL=327.57
2025-09-21 04:10:12,782 - training.trainer - INFO - Epoch 63, Step 215328: Loss=5.9178, Acc=0.250, PPL=371.60
2025-09-21 04:10:20,848 - training.trainer - INFO - Epoch 63, Step 215428: Loss=5.7488, Acc=0.279, PPL=313.81
2025-09-21 04:10:28,926 - training.trainer - INFO - Epoch 63, Step 215528: Loss=4.2921, Acc=0.489, PPL=73.12
2025-09-21 04:10:37,011 - training.trainer - INFO - Epoch 63, Step 215628: Loss=6.1315, Acc=0.210, PPL=460.12
2025-09-21 04:10:44,969 - training.trainer - INFO - Epoch 63, Step 215728: Loss=5.7556, Acc=0.295, PPL=315.97
2025-09-21 04:10:52,937 - training.trainer - INFO - Epoch 63, Step 215828: Loss=6.2834, Acc=0.200, PPL=535.59
2025-09-21 04:11:00,904 - training.trainer - INFO - Epoch 63, Step 215928: Loss=5.2606, Acc=0.270, PPL=192.60
2025-09-21 04:11:08,931 - training.trainer - INFO - Epoch 63, Step 216028: Loss=5.0476, Acc=0.348, PPL=155.65
2025-09-21 04:11:16,894 - training.trainer - INFO - Epoch 63, Step 216128: Loss=5.3806, Acc=0.257, PPL=217.14
2025-09-21 04:11:24,935 - training.trainer - INFO - Epoch 63, Step 216228: Loss=5.1827, Acc=0.194, PPL=178.16
2025-09-21 04:11:32,932 - training.trainer - INFO - Epoch 63, Step 216328: Loss=5.3052, Acc=0.339, PPL=201.39
2025-09-21 04:11:41,045 - training.trainer - INFO - Epoch 63, Step 216428: Loss=4.1946, Acc=0.393, PPL=66.33
2025-09-21 04:11:58,040 - training.trainer - INFO - Epoch 64/100 completed in 281.60s - Train Loss: 5.4512, Train Acc: 0.286, Val Loss: 5.6819, Val Acc: 0.255
2025-09-21 04:12:06,179 - training.trainer - INFO - Epoch 64, Step 216611: Loss=5.7621, Acc=0.193, PPL=318.02
2025-09-21 04:12:14,328 - training.trainer - INFO - Epoch 64, Step 216711: Loss=5.3627, Acc=0.217, PPL=213.30
2025-09-21 04:12:22,374 - training.trainer - INFO - Epoch 64, Step 216811: Loss=5.9321, Acc=0.213, PPL=376.96
2025-09-21 04:12:30,378 - training.trainer - INFO - Epoch 64, Step 216911: Loss=6.4816, Acc=0.293, PPL=653.04
2025-09-21 04:12:38,541 - training.trainer - INFO - Epoch 64, Step 217011: Loss=4.8139, Acc=0.333, PPL=123.21
2025-09-21 04:12:46,534 - training.trainer - INFO - Epoch 64, Step 217111: Loss=5.4854, Acc=0.240, PPL=241.15
2025-09-21 04:12:54,504 - training.trainer - INFO - Epoch 64, Step 217211: Loss=3.6371, Acc=0.500, PPL=37.98
2025-09-21 04:13:02,439 - training.trainer - INFO - Epoch 64, Step 217311: Loss=5.9599, Acc=0.250, PPL=387.57
2025-09-21 04:13:10,519 - training.trainer - INFO - Epoch 64, Step 217411: Loss=5.7062, Acc=0.219, PPL=300.72
2025-09-21 04:13:18,555 - training.trainer - INFO - Epoch 64, Step 217511: Loss=5.2637, Acc=0.333, PPL=193.20
2025-09-21 04:13:26,680 - training.trainer - INFO - Epoch 64, Step 217611: Loss=5.5271, Acc=0.182, PPL=251.41
2025-09-21 04:13:34,622 - training.trainer - INFO - Epoch 64, Step 217711: Loss=4.8857, Acc=0.333, PPL=132.38
2025-09-21 04:13:42,499 - training.trainer - INFO - Epoch 64, Step 217811: Loss=6.1253, Acc=0.194, PPL=457.30
2025-09-21 04:13:50,460 - training.trainer - INFO - Epoch 64, Step 217911: Loss=4.9868, Acc=0.303, PPL=146.47
2025-09-21 04:13:58,344 - training.trainer - INFO - Epoch 64, Step 218011: Loss=5.4748, Acc=0.235, PPL=238.61
2025-09-21 04:14:06,284 - training.trainer - INFO - Epoch 64, Step 218111: Loss=6.1885, Acc=0.385, PPL=487.10
2025-09-21 04:14:14,273 - training.trainer - INFO - Epoch 64, Step 218211: Loss=5.5173, Acc=0.423, PPL=248.95
2025-09-21 04:14:22,269 - training.trainer - INFO - Epoch 64, Step 218311: Loss=5.4148, Acc=0.281, PPL=224.70
2025-09-21 04:14:30,276 - training.trainer - INFO - Epoch 64, Step 218411: Loss=4.2619, Acc=0.375, PPL=70.95
2025-09-21 04:14:38,258 - training.trainer - INFO - Epoch 64, Step 218511: Loss=5.5622, Acc=0.324, PPL=260.39
2025-09-21 04:14:46,510 - training.trainer - INFO - Epoch 64, Step 218611: Loss=5.6399, Acc=0.238, PPL=281.44
2025-09-21 04:14:54,692 - training.trainer - INFO - Epoch 64, Step 218711: Loss=5.8978, Acc=0.192, PPL=364.22
2025-09-21 04:15:02,864 - training.trainer - INFO - Epoch 64, Step 218811: Loss=5.5181, Acc=0.222, PPL=249.15
2025-09-21 04:15:10,785 - training.trainer - INFO - Epoch 64, Step 218911: Loss=4.5221, Acc=0.516, PPL=92.03
2025-09-21 04:15:18,830 - training.trainer - INFO - Epoch 64, Step 219011: Loss=5.0461, Acc=0.294, PPL=155.42
2025-09-21 04:15:26,878 - training.trainer - INFO - Epoch 64, Step 219111: Loss=5.4878, Acc=0.316, PPL=241.73
2025-09-21 04:15:35,121 - training.trainer - INFO - Epoch 64, Step 219211: Loss=4.8113, Acc=0.333, PPL=122.89
2025-09-21 04:15:43,357 - training.trainer - INFO - Epoch 64, Step 219311: Loss=6.0432, Acc=0.196, PPL=421.23
2025-09-21 04:15:51,531 - training.trainer - INFO - Epoch 64, Step 219411: Loss=5.5320, Acc=0.298, PPL=252.65
2025-09-21 04:15:59,816 - training.trainer - INFO - Epoch 64, Step 219511: Loss=5.1459, Acc=0.385, PPL=171.73
2025-09-21 04:16:08,030 - training.trainer - INFO - Epoch 64, Step 219611: Loss=5.0067, Acc=0.322, PPL=149.42
2025-09-21 04:16:16,184 - training.trainer - INFO - Epoch 64, Step 219711: Loss=5.6908, Acc=0.273, PPL=296.14
2025-09-21 04:16:24,193 - training.trainer - INFO - Epoch 64, Step 219811: Loss=5.3433, Acc=0.236, PPL=209.20
2025-09-21 04:16:41,722 - training.trainer - INFO - Epoch 65/100 completed in 283.68s - Train Loss: 5.4477, Train Acc: 0.285, Val Loss: 5.6921, Val Acc: 0.254
2025-09-21 04:16:42,060 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_65.pt
2025-09-21 04:16:50,469 - training.trainer - INFO - Epoch 65, Step 219994: Loss=5.9790, Acc=0.239, PPL=395.05
2025-09-21 04:16:58,585 - training.trainer - INFO - Epoch 65, Step 220094: Loss=5.5471, Acc=0.267, PPL=256.50
2025-09-21 04:17:06,626 - training.trainer - INFO - Epoch 65, Step 220194: Loss=5.6602, Acc=0.265, PPL=287.20
2025-09-21 04:17:14,750 - training.trainer - INFO - Epoch 65, Step 220294: Loss=5.0280, Acc=0.309, PPL=152.63
2025-09-21 04:17:22,843 - training.trainer - INFO - Epoch 65, Step 220394: Loss=5.6552, Acc=0.345, PPL=285.78
2025-09-21 04:17:30,871 - training.trainer - INFO - Epoch 65, Step 220494: Loss=6.0511, Acc=0.195, PPL=424.57
2025-09-21 04:17:38,901 - training.trainer - INFO - Epoch 65, Step 220594: Loss=5.7097, Acc=0.242, PPL=301.79
2025-09-21 04:17:47,064 - training.trainer - INFO - Epoch 65, Step 220694: Loss=4.9894, Acc=0.267, PPL=146.84
2025-09-21 04:17:54,994 - training.trainer - INFO - Epoch 65, Step 220794: Loss=5.7377, Acc=0.333, PPL=310.35
2025-09-21 04:18:02,856 - training.trainer - INFO - Epoch 65, Step 220894: Loss=4.7836, Acc=0.364, PPL=119.54
2025-09-21 04:18:10,721 - training.trainer - INFO - Epoch 65, Step 220994: Loss=5.3936, Acc=0.250, PPL=220.00
2025-09-21 04:18:18,688 - training.trainer - INFO - Epoch 65, Step 221094: Loss=5.6437, Acc=0.262, PPL=282.52
2025-09-21 04:18:26,634 - training.trainer - INFO - Epoch 65, Step 221194: Loss=5.3106, Acc=0.241, PPL=202.46
2025-09-21 04:18:34,659 - training.trainer - INFO - Epoch 65, Step 221294: Loss=6.2706, Acc=0.175, PPL=528.80
2025-09-21 04:18:42,591 - training.trainer - INFO - Epoch 65, Step 221394: Loss=5.5478, Acc=0.243, PPL=256.67
2025-09-21 04:18:50,521 - training.trainer - INFO - Epoch 65, Step 221494: Loss=5.5892, Acc=0.275, PPL=267.52
2025-09-21 04:18:58,571 - training.trainer - INFO - Epoch 65, Step 221594: Loss=5.3933, Acc=0.277, PPL=219.93
2025-09-21 04:19:06,611 - training.trainer - INFO - Epoch 65, Step 221694: Loss=5.4133, Acc=0.368, PPL=224.38
2025-09-21 04:19:14,613 - training.trainer - INFO - Epoch 65, Step 221794: Loss=4.1044, Acc=0.562, PPL=60.60
2025-09-21 04:19:22,650 - training.trainer - INFO - Epoch 65, Step 221894: Loss=5.8607, Acc=0.189, PPL=350.95
2025-09-21 04:19:30,805 - training.trainer - INFO - Epoch 65, Step 221994: Loss=4.0863, Acc=0.500, PPL=59.52
2025-09-21 04:19:38,987 - training.trainer - INFO - Epoch 65, Step 222094: Loss=6.2391, Acc=0.204, PPL=512.42
2025-09-21 04:19:47,074 - training.trainer - INFO - Epoch 65, Step 222194: Loss=5.8790, Acc=0.212, PPL=357.44
2025-09-21 04:19:55,063 - training.trainer - INFO - Epoch 65, Step 222294: Loss=5.0428, Acc=0.407, PPL=154.90
2025-09-21 04:20:03,062 - training.trainer - INFO - Epoch 65, Step 222394: Loss=3.8914, Acc=0.450, PPL=48.98
2025-09-21 04:20:11,108 - training.trainer - INFO - Epoch 65, Step 222494: Loss=5.1341, Acc=0.240, PPL=169.72
2025-09-21 04:20:19,179 - training.trainer - INFO - Epoch 65, Step 222594: Loss=6.0504, Acc=0.211, PPL=424.26
2025-09-21 04:20:27,154 - training.trainer - INFO - Epoch 65, Step 222694: Loss=5.2322, Acc=0.300, PPL=187.20
2025-09-21 04:20:35,071 - training.trainer - INFO - Epoch 65, Step 222794: Loss=6.1465, Acc=0.182, PPL=467.10
2025-09-21 04:20:43,152 - training.trainer - INFO - Epoch 65, Step 222894: Loss=6.0830, Acc=0.250, PPL=438.34
2025-09-21 04:20:51,133 - training.trainer - INFO - Epoch 65, Step 222994: Loss=5.4208, Acc=0.275, PPL=226.05
2025-09-21 04:20:59,130 - training.trainer - INFO - Epoch 65, Step 223094: Loss=5.4210, Acc=0.324, PPL=226.10
2025-09-21 04:21:07,215 - training.trainer - INFO - Epoch 65, Step 223194: Loss=6.0615, Acc=0.164, PPL=429.02
2025-09-21 04:21:24,862 - training.trainer - INFO - Epoch 66/100 completed in 282.80s - Train Loss: 5.4411, Train Acc: 0.286, Val Loss: 5.6841, Val Acc: 0.254
2025-09-21 04:21:33,269 - training.trainer - INFO - Epoch 66, Step 223377: Loss=5.6475, Acc=0.301, PPL=283.57
2025-09-21 04:21:41,430 - training.trainer - INFO - Epoch 66, Step 223477: Loss=6.2832, Acc=0.220, PPL=535.52
2025-09-21 04:21:49,604 - training.trainer - INFO - Epoch 66, Step 223577: Loss=5.8186, Acc=0.214, PPL=336.48
2025-09-21 04:21:57,587 - training.trainer - INFO - Epoch 66, Step 223677: Loss=6.0814, Acc=0.205, PPL=437.64
2025-09-21 04:22:05,579 - training.trainer - INFO - Epoch 66, Step 223777: Loss=6.0301, Acc=0.250, PPL=415.75
2025-09-21 04:22:13,677 - training.trainer - INFO - Epoch 66, Step 223877: Loss=5.4686, Acc=0.343, PPL=237.14
2025-09-21 04:22:21,903 - training.trainer - INFO - Epoch 66, Step 223977: Loss=5.1095, Acc=0.333, PPL=165.58
2025-09-21 04:22:29,909 - training.trainer - INFO - Epoch 66, Step 224077: Loss=4.9856, Acc=0.242, PPL=146.29
2025-09-21 04:22:37,983 - training.trainer - INFO - Epoch 66, Step 224177: Loss=5.6389, Acc=0.250, PPL=281.14
2025-09-21 04:22:46,116 - training.trainer - INFO - Epoch 66, Step 224277: Loss=5.4159, Acc=0.236, PPL=224.95
2025-09-21 04:22:54,179 - training.trainer - INFO - Epoch 66, Step 224377: Loss=3.9583, Acc=0.476, PPL=52.37
2025-09-21 04:23:02,145 - training.trainer - INFO - Epoch 66, Step 224477: Loss=5.3145, Acc=0.241, PPL=203.27
2025-09-21 04:23:10,097 - training.trainer - INFO - Epoch 66, Step 224577: Loss=5.5821, Acc=0.310, PPL=265.64
2025-09-21 04:23:18,052 - training.trainer - INFO - Epoch 66, Step 224677: Loss=5.3836, Acc=0.455, PPL=217.80
2025-09-21 04:23:26,036 - training.trainer - INFO - Epoch 66, Step 224777: Loss=5.1062, Acc=0.324, PPL=165.04
2025-09-21 04:23:33,959 - training.trainer - INFO - Epoch 66, Step 224877: Loss=5.4628, Acc=0.308, PPL=235.76
2025-09-21 04:23:41,884 - training.trainer - INFO - Epoch 66, Step 224977: Loss=5.8939, Acc=0.242, PPL=362.81
2025-09-21 04:23:49,788 - training.trainer - INFO - Epoch 66, Step 225077: Loss=5.9464, Acc=0.259, PPL=382.36
2025-09-21 04:23:57,697 - training.trainer - INFO - Epoch 66, Step 225177: Loss=5.3387, Acc=0.250, PPL=208.24
2025-09-21 04:24:05,653 - training.trainer - INFO - Epoch 66, Step 225277: Loss=5.3703, Acc=0.271, PPL=214.93
2025-09-21 04:24:13,541 - training.trainer - INFO - Epoch 66, Step 225377: Loss=6.3884, Acc=0.233, PPL=594.91
2025-09-21 04:24:21,524 - training.trainer - INFO - Epoch 66, Step 225477: Loss=5.2860, Acc=0.200, PPL=197.54
2025-09-21 04:24:29,444 - training.trainer - INFO - Epoch 66, Step 225577: Loss=6.2198, Acc=0.175, PPL=502.61
2025-09-21 04:24:37,375 - training.trainer - INFO - Epoch 66, Step 225677: Loss=5.4192, Acc=0.216, PPL=225.69
2025-09-21 04:24:45,314 - training.trainer - INFO - Epoch 66, Step 225777: Loss=4.7190, Acc=0.276, PPL=112.06
2025-09-21 04:24:53,247 - training.trainer - INFO - Epoch 66, Step 225877: Loss=6.3134, Acc=0.231, PPL=551.94
2025-09-21 04:25:01,109 - training.trainer - INFO - Epoch 66, Step 225977: Loss=6.3066, Acc=0.200, PPL=548.20
2025-09-21 04:25:09,062 - training.trainer - INFO - Epoch 66, Step 226077: Loss=5.2499, Acc=0.339, PPL=190.54
2025-09-21 04:25:16,940 - training.trainer - INFO - Epoch 66, Step 226177: Loss=6.2435, Acc=0.162, PPL=514.65
2025-09-21 04:25:24,861 - training.trainer - INFO - Epoch 66, Step 226277: Loss=5.5319, Acc=0.306, PPL=252.61
2025-09-21 04:25:32,765 - training.trainer - INFO - Epoch 66, Step 226377: Loss=5.8028, Acc=0.351, PPL=331.24
2025-09-21 04:25:40,731 - training.trainer - INFO - Epoch 66, Step 226477: Loss=5.7250, Acc=0.308, PPL=306.45
2025-09-21 04:25:48,721 - training.trainer - INFO - Epoch 66, Step 226577: Loss=2.9199, Acc=0.769, PPL=18.54
2025-09-21 04:26:06,249 - training.trainer - INFO - Epoch 67/100 completed in 281.39s - Train Loss: 5.4397, Train Acc: 0.287, Val Loss: 5.6861, Val Acc: 0.253
2025-09-21 04:26:14,721 - training.trainer - INFO - Epoch 67, Step 226760: Loss=5.3161, Acc=0.256, PPL=203.59
2025-09-21 04:26:22,821 - training.trainer - INFO - Epoch 67, Step 226860: Loss=5.5759, Acc=0.364, PPL=263.98
2025-09-21 04:26:30,923 - training.trainer - INFO - Epoch 67, Step 226960: Loss=5.9499, Acc=0.236, PPL=383.70
2025-09-21 04:26:39,144 - training.trainer - INFO - Epoch 67, Step 227060: Loss=4.4439, Acc=0.448, PPL=85.11
2025-09-21 04:26:47,188 - training.trainer - INFO - Epoch 67, Step 227160: Loss=5.7008, Acc=0.303, PPL=299.10
2025-09-21 04:26:55,295 - training.trainer - INFO - Epoch 67, Step 227260: Loss=4.5306, Acc=0.286, PPL=92.81
2025-09-21 04:27:03,454 - training.trainer - INFO - Epoch 67, Step 227360: Loss=5.4726, Acc=0.302, PPL=238.08
2025-09-21 04:27:11,514 - training.trainer - INFO - Epoch 67, Step 227460: Loss=5.2519, Acc=0.308, PPL=190.93
2025-09-21 04:27:19,717 - training.trainer - INFO - Epoch 67, Step 227560: Loss=5.7728, Acc=0.306, PPL=321.42
2025-09-21 04:27:27,738 - training.trainer - INFO - Epoch 67, Step 227660: Loss=5.2687, Acc=0.270, PPL=194.16
2025-09-21 04:27:35,805 - training.trainer - INFO - Epoch 67, Step 227760: Loss=6.3733, Acc=0.258, PPL=585.99
2025-09-21 04:27:43,886 - training.trainer - INFO - Epoch 67, Step 227860: Loss=5.8315, Acc=0.233, PPL=340.88
2025-09-21 04:27:52,008 - training.trainer - INFO - Epoch 67, Step 227960: Loss=5.6011, Acc=0.267, PPL=270.73
2025-09-21 04:28:00,183 - training.trainer - INFO - Epoch 67, Step 228060: Loss=5.5720, Acc=0.260, PPL=262.95
2025-09-21 04:28:08,255 - training.trainer - INFO - Epoch 67, Step 228160: Loss=5.3405, Acc=0.375, PPL=208.61
2025-09-21 04:28:16,313 - training.trainer - INFO - Epoch 67, Step 228260: Loss=4.5817, Acc=0.286, PPL=97.68
2025-09-21 04:28:24,262 - training.trainer - INFO - Epoch 67, Step 228360: Loss=6.1867, Acc=0.209, PPL=486.26
2025-09-21 04:28:32,345 - training.trainer - INFO - Epoch 67, Step 228460: Loss=5.6118, Acc=0.194, PPL=273.65
2025-09-21 04:28:40,284 - training.trainer - INFO - Epoch 67, Step 228560: Loss=4.9019, Acc=0.360, PPL=134.54
2025-09-21 04:28:48,208 - training.trainer - INFO - Epoch 67, Step 228660: Loss=5.7663, Acc=0.259, PPL=319.37
2025-09-21 04:28:56,177 - training.trainer - INFO - Epoch 67, Step 228760: Loss=5.2525, Acc=0.290, PPL=191.05
2025-09-21 04:29:04,089 - training.trainer - INFO - Epoch 67, Step 228860: Loss=5.2223, Acc=0.250, PPL=185.35
2025-09-21 04:29:11,881 - training.trainer - INFO - Epoch 67, Step 228960: Loss=5.0592, Acc=0.259, PPL=157.46
2025-09-21 04:29:19,784 - training.trainer - INFO - Epoch 67, Step 229060: Loss=5.6429, Acc=0.269, PPL=282.27
2025-09-21 04:29:27,615 - training.trainer - INFO - Epoch 67, Step 229160: Loss=5.6567, Acc=0.243, PPL=286.20
2025-09-21 04:29:35,559 - training.trainer - INFO - Epoch 67, Step 229260: Loss=5.9988, Acc=0.208, PPL=402.96
2025-09-21 04:29:43,397 - training.trainer - INFO - Epoch 67, Step 229360: Loss=6.0894, Acc=0.256, PPL=441.14
2025-09-21 04:29:51,210 - training.trainer - INFO - Epoch 67, Step 229460: Loss=5.6140, Acc=0.200, PPL=274.24
2025-09-21 04:29:59,058 - training.trainer - INFO - Epoch 67, Step 229560: Loss=4.8406, Acc=0.385, PPL=126.54
2025-09-21 04:30:07,168 - training.trainer - INFO - Epoch 67, Step 229660: Loss=5.3585, Acc=0.293, PPL=212.41
2025-09-21 04:30:15,082 - training.trainer - INFO - Epoch 67, Step 229760: Loss=5.1062, Acc=0.368, PPL=165.03
2025-09-21 04:30:22,937 - training.trainer - INFO - Epoch 67, Step 229860: Loss=5.4946, Acc=0.343, PPL=243.38
2025-09-21 04:30:30,799 - training.trainer - INFO - Epoch 67, Step 229960: Loss=5.3001, Acc=0.208, PPL=200.37
2025-09-21 04:30:48,293 - training.trainer - INFO - Epoch 68/100 completed in 282.04s - Train Loss: 5.4327, Train Acc: 0.288, Val Loss: 5.6818, Val Acc: 0.255
2025-09-21 04:30:56,737 - training.trainer - INFO - Epoch 68, Step 230143: Loss=6.4278, Acc=0.182, PPL=618.84
2025-09-21 04:31:04,740 - training.trainer - INFO - Epoch 68, Step 230243: Loss=5.7692, Acc=0.280, PPL=320.27
2025-09-21 04:31:12,741 - training.trainer - INFO - Epoch 68, Step 230343: Loss=5.9881, Acc=0.294, PPL=398.64
2025-09-21 04:31:20,736 - training.trainer - INFO - Epoch 68, Step 230443: Loss=6.4153, Acc=0.203, PPL=611.13
2025-09-21 04:31:28,776 - training.trainer - INFO - Epoch 68, Step 230543: Loss=5.2843, Acc=0.244, PPL=197.21
2025-09-21 04:31:36,764 - training.trainer - INFO - Epoch 68, Step 230643: Loss=4.8708, Acc=0.269, PPL=130.43
2025-09-21 04:31:44,846 - training.trainer - INFO - Epoch 68, Step 230743: Loss=5.2466, Acc=0.326, PPL=189.92
2025-09-21 04:31:52,869 - training.trainer - INFO - Epoch 68, Step 230843: Loss=4.8750, Acc=0.278, PPL=130.97
2025-09-21 04:32:00,846 - training.trainer - INFO - Epoch 68, Step 230943: Loss=3.7707, Acc=0.435, PPL=43.41
2025-09-21 04:32:08,873 - training.trainer - INFO - Epoch 68, Step 231043: Loss=6.2223, Acc=0.184, PPL=503.85
2025-09-21 04:32:16,893 - training.trainer - INFO - Epoch 68, Step 231143: Loss=6.1046, Acc=0.267, PPL=447.90
2025-09-21 04:32:24,874 - training.trainer - INFO - Epoch 68, Step 231243: Loss=5.7903, Acc=0.277, PPL=327.10
2025-09-21 04:32:32,856 - training.trainer - INFO - Epoch 68, Step 231343: Loss=5.6130, Acc=0.258, PPL=273.97
2025-09-21 04:32:40,835 - training.trainer - INFO - Epoch 68, Step 231443: Loss=5.4444, Acc=0.232, PPL=231.46
2025-09-21 04:32:48,848 - training.trainer - INFO - Epoch 68, Step 231543: Loss=5.5332, Acc=0.220, PPL=252.96
2025-09-21 04:32:56,806 - training.trainer - INFO - Epoch 68, Step 231643: Loss=5.4184, Acc=0.212, PPL=225.51
2025-09-21 04:33:04,805 - training.trainer - INFO - Epoch 68, Step 231743: Loss=5.5213, Acc=0.269, PPL=249.96
2025-09-21 04:33:12,811 - training.trainer - INFO - Epoch 68, Step 231843: Loss=5.3516, Acc=0.279, PPL=210.94
2025-09-21 04:33:20,811 - training.trainer - INFO - Epoch 68, Step 231943: Loss=6.5114, Acc=0.226, PPL=672.77
2025-09-21 04:33:28,769 - training.trainer - INFO - Epoch 68, Step 232043: Loss=5.1939, Acc=0.256, PPL=180.17
2025-09-21 04:33:36,798 - training.trainer - INFO - Epoch 68, Step 232143: Loss=5.5335, Acc=0.235, PPL=253.02
2025-09-21 04:33:44,755 - training.trainer - INFO - Epoch 68, Step 232243: Loss=5.5225, Acc=0.320, PPL=250.26
2025-09-21 04:33:52,673 - training.trainer - INFO - Epoch 68, Step 232343: Loss=5.5919, Acc=0.250, PPL=268.24
2025-09-21 04:34:00,624 - training.trainer - INFO - Epoch 68, Step 232443: Loss=4.8109, Acc=0.333, PPL=122.84
2025-09-21 04:34:08,561 - training.trainer - INFO - Epoch 68, Step 232543: Loss=6.2346, Acc=0.226, PPL=510.09
2025-09-21 04:34:16,492 - training.trainer - INFO - Epoch 68, Step 232643: Loss=4.7809, Acc=0.292, PPL=119.21
2025-09-21 04:34:24,458 - training.trainer - INFO - Epoch 68, Step 232743: Loss=5.6076, Acc=0.333, PPL=272.48
2025-09-21 04:34:32,367 - training.trainer - INFO - Epoch 68, Step 232843: Loss=5.7942, Acc=0.233, PPL=328.38
2025-09-21 04:34:40,315 - training.trainer - INFO - Epoch 68, Step 232943: Loss=5.5034, Acc=0.200, PPL=245.52
2025-09-21 04:34:48,221 - training.trainer - INFO - Epoch 68, Step 233043: Loss=6.1106, Acc=0.281, PPL=450.60
2025-09-21 04:34:56,146 - training.trainer - INFO - Epoch 68, Step 233143: Loss=5.3658, Acc=0.288, PPL=213.97
2025-09-21 04:35:04,176 - training.trainer - INFO - Epoch 68, Step 233243: Loss=6.3136, Acc=0.269, PPL=552.03
2025-09-21 04:35:12,111 - training.trainer - INFO - Epoch 68, Step 233343: Loss=4.3625, Acc=0.312, PPL=78.45
2025-09-21 04:35:29,668 - training.trainer - INFO - Epoch 69/100 completed in 281.37s - Train Loss: 5.4279, Train Acc: 0.288, Val Loss: 5.6901, Val Acc: 0.252
2025-09-21 04:35:38,199 - training.trainer - INFO - Epoch 69, Step 233526: Loss=6.3159, Acc=0.222, PPL=553.30
2025-09-21 04:35:46,309 - training.trainer - INFO - Epoch 69, Step 233626: Loss=5.8782, Acc=0.229, PPL=357.16
2025-09-21 04:35:54,399 - training.trainer - INFO - Epoch 69, Step 233726: Loss=5.7583, Acc=0.264, PPL=316.81
2025-09-21 04:36:02,430 - training.trainer - INFO - Epoch 69, Step 233826: Loss=4.1825, Acc=0.429, PPL=65.53
2025-09-21 04:36:10,478 - training.trainer - INFO - Epoch 69, Step 233926: Loss=4.3740, Acc=0.500, PPL=79.36
2025-09-21 04:36:18,463 - training.trainer - INFO - Epoch 69, Step 234026: Loss=4.9523, Acc=0.206, PPL=141.50
2025-09-21 04:36:26,399 - training.trainer - INFO - Epoch 69, Step 234126: Loss=5.1482, Acc=0.318, PPL=172.12
2025-09-21 04:36:34,323 - training.trainer - INFO - Epoch 69, Step 234226: Loss=4.4366, Acc=0.409, PPL=84.49
2025-09-21 04:36:42,326 - training.trainer - INFO - Epoch 69, Step 234326: Loss=5.8553, Acc=0.182, PPL=349.08
2025-09-21 04:36:50,377 - training.trainer - INFO - Epoch 69, Step 234426: Loss=5.9982, Acc=0.230, PPL=402.70
2025-09-21 04:36:58,266 - training.trainer - INFO - Epoch 69, Step 234526: Loss=5.6996, Acc=0.297, PPL=298.76
2025-09-21 04:37:06,124 - training.trainer - INFO - Epoch 69, Step 234626: Loss=5.0023, Acc=0.222, PPL=148.76
2025-09-21 04:37:14,109 - training.trainer - INFO - Epoch 69, Step 234726: Loss=5.3768, Acc=0.300, PPL=216.32
2025-09-21 04:37:21,953 - training.trainer - INFO - Epoch 69, Step 234826: Loss=6.0900, Acc=0.259, PPL=441.43
2025-09-21 04:37:29,854 - training.trainer - INFO - Epoch 69, Step 234926: Loss=4.9524, Acc=0.394, PPL=141.51
2025-09-21 04:37:37,747 - training.trainer - INFO - Epoch 69, Step 235026: Loss=6.0272, Acc=0.247, PPL=414.56
2025-09-21 04:37:45,656 - training.trainer - INFO - Epoch 69, Step 235126: Loss=5.3934, Acc=0.370, PPL=219.95
2025-09-21 04:37:53,580 - training.trainer - INFO - Epoch 69, Step 235226: Loss=5.6391, Acc=0.278, PPL=281.20
2025-09-21 04:38:01,540 - training.trainer - INFO - Epoch 69, Step 235326: Loss=4.8247, Acc=0.386, PPL=124.54
2025-09-21 04:38:09,511 - training.trainer - INFO - Epoch 69, Step 235426: Loss=5.1443, Acc=0.370, PPL=171.45
2025-09-21 04:38:17,482 - training.trainer - INFO - Epoch 69, Step 235526: Loss=5.3785, Acc=0.409, PPL=216.69
2025-09-21 04:38:25,492 - training.trainer - INFO - Epoch 69, Step 235626: Loss=5.3481, Acc=0.339, PPL=210.20
2025-09-21 04:38:33,487 - training.trainer - INFO - Epoch 69, Step 235726: Loss=5.1806, Acc=0.394, PPL=177.79
2025-09-21 04:38:41,667 - training.trainer - INFO - Epoch 69, Step 235826: Loss=4.5765, Acc=0.318, PPL=97.18
2025-09-21 04:38:49,779 - training.trainer - INFO - Epoch 69, Step 235926: Loss=5.6510, Acc=0.250, PPL=284.56
2025-09-21 04:38:57,916 - training.trainer - INFO - Epoch 69, Step 236026: Loss=6.5449, Acc=0.186, PPL=695.68
2025-09-21 04:39:06,033 - training.trainer - INFO - Epoch 69, Step 236126: Loss=5.4527, Acc=0.300, PPL=233.40
2025-09-21 04:39:14,230 - training.trainer - INFO - Epoch 69, Step 236226: Loss=5.7972, Acc=0.216, PPL=329.37
2025-09-21 04:39:22,256 - training.trainer - INFO - Epoch 69, Step 236326: Loss=4.1653, Acc=0.235, PPL=64.41
2025-09-21 04:39:30,234 - training.trainer - INFO - Epoch 69, Step 236426: Loss=5.3770, Acc=0.261, PPL=216.37
2025-09-21 04:39:38,103 - training.trainer - INFO - Epoch 69, Step 236526: Loss=5.1018, Acc=0.286, PPL=164.31
2025-09-21 04:39:46,021 - training.trainer - INFO - Epoch 69, Step 236626: Loss=6.1391, Acc=0.171, PPL=463.63
2025-09-21 04:39:53,914 - training.trainer - INFO - Epoch 69, Step 236726: Loss=4.5066, Acc=0.404, PPL=90.61
2025-09-21 04:40:10,493 - training.trainer - INFO - Epoch 70/100 completed in 280.82s - Train Loss: 5.4230, Train Acc: 0.290, Val Loss: 5.6775, Val Acc: 0.255
2025-09-21 04:40:10,846 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_70.pt
2025-09-21 04:40:19,212 - training.trainer - INFO - Epoch 70, Step 236909: Loss=6.0410, Acc=0.214, PPL=420.32
2025-09-21 04:40:27,352 - training.trainer - INFO - Epoch 70, Step 237009: Loss=4.6646, Acc=0.435, PPL=106.13
2025-09-21 04:40:35,447 - training.trainer - INFO - Epoch 70, Step 237109: Loss=5.4820, Acc=0.256, PPL=240.32
2025-09-21 04:40:43,479 - training.trainer - INFO - Epoch 70, Step 237209: Loss=5.5896, Acc=0.300, PPL=267.64
2025-09-21 04:40:51,557 - training.trainer - INFO - Epoch 70, Step 237309: Loss=6.1268, Acc=0.231, PPL=457.98
2025-09-21 04:40:59,649 - training.trainer - INFO - Epoch 70, Step 237409: Loss=4.8705, Acc=0.250, PPL=130.39
2025-09-21 04:41:07,728 - training.trainer - INFO - Epoch 70, Step 237509: Loss=5.9117, Acc=0.275, PPL=369.34
2025-09-21 04:41:15,993 - training.trainer - INFO - Epoch 70, Step 237609: Loss=5.2082, Acc=0.290, PPL=182.77
2025-09-21 04:41:23,991 - training.trainer - INFO - Epoch 70, Step 237709: Loss=5.8476, Acc=0.235, PPL=346.39
2025-09-21 04:41:31,945 - training.trainer - INFO - Epoch 70, Step 237809: Loss=5.2604, Acc=0.194, PPL=192.56
2025-09-21 04:41:40,105 - training.trainer - INFO - Epoch 70, Step 237909: Loss=5.3671, Acc=0.255, PPL=214.23
2025-09-21 04:41:48,161 - training.trainer - INFO - Epoch 70, Step 238009: Loss=5.1170, Acc=0.280, PPL=166.84
2025-09-21 04:41:56,259 - training.trainer - INFO - Epoch 70, Step 238109: Loss=6.1135, Acc=0.203, PPL=451.91
2025-09-21 04:42:04,115 - training.trainer - INFO - Epoch 70, Step 238209: Loss=5.6846, Acc=0.237, PPL=294.31
2025-09-21 04:42:12,023 - training.trainer - INFO - Epoch 70, Step 238309: Loss=6.1401, Acc=0.219, PPL=464.11
2025-09-21 04:42:19,942 - training.trainer - INFO - Epoch 70, Step 238409: Loss=4.9214, Acc=0.318, PPL=137.19
2025-09-21 04:42:27,989 - training.trainer - INFO - Epoch 70, Step 238509: Loss=6.0151, Acc=0.276, PPL=409.55
2025-09-21 04:42:36,003 - training.trainer - INFO - Epoch 70, Step 238609: Loss=5.5412, Acc=0.258, PPL=254.99
2025-09-21 04:42:43,996 - training.trainer - INFO - Epoch 70, Step 238709: Loss=5.3092, Acc=0.267, PPL=202.19
2025-09-21 04:42:51,966 - training.trainer - INFO - Epoch 70, Step 238809: Loss=5.8324, Acc=0.309, PPL=341.19
2025-09-21 04:42:59,967 - training.trainer - INFO - Epoch 70, Step 238909: Loss=5.6330, Acc=0.306, PPL=279.49
2025-09-21 04:43:07,984 - training.trainer - INFO - Epoch 70, Step 239009: Loss=4.5556, Acc=0.391, PPL=95.16
2025-09-21 04:43:16,069 - training.trainer - INFO - Epoch 70, Step 239109: Loss=5.2440, Acc=0.294, PPL=189.42
2025-09-21 04:43:24,182 - training.trainer - INFO - Epoch 70, Step 239209: Loss=4.5560, Acc=0.390, PPL=95.21
2025-09-21 04:43:32,347 - training.trainer - INFO - Epoch 70, Step 239309: Loss=5.0775, Acc=0.297, PPL=160.37
2025-09-21 04:43:40,419 - training.trainer - INFO - Epoch 70, Step 239409: Loss=5.6405, Acc=0.259, PPL=281.61
2025-09-21 04:43:48,560 - training.trainer - INFO - Epoch 70, Step 239509: Loss=4.8661, Acc=0.300, PPL=129.82
2025-09-21 04:43:56,674 - training.trainer - INFO - Epoch 70, Step 239609: Loss=5.2321, Acc=0.296, PPL=187.19
2025-09-21 04:44:04,823 - training.trainer - INFO - Epoch 70, Step 239709: Loss=5.5517, Acc=0.357, PPL=257.67
2025-09-21 04:44:12,918 - training.trainer - INFO - Epoch 70, Step 239809: Loss=5.9814, Acc=0.213, PPL=395.98
2025-09-21 04:44:20,989 - training.trainer - INFO - Epoch 70, Step 239909: Loss=5.9850, Acc=0.244, PPL=397.42
2025-09-21 04:44:28,964 - training.trainer - INFO - Epoch 70, Step 240009: Loss=5.9560, Acc=0.167, PPL=386.08
2025-09-21 04:44:36,925 - training.trainer - INFO - Epoch 70, Step 240109: Loss=5.6645, Acc=0.250, PPL=288.45
2025-09-21 04:44:53,903 - training.trainer - INFO - Epoch 71/100 completed in 283.06s - Train Loss: 5.4190, Train Acc: 0.291, Val Loss: 5.6837, Val Acc: 0.255
2025-09-21 04:45:02,083 - training.trainer - INFO - Epoch 71, Step 240292: Loss=5.4830, Acc=0.208, PPL=240.56
2025-09-21 04:45:10,071 - training.trainer - INFO - Epoch 71, Step 240392: Loss=4.7595, Acc=0.238, PPL=116.69
2025-09-21 04:45:18,016 - training.trainer - INFO - Epoch 71, Step 240492: Loss=5.5567, Acc=0.273, PPL=258.96
2025-09-21 04:45:26,147 - training.trainer - INFO - Epoch 71, Step 240592: Loss=5.1315, Acc=0.286, PPL=169.27
2025-09-21 04:45:34,145 - training.trainer - INFO - Epoch 71, Step 240692: Loss=6.0102, Acc=0.185, PPL=407.58
2025-09-21 04:45:42,081 - training.trainer - INFO - Epoch 71, Step 240792: Loss=6.0172, Acc=0.192, PPL=410.42
2025-09-21 04:45:49,974 - training.trainer - INFO - Epoch 71, Step 240892: Loss=6.4575, Acc=0.225, PPL=637.49
2025-09-21 04:45:57,876 - training.trainer - INFO - Epoch 71, Step 240992: Loss=5.7480, Acc=0.175, PPL=313.57
2025-09-21 04:46:05,823 - training.trainer - INFO - Epoch 71, Step 241092: Loss=5.9360, Acc=0.241, PPL=378.43
2025-09-21 04:46:13,801 - training.trainer - INFO - Epoch 71, Step 241192: Loss=5.7276, Acc=0.227, PPL=307.23
2025-09-21 04:46:21,748 - training.trainer - INFO - Epoch 71, Step 241292: Loss=5.9832, Acc=0.108, PPL=396.72
2025-09-21 04:46:29,670 - training.trainer - INFO - Epoch 71, Step 241392: Loss=5.8153, Acc=0.211, PPL=335.39
2025-09-21 04:46:37,602 - training.trainer - INFO - Epoch 71, Step 241492: Loss=5.6497, Acc=0.245, PPL=284.20
2025-09-21 04:46:45,491 - training.trainer - INFO - Epoch 71, Step 241592: Loss=3.0846, Acc=0.571, PPL=21.86
2025-09-21 04:46:53,416 - training.trainer - INFO - Epoch 71, Step 241692: Loss=6.2531, Acc=0.182, PPL=519.64
2025-09-21 04:47:01,310 - training.trainer - INFO - Epoch 71, Step 241792: Loss=6.0853, Acc=0.164, PPL=439.35
2025-09-21 04:47:09,244 - training.trainer - INFO - Epoch 71, Step 241892: Loss=5.2664, Acc=0.308, PPL=193.73
2025-09-21 04:47:17,155 - training.trainer - INFO - Epoch 71, Step 241992: Loss=3.4806, Acc=0.609, PPL=32.48
2025-09-21 04:47:25,080 - training.trainer - INFO - Epoch 71, Step 242092: Loss=6.1993, Acc=0.259, PPL=492.42
2025-09-21 04:47:32,998 - training.trainer - INFO - Epoch 71, Step 242192: Loss=5.2573, Acc=0.292, PPL=191.97
2025-09-21 04:47:40,968 - training.trainer - INFO - Epoch 71, Step 242292: Loss=4.9155, Acc=0.250, PPL=136.39
2025-09-21 04:47:48,954 - training.trainer - INFO - Epoch 71, Step 242392: Loss=6.1299, Acc=0.217, PPL=459.41
2025-09-21 04:47:56,922 - training.trainer - INFO - Epoch 71, Step 242492: Loss=6.2093, Acc=0.263, PPL=497.36
2025-09-21 04:48:04,849 - training.trainer - INFO - Epoch 71, Step 242592: Loss=5.0696, Acc=0.299, PPL=159.10
2025-09-21 04:48:12,801 - training.trainer - INFO - Epoch 71, Step 242692: Loss=5.9311, Acc=0.308, PPL=376.56
2025-09-21 04:48:20,722 - training.trainer - INFO - Epoch 71, Step 242792: Loss=5.6399, Acc=0.211, PPL=281.44
2025-09-21 04:48:28,716 - training.trainer - INFO - Epoch 71, Step 242892: Loss=4.7442, Acc=0.316, PPL=114.92
2025-09-21 04:48:36,718 - training.trainer - INFO - Epoch 71, Step 242992: Loss=5.7971, Acc=0.214, PPL=329.33
2025-09-21 04:48:44,718 - training.trainer - INFO - Epoch 71, Step 243092: Loss=6.0477, Acc=0.173, PPL=423.14
2025-09-21 04:48:52,689 - training.trainer - INFO - Epoch 71, Step 243192: Loss=5.4067, Acc=0.326, PPL=222.88
2025-09-21 04:49:00,766 - training.trainer - INFO - Epoch 71, Step 243292: Loss=5.2615, Acc=0.387, PPL=192.77
2025-09-21 04:49:08,684 - training.trainer - INFO - Epoch 71, Step 243392: Loss=6.0037, Acc=0.239, PPL=404.92
2025-09-21 04:49:16,611 - training.trainer - INFO - Epoch 71, Step 243492: Loss=6.0720, Acc=0.224, PPL=433.55
2025-09-21 04:49:33,307 - training.trainer - INFO - Epoch 72/100 completed in 279.40s - Train Loss: 5.4194, Train Acc: 0.290, Val Loss: 5.6851, Val Acc: 0.254
2025-09-21 04:49:40,835 - training.trainer - INFO - Epoch 72, Step 243675: Loss=5.7322, Acc=0.183, PPL=308.66
2025-09-21 04:49:48,841 - training.trainer - INFO - Epoch 72, Step 243775: Loss=6.2058, Acc=0.204, PPL=495.59
2025-09-21 04:49:56,774 - training.trainer - INFO - Epoch 72, Step 243875: Loss=5.1635, Acc=0.297, PPL=174.77
2025-09-21 04:50:04,842 - training.trainer - INFO - Epoch 72, Step 243975: Loss=5.5843, Acc=0.294, PPL=266.21
2025-09-21 04:50:12,897 - training.trainer - INFO - Epoch 72, Step 244075: Loss=6.0968, Acc=0.206, PPL=444.45
2025-09-21 04:50:20,914 - training.trainer - INFO - Epoch 72, Step 244175: Loss=4.6965, Acc=0.371, PPL=109.56
2025-09-21 04:50:28,851 - training.trainer - INFO - Epoch 72, Step 244275: Loss=4.7758, Acc=0.360, PPL=118.61
2025-09-21 04:50:36,749 - training.trainer - INFO - Epoch 72, Step 244375: Loss=5.2818, Acc=0.318, PPL=196.73
2025-09-21 04:50:44,652 - training.trainer - INFO - Epoch 72, Step 244475: Loss=6.0882, Acc=0.182, PPL=440.65
2025-09-21 04:50:52,605 - training.trainer - INFO - Epoch 72, Step 244575: Loss=5.9829, Acc=0.242, PPL=396.57
2025-09-21 04:51:00,535 - training.trainer - INFO - Epoch 72, Step 244675: Loss=5.5494, Acc=0.250, PPL=257.07
2025-09-21 04:51:08,500 - training.trainer - INFO - Epoch 72, Step 244775: Loss=5.1388, Acc=0.382, PPL=170.51
2025-09-21 04:51:16,513 - training.trainer - INFO - Epoch 72, Step 244875: Loss=4.9815, Acc=0.483, PPL=145.69
2025-09-21 04:51:24,480 - training.trainer - INFO - Epoch 72, Step 244975: Loss=5.4406, Acc=0.333, PPL=230.58
2025-09-21 04:51:32,502 - training.trainer - INFO - Epoch 72, Step 245075: Loss=4.6965, Acc=0.333, PPL=109.57
2025-09-21 04:51:40,498 - training.trainer - INFO - Epoch 72, Step 245175: Loss=6.1316, Acc=0.200, PPL=460.19
2025-09-21 04:51:48,499 - training.trainer - INFO - Epoch 72, Step 245275: Loss=5.6515, Acc=0.333, PPL=284.72
2025-09-21 04:51:56,448 - training.trainer - INFO - Epoch 72, Step 245375: Loss=6.1881, Acc=0.172, PPL=486.91
2025-09-21 04:52:04,393 - training.trainer - INFO - Epoch 72, Step 245475: Loss=5.8725, Acc=0.286, PPL=355.15
2025-09-21 04:52:12,364 - training.trainer - INFO - Epoch 72, Step 245575: Loss=5.6846, Acc=0.300, PPL=294.30
2025-09-21 04:52:20,322 - training.trainer - INFO - Epoch 72, Step 245675: Loss=5.3515, Acc=0.312, PPL=210.93
2025-09-21 04:52:28,304 - training.trainer - INFO - Epoch 72, Step 245775: Loss=5.1120, Acc=0.316, PPL=166.00
2025-09-21 04:52:36,279 - training.trainer - INFO - Epoch 72, Step 245875: Loss=5.0290, Acc=0.308, PPL=152.79
2025-09-21 04:52:44,298 - training.trainer - INFO - Epoch 72, Step 245975: Loss=6.1746, Acc=0.220, PPL=480.38
2025-09-21 04:52:52,312 - training.trainer - INFO - Epoch 72, Step 246075: Loss=4.8636, Acc=0.372, PPL=129.49
2025-09-21 04:53:00,272 - training.trainer - INFO - Epoch 72, Step 246175: Loss=6.3350, Acc=0.314, PPL=563.98
2025-09-21 04:53:08,319 - training.trainer - INFO - Epoch 72, Step 246275: Loss=3.6836, Acc=0.462, PPL=39.79
2025-09-21 04:53:16,312 - training.trainer - INFO - Epoch 72, Step 246375: Loss=5.5493, Acc=0.324, PPL=257.06
2025-09-21 04:53:24,259 - training.trainer - INFO - Epoch 72, Step 246475: Loss=5.7864, Acc=0.341, PPL=325.85
2025-09-21 04:53:32,286 - training.trainer - INFO - Epoch 72, Step 246575: Loss=4.4860, Acc=0.424, PPL=88.76
2025-09-21 04:53:40,367 - training.trainer - INFO - Epoch 72, Step 246675: Loss=5.4244, Acc=0.357, PPL=226.86
2025-09-21 04:53:48,336 - training.trainer - INFO - Epoch 72, Step 246775: Loss=5.6065, Acc=0.407, PPL=272.19
2025-09-21 04:53:56,300 - training.trainer - INFO - Epoch 72, Step 246875: Loss=6.0298, Acc=0.325, PPL=415.64
2025-09-21 04:54:13,900 - training.trainer - INFO - Epoch 73/100 completed in 280.59s - Train Loss: 5.4144, Train Acc: 0.291, Val Loss: 5.6811, Val Acc: 0.255
2025-09-21 04:54:22,063 - training.trainer - INFO - Epoch 73, Step 247058: Loss=5.3269, Acc=0.268, PPL=205.80
2025-09-21 04:54:29,998 - training.trainer - INFO - Epoch 73, Step 247158: Loss=5.8481, Acc=0.186, PPL=346.57
2025-09-21 04:54:37,985 - training.trainer - INFO - Epoch 73, Step 247258: Loss=6.0666, Acc=0.217, PPL=431.22
2025-09-21 04:54:46,023 - training.trainer - INFO - Epoch 73, Step 247358: Loss=5.7418, Acc=0.367, PPL=311.64
2025-09-21 04:54:54,052 - training.trainer - INFO - Epoch 73, Step 247458: Loss=5.7648, Acc=0.318, PPL=318.86
2025-09-21 04:55:01,962 - training.trainer - INFO - Epoch 73, Step 247558: Loss=6.0067, Acc=0.200, PPL=406.15
2025-09-21 04:55:09,845 - training.trainer - INFO - Epoch 73, Step 247658: Loss=5.6228, Acc=0.262, PPL=276.68
2025-09-21 04:55:17,865 - training.trainer - INFO - Epoch 73, Step 247758: Loss=5.2586, Acc=0.292, PPL=192.21
2025-09-21 04:55:25,872 - training.trainer - INFO - Epoch 73, Step 247858: Loss=6.1808, Acc=0.164, PPL=483.39
2025-09-21 04:55:33,747 - training.trainer - INFO - Epoch 73, Step 247958: Loss=5.6322, Acc=0.333, PPL=279.28
2025-09-21 04:55:41,713 - training.trainer - INFO - Epoch 73, Step 248058: Loss=5.5871, Acc=0.206, PPL=266.96
2025-09-21 04:55:49,607 - training.trainer - INFO - Epoch 73, Step 248158: Loss=4.5916, Acc=0.368, PPL=98.65
2025-09-21 04:55:57,586 - training.trainer - INFO - Epoch 73, Step 248258: Loss=5.6250, Acc=0.222, PPL=277.28
2025-09-21 04:56:05,735 - training.trainer - INFO - Epoch 73, Step 248358: Loss=5.6300, Acc=0.235, PPL=278.66
2025-09-21 04:56:13,850 - training.trainer - INFO - Epoch 73, Step 248458: Loss=5.8951, Acc=0.183, PPL=363.24
2025-09-21 04:56:21,815 - training.trainer - INFO - Epoch 73, Step 248558: Loss=5.5990, Acc=0.321, PPL=270.15
2025-09-21 04:56:29,876 - training.trainer - INFO - Epoch 73, Step 248658: Loss=5.2929, Acc=0.256, PPL=198.92
2025-09-21 04:56:37,976 - training.trainer - INFO - Epoch 73, Step 248758: Loss=5.5894, Acc=0.306, PPL=267.58
2025-09-21 04:56:46,044 - training.trainer - INFO - Epoch 73, Step 248858: Loss=6.1509, Acc=0.280, PPL=469.12
2025-09-21 04:56:54,107 - training.trainer - INFO - Epoch 73, Step 248958: Loss=5.3580, Acc=0.333, PPL=212.31
2025-09-21 04:57:02,012 - training.trainer - INFO - Epoch 73, Step 249058: Loss=4.6098, Acc=0.423, PPL=100.47
2025-09-21 04:57:09,905 - training.trainer - INFO - Epoch 73, Step 249158: Loss=4.8338, Acc=0.286, PPL=125.69
2025-09-21 04:57:17,791 - training.trainer - INFO - Epoch 73, Step 249258: Loss=5.3495, Acc=0.188, PPL=210.50
2025-09-21 04:57:25,715 - training.trainer - INFO - Epoch 73, Step 249358: Loss=5.4067, Acc=0.280, PPL=222.90
2025-09-21 04:57:33,800 - training.trainer - INFO - Epoch 73, Step 249458: Loss=4.9455, Acc=0.391, PPL=140.55
2025-09-21 04:57:41,924 - training.trainer - INFO - Epoch 73, Step 249558: Loss=6.3246, Acc=0.222, PPL=558.13
2025-09-21 04:57:50,043 - training.trainer - INFO - Epoch 73, Step 249658: Loss=5.1693, Acc=0.333, PPL=175.80
2025-09-21 04:57:58,009 - training.trainer - INFO - Epoch 73, Step 249758: Loss=5.6786, Acc=0.258, PPL=292.54
2025-09-21 04:58:06,128 - training.trainer - INFO - Epoch 73, Step 249858: Loss=6.3580, Acc=0.172, PPL=577.12
2025-09-21 04:58:14,360 - training.trainer - INFO - Epoch 73, Step 249958: Loss=4.8102, Acc=0.250, PPL=122.76
2025-09-21 04:58:22,503 - training.trainer - INFO - Epoch 73, Step 250058: Loss=5.7852, Acc=0.175, PPL=325.44
2025-09-21 04:58:30,462 - training.trainer - INFO - Epoch 73, Step 250158: Loss=5.7609, Acc=0.208, PPL=317.63
2025-09-21 04:58:38,425 - training.trainer - INFO - Epoch 73, Step 250258: Loss=5.5352, Acc=0.423, PPL=253.45
2025-09-21 04:58:55,312 - training.trainer - INFO - Epoch 74/100 completed in 281.41s - Train Loss: 5.4096, Train Acc: 0.292, Val Loss: 5.6848, Val Acc: 0.256
2025-09-21 04:59:03,746 - training.trainer - INFO - Epoch 74, Step 250441: Loss=5.6870, Acc=0.267, PPL=295.01
2025-09-21 04:59:11,879 - training.trainer - INFO - Epoch 74, Step 250541: Loss=5.3606, Acc=0.308, PPL=212.85
2025-09-21 04:59:20,017 - training.trainer - INFO - Epoch 74, Step 250641: Loss=6.1113, Acc=0.196, PPL=450.93
2025-09-21 04:59:28,073 - training.trainer - INFO - Epoch 74, Step 250741: Loss=5.8768, Acc=0.227, PPL=356.68
2025-09-21 04:59:36,232 - training.trainer - INFO - Epoch 74, Step 250841: Loss=5.3536, Acc=0.286, PPL=211.37
2025-09-21 04:59:44,211 - training.trainer - INFO - Epoch 74, Step 250941: Loss=5.8838, Acc=0.293, PPL=359.15
2025-09-21 04:59:52,332 - training.trainer - INFO - Epoch 74, Step 251041: Loss=5.4560, Acc=0.321, PPL=234.16
2025-09-21 05:00:00,597 - training.trainer - INFO - Epoch 74, Step 251141: Loss=5.0488, Acc=0.364, PPL=155.83
2025-09-21 05:00:08,755 - training.trainer - INFO - Epoch 74, Step 251241: Loss=5.3831, Acc=0.289, PPL=217.69
2025-09-21 05:00:16,837 - training.trainer - INFO - Epoch 74, Step 251341: Loss=5.7322, Acc=0.227, PPL=308.65
2025-09-21 05:00:24,935 - training.trainer - INFO - Epoch 74, Step 251441: Loss=4.6351, Acc=0.385, PPL=103.04
2025-09-21 05:00:33,075 - training.trainer - INFO - Epoch 74, Step 251541: Loss=5.9137, Acc=0.235, PPL=370.05
2025-09-21 05:00:41,063 - training.trainer - INFO - Epoch 74, Step 251641: Loss=5.0991, Acc=0.343, PPL=163.88
2025-09-21 05:00:49,078 - training.trainer - INFO - Epoch 74, Step 251741: Loss=4.6197, Acc=0.346, PPL=101.47
2025-09-21 05:00:57,162 - training.trainer - INFO - Epoch 74, Step 251841: Loss=4.6648, Acc=0.357, PPL=106.14
2025-09-21 05:01:05,236 - training.trainer - INFO - Epoch 74, Step 251941: Loss=5.9416, Acc=0.235, PPL=380.55
2025-09-21 05:01:13,227 - training.trainer - INFO - Epoch 74, Step 252041: Loss=4.5690, Acc=0.452, PPL=96.45
2025-09-21 05:01:21,243 - training.trainer - INFO - Epoch 74, Step 252141: Loss=5.8335, Acc=0.319, PPL=341.54
2025-09-21 05:01:29,247 - training.trainer - INFO - Epoch 74, Step 252241: Loss=5.6225, Acc=0.265, PPL=276.57
2025-09-21 05:01:37,377 - training.trainer - INFO - Epoch 74, Step 252341: Loss=5.5212, Acc=0.296, PPL=249.95
2025-09-21 05:01:45,562 - training.trainer - INFO - Epoch 74, Step 252441: Loss=6.0148, Acc=0.246, PPL=409.46
2025-09-21 05:01:53,572 - training.trainer - INFO - Epoch 74, Step 252541: Loss=5.5364, Acc=0.280, PPL=253.77
2025-09-21 05:02:01,586 - training.trainer - INFO - Epoch 74, Step 252641: Loss=5.5839, Acc=0.317, PPL=266.11
2025-09-21 05:02:09,763 - training.trainer - INFO - Epoch 74, Step 252741: Loss=5.9191, Acc=0.245, PPL=372.07
2025-09-21 05:02:17,809 - training.trainer - INFO - Epoch 74, Step 252841: Loss=5.8195, Acc=0.288, PPL=336.81
2025-09-21 05:02:25,866 - training.trainer - INFO - Epoch 74, Step 252941: Loss=4.4460, Acc=0.362, PPL=85.28
2025-09-21 05:02:33,945 - training.trainer - INFO - Epoch 74, Step 253041: Loss=5.7237, Acc=0.323, PPL=306.04
2025-09-21 05:02:42,078 - training.trainer - INFO - Epoch 74, Step 253141: Loss=4.3206, Acc=0.300, PPL=75.24
2025-09-21 05:02:50,120 - training.trainer - INFO - Epoch 74, Step 253241: Loss=4.3940, Acc=0.423, PPL=80.96
2025-09-21 05:02:58,056 - training.trainer - INFO - Epoch 74, Step 253341: Loss=5.2380, Acc=0.250, PPL=188.30
2025-09-21 05:03:05,933 - training.trainer - INFO - Epoch 74, Step 253441: Loss=4.7810, Acc=0.333, PPL=119.23
2025-09-21 05:03:13,866 - training.trainer - INFO - Epoch 74, Step 253541: Loss=5.5977, Acc=0.230, PPL=269.80
2025-09-21 05:03:21,914 - training.trainer - INFO - Epoch 74, Step 253641: Loss=4.2700, Acc=0.333, PPL=71.52
2025-09-21 05:03:39,183 - training.trainer - INFO - Epoch 75/100 completed in 283.87s - Train Loss: 5.4165, Train Acc: 0.290, Val Loss: 5.6859, Val Acc: 0.253
2025-09-21 05:03:39,481 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_75.pt
2025-09-21 05:03:47,893 - training.trainer - INFO - Epoch 75, Step 253824: Loss=5.9399, Acc=0.200, PPL=379.91
2025-09-21 05:03:56,068 - training.trainer - INFO - Epoch 75, Step 253924: Loss=6.2378, Acc=0.250, PPL=511.74
2025-09-21 05:04:04,238 - training.trainer - INFO - Epoch 75, Step 254024: Loss=4.9368, Acc=0.282, PPL=139.32
2025-09-21 05:04:12,347 - training.trainer - INFO - Epoch 75, Step 254124: Loss=6.4582, Acc=0.243, PPL=637.90
2025-09-21 05:04:20,579 - training.trainer - INFO - Epoch 75, Step 254224: Loss=5.8753, Acc=0.250, PPL=356.14
2025-09-21 05:04:28,660 - training.trainer - INFO - Epoch 75, Step 254324: Loss=4.8682, Acc=0.292, PPL=130.09
2025-09-21 05:04:36,793 - training.trainer - INFO - Epoch 75, Step 254424: Loss=5.3823, Acc=0.412, PPL=217.51
2025-09-21 05:04:44,827 - training.trainer - INFO - Epoch 75, Step 254524: Loss=4.9996, Acc=0.348, PPL=148.36
2025-09-21 05:04:52,889 - training.trainer - INFO - Epoch 75, Step 254624: Loss=5.3843, Acc=0.273, PPL=217.96
2025-09-21 05:05:00,820 - training.trainer - INFO - Epoch 75, Step 254724: Loss=4.5068, Acc=0.372, PPL=90.63
2025-09-21 05:05:08,927 - training.trainer - INFO - Epoch 75, Step 254824: Loss=6.5145, Acc=0.149, PPL=674.89
2025-09-21 05:05:17,055 - training.trainer - INFO - Epoch 75, Step 254924: Loss=5.9230, Acc=0.233, PPL=373.54
2025-09-21 05:05:25,222 - training.trainer - INFO - Epoch 75, Step 255024: Loss=5.6586, Acc=0.333, PPL=286.74
2025-09-21 05:05:33,211 - training.trainer - INFO - Epoch 75, Step 255124: Loss=6.6679, Acc=0.183, PPL=786.71
2025-09-21 05:05:41,354 - training.trainer - INFO - Epoch 75, Step 255224: Loss=5.7636, Acc=0.227, PPL=318.50
2025-09-21 05:05:49,418 - training.trainer - INFO - Epoch 75, Step 255324: Loss=5.0252, Acc=0.381, PPL=152.20
2025-09-21 05:05:57,473 - training.trainer - INFO - Epoch 75, Step 255424: Loss=5.4851, Acc=0.269, PPL=241.07
2025-09-21 05:06:05,651 - training.trainer - INFO - Epoch 75, Step 255524: Loss=5.2458, Acc=0.300, PPL=189.76
2025-09-21 05:06:13,828 - training.trainer - INFO - Epoch 75, Step 255624: Loss=5.7075, Acc=0.293, PPL=301.13
2025-09-21 05:06:21,867 - training.trainer - INFO - Epoch 75, Step 255724: Loss=5.4067, Acc=0.268, PPL=222.89
2025-09-21 05:06:29,814 - training.trainer - INFO - Epoch 75, Step 255824: Loss=5.9594, Acc=0.186, PPL=387.39
2025-09-21 05:06:37,777 - training.trainer - INFO - Epoch 75, Step 255924: Loss=5.2897, Acc=0.356, PPL=198.28
2025-09-21 05:06:45,714 - training.trainer - INFO - Epoch 75, Step 256024: Loss=5.0583, Acc=0.292, PPL=157.32
2025-09-21 05:06:53,642 - training.trainer - INFO - Epoch 75, Step 256124: Loss=6.1471, Acc=0.310, PPL=467.37
2025-09-21 05:07:01,488 - training.trainer - INFO - Epoch 75, Step 256224: Loss=6.0398, Acc=0.218, PPL=419.79
2025-09-21 05:07:09,378 - training.trainer - INFO - Epoch 75, Step 256324: Loss=5.0756, Acc=0.316, PPL=160.07
2025-09-21 05:07:17,255 - training.trainer - INFO - Epoch 75, Step 256424: Loss=5.6132, Acc=0.421, PPL=274.02
2025-09-21 05:07:25,154 - training.trainer - INFO - Epoch 75, Step 256524: Loss=5.3937, Acc=0.256, PPL=220.02
2025-09-21 05:07:33,064 - training.trainer - INFO - Epoch 75, Step 256624: Loss=4.3613, Acc=0.444, PPL=78.36
2025-09-21 05:07:40,951 - training.trainer - INFO - Epoch 75, Step 256724: Loss=5.9087, Acc=0.250, PPL=368.22
2025-09-21 05:07:48,869 - training.trainer - INFO - Epoch 75, Step 256824: Loss=5.2311, Acc=0.300, PPL=186.99
2025-09-21 05:07:56,853 - training.trainer - INFO - Epoch 75, Step 256924: Loss=5.9602, Acc=0.273, PPL=387.67
2025-09-21 05:08:04,746 - training.trainer - INFO - Epoch 75, Step 257024: Loss=4.6077, Acc=0.269, PPL=100.25
2025-09-21 05:08:21,752 - training.trainer - INFO - Epoch 76/100 completed in 282.27s - Train Loss: 5.4009, Train Acc: 0.293, Val Loss: 5.6879, Val Acc: 0.254
2025-09-21 05:08:21,752 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-09-21 05:08:21,752 - training.trainer - INFO - Training completed!
2025-09-21 05:08:21,752 - __main__ - INFO - Training completed successfully!
2025-09-21 05:08:21,870 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-21 05:08:21,903 - __main__ - INFO - Process completed!
2025-09-21 05:08:26,051 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-21 05:08:26,052 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 05:08:26,052 - __main__ - INFO - Starting model evaluation
2025-09-21 05:08:26,700 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-21 05:10:33,366 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-21 05:10:33,383 - __main__ - INFO - Process completed!
2025-09-21 05:10:38,790 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-21 05:10:38,790 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 05:10:38,790 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-09-21 05:10:39,587 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-21 05:10:41,967 - __main__ - INFO - Inference completed successfully!
2025-09-21 05:10:41,975 - __main__ - INFO - Process completed!
2025-09-21 22:09:26,784 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-21 22:09:26,784 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 22:09:26,784 - __main__ - INFO - Starting training pipeline
2025-09-21 22:09:26,881 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-21 22:09:26,903 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-21 22:09:26,903 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-21 22:09:26,904 - __main__ - INFO - Loading training data...
2025-09-21 22:09:34,697 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-21 22:09:34,697 - __main__ - INFO - Processing train split...
2025-09-21 22:09:34,762 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-21 22:09:34,762 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-21 22:09:34,773 - __main__ - WARNING -   Skipped train sample 0 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,775 - __main__ - WARNING -   Skipped train sample 1 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,777 - __main__ - WARNING -   Skipped train sample 2 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,778 - __main__ - WARNING -   Skipped train sample 3 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,781 - __main__ - WARNING -   Skipped train sample 4 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,782 - __main__ - WARNING -   Skipped train sample 5 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,784 - __main__ - WARNING -   Skipped train sample 6 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,786 - __main__ - WARNING -   Skipped train sample 7 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,788 - __main__ - WARNING -   Skipped train sample 8 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,790 - __main__ - WARNING -   Skipped train sample 9 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,792 - __main__ - WARNING -   Skipped train sample 10 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,794 - __main__ - WARNING -   Skipped train sample 11 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,796 - __main__ - WARNING -   Skipped train sample 12 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,797 - __main__ - WARNING -   Skipped train sample 13 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,800 - __main__ - WARNING -   Skipped train sample 14 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,801 - __main__ - WARNING -   Skipped train sample 15 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,804 - __main__ - WARNING -   Skipped train sample 16 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,806 - __main__ - WARNING -   Skipped train sample 17 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,808 - __main__ - WARNING -   Skipped train sample 18 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,810 - __main__ - WARNING -   Skipped train sample 19 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,812 - __main__ - WARNING -   Skipped train sample 20 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,814 - __main__ - WARNING -   Skipped train sample 21 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,816 - __main__ - WARNING -   Skipped train sample 22 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,818 - __main__ - WARNING -   Skipped train sample 23 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,820 - __main__ - WARNING -   Skipped train sample 24 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,822 - __main__ - WARNING -   Skipped train sample 25 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,824 - __main__ - WARNING -   Skipped train sample 26 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,826 - __main__ - WARNING -   Skipped train sample 27 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,828 - __main__ - WARNING -   Skipped train sample 28 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,830 - __main__ - WARNING -   Skipped train sample 29 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,832 - __main__ - WARNING -   Skipped train sample 30 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,834 - __main__ - WARNING -   Skipped train sample 31 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,836 - __main__ - WARNING -   Skipped train sample 32 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,838 - __main__ - WARNING -   Skipped train sample 33 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,840 - __main__ - WARNING -   Skipped train sample 34 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,842 - __main__ - WARNING -   Skipped train sample 35 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,843 - __main__ - WARNING -   Skipped train sample 36 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,846 - __main__ - WARNING -   Skipped train sample 37 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,847 - __main__ - WARNING -   Skipped train sample 38 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,849 - __main__ - WARNING -   Skipped train sample 39 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,851 - __main__ - WARNING -   Skipped train sample 40 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,853 - __main__ - WARNING -   Skipped train sample 41 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,855 - __main__ - WARNING -   Skipped train sample 42 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,857 - __main__ - WARNING -   Skipped train sample 43 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,859 - __main__ - WARNING -   Skipped train sample 44 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,861 - __main__ - WARNING -   Skipped train sample 45 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,863 - __main__ - WARNING -   Skipped train sample 46 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,865 - __main__ - WARNING -   Skipped train sample 47 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,867 - __main__ - WARNING -   Skipped train sample 48 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,869 - __main__ - WARNING -   Skipped train sample 49 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,871 - __main__ - WARNING -   Skipped train sample 50 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,872 - __main__ - WARNING -   Skipped train sample 51 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,874 - __main__ - WARNING -   Skipped train sample 52 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,876 - __main__ - WARNING -   Skipped train sample 53 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,878 - __main__ - WARNING -   Skipped train sample 54 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,880 - __main__ - WARNING -   Skipped train sample 55 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,882 - __main__ - WARNING -   Skipped train sample 56 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,884 - __main__ - WARNING -   Skipped train sample 57 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,886 - __main__ - WARNING -   Skipped train sample 58 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,888 - __main__ - WARNING -   Skipped train sample 59 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,890 - __main__ - WARNING -   Skipped train sample 60 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,892 - __main__ - WARNING -   Skipped train sample 61 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,894 - __main__ - WARNING -   Skipped train sample 62 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,896 - __main__ - WARNING -   Skipped train sample 63 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,897 - __main__ - WARNING -   Skipped train sample 64 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,899 - __main__ - WARNING -   Skipped train sample 65 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,901 - __main__ - WARNING -   Skipped train sample 66 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,903 - __main__ - WARNING -   Skipped train sample 67 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,905 - __main__ - WARNING -   Skipped train sample 68 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,907 - __main__ - WARNING -   Skipped train sample 69 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:34,909 - __main__ - WARNING -   Skipped train sample 70 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,911 - __main__ - WARNING -   Skipped train sample 71 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,913 - __main__ - WARNING -   Skipped train sample 72 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,915 - __main__ - WARNING -   Skipped train sample 73 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,917 - __main__ - WARNING -   Skipped train sample 74 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,919 - __main__ - WARNING -   Skipped train sample 75 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,921 - __main__ - WARNING -   Skipped train sample 76 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,923 - __main__ - WARNING -   Skipped train sample 77 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,925 - __main__ - WARNING -   Skipped train sample 78 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,927 - __main__ - WARNING -   Skipped train sample 79 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,929 - __main__ - WARNING -   Skipped train sample 80 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,931 - __main__ - WARNING -   Skipped train sample 81 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,932 - __main__ - WARNING -   Skipped train sample 82 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,934 - __main__ - WARNING -   Skipped train sample 83 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,936 - __main__ - WARNING -   Skipped train sample 84 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,938 - __main__ - WARNING -   Skipped train sample 85 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:34,940 - __main__ - WARNING -   Skipped train sample 86 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,942 - __main__ - WARNING -   Skipped train sample 87 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,944 - __main__ - WARNING -   Skipped train sample 88 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,946 - __main__ - WARNING -   Skipped train sample 89 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,948 - __main__ - WARNING -   Skipped train sample 90 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,950 - __main__ - WARNING -   Skipped train sample 91 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,952 - __main__ - WARNING -   Skipped train sample 92 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,954 - __main__ - WARNING -   Skipped train sample 93 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,956 - __main__ - WARNING -   Skipped train sample 94 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,958 - __main__ - WARNING -   Skipped train sample 95 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,960 - __main__ - WARNING -   Skipped train sample 96 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,962 - __main__ - WARNING -   Skipped train sample 97 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,964 - __main__ - WARNING -   Skipped train sample 98 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,966 - __main__ - WARNING -   Skipped train sample 99 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,968 - __main__ - WARNING -   Skipped train sample 100 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,970 - __main__ - WARNING -   Skipped train sample 101 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,972 - __main__ - WARNING -   Skipped train sample 102 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,974 - __main__ - WARNING -   Skipped train sample 103 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,976 - __main__ - WARNING -   Skipped train sample 104 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:34,977 - __main__ - WARNING -   Skipped train sample 105 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:34,980 - __main__ - WARNING -   Skipped train sample 106 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,982 - __main__ - WARNING -   Skipped train sample 107 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,983 - __main__ - WARNING -   Skipped train sample 108 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:34,985 - __main__ - WARNING -   Skipped train sample 109 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,987 - __main__ - WARNING -   Skipped train sample 110 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,989 - __main__ - WARNING -   Skipped train sample 111 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,991 - __main__ - WARNING -   Skipped train sample 112 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,993 - __main__ - WARNING -   Skipped train sample 113 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,994 - __main__ - WARNING -   Skipped train sample 114 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:34,996 - __main__ - WARNING -   Skipped train sample 115 due to error: cannot convert float NaN to integer
2025-09-21 22:09:34,999 - __main__ - WARNING -   Skipped train sample 116 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,000 - __main__ - WARNING -   Skipped train sample 117 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,002 - __main__ - WARNING -   Skipped train sample 118 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,004 - __main__ - WARNING -   Skipped train sample 119 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,006 - __main__ - WARNING -   Skipped train sample 120 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,008 - __main__ - WARNING -   Skipped train sample 121 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,010 - __main__ - WARNING -   Skipped train sample 122 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,011 - __main__ - WARNING -   Skipped train sample 123 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,013 - __main__ - WARNING -   Skipped train sample 124 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,015 - __main__ - WARNING -   Skipped train sample 125 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,017 - __main__ - WARNING -   Skipped train sample 126 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,019 - __main__ - WARNING -   Skipped train sample 127 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,020 - __main__ - WARNING -   Skipped train sample 128 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,022 - __main__ - WARNING -   Skipped train sample 129 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,024 - __main__ - WARNING -   Skipped train sample 130 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,026 - __main__ - WARNING -   Skipped train sample 131 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,028 - __main__ - WARNING -   Skipped train sample 132 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,030 - __main__ - WARNING -   Skipped train sample 133 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,032 - __main__ - WARNING -   Skipped train sample 134 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,034 - __main__ - WARNING -   Skipped train sample 135 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,036 - __main__ - WARNING -   Skipped train sample 136 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,038 - __main__ - WARNING -   Skipped train sample 137 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,040 - __main__ - WARNING -   Skipped train sample 138 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,042 - __main__ - WARNING -   Skipped train sample 139 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,044 - __main__ - WARNING -   Skipped train sample 140 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,046 - __main__ - WARNING -   Skipped train sample 141 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,048 - __main__ - WARNING -   Skipped train sample 142 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,049 - __main__ - WARNING -   Skipped train sample 143 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,051 - __main__ - WARNING -   Skipped train sample 144 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,053 - __main__ - WARNING -   Skipped train sample 145 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,056 - __main__ - WARNING -   Skipped train sample 146 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,057 - __main__ - WARNING -   Skipped train sample 147 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,059 - __main__ - WARNING -   Skipped train sample 148 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,062 - __main__ - WARNING -   Skipped train sample 149 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,064 - __main__ - WARNING -   Skipped train sample 150 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,065 - __main__ - WARNING -   Skipped train sample 151 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,067 - __main__ - WARNING -   Skipped train sample 152 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,069 - __main__ - WARNING -   Skipped train sample 153 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,071 - __main__ - WARNING -   Skipped train sample 154 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,073 - __main__ - WARNING -   Skipped train sample 155 due to error: invalid literal for int() with base 10: 'signer_6'
2025-09-21 22:09:35,075 - __main__ - WARNING -   Skipped train sample 156 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,077 - __main__ - WARNING -   Skipped train sample 157 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,079 - __main__ - WARNING -   Skipped train sample 158 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,080 - __main__ - WARNING -   Skipped train sample 159 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,082 - __main__ - WARNING -   Skipped train sample 160 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,084 - __main__ - WARNING -   Skipped train sample 161 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,086 - __main__ - WARNING -   Skipped train sample 162 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,088 - __main__ - WARNING -   Skipped train sample 163 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,090 - __main__ - WARNING -   Skipped train sample 164 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,092 - __main__ - WARNING -   Skipped train sample 165 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,094 - __main__ - WARNING -   Skipped train sample 166 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,096 - __main__ - WARNING -   Skipped train sample 167 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,098 - __main__ - WARNING -   Skipped train sample 168 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,100 - __main__ - WARNING -   Skipped train sample 169 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,102 - __main__ - WARNING -   Skipped train sample 170 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,104 - __main__ - WARNING -   Skipped train sample 171 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,105 - __main__ - WARNING -   Skipped train sample 172 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,107 - __main__ - WARNING -   Skipped train sample 173 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,109 - __main__ - WARNING -   Skipped train sample 174 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,111 - __main__ - WARNING -   Skipped train sample 175 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,113 - __main__ - WARNING -   Skipped train sample 176 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,115 - __main__ - WARNING -   Skipped train sample 177 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,116 - __main__ - WARNING -   Skipped train sample 178 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,118 - __main__ - WARNING -   Skipped train sample 179 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,120 - __main__ - WARNING -   Skipped train sample 180 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,122 - __main__ - WARNING -   Skipped train sample 181 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,124 - __main__ - WARNING -   Skipped train sample 182 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,127 - __main__ - WARNING -   Skipped train sample 183 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,129 - __main__ - WARNING -   Skipped train sample 184 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,131 - __main__ - WARNING -   Skipped train sample 185 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,133 - __main__ - WARNING -   Skipped train sample 186 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,135 - __main__ - WARNING -   Skipped train sample 187 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,137 - __main__ - WARNING -   Skipped train sample 188 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,139 - __main__ - WARNING -   Skipped train sample 189 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,141 - __main__ - WARNING -   Skipped train sample 190 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,143 - __main__ - WARNING -   Skipped train sample 191 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,146 - __main__ - WARNING -   Skipped train sample 192 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,147 - __main__ - WARNING -   Skipped train sample 193 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,150 - __main__ - WARNING -   Skipped train sample 194 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,153 - __main__ - WARNING -   Skipped train sample 195 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,154 - __main__ - WARNING -   Skipped train sample 196 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,156 - __main__ - WARNING -   Skipped train sample 197 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,158 - __main__ - WARNING -   Skipped train sample 198 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,161 - __main__ - WARNING -   Skipped train sample 199 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,163 - __main__ - WARNING -   Skipped train sample 200 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,164 - __main__ - WARNING -   Skipped train sample 201 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,167 - __main__ - WARNING -   Skipped train sample 202 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,168 - __main__ - WARNING -   Skipped train sample 203 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,171 - __main__ - WARNING -   Skipped train sample 204 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,173 - __main__ - WARNING -   Skipped train sample 205 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,175 - __main__ - WARNING -   Skipped train sample 206 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,177 - __main__ - WARNING -   Skipped train sample 207 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,179 - __main__ - WARNING -   Skipped train sample 208 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,180 - __main__ - WARNING -   Skipped train sample 209 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,182 - __main__ - WARNING -   Skipped train sample 210 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,184 - __main__ - WARNING -   Skipped train sample 211 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,186 - __main__ - WARNING -   Skipped train sample 212 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,189 - __main__ - WARNING -   Skipped train sample 213 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,191 - __main__ - WARNING -   Skipped train sample 214 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,193 - __main__ - WARNING -   Skipped train sample 215 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,195 - __main__ - WARNING -   Skipped train sample 216 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,197 - __main__ - WARNING -   Skipped train sample 217 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,199 - __main__ - WARNING -   Skipped train sample 218 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,201 - __main__ - WARNING -   Skipped train sample 219 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,203 - __main__ - WARNING -   Skipped train sample 220 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,205 - __main__ - WARNING -   Skipped train sample 221 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,207 - __main__ - WARNING -   Skipped train sample 222 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,209 - __main__ - WARNING -   Skipped train sample 223 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,211 - __main__ - WARNING -   Skipped train sample 224 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,213 - __main__ - WARNING -   Skipped train sample 225 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:35,214 - __main__ - WARNING -   Skipped train sample 226 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,216 - __main__ - WARNING -   Skipped train sample 227 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,218 - __main__ - WARNING -   Skipped train sample 228 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,220 - __main__ - WARNING -   Skipped train sample 229 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,222 - __main__ - WARNING -   Skipped train sample 230 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,224 - __main__ - WARNING -   Skipped train sample 231 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,226 - __main__ - WARNING -   Skipped train sample 232 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,228 - __main__ - WARNING -   Skipped train sample 233 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,230 - __main__ - WARNING -   Skipped train sample 234 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,232 - __main__ - WARNING -   Skipped train sample 235 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,234 - __main__ - WARNING -   Skipped train sample 236 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,236 - __main__ - WARNING -   Skipped train sample 237 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,238 - __main__ - WARNING -   Skipped train sample 238 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,240 - __main__ - WARNING -   Skipped train sample 239 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,242 - __main__ - WARNING -   Skipped train sample 240 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,243 - __main__ - WARNING -   Skipped train sample 241 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,245 - __main__ - WARNING -   Skipped train sample 242 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,247 - __main__ - WARNING -   Skipped train sample 243 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,249 - __main__ - WARNING -   Skipped train sample 244 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,251 - __main__ - WARNING -   Skipped train sample 245 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,253 - __main__ - WARNING -   Skipped train sample 246 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,255 - __main__ - WARNING -   Skipped train sample 247 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,257 - __main__ - WARNING -   Skipped train sample 248 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,259 - __main__ - WARNING -   Skipped train sample 249 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,261 - __main__ - WARNING -   Skipped train sample 250 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,263 - __main__ - WARNING -   Skipped train sample 251 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,264 - __main__ - WARNING -   Skipped train sample 252 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,267 - __main__ - WARNING -   Skipped train sample 253 due to error: invalid literal for int() with base 10: 'signer_7'
2025-09-21 22:09:35,269 - __main__ - WARNING -   Skipped train sample 254 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,271 - __main__ - WARNING -   Skipped train sample 255 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,272 - __main__ - WARNING -   Skipped train sample 256 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,274 - __main__ - WARNING -   Skipped train sample 257 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,276 - __main__ - WARNING -   Skipped train sample 258 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,278 - __main__ - WARNING -   Skipped train sample 259 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,280 - __main__ - WARNING -   Skipped train sample 260 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,282 - __main__ - WARNING -   Skipped train sample 261 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,284 - __main__ - WARNING -   Skipped train sample 262 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,286 - __main__ - WARNING -   Skipped train sample 263 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,288 - __main__ - WARNING -   Skipped train sample 264 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,290 - __main__ - WARNING -   Skipped train sample 265 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,292 - __main__ - WARNING -   Skipped train sample 266 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,294 - __main__ - WARNING -   Skipped train sample 267 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,295 - __main__ - WARNING -   Skipped train sample 268 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,297 - __main__ - WARNING -   Skipped train sample 269 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,300 - __main__ - WARNING -   Skipped train sample 270 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,302 - __main__ - WARNING -   Skipped train sample 271 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,303 - __main__ - WARNING -   Skipped train sample 272 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,305 - __main__ - WARNING -   Skipped train sample 273 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,307 - __main__ - WARNING -   Skipped train sample 274 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,309 - __main__ - WARNING -   Skipped train sample 275 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,311 - __main__ - WARNING -   Skipped train sample 276 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,313 - __main__ - WARNING -   Skipped train sample 277 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,315 - __main__ - WARNING -   Skipped train sample 278 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,317 - __main__ - WARNING -   Skipped train sample 279 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,319 - __main__ - WARNING -   Skipped train sample 280 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,321 - __main__ - WARNING -   Skipped train sample 281 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,323 - __main__ - WARNING -   Skipped train sample 282 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,324 - __main__ - WARNING -   Skipped train sample 283 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,326 - __main__ - WARNING -   Skipped train sample 284 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,328 - __main__ - WARNING -   Skipped train sample 285 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,330 - __main__ - WARNING -   Skipped train sample 286 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,332 - __main__ - WARNING -   Skipped train sample 287 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,334 - __main__ - WARNING -   Skipped train sample 288 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,336 - __main__ - WARNING -   Skipped train sample 289 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,338 - __main__ - WARNING -   Skipped train sample 290 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,340 - __main__ - WARNING -   Skipped train sample 291 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,342 - __main__ - WARNING -   Skipped train sample 292 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,344 - __main__ - WARNING -   Skipped train sample 293 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,346 - __main__ - WARNING -   Skipped train sample 294 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,348 - __main__ - WARNING -   Skipped train sample 295 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,350 - __main__ - WARNING -   Skipped train sample 296 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,352 - __main__ - WARNING -   Skipped train sample 297 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,354 - __main__ - WARNING -   Skipped train sample 298 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,356 - __main__ - WARNING -   Skipped train sample 299 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,358 - __main__ - WARNING -   Skipped train sample 300 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,359 - __main__ - WARNING -   Skipped train sample 301 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,362 - __main__ - WARNING -   Skipped train sample 302 due to error: invalid literal for int() with base 10: 'signer_21'
2025-09-21 22:09:35,363 - __main__ - WARNING -   Skipped train sample 303 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,365 - __main__ - WARNING -   Skipped train sample 304 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,367 - __main__ - WARNING -   Skipped train sample 305 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,369 - __main__ - WARNING -   Skipped train sample 306 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,372 - __main__ - WARNING -   Skipped train sample 307 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,373 - __main__ - WARNING -   Skipped train sample 308 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,375 - __main__ - WARNING -   Skipped train sample 309 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,377 - __main__ - WARNING -   Skipped train sample 310 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,379 - __main__ - WARNING -   Skipped train sample 311 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,381 - __main__ - WARNING -   Skipped train sample 312 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,383 - __main__ - WARNING -   Skipped train sample 313 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,385 - __main__ - WARNING -   Skipped train sample 314 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,387 - __main__ - WARNING -   Skipped train sample 315 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,389 - __main__ - WARNING -   Skipped train sample 316 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,391 - __main__ - WARNING -   Skipped train sample 317 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,392 - __main__ - WARNING -   Skipped train sample 318 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,394 - __main__ - WARNING -   Skipped train sample 319 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,396 - __main__ - WARNING -   Skipped train sample 320 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,398 - __main__ - WARNING -   Skipped train sample 321 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,400 - __main__ - WARNING -   Skipped train sample 322 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,402 - __main__ - WARNING -   Skipped train sample 323 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,404 - __main__ - WARNING -   Skipped train sample 324 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,406 - __main__ - WARNING -   Skipped train sample 325 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,408 - __main__ - WARNING -   Skipped train sample 326 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,410 - __main__ - WARNING -   Skipped train sample 327 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,412 - __main__ - WARNING -   Skipped train sample 328 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,414 - __main__ - WARNING -   Skipped train sample 329 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,416 - __main__ - WARNING -   Skipped train sample 330 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,418 - __main__ - WARNING -   Skipped train sample 331 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,420 - __main__ - WARNING -   Skipped train sample 332 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,422 - __main__ - WARNING -   Skipped train sample 333 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,424 - __main__ - WARNING -   Skipped train sample 334 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,426 - __main__ - WARNING -   Skipped train sample 335 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,428 - __main__ - WARNING -   Skipped train sample 336 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,430 - __main__ - WARNING -   Skipped train sample 337 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,432 - __main__ - WARNING -   Skipped train sample 338 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,434 - __main__ - WARNING -   Skipped train sample 339 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,436 - __main__ - WARNING -   Skipped train sample 340 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,438 - __main__ - WARNING -   Skipped train sample 341 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,440 - __main__ - WARNING -   Skipped train sample 342 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,442 - __main__ - WARNING -   Skipped train sample 343 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,443 - __main__ - WARNING -   Skipped train sample 344 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,445 - __main__ - WARNING -   Skipped train sample 345 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,447 - __main__ - WARNING -   Skipped train sample 346 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,449 - __main__ - WARNING -   Skipped train sample 347 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,451 - __main__ - WARNING -   Skipped train sample 348 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,453 - __main__ - WARNING -   Skipped train sample 349 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,455 - __main__ - WARNING -   Skipped train sample 350 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,457 - __main__ - WARNING -   Skipped train sample 351 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,459 - __main__ - WARNING -   Skipped train sample 352 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,460 - __main__ - WARNING -   Skipped train sample 353 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,462 - __main__ - WARNING -   Skipped train sample 354 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,464 - __main__ - WARNING -   Skipped train sample 355 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,466 - __main__ - WARNING -   Skipped train sample 356 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,468 - __main__ - WARNING -   Skipped train sample 357 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,470 - __main__ - WARNING -   Skipped train sample 358 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,472 - __main__ - WARNING -   Skipped train sample 359 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,474 - __main__ - WARNING -   Skipped train sample 360 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,476 - __main__ - WARNING -   Skipped train sample 361 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,478 - __main__ - WARNING -   Skipped train sample 362 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,480 - __main__ - WARNING -   Skipped train sample 363 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,482 - __main__ - WARNING -   Skipped train sample 364 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,484 - __main__ - WARNING -   Skipped train sample 365 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,486 - __main__ - WARNING -   Skipped train sample 366 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,488 - __main__ - WARNING -   Skipped train sample 367 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,490 - __main__ - WARNING -   Skipped train sample 368 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,491 - __main__ - WARNING -   Skipped train sample 369 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,494 - __main__ - WARNING -   Skipped train sample 370 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,496 - __main__ - WARNING -   Skipped train sample 371 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,498 - __main__ - WARNING -   Skipped train sample 372 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,499 - __main__ - WARNING -   Skipped train sample 373 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,502 - __main__ - WARNING -   Skipped train sample 374 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,504 - __main__ - WARNING -   Skipped train sample 375 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,506 - __main__ - WARNING -   Skipped train sample 376 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,508 - __main__ - WARNING -   Skipped train sample 377 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,509 - __main__ - WARNING -   Skipped train sample 378 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,511 - __main__ - WARNING -   Skipped train sample 379 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,513 - __main__ - WARNING -   Skipped train sample 380 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,515 - __main__ - WARNING -   Skipped train sample 381 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,517 - __main__ - WARNING -   Skipped train sample 382 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,519 - __main__ - WARNING -   Skipped train sample 383 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,521 - __main__ - WARNING -   Skipped train sample 384 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,523 - __main__ - WARNING -   Skipped train sample 385 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,525 - __main__ - WARNING -   Skipped train sample 386 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,527 - __main__ - WARNING -   Skipped train sample 387 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,529 - __main__ - WARNING -   Skipped train sample 388 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,531 - __main__ - WARNING -   Skipped train sample 389 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,533 - __main__ - WARNING -   Skipped train sample 390 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,535 - __main__ - WARNING -   Skipped train sample 391 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,536 - __main__ - WARNING -   Skipped train sample 392 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,538 - __main__ - WARNING -   Skipped train sample 393 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,540 - __main__ - WARNING -   Skipped train sample 394 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,542 - __main__ - WARNING -   Skipped train sample 395 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,544 - __main__ - WARNING -   Skipped train sample 396 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,546 - __main__ - WARNING -   Skipped train sample 397 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,548 - __main__ - WARNING -   Skipped train sample 398 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,550 - __main__ - WARNING -   Skipped train sample 399 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,552 - __main__ - WARNING -   Skipped train sample 400 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,554 - __main__ - WARNING -   Skipped train sample 401 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,556 - __main__ - WARNING -   Skipped train sample 402 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,558 - __main__ - WARNING -   Skipped train sample 403 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,560 - __main__ - WARNING -   Skipped train sample 404 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:35,562 - __main__ - WARNING -   Skipped train sample 405 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,564 - __main__ - WARNING -   Skipped train sample 406 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,566 - __main__ - WARNING -   Skipped train sample 407 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,568 - __main__ - WARNING -   Skipped train sample 408 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,570 - __main__ - WARNING -   Skipped train sample 409 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,572 - __main__ - WARNING -   Skipped train sample 410 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,574 - __main__ - WARNING -   Skipped train sample 411 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,576 - __main__ - WARNING -   Skipped train sample 412 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,578 - __main__ - WARNING -   Skipped train sample 413 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,580 - __main__ - WARNING -   Skipped train sample 414 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,582 - __main__ - WARNING -   Skipped train sample 415 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,584 - __main__ - WARNING -   Skipped train sample 416 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,586 - __main__ - WARNING -   Skipped train sample 417 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,588 - __main__ - WARNING -   Skipped train sample 418 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,590 - __main__ - WARNING -   Skipped train sample 419 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,592 - __main__ - WARNING -   Skipped train sample 420 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,594 - __main__ - WARNING -   Skipped train sample 421 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,596 - __main__ - WARNING -   Skipped train sample 422 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:35,598 - __main__ - WARNING -   Skipped train sample 423 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,600 - __main__ - WARNING -   Skipped train sample 424 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,602 - __main__ - WARNING -   Skipped train sample 425 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,603 - __main__ - WARNING -   Skipped train sample 426 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:35,605 - __main__ - WARNING -   Skipped train sample 427 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,607 - __main__ - WARNING -   Skipped train sample 428 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,609 - __main__ - WARNING -   Skipped train sample 429 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,611 - __main__ - WARNING -   Skipped train sample 430 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:35,613 - __main__ - WARNING -   Skipped train sample 431 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,615 - __main__ - WARNING -   Skipped train sample 432 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,617 - __main__ - WARNING -   Skipped train sample 433 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,619 - __main__ - WARNING -   Skipped train sample 434 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,621 - __main__ - WARNING -   Skipped train sample 435 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,623 - __main__ - WARNING -   Skipped train sample 436 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,624 - __main__ - WARNING -   Skipped train sample 437 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,626 - __main__ - WARNING -   Skipped train sample 438 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,628 - __main__ - WARNING -   Skipped train sample 439 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,630 - __main__ - WARNING -   Skipped train sample 440 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,632 - __main__ - WARNING -   Skipped train sample 441 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,634 - __main__ - WARNING -   Skipped train sample 442 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,636 - __main__ - WARNING -   Skipped train sample 443 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,638 - __main__ - WARNING -   Skipped train sample 444 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,640 - __main__ - WARNING -   Skipped train sample 445 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,642 - __main__ - WARNING -   Skipped train sample 446 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,644 - __main__ - WARNING -   Skipped train sample 447 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,646 - __main__ - WARNING -   Skipped train sample 448 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,648 - __main__ - WARNING -   Skipped train sample 449 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,650 - __main__ - WARNING -   Skipped train sample 450 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,651 - __main__ - WARNING -   Skipped train sample 451 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,654 - __main__ - WARNING -   Skipped train sample 452 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,656 - __main__ - WARNING -   Skipped train sample 453 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,657 - __main__ - WARNING -   Skipped train sample 454 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,659 - __main__ - WARNING -   Skipped train sample 455 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,661 - __main__ - WARNING -   Skipped train sample 456 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,663 - __main__ - WARNING -   Skipped train sample 457 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,665 - __main__ - WARNING -   Skipped train sample 458 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,667 - __main__ - WARNING -   Skipped train sample 459 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,669 - __main__ - WARNING -   Skipped train sample 460 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,671 - __main__ - WARNING -   Skipped train sample 461 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,673 - __main__ - WARNING -   Skipped train sample 462 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,675 - __main__ - WARNING -   Skipped train sample 463 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,677 - __main__ - WARNING -   Skipped train sample 464 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,679 - __main__ - WARNING -   Skipped train sample 465 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,681 - __main__ - WARNING -   Skipped train sample 466 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,683 - __main__ - WARNING -   Skipped train sample 467 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,685 - __main__ - WARNING -   Skipped train sample 468 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,687 - __main__ - WARNING -   Skipped train sample 469 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,689 - __main__ - WARNING -   Skipped train sample 470 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,691 - __main__ - WARNING -   Skipped train sample 471 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,692 - __main__ - WARNING -   Skipped train sample 472 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,694 - __main__ - WARNING -   Skipped train sample 473 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,696 - __main__ - WARNING -   Skipped train sample 474 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,698 - __main__ - WARNING -   Skipped train sample 475 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,700 - __main__ - WARNING -   Skipped train sample 476 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,702 - __main__ - WARNING -   Skipped train sample 477 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,704 - __main__ - WARNING -   Skipped train sample 478 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,706 - __main__ - WARNING -   Skipped train sample 479 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,708 - __main__ - WARNING -   Skipped train sample 480 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,710 - __main__ - WARNING -   Skipped train sample 481 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,712 - __main__ - WARNING -   Skipped train sample 482 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,714 - __main__ - WARNING -   Skipped train sample 483 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,716 - __main__ - WARNING -   Skipped train sample 484 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,718 - __main__ - WARNING -   Skipped train sample 485 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,720 - __main__ - WARNING -   Skipped train sample 486 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,722 - __main__ - WARNING -   Skipped train sample 487 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,724 - __main__ - WARNING -   Skipped train sample 488 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,726 - __main__ - WARNING -   Skipped train sample 489 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,728 - __main__ - WARNING -   Skipped train sample 490 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,730 - __main__ - WARNING -   Skipped train sample 491 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,732 - __main__ - WARNING -   Skipped train sample 492 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,734 - __main__ - WARNING -   Skipped train sample 493 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:35,736 - __main__ - WARNING -   Skipped train sample 494 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,738 - __main__ - WARNING -   Skipped train sample 495 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,740 - __main__ - WARNING -   Skipped train sample 496 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,742 - __main__ - WARNING -   Skipped train sample 497 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,744 - __main__ - WARNING -   Skipped train sample 498 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,746 - __main__ - WARNING -   Skipped train sample 499 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,748 - __main__ - WARNING -   Skipped train sample 500 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,749 - __main__ - WARNING -   Skipped train sample 501 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,751 - __main__ - WARNING -   Skipped train sample 502 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,753 - __main__ - WARNING -   Skipped train sample 503 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,755 - __main__ - WARNING -   Skipped train sample 504 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,757 - __main__ - WARNING -   Skipped train sample 505 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,759 - __main__ - WARNING -   Skipped train sample 506 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,760 - __main__ - WARNING -   Skipped train sample 507 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,762 - __main__ - WARNING -   Skipped train sample 508 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,764 - __main__ - WARNING -   Skipped train sample 509 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,766 - __main__ - WARNING -   Skipped train sample 510 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,768 - __main__ - WARNING -   Skipped train sample 511 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,770 - __main__ - WARNING -   Skipped train sample 512 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,772 - __main__ - WARNING -   Skipped train sample 513 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,774 - __main__ - WARNING -   Skipped train sample 514 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,775 - __main__ - WARNING -   Skipped train sample 515 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,777 - __main__ - WARNING -   Skipped train sample 516 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,779 - __main__ - WARNING -   Skipped train sample 517 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,781 - __main__ - WARNING -   Skipped train sample 518 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,783 - __main__ - WARNING -   Skipped train sample 519 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,785 - __main__ - WARNING -   Skipped train sample 520 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,787 - __main__ - WARNING -   Skipped train sample 521 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,789 - __main__ - WARNING -   Skipped train sample 522 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,791 - __main__ - WARNING -   Skipped train sample 523 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,793 - __main__ - WARNING -   Skipped train sample 524 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,795 - __main__ - WARNING -   Skipped train sample 525 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,797 - __main__ - WARNING -   Skipped train sample 526 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,799 - __main__ - WARNING -   Skipped train sample 527 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,800 - __main__ - WARNING -   Skipped train sample 528 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,803 - __main__ - WARNING -   Skipped train sample 529 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,805 - __main__ - WARNING -   Skipped train sample 530 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,807 - __main__ - WARNING -   Skipped train sample 531 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:35,809 - __main__ - WARNING -   Skipped train sample 532 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,811 - __main__ - WARNING -   Skipped train sample 533 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,812 - __main__ - WARNING -   Skipped train sample 534 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,814 - __main__ - WARNING -   Skipped train sample 535 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,816 - __main__ - WARNING -   Skipped train sample 536 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,818 - __main__ - WARNING -   Skipped train sample 537 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,820 - __main__ - WARNING -   Skipped train sample 538 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,822 - __main__ - WARNING -   Skipped train sample 539 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,824 - __main__ - WARNING -   Skipped train sample 540 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,826 - __main__ - WARNING -   Skipped train sample 541 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,828 - __main__ - WARNING -   Skipped train sample 542 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,829 - __main__ - WARNING -   Skipped train sample 543 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,831 - __main__ - WARNING -   Skipped train sample 544 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,833 - __main__ - WARNING -   Skipped train sample 545 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,835 - __main__ - WARNING -   Skipped train sample 546 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,837 - __main__ - WARNING -   Skipped train sample 547 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,839 - __main__ - WARNING -   Skipped train sample 548 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,840 - __main__ - WARNING -   Skipped train sample 549 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,842 - __main__ - WARNING -   Skipped train sample 550 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,845 - __main__ - WARNING -   Skipped train sample 551 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,847 - __main__ - WARNING -   Skipped train sample 552 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,848 - __main__ - WARNING -   Skipped train sample 553 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,850 - __main__ - WARNING -   Skipped train sample 554 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,852 - __main__ - WARNING -   Skipped train sample 555 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,854 - __main__ - WARNING -   Skipped train sample 556 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,856 - __main__ - WARNING -   Skipped train sample 557 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,858 - __main__ - WARNING -   Skipped train sample 558 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,860 - __main__ - WARNING -   Skipped train sample 559 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,861 - __main__ - WARNING -   Skipped train sample 560 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,863 - __main__ - WARNING -   Skipped train sample 561 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,865 - __main__ - WARNING -   Skipped train sample 562 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,867 - __main__ - WARNING -   Skipped train sample 563 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,869 - __main__ - WARNING -   Skipped train sample 564 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,871 - __main__ - WARNING -   Skipped train sample 565 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,873 - __main__ - WARNING -   Skipped train sample 566 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,875 - __main__ - WARNING -   Skipped train sample 567 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,877 - __main__ - WARNING -   Skipped train sample 568 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,878 - __main__ - WARNING -   Skipped train sample 569 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,880 - __main__ - WARNING -   Skipped train sample 570 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,882 - __main__ - WARNING -   Skipped train sample 571 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,884 - __main__ - WARNING -   Skipped train sample 572 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,886 - __main__ - WARNING -   Skipped train sample 573 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,888 - __main__ - WARNING -   Skipped train sample 574 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,890 - __main__ - WARNING -   Skipped train sample 575 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,891 - __main__ - WARNING -   Skipped train sample 576 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,893 - __main__ - WARNING -   Skipped train sample 577 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,895 - __main__ - WARNING -   Skipped train sample 578 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,897 - __main__ - WARNING -   Skipped train sample 579 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,899 - __main__ - WARNING -   Skipped train sample 580 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,901 - __main__ - WARNING -   Skipped train sample 581 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,903 - __main__ - WARNING -   Skipped train sample 582 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,904 - __main__ - WARNING -   Skipped train sample 583 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,906 - __main__ - WARNING -   Skipped train sample 584 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,908 - __main__ - WARNING -   Skipped train sample 585 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,910 - __main__ - WARNING -   Skipped train sample 586 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,912 - __main__ - WARNING -   Skipped train sample 587 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:35,914 - __main__ - WARNING -   Skipped train sample 588 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,916 - __main__ - WARNING -   Skipped train sample 589 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,918 - __main__ - WARNING -   Skipped train sample 590 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,920 - __main__ - WARNING -   Skipped train sample 591 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,922 - __main__ - WARNING -   Skipped train sample 592 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,924 - __main__ - WARNING -   Skipped train sample 593 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,926 - __main__ - WARNING -   Skipped train sample 594 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,927 - __main__ - WARNING -   Skipped train sample 595 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,929 - __main__ - WARNING -   Skipped train sample 596 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,931 - __main__ - WARNING -   Skipped train sample 597 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,933 - __main__ - WARNING -   Skipped train sample 598 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,935 - __main__ - WARNING -   Skipped train sample 599 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,937 - __main__ - WARNING -   Skipped train sample 600 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,939 - __main__ - WARNING -   Skipped train sample 601 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,940 - __main__ - WARNING -   Skipped train sample 602 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,942 - __main__ - WARNING -   Skipped train sample 603 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,944 - __main__ - WARNING -   Skipped train sample 604 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,946 - __main__ - WARNING -   Skipped train sample 605 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,948 - __main__ - WARNING -   Skipped train sample 606 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,950 - __main__ - WARNING -   Skipped train sample 607 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,952 - __main__ - WARNING -   Skipped train sample 608 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,954 - __main__ - WARNING -   Skipped train sample 609 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,956 - __main__ - WARNING -   Skipped train sample 610 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,958 - __main__ - WARNING -   Skipped train sample 611 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,960 - __main__ - WARNING -   Skipped train sample 612 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,962 - __main__ - WARNING -   Skipped train sample 613 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,964 - __main__ - WARNING -   Skipped train sample 614 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,966 - __main__ - WARNING -   Skipped train sample 615 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,968 - __main__ - WARNING -   Skipped train sample 616 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,970 - __main__ - WARNING -   Skipped train sample 617 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,972 - __main__ - WARNING -   Skipped train sample 618 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,973 - __main__ - WARNING -   Skipped train sample 619 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,975 - __main__ - WARNING -   Skipped train sample 620 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,977 - __main__ - WARNING -   Skipped train sample 621 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,979 - __main__ - WARNING -   Skipped train sample 622 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,981 - __main__ - WARNING -   Skipped train sample 623 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,983 - __main__ - WARNING -   Skipped train sample 624 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,984 - __main__ - WARNING -   Skipped train sample 625 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,986 - __main__ - WARNING -   Skipped train sample 626 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,988 - __main__ - WARNING -   Skipped train sample 627 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,990 - __main__ - WARNING -   Skipped train sample 628 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,992 - __main__ - WARNING -   Skipped train sample 629 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:35,994 - __main__ - WARNING -   Skipped train sample 630 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,996 - __main__ - WARNING -   Skipped train sample 631 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:35,998 - __main__ - WARNING -   Skipped train sample 632 due to error: cannot convert float NaN to integer
2025-09-21 22:09:35,999 - __main__ - WARNING -   Skipped train sample 633 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,001 - __main__ - WARNING -   Skipped train sample 634 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,003 - __main__ - WARNING -   Skipped train sample 635 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,005 - __main__ - WARNING -   Skipped train sample 636 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,007 - __main__ - WARNING -   Skipped train sample 637 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,009 - __main__ - WARNING -   Skipped train sample 638 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,011 - __main__ - WARNING -   Skipped train sample 639 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,012 - __main__ - WARNING -   Skipped train sample 640 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,014 - __main__ - WARNING -   Skipped train sample 641 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,016 - __main__ - WARNING -   Skipped train sample 642 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,018 - __main__ - WARNING -   Skipped train sample 643 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,020 - __main__ - WARNING -   Skipped train sample 644 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,022 - __main__ - WARNING -   Skipped train sample 645 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,024 - __main__ - WARNING -   Skipped train sample 646 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,025 - __main__ - WARNING -   Skipped train sample 647 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,027 - __main__ - WARNING -   Skipped train sample 648 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,029 - __main__ - WARNING -   Skipped train sample 649 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,031 - __main__ - WARNING -   Skipped train sample 650 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,033 - __main__ - WARNING -   Skipped train sample 651 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,035 - __main__ - WARNING -   Skipped train sample 652 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,037 - __main__ - WARNING -   Skipped train sample 653 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,039 - __main__ - WARNING -   Skipped train sample 654 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,040 - __main__ - WARNING -   Skipped train sample 655 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,042 - __main__ - WARNING -   Skipped train sample 656 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,044 - __main__ - WARNING -   Skipped train sample 657 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,046 - __main__ - WARNING -   Skipped train sample 658 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,048 - __main__ - WARNING -   Skipped train sample 659 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:36,050 - __main__ - WARNING -   Skipped train sample 660 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,052 - __main__ - WARNING -   Skipped train sample 661 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,054 - __main__ - WARNING -   Skipped train sample 662 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,056 - __main__ - WARNING -   Skipped train sample 663 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,058 - __main__ - WARNING -   Skipped train sample 664 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,060 - __main__ - WARNING -   Skipped train sample 665 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,061 - __main__ - WARNING -   Skipped train sample 666 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,063 - __main__ - WARNING -   Skipped train sample 667 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,065 - __main__ - WARNING -   Skipped train sample 668 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,067 - __main__ - WARNING -   Skipped train sample 669 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,069 - __main__ - WARNING -   Skipped train sample 670 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,071 - __main__ - WARNING -   Skipped train sample 671 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,073 - __main__ - WARNING -   Skipped train sample 672 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,075 - __main__ - WARNING -   Skipped train sample 673 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,077 - __main__ - WARNING -   Skipped train sample 674 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,079 - __main__ - WARNING -   Skipped train sample 675 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,080 - __main__ - WARNING -   Skipped train sample 676 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,082 - __main__ - WARNING -   Skipped train sample 677 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,084 - __main__ - WARNING -   Skipped train sample 678 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,086 - __main__ - WARNING -   Skipped train sample 679 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,088 - __main__ - WARNING -   Skipped train sample 680 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,090 - __main__ - WARNING -   Skipped train sample 681 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,092 - __main__ - WARNING -   Skipped train sample 682 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,094 - __main__ - WARNING -   Skipped train sample 683 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,096 - __main__ - WARNING -   Skipped train sample 684 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,098 - __main__ - WARNING -   Skipped train sample 685 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,100 - __main__ - WARNING -   Skipped train sample 686 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,102 - __main__ - WARNING -   Skipped train sample 687 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,104 - __main__ - WARNING -   Skipped train sample 688 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,106 - __main__ - WARNING -   Skipped train sample 689 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,108 - __main__ - WARNING -   Skipped train sample 690 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,110 - __main__ - WARNING -   Skipped train sample 691 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,112 - __main__ - WARNING -   Skipped train sample 692 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,114 - __main__ - WARNING -   Skipped train sample 693 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,117 - __main__ - WARNING -   Skipped train sample 694 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,119 - __main__ - WARNING -   Skipped train sample 695 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,120 - __main__ - WARNING -   Skipped train sample 696 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,122 - __main__ - WARNING -   Skipped train sample 697 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,124 - __main__ - WARNING -   Skipped train sample 698 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,126 - __main__ - WARNING -   Skipped train sample 699 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,129 - __main__ - WARNING -   Skipped train sample 700 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,131 - __main__ - WARNING -   Skipped train sample 701 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,133 - __main__ - WARNING -   Skipped train sample 702 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,134 - __main__ - WARNING -   Skipped train sample 703 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,136 - __main__ - WARNING -   Skipped train sample 704 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,138 - __main__ - WARNING -   Skipped train sample 705 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,140 - __main__ - WARNING -   Skipped train sample 706 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,142 - __main__ - WARNING -   Skipped train sample 707 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,144 - __main__ - WARNING -   Skipped train sample 708 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,146 - __main__ - WARNING -   Skipped train sample 709 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,148 - __main__ - WARNING -   Skipped train sample 710 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,150 - __main__ - WARNING -   Skipped train sample 711 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,152 - __main__ - WARNING -   Skipped train sample 712 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,154 - __main__ - WARNING -   Skipped train sample 713 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,156 - __main__ - WARNING -   Skipped train sample 714 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,158 - __main__ - WARNING -   Skipped train sample 715 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,160 - __main__ - WARNING -   Skipped train sample 716 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,162 - __main__ - WARNING -   Skipped train sample 717 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,164 - __main__ - WARNING -   Skipped train sample 718 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,166 - __main__ - WARNING -   Skipped train sample 719 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,168 - __main__ - WARNING -   Skipped train sample 720 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,170 - __main__ - WARNING -   Skipped train sample 721 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,172 - __main__ - WARNING -   Skipped train sample 722 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,174 - __main__ - WARNING -   Skipped train sample 723 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,176 - __main__ - WARNING -   Skipped train sample 724 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,178 - __main__ - WARNING -   Skipped train sample 725 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,180 - __main__ - WARNING -   Skipped train sample 726 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,182 - __main__ - WARNING -   Skipped train sample 727 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,184 - __main__ - WARNING -   Skipped train sample 728 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,186 - __main__ - WARNING -   Skipped train sample 729 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,188 - __main__ - WARNING -   Skipped train sample 730 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,190 - __main__ - WARNING -   Skipped train sample 731 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,192 - __main__ - WARNING -   Skipped train sample 732 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,194 - __main__ - WARNING -   Skipped train sample 733 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,196 - __main__ - WARNING -   Skipped train sample 734 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,198 - __main__ - WARNING -   Skipped train sample 735 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,199 - __main__ - WARNING -   Skipped train sample 736 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,201 - __main__ - WARNING -   Skipped train sample 737 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,203 - __main__ - WARNING -   Skipped train sample 738 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,205 - __main__ - WARNING -   Skipped train sample 739 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,207 - __main__ - WARNING -   Skipped train sample 740 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:36,209 - __main__ - WARNING -   Skipped train sample 741 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,211 - __main__ - WARNING -   Skipped train sample 742 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,213 - __main__ - WARNING -   Skipped train sample 743 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:36,215 - __main__ - WARNING -   Skipped train sample 744 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,218 - __main__ - WARNING -   Skipped train sample 745 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,220 - __main__ - WARNING -   Skipped train sample 746 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,222 - __main__ - WARNING -   Skipped train sample 747 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,224 - __main__ - WARNING -   Skipped train sample 748 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,226 - __main__ - WARNING -   Skipped train sample 749 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,228 - __main__ - WARNING -   Skipped train sample 750 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,230 - __main__ - WARNING -   Skipped train sample 751 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,232 - __main__ - WARNING -   Skipped train sample 752 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,234 - __main__ - WARNING -   Skipped train sample 753 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,236 - __main__ - WARNING -   Skipped train sample 754 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,238 - __main__ - WARNING -   Skipped train sample 755 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,240 - __main__ - WARNING -   Skipped train sample 756 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,242 - __main__ - WARNING -   Skipped train sample 757 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,244 - __main__ - WARNING -   Skipped train sample 758 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,246 - __main__ - WARNING -   Skipped train sample 759 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,248 - __main__ - WARNING -   Skipped train sample 760 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,249 - __main__ - WARNING -   Skipped train sample 761 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,251 - __main__ - WARNING -   Skipped train sample 762 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:36,253 - __main__ - WARNING -   Skipped train sample 763 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,255 - __main__ - WARNING -   Skipped train sample 764 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,257 - __main__ - WARNING -   Skipped train sample 765 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,259 - __main__ - WARNING -   Skipped train sample 766 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,261 - __main__ - WARNING -   Skipped train sample 767 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,263 - __main__ - WARNING -   Skipped train sample 768 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,265 - __main__ - WARNING -   Skipped train sample 769 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,267 - __main__ - WARNING -   Skipped train sample 770 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,269 - __main__ - WARNING -   Skipped train sample 771 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,270 - __main__ - WARNING -   Skipped train sample 772 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,272 - __main__ - WARNING -   Skipped train sample 773 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,274 - __main__ - WARNING -   Skipped train sample 774 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,276 - __main__ - WARNING -   Skipped train sample 775 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,278 - __main__ - WARNING -   Skipped train sample 776 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,280 - __main__ - WARNING -   Skipped train sample 777 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:36,282 - __main__ - WARNING -   Skipped train sample 778 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,284 - __main__ - WARNING -   Skipped train sample 779 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,286 - __main__ - WARNING -   Skipped train sample 780 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,288 - __main__ - WARNING -   Skipped train sample 781 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,290 - __main__ - WARNING -   Skipped train sample 782 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,292 - __main__ - WARNING -   Skipped train sample 783 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,294 - __main__ - WARNING -   Skipped train sample 784 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,296 - __main__ - WARNING -   Skipped train sample 785 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,297 - __main__ - WARNING -   Skipped train sample 786 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,299 - __main__ - WARNING -   Skipped train sample 787 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,301 - __main__ - WARNING -   Skipped train sample 788 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,303 - __main__ - WARNING -   Skipped train sample 789 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,305 - __main__ - WARNING -   Skipped train sample 790 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,307 - __main__ - WARNING -   Skipped train sample 791 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,309 - __main__ - WARNING -   Skipped train sample 792 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,311 - __main__ - WARNING -   Skipped train sample 793 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,312 - __main__ - WARNING -   Skipped train sample 794 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,314 - __main__ - WARNING -   Skipped train sample 795 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,316 - __main__ - WARNING -   Skipped train sample 796 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,318 - __main__ - WARNING -   Skipped train sample 797 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,320 - __main__ - WARNING -   Skipped train sample 798 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,322 - __main__ - WARNING -   Skipped train sample 799 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,324 - __main__ - WARNING -   Skipped train sample 800 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,325 - __main__ - WARNING -   Skipped train sample 801 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,327 - __main__ - WARNING -   Skipped train sample 802 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,329 - __main__ - WARNING -   Skipped train sample 803 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,331 - __main__ - WARNING -   Skipped train sample 804 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,333 - __main__ - WARNING -   Skipped train sample 805 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,335 - __main__ - WARNING -   Skipped train sample 806 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,337 - __main__ - WARNING -   Skipped train sample 807 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,339 - __main__ - WARNING -   Skipped train sample 808 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,341 - __main__ - WARNING -   Skipped train sample 809 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,343 - __main__ - WARNING -   Skipped train sample 810 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,345 - __main__ - WARNING -   Skipped train sample 811 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,347 - __main__ - WARNING -   Skipped train sample 812 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,349 - __main__ - WARNING -   Skipped train sample 813 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,350 - __main__ - WARNING -   Skipped train sample 814 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,352 - __main__ - WARNING -   Skipped train sample 815 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,354 - __main__ - WARNING -   Skipped train sample 816 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,356 - __main__ - WARNING -   Skipped train sample 817 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,359 - __main__ - WARNING -   Skipped train sample 818 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,360 - __main__ - WARNING -   Skipped train sample 819 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,362 - __main__ - WARNING -   Skipped train sample 820 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,364 - __main__ - WARNING -   Skipped train sample 821 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,366 - __main__ - WARNING -   Skipped train sample 822 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,368 - __main__ - WARNING -   Skipped train sample 823 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,370 - __main__ - WARNING -   Skipped train sample 824 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,372 - __main__ - WARNING -   Skipped train sample 825 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,374 - __main__ - WARNING -   Skipped train sample 826 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,375 - __main__ - WARNING -   Skipped train sample 827 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,377 - __main__ - WARNING -   Skipped train sample 828 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,379 - __main__ - WARNING -   Skipped train sample 829 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,381 - __main__ - WARNING -   Skipped train sample 830 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,383 - __main__ - WARNING -   Skipped train sample 831 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,385 - __main__ - WARNING -   Skipped train sample 832 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,387 - __main__ - WARNING -   Skipped train sample 833 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,389 - __main__ - WARNING -   Skipped train sample 834 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,391 - __main__ - WARNING -   Skipped train sample 835 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,393 - __main__ - WARNING -   Skipped train sample 836 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,395 - __main__ - WARNING -   Skipped train sample 837 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,397 - __main__ - WARNING -   Skipped train sample 838 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,399 - __main__ - WARNING -   Skipped train sample 839 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,401 - __main__ - WARNING -   Skipped train sample 840 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,402 - __main__ - WARNING -   Skipped train sample 841 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,405 - __main__ - WARNING -   Skipped train sample 842 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,407 - __main__ - WARNING -   Skipped train sample 843 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,408 - __main__ - WARNING -   Skipped train sample 844 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,410 - __main__ - WARNING -   Skipped train sample 845 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,412 - __main__ - WARNING -   Skipped train sample 846 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,414 - __main__ - WARNING -   Skipped train sample 847 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,416 - __main__ - WARNING -   Skipped train sample 848 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,418 - __main__ - WARNING -   Skipped train sample 849 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,420 - __main__ - WARNING -   Skipped train sample 850 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,422 - __main__ - WARNING -   Skipped train sample 851 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,423 - __main__ - WARNING -   Skipped train sample 852 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,425 - __main__ - WARNING -   Skipped train sample 853 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,427 - __main__ - WARNING -   Skipped train sample 854 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,429 - __main__ - WARNING -   Skipped train sample 855 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,431 - __main__ - WARNING -   Skipped train sample 856 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,432 - __main__ - WARNING -   Skipped train sample 857 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,434 - __main__ - WARNING -   Skipped train sample 858 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,436 - __main__ - WARNING -   Skipped train sample 859 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,438 - __main__ - WARNING -   Skipped train sample 860 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,440 - __main__ - WARNING -   Skipped train sample 861 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,442 - __main__ - WARNING -   Skipped train sample 862 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,444 - __main__ - WARNING -   Skipped train sample 863 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,446 - __main__ - WARNING -   Skipped train sample 864 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,448 - __main__ - WARNING -   Skipped train sample 865 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,450 - __main__ - WARNING -   Skipped train sample 866 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,452 - __main__ - WARNING -   Skipped train sample 867 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,454 - __main__ - WARNING -   Skipped train sample 868 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,456 - __main__ - WARNING -   Skipped train sample 869 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,458 - __main__ - WARNING -   Skipped train sample 870 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,460 - __main__ - WARNING -   Skipped train sample 871 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,462 - __main__ - WARNING -   Skipped train sample 872 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,464 - __main__ - WARNING -   Skipped train sample 873 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,466 - __main__ - WARNING -   Skipped train sample 874 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,468 - __main__ - WARNING -   Skipped train sample 875 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,470 - __main__ - WARNING -   Skipped train sample 876 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,472 - __main__ - WARNING -   Skipped train sample 877 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,473 - __main__ - WARNING -   Skipped train sample 878 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,475 - __main__ - WARNING -   Skipped train sample 879 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,477 - __main__ - WARNING -   Skipped train sample 880 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,479 - __main__ - WARNING -   Skipped train sample 881 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,481 - __main__ - WARNING -   Skipped train sample 882 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,482 - __main__ - WARNING -   Skipped train sample 883 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,485 - __main__ - WARNING -   Skipped train sample 884 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:36,486 - __main__ - WARNING -   Skipped train sample 885 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,488 - __main__ - WARNING -   Skipped train sample 886 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,490 - __main__ - WARNING -   Skipped train sample 887 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,492 - __main__ - WARNING -   Skipped train sample 888 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,494 - __main__ - WARNING -   Skipped train sample 889 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,496 - __main__ - WARNING -   Skipped train sample 890 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,498 - __main__ - WARNING -   Skipped train sample 891 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,500 - __main__ - WARNING -   Skipped train sample 892 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,501 - __main__ - WARNING -   Skipped train sample 893 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,503 - __main__ - WARNING -   Skipped train sample 894 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,505 - __main__ - WARNING -   Skipped train sample 895 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,507 - __main__ - WARNING -   Skipped train sample 896 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,509 - __main__ - WARNING -   Skipped train sample 897 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,511 - __main__ - WARNING -   Skipped train sample 898 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,513 - __main__ - WARNING -   Skipped train sample 899 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,515 - __main__ - WARNING -   Skipped train sample 900 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:36,517 - __main__ - WARNING -   Skipped train sample 901 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,519 - __main__ - WARNING -   Skipped train sample 902 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,520 - __main__ - WARNING -   Skipped train sample 903 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,522 - __main__ - WARNING -   Skipped train sample 904 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,524 - __main__ - WARNING -   Skipped train sample 905 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,526 - __main__ - WARNING -   Skipped train sample 906 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,528 - __main__ - WARNING -   Skipped train sample 907 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,530 - __main__ - WARNING -   Skipped train sample 908 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,532 - __main__ - WARNING -   Skipped train sample 909 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,534 - __main__ - WARNING -   Skipped train sample 910 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,536 - __main__ - WARNING -   Skipped train sample 911 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,538 - __main__ - WARNING -   Skipped train sample 912 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,539 - __main__ - WARNING -   Skipped train sample 913 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,541 - __main__ - WARNING -   Skipped train sample 914 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,543 - __main__ - WARNING -   Skipped train sample 915 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,545 - __main__ - WARNING -   Skipped train sample 916 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,547 - __main__ - WARNING -   Skipped train sample 917 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,549 - __main__ - WARNING -   Skipped train sample 918 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,551 - __main__ - WARNING -   Skipped train sample 919 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,553 - __main__ - WARNING -   Skipped train sample 920 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,555 - __main__ - WARNING -   Skipped train sample 921 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,557 - __main__ - WARNING -   Skipped train sample 922 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,559 - __main__ - WARNING -   Skipped train sample 923 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,560 - __main__ - WARNING -   Skipped train sample 924 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,563 - __main__ - WARNING -   Skipped train sample 925 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,565 - __main__ - WARNING -   Skipped train sample 926 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,566 - __main__ - WARNING -   Skipped train sample 927 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,568 - __main__ - WARNING -   Skipped train sample 928 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,570 - __main__ - WARNING -   Skipped train sample 929 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,572 - __main__ - WARNING -   Skipped train sample 930 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,574 - __main__ - WARNING -   Skipped train sample 931 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,576 - __main__ - WARNING -   Skipped train sample 932 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,578 - __main__ - WARNING -   Skipped train sample 933 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,580 - __main__ - WARNING -   Skipped train sample 934 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,582 - __main__ - WARNING -   Skipped train sample 935 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,584 - __main__ - WARNING -   Skipped train sample 936 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,586 - __main__ - WARNING -   Skipped train sample 937 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,589 - __main__ - WARNING -   Skipped train sample 938 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,591 - __main__ - WARNING -   Skipped train sample 939 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,592 - __main__ - WARNING -   Skipped train sample 940 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,594 - __main__ - WARNING -   Skipped train sample 941 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,596 - __main__ - WARNING -   Skipped train sample 942 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,598 - __main__ - WARNING -   Skipped train sample 943 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,600 - __main__ - WARNING -   Skipped train sample 944 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,602 - __main__ - WARNING -   Skipped train sample 945 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,604 - __main__ - WARNING -   Skipped train sample 946 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,606 - __main__ - WARNING -   Skipped train sample 947 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,608 - __main__ - WARNING -   Skipped train sample 948 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,610 - __main__ - WARNING -   Skipped train sample 949 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,611 - __main__ - WARNING -   Skipped train sample 950 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,613 - __main__ - WARNING -   Skipped train sample 951 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,615 - __main__ - WARNING -   Skipped train sample 952 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,617 - __main__ - WARNING -   Skipped train sample 953 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,619 - __main__ - WARNING -   Skipped train sample 954 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,621 - __main__ - WARNING -   Skipped train sample 955 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,623 - __main__ - WARNING -   Skipped train sample 956 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,624 - __main__ - WARNING -   Skipped train sample 957 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,626 - __main__ - WARNING -   Skipped train sample 958 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,628 - __main__ - WARNING -   Skipped train sample 959 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,630 - __main__ - WARNING -   Skipped train sample 960 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,632 - __main__ - WARNING -   Skipped train sample 961 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,634 - __main__ - WARNING -   Skipped train sample 962 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,636 - __main__ - WARNING -   Skipped train sample 963 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,638 - __main__ - WARNING -   Skipped train sample 964 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,640 - __main__ - WARNING -   Skipped train sample 965 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,642 - __main__ - WARNING -   Skipped train sample 966 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,644 - __main__ - WARNING -   Skipped train sample 967 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,645 - __main__ - WARNING -   Skipped train sample 968 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,647 - __main__ - WARNING -   Skipped train sample 969 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,649 - __main__ - WARNING -   Skipped train sample 970 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,651 - __main__ - WARNING -   Skipped train sample 971 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,653 - __main__ - WARNING -   Skipped train sample 972 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,655 - __main__ - WARNING -   Skipped train sample 973 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,657 - __main__ - WARNING -   Skipped train sample 974 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,659 - __main__ - WARNING -   Skipped train sample 975 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,660 - __main__ - WARNING -   Skipped train sample 976 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,662 - __main__ - WARNING -   Skipped train sample 977 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,664 - __main__ - WARNING -   Skipped train sample 978 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,666 - __main__ - WARNING -   Skipped train sample 979 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,668 - __main__ - WARNING -   Skipped train sample 980 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,670 - __main__ - WARNING -   Skipped train sample 981 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,672 - __main__ - WARNING -   Skipped train sample 982 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,673 - __main__ - WARNING -   Skipped train sample 983 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,675 - __main__ - WARNING -   Skipped train sample 984 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,677 - __main__ - WARNING -   Skipped train sample 985 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,679 - __main__ - WARNING -   Skipped train sample 986 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,682 - __main__ - WARNING -   Skipped train sample 987 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,684 - __main__ - WARNING -   Skipped train sample 988 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,685 - __main__ - WARNING -   Skipped train sample 989 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,687 - __main__ - WARNING -   Skipped train sample 990 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,689 - __main__ - WARNING -   Skipped train sample 991 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,691 - __main__ - WARNING -   Skipped train sample 992 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,693 - __main__ - WARNING -   Skipped train sample 993 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,695 - __main__ - WARNING -   Skipped train sample 994 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,697 - __main__ - WARNING -   Skipped train sample 995 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,698 - __main__ - WARNING -   Skipped train sample 996 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,700 - __main__ - WARNING -   Skipped train sample 997 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,702 - __main__ - WARNING -   Skipped train sample 998 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,704 - __main__ - WARNING -   Skipped train sample 999 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,704 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-21 22:09:36,706 - __main__ - WARNING -   Skipped train sample 1000 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,708 - __main__ - WARNING -   Skipped train sample 1001 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,710 - __main__ - WARNING -   Skipped train sample 1002 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,712 - __main__ - WARNING -   Skipped train sample 1003 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,714 - __main__ - WARNING -   Skipped train sample 1004 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,716 - __main__ - WARNING -   Skipped train sample 1005 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,718 - __main__ - WARNING -   Skipped train sample 1006 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,720 - __main__ - WARNING -   Skipped train sample 1007 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,722 - __main__ - WARNING -   Skipped train sample 1008 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,724 - __main__ - WARNING -   Skipped train sample 1009 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,726 - __main__ - WARNING -   Skipped train sample 1010 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,728 - __main__ - WARNING -   Skipped train sample 1011 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,729 - __main__ - WARNING -   Skipped train sample 1012 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,732 - __main__ - WARNING -   Skipped train sample 1013 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,734 - __main__ - WARNING -   Skipped train sample 1014 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,735 - __main__ - WARNING -   Skipped train sample 1015 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,738 - __main__ - WARNING -   Skipped train sample 1016 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,740 - __main__ - WARNING -   Skipped train sample 1017 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,742 - __main__ - WARNING -   Skipped train sample 1018 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,744 - __main__ - WARNING -   Skipped train sample 1019 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,745 - __main__ - WARNING -   Skipped train sample 1020 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,747 - __main__ - WARNING -   Skipped train sample 1021 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,749 - __main__ - WARNING -   Skipped train sample 1022 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,751 - __main__ - WARNING -   Skipped train sample 1023 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,753 - __main__ - WARNING -   Skipped train sample 1024 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,755 - __main__ - WARNING -   Skipped train sample 1025 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,757 - __main__ - WARNING -   Skipped train sample 1026 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,759 - __main__ - WARNING -   Skipped train sample 1027 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,760 - __main__ - WARNING -   Skipped train sample 1028 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,763 - __main__ - WARNING -   Skipped train sample 1029 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,764 - __main__ - WARNING -   Skipped train sample 1030 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,766 - __main__ - WARNING -   Skipped train sample 1031 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,768 - __main__ - WARNING -   Skipped train sample 1032 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,770 - __main__ - WARNING -   Skipped train sample 1033 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,772 - __main__ - WARNING -   Skipped train sample 1034 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,774 - __main__ - WARNING -   Skipped train sample 1035 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,776 - __main__ - WARNING -   Skipped train sample 1036 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,778 - __main__ - WARNING -   Skipped train sample 1037 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,780 - __main__ - WARNING -   Skipped train sample 1038 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,782 - __main__ - WARNING -   Skipped train sample 1039 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,784 - __main__ - WARNING -   Skipped train sample 1040 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,786 - __main__ - WARNING -   Skipped train sample 1041 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:36,788 - __main__ - WARNING -   Skipped train sample 1042 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,790 - __main__ - WARNING -   Skipped train sample 1043 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,792 - __main__ - WARNING -   Skipped train sample 1044 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,795 - __main__ - WARNING -   Skipped train sample 1045 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,796 - __main__ - WARNING -   Skipped train sample 1046 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,798 - __main__ - WARNING -   Skipped train sample 1047 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,800 - __main__ - WARNING -   Skipped train sample 1048 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,802 - __main__ - WARNING -   Skipped train sample 1049 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,804 - __main__ - WARNING -   Skipped train sample 1050 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,806 - __main__ - WARNING -   Skipped train sample 1051 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,808 - __main__ - WARNING -   Skipped train sample 1052 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,809 - __main__ - WARNING -   Skipped train sample 1053 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,811 - __main__ - WARNING -   Skipped train sample 1054 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,813 - __main__ - WARNING -   Skipped train sample 1055 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,815 - __main__ - WARNING -   Skipped train sample 1056 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,817 - __main__ - WARNING -   Skipped train sample 1057 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,819 - __main__ - WARNING -   Skipped train sample 1058 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,820 - __main__ - WARNING -   Skipped train sample 1059 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,822 - __main__ - WARNING -   Skipped train sample 1060 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,824 - __main__ - WARNING -   Skipped train sample 1061 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,826 - __main__ - WARNING -   Skipped train sample 1062 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,828 - __main__ - WARNING -   Skipped train sample 1063 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,830 - __main__ - WARNING -   Skipped train sample 1064 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,832 - __main__ - WARNING -   Skipped train sample 1065 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,834 - __main__ - WARNING -   Skipped train sample 1066 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,836 - __main__ - WARNING -   Skipped train sample 1067 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,838 - __main__ - WARNING -   Skipped train sample 1068 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,840 - __main__ - WARNING -   Skipped train sample 1069 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,842 - __main__ - WARNING -   Skipped train sample 1070 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,844 - __main__ - WARNING -   Skipped train sample 1071 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,846 - __main__ - WARNING -   Skipped train sample 1072 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,848 - __main__ - WARNING -   Skipped train sample 1073 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,850 - __main__ - WARNING -   Skipped train sample 1074 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,852 - __main__ - WARNING -   Skipped train sample 1075 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,854 - __main__ - WARNING -   Skipped train sample 1076 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,856 - __main__ - WARNING -   Skipped train sample 1077 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,858 - __main__ - WARNING -   Skipped train sample 1078 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,859 - __main__ - WARNING -   Skipped train sample 1079 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,861 - __main__ - WARNING -   Skipped train sample 1080 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,863 - __main__ - WARNING -   Skipped train sample 1081 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,865 - __main__ - WARNING -   Skipped train sample 1082 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,867 - __main__ - WARNING -   Skipped train sample 1083 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,869 - __main__ - WARNING -   Skipped train sample 1084 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,871 - __main__ - WARNING -   Skipped train sample 1085 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,873 - __main__ - WARNING -   Skipped train sample 1086 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,874 - __main__ - WARNING -   Skipped train sample 1087 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,876 - __main__ - WARNING -   Skipped train sample 1088 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,878 - __main__ - WARNING -   Skipped train sample 1089 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,880 - __main__ - WARNING -   Skipped train sample 1090 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,882 - __main__ - WARNING -   Skipped train sample 1091 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,884 - __main__ - WARNING -   Skipped train sample 1092 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,886 - __main__ - WARNING -   Skipped train sample 1093 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,888 - __main__ - WARNING -   Skipped train sample 1094 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,890 - __main__ - WARNING -   Skipped train sample 1095 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,892 - __main__ - WARNING -   Skipped train sample 1096 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,894 - __main__ - WARNING -   Skipped train sample 1097 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,895 - __main__ - WARNING -   Skipped train sample 1098 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,897 - __main__ - WARNING -   Skipped train sample 1099 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,899 - __main__ - WARNING -   Skipped train sample 1100 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,901 - __main__ - WARNING -   Skipped train sample 1101 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,903 - __main__ - WARNING -   Skipped train sample 1102 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,905 - __main__ - WARNING -   Skipped train sample 1103 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,907 - __main__ - WARNING -   Skipped train sample 1104 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,908 - __main__ - WARNING -   Skipped train sample 1105 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,911 - __main__ - WARNING -   Skipped train sample 1106 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,913 - __main__ - WARNING -   Skipped train sample 1107 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,915 - __main__ - WARNING -   Skipped train sample 1108 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,916 - __main__ - WARNING -   Skipped train sample 1109 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,918 - __main__ - WARNING -   Skipped train sample 1110 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,920 - __main__ - WARNING -   Skipped train sample 1111 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,922 - __main__ - WARNING -   Skipped train sample 1112 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,924 - __main__ - WARNING -   Skipped train sample 1113 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,926 - __main__ - WARNING -   Skipped train sample 1114 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,928 - __main__ - WARNING -   Skipped train sample 1115 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,930 - __main__ - WARNING -   Skipped train sample 1116 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,932 - __main__ - WARNING -   Skipped train sample 1117 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,933 - __main__ - WARNING -   Skipped train sample 1118 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,935 - __main__ - WARNING -   Skipped train sample 1119 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,937 - __main__ - WARNING -   Skipped train sample 1120 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,939 - __main__ - WARNING -   Skipped train sample 1121 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,941 - __main__ - WARNING -   Skipped train sample 1122 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,943 - __main__ - WARNING -   Skipped train sample 1123 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,945 - __main__ - WARNING -   Skipped train sample 1124 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,947 - __main__ - WARNING -   Skipped train sample 1125 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,948 - __main__ - WARNING -   Skipped train sample 1126 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,950 - __main__ - WARNING -   Skipped train sample 1127 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,952 - __main__ - WARNING -   Skipped train sample 1128 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,954 - __main__ - WARNING -   Skipped train sample 1129 due to error: invalid literal for int() with base 10: 'signer_4'
2025-09-21 22:09:36,956 - __main__ - WARNING -   Skipped train sample 1130 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,958 - __main__ - WARNING -   Skipped train sample 1131 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,960 - __main__ - WARNING -   Skipped train sample 1132 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,962 - __main__ - WARNING -   Skipped train sample 1133 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,964 - __main__ - WARNING -   Skipped train sample 1134 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,966 - __main__ - WARNING -   Skipped train sample 1135 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,968 - __main__ - WARNING -   Skipped train sample 1136 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,970 - __main__ - WARNING -   Skipped train sample 1137 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,972 - __main__ - WARNING -   Skipped train sample 1138 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,974 - __main__ - WARNING -   Skipped train sample 1139 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,976 - __main__ - WARNING -   Skipped train sample 1140 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,978 - __main__ - WARNING -   Skipped train sample 1141 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,980 - __main__ - WARNING -   Skipped train sample 1142 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,982 - __main__ - WARNING -   Skipped train sample 1143 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,984 - __main__ - WARNING -   Skipped train sample 1144 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,986 - __main__ - WARNING -   Skipped train sample 1145 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,988 - __main__ - WARNING -   Skipped train sample 1146 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,990 - __main__ - WARNING -   Skipped train sample 1147 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,991 - __main__ - WARNING -   Skipped train sample 1148 due to error: cannot convert float NaN to integer
2025-09-21 22:09:36,993 - __main__ - WARNING -   Skipped train sample 1149 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,995 - __main__ - WARNING -   Skipped train sample 1150 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:36,997 - __main__ - WARNING -   Skipped train sample 1151 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:36,999 - __main__ - WARNING -   Skipped train sample 1152 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,001 - __main__ - WARNING -   Skipped train sample 1153 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,003 - __main__ - WARNING -   Skipped train sample 1154 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,005 - __main__ - WARNING -   Skipped train sample 1155 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,007 - __main__ - WARNING -   Skipped train sample 1156 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,009 - __main__ - WARNING -   Skipped train sample 1157 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,011 - __main__ - WARNING -   Skipped train sample 1158 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,013 - __main__ - WARNING -   Skipped train sample 1159 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,014 - __main__ - WARNING -   Skipped train sample 1160 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,016 - __main__ - WARNING -   Skipped train sample 1161 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,018 - __main__ - WARNING -   Skipped train sample 1162 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,020 - __main__ - WARNING -   Skipped train sample 1163 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,022 - __main__ - WARNING -   Skipped train sample 1164 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,024 - __main__ - WARNING -   Skipped train sample 1165 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,026 - __main__ - WARNING -   Skipped train sample 1166 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,028 - __main__ - WARNING -   Skipped train sample 1167 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,029 - __main__ - WARNING -   Skipped train sample 1168 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,031 - __main__ - WARNING -   Skipped train sample 1169 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,033 - __main__ - WARNING -   Skipped train sample 1170 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,035 - __main__ - WARNING -   Skipped train sample 1171 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,037 - __main__ - WARNING -   Skipped train sample 1172 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,039 - __main__ - WARNING -   Skipped train sample 1173 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,041 - __main__ - WARNING -   Skipped train sample 1174 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,043 - __main__ - WARNING -   Skipped train sample 1175 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,045 - __main__ - WARNING -   Skipped train sample 1176 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,047 - __main__ - WARNING -   Skipped train sample 1177 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,049 - __main__ - WARNING -   Skipped train sample 1178 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,050 - __main__ - WARNING -   Skipped train sample 1179 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,052 - __main__ - WARNING -   Skipped train sample 1180 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,054 - __main__ - WARNING -   Skipped train sample 1181 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,056 - __main__ - WARNING -   Skipped train sample 1182 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,058 - __main__ - WARNING -   Skipped train sample 1183 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,060 - __main__ - WARNING -   Skipped train sample 1184 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,062 - __main__ - WARNING -   Skipped train sample 1185 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,064 - __main__ - WARNING -   Skipped train sample 1186 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,066 - __main__ - WARNING -   Skipped train sample 1187 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,068 - __main__ - WARNING -   Skipped train sample 1188 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,069 - __main__ - WARNING -   Skipped train sample 1189 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,072 - __main__ - WARNING -   Skipped train sample 1190 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,073 - __main__ - WARNING -   Skipped train sample 1191 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,075 - __main__ - WARNING -   Skipped train sample 1192 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,077 - __main__ - WARNING -   Skipped train sample 1193 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,079 - __main__ - WARNING -   Skipped train sample 1194 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,081 - __main__ - WARNING -   Skipped train sample 1195 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,083 - __main__ - WARNING -   Skipped train sample 1196 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,085 - __main__ - WARNING -   Skipped train sample 1197 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,087 - __main__ - WARNING -   Skipped train sample 1198 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,089 - __main__ - WARNING -   Skipped train sample 1199 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,091 - __main__ - WARNING -   Skipped train sample 1200 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,093 - __main__ - WARNING -   Skipped train sample 1201 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,095 - __main__ - WARNING -   Skipped train sample 1202 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,097 - __main__ - WARNING -   Skipped train sample 1203 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,098 - __main__ - WARNING -   Skipped train sample 1204 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,100 - __main__ - WARNING -   Skipped train sample 1205 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,102 - __main__ - WARNING -   Skipped train sample 1206 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,104 - __main__ - WARNING -   Skipped train sample 1207 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,106 - __main__ - WARNING -   Skipped train sample 1208 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,108 - __main__ - WARNING -   Skipped train sample 1209 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,110 - __main__ - WARNING -   Skipped train sample 1210 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,112 - __main__ - WARNING -   Skipped train sample 1211 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,114 - __main__ - WARNING -   Skipped train sample 1212 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,116 - __main__ - WARNING -   Skipped train sample 1213 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,117 - __main__ - WARNING -   Skipped train sample 1214 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,119 - __main__ - WARNING -   Skipped train sample 1215 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,121 - __main__ - WARNING -   Skipped train sample 1216 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,123 - __main__ - WARNING -   Skipped train sample 1217 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,125 - __main__ - WARNING -   Skipped train sample 1218 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,127 - __main__ - WARNING -   Skipped train sample 1219 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,128 - __main__ - WARNING -   Skipped train sample 1220 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,130 - __main__ - WARNING -   Skipped train sample 1221 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,132 - __main__ - WARNING -   Skipped train sample 1222 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,134 - __main__ - WARNING -   Skipped train sample 1223 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,136 - __main__ - WARNING -   Skipped train sample 1224 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,138 - __main__ - WARNING -   Skipped train sample 1225 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,140 - __main__ - WARNING -   Skipped train sample 1226 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,142 - __main__ - WARNING -   Skipped train sample 1227 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,144 - __main__ - WARNING -   Skipped train sample 1228 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,146 - __main__ - WARNING -   Skipped train sample 1229 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,147 - __main__ - WARNING -   Skipped train sample 1230 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,149 - __main__ - WARNING -   Skipped train sample 1231 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,151 - __main__ - WARNING -   Skipped train sample 1232 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,153 - __main__ - WARNING -   Skipped train sample 1233 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,155 - __main__ - WARNING -   Skipped train sample 1234 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,157 - __main__ - WARNING -   Skipped train sample 1235 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,159 - __main__ - WARNING -   Skipped train sample 1236 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,161 - __main__ - WARNING -   Skipped train sample 1237 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,163 - __main__ - WARNING -   Skipped train sample 1238 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,165 - __main__ - WARNING -   Skipped train sample 1239 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,166 - __main__ - WARNING -   Skipped train sample 1240 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,168 - __main__ - WARNING -   Skipped train sample 1241 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,170 - __main__ - WARNING -   Skipped train sample 1242 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,172 - __main__ - WARNING -   Skipped train sample 1243 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,174 - __main__ - WARNING -   Skipped train sample 1244 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,176 - __main__ - WARNING -   Skipped train sample 1245 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,178 - __main__ - WARNING -   Skipped train sample 1246 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,180 - __main__ - WARNING -   Skipped train sample 1247 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,182 - __main__ - WARNING -   Skipped train sample 1248 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,184 - __main__ - WARNING -   Skipped train sample 1249 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,186 - __main__ - WARNING -   Skipped train sample 1250 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,188 - __main__ - WARNING -   Skipped train sample 1251 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,189 - __main__ - WARNING -   Skipped train sample 1252 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,192 - __main__ - WARNING -   Skipped train sample 1253 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,194 - __main__ - WARNING -   Skipped train sample 1254 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,195 - __main__ - WARNING -   Skipped train sample 1255 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,197 - __main__ - WARNING -   Skipped train sample 1256 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,199 - __main__ - WARNING -   Skipped train sample 1257 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,201 - __main__ - WARNING -   Skipped train sample 1258 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,203 - __main__ - WARNING -   Skipped train sample 1259 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,205 - __main__ - WARNING -   Skipped train sample 1260 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,207 - __main__ - WARNING -   Skipped train sample 1261 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,208 - __main__ - WARNING -   Skipped train sample 1262 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,210 - __main__ - WARNING -   Skipped train sample 1263 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,212 - __main__ - WARNING -   Skipped train sample 1264 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,214 - __main__ - WARNING -   Skipped train sample 1265 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,216 - __main__ - WARNING -   Skipped train sample 1266 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,218 - __main__ - WARNING -   Skipped train sample 1267 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,220 - __main__ - WARNING -   Skipped train sample 1268 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,222 - __main__ - WARNING -   Skipped train sample 1269 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,223 - __main__ - WARNING -   Skipped train sample 1270 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,225 - __main__ - WARNING -   Skipped train sample 1271 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,227 - __main__ - WARNING -   Skipped train sample 1272 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,229 - __main__ - WARNING -   Skipped train sample 1273 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,231 - __main__ - WARNING -   Skipped train sample 1274 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,233 - __main__ - WARNING -   Skipped train sample 1275 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,235 - __main__ - WARNING -   Skipped train sample 1276 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,237 - __main__ - WARNING -   Skipped train sample 1277 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,239 - __main__ - WARNING -   Skipped train sample 1278 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,240 - __main__ - WARNING -   Skipped train sample 1279 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,243 - __main__ - WARNING -   Skipped train sample 1280 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,244 - __main__ - WARNING -   Skipped train sample 1281 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,246 - __main__ - WARNING -   Skipped train sample 1282 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,248 - __main__ - WARNING -   Skipped train sample 1283 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,250 - __main__ - WARNING -   Skipped train sample 1284 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,252 - __main__ - WARNING -   Skipped train sample 1285 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,254 - __main__ - WARNING -   Skipped train sample 1286 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,256 - __main__ - WARNING -   Skipped train sample 1287 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,257 - __main__ - WARNING -   Skipped train sample 1288 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,259 - __main__ - WARNING -   Skipped train sample 1289 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,261 - __main__ - WARNING -   Skipped train sample 1290 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,263 - __main__ - WARNING -   Skipped train sample 1291 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,265 - __main__ - WARNING -   Skipped train sample 1292 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,267 - __main__ - WARNING -   Skipped train sample 1293 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,269 - __main__ - WARNING -   Skipped train sample 1294 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,271 - __main__ - WARNING -   Skipped train sample 1295 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,273 - __main__ - WARNING -   Skipped train sample 1296 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,274 - __main__ - WARNING -   Skipped train sample 1297 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,276 - __main__ - WARNING -   Skipped train sample 1298 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,278 - __main__ - WARNING -   Skipped train sample 1299 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,280 - __main__ - WARNING -   Skipped train sample 1300 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,282 - __main__ - WARNING -   Skipped train sample 1301 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,284 - __main__ - WARNING -   Skipped train sample 1302 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,286 - __main__ - WARNING -   Skipped train sample 1303 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,288 - __main__ - WARNING -   Skipped train sample 1304 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,290 - __main__ - WARNING -   Skipped train sample 1305 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,292 - __main__ - WARNING -   Skipped train sample 1306 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,294 - __main__ - WARNING -   Skipped train sample 1307 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,295 - __main__ - WARNING -   Skipped train sample 1308 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,297 - __main__ - WARNING -   Skipped train sample 1309 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,299 - __main__ - WARNING -   Skipped train sample 1310 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,301 - __main__ - WARNING -   Skipped train sample 1311 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,303 - __main__ - WARNING -   Skipped train sample 1312 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,305 - __main__ - WARNING -   Skipped train sample 1313 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,307 - __main__ - WARNING -   Skipped train sample 1314 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,309 - __main__ - WARNING -   Skipped train sample 1315 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,311 - __main__ - WARNING -   Skipped train sample 1316 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,313 - __main__ - WARNING -   Skipped train sample 1317 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,315 - __main__ - WARNING -   Skipped train sample 1318 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,317 - __main__ - WARNING -   Skipped train sample 1319 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,319 - __main__ - WARNING -   Skipped train sample 1320 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,321 - __main__ - WARNING -   Skipped train sample 1321 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,323 - __main__ - WARNING -   Skipped train sample 1322 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,325 - __main__ - WARNING -   Skipped train sample 1323 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,327 - __main__ - WARNING -   Skipped train sample 1324 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,329 - __main__ - WARNING -   Skipped train sample 1325 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,331 - __main__ - WARNING -   Skipped train sample 1326 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,332 - __main__ - WARNING -   Skipped train sample 1327 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,334 - __main__ - WARNING -   Skipped train sample 1328 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,336 - __main__ - WARNING -   Skipped train sample 1329 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,338 - __main__ - WARNING -   Skipped train sample 1330 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,340 - __main__ - WARNING -   Skipped train sample 1331 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,342 - __main__ - WARNING -   Skipped train sample 1332 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,344 - __main__ - WARNING -   Skipped train sample 1333 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,346 - __main__ - WARNING -   Skipped train sample 1334 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,348 - __main__ - WARNING -   Skipped train sample 1335 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,350 - __main__ - WARNING -   Skipped train sample 1336 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,352 - __main__ - WARNING -   Skipped train sample 1337 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,354 - __main__ - WARNING -   Skipped train sample 1338 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,355 - __main__ - WARNING -   Skipped train sample 1339 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,357 - __main__ - WARNING -   Skipped train sample 1340 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,359 - __main__ - WARNING -   Skipped train sample 1341 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,361 - __main__ - WARNING -   Skipped train sample 1342 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,363 - __main__ - WARNING -   Skipped train sample 1343 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,364 - __main__ - WARNING -   Skipped train sample 1344 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,366 - __main__ - WARNING -   Skipped train sample 1345 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,368 - __main__ - WARNING -   Skipped train sample 1346 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,370 - __main__ - WARNING -   Skipped train sample 1347 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,372 - __main__ - WARNING -   Skipped train sample 1348 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,374 - __main__ - WARNING -   Skipped train sample 1349 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,376 - __main__ - WARNING -   Skipped train sample 1350 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,378 - __main__ - WARNING -   Skipped train sample 1351 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,380 - __main__ - WARNING -   Skipped train sample 1352 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,382 - __main__ - WARNING -   Skipped train sample 1353 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,384 - __main__ - WARNING -   Skipped train sample 1354 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,386 - __main__ - WARNING -   Skipped train sample 1355 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,388 - __main__ - WARNING -   Skipped train sample 1356 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,390 - __main__ - WARNING -   Skipped train sample 1357 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,391 - __main__ - WARNING -   Skipped train sample 1358 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,393 - __main__ - WARNING -   Skipped train sample 1359 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,395 - __main__ - WARNING -   Skipped train sample 1360 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,397 - __main__ - WARNING -   Skipped train sample 1361 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,399 - __main__ - WARNING -   Skipped train sample 1362 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,401 - __main__ - WARNING -   Skipped train sample 1363 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,403 - __main__ - WARNING -   Skipped train sample 1364 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,405 - __main__ - WARNING -   Skipped train sample 1365 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,406 - __main__ - WARNING -   Skipped train sample 1366 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,408 - __main__ - WARNING -   Skipped train sample 1367 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,410 - __main__ - WARNING -   Skipped train sample 1368 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,412 - __main__ - WARNING -   Skipped train sample 1369 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,414 - __main__ - WARNING -   Skipped train sample 1370 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,416 - __main__ - WARNING -   Skipped train sample 1371 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,418 - __main__ - WARNING -   Skipped train sample 1372 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,420 - __main__ - WARNING -   Skipped train sample 1373 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,422 - __main__ - WARNING -   Skipped train sample 1374 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,424 - __main__ - WARNING -   Skipped train sample 1375 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,426 - __main__ - WARNING -   Skipped train sample 1376 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,428 - __main__ - WARNING -   Skipped train sample 1377 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,430 - __main__ - WARNING -   Skipped train sample 1378 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,431 - __main__ - WARNING -   Skipped train sample 1379 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,433 - __main__ - WARNING -   Skipped train sample 1380 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,435 - __main__ - WARNING -   Skipped train sample 1381 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,437 - __main__ - WARNING -   Skipped train sample 1382 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,439 - __main__ - WARNING -   Skipped train sample 1383 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,441 - __main__ - WARNING -   Skipped train sample 1384 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,443 - __main__ - WARNING -   Skipped train sample 1385 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,445 - __main__ - WARNING -   Skipped train sample 1386 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,447 - __main__ - WARNING -   Skipped train sample 1387 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,449 - __main__ - WARNING -   Skipped train sample 1388 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,451 - __main__ - WARNING -   Skipped train sample 1389 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,453 - __main__ - WARNING -   Skipped train sample 1390 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,455 - __main__ - WARNING -   Skipped train sample 1391 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,456 - __main__ - WARNING -   Skipped train sample 1392 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,458 - __main__ - WARNING -   Skipped train sample 1393 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,460 - __main__ - WARNING -   Skipped train sample 1394 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,462 - __main__ - WARNING -   Skipped train sample 1395 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,464 - __main__ - WARNING -   Skipped train sample 1396 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,466 - __main__ - WARNING -   Skipped train sample 1397 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,468 - __main__ - WARNING -   Skipped train sample 1398 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,470 - __main__ - WARNING -   Skipped train sample 1399 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,472 - __main__ - WARNING -   Skipped train sample 1400 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,474 - __main__ - WARNING -   Skipped train sample 1401 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,476 - __main__ - WARNING -   Skipped train sample 1402 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,478 - __main__ - WARNING -   Skipped train sample 1403 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,480 - __main__ - WARNING -   Skipped train sample 1404 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,482 - __main__ - WARNING -   Skipped train sample 1405 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,484 - __main__ - WARNING -   Skipped train sample 1406 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,486 - __main__ - WARNING -   Skipped train sample 1407 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,487 - __main__ - WARNING -   Skipped train sample 1408 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,489 - __main__ - WARNING -   Skipped train sample 1409 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,491 - __main__ - WARNING -   Skipped train sample 1410 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,493 - __main__ - WARNING -   Skipped train sample 1411 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,495 - __main__ - WARNING -   Skipped train sample 1412 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,497 - __main__ - WARNING -   Skipped train sample 1413 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,499 - __main__ - WARNING -   Skipped train sample 1414 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,501 - __main__ - WARNING -   Skipped train sample 1415 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,503 - __main__ - WARNING -   Skipped train sample 1416 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,504 - __main__ - WARNING -   Skipped train sample 1417 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,507 - __main__ - WARNING -   Skipped train sample 1418 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,508 - __main__ - WARNING -   Skipped train sample 1419 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,510 - __main__ - WARNING -   Skipped train sample 1420 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,512 - __main__ - WARNING -   Skipped train sample 1421 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,514 - __main__ - WARNING -   Skipped train sample 1422 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,516 - __main__ - WARNING -   Skipped train sample 1423 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,518 - __main__ - WARNING -   Skipped train sample 1424 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,520 - __main__ - WARNING -   Skipped train sample 1425 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,522 - __main__ - WARNING -   Skipped train sample 1426 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,524 - __main__ - WARNING -   Skipped train sample 1427 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,526 - __main__ - WARNING -   Skipped train sample 1428 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,528 - __main__ - WARNING -   Skipped train sample 1429 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,530 - __main__ - WARNING -   Skipped train sample 1430 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,532 - __main__ - WARNING -   Skipped train sample 1431 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,534 - __main__ - WARNING -   Skipped train sample 1432 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,535 - __main__ - WARNING -   Skipped train sample 1433 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,537 - __main__ - WARNING -   Skipped train sample 1434 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,539 - __main__ - WARNING -   Skipped train sample 1435 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,541 - __main__ - WARNING -   Skipped train sample 1436 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,542 - __main__ - WARNING -   Skipped train sample 1437 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,544 - __main__ - WARNING -   Skipped train sample 1438 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,546 - __main__ - WARNING -   Skipped train sample 1439 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,548 - __main__ - WARNING -   Skipped train sample 1440 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,550 - __main__ - WARNING -   Skipped train sample 1441 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,552 - __main__ - WARNING -   Skipped train sample 1442 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,554 - __main__ - WARNING -   Skipped train sample 1443 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,556 - __main__ - WARNING -   Skipped train sample 1444 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,558 - __main__ - WARNING -   Skipped train sample 1445 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,560 - __main__ - WARNING -   Skipped train sample 1446 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,562 - __main__ - WARNING -   Skipped train sample 1447 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,564 - __main__ - WARNING -   Skipped train sample 1448 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,565 - __main__ - WARNING -   Skipped train sample 1449 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,567 - __main__ - WARNING -   Skipped train sample 1450 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,569 - __main__ - WARNING -   Skipped train sample 1451 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,571 - __main__ - WARNING -   Skipped train sample 1452 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,573 - __main__ - WARNING -   Skipped train sample 1453 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,575 - __main__ - WARNING -   Skipped train sample 1454 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,577 - __main__ - WARNING -   Skipped train sample 1455 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,579 - __main__ - WARNING -   Skipped train sample 1456 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,580 - __main__ - WARNING -   Skipped train sample 1457 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,582 - __main__ - WARNING -   Skipped train sample 1458 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,584 - __main__ - WARNING -   Skipped train sample 1459 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,586 - __main__ - WARNING -   Skipped train sample 1460 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,588 - __main__ - WARNING -   Skipped train sample 1461 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,590 - __main__ - WARNING -   Skipped train sample 1462 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,592 - __main__ - WARNING -   Skipped train sample 1463 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,594 - __main__ - WARNING -   Skipped train sample 1464 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,596 - __main__ - WARNING -   Skipped train sample 1465 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,598 - __main__ - WARNING -   Skipped train sample 1466 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,600 - __main__ - WARNING -   Skipped train sample 1467 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,601 - __main__ - WARNING -   Skipped train sample 1468 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,603 - __main__ - WARNING -   Skipped train sample 1469 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,605 - __main__ - WARNING -   Skipped train sample 1470 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,607 - __main__ - WARNING -   Skipped train sample 1471 due to error: invalid literal for int() with base 10: 'signer_4'
2025-09-21 22:09:37,609 - __main__ - WARNING -   Skipped train sample 1472 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,611 - __main__ - WARNING -   Skipped train sample 1473 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,613 - __main__ - WARNING -   Skipped train sample 1474 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,615 - __main__ - WARNING -   Skipped train sample 1475 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,616 - __main__ - WARNING -   Skipped train sample 1476 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,618 - __main__ - WARNING -   Skipped train sample 1477 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,620 - __main__ - WARNING -   Skipped train sample 1478 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,622 - __main__ - WARNING -   Skipped train sample 1479 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,624 - __main__ - WARNING -   Skipped train sample 1480 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,626 - __main__ - WARNING -   Skipped train sample 1481 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,628 - __main__ - WARNING -   Skipped train sample 1482 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,630 - __main__ - WARNING -   Skipped train sample 1483 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,632 - __main__ - WARNING -   Skipped train sample 1484 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,634 - __main__ - WARNING -   Skipped train sample 1485 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,636 - __main__ - WARNING -   Skipped train sample 1486 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,638 - __main__ - WARNING -   Skipped train sample 1487 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,640 - __main__ - WARNING -   Skipped train sample 1488 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,642 - __main__ - WARNING -   Skipped train sample 1489 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,644 - __main__ - WARNING -   Skipped train sample 1490 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,646 - __main__ - WARNING -   Skipped train sample 1491 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,648 - __main__ - WARNING -   Skipped train sample 1492 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,650 - __main__ - WARNING -   Skipped train sample 1493 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,652 - __main__ - WARNING -   Skipped train sample 1494 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,653 - __main__ - WARNING -   Skipped train sample 1495 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,655 - __main__ - WARNING -   Skipped train sample 1496 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,657 - __main__ - WARNING -   Skipped train sample 1497 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,659 - __main__ - WARNING -   Skipped train sample 1498 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,661 - __main__ - WARNING -   Skipped train sample 1499 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,663 - __main__ - WARNING -   Skipped train sample 1500 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,665 - __main__ - WARNING -   Skipped train sample 1501 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,667 - __main__ - WARNING -   Skipped train sample 1502 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,669 - __main__ - WARNING -   Skipped train sample 1503 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,671 - __main__ - WARNING -   Skipped train sample 1504 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,672 - __main__ - WARNING -   Skipped train sample 1505 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,674 - __main__ - WARNING -   Skipped train sample 1506 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,676 - __main__ - WARNING -   Skipped train sample 1507 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,678 - __main__ - WARNING -   Skipped train sample 1508 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,680 - __main__ - WARNING -   Skipped train sample 1509 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,682 - __main__ - WARNING -   Skipped train sample 1510 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,684 - __main__ - WARNING -   Skipped train sample 1511 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,686 - __main__ - WARNING -   Skipped train sample 1512 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,688 - __main__ - WARNING -   Skipped train sample 1513 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,690 - __main__ - WARNING -   Skipped train sample 1514 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,692 - __main__ - WARNING -   Skipped train sample 1515 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,694 - __main__ - WARNING -   Skipped train sample 1516 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,696 - __main__ - WARNING -   Skipped train sample 1517 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,698 - __main__ - WARNING -   Skipped train sample 1518 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,700 - __main__ - WARNING -   Skipped train sample 1519 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,702 - __main__ - WARNING -   Skipped train sample 1520 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,704 - __main__ - WARNING -   Skipped train sample 1521 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,706 - __main__ - WARNING -   Skipped train sample 1522 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,708 - __main__ - WARNING -   Skipped train sample 1523 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,710 - __main__ - WARNING -   Skipped train sample 1524 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,712 - __main__ - WARNING -   Skipped train sample 1525 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,714 - __main__ - WARNING -   Skipped train sample 1526 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,716 - __main__ - WARNING -   Skipped train sample 1527 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,718 - __main__ - WARNING -   Skipped train sample 1528 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,720 - __main__ - WARNING -   Skipped train sample 1529 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,721 - __main__ - WARNING -   Skipped train sample 1530 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,723 - __main__ - WARNING -   Skipped train sample 1531 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,725 - __main__ - WARNING -   Skipped train sample 1532 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,727 - __main__ - WARNING -   Skipped train sample 1533 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,729 - __main__ - WARNING -   Skipped train sample 1534 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,731 - __main__ - WARNING -   Skipped train sample 1535 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,733 - __main__ - WARNING -   Skipped train sample 1536 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,735 - __main__ - WARNING -   Skipped train sample 1537 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,736 - __main__ - WARNING -   Skipped train sample 1538 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,739 - __main__ - WARNING -   Skipped train sample 1539 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,740 - __main__ - WARNING -   Skipped train sample 1540 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,742 - __main__ - WARNING -   Skipped train sample 1541 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,744 - __main__ - WARNING -   Skipped train sample 1542 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,746 - __main__ - WARNING -   Skipped train sample 1543 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,748 - __main__ - WARNING -   Skipped train sample 1544 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,750 - __main__ - WARNING -   Skipped train sample 1545 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,752 - __main__ - WARNING -   Skipped train sample 1546 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,754 - __main__ - WARNING -   Skipped train sample 1547 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,756 - __main__ - WARNING -   Skipped train sample 1548 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,758 - __main__ - WARNING -   Skipped train sample 1549 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,760 - __main__ - WARNING -   Skipped train sample 1550 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,762 - __main__ - WARNING -   Skipped train sample 1551 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,764 - __main__ - WARNING -   Skipped train sample 1552 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,766 - __main__ - WARNING -   Skipped train sample 1553 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,767 - __main__ - WARNING -   Skipped train sample 1554 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,769 - __main__ - WARNING -   Skipped train sample 1555 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,771 - __main__ - WARNING -   Skipped train sample 1556 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,773 - __main__ - WARNING -   Skipped train sample 1557 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,775 - __main__ - WARNING -   Skipped train sample 1558 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,777 - __main__ - WARNING -   Skipped train sample 1559 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,779 - __main__ - WARNING -   Skipped train sample 1560 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,780 - __main__ - WARNING -   Skipped train sample 1561 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,782 - __main__ - WARNING -   Skipped train sample 1562 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,784 - __main__ - WARNING -   Skipped train sample 1563 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,786 - __main__ - WARNING -   Skipped train sample 1564 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,788 - __main__ - WARNING -   Skipped train sample 1565 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,790 - __main__ - WARNING -   Skipped train sample 1566 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,792 - __main__ - WARNING -   Skipped train sample 1567 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,794 - __main__ - WARNING -   Skipped train sample 1568 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,796 - __main__ - WARNING -   Skipped train sample 1569 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,798 - __main__ - WARNING -   Skipped train sample 1570 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,800 - __main__ - WARNING -   Skipped train sample 1571 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,802 - __main__ - WARNING -   Skipped train sample 1572 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,804 - __main__ - WARNING -   Skipped train sample 1573 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,806 - __main__ - WARNING -   Skipped train sample 1574 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,808 - __main__ - WARNING -   Skipped train sample 1575 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,809 - __main__ - WARNING -   Skipped train sample 1576 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,811 - __main__ - WARNING -   Skipped train sample 1577 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,813 - __main__ - WARNING -   Skipped train sample 1578 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,815 - __main__ - WARNING -   Skipped train sample 1579 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,817 - __main__ - WARNING -   Skipped train sample 1580 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,819 - __main__ - WARNING -   Skipped train sample 1581 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,820 - __main__ - WARNING -   Skipped train sample 1582 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,822 - __main__ - WARNING -   Skipped train sample 1583 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,824 - __main__ - WARNING -   Skipped train sample 1584 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,826 - __main__ - WARNING -   Skipped train sample 1585 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,828 - __main__ - WARNING -   Skipped train sample 1586 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,830 - __main__ - WARNING -   Skipped train sample 1587 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,832 - __main__ - WARNING -   Skipped train sample 1588 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,834 - __main__ - WARNING -   Skipped train sample 1589 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,836 - __main__ - WARNING -   Skipped train sample 1590 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,838 - __main__ - WARNING -   Skipped train sample 1591 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,840 - __main__ - WARNING -   Skipped train sample 1592 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,842 - __main__ - WARNING -   Skipped train sample 1593 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,844 - __main__ - WARNING -   Skipped train sample 1594 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,846 - __main__ - WARNING -   Skipped train sample 1595 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,848 - __main__ - WARNING -   Skipped train sample 1596 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,850 - __main__ - WARNING -   Skipped train sample 1597 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,852 - __main__ - WARNING -   Skipped train sample 1598 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,854 - __main__ - WARNING -   Skipped train sample 1599 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,856 - __main__ - WARNING -   Skipped train sample 1600 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,858 - __main__ - WARNING -   Skipped train sample 1601 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,860 - __main__ - WARNING -   Skipped train sample 1602 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,862 - __main__ - WARNING -   Skipped train sample 1603 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,864 - __main__ - WARNING -   Skipped train sample 1604 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,866 - __main__ - WARNING -   Skipped train sample 1605 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,868 - __main__ - WARNING -   Skipped train sample 1606 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,870 - __main__ - WARNING -   Skipped train sample 1607 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,872 - __main__ - WARNING -   Skipped train sample 1608 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,874 - __main__ - WARNING -   Skipped train sample 1609 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,876 - __main__ - WARNING -   Skipped train sample 1610 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,878 - __main__ - WARNING -   Skipped train sample 1611 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,880 - __main__ - WARNING -   Skipped train sample 1612 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,882 - __main__ - WARNING -   Skipped train sample 1613 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,884 - __main__ - WARNING -   Skipped train sample 1614 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,887 - __main__ - WARNING -   Skipped train sample 1615 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,889 - __main__ - WARNING -   Skipped train sample 1616 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,891 - __main__ - WARNING -   Skipped train sample 1617 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,893 - __main__ - WARNING -   Skipped train sample 1618 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,894 - __main__ - WARNING -   Skipped train sample 1619 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,896 - __main__ - WARNING -   Skipped train sample 1620 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,898 - __main__ - WARNING -   Skipped train sample 1621 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,900 - __main__ - WARNING -   Skipped train sample 1622 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,902 - __main__ - WARNING -   Skipped train sample 1623 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,904 - __main__ - WARNING -   Skipped train sample 1624 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,906 - __main__ - WARNING -   Skipped train sample 1625 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,908 - __main__ - WARNING -   Skipped train sample 1626 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,910 - __main__ - WARNING -   Skipped train sample 1627 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,912 - __main__ - WARNING -   Skipped train sample 1628 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,914 - __main__ - WARNING -   Skipped train sample 1629 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,915 - __main__ - WARNING -   Skipped train sample 1630 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,917 - __main__ - WARNING -   Skipped train sample 1631 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,919 - __main__ - WARNING -   Skipped train sample 1632 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,921 - __main__ - WARNING -   Skipped train sample 1633 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,923 - __main__ - WARNING -   Skipped train sample 1634 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,925 - __main__ - WARNING -   Skipped train sample 1635 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,927 - __main__ - WARNING -   Skipped train sample 1636 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,929 - __main__ - WARNING -   Skipped train sample 1637 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,931 - __main__ - WARNING -   Skipped train sample 1638 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,933 - __main__ - WARNING -   Skipped train sample 1639 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,935 - __main__ - WARNING -   Skipped train sample 1640 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,936 - __main__ - WARNING -   Skipped train sample 1641 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,939 - __main__ - WARNING -   Skipped train sample 1642 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,940 - __main__ - WARNING -   Skipped train sample 1643 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,942 - __main__ - WARNING -   Skipped train sample 1644 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,944 - __main__ - WARNING -   Skipped train sample 1645 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,946 - __main__ - WARNING -   Skipped train sample 1646 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,948 - __main__ - WARNING -   Skipped train sample 1647 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,950 - __main__ - WARNING -   Skipped train sample 1648 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,952 - __main__ - WARNING -   Skipped train sample 1649 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,954 - __main__ - WARNING -   Skipped train sample 1650 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,956 - __main__ - WARNING -   Skipped train sample 1651 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,958 - __main__ - WARNING -   Skipped train sample 1652 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,960 - __main__ - WARNING -   Skipped train sample 1653 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,962 - __main__ - WARNING -   Skipped train sample 1654 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,963 - __main__ - WARNING -   Skipped train sample 1655 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,965 - __main__ - WARNING -   Skipped train sample 1656 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,967 - __main__ - WARNING -   Skipped train sample 1657 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,969 - __main__ - WARNING -   Skipped train sample 1658 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,971 - __main__ - WARNING -   Skipped train sample 1659 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,973 - __main__ - WARNING -   Skipped train sample 1660 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,975 - __main__ - WARNING -   Skipped train sample 1661 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,977 - __main__ - WARNING -   Skipped train sample 1662 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,979 - __main__ - WARNING -   Skipped train sample 1663 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,981 - __main__ - WARNING -   Skipped train sample 1664 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:37,982 - __main__ - WARNING -   Skipped train sample 1665 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,985 - __main__ - WARNING -   Skipped train sample 1666 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,987 - __main__ - WARNING -   Skipped train sample 1667 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:37,989 - __main__ - WARNING -   Skipped train sample 1668 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,991 - __main__ - WARNING -   Skipped train sample 1669 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,992 - __main__ - WARNING -   Skipped train sample 1670 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:37,994 - __main__ - WARNING -   Skipped train sample 1671 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,996 - __main__ - WARNING -   Skipped train sample 1672 due to error: cannot convert float NaN to integer
2025-09-21 22:09:37,998 - __main__ - WARNING -   Skipped train sample 1673 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,000 - __main__ - WARNING -   Skipped train sample 1674 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,002 - __main__ - WARNING -   Skipped train sample 1675 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,004 - __main__ - WARNING -   Skipped train sample 1676 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,006 - __main__ - WARNING -   Skipped train sample 1677 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,008 - __main__ - WARNING -   Skipped train sample 1678 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,010 - __main__ - WARNING -   Skipped train sample 1679 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,012 - __main__ - WARNING -   Skipped train sample 1680 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,013 - __main__ - WARNING -   Skipped train sample 1681 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,015 - __main__ - WARNING -   Skipped train sample 1682 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,017 - __main__ - WARNING -   Skipped train sample 1683 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,019 - __main__ - WARNING -   Skipped train sample 1684 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,021 - __main__ - WARNING -   Skipped train sample 1685 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,023 - __main__ - WARNING -   Skipped train sample 1686 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,024 - __main__ - WARNING -   Skipped train sample 1687 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,026 - __main__ - WARNING -   Skipped train sample 1688 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,028 - __main__ - WARNING -   Skipped train sample 1689 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,030 - __main__ - WARNING -   Skipped train sample 1690 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,032 - __main__ - WARNING -   Skipped train sample 1691 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,034 - __main__ - WARNING -   Skipped train sample 1692 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,036 - __main__ - WARNING -   Skipped train sample 1693 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,038 - __main__ - WARNING -   Skipped train sample 1694 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,040 - __main__ - WARNING -   Skipped train sample 1695 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,042 - __main__ - WARNING -   Skipped train sample 1696 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,044 - __main__ - WARNING -   Skipped train sample 1697 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,046 - __main__ - WARNING -   Skipped train sample 1698 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,048 - __main__ - WARNING -   Skipped train sample 1699 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,050 - __main__ - WARNING -   Skipped train sample 1700 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,051 - __main__ - WARNING -   Skipped train sample 1701 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,053 - __main__ - WARNING -   Skipped train sample 1702 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,055 - __main__ - WARNING -   Skipped train sample 1703 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,057 - __main__ - WARNING -   Skipped train sample 1704 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,059 - __main__ - WARNING -   Skipped train sample 1705 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,061 - __main__ - WARNING -   Skipped train sample 1706 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,063 - __main__ - WARNING -   Skipped train sample 1707 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,065 - __main__ - WARNING -   Skipped train sample 1708 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,067 - __main__ - WARNING -   Skipped train sample 1709 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,069 - __main__ - WARNING -   Skipped train sample 1710 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,071 - __main__ - WARNING -   Skipped train sample 1711 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,073 - __main__ - WARNING -   Skipped train sample 1712 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,075 - __main__ - WARNING -   Skipped train sample 1713 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,076 - __main__ - WARNING -   Skipped train sample 1714 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,078 - __main__ - WARNING -   Skipped train sample 1715 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,080 - __main__ - WARNING -   Skipped train sample 1716 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,082 - __main__ - WARNING -   Skipped train sample 1717 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:38,084 - __main__ - WARNING -   Skipped train sample 1718 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,086 - __main__ - WARNING -   Skipped train sample 1719 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,088 - __main__ - WARNING -   Skipped train sample 1720 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,090 - __main__ - WARNING -   Skipped train sample 1721 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,091 - __main__ - WARNING -   Skipped train sample 1722 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,094 - __main__ - WARNING -   Skipped train sample 1723 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,095 - __main__ - WARNING -   Skipped train sample 1724 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,097 - __main__ - WARNING -   Skipped train sample 1725 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,099 - __main__ - WARNING -   Skipped train sample 1726 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,101 - __main__ - WARNING -   Skipped train sample 1727 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,103 - __main__ - WARNING -   Skipped train sample 1728 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,106 - __main__ - WARNING -   Skipped train sample 1729 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,107 - __main__ - WARNING -   Skipped train sample 1730 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,109 - __main__ - WARNING -   Skipped train sample 1731 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,111 - __main__ - WARNING -   Skipped train sample 1732 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,113 - __main__ - WARNING -   Skipped train sample 1733 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,115 - __main__ - WARNING -   Skipped train sample 1734 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,117 - __main__ - WARNING -   Skipped train sample 1735 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,120 - __main__ - WARNING -   Skipped train sample 1736 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,122 - __main__ - WARNING -   Skipped train sample 1737 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,123 - __main__ - WARNING -   Skipped train sample 1738 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,125 - __main__ - WARNING -   Skipped train sample 1739 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,127 - __main__ - WARNING -   Skipped train sample 1740 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,129 - __main__ - WARNING -   Skipped train sample 1741 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,131 - __main__ - WARNING -   Skipped train sample 1742 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,133 - __main__ - WARNING -   Skipped train sample 1743 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,135 - __main__ - WARNING -   Skipped train sample 1744 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,137 - __main__ - WARNING -   Skipped train sample 1745 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,139 - __main__ - WARNING -   Skipped train sample 1746 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,140 - __main__ - WARNING -   Skipped train sample 1747 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,142 - __main__ - WARNING -   Skipped train sample 1748 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,144 - __main__ - WARNING -   Skipped train sample 1749 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,146 - __main__ - WARNING -   Skipped train sample 1750 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,148 - __main__ - WARNING -   Skipped train sample 1751 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,150 - __main__ - WARNING -   Skipped train sample 1752 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,152 - __main__ - WARNING -   Skipped train sample 1753 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,154 - __main__ - WARNING -   Skipped train sample 1754 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,156 - __main__ - WARNING -   Skipped train sample 1755 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,158 - __main__ - WARNING -   Skipped train sample 1756 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,160 - __main__ - WARNING -   Skipped train sample 1757 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,162 - __main__ - WARNING -   Skipped train sample 1758 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,164 - __main__ - WARNING -   Skipped train sample 1759 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,165 - __main__ - WARNING -   Skipped train sample 1760 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,167 - __main__ - WARNING -   Skipped train sample 1761 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,169 - __main__ - WARNING -   Skipped train sample 1762 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,171 - __main__ - WARNING -   Skipped train sample 1763 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,173 - __main__ - WARNING -   Skipped train sample 1764 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,175 - __main__ - WARNING -   Skipped train sample 1765 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,177 - __main__ - WARNING -   Skipped train sample 1766 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,179 - __main__ - WARNING -   Skipped train sample 1767 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,181 - __main__ - WARNING -   Skipped train sample 1768 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,183 - __main__ - WARNING -   Skipped train sample 1769 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,184 - __main__ - WARNING -   Skipped train sample 1770 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,186 - __main__ - WARNING -   Skipped train sample 1771 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,188 - __main__ - WARNING -   Skipped train sample 1772 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,190 - __main__ - WARNING -   Skipped train sample 1773 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,192 - __main__ - WARNING -   Skipped train sample 1774 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,194 - __main__ - WARNING -   Skipped train sample 1775 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,196 - __main__ - WARNING -   Skipped train sample 1776 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,198 - __main__ - WARNING -   Skipped train sample 1777 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,200 - __main__ - WARNING -   Skipped train sample 1778 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,202 - __main__ - WARNING -   Skipped train sample 1779 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,204 - __main__ - WARNING -   Skipped train sample 1780 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,206 - __main__ - WARNING -   Skipped train sample 1781 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,208 - __main__ - WARNING -   Skipped train sample 1782 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,209 - __main__ - WARNING -   Skipped train sample 1783 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,211 - __main__ - WARNING -   Skipped train sample 1784 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,213 - __main__ - WARNING -   Skipped train sample 1785 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,215 - __main__ - WARNING -   Skipped train sample 1786 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,217 - __main__ - WARNING -   Skipped train sample 1787 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,219 - __main__ - WARNING -   Skipped train sample 1788 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,221 - __main__ - WARNING -   Skipped train sample 1789 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,223 - __main__ - WARNING -   Skipped train sample 1790 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,226 - __main__ - WARNING -   Skipped train sample 1791 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,228 - __main__ - WARNING -   Skipped train sample 1792 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,230 - __main__ - WARNING -   Skipped train sample 1793 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,232 - __main__ - WARNING -   Skipped train sample 1794 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,234 - __main__ - WARNING -   Skipped train sample 1795 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,236 - __main__ - WARNING -   Skipped train sample 1796 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,238 - __main__ - WARNING -   Skipped train sample 1797 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,240 - __main__ - WARNING -   Skipped train sample 1798 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,242 - __main__ - WARNING -   Skipped train sample 1799 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,244 - __main__ - WARNING -   Skipped train sample 1800 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,246 - __main__ - WARNING -   Skipped train sample 1801 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,248 - __main__ - WARNING -   Skipped train sample 1802 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,250 - __main__ - WARNING -   Skipped train sample 1803 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,252 - __main__ - WARNING -   Skipped train sample 1804 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,254 - __main__ - WARNING -   Skipped train sample 1805 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,255 - __main__ - WARNING -   Skipped train sample 1806 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,257 - __main__ - WARNING -   Skipped train sample 1807 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,259 - __main__ - WARNING -   Skipped train sample 1808 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,261 - __main__ - WARNING -   Skipped train sample 1809 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,263 - __main__ - WARNING -   Skipped train sample 1810 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,265 - __main__ - WARNING -   Skipped train sample 1811 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,267 - __main__ - WARNING -   Skipped train sample 1812 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,269 - __main__ - WARNING -   Skipped train sample 1813 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,271 - __main__ - WARNING -   Skipped train sample 1814 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,273 - __main__ - WARNING -   Skipped train sample 1815 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,275 - __main__ - WARNING -   Skipped train sample 1816 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,277 - __main__ - WARNING -   Skipped train sample 1817 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,279 - __main__ - WARNING -   Skipped train sample 1818 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,281 - __main__ - WARNING -   Skipped train sample 1819 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,283 - __main__ - WARNING -   Skipped train sample 1820 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,285 - __main__ - WARNING -   Skipped train sample 1821 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:38,287 - __main__ - WARNING -   Skipped train sample 1822 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,289 - __main__ - WARNING -   Skipped train sample 1823 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,291 - __main__ - WARNING -   Skipped train sample 1824 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,293 - __main__ - WARNING -   Skipped train sample 1825 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,295 - __main__ - WARNING -   Skipped train sample 1826 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,297 - __main__ - WARNING -   Skipped train sample 1827 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,299 - __main__ - WARNING -   Skipped train sample 1828 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,301 - __main__ - WARNING -   Skipped train sample 1829 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,303 - __main__ - WARNING -   Skipped train sample 1830 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,305 - __main__ - WARNING -   Skipped train sample 1831 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,307 - __main__ - WARNING -   Skipped train sample 1832 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,308 - __main__ - WARNING -   Skipped train sample 1833 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,310 - __main__ - WARNING -   Skipped train sample 1834 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,312 - __main__ - WARNING -   Skipped train sample 1835 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,315 - __main__ - WARNING -   Skipped train sample 1836 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,317 - __main__ - WARNING -   Skipped train sample 1837 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,319 - __main__ - WARNING -   Skipped train sample 1838 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,321 - __main__ - WARNING -   Skipped train sample 1839 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,322 - __main__ - WARNING -   Skipped train sample 1840 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,325 - __main__ - WARNING -   Skipped train sample 1841 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,327 - __main__ - WARNING -   Skipped train sample 1842 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,328 - __main__ - WARNING -   Skipped train sample 1843 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,330 - __main__ - WARNING -   Skipped train sample 1844 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,332 - __main__ - WARNING -   Skipped train sample 1845 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,334 - __main__ - WARNING -   Skipped train sample 1846 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,336 - __main__ - WARNING -   Skipped train sample 1847 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,339 - __main__ - WARNING -   Skipped train sample 1848 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:38,341 - __main__ - WARNING -   Skipped train sample 1849 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,343 - __main__ - WARNING -   Skipped train sample 1850 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,345 - __main__ - WARNING -   Skipped train sample 1851 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,347 - __main__ - WARNING -   Skipped train sample 1852 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,349 - __main__ - WARNING -   Skipped train sample 1853 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,351 - __main__ - WARNING -   Skipped train sample 1854 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,353 - __main__ - WARNING -   Skipped train sample 1855 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,355 - __main__ - WARNING -   Skipped train sample 1856 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,357 - __main__ - WARNING -   Skipped train sample 1857 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,358 - __main__ - WARNING -   Skipped train sample 1858 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,360 - __main__ - WARNING -   Skipped train sample 1859 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,362 - __main__ - WARNING -   Skipped train sample 1860 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:38,365 - __main__ - WARNING -   Skipped train sample 1861 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,367 - __main__ - WARNING -   Skipped train sample 1862 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,369 - __main__ - WARNING -   Skipped train sample 1863 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,371 - __main__ - WARNING -   Skipped train sample 1864 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,372 - __main__ - WARNING -   Skipped train sample 1865 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,375 - __main__ - WARNING -   Skipped train sample 1866 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,377 - __main__ - WARNING -   Skipped train sample 1867 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,379 - __main__ - WARNING -   Skipped train sample 1868 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,380 - __main__ - WARNING -   Skipped train sample 1869 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,383 - __main__ - WARNING -   Skipped train sample 1870 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,384 - __main__ - WARNING -   Skipped train sample 1871 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,386 - __main__ - WARNING -   Skipped train sample 1872 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,388 - __main__ - WARNING -   Skipped train sample 1873 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,390 - __main__ - WARNING -   Skipped train sample 1874 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,392 - __main__ - WARNING -   Skipped train sample 1875 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,394 - __main__ - WARNING -   Skipped train sample 1876 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,396 - __main__ - WARNING -   Skipped train sample 1877 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,398 - __main__ - WARNING -   Skipped train sample 1878 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,400 - __main__ - WARNING -   Skipped train sample 1879 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,401 - __main__ - WARNING -   Skipped train sample 1880 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,403 - __main__ - WARNING -   Skipped train sample 1881 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,405 - __main__ - WARNING -   Skipped train sample 1882 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,407 - __main__ - WARNING -   Skipped train sample 1883 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,409 - __main__ - WARNING -   Skipped train sample 1884 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,411 - __main__ - WARNING -   Skipped train sample 1885 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,413 - __main__ - WARNING -   Skipped train sample 1886 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,415 - __main__ - WARNING -   Skipped train sample 1887 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,417 - __main__ - WARNING -   Skipped train sample 1888 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,419 - __main__ - WARNING -   Skipped train sample 1889 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,421 - __main__ - WARNING -   Skipped train sample 1890 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,423 - __main__ - WARNING -   Skipped train sample 1891 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,425 - __main__ - WARNING -   Skipped train sample 1892 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,427 - __main__ - WARNING -   Skipped train sample 1893 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:38,428 - __main__ - WARNING -   Skipped train sample 1894 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,430 - __main__ - WARNING -   Skipped train sample 1895 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,432 - __main__ - WARNING -   Skipped train sample 1896 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,434 - __main__ - WARNING -   Skipped train sample 1897 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,436 - __main__ - WARNING -   Skipped train sample 1898 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,438 - __main__ - WARNING -   Skipped train sample 1899 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,440 - __main__ - WARNING -   Skipped train sample 1900 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,442 - __main__ - WARNING -   Skipped train sample 1901 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,444 - __main__ - WARNING -   Skipped train sample 1902 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,446 - __main__ - WARNING -   Skipped train sample 1903 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,448 - __main__ - WARNING -   Skipped train sample 1904 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,450 - __main__ - WARNING -   Skipped train sample 1905 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,452 - __main__ - WARNING -   Skipped train sample 1906 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,454 - __main__ - WARNING -   Skipped train sample 1907 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,456 - __main__ - WARNING -   Skipped train sample 1908 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,458 - __main__ - WARNING -   Skipped train sample 1909 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,459 - __main__ - WARNING -   Skipped train sample 1910 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,461 - __main__ - WARNING -   Skipped train sample 1911 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,463 - __main__ - WARNING -   Skipped train sample 1912 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,465 - __main__ - WARNING -   Skipped train sample 1913 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,467 - __main__ - WARNING -   Skipped train sample 1914 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,469 - __main__ - WARNING -   Skipped train sample 1915 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,471 - __main__ - WARNING -   Skipped train sample 1916 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,473 - __main__ - WARNING -   Skipped train sample 1917 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,475 - __main__ - WARNING -   Skipped train sample 1918 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,477 - __main__ - WARNING -   Skipped train sample 1919 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,479 - __main__ - WARNING -   Skipped train sample 1920 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,480 - __main__ - WARNING -   Skipped train sample 1921 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,482 - __main__ - WARNING -   Skipped train sample 1922 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,484 - __main__ - WARNING -   Skipped train sample 1923 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,486 - __main__ - WARNING -   Skipped train sample 1924 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,488 - __main__ - WARNING -   Skipped train sample 1925 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,490 - __main__ - WARNING -   Skipped train sample 1926 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,492 - __main__ - WARNING -   Skipped train sample 1927 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,494 - __main__ - WARNING -   Skipped train sample 1928 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,496 - __main__ - WARNING -   Skipped train sample 1929 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,498 - __main__ - WARNING -   Skipped train sample 1930 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,500 - __main__ - WARNING -   Skipped train sample 1931 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,502 - __main__ - WARNING -   Skipped train sample 1932 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,504 - __main__ - WARNING -   Skipped train sample 1933 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,506 - __main__ - WARNING -   Skipped train sample 1934 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,508 - __main__ - WARNING -   Skipped train sample 1935 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,510 - __main__ - WARNING -   Skipped train sample 1936 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,512 - __main__ - WARNING -   Skipped train sample 1937 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,513 - __main__ - WARNING -   Skipped train sample 1938 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,515 - __main__ - WARNING -   Skipped train sample 1939 due to error: invalid literal for int() with base 10: 'signer_5'
2025-09-21 22:09:38,517 - __main__ - WARNING -   Skipped train sample 1940 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,519 - __main__ - WARNING -   Skipped train sample 1941 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,521 - __main__ - WARNING -   Skipped train sample 1942 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,523 - __main__ - WARNING -   Skipped train sample 1943 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,525 - __main__ - WARNING -   Skipped train sample 1944 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,527 - __main__ - WARNING -   Skipped train sample 1945 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,529 - __main__ - WARNING -   Skipped train sample 1946 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,531 - __main__ - WARNING -   Skipped train sample 1947 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,532 - __main__ - WARNING -   Skipped train sample 1948 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,534 - __main__ - WARNING -   Skipped train sample 1949 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,536 - __main__ - WARNING -   Skipped train sample 1950 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,538 - __main__ - WARNING -   Skipped train sample 1951 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,540 - __main__ - WARNING -   Skipped train sample 1952 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,542 - __main__ - WARNING -   Skipped train sample 1953 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,544 - __main__ - WARNING -   Skipped train sample 1954 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,546 - __main__ - WARNING -   Skipped train sample 1955 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,548 - __main__ - WARNING -   Skipped train sample 1956 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,550 - __main__ - WARNING -   Skipped train sample 1957 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,552 - __main__ - WARNING -   Skipped train sample 1958 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,554 - __main__ - WARNING -   Skipped train sample 1959 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,556 - __main__ - WARNING -   Skipped train sample 1960 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,558 - __main__ - WARNING -   Skipped train sample 1961 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,560 - __main__ - WARNING -   Skipped train sample 1962 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,562 - __main__ - WARNING -   Skipped train sample 1963 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,564 - __main__ - WARNING -   Skipped train sample 1964 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,566 - __main__ - WARNING -   Skipped train sample 1965 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:38,568 - __main__ - WARNING -   Skipped train sample 1966 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,570 - __main__ - WARNING -   Skipped train sample 1967 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,572 - __main__ - WARNING -   Skipped train sample 1968 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,574 - __main__ - WARNING -   Skipped train sample 1969 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,576 - __main__ - WARNING -   Skipped train sample 1970 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,578 - __main__ - WARNING -   Skipped train sample 1971 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,580 - __main__ - WARNING -   Skipped train sample 1972 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,582 - __main__ - WARNING -   Skipped train sample 1973 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,584 - __main__ - WARNING -   Skipped train sample 1974 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,586 - __main__ - WARNING -   Skipped train sample 1975 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,588 - __main__ - WARNING -   Skipped train sample 1976 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,590 - __main__ - WARNING -   Skipped train sample 1977 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:38,591 - __main__ - WARNING -   Skipped train sample 1978 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,593 - __main__ - WARNING -   Skipped train sample 1979 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,595 - __main__ - WARNING -   Skipped train sample 1980 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,597 - __main__ - WARNING -   Skipped train sample 1981 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,599 - __main__ - WARNING -   Skipped train sample 1982 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,601 - __main__ - WARNING -   Skipped train sample 1983 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,603 - __main__ - WARNING -   Skipped train sample 1984 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,605 - __main__ - WARNING -   Skipped train sample 1985 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,607 - __main__ - WARNING -   Skipped train sample 1986 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,609 - __main__ - WARNING -   Skipped train sample 1987 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,610 - __main__ - WARNING -   Skipped train sample 1988 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,612 - __main__ - WARNING -   Skipped train sample 1989 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,614 - __main__ - WARNING -   Skipped train sample 1990 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,616 - __main__ - WARNING -   Skipped train sample 1991 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,618 - __main__ - WARNING -   Skipped train sample 1992 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,620 - __main__ - WARNING -   Skipped train sample 1993 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,622 - __main__ - WARNING -   Skipped train sample 1994 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,624 - __main__ - WARNING -   Skipped train sample 1995 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,626 - __main__ - WARNING -   Skipped train sample 1996 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,628 - __main__ - WARNING -   Skipped train sample 1997 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,630 - __main__ - WARNING -   Skipped train sample 1998 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,632 - __main__ - WARNING -   Skipped train sample 1999 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,632 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-21 22:09:38,634 - __main__ - WARNING -   Skipped train sample 2000 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,636 - __main__ - WARNING -   Skipped train sample 2001 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,638 - __main__ - WARNING -   Skipped train sample 2002 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,639 - __main__ - WARNING -   Skipped train sample 2003 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,641 - __main__ - WARNING -   Skipped train sample 2004 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,643 - __main__ - WARNING -   Skipped train sample 2005 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,645 - __main__ - WARNING -   Skipped train sample 2006 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,647 - __main__ - WARNING -   Skipped train sample 2007 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:38,649 - __main__ - WARNING -   Skipped train sample 2008 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,651 - __main__ - WARNING -   Skipped train sample 2009 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,653 - __main__ - WARNING -   Skipped train sample 2010 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,655 - __main__ - WARNING -   Skipped train sample 2011 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,656 - __main__ - WARNING -   Skipped train sample 2012 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,658 - __main__ - WARNING -   Skipped train sample 2013 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,660 - __main__ - WARNING -   Skipped train sample 2014 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,662 - __main__ - WARNING -   Skipped train sample 2015 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,664 - __main__ - WARNING -   Skipped train sample 2016 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,666 - __main__ - WARNING -   Skipped train sample 2017 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,668 - __main__ - WARNING -   Skipped train sample 2018 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,670 - __main__ - WARNING -   Skipped train sample 2019 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,672 - __main__ - WARNING -   Skipped train sample 2020 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,674 - __main__ - WARNING -   Skipped train sample 2021 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,676 - __main__ - WARNING -   Skipped train sample 2022 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,678 - __main__ - WARNING -   Skipped train sample 2023 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,680 - __main__ - WARNING -   Skipped train sample 2024 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,682 - __main__ - WARNING -   Skipped train sample 2025 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,684 - __main__ - WARNING -   Skipped train sample 2026 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,685 - __main__ - WARNING -   Skipped train sample 2027 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,687 - __main__ - WARNING -   Skipped train sample 2028 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,689 - __main__ - WARNING -   Skipped train sample 2029 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,691 - __main__ - WARNING -   Skipped train sample 2030 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,693 - __main__ - WARNING -   Skipped train sample 2031 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,695 - __main__ - WARNING -   Skipped train sample 2032 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,697 - __main__ - WARNING -   Skipped train sample 2033 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,698 - __main__ - WARNING -   Skipped train sample 2034 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,700 - __main__ - WARNING -   Skipped train sample 2035 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,702 - __main__ - WARNING -   Skipped train sample 2036 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,704 - __main__ - WARNING -   Skipped train sample 2037 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,706 - __main__ - WARNING -   Skipped train sample 2038 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,708 - __main__ - WARNING -   Skipped train sample 2039 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,710 - __main__ - WARNING -   Skipped train sample 2040 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,712 - __main__ - WARNING -   Skipped train sample 2041 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,714 - __main__ - WARNING -   Skipped train sample 2042 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,716 - __main__ - WARNING -   Skipped train sample 2043 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,717 - __main__ - WARNING -   Skipped train sample 2044 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,719 - __main__ - WARNING -   Skipped train sample 2045 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,721 - __main__ - WARNING -   Skipped train sample 2046 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,723 - __main__ - WARNING -   Skipped train sample 2047 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,725 - __main__ - WARNING -   Skipped train sample 2048 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,727 - __main__ - WARNING -   Skipped train sample 2049 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,729 - __main__ - WARNING -   Skipped train sample 2050 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,731 - __main__ - WARNING -   Skipped train sample 2051 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,733 - __main__ - WARNING -   Skipped train sample 2052 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,735 - __main__ - WARNING -   Skipped train sample 2053 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,737 - __main__ - WARNING -   Skipped train sample 2054 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,739 - __main__ - WARNING -   Skipped train sample 2055 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,741 - __main__ - WARNING -   Skipped train sample 2056 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,743 - __main__ - WARNING -   Skipped train sample 2057 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,744 - __main__ - WARNING -   Skipped train sample 2058 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,746 - __main__ - WARNING -   Skipped train sample 2059 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,749 - __main__ - WARNING -   Skipped train sample 2060 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:38,750 - __main__ - WARNING -   Skipped train sample 2061 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,752 - __main__ - WARNING -   Skipped train sample 2062 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,754 - __main__ - WARNING -   Skipped train sample 2063 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,756 - __main__ - WARNING -   Skipped train sample 2064 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,758 - __main__ - WARNING -   Skipped train sample 2065 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,760 - __main__ - WARNING -   Skipped train sample 2066 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,762 - __main__ - WARNING -   Skipped train sample 2067 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,764 - __main__ - WARNING -   Skipped train sample 2068 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,766 - __main__ - WARNING -   Skipped train sample 2069 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,768 - __main__ - WARNING -   Skipped train sample 2070 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,770 - __main__ - WARNING -   Skipped train sample 2071 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,771 - __main__ - WARNING -   Skipped train sample 2072 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,773 - __main__ - WARNING -   Skipped train sample 2073 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,775 - __main__ - WARNING -   Skipped train sample 2074 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,777 - __main__ - WARNING -   Skipped train sample 2075 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,779 - __main__ - WARNING -   Skipped train sample 2076 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,781 - __main__ - WARNING -   Skipped train sample 2077 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,783 - __main__ - WARNING -   Skipped train sample 2078 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,785 - __main__ - WARNING -   Skipped train sample 2079 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,787 - __main__ - WARNING -   Skipped train sample 2080 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,789 - __main__ - WARNING -   Skipped train sample 2081 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,791 - __main__ - WARNING -   Skipped train sample 2082 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,793 - __main__ - WARNING -   Skipped train sample 2083 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,795 - __main__ - WARNING -   Skipped train sample 2084 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:38,797 - __main__ - WARNING -   Skipped train sample 2085 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,799 - __main__ - WARNING -   Skipped train sample 2086 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,800 - __main__ - WARNING -   Skipped train sample 2087 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,802 - __main__ - WARNING -   Skipped train sample 2088 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,804 - __main__ - WARNING -   Skipped train sample 2089 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,806 - __main__ - WARNING -   Skipped train sample 2090 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,808 - __main__ - WARNING -   Skipped train sample 2091 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,810 - __main__ - WARNING -   Skipped train sample 2092 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,812 - __main__ - WARNING -   Skipped train sample 2093 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,814 - __main__ - WARNING -   Skipped train sample 2094 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,816 - __main__ - WARNING -   Skipped train sample 2095 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,818 - __main__ - WARNING -   Skipped train sample 2096 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,820 - __main__ - WARNING -   Skipped train sample 2097 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,822 - __main__ - WARNING -   Skipped train sample 2098 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,824 - __main__ - WARNING -   Skipped train sample 2099 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,826 - __main__ - WARNING -   Skipped train sample 2100 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,828 - __main__ - WARNING -   Skipped train sample 2101 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,830 - __main__ - WARNING -   Skipped train sample 2102 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,831 - __main__ - WARNING -   Skipped train sample 2103 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,833 - __main__ - WARNING -   Skipped train sample 2104 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,835 - __main__ - WARNING -   Skipped train sample 2105 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,837 - __main__ - WARNING -   Skipped train sample 2106 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,839 - __main__ - WARNING -   Skipped train sample 2107 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,841 - __main__ - WARNING -   Skipped train sample 2108 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,843 - __main__ - WARNING -   Skipped train sample 2109 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,845 - __main__ - WARNING -   Skipped train sample 2110 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,847 - __main__ - WARNING -   Skipped train sample 2111 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,849 - __main__ - WARNING -   Skipped train sample 2112 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,851 - __main__ - WARNING -   Skipped train sample 2113 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,853 - __main__ - WARNING -   Skipped train sample 2114 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,854 - __main__ - WARNING -   Skipped train sample 2115 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,856 - __main__ - WARNING -   Skipped train sample 2116 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,858 - __main__ - WARNING -   Skipped train sample 2117 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,860 - __main__ - WARNING -   Skipped train sample 2118 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,862 - __main__ - WARNING -   Skipped train sample 2119 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,864 - __main__ - WARNING -   Skipped train sample 2120 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,866 - __main__ - WARNING -   Skipped train sample 2121 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,868 - __main__ - WARNING -   Skipped train sample 2122 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,870 - __main__ - WARNING -   Skipped train sample 2123 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,872 - __main__ - WARNING -   Skipped train sample 2124 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,874 - __main__ - WARNING -   Skipped train sample 2125 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,876 - __main__ - WARNING -   Skipped train sample 2126 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,878 - __main__ - WARNING -   Skipped train sample 2127 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,880 - __main__ - WARNING -   Skipped train sample 2128 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,882 - __main__ - WARNING -   Skipped train sample 2129 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,883 - __main__ - WARNING -   Skipped train sample 2130 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,885 - __main__ - WARNING -   Skipped train sample 2131 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,887 - __main__ - WARNING -   Skipped train sample 2132 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,889 - __main__ - WARNING -   Skipped train sample 2133 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,891 - __main__ - WARNING -   Skipped train sample 2134 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,893 - __main__ - WARNING -   Skipped train sample 2135 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,895 - __main__ - WARNING -   Skipped train sample 2136 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,897 - __main__ - WARNING -   Skipped train sample 2137 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,898 - __main__ - WARNING -   Skipped train sample 2138 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,900 - __main__ - WARNING -   Skipped train sample 2139 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,902 - __main__ - WARNING -   Skipped train sample 2140 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,904 - __main__ - WARNING -   Skipped train sample 2141 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,906 - __main__ - WARNING -   Skipped train sample 2142 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,908 - __main__ - WARNING -   Skipped train sample 2143 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,910 - __main__ - WARNING -   Skipped train sample 2144 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,912 - __main__ - WARNING -   Skipped train sample 2145 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,914 - __main__ - WARNING -   Skipped train sample 2146 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,916 - __main__ - WARNING -   Skipped train sample 2147 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,917 - __main__ - WARNING -   Skipped train sample 2148 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,919 - __main__ - WARNING -   Skipped train sample 2149 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,921 - __main__ - WARNING -   Skipped train sample 2150 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,923 - __main__ - WARNING -   Skipped train sample 2151 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,925 - __main__ - WARNING -   Skipped train sample 2152 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,927 - __main__ - WARNING -   Skipped train sample 2153 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,929 - __main__ - WARNING -   Skipped train sample 2154 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,931 - __main__ - WARNING -   Skipped train sample 2155 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,933 - __main__ - WARNING -   Skipped train sample 2156 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,935 - __main__ - WARNING -   Skipped train sample 2157 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,937 - __main__ - WARNING -   Skipped train sample 2158 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,939 - __main__ - WARNING -   Skipped train sample 2159 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,940 - __main__ - WARNING -   Skipped train sample 2160 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,942 - __main__ - WARNING -   Skipped train sample 2161 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,944 - __main__ - WARNING -   Skipped train sample 2162 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,946 - __main__ - WARNING -   Skipped train sample 2163 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,948 - __main__ - WARNING -   Skipped train sample 2164 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,950 - __main__ - WARNING -   Skipped train sample 2165 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,952 - __main__ - WARNING -   Skipped train sample 2166 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,954 - __main__ - WARNING -   Skipped train sample 2167 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,956 - __main__ - WARNING -   Skipped train sample 2168 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,958 - __main__ - WARNING -   Skipped train sample 2169 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,959 - __main__ - WARNING -   Skipped train sample 2170 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,961 - __main__ - WARNING -   Skipped train sample 2171 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,963 - __main__ - WARNING -   Skipped train sample 2172 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,965 - __main__ - WARNING -   Skipped train sample 2173 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:38,967 - __main__ - WARNING -   Skipped train sample 2174 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,969 - __main__ - WARNING -   Skipped train sample 2175 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,971 - __main__ - WARNING -   Skipped train sample 2176 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,973 - __main__ - WARNING -   Skipped train sample 2177 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,975 - __main__ - WARNING -   Skipped train sample 2178 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,977 - __main__ - WARNING -   Skipped train sample 2179 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,979 - __main__ - WARNING -   Skipped train sample 2180 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,980 - __main__ - WARNING -   Skipped train sample 2181 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,982 - __main__ - WARNING -   Skipped train sample 2182 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,984 - __main__ - WARNING -   Skipped train sample 2183 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,986 - __main__ - WARNING -   Skipped train sample 2184 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,988 - __main__ - WARNING -   Skipped train sample 2185 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,990 - __main__ - WARNING -   Skipped train sample 2186 due to error: cannot convert float NaN to integer
2025-09-21 22:09:38,992 - __main__ - WARNING -   Skipped train sample 2187 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,994 - __main__ - WARNING -   Skipped train sample 2188 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:38,996 - __main__ - WARNING -   Skipped train sample 2189 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:38,998 - __main__ - WARNING -   Skipped train sample 2190 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,000 - __main__ - WARNING -   Skipped train sample 2191 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:39,002 - __main__ - WARNING -   Skipped train sample 2192 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,003 - __main__ - WARNING -   Skipped train sample 2193 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,005 - __main__ - WARNING -   Skipped train sample 2194 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,007 - __main__ - WARNING -   Skipped train sample 2195 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,009 - __main__ - WARNING -   Skipped train sample 2196 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,011 - __main__ - WARNING -   Skipped train sample 2197 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,013 - __main__ - WARNING -   Skipped train sample 2198 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,014 - __main__ - WARNING -   Skipped train sample 2199 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,016 - __main__ - WARNING -   Skipped train sample 2200 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,018 - __main__ - WARNING -   Skipped train sample 2201 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,020 - __main__ - WARNING -   Skipped train sample 2202 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,022 - __main__ - WARNING -   Skipped train sample 2203 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,024 - __main__ - WARNING -   Skipped train sample 2204 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,026 - __main__ - WARNING -   Skipped train sample 2205 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,028 - __main__ - WARNING -   Skipped train sample 2206 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,030 - __main__ - WARNING -   Skipped train sample 2207 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,031 - __main__ - WARNING -   Skipped train sample 2208 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,033 - __main__ - WARNING -   Skipped train sample 2209 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,035 - __main__ - WARNING -   Skipped train sample 2210 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,037 - __main__ - WARNING -   Skipped train sample 2211 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,039 - __main__ - WARNING -   Skipped train sample 2212 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,041 - __main__ - WARNING -   Skipped train sample 2213 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,043 - __main__ - WARNING -   Skipped train sample 2214 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,045 - __main__ - WARNING -   Skipped train sample 2215 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,046 - __main__ - WARNING -   Skipped train sample 2216 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,048 - __main__ - WARNING -   Skipped train sample 2217 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,050 - __main__ - WARNING -   Skipped train sample 2218 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,052 - __main__ - WARNING -   Skipped train sample 2219 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,054 - __main__ - WARNING -   Skipped train sample 2220 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,056 - __main__ - WARNING -   Skipped train sample 2221 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,058 - __main__ - WARNING -   Skipped train sample 2222 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,060 - __main__ - WARNING -   Skipped train sample 2223 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,062 - __main__ - WARNING -   Skipped train sample 2224 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,064 - __main__ - WARNING -   Skipped train sample 2225 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,065 - __main__ - WARNING -   Skipped train sample 2226 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,067 - __main__ - WARNING -   Skipped train sample 2227 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,069 - __main__ - WARNING -   Skipped train sample 2228 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,071 - __main__ - WARNING -   Skipped train sample 2229 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,073 - __main__ - WARNING -   Skipped train sample 2230 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,075 - __main__ - WARNING -   Skipped train sample 2231 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,077 - __main__ - WARNING -   Skipped train sample 2232 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,079 - __main__ - WARNING -   Skipped train sample 2233 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,081 - __main__ - WARNING -   Skipped train sample 2234 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,083 - __main__ - WARNING -   Skipped train sample 2235 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,084 - __main__ - WARNING -   Skipped train sample 2236 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,086 - __main__ - WARNING -   Skipped train sample 2237 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:39,088 - __main__ - WARNING -   Skipped train sample 2238 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,090 - __main__ - WARNING -   Skipped train sample 2239 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,092 - __main__ - WARNING -   Skipped train sample 2240 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,094 - __main__ - WARNING -   Skipped train sample 2241 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,096 - __main__ - WARNING -   Skipped train sample 2242 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,098 - __main__ - WARNING -   Skipped train sample 2243 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,100 - __main__ - WARNING -   Skipped train sample 2244 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,102 - __main__ - WARNING -   Skipped train sample 2245 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,104 - __main__ - WARNING -   Skipped train sample 2246 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,106 - __main__ - WARNING -   Skipped train sample 2247 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,108 - __main__ - WARNING -   Skipped train sample 2248 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,109 - __main__ - WARNING -   Skipped train sample 2249 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,111 - __main__ - WARNING -   Skipped train sample 2250 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,113 - __main__ - WARNING -   Skipped train sample 2251 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,115 - __main__ - WARNING -   Skipped train sample 2252 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,117 - __main__ - WARNING -   Skipped train sample 2253 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,119 - __main__ - WARNING -   Skipped train sample 2254 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,121 - __main__ - WARNING -   Skipped train sample 2255 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,123 - __main__ - WARNING -   Skipped train sample 2256 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,124 - __main__ - WARNING -   Skipped train sample 2257 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,126 - __main__ - WARNING -   Skipped train sample 2258 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,128 - __main__ - WARNING -   Skipped train sample 2259 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,130 - __main__ - WARNING -   Skipped train sample 2260 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,132 - __main__ - WARNING -   Skipped train sample 2261 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,134 - __main__ - WARNING -   Skipped train sample 2262 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,136 - __main__ - WARNING -   Skipped train sample 2263 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,138 - __main__ - WARNING -   Skipped train sample 2264 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,140 - __main__ - WARNING -   Skipped train sample 2265 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,142 - __main__ - WARNING -   Skipped train sample 2266 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,143 - __main__ - WARNING -   Skipped train sample 2267 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,145 - __main__ - WARNING -   Skipped train sample 2268 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,147 - __main__ - WARNING -   Skipped train sample 2269 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:39,149 - __main__ - WARNING -   Skipped train sample 2270 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,151 - __main__ - WARNING -   Skipped train sample 2271 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,153 - __main__ - WARNING -   Skipped train sample 2272 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,155 - __main__ - WARNING -   Skipped train sample 2273 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,157 - __main__ - WARNING -   Skipped train sample 2274 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,159 - __main__ - WARNING -   Skipped train sample 2275 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,160 - __main__ - WARNING -   Skipped train sample 2276 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,162 - __main__ - WARNING -   Skipped train sample 2277 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,164 - __main__ - WARNING -   Skipped train sample 2278 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,166 - __main__ - WARNING -   Skipped train sample 2279 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,168 - __main__ - WARNING -   Skipped train sample 2280 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,170 - __main__ - WARNING -   Skipped train sample 2281 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,172 - __main__ - WARNING -   Skipped train sample 2282 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,174 - __main__ - WARNING -   Skipped train sample 2283 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,176 - __main__ - WARNING -   Skipped train sample 2284 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,178 - __main__ - WARNING -   Skipped train sample 2285 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,180 - __main__ - WARNING -   Skipped train sample 2286 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,182 - __main__ - WARNING -   Skipped train sample 2287 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,183 - __main__ - WARNING -   Skipped train sample 2288 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,185 - __main__ - WARNING -   Skipped train sample 2289 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,187 - __main__ - WARNING -   Skipped train sample 2290 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,189 - __main__ - WARNING -   Skipped train sample 2291 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,191 - __main__ - WARNING -   Skipped train sample 2292 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,193 - __main__ - WARNING -   Skipped train sample 2293 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,195 - __main__ - WARNING -   Skipped train sample 2294 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,196 - __main__ - WARNING -   Skipped train sample 2295 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,198 - __main__ - WARNING -   Skipped train sample 2296 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,200 - __main__ - WARNING -   Skipped train sample 2297 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,202 - __main__ - WARNING -   Skipped train sample 2298 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,204 - __main__ - WARNING -   Skipped train sample 2299 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,206 - __main__ - WARNING -   Skipped train sample 2300 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,208 - __main__ - WARNING -   Skipped train sample 2301 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,210 - __main__ - WARNING -   Skipped train sample 2302 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,212 - __main__ - WARNING -   Skipped train sample 2303 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,214 - __main__ - WARNING -   Skipped train sample 2304 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,216 - __main__ - WARNING -   Skipped train sample 2305 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,218 - __main__ - WARNING -   Skipped train sample 2306 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,219 - __main__ - WARNING -   Skipped train sample 2307 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,221 - __main__ - WARNING -   Skipped train sample 2308 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,223 - __main__ - WARNING -   Skipped train sample 2309 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,225 - __main__ - WARNING -   Skipped train sample 2310 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,227 - __main__ - WARNING -   Skipped train sample 2311 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,229 - __main__ - WARNING -   Skipped train sample 2312 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,231 - __main__ - WARNING -   Skipped train sample 2313 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,233 - __main__ - WARNING -   Skipped train sample 2314 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,235 - __main__ - WARNING -   Skipped train sample 2315 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,236 - __main__ - WARNING -   Skipped train sample 2316 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,238 - __main__ - WARNING -   Skipped train sample 2317 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,240 - __main__ - WARNING -   Skipped train sample 2318 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,242 - __main__ - WARNING -   Skipped train sample 2319 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,244 - __main__ - WARNING -   Skipped train sample 2320 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,246 - __main__ - WARNING -   Skipped train sample 2321 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,247 - __main__ - WARNING -   Skipped train sample 2322 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,250 - __main__ - WARNING -   Skipped train sample 2323 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,252 - __main__ - WARNING -   Skipped train sample 2324 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,254 - __main__ - WARNING -   Skipped train sample 2325 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,256 - __main__ - WARNING -   Skipped train sample 2326 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,257 - __main__ - WARNING -   Skipped train sample 2327 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,259 - __main__ - WARNING -   Skipped train sample 2328 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,261 - __main__ - WARNING -   Skipped train sample 2329 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,263 - __main__ - WARNING -   Skipped train sample 2330 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,265 - __main__ - WARNING -   Skipped train sample 2331 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,267 - __main__ - WARNING -   Skipped train sample 2332 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,269 - __main__ - WARNING -   Skipped train sample 2333 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,271 - __main__ - WARNING -   Skipped train sample 2334 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,273 - __main__ - WARNING -   Skipped train sample 2335 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,275 - __main__ - WARNING -   Skipped train sample 2336 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,276 - __main__ - WARNING -   Skipped train sample 2337 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,278 - __main__ - WARNING -   Skipped train sample 2338 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,280 - __main__ - WARNING -   Skipped train sample 2339 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,282 - __main__ - WARNING -   Skipped train sample 2340 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,284 - __main__ - WARNING -   Skipped train sample 2341 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,286 - __main__ - WARNING -   Skipped train sample 2342 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,288 - __main__ - WARNING -   Skipped train sample 2343 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,290 - __main__ - WARNING -   Skipped train sample 2344 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,292 - __main__ - WARNING -   Skipped train sample 2345 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,294 - __main__ - WARNING -   Skipped train sample 2346 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,296 - __main__ - WARNING -   Skipped train sample 2347 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,298 - __main__ - WARNING -   Skipped train sample 2348 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,299 - __main__ - WARNING -   Skipped train sample 2349 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,301 - __main__ - WARNING -   Skipped train sample 2350 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,303 - __main__ - WARNING -   Skipped train sample 2351 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,305 - __main__ - WARNING -   Skipped train sample 2352 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,307 - __main__ - WARNING -   Skipped train sample 2353 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,309 - __main__ - WARNING -   Skipped train sample 2354 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,311 - __main__ - WARNING -   Skipped train sample 2355 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,313 - __main__ - WARNING -   Skipped train sample 2356 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,315 - __main__ - WARNING -   Skipped train sample 2357 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,317 - __main__ - WARNING -   Skipped train sample 2358 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,319 - __main__ - WARNING -   Skipped train sample 2359 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,321 - __main__ - WARNING -   Skipped train sample 2360 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,322 - __main__ - WARNING -   Skipped train sample 2361 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,324 - __main__ - WARNING -   Skipped train sample 2362 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,326 - __main__ - WARNING -   Skipped train sample 2363 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,328 - __main__ - WARNING -   Skipped train sample 2364 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,330 - __main__ - WARNING -   Skipped train sample 2365 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,332 - __main__ - WARNING -   Skipped train sample 2366 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,334 - __main__ - WARNING -   Skipped train sample 2367 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,336 - __main__ - WARNING -   Skipped train sample 2368 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,338 - __main__ - WARNING -   Skipped train sample 2369 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,340 - __main__ - WARNING -   Skipped train sample 2370 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,342 - __main__ - WARNING -   Skipped train sample 2371 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,344 - __main__ - WARNING -   Skipped train sample 2372 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,346 - __main__ - WARNING -   Skipped train sample 2373 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,348 - __main__ - WARNING -   Skipped train sample 2374 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,350 - __main__ - WARNING -   Skipped train sample 2375 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,352 - __main__ - WARNING -   Skipped train sample 2376 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,354 - __main__ - WARNING -   Skipped train sample 2377 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,356 - __main__ - WARNING -   Skipped train sample 2378 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,358 - __main__ - WARNING -   Skipped train sample 2379 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,360 - __main__ - WARNING -   Skipped train sample 2380 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,362 - __main__ - WARNING -   Skipped train sample 2381 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,363 - __main__ - WARNING -   Skipped train sample 2382 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,366 - __main__ - WARNING -   Skipped train sample 2383 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,367 - __main__ - WARNING -   Skipped train sample 2384 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,369 - __main__ - WARNING -   Skipped train sample 2385 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,371 - __main__ - WARNING -   Skipped train sample 2386 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:39,373 - __main__ - WARNING -   Skipped train sample 2387 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,375 - __main__ - WARNING -   Skipped train sample 2388 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,377 - __main__ - WARNING -   Skipped train sample 2389 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,379 - __main__ - WARNING -   Skipped train sample 2390 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,380 - __main__ - WARNING -   Skipped train sample 2391 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,382 - __main__ - WARNING -   Skipped train sample 2392 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,384 - __main__ - WARNING -   Skipped train sample 2393 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,386 - __main__ - WARNING -   Skipped train sample 2394 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,388 - __main__ - WARNING -   Skipped train sample 2395 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,390 - __main__ - WARNING -   Skipped train sample 2396 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,392 - __main__ - WARNING -   Skipped train sample 2397 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,393 - __main__ - WARNING -   Skipped train sample 2398 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,395 - __main__ - WARNING -   Skipped train sample 2399 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,397 - __main__ - WARNING -   Skipped train sample 2400 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,399 - __main__ - WARNING -   Skipped train sample 2401 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,401 - __main__ - WARNING -   Skipped train sample 2402 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,403 - __main__ - WARNING -   Skipped train sample 2403 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,405 - __main__ - WARNING -   Skipped train sample 2404 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,407 - __main__ - WARNING -   Skipped train sample 2405 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,408 - __main__ - WARNING -   Skipped train sample 2406 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,410 - __main__ - WARNING -   Skipped train sample 2407 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,412 - __main__ - WARNING -   Skipped train sample 2408 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,414 - __main__ - WARNING -   Skipped train sample 2409 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,416 - __main__ - WARNING -   Skipped train sample 2410 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,418 - __main__ - WARNING -   Skipped train sample 2411 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,420 - __main__ - WARNING -   Skipped train sample 2412 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,422 - __main__ - WARNING -   Skipped train sample 2413 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,424 - __main__ - WARNING -   Skipped train sample 2414 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,426 - __main__ - WARNING -   Skipped train sample 2415 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,427 - __main__ - WARNING -   Skipped train sample 2416 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,429 - __main__ - WARNING -   Skipped train sample 2417 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,431 - __main__ - WARNING -   Skipped train sample 2418 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,433 - __main__ - WARNING -   Skipped train sample 2419 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,435 - __main__ - WARNING -   Skipped train sample 2420 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,437 - __main__ - WARNING -   Skipped train sample 2421 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,439 - __main__ - WARNING -   Skipped train sample 2422 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,440 - __main__ - WARNING -   Skipped train sample 2423 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,442 - __main__ - WARNING -   Skipped train sample 2424 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,444 - __main__ - WARNING -   Skipped train sample 2425 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,446 - __main__ - WARNING -   Skipped train sample 2426 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,448 - __main__ - WARNING -   Skipped train sample 2427 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,450 - __main__ - WARNING -   Skipped train sample 2428 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,452 - __main__ - WARNING -   Skipped train sample 2429 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,454 - __main__ - WARNING -   Skipped train sample 2430 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,456 - __main__ - WARNING -   Skipped train sample 2431 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,458 - __main__ - WARNING -   Skipped train sample 2432 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,460 - __main__ - WARNING -   Skipped train sample 2433 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,462 - __main__ - WARNING -   Skipped train sample 2434 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,464 - __main__ - WARNING -   Skipped train sample 2435 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,466 - __main__ - WARNING -   Skipped train sample 2436 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,467 - __main__ - WARNING -   Skipped train sample 2437 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,469 - __main__ - WARNING -   Skipped train sample 2438 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,471 - __main__ - WARNING -   Skipped train sample 2439 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,473 - __main__ - WARNING -   Skipped train sample 2440 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,475 - __main__ - WARNING -   Skipped train sample 2441 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,477 - __main__ - WARNING -   Skipped train sample 2442 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,479 - __main__ - WARNING -   Skipped train sample 2443 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,481 - __main__ - WARNING -   Skipped train sample 2444 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,483 - __main__ - WARNING -   Skipped train sample 2445 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,485 - __main__ - WARNING -   Skipped train sample 2446 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,487 - __main__ - WARNING -   Skipped train sample 2447 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,489 - __main__ - WARNING -   Skipped train sample 2448 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,490 - __main__ - WARNING -   Skipped train sample 2449 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,492 - __main__ - WARNING -   Skipped train sample 2450 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,494 - __main__ - WARNING -   Skipped train sample 2451 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,496 - __main__ - WARNING -   Skipped train sample 2452 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,498 - __main__ - WARNING -   Skipped train sample 2453 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,500 - __main__ - WARNING -   Skipped train sample 2454 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,502 - __main__ - WARNING -   Skipped train sample 2455 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,504 - __main__ - WARNING -   Skipped train sample 2456 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,506 - __main__ - WARNING -   Skipped train sample 2457 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,508 - __main__ - WARNING -   Skipped train sample 2458 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,510 - __main__ - WARNING -   Skipped train sample 2459 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,512 - __main__ - WARNING -   Skipped train sample 2460 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,514 - __main__ - WARNING -   Skipped train sample 2461 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,516 - __main__ - WARNING -   Skipped train sample 2462 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,518 - __main__ - WARNING -   Skipped train sample 2463 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,520 - __main__ - WARNING -   Skipped train sample 2464 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,522 - __main__ - WARNING -   Skipped train sample 2465 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,524 - __main__ - WARNING -   Skipped train sample 2466 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,525 - __main__ - WARNING -   Skipped train sample 2467 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,527 - __main__ - WARNING -   Skipped train sample 2468 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,529 - __main__ - WARNING -   Skipped train sample 2469 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,531 - __main__ - WARNING -   Skipped train sample 2470 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,533 - __main__ - WARNING -   Skipped train sample 2471 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,535 - __main__ - WARNING -   Skipped train sample 2472 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,537 - __main__ - WARNING -   Skipped train sample 2473 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,538 - __main__ - WARNING -   Skipped train sample 2474 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,540 - __main__ - WARNING -   Skipped train sample 2475 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,542 - __main__ - WARNING -   Skipped train sample 2476 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,544 - __main__ - WARNING -   Skipped train sample 2477 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,546 - __main__ - WARNING -   Skipped train sample 2478 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,548 - __main__ - WARNING -   Skipped train sample 2479 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,550 - __main__ - WARNING -   Skipped train sample 2480 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,552 - __main__ - WARNING -   Skipped train sample 2481 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,554 - __main__ - WARNING -   Skipped train sample 2482 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,556 - __main__ - WARNING -   Skipped train sample 2483 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,558 - __main__ - WARNING -   Skipped train sample 2484 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,560 - __main__ - WARNING -   Skipped train sample 2485 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,562 - __main__ - WARNING -   Skipped train sample 2486 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,563 - __main__ - WARNING -   Skipped train sample 2487 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,565 - __main__ - WARNING -   Skipped train sample 2488 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,567 - __main__ - WARNING -   Skipped train sample 2489 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,569 - __main__ - WARNING -   Skipped train sample 2490 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,571 - __main__ - WARNING -   Skipped train sample 2491 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,573 - __main__ - WARNING -   Skipped train sample 2492 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,575 - __main__ - WARNING -   Skipped train sample 2493 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,577 - __main__ - WARNING -   Skipped train sample 2494 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,579 - __main__ - WARNING -   Skipped train sample 2495 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,581 - __main__ - WARNING -   Skipped train sample 2496 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,583 - __main__ - WARNING -   Skipped train sample 2497 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,584 - __main__ - WARNING -   Skipped train sample 2498 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,587 - __main__ - WARNING -   Skipped train sample 2499 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,589 - __main__ - WARNING -   Skipped train sample 2500 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,591 - __main__ - WARNING -   Skipped train sample 2501 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,593 - __main__ - WARNING -   Skipped train sample 2502 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,594 - __main__ - WARNING -   Skipped train sample 2503 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,596 - __main__ - WARNING -   Skipped train sample 2504 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,598 - __main__ - WARNING -   Skipped train sample 2505 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,600 - __main__ - WARNING -   Skipped train sample 2506 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,602 - __main__ - WARNING -   Skipped train sample 2507 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,604 - __main__ - WARNING -   Skipped train sample 2508 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,606 - __main__ - WARNING -   Skipped train sample 2509 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,608 - __main__ - WARNING -   Skipped train sample 2510 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,610 - __main__ - WARNING -   Skipped train sample 2511 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,612 - __main__ - WARNING -   Skipped train sample 2512 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,614 - __main__ - WARNING -   Skipped train sample 2513 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,616 - __main__ - WARNING -   Skipped train sample 2514 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,618 - __main__ - WARNING -   Skipped train sample 2515 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,620 - __main__ - WARNING -   Skipped train sample 2516 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,622 - __main__ - WARNING -   Skipped train sample 2517 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,624 - __main__ - WARNING -   Skipped train sample 2518 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,626 - __main__ - WARNING -   Skipped train sample 2519 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,627 - __main__ - WARNING -   Skipped train sample 2520 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,629 - __main__ - WARNING -   Skipped train sample 2521 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,631 - __main__ - WARNING -   Skipped train sample 2522 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,633 - __main__ - WARNING -   Skipped train sample 2523 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,635 - __main__ - WARNING -   Skipped train sample 2524 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,637 - __main__ - WARNING -   Skipped train sample 2525 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,639 - __main__ - WARNING -   Skipped train sample 2526 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,641 - __main__ - WARNING -   Skipped train sample 2527 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,643 - __main__ - WARNING -   Skipped train sample 2528 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,644 - __main__ - WARNING -   Skipped train sample 2529 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,646 - __main__ - WARNING -   Skipped train sample 2530 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,648 - __main__ - WARNING -   Skipped train sample 2531 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,650 - __main__ - WARNING -   Skipped train sample 2532 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,652 - __main__ - WARNING -   Skipped train sample 2533 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,654 - __main__ - WARNING -   Skipped train sample 2534 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,656 - __main__ - WARNING -   Skipped train sample 2535 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,658 - __main__ - WARNING -   Skipped train sample 2536 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,660 - __main__ - WARNING -   Skipped train sample 2537 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,662 - __main__ - WARNING -   Skipped train sample 2538 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,664 - __main__ - WARNING -   Skipped train sample 2539 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,666 - __main__ - WARNING -   Skipped train sample 2540 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,667 - __main__ - WARNING -   Skipped train sample 2541 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,669 - __main__ - WARNING -   Skipped train sample 2542 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,671 - __main__ - WARNING -   Skipped train sample 2543 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,673 - __main__ - WARNING -   Skipped train sample 2544 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,675 - __main__ - WARNING -   Skipped train sample 2545 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,677 - __main__ - WARNING -   Skipped train sample 2546 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,679 - __main__ - WARNING -   Skipped train sample 2547 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,681 - __main__ - WARNING -   Skipped train sample 2548 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,683 - __main__ - WARNING -   Skipped train sample 2549 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,685 - __main__ - WARNING -   Skipped train sample 2550 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,687 - __main__ - WARNING -   Skipped train sample 2551 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,688 - __main__ - WARNING -   Skipped train sample 2552 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,690 - __main__ - WARNING -   Skipped train sample 2553 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,692 - __main__ - WARNING -   Skipped train sample 2554 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,694 - __main__ - WARNING -   Skipped train sample 2555 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,696 - __main__ - WARNING -   Skipped train sample 2556 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,698 - __main__ - WARNING -   Skipped train sample 2557 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,700 - __main__ - WARNING -   Skipped train sample 2558 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,702 - __main__ - WARNING -   Skipped train sample 2559 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,704 - __main__ - WARNING -   Skipped train sample 2560 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,706 - __main__ - WARNING -   Skipped train sample 2561 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,708 - __main__ - WARNING -   Skipped train sample 2562 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,710 - __main__ - WARNING -   Skipped train sample 2563 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,712 - __main__ - WARNING -   Skipped train sample 2564 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,714 - __main__ - WARNING -   Skipped train sample 2565 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,716 - __main__ - WARNING -   Skipped train sample 2566 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,718 - __main__ - WARNING -   Skipped train sample 2567 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,720 - __main__ - WARNING -   Skipped train sample 2568 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,722 - __main__ - WARNING -   Skipped train sample 2569 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,724 - __main__ - WARNING -   Skipped train sample 2570 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,726 - __main__ - WARNING -   Skipped train sample 2571 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,727 - __main__ - WARNING -   Skipped train sample 2572 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,729 - __main__ - WARNING -   Skipped train sample 2573 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,731 - __main__ - WARNING -   Skipped train sample 2574 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,733 - __main__ - WARNING -   Skipped train sample 2575 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,735 - __main__ - WARNING -   Skipped train sample 2576 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,737 - __main__ - WARNING -   Skipped train sample 2577 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,739 - __main__ - WARNING -   Skipped train sample 2578 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,741 - __main__ - WARNING -   Skipped train sample 2579 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,743 - __main__ - WARNING -   Skipped train sample 2580 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,744 - __main__ - WARNING -   Skipped train sample 2581 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,746 - __main__ - WARNING -   Skipped train sample 2582 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,748 - __main__ - WARNING -   Skipped train sample 2583 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,750 - __main__ - WARNING -   Skipped train sample 2584 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,752 - __main__ - WARNING -   Skipped train sample 2585 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,754 - __main__ - WARNING -   Skipped train sample 2586 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,756 - __main__ - WARNING -   Skipped train sample 2587 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,758 - __main__ - WARNING -   Skipped train sample 2588 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,760 - __main__ - WARNING -   Skipped train sample 2589 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,762 - __main__ - WARNING -   Skipped train sample 2590 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,763 - __main__ - WARNING -   Skipped train sample 2591 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,765 - __main__ - WARNING -   Skipped train sample 2592 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,767 - __main__ - WARNING -   Skipped train sample 2593 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,769 - __main__ - WARNING -   Skipped train sample 2594 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,771 - __main__ - WARNING -   Skipped train sample 2595 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:39,773 - __main__ - WARNING -   Skipped train sample 2596 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,774 - __main__ - WARNING -   Skipped train sample 2597 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,776 - __main__ - WARNING -   Skipped train sample 2598 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,778 - __main__ - WARNING -   Skipped train sample 2599 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,780 - __main__ - WARNING -   Skipped train sample 2600 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,782 - __main__ - WARNING -   Skipped train sample 2601 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,784 - __main__ - WARNING -   Skipped train sample 2602 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,786 - __main__ - WARNING -   Skipped train sample 2603 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,788 - __main__ - WARNING -   Skipped train sample 2604 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,790 - __main__ - WARNING -   Skipped train sample 2605 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,792 - __main__ - WARNING -   Skipped train sample 2606 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,794 - __main__ - WARNING -   Skipped train sample 2607 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,795 - __main__ - WARNING -   Skipped train sample 2608 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,797 - __main__ - WARNING -   Skipped train sample 2609 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,799 - __main__ - WARNING -   Skipped train sample 2610 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,801 - __main__ - WARNING -   Skipped train sample 2611 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,803 - __main__ - WARNING -   Skipped train sample 2612 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,805 - __main__ - WARNING -   Skipped train sample 2613 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,807 - __main__ - WARNING -   Skipped train sample 2614 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,808 - __main__ - WARNING -   Skipped train sample 2615 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,810 - __main__ - WARNING -   Skipped train sample 2616 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,812 - __main__ - WARNING -   Skipped train sample 2617 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,814 - __main__ - WARNING -   Skipped train sample 2618 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,816 - __main__ - WARNING -   Skipped train sample 2619 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,818 - __main__ - WARNING -   Skipped train sample 2620 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,820 - __main__ - WARNING -   Skipped train sample 2621 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,822 - __main__ - WARNING -   Skipped train sample 2622 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,824 - __main__ - WARNING -   Skipped train sample 2623 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,826 - __main__ - WARNING -   Skipped train sample 2624 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,828 - __main__ - WARNING -   Skipped train sample 2625 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,830 - __main__ - WARNING -   Skipped train sample 2626 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,831 - __main__ - WARNING -   Skipped train sample 2627 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,834 - __main__ - WARNING -   Skipped train sample 2628 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,835 - __main__ - WARNING -   Skipped train sample 2629 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,837 - __main__ - WARNING -   Skipped train sample 2630 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,839 - __main__ - WARNING -   Skipped train sample 2631 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,841 - __main__ - WARNING -   Skipped train sample 2632 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,843 - __main__ - WARNING -   Skipped train sample 2633 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,845 - __main__ - WARNING -   Skipped train sample 2634 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,847 - __main__ - WARNING -   Skipped train sample 2635 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,849 - __main__ - WARNING -   Skipped train sample 2636 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,851 - __main__ - WARNING -   Skipped train sample 2637 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,853 - __main__ - WARNING -   Skipped train sample 2638 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,855 - __main__ - WARNING -   Skipped train sample 2639 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,857 - __main__ - WARNING -   Skipped train sample 2640 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,858 - __main__ - WARNING -   Skipped train sample 2641 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,860 - __main__ - WARNING -   Skipped train sample 2642 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,862 - __main__ - WARNING -   Skipped train sample 2643 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,864 - __main__ - WARNING -   Skipped train sample 2644 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,866 - __main__ - WARNING -   Skipped train sample 2645 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,868 - __main__ - WARNING -   Skipped train sample 2646 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,870 - __main__ - WARNING -   Skipped train sample 2647 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:39,872 - __main__ - WARNING -   Skipped train sample 2648 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,874 - __main__ - WARNING -   Skipped train sample 2649 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,876 - __main__ - WARNING -   Skipped train sample 2650 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,878 - __main__ - WARNING -   Skipped train sample 2651 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,880 - __main__ - WARNING -   Skipped train sample 2652 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,882 - __main__ - WARNING -   Skipped train sample 2653 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,884 - __main__ - WARNING -   Skipped train sample 2654 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,886 - __main__ - WARNING -   Skipped train sample 2655 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,888 - __main__ - WARNING -   Skipped train sample 2656 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,890 - __main__ - WARNING -   Skipped train sample 2657 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,892 - __main__ - WARNING -   Skipped train sample 2658 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,894 - __main__ - WARNING -   Skipped train sample 2659 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,896 - __main__ - WARNING -   Skipped train sample 2660 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,897 - __main__ - WARNING -   Skipped train sample 2661 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,899 - __main__ - WARNING -   Skipped train sample 2662 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,901 - __main__ - WARNING -   Skipped train sample 2663 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,903 - __main__ - WARNING -   Skipped train sample 2664 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,905 - __main__ - WARNING -   Skipped train sample 2665 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,907 - __main__ - WARNING -   Skipped train sample 2666 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,909 - __main__ - WARNING -   Skipped train sample 2667 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,911 - __main__ - WARNING -   Skipped train sample 2668 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,913 - __main__ - WARNING -   Skipped train sample 2669 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,915 - __main__ - WARNING -   Skipped train sample 2670 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,917 - __main__ - WARNING -   Skipped train sample 2671 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,919 - __main__ - WARNING -   Skipped train sample 2672 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,921 - __main__ - WARNING -   Skipped train sample 2673 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,923 - __main__ - WARNING -   Skipped train sample 2674 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,924 - __main__ - WARNING -   Skipped train sample 2675 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,926 - __main__ - WARNING -   Skipped train sample 2676 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,928 - __main__ - WARNING -   Skipped train sample 2677 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,930 - __main__ - WARNING -   Skipped train sample 2678 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,932 - __main__ - WARNING -   Skipped train sample 2679 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,934 - __main__ - WARNING -   Skipped train sample 2680 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,936 - __main__ - WARNING -   Skipped train sample 2681 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,938 - __main__ - WARNING -   Skipped train sample 2682 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,940 - __main__ - WARNING -   Skipped train sample 2683 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,942 - __main__ - WARNING -   Skipped train sample 2684 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,944 - __main__ - WARNING -   Skipped train sample 2685 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,946 - __main__ - WARNING -   Skipped train sample 2686 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,948 - __main__ - WARNING -   Skipped train sample 2687 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,950 - __main__ - WARNING -   Skipped train sample 2688 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,952 - __main__ - WARNING -   Skipped train sample 2689 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,954 - __main__ - WARNING -   Skipped train sample 2690 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,956 - __main__ - WARNING -   Skipped train sample 2691 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:39,957 - __main__ - WARNING -   Skipped train sample 2692 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,959 - __main__ - WARNING -   Skipped train sample 2693 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,961 - __main__ - WARNING -   Skipped train sample 2694 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,963 - __main__ - WARNING -   Skipped train sample 2695 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,965 - __main__ - WARNING -   Skipped train sample 2696 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,967 - __main__ - WARNING -   Skipped train sample 2697 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,969 - __main__ - WARNING -   Skipped train sample 2698 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,971 - __main__ - WARNING -   Skipped train sample 2699 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,973 - __main__ - WARNING -   Skipped train sample 2700 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,975 - __main__ - WARNING -   Skipped train sample 2701 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,976 - __main__ - WARNING -   Skipped train sample 2702 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,978 - __main__ - WARNING -   Skipped train sample 2703 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,981 - __main__ - WARNING -   Skipped train sample 2704 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,982 - __main__ - WARNING -   Skipped train sample 2705 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,984 - __main__ - WARNING -   Skipped train sample 2706 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,986 - __main__ - WARNING -   Skipped train sample 2707 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,988 - __main__ - WARNING -   Skipped train sample 2708 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:39,990 - __main__ - WARNING -   Skipped train sample 2709 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,992 - __main__ - WARNING -   Skipped train sample 2710 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:39,994 - __main__ - WARNING -   Skipped train sample 2711 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,996 - __main__ - WARNING -   Skipped train sample 2712 due to error: cannot convert float NaN to integer
2025-09-21 22:09:39,998 - __main__ - WARNING -   Skipped train sample 2713 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,000 - __main__ - WARNING -   Skipped train sample 2714 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,002 - __main__ - WARNING -   Skipped train sample 2715 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,004 - __main__ - WARNING -   Skipped train sample 2716 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,006 - __main__ - WARNING -   Skipped train sample 2717 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,008 - __main__ - WARNING -   Skipped train sample 2718 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,010 - __main__ - WARNING -   Skipped train sample 2719 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,012 - __main__ - WARNING -   Skipped train sample 2720 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,014 - __main__ - WARNING -   Skipped train sample 2721 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,016 - __main__ - WARNING -   Skipped train sample 2722 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,018 - __main__ - WARNING -   Skipped train sample 2723 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,020 - __main__ - WARNING -   Skipped train sample 2724 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,022 - __main__ - WARNING -   Skipped train sample 2725 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,023 - __main__ - WARNING -   Skipped train sample 2726 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,026 - __main__ - WARNING -   Skipped train sample 2727 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,027 - __main__ - WARNING -   Skipped train sample 2728 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,029 - __main__ - WARNING -   Skipped train sample 2729 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,031 - __main__ - WARNING -   Skipped train sample 2730 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,033 - __main__ - WARNING -   Skipped train sample 2731 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,035 - __main__ - WARNING -   Skipped train sample 2732 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,037 - __main__ - WARNING -   Skipped train sample 2733 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,039 - __main__ - WARNING -   Skipped train sample 2734 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,040 - __main__ - WARNING -   Skipped train sample 2735 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,042 - __main__ - WARNING -   Skipped train sample 2736 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,044 - __main__ - WARNING -   Skipped train sample 2737 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,046 - __main__ - WARNING -   Skipped train sample 2738 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,048 - __main__ - WARNING -   Skipped train sample 2739 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,050 - __main__ - WARNING -   Skipped train sample 2740 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,052 - __main__ - WARNING -   Skipped train sample 2741 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,054 - __main__ - WARNING -   Skipped train sample 2742 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,056 - __main__ - WARNING -   Skipped train sample 2743 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,058 - __main__ - WARNING -   Skipped train sample 2744 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,060 - __main__ - WARNING -   Skipped train sample 2745 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,062 - __main__ - WARNING -   Skipped train sample 2746 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,064 - __main__ - WARNING -   Skipped train sample 2747 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,066 - __main__ - WARNING -   Skipped train sample 2748 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,068 - __main__ - WARNING -   Skipped train sample 2749 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,069 - __main__ - WARNING -   Skipped train sample 2750 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,071 - __main__ - WARNING -   Skipped train sample 2751 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,073 - __main__ - WARNING -   Skipped train sample 2752 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,075 - __main__ - WARNING -   Skipped train sample 2753 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,078 - __main__ - WARNING -   Skipped train sample 2754 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,079 - __main__ - WARNING -   Skipped train sample 2755 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,081 - __main__ - WARNING -   Skipped train sample 2756 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,083 - __main__ - WARNING -   Skipped train sample 2757 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,085 - __main__ - WARNING -   Skipped train sample 2758 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,087 - __main__ - WARNING -   Skipped train sample 2759 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,089 - __main__ - WARNING -   Skipped train sample 2760 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,091 - __main__ - WARNING -   Skipped train sample 2761 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,092 - __main__ - WARNING -   Skipped train sample 2762 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,094 - __main__ - WARNING -   Skipped train sample 2763 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,096 - __main__ - WARNING -   Skipped train sample 2764 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,098 - __main__ - WARNING -   Skipped train sample 2765 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,100 - __main__ - WARNING -   Skipped train sample 2766 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,102 - __main__ - WARNING -   Skipped train sample 2767 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,104 - __main__ - WARNING -   Skipped train sample 2768 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,106 - __main__ - WARNING -   Skipped train sample 2769 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,108 - __main__ - WARNING -   Skipped train sample 2770 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,110 - __main__ - WARNING -   Skipped train sample 2771 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,112 - __main__ - WARNING -   Skipped train sample 2772 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,114 - __main__ - WARNING -   Skipped train sample 2773 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,116 - __main__ - WARNING -   Skipped train sample 2774 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,118 - __main__ - WARNING -   Skipped train sample 2775 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,120 - __main__ - WARNING -   Skipped train sample 2776 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,122 - __main__ - WARNING -   Skipped train sample 2777 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,124 - __main__ - WARNING -   Skipped train sample 2778 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,126 - __main__ - WARNING -   Skipped train sample 2779 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,128 - __main__ - WARNING -   Skipped train sample 2780 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,130 - __main__ - WARNING -   Skipped train sample 2781 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,131 - __main__ - WARNING -   Skipped train sample 2782 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,134 - __main__ - WARNING -   Skipped train sample 2783 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,135 - __main__ - WARNING -   Skipped train sample 2784 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,137 - __main__ - WARNING -   Skipped train sample 2785 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,139 - __main__ - WARNING -   Skipped train sample 2786 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,141 - __main__ - WARNING -   Skipped train sample 2787 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,143 - __main__ - WARNING -   Skipped train sample 2788 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,145 - __main__ - WARNING -   Skipped train sample 2789 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,147 - __main__ - WARNING -   Skipped train sample 2790 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,148 - __main__ - WARNING -   Skipped train sample 2791 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,150 - __main__ - WARNING -   Skipped train sample 2792 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,152 - __main__ - WARNING -   Skipped train sample 2793 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,154 - __main__ - WARNING -   Skipped train sample 2794 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,156 - __main__ - WARNING -   Skipped train sample 2795 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,158 - __main__ - WARNING -   Skipped train sample 2796 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,160 - __main__ - WARNING -   Skipped train sample 2797 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,162 - __main__ - WARNING -   Skipped train sample 2798 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,164 - __main__ - WARNING -   Skipped train sample 2799 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,166 - __main__ - WARNING -   Skipped train sample 2800 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,168 - __main__ - WARNING -   Skipped train sample 2801 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,170 - __main__ - WARNING -   Skipped train sample 2802 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,172 - __main__ - WARNING -   Skipped train sample 2803 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,174 - __main__ - WARNING -   Skipped train sample 2804 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,176 - __main__ - WARNING -   Skipped train sample 2805 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,178 - __main__ - WARNING -   Skipped train sample 2806 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,180 - __main__ - WARNING -   Skipped train sample 2807 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,182 - __main__ - WARNING -   Skipped train sample 2808 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,183 - __main__ - WARNING -   Skipped train sample 2809 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,186 - __main__ - WARNING -   Skipped train sample 2810 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,187 - __main__ - WARNING -   Skipped train sample 2811 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,189 - __main__ - WARNING -   Skipped train sample 2812 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,191 - __main__ - WARNING -   Skipped train sample 2813 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,193 - __main__ - WARNING -   Skipped train sample 2814 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,195 - __main__ - WARNING -   Skipped train sample 2815 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,197 - __main__ - WARNING -   Skipped train sample 2816 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,199 - __main__ - WARNING -   Skipped train sample 2817 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,200 - __main__ - WARNING -   Skipped train sample 2818 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,202 - __main__ - WARNING -   Skipped train sample 2819 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,204 - __main__ - WARNING -   Skipped train sample 2820 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,206 - __main__ - WARNING -   Skipped train sample 2821 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,209 - __main__ - WARNING -   Skipped train sample 2822 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,211 - __main__ - WARNING -   Skipped train sample 2823 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,213 - __main__ - WARNING -   Skipped train sample 2824 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,215 - __main__ - WARNING -   Skipped train sample 2825 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,217 - __main__ - WARNING -   Skipped train sample 2826 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,219 - __main__ - WARNING -   Skipped train sample 2827 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,221 - __main__ - WARNING -   Skipped train sample 2828 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,223 - __main__ - WARNING -   Skipped train sample 2829 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,226 - __main__ - WARNING -   Skipped train sample 2830 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,227 - __main__ - WARNING -   Skipped train sample 2831 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,229 - __main__ - WARNING -   Skipped train sample 2832 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,231 - __main__ - WARNING -   Skipped train sample 2833 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,233 - __main__ - WARNING -   Skipped train sample 2834 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,235 - __main__ - WARNING -   Skipped train sample 2835 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,237 - __main__ - WARNING -   Skipped train sample 2836 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,239 - __main__ - WARNING -   Skipped train sample 2837 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,241 - __main__ - WARNING -   Skipped train sample 2838 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,243 - __main__ - WARNING -   Skipped train sample 2839 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,244 - __main__ - WARNING -   Skipped train sample 2840 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,246 - __main__ - WARNING -   Skipped train sample 2841 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,248 - __main__ - WARNING -   Skipped train sample 2842 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,250 - __main__ - WARNING -   Skipped train sample 2843 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,252 - __main__ - WARNING -   Skipped train sample 2844 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,254 - __main__ - WARNING -   Skipped train sample 2845 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,256 - __main__ - WARNING -   Skipped train sample 2846 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,258 - __main__ - WARNING -   Skipped train sample 2847 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,260 - __main__ - WARNING -   Skipped train sample 2848 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,262 - __main__ - WARNING -   Skipped train sample 2849 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,264 - __main__ - WARNING -   Skipped train sample 2850 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,266 - __main__ - WARNING -   Skipped train sample 2851 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,268 - __main__ - WARNING -   Skipped train sample 2852 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,270 - __main__ - WARNING -   Skipped train sample 2853 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,271 - __main__ - WARNING -   Skipped train sample 2854 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,273 - __main__ - WARNING -   Skipped train sample 2855 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,275 - __main__ - WARNING -   Skipped train sample 2856 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,277 - __main__ - WARNING -   Skipped train sample 2857 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,279 - __main__ - WARNING -   Skipped train sample 2858 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,281 - __main__ - WARNING -   Skipped train sample 2859 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,283 - __main__ - WARNING -   Skipped train sample 2860 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,285 - __main__ - WARNING -   Skipped train sample 2861 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,287 - __main__ - WARNING -   Skipped train sample 2862 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,288 - __main__ - WARNING -   Skipped train sample 2863 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,290 - __main__ - WARNING -   Skipped train sample 2864 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,292 - __main__ - WARNING -   Skipped train sample 2865 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,294 - __main__ - WARNING -   Skipped train sample 2866 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,296 - __main__ - WARNING -   Skipped train sample 2867 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,298 - __main__ - WARNING -   Skipped train sample 2868 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,300 - __main__ - WARNING -   Skipped train sample 2869 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,302 - __main__ - WARNING -   Skipped train sample 2870 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,304 - __main__ - WARNING -   Skipped train sample 2871 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,306 - __main__ - WARNING -   Skipped train sample 2872 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,307 - __main__ - WARNING -   Skipped train sample 2873 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,309 - __main__ - WARNING -   Skipped train sample 2874 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,311 - __main__ - WARNING -   Skipped train sample 2875 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,313 - __main__ - WARNING -   Skipped train sample 2876 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,315 - __main__ - WARNING -   Skipped train sample 2877 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,317 - __main__ - WARNING -   Skipped train sample 2878 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,319 - __main__ - WARNING -   Skipped train sample 2879 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,321 - __main__ - WARNING -   Skipped train sample 2880 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,323 - __main__ - WARNING -   Skipped train sample 2881 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,325 - __main__ - WARNING -   Skipped train sample 2882 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,327 - __main__ - WARNING -   Skipped train sample 2883 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,328 - __main__ - WARNING -   Skipped train sample 2884 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,330 - __main__ - WARNING -   Skipped train sample 2885 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,332 - __main__ - WARNING -   Skipped train sample 2886 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,334 - __main__ - WARNING -   Skipped train sample 2887 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,336 - __main__ - WARNING -   Skipped train sample 2888 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,338 - __main__ - WARNING -   Skipped train sample 2889 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,340 - __main__ - WARNING -   Skipped train sample 2890 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,342 - __main__ - WARNING -   Skipped train sample 2891 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,344 - __main__ - WARNING -   Skipped train sample 2892 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,346 - __main__ - WARNING -   Skipped train sample 2893 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,347 - __main__ - WARNING -   Skipped train sample 2894 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,349 - __main__ - WARNING -   Skipped train sample 2895 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,351 - __main__ - WARNING -   Skipped train sample 2896 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,353 - __main__ - WARNING -   Skipped train sample 2897 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,355 - __main__ - WARNING -   Skipped train sample 2898 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,357 - __main__ - WARNING -   Skipped train sample 2899 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,359 - __main__ - WARNING -   Skipped train sample 2900 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,361 - __main__ - WARNING -   Skipped train sample 2901 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,363 - __main__ - WARNING -   Skipped train sample 2902 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,365 - __main__ - WARNING -   Skipped train sample 2903 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,367 - __main__ - WARNING -   Skipped train sample 2904 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,369 - __main__ - WARNING -   Skipped train sample 2905 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,371 - __main__ - WARNING -   Skipped train sample 2906 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,373 - __main__ - WARNING -   Skipped train sample 2907 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,375 - __main__ - WARNING -   Skipped train sample 2908 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,376 - __main__ - WARNING -   Skipped train sample 2909 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,378 - __main__ - WARNING -   Skipped train sample 2910 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,380 - __main__ - WARNING -   Skipped train sample 2911 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,382 - __main__ - WARNING -   Skipped train sample 2912 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,384 - __main__ - WARNING -   Skipped train sample 2913 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,386 - __main__ - WARNING -   Skipped train sample 2914 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,388 - __main__ - WARNING -   Skipped train sample 2915 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,390 - __main__ - WARNING -   Skipped train sample 2916 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,392 - __main__ - WARNING -   Skipped train sample 2917 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,394 - __main__ - WARNING -   Skipped train sample 2918 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,396 - __main__ - WARNING -   Skipped train sample 2919 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,397 - __main__ - WARNING -   Skipped train sample 2920 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,399 - __main__ - WARNING -   Skipped train sample 2921 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,401 - __main__ - WARNING -   Skipped train sample 2922 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,403 - __main__ - WARNING -   Skipped train sample 2923 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,405 - __main__ - WARNING -   Skipped train sample 2924 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,407 - __main__ - WARNING -   Skipped train sample 2925 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,409 - __main__ - WARNING -   Skipped train sample 2926 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,411 - __main__ - WARNING -   Skipped train sample 2927 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,413 - __main__ - WARNING -   Skipped train sample 2928 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,415 - __main__ - WARNING -   Skipped train sample 2929 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,417 - __main__ - WARNING -   Skipped train sample 2930 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,419 - __main__ - WARNING -   Skipped train sample 2931 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,421 - __main__ - WARNING -   Skipped train sample 2932 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,423 - __main__ - WARNING -   Skipped train sample 2933 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,425 - __main__ - WARNING -   Skipped train sample 2934 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,427 - __main__ - WARNING -   Skipped train sample 2935 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,429 - __main__ - WARNING -   Skipped train sample 2936 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,431 - __main__ - WARNING -   Skipped train sample 2937 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,433 - __main__ - WARNING -   Skipped train sample 2938 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,435 - __main__ - WARNING -   Skipped train sample 2939 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,437 - __main__ - WARNING -   Skipped train sample 2940 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,439 - __main__ - WARNING -   Skipped train sample 2941 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,441 - __main__ - WARNING -   Skipped train sample 2942 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,443 - __main__ - WARNING -   Skipped train sample 2943 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,445 - __main__ - WARNING -   Skipped train sample 2944 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,447 - __main__ - WARNING -   Skipped train sample 2945 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,449 - __main__ - WARNING -   Skipped train sample 2946 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,451 - __main__ - WARNING -   Skipped train sample 2947 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,453 - __main__ - WARNING -   Skipped train sample 2948 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,455 - __main__ - WARNING -   Skipped train sample 2949 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,457 - __main__ - WARNING -   Skipped train sample 2950 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,459 - __main__ - WARNING -   Skipped train sample 2951 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,461 - __main__ - WARNING -   Skipped train sample 2952 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,463 - __main__ - WARNING -   Skipped train sample 2953 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,465 - __main__ - WARNING -   Skipped train sample 2954 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,467 - __main__ - WARNING -   Skipped train sample 2955 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,469 - __main__ - WARNING -   Skipped train sample 2956 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,471 - __main__ - WARNING -   Skipped train sample 2957 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,472 - __main__ - WARNING -   Skipped train sample 2958 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,474 - __main__ - WARNING -   Skipped train sample 2959 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,476 - __main__ - WARNING -   Skipped train sample 2960 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,478 - __main__ - WARNING -   Skipped train sample 2961 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,480 - __main__ - WARNING -   Skipped train sample 2962 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,482 - __main__ - WARNING -   Skipped train sample 2963 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,484 - __main__ - WARNING -   Skipped train sample 2964 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,486 - __main__ - WARNING -   Skipped train sample 2965 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,488 - __main__ - WARNING -   Skipped train sample 2966 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,490 - __main__ - WARNING -   Skipped train sample 2967 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,492 - __main__ - WARNING -   Skipped train sample 2968 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,494 - __main__ - WARNING -   Skipped train sample 2969 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,496 - __main__ - WARNING -   Skipped train sample 2970 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,499 - __main__ - WARNING -   Skipped train sample 2971 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,501 - __main__ - WARNING -   Skipped train sample 2972 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,503 - __main__ - WARNING -   Skipped train sample 2973 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,504 - __main__ - WARNING -   Skipped train sample 2974 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,507 - __main__ - WARNING -   Skipped train sample 2975 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,508 - __main__ - WARNING -   Skipped train sample 2976 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,510 - __main__ - WARNING -   Skipped train sample 2977 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,512 - __main__ - WARNING -   Skipped train sample 2978 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,514 - __main__ - WARNING -   Skipped train sample 2979 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,516 - __main__ - WARNING -   Skipped train sample 2980 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,518 - __main__ - WARNING -   Skipped train sample 2981 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:40,519 - __main__ - WARNING -   Skipped train sample 2982 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,521 - __main__ - WARNING -   Skipped train sample 2983 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,523 - __main__ - WARNING -   Skipped train sample 2984 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,525 - __main__ - WARNING -   Skipped train sample 2985 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,527 - __main__ - WARNING -   Skipped train sample 2986 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,529 - __main__ - WARNING -   Skipped train sample 2987 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,531 - __main__ - WARNING -   Skipped train sample 2988 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,533 - __main__ - WARNING -   Skipped train sample 2989 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,535 - __main__ - WARNING -   Skipped train sample 2990 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,537 - __main__ - WARNING -   Skipped train sample 2991 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,539 - __main__ - WARNING -   Skipped train sample 2992 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,541 - __main__ - WARNING -   Skipped train sample 2993 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,543 - __main__ - WARNING -   Skipped train sample 2994 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,545 - __main__ - WARNING -   Skipped train sample 2995 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,547 - __main__ - WARNING -   Skipped train sample 2996 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,549 - __main__ - WARNING -   Skipped train sample 2997 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,551 - __main__ - WARNING -   Skipped train sample 2998 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,553 - __main__ - WARNING -   Skipped train sample 2999 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,553 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-21 22:09:40,557 - __main__ - WARNING -   Skipped train sample 3000 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,559 - __main__ - WARNING -   Skipped train sample 3001 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,561 - __main__ - WARNING -   Skipped train sample 3002 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,563 - __main__ - WARNING -   Skipped train sample 3003 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,565 - __main__ - WARNING -   Skipped train sample 3004 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,567 - __main__ - WARNING -   Skipped train sample 3005 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,569 - __main__ - WARNING -   Skipped train sample 3006 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,571 - __main__ - WARNING -   Skipped train sample 3007 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,573 - __main__ - WARNING -   Skipped train sample 3008 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,575 - __main__ - WARNING -   Skipped train sample 3009 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,577 - __main__ - WARNING -   Skipped train sample 3010 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,579 - __main__ - WARNING -   Skipped train sample 3011 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,581 - __main__ - WARNING -   Skipped train sample 3012 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,583 - __main__ - WARNING -   Skipped train sample 3013 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,585 - __main__ - WARNING -   Skipped train sample 3014 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,587 - __main__ - WARNING -   Skipped train sample 3015 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,589 - __main__ - WARNING -   Skipped train sample 3016 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,591 - __main__ - WARNING -   Skipped train sample 3017 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,593 - __main__ - WARNING -   Skipped train sample 3018 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,595 - __main__ - WARNING -   Skipped train sample 3019 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,596 - __main__ - WARNING -   Skipped train sample 3020 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,598 - __main__ - WARNING -   Skipped train sample 3021 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,600 - __main__ - WARNING -   Skipped train sample 3022 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,602 - __main__ - WARNING -   Skipped train sample 3023 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,604 - __main__ - WARNING -   Skipped train sample 3024 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,606 - __main__ - WARNING -   Skipped train sample 3025 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:40,608 - __main__ - WARNING -   Skipped train sample 3026 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,611 - __main__ - WARNING -   Skipped train sample 3027 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,612 - __main__ - WARNING -   Skipped train sample 3028 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,614 - __main__ - WARNING -   Skipped train sample 3029 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,616 - __main__ - WARNING -   Skipped train sample 3030 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,618 - __main__ - WARNING -   Skipped train sample 3031 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,620 - __main__ - WARNING -   Skipped train sample 3032 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,622 - __main__ - WARNING -   Skipped train sample 3033 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,624 - __main__ - WARNING -   Skipped train sample 3034 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,626 - __main__ - WARNING -   Skipped train sample 3035 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,628 - __main__ - WARNING -   Skipped train sample 3036 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,630 - __main__ - WARNING -   Skipped train sample 3037 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,631 - __main__ - WARNING -   Skipped train sample 3038 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,633 - __main__ - WARNING -   Skipped train sample 3039 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,635 - __main__ - WARNING -   Skipped train sample 3040 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,637 - __main__ - WARNING -   Skipped train sample 3041 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,639 - __main__ - WARNING -   Skipped train sample 3042 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,641 - __main__ - WARNING -   Skipped train sample 3043 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,643 - __main__ - WARNING -   Skipped train sample 3044 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:40,645 - __main__ - WARNING -   Skipped train sample 3045 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,647 - __main__ - WARNING -   Skipped train sample 3046 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,649 - __main__ - WARNING -   Skipped train sample 3047 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,651 - __main__ - WARNING -   Skipped train sample 3048 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,653 - __main__ - WARNING -   Skipped train sample 3049 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,654 - __main__ - WARNING -   Skipped train sample 3050 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,656 - __main__ - WARNING -   Skipped train sample 3051 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,658 - __main__ - WARNING -   Skipped train sample 3052 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,660 - __main__ - WARNING -   Skipped train sample 3053 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,662 - __main__ - WARNING -   Skipped train sample 3054 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,664 - __main__ - WARNING -   Skipped train sample 3055 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,666 - __main__ - WARNING -   Skipped train sample 3056 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,668 - __main__ - WARNING -   Skipped train sample 3057 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,670 - __main__ - WARNING -   Skipped train sample 3058 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,672 - __main__ - WARNING -   Skipped train sample 3059 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,674 - __main__ - WARNING -   Skipped train sample 3060 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,676 - __main__ - WARNING -   Skipped train sample 3061 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,678 - __main__ - WARNING -   Skipped train sample 3062 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,680 - __main__ - WARNING -   Skipped train sample 3063 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,682 - __main__ - WARNING -   Skipped train sample 3064 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,684 - __main__ - WARNING -   Skipped train sample 3065 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,685 - __main__ - WARNING -   Skipped train sample 3066 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,687 - __main__ - WARNING -   Skipped train sample 3067 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,690 - __main__ - WARNING -   Skipped train sample 3068 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,691 - __main__ - WARNING -   Skipped train sample 3069 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,693 - __main__ - WARNING -   Skipped train sample 3070 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,695 - __main__ - WARNING -   Skipped train sample 3071 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,697 - __main__ - WARNING -   Skipped train sample 3072 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,699 - __main__ - WARNING -   Skipped train sample 3073 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,701 - __main__ - WARNING -   Skipped train sample 3074 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,703 - __main__ - WARNING -   Skipped train sample 3075 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,705 - __main__ - WARNING -   Skipped train sample 3076 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,707 - __main__ - WARNING -   Skipped train sample 3077 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,709 - __main__ - WARNING -   Skipped train sample 3078 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,711 - __main__ - WARNING -   Skipped train sample 3079 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,712 - __main__ - WARNING -   Skipped train sample 3080 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,714 - __main__ - WARNING -   Skipped train sample 3081 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,716 - __main__ - WARNING -   Skipped train sample 3082 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,718 - __main__ - WARNING -   Skipped train sample 3083 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:40,720 - __main__ - WARNING -   Skipped train sample 3084 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,722 - __main__ - WARNING -   Skipped train sample 3085 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,724 - __main__ - WARNING -   Skipped train sample 3086 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,726 - __main__ - WARNING -   Skipped train sample 3087 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,728 - __main__ - WARNING -   Skipped train sample 3088 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,730 - __main__ - WARNING -   Skipped train sample 3089 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,732 - __main__ - WARNING -   Skipped train sample 3090 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,734 - __main__ - WARNING -   Skipped train sample 3091 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,736 - __main__ - WARNING -   Skipped train sample 3092 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,738 - __main__ - WARNING -   Skipped train sample 3093 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,740 - __main__ - WARNING -   Skipped train sample 3094 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,742 - __main__ - WARNING -   Skipped train sample 3095 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,744 - __main__ - WARNING -   Skipped train sample 3096 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,746 - __main__ - WARNING -   Skipped train sample 3097 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,748 - __main__ - WARNING -   Skipped train sample 3098 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,749 - __main__ - WARNING -   Skipped train sample 3099 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,752 - __main__ - WARNING -   Skipped train sample 3100 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,754 - __main__ - WARNING -   Skipped train sample 3101 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,756 - __main__ - WARNING -   Skipped train sample 3102 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,757 - __main__ - WARNING -   Skipped train sample 3103 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,759 - __main__ - WARNING -   Skipped train sample 3104 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,761 - __main__ - WARNING -   Skipped train sample 3105 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,763 - __main__ - WARNING -   Skipped train sample 3106 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,765 - __main__ - WARNING -   Skipped train sample 3107 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,767 - __main__ - WARNING -   Skipped train sample 3108 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,769 - __main__ - WARNING -   Skipped train sample 3109 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,771 - __main__ - WARNING -   Skipped train sample 3110 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,773 - __main__ - WARNING -   Skipped train sample 3111 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,775 - __main__ - WARNING -   Skipped train sample 3112 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,776 - __main__ - WARNING -   Skipped train sample 3113 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,779 - __main__ - WARNING -   Skipped train sample 3114 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,780 - __main__ - WARNING -   Skipped train sample 3115 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,782 - __main__ - WARNING -   Skipped train sample 3116 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,784 - __main__ - WARNING -   Skipped train sample 3117 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,786 - __main__ - WARNING -   Skipped train sample 3118 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,788 - __main__ - WARNING -   Skipped train sample 3119 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,790 - __main__ - WARNING -   Skipped train sample 3120 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,792 - __main__ - WARNING -   Skipped train sample 3121 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,794 - __main__ - WARNING -   Skipped train sample 3122 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,796 - __main__ - WARNING -   Skipped train sample 3123 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,798 - __main__ - WARNING -   Skipped train sample 3124 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,800 - __main__ - WARNING -   Skipped train sample 3125 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,802 - __main__ - WARNING -   Skipped train sample 3126 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,804 - __main__ - WARNING -   Skipped train sample 3127 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,805 - __main__ - WARNING -   Skipped train sample 3128 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,807 - __main__ - WARNING -   Skipped train sample 3129 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,809 - __main__ - WARNING -   Skipped train sample 3130 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,811 - __main__ - WARNING -   Skipped train sample 3131 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,813 - __main__ - WARNING -   Skipped train sample 3132 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,815 - __main__ - WARNING -   Skipped train sample 3133 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,817 - __main__ - WARNING -   Skipped train sample 3134 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,819 - __main__ - WARNING -   Skipped train sample 3135 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,821 - __main__ - WARNING -   Skipped train sample 3136 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,823 - __main__ - WARNING -   Skipped train sample 3137 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,825 - __main__ - WARNING -   Skipped train sample 3138 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,827 - __main__ - WARNING -   Skipped train sample 3139 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,829 - __main__ - WARNING -   Skipped train sample 3140 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,830 - __main__ - WARNING -   Skipped train sample 3141 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,832 - __main__ - WARNING -   Skipped train sample 3142 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,834 - __main__ - WARNING -   Skipped train sample 3143 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,836 - __main__ - WARNING -   Skipped train sample 3144 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,838 - __main__ - WARNING -   Skipped train sample 3145 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,840 - __main__ - WARNING -   Skipped train sample 3146 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,842 - __main__ - WARNING -   Skipped train sample 3147 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,844 - __main__ - WARNING -   Skipped train sample 3148 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,846 - __main__ - WARNING -   Skipped train sample 3149 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,848 - __main__ - WARNING -   Skipped train sample 3150 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,850 - __main__ - WARNING -   Skipped train sample 3151 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,852 - __main__ - WARNING -   Skipped train sample 3152 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,854 - __main__ - WARNING -   Skipped train sample 3153 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,856 - __main__ - WARNING -   Skipped train sample 3154 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,858 - __main__ - WARNING -   Skipped train sample 3155 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,860 - __main__ - WARNING -   Skipped train sample 3156 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,862 - __main__ - WARNING -   Skipped train sample 3157 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,864 - __main__ - WARNING -   Skipped train sample 3158 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,866 - __main__ - WARNING -   Skipped train sample 3159 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,867 - __main__ - WARNING -   Skipped train sample 3160 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,869 - __main__ - WARNING -   Skipped train sample 3161 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,871 - __main__ - WARNING -   Skipped train sample 3162 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,873 - __main__ - WARNING -   Skipped train sample 3163 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,875 - __main__ - WARNING -   Skipped train sample 3164 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,877 - __main__ - WARNING -   Skipped train sample 3165 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,879 - __main__ - WARNING -   Skipped train sample 3166 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,881 - __main__ - WARNING -   Skipped train sample 3167 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,883 - __main__ - WARNING -   Skipped train sample 3168 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,884 - __main__ - WARNING -   Skipped train sample 3169 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,886 - __main__ - WARNING -   Skipped train sample 3170 due to error: invalid literal for int() with base 10: 'signer_10'
2025-09-21 22:09:40,888 - __main__ - WARNING -   Skipped train sample 3171 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,890 - __main__ - WARNING -   Skipped train sample 3172 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,892 - __main__ - WARNING -   Skipped train sample 3173 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,894 - __main__ - WARNING -   Skipped train sample 3174 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,896 - __main__ - WARNING -   Skipped train sample 3175 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,898 - __main__ - WARNING -   Skipped train sample 3176 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,900 - __main__ - WARNING -   Skipped train sample 3177 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,902 - __main__ - WARNING -   Skipped train sample 3178 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,904 - __main__ - WARNING -   Skipped train sample 3179 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,906 - __main__ - WARNING -   Skipped train sample 3180 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,907 - __main__ - WARNING -   Skipped train sample 3181 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,909 - __main__ - WARNING -   Skipped train sample 3182 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,911 - __main__ - WARNING -   Skipped train sample 3183 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,913 - __main__ - WARNING -   Skipped train sample 3184 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,915 - __main__ - WARNING -   Skipped train sample 3185 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,917 - __main__ - WARNING -   Skipped train sample 3186 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,919 - __main__ - WARNING -   Skipped train sample 3187 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,921 - __main__ - WARNING -   Skipped train sample 3188 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,923 - __main__ - WARNING -   Skipped train sample 3189 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,925 - __main__ - WARNING -   Skipped train sample 3190 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,927 - __main__ - WARNING -   Skipped train sample 3191 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,929 - __main__ - WARNING -   Skipped train sample 3192 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,930 - __main__ - WARNING -   Skipped train sample 3193 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,932 - __main__ - WARNING -   Skipped train sample 3194 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,934 - __main__ - WARNING -   Skipped train sample 3195 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,936 - __main__ - WARNING -   Skipped train sample 3196 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,938 - __main__ - WARNING -   Skipped train sample 3197 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,940 - __main__ - WARNING -   Skipped train sample 3198 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,942 - __main__ - WARNING -   Skipped train sample 3199 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,944 - __main__ - WARNING -   Skipped train sample 3200 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,946 - __main__ - WARNING -   Skipped train sample 3201 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,948 - __main__ - WARNING -   Skipped train sample 3202 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,950 - __main__ - WARNING -   Skipped train sample 3203 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,952 - __main__ - WARNING -   Skipped train sample 3204 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,954 - __main__ - WARNING -   Skipped train sample 3205 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,955 - __main__ - WARNING -   Skipped train sample 3206 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,958 - __main__ - WARNING -   Skipped train sample 3207 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,959 - __main__ - WARNING -   Skipped train sample 3208 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,961 - __main__ - WARNING -   Skipped train sample 3209 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,963 - __main__ - WARNING -   Skipped train sample 3210 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,965 - __main__ - WARNING -   Skipped train sample 3211 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,967 - __main__ - WARNING -   Skipped train sample 3212 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,969 - __main__ - WARNING -   Skipped train sample 3213 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,971 - __main__ - WARNING -   Skipped train sample 3214 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,973 - __main__ - WARNING -   Skipped train sample 3215 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,975 - __main__ - WARNING -   Skipped train sample 3216 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,976 - __main__ - WARNING -   Skipped train sample 3217 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,978 - __main__ - WARNING -   Skipped train sample 3218 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,980 - __main__ - WARNING -   Skipped train sample 3219 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,982 - __main__ - WARNING -   Skipped train sample 3220 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,984 - __main__ - WARNING -   Skipped train sample 3221 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,986 - __main__ - WARNING -   Skipped train sample 3222 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:40,988 - __main__ - WARNING -   Skipped train sample 3223 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,990 - __main__ - WARNING -   Skipped train sample 3224 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,992 - __main__ - WARNING -   Skipped train sample 3225 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:40,994 - __main__ - WARNING -   Skipped train sample 3226 due to error: cannot convert float NaN to integer
2025-09-21 22:09:40,996 - __main__ - WARNING -   Skipped train sample 3227 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:40,998 - __main__ - WARNING -   Skipped train sample 3228 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,000 - __main__ - WARNING -   Skipped train sample 3229 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,002 - __main__ - WARNING -   Skipped train sample 3230 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,004 - __main__ - WARNING -   Skipped train sample 3231 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,006 - __main__ - WARNING -   Skipped train sample 3232 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,008 - __main__ - WARNING -   Skipped train sample 3233 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,010 - __main__ - WARNING -   Skipped train sample 3234 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,012 - __main__ - WARNING -   Skipped train sample 3235 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,014 - __main__ - WARNING -   Skipped train sample 3236 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,015 - __main__ - WARNING -   Skipped train sample 3237 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,017 - __main__ - WARNING -   Skipped train sample 3238 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,019 - __main__ - WARNING -   Skipped train sample 3239 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,021 - __main__ - WARNING -   Skipped train sample 3240 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,023 - __main__ - WARNING -   Skipped train sample 3241 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,025 - __main__ - WARNING -   Skipped train sample 3242 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,027 - __main__ - WARNING -   Skipped train sample 3243 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,029 - __main__ - WARNING -   Skipped train sample 3244 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,031 - __main__ - WARNING -   Skipped train sample 3245 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,032 - __main__ - WARNING -   Skipped train sample 3246 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,034 - __main__ - WARNING -   Skipped train sample 3247 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,036 - __main__ - WARNING -   Skipped train sample 3248 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,038 - __main__ - WARNING -   Skipped train sample 3249 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,040 - __main__ - WARNING -   Skipped train sample 3250 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,042 - __main__ - WARNING -   Skipped train sample 3251 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,044 - __main__ - WARNING -   Skipped train sample 3252 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,046 - __main__ - WARNING -   Skipped train sample 3253 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,048 - __main__ - WARNING -   Skipped train sample 3254 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,050 - __main__ - WARNING -   Skipped train sample 3255 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,052 - __main__ - WARNING -   Skipped train sample 3256 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,054 - __main__ - WARNING -   Skipped train sample 3257 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,056 - __main__ - WARNING -   Skipped train sample 3258 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,058 - __main__ - WARNING -   Skipped train sample 3259 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,060 - __main__ - WARNING -   Skipped train sample 3260 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,062 - __main__ - WARNING -   Skipped train sample 3261 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,064 - __main__ - WARNING -   Skipped train sample 3262 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,066 - __main__ - WARNING -   Skipped train sample 3263 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,068 - __main__ - WARNING -   Skipped train sample 3264 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,070 - __main__ - WARNING -   Skipped train sample 3265 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,072 - __main__ - WARNING -   Skipped train sample 3266 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,074 - __main__ - WARNING -   Skipped train sample 3267 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,075 - __main__ - WARNING -   Skipped train sample 3268 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,077 - __main__ - WARNING -   Skipped train sample 3269 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,079 - __main__ - WARNING -   Skipped train sample 3270 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,081 - __main__ - WARNING -   Skipped train sample 3271 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,083 - __main__ - WARNING -   Skipped train sample 3272 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,084 - __main__ - WARNING -   Skipped train sample 3273 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,087 - __main__ - WARNING -   Skipped train sample 3274 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,089 - __main__ - WARNING -   Skipped train sample 3275 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,091 - __main__ - WARNING -   Skipped train sample 3276 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,092 - __main__ - WARNING -   Skipped train sample 3277 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,095 - __main__ - WARNING -   Skipped train sample 3278 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,097 - __main__ - WARNING -   Skipped train sample 3279 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,099 - __main__ - WARNING -   Skipped train sample 3280 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,101 - __main__ - WARNING -   Skipped train sample 3281 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,103 - __main__ - WARNING -   Skipped train sample 3282 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,105 - __main__ - WARNING -   Skipped train sample 3283 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,107 - __main__ - WARNING -   Skipped train sample 3284 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,109 - __main__ - WARNING -   Skipped train sample 3285 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,111 - __main__ - WARNING -   Skipped train sample 3286 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,113 - __main__ - WARNING -   Skipped train sample 3287 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,115 - __main__ - WARNING -   Skipped train sample 3288 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,116 - __main__ - WARNING -   Skipped train sample 3289 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,118 - __main__ - WARNING -   Skipped train sample 3290 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,120 - __main__ - WARNING -   Skipped train sample 3291 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,122 - __main__ - WARNING -   Skipped train sample 3292 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,124 - __main__ - WARNING -   Skipped train sample 3293 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,126 - __main__ - WARNING -   Skipped train sample 3294 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,128 - __main__ - WARNING -   Skipped train sample 3295 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,130 - __main__ - WARNING -   Skipped train sample 3296 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,132 - __main__ - WARNING -   Skipped train sample 3297 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,134 - __main__ - WARNING -   Skipped train sample 3298 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,135 - __main__ - WARNING -   Skipped train sample 3299 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,137 - __main__ - WARNING -   Skipped train sample 3300 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,139 - __main__ - WARNING -   Skipped train sample 3301 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,141 - __main__ - WARNING -   Skipped train sample 3302 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,143 - __main__ - WARNING -   Skipped train sample 3303 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,145 - __main__ - WARNING -   Skipped train sample 3304 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,147 - __main__ - WARNING -   Skipped train sample 3305 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,149 - __main__ - WARNING -   Skipped train sample 3306 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,151 - __main__ - WARNING -   Skipped train sample 3307 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,153 - __main__ - WARNING -   Skipped train sample 3308 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,155 - __main__ - WARNING -   Skipped train sample 3309 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,157 - __main__ - WARNING -   Skipped train sample 3310 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,159 - __main__ - WARNING -   Skipped train sample 3311 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,161 - __main__ - WARNING -   Skipped train sample 3312 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,163 - __main__ - WARNING -   Skipped train sample 3313 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,165 - __main__ - WARNING -   Skipped train sample 3314 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,167 - __main__ - WARNING -   Skipped train sample 3315 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,169 - __main__ - WARNING -   Skipped train sample 3316 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,172 - __main__ - WARNING -   Skipped train sample 3317 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,174 - __main__ - WARNING -   Skipped train sample 3318 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,175 - __main__ - WARNING -   Skipped train sample 3319 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,178 - __main__ - WARNING -   Skipped train sample 3320 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,179 - __main__ - WARNING -   Skipped train sample 3321 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,181 - __main__ - WARNING -   Skipped train sample 3322 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,183 - __main__ - WARNING -   Skipped train sample 3323 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,185 - __main__ - WARNING -   Skipped train sample 3324 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,187 - __main__ - WARNING -   Skipped train sample 3325 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,189 - __main__ - WARNING -   Skipped train sample 3326 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,191 - __main__ - WARNING -   Skipped train sample 3327 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,193 - __main__ - WARNING -   Skipped train sample 3328 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,195 - __main__ - WARNING -   Skipped train sample 3329 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,197 - __main__ - WARNING -   Skipped train sample 3330 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,199 - __main__ - WARNING -   Skipped train sample 3331 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,201 - __main__ - WARNING -   Skipped train sample 3332 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,203 - __main__ - WARNING -   Skipped train sample 3333 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,204 - __main__ - WARNING -   Skipped train sample 3334 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,207 - __main__ - WARNING -   Skipped train sample 3335 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,208 - __main__ - WARNING -   Skipped train sample 3336 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,210 - __main__ - WARNING -   Skipped train sample 3337 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,212 - __main__ - WARNING -   Skipped train sample 3338 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,214 - __main__ - WARNING -   Skipped train sample 3339 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,216 - __main__ - WARNING -   Skipped train sample 3340 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,218 - __main__ - WARNING -   Skipped train sample 3341 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,220 - __main__ - WARNING -   Skipped train sample 3342 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,222 - __main__ - WARNING -   Skipped train sample 3343 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,224 - __main__ - WARNING -   Skipped train sample 3344 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,226 - __main__ - WARNING -   Skipped train sample 3345 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,228 - __main__ - WARNING -   Skipped train sample 3346 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,230 - __main__ - WARNING -   Skipped train sample 3347 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,232 - __main__ - WARNING -   Skipped train sample 3348 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,233 - __main__ - WARNING -   Skipped train sample 3349 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,236 - __main__ - WARNING -   Skipped train sample 3350 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,238 - __main__ - WARNING -   Skipped train sample 3351 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,240 - __main__ - WARNING -   Skipped train sample 3352 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,242 - __main__ - WARNING -   Skipped train sample 3353 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,243 - __main__ - WARNING -   Skipped train sample 3354 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,245 - __main__ - WARNING -   Skipped train sample 3355 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,247 - __main__ - WARNING -   Skipped train sample 3356 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,249 - __main__ - WARNING -   Skipped train sample 3357 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,251 - __main__ - WARNING -   Skipped train sample 3358 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:41,253 - __main__ - WARNING -   Skipped train sample 3359 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,255 - __main__ - WARNING -   Skipped train sample 3360 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,257 - __main__ - WARNING -   Skipped train sample 3361 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,259 - __main__ - WARNING -   Skipped train sample 3362 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,261 - __main__ - WARNING -   Skipped train sample 3363 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,263 - __main__ - WARNING -   Skipped train sample 3364 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,264 - __main__ - WARNING -   Skipped train sample 3365 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,266 - __main__ - WARNING -   Skipped train sample 3366 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,268 - __main__ - WARNING -   Skipped train sample 3367 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,270 - __main__ - WARNING -   Skipped train sample 3368 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,272 - __main__ - WARNING -   Skipped train sample 3369 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,274 - __main__ - WARNING -   Skipped train sample 3370 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,276 - __main__ - WARNING -   Skipped train sample 3371 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,278 - __main__ - WARNING -   Skipped train sample 3372 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,280 - __main__ - WARNING -   Skipped train sample 3373 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,282 - __main__ - WARNING -   Skipped train sample 3374 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,284 - __main__ - WARNING -   Skipped train sample 3375 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,285 - __main__ - WARNING -   Skipped train sample 3376 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,287 - __main__ - WARNING -   Skipped train sample 3377 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,289 - __main__ - WARNING -   Skipped train sample 3378 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,291 - __main__ - WARNING -   Skipped train sample 3379 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,293 - __main__ - WARNING -   Skipped train sample 3380 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,295 - __main__ - WARNING -   Skipped train sample 3381 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,297 - __main__ - WARNING -   Skipped train sample 3382 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,299 - __main__ - WARNING -   Skipped train sample 3383 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,301 - __main__ - WARNING -   Skipped train sample 3384 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,303 - __main__ - WARNING -   Skipped train sample 3385 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:41,305 - __main__ - WARNING -   Skipped train sample 3386 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,307 - __main__ - WARNING -   Skipped train sample 3387 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,309 - __main__ - WARNING -   Skipped train sample 3388 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,310 - __main__ - WARNING -   Skipped train sample 3389 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,312 - __main__ - WARNING -   Skipped train sample 3390 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,314 - __main__ - WARNING -   Skipped train sample 3391 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,316 - __main__ - WARNING -   Skipped train sample 3392 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,318 - __main__ - WARNING -   Skipped train sample 3393 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,320 - __main__ - WARNING -   Skipped train sample 3394 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,322 - __main__ - WARNING -   Skipped train sample 3395 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,324 - __main__ - WARNING -   Skipped train sample 3396 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,326 - __main__ - WARNING -   Skipped train sample 3397 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,328 - __main__ - WARNING -   Skipped train sample 3398 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,330 - __main__ - WARNING -   Skipped train sample 3399 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,332 - __main__ - WARNING -   Skipped train sample 3400 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,334 - __main__ - WARNING -   Skipped train sample 3401 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,336 - __main__ - WARNING -   Skipped train sample 3402 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,338 - __main__ - WARNING -   Skipped train sample 3403 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,340 - __main__ - WARNING -   Skipped train sample 3404 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,342 - __main__ - WARNING -   Skipped train sample 3405 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,344 - __main__ - WARNING -   Skipped train sample 3406 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,346 - __main__ - WARNING -   Skipped train sample 3407 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,348 - __main__ - WARNING -   Skipped train sample 3408 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,350 - __main__ - WARNING -   Skipped train sample 3409 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,351 - __main__ - WARNING -   Skipped train sample 3410 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,353 - __main__ - WARNING -   Skipped train sample 3411 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,355 - __main__ - WARNING -   Skipped train sample 3412 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:41,357 - __main__ - WARNING -   Skipped train sample 3413 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,359 - __main__ - WARNING -   Skipped train sample 3414 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,360 - __main__ - WARNING -   Skipped train sample 3415 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,362 - __main__ - WARNING -   Skipped train sample 3416 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,364 - __main__ - WARNING -   Skipped train sample 3417 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,366 - __main__ - WARNING -   Skipped train sample 3418 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,368 - __main__ - WARNING -   Skipped train sample 3419 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,370 - __main__ - WARNING -   Skipped train sample 3420 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,372 - __main__ - WARNING -   Skipped train sample 3421 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,374 - __main__ - WARNING -   Skipped train sample 3422 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,376 - __main__ - WARNING -   Skipped train sample 3423 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,378 - __main__ - WARNING -   Skipped train sample 3424 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,380 - __main__ - WARNING -   Skipped train sample 3425 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,382 - __main__ - WARNING -   Skipped train sample 3426 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,384 - __main__ - WARNING -   Skipped train sample 3427 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,386 - __main__ - WARNING -   Skipped train sample 3428 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,387 - __main__ - WARNING -   Skipped train sample 3429 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,389 - __main__ - WARNING -   Skipped train sample 3430 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,391 - __main__ - WARNING -   Skipped train sample 3431 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,393 - __main__ - WARNING -   Skipped train sample 3432 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,395 - __main__ - WARNING -   Skipped train sample 3433 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,397 - __main__ - WARNING -   Skipped train sample 3434 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,399 - __main__ - WARNING -   Skipped train sample 3435 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,401 - __main__ - WARNING -   Skipped train sample 3436 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,403 - __main__ - WARNING -   Skipped train sample 3437 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,405 - __main__ - WARNING -   Skipped train sample 3438 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,407 - __main__ - WARNING -   Skipped train sample 3439 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,408 - __main__ - WARNING -   Skipped train sample 3440 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,410 - __main__ - WARNING -   Skipped train sample 3441 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,412 - __main__ - WARNING -   Skipped train sample 3442 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,414 - __main__ - WARNING -   Skipped train sample 3443 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,416 - __main__ - WARNING -   Skipped train sample 3444 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,418 - __main__ - WARNING -   Skipped train sample 3445 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,420 - __main__ - WARNING -   Skipped train sample 3446 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,422 - __main__ - WARNING -   Skipped train sample 3447 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,424 - __main__ - WARNING -   Skipped train sample 3448 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,426 - __main__ - WARNING -   Skipped train sample 3449 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,427 - __main__ - WARNING -   Skipped train sample 3450 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,429 - __main__ - WARNING -   Skipped train sample 3451 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,431 - __main__ - WARNING -   Skipped train sample 3452 due to error: invalid literal for int() with base 10: 'signer_4'
2025-09-21 22:09:41,433 - __main__ - WARNING -   Skipped train sample 3453 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,435 - __main__ - WARNING -   Skipped train sample 3454 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,437 - __main__ - WARNING -   Skipped train sample 3455 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,439 - __main__ - WARNING -   Skipped train sample 3456 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,441 - __main__ - WARNING -   Skipped train sample 3457 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,443 - __main__ - WARNING -   Skipped train sample 3458 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,445 - __main__ - WARNING -   Skipped train sample 3459 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,447 - __main__ - WARNING -   Skipped train sample 3460 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,449 - __main__ - WARNING -   Skipped train sample 3461 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,451 - __main__ - WARNING -   Skipped train sample 3462 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,453 - __main__ - WARNING -   Skipped train sample 3463 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,455 - __main__ - WARNING -   Skipped train sample 3464 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,457 - __main__ - WARNING -   Skipped train sample 3465 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,459 - __main__ - WARNING -   Skipped train sample 3466 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,461 - __main__ - WARNING -   Skipped train sample 3467 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,463 - __main__ - WARNING -   Skipped train sample 3468 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,465 - __main__ - WARNING -   Skipped train sample 3469 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,467 - __main__ - WARNING -   Skipped train sample 3470 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,469 - __main__ - WARNING -   Skipped train sample 3471 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,471 - __main__ - WARNING -   Skipped train sample 3472 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,472 - __main__ - WARNING -   Skipped train sample 3473 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,475 - __main__ - WARNING -   Skipped train sample 3474 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,477 - __main__ - WARNING -   Skipped train sample 3475 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,479 - __main__ - WARNING -   Skipped train sample 3476 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,481 - __main__ - WARNING -   Skipped train sample 3477 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,483 - __main__ - WARNING -   Skipped train sample 3478 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,485 - __main__ - WARNING -   Skipped train sample 3479 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,487 - __main__ - WARNING -   Skipped train sample 3480 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,488 - __main__ - WARNING -   Skipped train sample 3481 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,490 - __main__ - WARNING -   Skipped train sample 3482 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,492 - __main__ - WARNING -   Skipped train sample 3483 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,494 - __main__ - WARNING -   Skipped train sample 3484 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,496 - __main__ - WARNING -   Skipped train sample 3485 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,498 - __main__ - WARNING -   Skipped train sample 3486 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,500 - __main__ - WARNING -   Skipped train sample 3487 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,502 - __main__ - WARNING -   Skipped train sample 3488 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,504 - __main__ - WARNING -   Skipped train sample 3489 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,506 - __main__ - WARNING -   Skipped train sample 3490 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,508 - __main__ - WARNING -   Skipped train sample 3491 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,510 - __main__ - WARNING -   Skipped train sample 3492 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,512 - __main__ - WARNING -   Skipped train sample 3493 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,514 - __main__ - WARNING -   Skipped train sample 3494 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,516 - __main__ - WARNING -   Skipped train sample 3495 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,518 - __main__ - WARNING -   Skipped train sample 3496 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,520 - __main__ - WARNING -   Skipped train sample 3497 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,522 - __main__ - WARNING -   Skipped train sample 3498 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,524 - __main__ - WARNING -   Skipped train sample 3499 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:41,525 - __main__ - WARNING -   Skipped train sample 3500 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,527 - __main__ - WARNING -   Skipped train sample 3501 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,529 - __main__ - WARNING -   Skipped train sample 3502 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,531 - __main__ - WARNING -   Skipped train sample 3503 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,533 - __main__ - WARNING -   Skipped train sample 3504 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,535 - __main__ - WARNING -   Skipped train sample 3505 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,537 - __main__ - WARNING -   Skipped train sample 3506 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,539 - __main__ - WARNING -   Skipped train sample 3507 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,541 - __main__ - WARNING -   Skipped train sample 3508 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,543 - __main__ - WARNING -   Skipped train sample 3509 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,545 - __main__ - WARNING -   Skipped train sample 3510 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,547 - __main__ - WARNING -   Skipped train sample 3511 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,548 - __main__ - WARNING -   Skipped train sample 3512 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,550 - __main__ - WARNING -   Skipped train sample 3513 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,552 - __main__ - WARNING -   Skipped train sample 3514 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,554 - __main__ - WARNING -   Skipped train sample 3515 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,556 - __main__ - WARNING -   Skipped train sample 3516 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,558 - __main__ - WARNING -   Skipped train sample 3517 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,561 - __main__ - WARNING -   Skipped train sample 3518 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,562 - __main__ - WARNING -   Skipped train sample 3519 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,564 - __main__ - WARNING -   Skipped train sample 3520 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,566 - __main__ - WARNING -   Skipped train sample 3521 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,568 - __main__ - WARNING -   Skipped train sample 3522 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,570 - __main__ - WARNING -   Skipped train sample 3523 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,572 - __main__ - WARNING -   Skipped train sample 3524 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,574 - __main__ - WARNING -   Skipped train sample 3525 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,576 - __main__ - WARNING -   Skipped train sample 3526 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,578 - __main__ - WARNING -   Skipped train sample 3527 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,580 - __main__ - WARNING -   Skipped train sample 3528 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,582 - __main__ - WARNING -   Skipped train sample 3529 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,583 - __main__ - WARNING -   Skipped train sample 3530 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,585 - __main__ - WARNING -   Skipped train sample 3531 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:41,587 - __main__ - WARNING -   Skipped train sample 3532 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,589 - __main__ - WARNING -   Skipped train sample 3533 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,591 - __main__ - WARNING -   Skipped train sample 3534 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,593 - __main__ - WARNING -   Skipped train sample 3535 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,595 - __main__ - WARNING -   Skipped train sample 3536 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,597 - __main__ - WARNING -   Skipped train sample 3537 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,599 - __main__ - WARNING -   Skipped train sample 3538 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,601 - __main__ - WARNING -   Skipped train sample 3539 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,603 - __main__ - WARNING -   Skipped train sample 3540 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,605 - __main__ - WARNING -   Skipped train sample 3541 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,607 - __main__ - WARNING -   Skipped train sample 3542 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,609 - __main__ - WARNING -   Skipped train sample 3543 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,611 - __main__ - WARNING -   Skipped train sample 3544 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,613 - __main__ - WARNING -   Skipped train sample 3545 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,615 - __main__ - WARNING -   Skipped train sample 3546 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,616 - __main__ - WARNING -   Skipped train sample 3547 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,618 - __main__ - WARNING -   Skipped train sample 3548 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,620 - __main__ - WARNING -   Skipped train sample 3549 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,622 - __main__ - WARNING -   Skipped train sample 3550 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,624 - __main__ - WARNING -   Skipped train sample 3551 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,626 - __main__ - WARNING -   Skipped train sample 3552 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,628 - __main__ - WARNING -   Skipped train sample 3553 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,630 - __main__ - WARNING -   Skipped train sample 3554 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,632 - __main__ - WARNING -   Skipped train sample 3555 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,634 - __main__ - WARNING -   Skipped train sample 3556 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,636 - __main__ - WARNING -   Skipped train sample 3557 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,638 - __main__ - WARNING -   Skipped train sample 3558 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,640 - __main__ - WARNING -   Skipped train sample 3559 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,642 - __main__ - WARNING -   Skipped train sample 3560 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,644 - __main__ - WARNING -   Skipped train sample 3561 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,646 - __main__ - WARNING -   Skipped train sample 3562 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,648 - __main__ - WARNING -   Skipped train sample 3563 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,649 - __main__ - WARNING -   Skipped train sample 3564 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,651 - __main__ - WARNING -   Skipped train sample 3565 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,653 - __main__ - WARNING -   Skipped train sample 3566 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,655 - __main__ - WARNING -   Skipped train sample 3567 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,657 - __main__ - WARNING -   Skipped train sample 3568 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,659 - __main__ - WARNING -   Skipped train sample 3569 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,661 - __main__ - WARNING -   Skipped train sample 3570 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,663 - __main__ - WARNING -   Skipped train sample 3571 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,665 - __main__ - WARNING -   Skipped train sample 3572 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,667 - __main__ - WARNING -   Skipped train sample 3573 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,669 - __main__ - WARNING -   Skipped train sample 3574 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,671 - __main__ - WARNING -   Skipped train sample 3575 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,673 - __main__ - WARNING -   Skipped train sample 3576 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,675 - __main__ - WARNING -   Skipped train sample 3577 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,677 - __main__ - WARNING -   Skipped train sample 3578 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,679 - __main__ - WARNING -   Skipped train sample 3579 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,681 - __main__ - WARNING -   Skipped train sample 3580 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,683 - __main__ - WARNING -   Skipped train sample 3581 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,685 - __main__ - WARNING -   Skipped train sample 3582 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,687 - __main__ - WARNING -   Skipped train sample 3583 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,689 - __main__ - WARNING -   Skipped train sample 3584 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,691 - __main__ - WARNING -   Skipped train sample 3585 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,693 - __main__ - WARNING -   Skipped train sample 3586 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,694 - __main__ - WARNING -   Skipped train sample 3587 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,696 - __main__ - WARNING -   Skipped train sample 3588 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,698 - __main__ - WARNING -   Skipped train sample 3589 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,700 - __main__ - WARNING -   Skipped train sample 3590 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,702 - __main__ - WARNING -   Skipped train sample 3591 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,704 - __main__ - WARNING -   Skipped train sample 3592 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,706 - __main__ - WARNING -   Skipped train sample 3593 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,708 - __main__ - WARNING -   Skipped train sample 3594 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,710 - __main__ - WARNING -   Skipped train sample 3595 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,712 - __main__ - WARNING -   Skipped train sample 3596 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,714 - __main__ - WARNING -   Skipped train sample 3597 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,716 - __main__ - WARNING -   Skipped train sample 3598 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,718 - __main__ - WARNING -   Skipped train sample 3599 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,720 - __main__ - WARNING -   Skipped train sample 3600 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:41,722 - __main__ - WARNING -   Skipped train sample 3601 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,724 - __main__ - WARNING -   Skipped train sample 3602 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,726 - __main__ - WARNING -   Skipped train sample 3603 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,728 - __main__ - WARNING -   Skipped train sample 3604 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,729 - __main__ - WARNING -   Skipped train sample 3605 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,731 - __main__ - WARNING -   Skipped train sample 3606 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,733 - __main__ - WARNING -   Skipped train sample 3607 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,735 - __main__ - WARNING -   Skipped train sample 3608 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,737 - __main__ - WARNING -   Skipped train sample 3609 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,739 - __main__ - WARNING -   Skipped train sample 3610 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,741 - __main__ - WARNING -   Skipped train sample 3611 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,743 - __main__ - WARNING -   Skipped train sample 3612 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,745 - __main__ - WARNING -   Skipped train sample 3613 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,747 - __main__ - WARNING -   Skipped train sample 3614 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,749 - __main__ - WARNING -   Skipped train sample 3615 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,751 - __main__ - WARNING -   Skipped train sample 3616 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,753 - __main__ - WARNING -   Skipped train sample 3617 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,755 - __main__ - WARNING -   Skipped train sample 3618 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,757 - __main__ - WARNING -   Skipped train sample 3619 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,759 - __main__ - WARNING -   Skipped train sample 3620 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,761 - __main__ - WARNING -   Skipped train sample 3621 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,763 - __main__ - WARNING -   Skipped train sample 3622 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,764 - __main__ - WARNING -   Skipped train sample 3623 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,767 - __main__ - WARNING -   Skipped train sample 3624 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,769 - __main__ - WARNING -   Skipped train sample 3625 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,771 - __main__ - WARNING -   Skipped train sample 3626 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,773 - __main__ - WARNING -   Skipped train sample 3627 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,775 - __main__ - WARNING -   Skipped train sample 3628 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,777 - __main__ - WARNING -   Skipped train sample 3629 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,779 - __main__ - WARNING -   Skipped train sample 3630 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,781 - __main__ - WARNING -   Skipped train sample 3631 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,783 - __main__ - WARNING -   Skipped train sample 3632 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,785 - __main__ - WARNING -   Skipped train sample 3633 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,787 - __main__ - WARNING -   Skipped train sample 3634 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,789 - __main__ - WARNING -   Skipped train sample 3635 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,791 - __main__ - WARNING -   Skipped train sample 3636 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,793 - __main__ - WARNING -   Skipped train sample 3637 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,795 - __main__ - WARNING -   Skipped train sample 3638 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,797 - __main__ - WARNING -   Skipped train sample 3639 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,799 - __main__ - WARNING -   Skipped train sample 3640 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,800 - __main__ - WARNING -   Skipped train sample 3641 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,802 - __main__ - WARNING -   Skipped train sample 3642 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,804 - __main__ - WARNING -   Skipped train sample 3643 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,806 - __main__ - WARNING -   Skipped train sample 3644 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,808 - __main__ - WARNING -   Skipped train sample 3645 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,810 - __main__ - WARNING -   Skipped train sample 3646 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,812 - __main__ - WARNING -   Skipped train sample 3647 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,814 - __main__ - WARNING -   Skipped train sample 3648 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,816 - __main__ - WARNING -   Skipped train sample 3649 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,818 - __main__ - WARNING -   Skipped train sample 3650 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,820 - __main__ - WARNING -   Skipped train sample 3651 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,822 - __main__ - WARNING -   Skipped train sample 3652 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,823 - __main__ - WARNING -   Skipped train sample 3653 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,825 - __main__ - WARNING -   Skipped train sample 3654 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,827 - __main__ - WARNING -   Skipped train sample 3655 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,829 - __main__ - WARNING -   Skipped train sample 3656 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,831 - __main__ - WARNING -   Skipped train sample 3657 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,833 - __main__ - WARNING -   Skipped train sample 3658 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,835 - __main__ - WARNING -   Skipped train sample 3659 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,837 - __main__ - WARNING -   Skipped train sample 3660 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,839 - __main__ - WARNING -   Skipped train sample 3661 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,841 - __main__ - WARNING -   Skipped train sample 3662 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,843 - __main__ - WARNING -   Skipped train sample 3663 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,845 - __main__ - WARNING -   Skipped train sample 3664 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,847 - __main__ - WARNING -   Skipped train sample 3665 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,849 - __main__ - WARNING -   Skipped train sample 3666 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,851 - __main__ - WARNING -   Skipped train sample 3667 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,853 - __main__ - WARNING -   Skipped train sample 3668 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,854 - __main__ - WARNING -   Skipped train sample 3669 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,856 - __main__ - WARNING -   Skipped train sample 3670 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,859 - __main__ - WARNING -   Skipped train sample 3671 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,860 - __main__ - WARNING -   Skipped train sample 3672 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,862 - __main__ - WARNING -   Skipped train sample 3673 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,864 - __main__ - WARNING -   Skipped train sample 3674 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,866 - __main__ - WARNING -   Skipped train sample 3675 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,868 - __main__ - WARNING -   Skipped train sample 3676 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,870 - __main__ - WARNING -   Skipped train sample 3677 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,872 - __main__ - WARNING -   Skipped train sample 3678 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,874 - __main__ - WARNING -   Skipped train sample 3679 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,876 - __main__ - WARNING -   Skipped train sample 3680 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,878 - __main__ - WARNING -   Skipped train sample 3681 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,880 - __main__ - WARNING -   Skipped train sample 3682 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,882 - __main__ - WARNING -   Skipped train sample 3683 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,884 - __main__ - WARNING -   Skipped train sample 3684 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,886 - __main__ - WARNING -   Skipped train sample 3685 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,888 - __main__ - WARNING -   Skipped train sample 3686 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,890 - __main__ - WARNING -   Skipped train sample 3687 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,892 - __main__ - WARNING -   Skipped train sample 3688 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,893 - __main__ - WARNING -   Skipped train sample 3689 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,895 - __main__ - WARNING -   Skipped train sample 3690 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,897 - __main__ - WARNING -   Skipped train sample 3691 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,899 - __main__ - WARNING -   Skipped train sample 3692 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,901 - __main__ - WARNING -   Skipped train sample 3693 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,903 - __main__ - WARNING -   Skipped train sample 3694 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,904 - __main__ - WARNING -   Skipped train sample 3695 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,906 - __main__ - WARNING -   Skipped train sample 3696 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,908 - __main__ - WARNING -   Skipped train sample 3697 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,910 - __main__ - WARNING -   Skipped train sample 3698 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,912 - __main__ - WARNING -   Skipped train sample 3699 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,914 - __main__ - WARNING -   Skipped train sample 3700 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,916 - __main__ - WARNING -   Skipped train sample 3701 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,918 - __main__ - WARNING -   Skipped train sample 3702 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,920 - __main__ - WARNING -   Skipped train sample 3703 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,922 - __main__ - WARNING -   Skipped train sample 3704 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,924 - __main__ - WARNING -   Skipped train sample 3705 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,926 - __main__ - WARNING -   Skipped train sample 3706 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,928 - __main__ - WARNING -   Skipped train sample 3707 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,930 - __main__ - WARNING -   Skipped train sample 3708 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,932 - __main__ - WARNING -   Skipped train sample 3709 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,934 - __main__ - WARNING -   Skipped train sample 3710 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,936 - __main__ - WARNING -   Skipped train sample 3711 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,939 - __main__ - WARNING -   Skipped train sample 3712 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,940 - __main__ - WARNING -   Skipped train sample 3713 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,942 - __main__ - WARNING -   Skipped train sample 3714 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,944 - __main__ - WARNING -   Skipped train sample 3715 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,946 - __main__ - WARNING -   Skipped train sample 3716 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,948 - __main__ - WARNING -   Skipped train sample 3717 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,950 - __main__ - WARNING -   Skipped train sample 3718 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,952 - __main__ - WARNING -   Skipped train sample 3719 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,954 - __main__ - WARNING -   Skipped train sample 3720 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,956 - __main__ - WARNING -   Skipped train sample 3721 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,958 - __main__ - WARNING -   Skipped train sample 3722 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,960 - __main__ - WARNING -   Skipped train sample 3723 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,962 - __main__ - WARNING -   Skipped train sample 3724 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,964 - __main__ - WARNING -   Skipped train sample 3725 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,966 - __main__ - WARNING -   Skipped train sample 3726 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,967 - __main__ - WARNING -   Skipped train sample 3727 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,970 - __main__ - WARNING -   Skipped train sample 3728 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,971 - __main__ - WARNING -   Skipped train sample 3729 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,973 - __main__ - WARNING -   Skipped train sample 3730 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,975 - __main__ - WARNING -   Skipped train sample 3731 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,977 - __main__ - WARNING -   Skipped train sample 3732 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,979 - __main__ - WARNING -   Skipped train sample 3733 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,981 - __main__ - WARNING -   Skipped train sample 3734 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,983 - __main__ - WARNING -   Skipped train sample 3735 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,985 - __main__ - WARNING -   Skipped train sample 3736 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,987 - __main__ - WARNING -   Skipped train sample 3737 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,988 - __main__ - WARNING -   Skipped train sample 3738 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,990 - __main__ - WARNING -   Skipped train sample 3739 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,992 - __main__ - WARNING -   Skipped train sample 3740 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:41,994 - __main__ - WARNING -   Skipped train sample 3741 due to error: cannot convert float NaN to integer
2025-09-21 22:09:41,996 - __main__ - WARNING -   Skipped train sample 3742 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:41,998 - __main__ - WARNING -   Skipped train sample 3743 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,000 - __main__ - WARNING -   Skipped train sample 3744 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,002 - __main__ - WARNING -   Skipped train sample 3745 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,004 - __main__ - WARNING -   Skipped train sample 3746 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,006 - __main__ - WARNING -   Skipped train sample 3747 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,008 - __main__ - WARNING -   Skipped train sample 3748 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,010 - __main__ - WARNING -   Skipped train sample 3749 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,012 - __main__ - WARNING -   Skipped train sample 3750 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,014 - __main__ - WARNING -   Skipped train sample 3751 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,016 - __main__ - WARNING -   Skipped train sample 3752 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,018 - __main__ - WARNING -   Skipped train sample 3753 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,020 - __main__ - WARNING -   Skipped train sample 3754 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,022 - __main__ - WARNING -   Skipped train sample 3755 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,024 - __main__ - WARNING -   Skipped train sample 3756 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,026 - __main__ - WARNING -   Skipped train sample 3757 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,028 - __main__ - WARNING -   Skipped train sample 3758 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,030 - __main__ - WARNING -   Skipped train sample 3759 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:42,032 - __main__ - WARNING -   Skipped train sample 3760 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,034 - __main__ - WARNING -   Skipped train sample 3761 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,036 - __main__ - WARNING -   Skipped train sample 3762 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,038 - __main__ - WARNING -   Skipped train sample 3763 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,040 - __main__ - WARNING -   Skipped train sample 3764 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,042 - __main__ - WARNING -   Skipped train sample 3765 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,044 - __main__ - WARNING -   Skipped train sample 3766 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,046 - __main__ - WARNING -   Skipped train sample 3767 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,048 - __main__ - WARNING -   Skipped train sample 3768 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,050 - __main__ - WARNING -   Skipped train sample 3769 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,052 - __main__ - WARNING -   Skipped train sample 3770 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,054 - __main__ - WARNING -   Skipped train sample 3771 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,056 - __main__ - WARNING -   Skipped train sample 3772 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,058 - __main__ - WARNING -   Skipped train sample 3773 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,060 - __main__ - WARNING -   Skipped train sample 3774 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,062 - __main__ - WARNING -   Skipped train sample 3775 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,063 - __main__ - WARNING -   Skipped train sample 3776 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,065 - __main__ - WARNING -   Skipped train sample 3777 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,067 - __main__ - WARNING -   Skipped train sample 3778 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,069 - __main__ - WARNING -   Skipped train sample 3779 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,071 - __main__ - WARNING -   Skipped train sample 3780 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,073 - __main__ - WARNING -   Skipped train sample 3781 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,075 - __main__ - WARNING -   Skipped train sample 3782 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,077 - __main__ - WARNING -   Skipped train sample 3783 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,079 - __main__ - WARNING -   Skipped train sample 3784 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,080 - __main__ - WARNING -   Skipped train sample 3785 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,082 - __main__ - WARNING -   Skipped train sample 3786 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,084 - __main__ - WARNING -   Skipped train sample 3787 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,086 - __main__ - WARNING -   Skipped train sample 3788 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,088 - __main__ - WARNING -   Skipped train sample 3789 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,090 - __main__ - WARNING -   Skipped train sample 3790 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,092 - __main__ - WARNING -   Skipped train sample 3791 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,094 - __main__ - WARNING -   Skipped train sample 3792 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,096 - __main__ - WARNING -   Skipped train sample 3793 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,098 - __main__ - WARNING -   Skipped train sample 3794 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,099 - __main__ - WARNING -   Skipped train sample 3795 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,101 - __main__ - WARNING -   Skipped train sample 3796 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,103 - __main__ - WARNING -   Skipped train sample 3797 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,105 - __main__ - WARNING -   Skipped train sample 3798 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,107 - __main__ - WARNING -   Skipped train sample 3799 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,109 - __main__ - WARNING -   Skipped train sample 3800 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,111 - __main__ - WARNING -   Skipped train sample 3801 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,113 - __main__ - WARNING -   Skipped train sample 3802 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,115 - __main__ - WARNING -   Skipped train sample 3803 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,116 - __main__ - WARNING -   Skipped train sample 3804 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,119 - __main__ - WARNING -   Skipped train sample 3805 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,120 - __main__ - WARNING -   Skipped train sample 3806 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,123 - __main__ - WARNING -   Skipped train sample 3807 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,125 - __main__ - WARNING -   Skipped train sample 3808 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,127 - __main__ - WARNING -   Skipped train sample 3809 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,129 - __main__ - WARNING -   Skipped train sample 3810 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,130 - __main__ - WARNING -   Skipped train sample 3811 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,132 - __main__ - WARNING -   Skipped train sample 3812 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,134 - __main__ - WARNING -   Skipped train sample 3813 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,136 - __main__ - WARNING -   Skipped train sample 3814 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,138 - __main__ - WARNING -   Skipped train sample 3815 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,140 - __main__ - WARNING -   Skipped train sample 3816 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,142 - __main__ - WARNING -   Skipped train sample 3817 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,144 - __main__ - WARNING -   Skipped train sample 3818 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,146 - __main__ - WARNING -   Skipped train sample 3819 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,148 - __main__ - WARNING -   Skipped train sample 3820 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,150 - __main__ - WARNING -   Skipped train sample 3821 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,152 - __main__ - WARNING -   Skipped train sample 3822 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,154 - __main__ - WARNING -   Skipped train sample 3823 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,156 - __main__ - WARNING -   Skipped train sample 3824 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,158 - __main__ - WARNING -   Skipped train sample 3825 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,160 - __main__ - WARNING -   Skipped train sample 3826 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,162 - __main__ - WARNING -   Skipped train sample 3827 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,164 - __main__ - WARNING -   Skipped train sample 3828 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,167 - __main__ - WARNING -   Skipped train sample 3829 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,169 - __main__ - WARNING -   Skipped train sample 3830 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,171 - __main__ - WARNING -   Skipped train sample 3831 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,172 - __main__ - WARNING -   Skipped train sample 3832 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,175 - __main__ - WARNING -   Skipped train sample 3833 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,176 - __main__ - WARNING -   Skipped train sample 3834 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,179 - __main__ - WARNING -   Skipped train sample 3835 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,181 - __main__ - WARNING -   Skipped train sample 3836 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,183 - __main__ - WARNING -   Skipped train sample 3837 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,185 - __main__ - WARNING -   Skipped train sample 3838 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,187 - __main__ - WARNING -   Skipped train sample 3839 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,189 - __main__ - WARNING -   Skipped train sample 3840 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,191 - __main__ - WARNING -   Skipped train sample 3841 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,193 - __main__ - WARNING -   Skipped train sample 3842 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,195 - __main__ - WARNING -   Skipped train sample 3843 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,197 - __main__ - WARNING -   Skipped train sample 3844 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,199 - __main__ - WARNING -   Skipped train sample 3845 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,200 - __main__ - WARNING -   Skipped train sample 3846 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,202 - __main__ - WARNING -   Skipped train sample 3847 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,204 - __main__ - WARNING -   Skipped train sample 3848 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,206 - __main__ - WARNING -   Skipped train sample 3849 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,208 - __main__ - WARNING -   Skipped train sample 3850 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,210 - __main__ - WARNING -   Skipped train sample 3851 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,212 - __main__ - WARNING -   Skipped train sample 3852 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,214 - __main__ - WARNING -   Skipped train sample 3853 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,216 - __main__ - WARNING -   Skipped train sample 3854 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,218 - __main__ - WARNING -   Skipped train sample 3855 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,220 - __main__ - WARNING -   Skipped train sample 3856 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,222 - __main__ - WARNING -   Skipped train sample 3857 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,224 - __main__ - WARNING -   Skipped train sample 3858 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,226 - __main__ - WARNING -   Skipped train sample 3859 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,228 - __main__ - WARNING -   Skipped train sample 3860 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,230 - __main__ - WARNING -   Skipped train sample 3861 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,232 - __main__ - WARNING -   Skipped train sample 3862 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,234 - __main__ - WARNING -   Skipped train sample 3863 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,236 - __main__ - WARNING -   Skipped train sample 3864 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,238 - __main__ - WARNING -   Skipped train sample 3865 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,240 - __main__ - WARNING -   Skipped train sample 3866 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,241 - __main__ - WARNING -   Skipped train sample 3867 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,243 - __main__ - WARNING -   Skipped train sample 3868 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,245 - __main__ - WARNING -   Skipped train sample 3869 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,247 - __main__ - WARNING -   Skipped train sample 3870 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,249 - __main__ - WARNING -   Skipped train sample 3871 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,251 - __main__ - WARNING -   Skipped train sample 3872 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,253 - __main__ - WARNING -   Skipped train sample 3873 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,255 - __main__ - WARNING -   Skipped train sample 3874 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,257 - __main__ - WARNING -   Skipped train sample 3875 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,259 - __main__ - WARNING -   Skipped train sample 3876 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,260 - __main__ - WARNING -   Skipped train sample 3877 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,262 - __main__ - WARNING -   Skipped train sample 3878 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,264 - __main__ - WARNING -   Skipped train sample 3879 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,266 - __main__ - WARNING -   Skipped train sample 3880 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,268 - __main__ - WARNING -   Skipped train sample 3881 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,270 - __main__ - WARNING -   Skipped train sample 3882 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,272 - __main__ - WARNING -   Skipped train sample 3883 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,274 - __main__ - WARNING -   Skipped train sample 3884 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,276 - __main__ - WARNING -   Skipped train sample 3885 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,278 - __main__ - WARNING -   Skipped train sample 3886 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,280 - __main__ - WARNING -   Skipped train sample 3887 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,282 - __main__ - WARNING -   Skipped train sample 3888 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,284 - __main__ - WARNING -   Skipped train sample 3889 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,286 - __main__ - WARNING -   Skipped train sample 3890 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,288 - __main__ - WARNING -   Skipped train sample 3891 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,290 - __main__ - WARNING -   Skipped train sample 3892 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,292 - __main__ - WARNING -   Skipped train sample 3893 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,294 - __main__ - WARNING -   Skipped train sample 3894 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,296 - __main__ - WARNING -   Skipped train sample 3895 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,298 - __main__ - WARNING -   Skipped train sample 3896 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,299 - __main__ - WARNING -   Skipped train sample 3897 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,301 - __main__ - WARNING -   Skipped train sample 3898 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,303 - __main__ - WARNING -   Skipped train sample 3899 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,305 - __main__ - WARNING -   Skipped train sample 3900 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,307 - __main__ - WARNING -   Skipped train sample 3901 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,309 - __main__ - WARNING -   Skipped train sample 3902 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,311 - __main__ - WARNING -   Skipped train sample 3903 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,313 - __main__ - WARNING -   Skipped train sample 3904 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,315 - __main__ - WARNING -   Skipped train sample 3905 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,317 - __main__ - WARNING -   Skipped train sample 3906 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,319 - __main__ - WARNING -   Skipped train sample 3907 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,321 - __main__ - WARNING -   Skipped train sample 3908 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,323 - __main__ - WARNING -   Skipped train sample 3909 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,325 - __main__ - WARNING -   Skipped train sample 3910 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,327 - __main__ - WARNING -   Skipped train sample 3911 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,329 - __main__ - WARNING -   Skipped train sample 3912 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,331 - __main__ - WARNING -   Skipped train sample 3913 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,332 - __main__ - WARNING -   Skipped train sample 3914 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,334 - __main__ - WARNING -   Skipped train sample 3915 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,336 - __main__ - WARNING -   Skipped train sample 3916 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:42,338 - __main__ - WARNING -   Skipped train sample 3917 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,340 - __main__ - WARNING -   Skipped train sample 3918 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,342 - __main__ - WARNING -   Skipped train sample 3919 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,344 - __main__ - WARNING -   Skipped train sample 3920 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,346 - __main__ - WARNING -   Skipped train sample 3921 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,348 - __main__ - WARNING -   Skipped train sample 3922 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,350 - __main__ - WARNING -   Skipped train sample 3923 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,352 - __main__ - WARNING -   Skipped train sample 3924 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,354 - __main__ - WARNING -   Skipped train sample 3925 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,356 - __main__ - WARNING -   Skipped train sample 3926 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,358 - __main__ - WARNING -   Skipped train sample 3927 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,360 - __main__ - WARNING -   Skipped train sample 3928 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,362 - __main__ - WARNING -   Skipped train sample 3929 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,364 - __main__ - WARNING -   Skipped train sample 3930 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,366 - __main__ - WARNING -   Skipped train sample 3931 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,368 - __main__ - WARNING -   Skipped train sample 3932 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,370 - __main__ - WARNING -   Skipped train sample 3933 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,372 - __main__ - WARNING -   Skipped train sample 3934 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,374 - __main__ - WARNING -   Skipped train sample 3935 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,375 - __main__ - WARNING -   Skipped train sample 3936 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,377 - __main__ - WARNING -   Skipped train sample 3937 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,379 - __main__ - WARNING -   Skipped train sample 3938 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,381 - __main__ - WARNING -   Skipped train sample 3939 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,383 - __main__ - WARNING -   Skipped train sample 3940 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,385 - __main__ - WARNING -   Skipped train sample 3941 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,387 - __main__ - WARNING -   Skipped train sample 3942 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,389 - __main__ - WARNING -   Skipped train sample 3943 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,391 - __main__ - WARNING -   Skipped train sample 3944 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,393 - __main__ - WARNING -   Skipped train sample 3945 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,395 - __main__ - WARNING -   Skipped train sample 3946 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,396 - __main__ - WARNING -   Skipped train sample 3947 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,399 - __main__ - WARNING -   Skipped train sample 3948 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,400 - __main__ - WARNING -   Skipped train sample 3949 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,403 - __main__ - WARNING -   Skipped train sample 3950 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,405 - __main__ - WARNING -   Skipped train sample 3951 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,407 - __main__ - WARNING -   Skipped train sample 3952 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,409 - __main__ - WARNING -   Skipped train sample 3953 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,410 - __main__ - WARNING -   Skipped train sample 3954 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,412 - __main__ - WARNING -   Skipped train sample 3955 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,414 - __main__ - WARNING -   Skipped train sample 3956 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,416 - __main__ - WARNING -   Skipped train sample 3957 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,418 - __main__ - WARNING -   Skipped train sample 3958 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,420 - __main__ - WARNING -   Skipped train sample 3959 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,422 - __main__ - WARNING -   Skipped train sample 3960 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,424 - __main__ - WARNING -   Skipped train sample 3961 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,426 - __main__ - WARNING -   Skipped train sample 3962 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,428 - __main__ - WARNING -   Skipped train sample 3963 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,430 - __main__ - WARNING -   Skipped train sample 3964 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,432 - __main__ - WARNING -   Skipped train sample 3965 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,434 - __main__ - WARNING -   Skipped train sample 3966 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,436 - __main__ - WARNING -   Skipped train sample 3967 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,438 - __main__ - WARNING -   Skipped train sample 3968 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,440 - __main__ - WARNING -   Skipped train sample 3969 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,442 - __main__ - WARNING -   Skipped train sample 3970 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,444 - __main__ - WARNING -   Skipped train sample 3971 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,446 - __main__ - WARNING -   Skipped train sample 3972 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,448 - __main__ - WARNING -   Skipped train sample 3973 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,450 - __main__ - WARNING -   Skipped train sample 3974 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,452 - __main__ - WARNING -   Skipped train sample 3975 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,454 - __main__ - WARNING -   Skipped train sample 3976 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,456 - __main__ - WARNING -   Skipped train sample 3977 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,458 - __main__ - WARNING -   Skipped train sample 3978 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,460 - __main__ - WARNING -   Skipped train sample 3979 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,462 - __main__ - WARNING -   Skipped train sample 3980 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,463 - __main__ - WARNING -   Skipped train sample 3981 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,466 - __main__ - WARNING -   Skipped train sample 3982 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,467 - __main__ - WARNING -   Skipped train sample 3983 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,469 - __main__ - WARNING -   Skipped train sample 3984 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,471 - __main__ - WARNING -   Skipped train sample 3985 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,473 - __main__ - WARNING -   Skipped train sample 3986 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,475 - __main__ - WARNING -   Skipped train sample 3987 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,477 - __main__ - WARNING -   Skipped train sample 3988 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,479 - __main__ - WARNING -   Skipped train sample 3989 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,481 - __main__ - WARNING -   Skipped train sample 3990 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,483 - __main__ - WARNING -   Skipped train sample 3991 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,485 - __main__ - WARNING -   Skipped train sample 3992 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,487 - __main__ - WARNING -   Skipped train sample 3993 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,489 - __main__ - WARNING -   Skipped train sample 3994 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,491 - __main__ - WARNING -   Skipped train sample 3995 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,493 - __main__ - WARNING -   Skipped train sample 3996 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,496 - __main__ - WARNING -   Skipped train sample 3997 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,498 - __main__ - WARNING -   Skipped train sample 3998 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,500 - __main__ - WARNING -   Skipped train sample 3999 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,500 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-21 22:09:42,502 - __main__ - WARNING -   Skipped train sample 4000 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,504 - __main__ - WARNING -   Skipped train sample 4001 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,506 - __main__ - WARNING -   Skipped train sample 4002 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,508 - __main__ - WARNING -   Skipped train sample 4003 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,510 - __main__ - WARNING -   Skipped train sample 4004 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,512 - __main__ - WARNING -   Skipped train sample 4005 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,514 - __main__ - WARNING -   Skipped train sample 4006 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,516 - __main__ - WARNING -   Skipped train sample 4007 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,518 - __main__ - WARNING -   Skipped train sample 4008 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,520 - __main__ - WARNING -   Skipped train sample 4009 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,522 - __main__ - WARNING -   Skipped train sample 4010 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,524 - __main__ - WARNING -   Skipped train sample 4011 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,526 - __main__ - WARNING -   Skipped train sample 4012 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,528 - __main__ - WARNING -   Skipped train sample 4013 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,530 - __main__ - WARNING -   Skipped train sample 4014 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,532 - __main__ - WARNING -   Skipped train sample 4015 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,534 - __main__ - WARNING -   Skipped train sample 4016 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,535 - __main__ - WARNING -   Skipped train sample 4017 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,537 - __main__ - WARNING -   Skipped train sample 4018 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,540 - __main__ - WARNING -   Skipped train sample 4019 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,542 - __main__ - WARNING -   Skipped train sample 4020 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,544 - __main__ - WARNING -   Skipped train sample 4021 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,546 - __main__ - WARNING -   Skipped train sample 4022 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,548 - __main__ - WARNING -   Skipped train sample 4023 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,550 - __main__ - WARNING -   Skipped train sample 4024 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,552 - __main__ - WARNING -   Skipped train sample 4025 due to error: invalid literal for int() with base 10: 'signer_6'
2025-09-21 22:09:42,554 - __main__ - WARNING -   Skipped train sample 4026 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,556 - __main__ - WARNING -   Skipped train sample 4027 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,558 - __main__ - WARNING -   Skipped train sample 4028 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,560 - __main__ - WARNING -   Skipped train sample 4029 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,562 - __main__ - WARNING -   Skipped train sample 4030 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,564 - __main__ - WARNING -   Skipped train sample 4031 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,566 - __main__ - WARNING -   Skipped train sample 4032 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,568 - __main__ - WARNING -   Skipped train sample 4033 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,570 - __main__ - WARNING -   Skipped train sample 4034 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,572 - __main__ - WARNING -   Skipped train sample 4035 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,574 - __main__ - WARNING -   Skipped train sample 4036 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,576 - __main__ - WARNING -   Skipped train sample 4037 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,578 - __main__ - WARNING -   Skipped train sample 4038 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,580 - __main__ - WARNING -   Skipped train sample 4039 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,582 - __main__ - WARNING -   Skipped train sample 4040 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,584 - __main__ - WARNING -   Skipped train sample 4041 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,586 - __main__ - WARNING -   Skipped train sample 4042 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,588 - __main__ - WARNING -   Skipped train sample 4043 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,590 - __main__ - WARNING -   Skipped train sample 4044 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,592 - __main__ - WARNING -   Skipped train sample 4045 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,594 - __main__ - WARNING -   Skipped train sample 4046 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,596 - __main__ - WARNING -   Skipped train sample 4047 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,598 - __main__ - WARNING -   Skipped train sample 4048 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,600 - __main__ - WARNING -   Skipped train sample 4049 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,602 - __main__ - WARNING -   Skipped train sample 4050 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,604 - __main__ - WARNING -   Skipped train sample 4051 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,606 - __main__ - WARNING -   Skipped train sample 4052 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,608 - __main__ - WARNING -   Skipped train sample 4053 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,610 - __main__ - WARNING -   Skipped train sample 4054 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,612 - __main__ - WARNING -   Skipped train sample 4055 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,614 - __main__ - WARNING -   Skipped train sample 4056 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,616 - __main__ - WARNING -   Skipped train sample 4057 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,618 - __main__ - WARNING -   Skipped train sample 4058 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,620 - __main__ - WARNING -   Skipped train sample 4059 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,622 - __main__ - WARNING -   Skipped train sample 4060 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,624 - __main__ - WARNING -   Skipped train sample 4061 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,626 - __main__ - WARNING -   Skipped train sample 4062 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,628 - __main__ - WARNING -   Skipped train sample 4063 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,630 - __main__ - WARNING -   Skipped train sample 4064 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,632 - __main__ - WARNING -   Skipped train sample 4065 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,634 - __main__ - WARNING -   Skipped train sample 4066 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,636 - __main__ - WARNING -   Skipped train sample 4067 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,638 - __main__ - WARNING -   Skipped train sample 4068 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,640 - __main__ - WARNING -   Skipped train sample 4069 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,642 - __main__ - WARNING -   Skipped train sample 4070 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,644 - __main__ - WARNING -   Skipped train sample 4071 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,646 - __main__ - WARNING -   Skipped train sample 4072 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,648 - __main__ - WARNING -   Skipped train sample 4073 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,650 - __main__ - WARNING -   Skipped train sample 4074 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,651 - __main__ - WARNING -   Skipped train sample 4075 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,653 - __main__ - WARNING -   Skipped train sample 4076 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,655 - __main__ - WARNING -   Skipped train sample 4077 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,657 - __main__ - WARNING -   Skipped train sample 4078 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,659 - __main__ - WARNING -   Skipped train sample 4079 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,661 - __main__ - WARNING -   Skipped train sample 4080 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,663 - __main__ - WARNING -   Skipped train sample 4081 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,665 - __main__ - WARNING -   Skipped train sample 4082 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,667 - __main__ - WARNING -   Skipped train sample 4083 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,668 - __main__ - WARNING -   Skipped train sample 4084 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,671 - __main__ - WARNING -   Skipped train sample 4085 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,672 - __main__ - WARNING -   Skipped train sample 4086 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,674 - __main__ - WARNING -   Skipped train sample 4087 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,676 - __main__ - WARNING -   Skipped train sample 4088 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,678 - __main__ - WARNING -   Skipped train sample 4089 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,680 - __main__ - WARNING -   Skipped train sample 4090 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,682 - __main__ - WARNING -   Skipped train sample 4091 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,684 - __main__ - WARNING -   Skipped train sample 4092 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,686 - __main__ - WARNING -   Skipped train sample 4093 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,688 - __main__ - WARNING -   Skipped train sample 4094 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,690 - __main__ - WARNING -   Skipped train sample 4095 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,692 - __main__ - WARNING -   Skipped train sample 4096 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,694 - __main__ - WARNING -   Skipped train sample 4097 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,696 - __main__ - WARNING -   Skipped train sample 4098 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,698 - __main__ - WARNING -   Skipped train sample 4099 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,699 - __main__ - WARNING -   Skipped train sample 4100 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,701 - __main__ - WARNING -   Skipped train sample 4101 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,703 - __main__ - WARNING -   Skipped train sample 4102 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,705 - __main__ - WARNING -   Skipped train sample 4103 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,707 - __main__ - WARNING -   Skipped train sample 4104 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,709 - __main__ - WARNING -   Skipped train sample 4105 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,711 - __main__ - WARNING -   Skipped train sample 4106 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,713 - __main__ - WARNING -   Skipped train sample 4107 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,715 - __main__ - WARNING -   Skipped train sample 4108 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,717 - __main__ - WARNING -   Skipped train sample 4109 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,719 - __main__ - WARNING -   Skipped train sample 4110 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,720 - __main__ - WARNING -   Skipped train sample 4111 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,722 - __main__ - WARNING -   Skipped train sample 4112 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,724 - __main__ - WARNING -   Skipped train sample 4113 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,726 - __main__ - WARNING -   Skipped train sample 4114 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,728 - __main__ - WARNING -   Skipped train sample 4115 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,730 - __main__ - WARNING -   Skipped train sample 4116 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,732 - __main__ - WARNING -   Skipped train sample 4117 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,734 - __main__ - WARNING -   Skipped train sample 4118 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,736 - __main__ - WARNING -   Skipped train sample 4119 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,738 - __main__ - WARNING -   Skipped train sample 4120 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,740 - __main__ - WARNING -   Skipped train sample 4121 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,742 - __main__ - WARNING -   Skipped train sample 4122 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,744 - __main__ - WARNING -   Skipped train sample 4123 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,746 - __main__ - WARNING -   Skipped train sample 4124 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,748 - __main__ - WARNING -   Skipped train sample 4125 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,750 - __main__ - WARNING -   Skipped train sample 4126 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,751 - __main__ - WARNING -   Skipped train sample 4127 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,754 - __main__ - WARNING -   Skipped train sample 4128 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,755 - __main__ - WARNING -   Skipped train sample 4129 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,757 - __main__ - WARNING -   Skipped train sample 4130 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,759 - __main__ - WARNING -   Skipped train sample 4131 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,761 - __main__ - WARNING -   Skipped train sample 4132 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,763 - __main__ - WARNING -   Skipped train sample 4133 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,765 - __main__ - WARNING -   Skipped train sample 4134 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,767 - __main__ - WARNING -   Skipped train sample 4135 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,769 - __main__ - WARNING -   Skipped train sample 4136 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,771 - __main__ - WARNING -   Skipped train sample 4137 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,773 - __main__ - WARNING -   Skipped train sample 4138 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,775 - __main__ - WARNING -   Skipped train sample 4139 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,777 - __main__ - WARNING -   Skipped train sample 4140 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,779 - __main__ - WARNING -   Skipped train sample 4141 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,780 - __main__ - WARNING -   Skipped train sample 4142 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,782 - __main__ - WARNING -   Skipped train sample 4143 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,784 - __main__ - WARNING -   Skipped train sample 4144 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,786 - __main__ - WARNING -   Skipped train sample 4145 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,788 - __main__ - WARNING -   Skipped train sample 4146 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,790 - __main__ - WARNING -   Skipped train sample 4147 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,792 - __main__ - WARNING -   Skipped train sample 4148 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,794 - __main__ - WARNING -   Skipped train sample 4149 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,796 - __main__ - WARNING -   Skipped train sample 4150 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,799 - __main__ - WARNING -   Skipped train sample 4151 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,801 - __main__ - WARNING -   Skipped train sample 4152 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,802 - __main__ - WARNING -   Skipped train sample 4153 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,804 - __main__ - WARNING -   Skipped train sample 4154 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,806 - __main__ - WARNING -   Skipped train sample 4155 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,808 - __main__ - WARNING -   Skipped train sample 4156 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,810 - __main__ - WARNING -   Skipped train sample 4157 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,812 - __main__ - WARNING -   Skipped train sample 4158 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,814 - __main__ - WARNING -   Skipped train sample 4159 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,816 - __main__ - WARNING -   Skipped train sample 4160 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,818 - __main__ - WARNING -   Skipped train sample 4161 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,820 - __main__ - WARNING -   Skipped train sample 4162 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,821 - __main__ - WARNING -   Skipped train sample 4163 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,823 - __main__ - WARNING -   Skipped train sample 4164 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,825 - __main__ - WARNING -   Skipped train sample 4165 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,827 - __main__ - WARNING -   Skipped train sample 4166 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,829 - __main__ - WARNING -   Skipped train sample 4167 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,831 - __main__ - WARNING -   Skipped train sample 4168 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,833 - __main__ - WARNING -   Skipped train sample 4169 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,835 - __main__ - WARNING -   Skipped train sample 4170 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,837 - __main__ - WARNING -   Skipped train sample 4171 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,839 - __main__ - WARNING -   Skipped train sample 4172 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,841 - __main__ - WARNING -   Skipped train sample 4173 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,843 - __main__ - WARNING -   Skipped train sample 4174 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,845 - __main__ - WARNING -   Skipped train sample 4175 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,847 - __main__ - WARNING -   Skipped train sample 4176 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,849 - __main__ - WARNING -   Skipped train sample 4177 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,851 - __main__ - WARNING -   Skipped train sample 4178 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,853 - __main__ - WARNING -   Skipped train sample 4179 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,855 - __main__ - WARNING -   Skipped train sample 4180 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,856 - __main__ - WARNING -   Skipped train sample 4181 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,858 - __main__ - WARNING -   Skipped train sample 4182 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,860 - __main__ - WARNING -   Skipped train sample 4183 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,862 - __main__ - WARNING -   Skipped train sample 4184 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,864 - __main__ - WARNING -   Skipped train sample 4185 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,866 - __main__ - WARNING -   Skipped train sample 4186 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,868 - __main__ - WARNING -   Skipped train sample 4187 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,870 - __main__ - WARNING -   Skipped train sample 4188 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,872 - __main__ - WARNING -   Skipped train sample 4189 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,874 - __main__ - WARNING -   Skipped train sample 4190 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,876 - __main__ - WARNING -   Skipped train sample 4191 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,878 - __main__ - WARNING -   Skipped train sample 4192 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,880 - __main__ - WARNING -   Skipped train sample 4193 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:42,882 - __main__ - WARNING -   Skipped train sample 4194 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,884 - __main__ - WARNING -   Skipped train sample 4195 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,886 - __main__ - WARNING -   Skipped train sample 4196 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,888 - __main__ - WARNING -   Skipped train sample 4197 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,890 - __main__ - WARNING -   Skipped train sample 4198 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,891 - __main__ - WARNING -   Skipped train sample 4199 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,893 - __main__ - WARNING -   Skipped train sample 4200 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,895 - __main__ - WARNING -   Skipped train sample 4201 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,897 - __main__ - WARNING -   Skipped train sample 4202 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,899 - __main__ - WARNING -   Skipped train sample 4203 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,902 - __main__ - WARNING -   Skipped train sample 4204 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:42,903 - __main__ - WARNING -   Skipped train sample 4205 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,905 - __main__ - WARNING -   Skipped train sample 4206 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,907 - __main__ - WARNING -   Skipped train sample 4207 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,909 - __main__ - WARNING -   Skipped train sample 4208 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,911 - __main__ - WARNING -   Skipped train sample 4209 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,913 - __main__ - WARNING -   Skipped train sample 4210 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,915 - __main__ - WARNING -   Skipped train sample 4211 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,917 - __main__ - WARNING -   Skipped train sample 4212 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,919 - __main__ - WARNING -   Skipped train sample 4213 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,921 - __main__ - WARNING -   Skipped train sample 4214 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,923 - __main__ - WARNING -   Skipped train sample 4215 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,925 - __main__ - WARNING -   Skipped train sample 4216 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,927 - __main__ - WARNING -   Skipped train sample 4217 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,928 - __main__ - WARNING -   Skipped train sample 4218 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,930 - __main__ - WARNING -   Skipped train sample 4219 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,932 - __main__ - WARNING -   Skipped train sample 4220 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,935 - __main__ - WARNING -   Skipped train sample 4221 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,936 - __main__ - WARNING -   Skipped train sample 4222 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,938 - __main__ - WARNING -   Skipped train sample 4223 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,940 - __main__ - WARNING -   Skipped train sample 4224 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,942 - __main__ - WARNING -   Skipped train sample 4225 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,944 - __main__ - WARNING -   Skipped train sample 4226 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,946 - __main__ - WARNING -   Skipped train sample 4227 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,948 - __main__ - WARNING -   Skipped train sample 4228 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,950 - __main__ - WARNING -   Skipped train sample 4229 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,952 - __main__ - WARNING -   Skipped train sample 4230 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,954 - __main__ - WARNING -   Skipped train sample 4231 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,956 - __main__ - WARNING -   Skipped train sample 4232 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,958 - __main__ - WARNING -   Skipped train sample 4233 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,960 - __main__ - WARNING -   Skipped train sample 4234 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,962 - __main__ - WARNING -   Skipped train sample 4235 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,964 - __main__ - WARNING -   Skipped train sample 4236 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,966 - __main__ - WARNING -   Skipped train sample 4237 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,968 - __main__ - WARNING -   Skipped train sample 4238 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,970 - __main__ - WARNING -   Skipped train sample 4239 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,972 - __main__ - WARNING -   Skipped train sample 4240 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,974 - __main__ - WARNING -   Skipped train sample 4241 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,976 - __main__ - WARNING -   Skipped train sample 4242 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,977 - __main__ - WARNING -   Skipped train sample 4243 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,979 - __main__ - WARNING -   Skipped train sample 4244 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,981 - __main__ - WARNING -   Skipped train sample 4245 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,983 - __main__ - WARNING -   Skipped train sample 4246 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,985 - __main__ - WARNING -   Skipped train sample 4247 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,987 - __main__ - WARNING -   Skipped train sample 4248 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,989 - __main__ - WARNING -   Skipped train sample 4249 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,991 - __main__ - WARNING -   Skipped train sample 4250 due to error: cannot convert float NaN to integer
2025-09-21 22:09:42,993 - __main__ - WARNING -   Skipped train sample 4251 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:42,995 - __main__ - WARNING -   Skipped train sample 4252 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:42,997 - __main__ - WARNING -   Skipped train sample 4253 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,000 - __main__ - WARNING -   Skipped train sample 4254 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,002 - __main__ - WARNING -   Skipped train sample 4255 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,004 - __main__ - WARNING -   Skipped train sample 4256 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,006 - __main__ - WARNING -   Skipped train sample 4257 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,008 - __main__ - WARNING -   Skipped train sample 4258 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,010 - __main__ - WARNING -   Skipped train sample 4259 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,012 - __main__ - WARNING -   Skipped train sample 4260 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,014 - __main__ - WARNING -   Skipped train sample 4261 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,016 - __main__ - WARNING -   Skipped train sample 4262 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,018 - __main__ - WARNING -   Skipped train sample 4263 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,020 - __main__ - WARNING -   Skipped train sample 4264 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,022 - __main__ - WARNING -   Skipped train sample 4265 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,024 - __main__ - WARNING -   Skipped train sample 4266 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,026 - __main__ - WARNING -   Skipped train sample 4267 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,028 - __main__ - WARNING -   Skipped train sample 4268 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,030 - __main__ - WARNING -   Skipped train sample 4269 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,032 - __main__ - WARNING -   Skipped train sample 4270 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,034 - __main__ - WARNING -   Skipped train sample 4271 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,036 - __main__ - WARNING -   Skipped train sample 4272 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,037 - __main__ - WARNING -   Skipped train sample 4273 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,039 - __main__ - WARNING -   Skipped train sample 4274 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,042 - __main__ - WARNING -   Skipped train sample 4275 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,043 - __main__ - WARNING -   Skipped train sample 4276 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,045 - __main__ - WARNING -   Skipped train sample 4277 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,047 - __main__ - WARNING -   Skipped train sample 4278 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,049 - __main__ - WARNING -   Skipped train sample 4279 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,051 - __main__ - WARNING -   Skipped train sample 4280 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,053 - __main__ - WARNING -   Skipped train sample 4281 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,055 - __main__ - WARNING -   Skipped train sample 4282 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,057 - __main__ - WARNING -   Skipped train sample 4283 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,059 - __main__ - WARNING -   Skipped train sample 4284 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,061 - __main__ - WARNING -   Skipped train sample 4285 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,062 - __main__ - WARNING -   Skipped train sample 4286 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,064 - __main__ - WARNING -   Skipped train sample 4287 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,066 - __main__ - WARNING -   Skipped train sample 4288 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,068 - __main__ - WARNING -   Skipped train sample 4289 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,070 - __main__ - WARNING -   Skipped train sample 4290 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,072 - __main__ - WARNING -   Skipped train sample 4291 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,074 - __main__ - WARNING -   Skipped train sample 4292 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,076 - __main__ - WARNING -   Skipped train sample 4293 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,077 - __main__ - WARNING -   Skipped train sample 4294 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,079 - __main__ - WARNING -   Skipped train sample 4295 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,081 - __main__ - WARNING -   Skipped train sample 4296 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,083 - __main__ - WARNING -   Skipped train sample 4297 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,085 - __main__ - WARNING -   Skipped train sample 4298 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,087 - __main__ - WARNING -   Skipped train sample 4299 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,089 - __main__ - WARNING -   Skipped train sample 4300 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,091 - __main__ - WARNING -   Skipped train sample 4301 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,092 - __main__ - WARNING -   Skipped train sample 4302 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,094 - __main__ - WARNING -   Skipped train sample 4303 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,096 - __main__ - WARNING -   Skipped train sample 4304 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,098 - __main__ - WARNING -   Skipped train sample 4305 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,100 - __main__ - WARNING -   Skipped train sample 4306 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,102 - __main__ - WARNING -   Skipped train sample 4307 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,104 - __main__ - WARNING -   Skipped train sample 4308 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,106 - __main__ - WARNING -   Skipped train sample 4309 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,108 - __main__ - WARNING -   Skipped train sample 4310 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,110 - __main__ - WARNING -   Skipped train sample 4311 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,112 - __main__ - WARNING -   Skipped train sample 4312 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,114 - __main__ - WARNING -   Skipped train sample 4313 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,115 - __main__ - WARNING -   Skipped train sample 4314 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,117 - __main__ - WARNING -   Skipped train sample 4315 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,119 - __main__ - WARNING -   Skipped train sample 4316 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,121 - __main__ - WARNING -   Skipped train sample 4317 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,124 - __main__ - WARNING -   Skipped train sample 4318 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,126 - __main__ - WARNING -   Skipped train sample 4319 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,127 - __main__ - WARNING -   Skipped train sample 4320 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,130 - __main__ - WARNING -   Skipped train sample 4321 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,132 - __main__ - WARNING -   Skipped train sample 4322 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,133 - __main__ - WARNING -   Skipped train sample 4323 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,135 - __main__ - WARNING -   Skipped train sample 4324 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,137 - __main__ - WARNING -   Skipped train sample 4325 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,139 - __main__ - WARNING -   Skipped train sample 4326 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,141 - __main__ - WARNING -   Skipped train sample 4327 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,143 - __main__ - WARNING -   Skipped train sample 4328 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,144 - __main__ - WARNING -   Skipped train sample 4329 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,147 - __main__ - WARNING -   Skipped train sample 4330 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,148 - __main__ - WARNING -   Skipped train sample 4331 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,150 - __main__ - WARNING -   Skipped train sample 4332 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,152 - __main__ - WARNING -   Skipped train sample 4333 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,154 - __main__ - WARNING -   Skipped train sample 4334 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,156 - __main__ - WARNING -   Skipped train sample 4335 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,158 - __main__ - WARNING -   Skipped train sample 4336 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,160 - __main__ - WARNING -   Skipped train sample 4337 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,162 - __main__ - WARNING -   Skipped train sample 4338 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,164 - __main__ - WARNING -   Skipped train sample 4339 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,166 - __main__ - WARNING -   Skipped train sample 4340 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,168 - __main__ - WARNING -   Skipped train sample 4341 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,170 - __main__ - WARNING -   Skipped train sample 4342 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,172 - __main__ - WARNING -   Skipped train sample 4343 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,174 - __main__ - WARNING -   Skipped train sample 4344 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,176 - __main__ - WARNING -   Skipped train sample 4345 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,178 - __main__ - WARNING -   Skipped train sample 4346 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,180 - __main__ - WARNING -   Skipped train sample 4347 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,182 - __main__ - WARNING -   Skipped train sample 4348 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,183 - __main__ - WARNING -   Skipped train sample 4349 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,185 - __main__ - WARNING -   Skipped train sample 4350 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,187 - __main__ - WARNING -   Skipped train sample 4351 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,189 - __main__ - WARNING -   Skipped train sample 4352 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,191 - __main__ - WARNING -   Skipped train sample 4353 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,193 - __main__ - WARNING -   Skipped train sample 4354 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,195 - __main__ - WARNING -   Skipped train sample 4355 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,197 - __main__ - WARNING -   Skipped train sample 4356 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,199 - __main__ - WARNING -   Skipped train sample 4357 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,201 - __main__ - WARNING -   Skipped train sample 4358 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,203 - __main__ - WARNING -   Skipped train sample 4359 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,205 - __main__ - WARNING -   Skipped train sample 4360 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,206 - __main__ - WARNING -   Skipped train sample 4361 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,208 - __main__ - WARNING -   Skipped train sample 4362 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,210 - __main__ - WARNING -   Skipped train sample 4363 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,212 - __main__ - WARNING -   Skipped train sample 4364 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,214 - __main__ - WARNING -   Skipped train sample 4365 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,216 - __main__ - WARNING -   Skipped train sample 4366 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,218 - __main__ - WARNING -   Skipped train sample 4367 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,220 - __main__ - WARNING -   Skipped train sample 4368 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,222 - __main__ - WARNING -   Skipped train sample 4369 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,224 - __main__ - WARNING -   Skipped train sample 4370 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,226 - __main__ - WARNING -   Skipped train sample 4371 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,228 - __main__ - WARNING -   Skipped train sample 4372 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,230 - __main__ - WARNING -   Skipped train sample 4373 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,232 - __main__ - WARNING -   Skipped train sample 4374 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,234 - __main__ - WARNING -   Skipped train sample 4375 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,236 - __main__ - WARNING -   Skipped train sample 4376 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,238 - __main__ - WARNING -   Skipped train sample 4377 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,239 - __main__ - WARNING -   Skipped train sample 4378 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,241 - __main__ - WARNING -   Skipped train sample 4379 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,243 - __main__ - WARNING -   Skipped train sample 4380 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,245 - __main__ - WARNING -   Skipped train sample 4381 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,247 - __main__ - WARNING -   Skipped train sample 4382 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,249 - __main__ - WARNING -   Skipped train sample 4383 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,251 - __main__ - WARNING -   Skipped train sample 4384 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,253 - __main__ - WARNING -   Skipped train sample 4385 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,255 - __main__ - WARNING -   Skipped train sample 4386 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,257 - __main__ - WARNING -   Skipped train sample 4387 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,259 - __main__ - WARNING -   Skipped train sample 4388 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,260 - __main__ - WARNING -   Skipped train sample 4389 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,262 - __main__ - WARNING -   Skipped train sample 4390 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,264 - __main__ - WARNING -   Skipped train sample 4391 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,266 - __main__ - WARNING -   Skipped train sample 4392 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,268 - __main__ - WARNING -   Skipped train sample 4393 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,271 - __main__ - WARNING -   Skipped train sample 4394 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,272 - __main__ - WARNING -   Skipped train sample 4395 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,274 - __main__ - WARNING -   Skipped train sample 4396 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,276 - __main__ - WARNING -   Skipped train sample 4397 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,278 - __main__ - WARNING -   Skipped train sample 4398 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,280 - __main__ - WARNING -   Skipped train sample 4399 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,282 - __main__ - WARNING -   Skipped train sample 4400 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,284 - __main__ - WARNING -   Skipped train sample 4401 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,286 - __main__ - WARNING -   Skipped train sample 4402 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,288 - __main__ - WARNING -   Skipped train sample 4403 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,290 - __main__ - WARNING -   Skipped train sample 4404 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,292 - __main__ - WARNING -   Skipped train sample 4405 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,293 - __main__ - WARNING -   Skipped train sample 4406 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,295 - __main__ - WARNING -   Skipped train sample 4407 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,297 - __main__ - WARNING -   Skipped train sample 4408 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,299 - __main__ - WARNING -   Skipped train sample 4409 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,301 - __main__ - WARNING -   Skipped train sample 4410 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,303 - __main__ - WARNING -   Skipped train sample 4411 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,305 - __main__ - WARNING -   Skipped train sample 4412 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,307 - __main__ - WARNING -   Skipped train sample 4413 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,309 - __main__ - WARNING -   Skipped train sample 4414 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,311 - __main__ - WARNING -   Skipped train sample 4415 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,313 - __main__ - WARNING -   Skipped train sample 4416 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,315 - __main__ - WARNING -   Skipped train sample 4417 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,317 - __main__ - WARNING -   Skipped train sample 4418 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,319 - __main__ - WARNING -   Skipped train sample 4419 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,320 - __main__ - WARNING -   Skipped train sample 4420 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,322 - __main__ - WARNING -   Skipped train sample 4421 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,324 - __main__ - WARNING -   Skipped train sample 4422 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,326 - __main__ - WARNING -   Skipped train sample 4423 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,328 - __main__ - WARNING -   Skipped train sample 4424 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,330 - __main__ - WARNING -   Skipped train sample 4425 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,332 - __main__ - WARNING -   Skipped train sample 4426 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,334 - __main__ - WARNING -   Skipped train sample 4427 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,336 - __main__ - WARNING -   Skipped train sample 4428 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,338 - __main__ - WARNING -   Skipped train sample 4429 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,340 - __main__ - WARNING -   Skipped train sample 4430 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,342 - __main__ - WARNING -   Skipped train sample 4431 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,344 - __main__ - WARNING -   Skipped train sample 4432 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,346 - __main__ - WARNING -   Skipped train sample 4433 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,348 - __main__ - WARNING -   Skipped train sample 4434 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,350 - __main__ - WARNING -   Skipped train sample 4435 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,352 - __main__ - WARNING -   Skipped train sample 4436 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,354 - __main__ - WARNING -   Skipped train sample 4437 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,356 - __main__ - WARNING -   Skipped train sample 4438 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,358 - __main__ - WARNING -   Skipped train sample 4439 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,360 - __main__ - WARNING -   Skipped train sample 4440 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,362 - __main__ - WARNING -   Skipped train sample 4441 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,364 - __main__ - WARNING -   Skipped train sample 4442 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,366 - __main__ - WARNING -   Skipped train sample 4443 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,368 - __main__ - WARNING -   Skipped train sample 4444 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,370 - __main__ - WARNING -   Skipped train sample 4445 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,372 - __main__ - WARNING -   Skipped train sample 4446 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,374 - __main__ - WARNING -   Skipped train sample 4447 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,376 - __main__ - WARNING -   Skipped train sample 4448 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,378 - __main__ - WARNING -   Skipped train sample 4449 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,380 - __main__ - WARNING -   Skipped train sample 4450 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,382 - __main__ - WARNING -   Skipped train sample 4451 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,384 - __main__ - WARNING -   Skipped train sample 4452 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,386 - __main__ - WARNING -   Skipped train sample 4453 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,388 - __main__ - WARNING -   Skipped train sample 4454 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,390 - __main__ - WARNING -   Skipped train sample 4455 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,392 - __main__ - WARNING -   Skipped train sample 4456 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,394 - __main__ - WARNING -   Skipped train sample 4457 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,395 - __main__ - WARNING -   Skipped train sample 4458 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,397 - __main__ - WARNING -   Skipped train sample 4459 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,399 - __main__ - WARNING -   Skipped train sample 4460 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,401 - __main__ - WARNING -   Skipped train sample 4461 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,403 - __main__ - WARNING -   Skipped train sample 4462 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,405 - __main__ - WARNING -   Skipped train sample 4463 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,407 - __main__ - WARNING -   Skipped train sample 4464 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,409 - __main__ - WARNING -   Skipped train sample 4465 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,411 - __main__ - WARNING -   Skipped train sample 4466 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,413 - __main__ - WARNING -   Skipped train sample 4467 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,415 - __main__ - WARNING -   Skipped train sample 4468 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,417 - __main__ - WARNING -   Skipped train sample 4469 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,419 - __main__ - WARNING -   Skipped train sample 4470 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,420 - __main__ - WARNING -   Skipped train sample 4471 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,422 - __main__ - WARNING -   Skipped train sample 4472 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,424 - __main__ - WARNING -   Skipped train sample 4473 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,427 - __main__ - WARNING -   Skipped train sample 4474 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,429 - __main__ - WARNING -   Skipped train sample 4475 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,430 - __main__ - WARNING -   Skipped train sample 4476 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,432 - __main__ - WARNING -   Skipped train sample 4477 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,434 - __main__ - WARNING -   Skipped train sample 4478 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,436 - __main__ - WARNING -   Skipped train sample 4479 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,438 - __main__ - WARNING -   Skipped train sample 4480 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,440 - __main__ - WARNING -   Skipped train sample 4481 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,442 - __main__ - WARNING -   Skipped train sample 4482 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,444 - __main__ - WARNING -   Skipped train sample 4483 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,446 - __main__ - WARNING -   Skipped train sample 4484 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,448 - __main__ - WARNING -   Skipped train sample 4485 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,450 - __main__ - WARNING -   Skipped train sample 4486 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,452 - __main__ - WARNING -   Skipped train sample 4487 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,454 - __main__ - WARNING -   Skipped train sample 4488 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,456 - __main__ - WARNING -   Skipped train sample 4489 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,458 - __main__ - WARNING -   Skipped train sample 4490 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,460 - __main__ - WARNING -   Skipped train sample 4491 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,462 - __main__ - WARNING -   Skipped train sample 4492 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,464 - __main__ - WARNING -   Skipped train sample 4493 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,466 - __main__ - WARNING -   Skipped train sample 4494 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,468 - __main__ - WARNING -   Skipped train sample 4495 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,470 - __main__ - WARNING -   Skipped train sample 4496 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,472 - __main__ - WARNING -   Skipped train sample 4497 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,474 - __main__ - WARNING -   Skipped train sample 4498 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,476 - __main__ - WARNING -   Skipped train sample 4499 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,478 - __main__ - WARNING -   Skipped train sample 4500 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,480 - __main__ - WARNING -   Skipped train sample 4501 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,482 - __main__ - WARNING -   Skipped train sample 4502 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,484 - __main__ - WARNING -   Skipped train sample 4503 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,486 - __main__ - WARNING -   Skipped train sample 4504 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,488 - __main__ - WARNING -   Skipped train sample 4505 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,490 - __main__ - WARNING -   Skipped train sample 4506 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,492 - __main__ - WARNING -   Skipped train sample 4507 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,493 - __main__ - WARNING -   Skipped train sample 4508 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,496 - __main__ - WARNING -   Skipped train sample 4509 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,497 - __main__ - WARNING -   Skipped train sample 4510 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,499 - __main__ - WARNING -   Skipped train sample 4511 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,501 - __main__ - WARNING -   Skipped train sample 4512 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,503 - __main__ - WARNING -   Skipped train sample 4513 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,505 - __main__ - WARNING -   Skipped train sample 4514 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,507 - __main__ - WARNING -   Skipped train sample 4515 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,509 - __main__ - WARNING -   Skipped train sample 4516 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,511 - __main__ - WARNING -   Skipped train sample 4517 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,513 - __main__ - WARNING -   Skipped train sample 4518 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,515 - __main__ - WARNING -   Skipped train sample 4519 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,517 - __main__ - WARNING -   Skipped train sample 4520 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,519 - __main__ - WARNING -   Skipped train sample 4521 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,521 - __main__ - WARNING -   Skipped train sample 4522 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,523 - __main__ - WARNING -   Skipped train sample 4523 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,524 - __main__ - WARNING -   Skipped train sample 4524 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,527 - __main__ - WARNING -   Skipped train sample 4525 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,529 - __main__ - WARNING -   Skipped train sample 4526 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,531 - __main__ - WARNING -   Skipped train sample 4527 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,532 - __main__ - WARNING -   Skipped train sample 4528 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,534 - __main__ - WARNING -   Skipped train sample 4529 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,536 - __main__ - WARNING -   Skipped train sample 4530 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,538 - __main__ - WARNING -   Skipped train sample 4531 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,540 - __main__ - WARNING -   Skipped train sample 4532 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,543 - __main__ - WARNING -   Skipped train sample 4533 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,544 - __main__ - WARNING -   Skipped train sample 4534 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,546 - __main__ - WARNING -   Skipped train sample 4535 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,548 - __main__ - WARNING -   Skipped train sample 4536 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,550 - __main__ - WARNING -   Skipped train sample 4537 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,552 - __main__ - WARNING -   Skipped train sample 4538 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,554 - __main__ - WARNING -   Skipped train sample 4539 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,556 - __main__ - WARNING -   Skipped train sample 4540 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,558 - __main__ - WARNING -   Skipped train sample 4541 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,560 - __main__ - WARNING -   Skipped train sample 4542 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,562 - __main__ - WARNING -   Skipped train sample 4543 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,564 - __main__ - WARNING -   Skipped train sample 4544 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,566 - __main__ - WARNING -   Skipped train sample 4545 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,568 - __main__ - WARNING -   Skipped train sample 4546 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,570 - __main__ - WARNING -   Skipped train sample 4547 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,572 - __main__ - WARNING -   Skipped train sample 4548 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,574 - __main__ - WARNING -   Skipped train sample 4549 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,576 - __main__ - WARNING -   Skipped train sample 4550 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,578 - __main__ - WARNING -   Skipped train sample 4551 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,580 - __main__ - WARNING -   Skipped train sample 4552 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,582 - __main__ - WARNING -   Skipped train sample 4553 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,584 - __main__ - WARNING -   Skipped train sample 4554 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,586 - __main__ - WARNING -   Skipped train sample 4555 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,588 - __main__ - WARNING -   Skipped train sample 4556 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,590 - __main__ - WARNING -   Skipped train sample 4557 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,592 - __main__ - WARNING -   Skipped train sample 4558 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,594 - __main__ - WARNING -   Skipped train sample 4559 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,596 - __main__ - WARNING -   Skipped train sample 4560 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,599 - __main__ - WARNING -   Skipped train sample 4561 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,601 - __main__ - WARNING -   Skipped train sample 4562 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,603 - __main__ - WARNING -   Skipped train sample 4563 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,605 - __main__ - WARNING -   Skipped train sample 4564 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,607 - __main__ - WARNING -   Skipped train sample 4565 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,609 - __main__ - WARNING -   Skipped train sample 4566 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,611 - __main__ - WARNING -   Skipped train sample 4567 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,613 - __main__ - WARNING -   Skipped train sample 4568 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,615 - __main__ - WARNING -   Skipped train sample 4569 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,617 - __main__ - WARNING -   Skipped train sample 4570 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,619 - __main__ - WARNING -   Skipped train sample 4571 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,621 - __main__ - WARNING -   Skipped train sample 4572 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,623 - __main__ - WARNING -   Skipped train sample 4573 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,625 - __main__ - WARNING -   Skipped train sample 4574 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,627 - __main__ - WARNING -   Skipped train sample 4575 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,629 - __main__ - WARNING -   Skipped train sample 4576 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,631 - __main__ - WARNING -   Skipped train sample 4577 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,633 - __main__ - WARNING -   Skipped train sample 4578 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,635 - __main__ - WARNING -   Skipped train sample 4579 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,637 - __main__ - WARNING -   Skipped train sample 4580 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,639 - __main__ - WARNING -   Skipped train sample 4581 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,641 - __main__ - WARNING -   Skipped train sample 4582 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,643 - __main__ - WARNING -   Skipped train sample 4583 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,645 - __main__ - WARNING -   Skipped train sample 4584 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,647 - __main__ - WARNING -   Skipped train sample 4585 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,649 - __main__ - WARNING -   Skipped train sample 4586 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,651 - __main__ - WARNING -   Skipped train sample 4587 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,653 - __main__ - WARNING -   Skipped train sample 4588 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,655 - __main__ - WARNING -   Skipped train sample 4589 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,657 - __main__ - WARNING -   Skipped train sample 4590 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,659 - __main__ - WARNING -   Skipped train sample 4591 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,661 - __main__ - WARNING -   Skipped train sample 4592 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,663 - __main__ - WARNING -   Skipped train sample 4593 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,665 - __main__ - WARNING -   Skipped train sample 4594 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,667 - __main__ - WARNING -   Skipped train sample 4595 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,668 - __main__ - WARNING -   Skipped train sample 4596 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,671 - __main__ - WARNING -   Skipped train sample 4597 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,673 - __main__ - WARNING -   Skipped train sample 4598 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,675 - __main__ - WARNING -   Skipped train sample 4599 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,677 - __main__ - WARNING -   Skipped train sample 4600 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,679 - __main__ - WARNING -   Skipped train sample 4601 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,681 - __main__ - WARNING -   Skipped train sample 4602 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,683 - __main__ - WARNING -   Skipped train sample 4603 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,685 - __main__ - WARNING -   Skipped train sample 4604 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,687 - __main__ - WARNING -   Skipped train sample 4605 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,689 - __main__ - WARNING -   Skipped train sample 4606 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,691 - __main__ - WARNING -   Skipped train sample 4607 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,693 - __main__ - WARNING -   Skipped train sample 4608 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,695 - __main__ - WARNING -   Skipped train sample 4609 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,697 - __main__ - WARNING -   Skipped train sample 4610 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,699 - __main__ - WARNING -   Skipped train sample 4611 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,701 - __main__ - WARNING -   Skipped train sample 4612 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,703 - __main__ - WARNING -   Skipped train sample 4613 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,705 - __main__ - WARNING -   Skipped train sample 4614 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,707 - __main__ - WARNING -   Skipped train sample 4615 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,709 - __main__ - WARNING -   Skipped train sample 4616 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,711 - __main__ - WARNING -   Skipped train sample 4617 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,713 - __main__ - WARNING -   Skipped train sample 4618 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,715 - __main__ - WARNING -   Skipped train sample 4619 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,717 - __main__ - WARNING -   Skipped train sample 4620 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,719 - __main__ - WARNING -   Skipped train sample 4621 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,721 - __main__ - WARNING -   Skipped train sample 4622 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,723 - __main__ - WARNING -   Skipped train sample 4623 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,725 - __main__ - WARNING -   Skipped train sample 4624 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,727 - __main__ - WARNING -   Skipped train sample 4625 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,729 - __main__ - WARNING -   Skipped train sample 4626 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,731 - __main__ - WARNING -   Skipped train sample 4627 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,732 - __main__ - WARNING -   Skipped train sample 4628 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,735 - __main__ - WARNING -   Skipped train sample 4629 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,737 - __main__ - WARNING -   Skipped train sample 4630 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,738 - __main__ - WARNING -   Skipped train sample 4631 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,740 - __main__ - WARNING -   Skipped train sample 4632 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,742 - __main__ - WARNING -   Skipped train sample 4633 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,744 - __main__ - WARNING -   Skipped train sample 4634 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,747 - __main__ - WARNING -   Skipped train sample 4635 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,749 - __main__ - WARNING -   Skipped train sample 4636 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,751 - __main__ - WARNING -   Skipped train sample 4637 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,753 - __main__ - WARNING -   Skipped train sample 4638 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,755 - __main__ - WARNING -   Skipped train sample 4639 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,757 - __main__ - WARNING -   Skipped train sample 4640 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,759 - __main__ - WARNING -   Skipped train sample 4641 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,761 - __main__ - WARNING -   Skipped train sample 4642 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,763 - __main__ - WARNING -   Skipped train sample 4643 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,765 - __main__ - WARNING -   Skipped train sample 4644 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,767 - __main__ - WARNING -   Skipped train sample 4645 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,769 - __main__ - WARNING -   Skipped train sample 4646 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,771 - __main__ - WARNING -   Skipped train sample 4647 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,773 - __main__ - WARNING -   Skipped train sample 4648 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,775 - __main__ - WARNING -   Skipped train sample 4649 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,777 - __main__ - WARNING -   Skipped train sample 4650 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,779 - __main__ - WARNING -   Skipped train sample 4651 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,781 - __main__ - WARNING -   Skipped train sample 4652 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,783 - __main__ - WARNING -   Skipped train sample 4653 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,785 - __main__ - WARNING -   Skipped train sample 4654 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,786 - __main__ - WARNING -   Skipped train sample 4655 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,788 - __main__ - WARNING -   Skipped train sample 4656 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,790 - __main__ - WARNING -   Skipped train sample 4657 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,792 - __main__ - WARNING -   Skipped train sample 4658 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,794 - __main__ - WARNING -   Skipped train sample 4659 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,796 - __main__ - WARNING -   Skipped train sample 4660 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,798 - __main__ - WARNING -   Skipped train sample 4661 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,800 - __main__ - WARNING -   Skipped train sample 4662 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,802 - __main__ - WARNING -   Skipped train sample 4663 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,804 - __main__ - WARNING -   Skipped train sample 4664 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,807 - __main__ - WARNING -   Skipped train sample 4665 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,809 - __main__ - WARNING -   Skipped train sample 4666 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,811 - __main__ - WARNING -   Skipped train sample 4667 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,812 - __main__ - WARNING -   Skipped train sample 4668 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,814 - __main__ - WARNING -   Skipped train sample 4669 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,816 - __main__ - WARNING -   Skipped train sample 4670 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,818 - __main__ - WARNING -   Skipped train sample 4671 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,820 - __main__ - WARNING -   Skipped train sample 4672 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,822 - __main__ - WARNING -   Skipped train sample 4673 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,824 - __main__ - WARNING -   Skipped train sample 4674 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,826 - __main__ - WARNING -   Skipped train sample 4675 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,828 - __main__ - WARNING -   Skipped train sample 4676 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,830 - __main__ - WARNING -   Skipped train sample 4677 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,832 - __main__ - WARNING -   Skipped train sample 4678 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,834 - __main__ - WARNING -   Skipped train sample 4679 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,836 - __main__ - WARNING -   Skipped train sample 4680 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,838 - __main__ - WARNING -   Skipped train sample 4681 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,840 - __main__ - WARNING -   Skipped train sample 4682 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,842 - __main__ - WARNING -   Skipped train sample 4683 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,844 - __main__ - WARNING -   Skipped train sample 4684 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,846 - __main__ - WARNING -   Skipped train sample 4685 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,848 - __main__ - WARNING -   Skipped train sample 4686 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,850 - __main__ - WARNING -   Skipped train sample 4687 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,852 - __main__ - WARNING -   Skipped train sample 4688 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,854 - __main__ - WARNING -   Skipped train sample 4689 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,856 - __main__ - WARNING -   Skipped train sample 4690 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,858 - __main__ - WARNING -   Skipped train sample 4691 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,860 - __main__ - WARNING -   Skipped train sample 4692 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,862 - __main__ - WARNING -   Skipped train sample 4693 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,864 - __main__ - WARNING -   Skipped train sample 4694 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,866 - __main__ - WARNING -   Skipped train sample 4695 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,868 - __main__ - WARNING -   Skipped train sample 4696 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,870 - __main__ - WARNING -   Skipped train sample 4697 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,872 - __main__ - WARNING -   Skipped train sample 4698 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,874 - __main__ - WARNING -   Skipped train sample 4699 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,876 - __main__ - WARNING -   Skipped train sample 4700 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,878 - __main__ - WARNING -   Skipped train sample 4701 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,879 - __main__ - WARNING -   Skipped train sample 4702 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,881 - __main__ - WARNING -   Skipped train sample 4703 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,883 - __main__ - WARNING -   Skipped train sample 4704 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,885 - __main__ - WARNING -   Skipped train sample 4705 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,887 - __main__ - WARNING -   Skipped train sample 4706 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,889 - __main__ - WARNING -   Skipped train sample 4707 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,891 - __main__ - WARNING -   Skipped train sample 4708 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,894 - __main__ - WARNING -   Skipped train sample 4709 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,896 - __main__ - WARNING -   Skipped train sample 4710 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,898 - __main__ - WARNING -   Skipped train sample 4711 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,900 - __main__ - WARNING -   Skipped train sample 4712 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,901 - __main__ - WARNING -   Skipped train sample 4713 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,903 - __main__ - WARNING -   Skipped train sample 4714 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,905 - __main__ - WARNING -   Skipped train sample 4715 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,907 - __main__ - WARNING -   Skipped train sample 4716 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,909 - __main__ - WARNING -   Skipped train sample 4717 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,911 - __main__ - WARNING -   Skipped train sample 4718 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,913 - __main__ - WARNING -   Skipped train sample 4719 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,914 - __main__ - WARNING -   Skipped train sample 4720 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,916 - __main__ - WARNING -   Skipped train sample 4721 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,918 - __main__ - WARNING -   Skipped train sample 4722 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,920 - __main__ - WARNING -   Skipped train sample 4723 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,922 - __main__ - WARNING -   Skipped train sample 4724 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,924 - __main__ - WARNING -   Skipped train sample 4725 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,926 - __main__ - WARNING -   Skipped train sample 4726 due to error: invalid literal for int() with base 10: 'signer_3'
2025-09-21 22:09:43,928 - __main__ - WARNING -   Skipped train sample 4727 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,930 - __main__ - WARNING -   Skipped train sample 4728 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,932 - __main__ - WARNING -   Skipped train sample 4729 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,934 - __main__ - WARNING -   Skipped train sample 4730 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,936 - __main__ - WARNING -   Skipped train sample 4731 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,938 - __main__ - WARNING -   Skipped train sample 4732 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,940 - __main__ - WARNING -   Skipped train sample 4733 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,942 - __main__ - WARNING -   Skipped train sample 4734 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,944 - __main__ - WARNING -   Skipped train sample 4735 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,946 - __main__ - WARNING -   Skipped train sample 4736 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,948 - __main__ - WARNING -   Skipped train sample 4737 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,950 - __main__ - WARNING -   Skipped train sample 4738 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:43,951 - __main__ - WARNING -   Skipped train sample 4739 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,953 - __main__ - WARNING -   Skipped train sample 4740 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,955 - __main__ - WARNING -   Skipped train sample 4741 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,957 - __main__ - WARNING -   Skipped train sample 4742 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,959 - __main__ - WARNING -   Skipped train sample 4743 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,961 - __main__ - WARNING -   Skipped train sample 4744 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,963 - __main__ - WARNING -   Skipped train sample 4745 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,965 - __main__ - WARNING -   Skipped train sample 4746 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,966 - __main__ - WARNING -   Skipped train sample 4747 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,968 - __main__ - WARNING -   Skipped train sample 4748 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,970 - __main__ - WARNING -   Skipped train sample 4749 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,972 - __main__ - WARNING -   Skipped train sample 4750 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,974 - __main__ - WARNING -   Skipped train sample 4751 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,976 - __main__ - WARNING -   Skipped train sample 4752 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,978 - __main__ - WARNING -   Skipped train sample 4753 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,980 - __main__ - WARNING -   Skipped train sample 4754 due to error: cannot convert float NaN to integer
2025-09-21 22:09:43,982 - __main__ - WARNING -   Skipped train sample 4755 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,984 - __main__ - WARNING -   Skipped train sample 4756 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,986 - __main__ - WARNING -   Skipped train sample 4757 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,988 - __main__ - WARNING -   Skipped train sample 4758 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,990 - __main__ - WARNING -   Skipped train sample 4759 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,992 - __main__ - WARNING -   Skipped train sample 4760 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,994 - __main__ - WARNING -   Skipped train sample 4761 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:43,996 - __main__ - WARNING -   Skipped train sample 4762 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:43,998 - __main__ - WARNING -   Skipped train sample 4763 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,000 - __main__ - WARNING -   Skipped train sample 4764 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,002 - __main__ - WARNING -   Skipped train sample 4765 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,004 - __main__ - WARNING -   Skipped train sample 4766 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,006 - __main__ - WARNING -   Skipped train sample 4767 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,008 - __main__ - WARNING -   Skipped train sample 4768 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,010 - __main__ - WARNING -   Skipped train sample 4769 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,012 - __main__ - WARNING -   Skipped train sample 4770 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,014 - __main__ - WARNING -   Skipped train sample 4771 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,016 - __main__ - WARNING -   Skipped train sample 4772 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:44,018 - __main__ - WARNING -   Skipped train sample 4773 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,020 - __main__ - WARNING -   Skipped train sample 4774 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,022 - __main__ - WARNING -   Skipped train sample 4775 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,024 - __main__ - WARNING -   Skipped train sample 4776 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,026 - __main__ - WARNING -   Skipped train sample 4777 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,028 - __main__ - WARNING -   Skipped train sample 4778 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,030 - __main__ - WARNING -   Skipped train sample 4779 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,032 - __main__ - WARNING -   Skipped train sample 4780 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,035 - __main__ - WARNING -   Skipped train sample 4781 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,036 - __main__ - WARNING -   Skipped train sample 4782 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,038 - __main__ - WARNING -   Skipped train sample 4783 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,040 - __main__ - WARNING -   Skipped train sample 4784 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,042 - __main__ - WARNING -   Skipped train sample 4785 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,044 - __main__ - WARNING -   Skipped train sample 4786 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,046 - __main__ - WARNING -   Skipped train sample 4787 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,048 - __main__ - WARNING -   Skipped train sample 4788 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,050 - __main__ - WARNING -   Skipped train sample 4789 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,052 - __main__ - WARNING -   Skipped train sample 4790 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,054 - __main__ - WARNING -   Skipped train sample 4791 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,056 - __main__ - WARNING -   Skipped train sample 4792 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,058 - __main__ - WARNING -   Skipped train sample 4793 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,060 - __main__ - WARNING -   Skipped train sample 4794 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,062 - __main__ - WARNING -   Skipped train sample 4795 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,063 - __main__ - WARNING -   Skipped train sample 4796 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,066 - __main__ - WARNING -   Skipped train sample 4797 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,067 - __main__ - WARNING -   Skipped train sample 4798 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,069 - __main__ - WARNING -   Skipped train sample 4799 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,071 - __main__ - WARNING -   Skipped train sample 4800 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,073 - __main__ - WARNING -   Skipped train sample 4801 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,075 - __main__ - WARNING -   Skipped train sample 4802 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,077 - __main__ - WARNING -   Skipped train sample 4803 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,079 - __main__ - WARNING -   Skipped train sample 4804 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,081 - __main__ - WARNING -   Skipped train sample 4805 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,083 - __main__ - WARNING -   Skipped train sample 4806 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,085 - __main__ - WARNING -   Skipped train sample 4807 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,087 - __main__ - WARNING -   Skipped train sample 4808 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,089 - __main__ - WARNING -   Skipped train sample 4809 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,090 - __main__ - WARNING -   Skipped train sample 4810 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,092 - __main__ - WARNING -   Skipped train sample 4811 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,094 - __main__ - WARNING -   Skipped train sample 4812 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,096 - __main__ - WARNING -   Skipped train sample 4813 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,098 - __main__ - WARNING -   Skipped train sample 4814 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,100 - __main__ - WARNING -   Skipped train sample 4815 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,102 - __main__ - WARNING -   Skipped train sample 4816 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:44,104 - __main__ - WARNING -   Skipped train sample 4817 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,106 - __main__ - WARNING -   Skipped train sample 4818 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,108 - __main__ - WARNING -   Skipped train sample 4819 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,110 - __main__ - WARNING -   Skipped train sample 4820 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,112 - __main__ - WARNING -   Skipped train sample 4821 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,114 - __main__ - WARNING -   Skipped train sample 4822 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,116 - __main__ - WARNING -   Skipped train sample 4823 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,118 - __main__ - WARNING -   Skipped train sample 4824 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,120 - __main__ - WARNING -   Skipped train sample 4825 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,122 - __main__ - WARNING -   Skipped train sample 4826 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,123 - __main__ - WARNING -   Skipped train sample 4827 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,125 - __main__ - WARNING -   Skipped train sample 4828 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,127 - __main__ - WARNING -   Skipped train sample 4829 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,129 - __main__ - WARNING -   Skipped train sample 4830 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,131 - __main__ - WARNING -   Skipped train sample 4831 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,133 - __main__ - WARNING -   Skipped train sample 4832 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,135 - __main__ - WARNING -   Skipped train sample 4833 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,137 - __main__ - WARNING -   Skipped train sample 4834 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,139 - __main__ - WARNING -   Skipped train sample 4835 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,141 - __main__ - WARNING -   Skipped train sample 4836 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,143 - __main__ - WARNING -   Skipped train sample 4837 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,145 - __main__ - WARNING -   Skipped train sample 4838 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,147 - __main__ - WARNING -   Skipped train sample 4839 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,149 - __main__ - WARNING -   Skipped train sample 4840 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,151 - __main__ - WARNING -   Skipped train sample 4841 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,153 - __main__ - WARNING -   Skipped train sample 4842 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,155 - __main__ - WARNING -   Skipped train sample 4843 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:44,157 - __main__ - WARNING -   Skipped train sample 4844 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,158 - __main__ - WARNING -   Skipped train sample 4845 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,160 - __main__ - WARNING -   Skipped train sample 4846 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,162 - __main__ - WARNING -   Skipped train sample 4847 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,164 - __main__ - WARNING -   Skipped train sample 4848 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,166 - __main__ - WARNING -   Skipped train sample 4849 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,168 - __main__ - WARNING -   Skipped train sample 4850 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,170 - __main__ - WARNING -   Skipped train sample 4851 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,172 - __main__ - WARNING -   Skipped train sample 4852 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,174 - __main__ - WARNING -   Skipped train sample 4853 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,176 - __main__ - WARNING -   Skipped train sample 4854 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,178 - __main__ - WARNING -   Skipped train sample 4855 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,180 - __main__ - WARNING -   Skipped train sample 4856 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,182 - __main__ - WARNING -   Skipped train sample 4857 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,184 - __main__ - WARNING -   Skipped train sample 4858 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,186 - __main__ - WARNING -   Skipped train sample 4859 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,188 - __main__ - WARNING -   Skipped train sample 4860 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,190 - __main__ - WARNING -   Skipped train sample 4861 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,192 - __main__ - WARNING -   Skipped train sample 4862 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,194 - __main__ - WARNING -   Skipped train sample 4863 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,196 - __main__ - WARNING -   Skipped train sample 4864 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,198 - __main__ - WARNING -   Skipped train sample 4865 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,200 - __main__ - WARNING -   Skipped train sample 4866 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,201 - __main__ - WARNING -   Skipped train sample 4867 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,203 - __main__ - WARNING -   Skipped train sample 4868 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,205 - __main__ - WARNING -   Skipped train sample 4869 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,207 - __main__ - WARNING -   Skipped train sample 4870 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,209 - __main__ - WARNING -   Skipped train sample 4871 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,211 - __main__ - WARNING -   Skipped train sample 4872 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,213 - __main__ - WARNING -   Skipped train sample 4873 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,215 - __main__ - WARNING -   Skipped train sample 4874 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,217 - __main__ - WARNING -   Skipped train sample 4875 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,218 - __main__ - WARNING -   Skipped train sample 4876 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,220 - __main__ - WARNING -   Skipped train sample 4877 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,222 - __main__ - WARNING -   Skipped train sample 4878 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,224 - __main__ - WARNING -   Skipped train sample 4879 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,226 - __main__ - WARNING -   Skipped train sample 4880 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,228 - __main__ - WARNING -   Skipped train sample 4881 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,230 - __main__ - WARNING -   Skipped train sample 4882 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,232 - __main__ - WARNING -   Skipped train sample 4883 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,234 - __main__ - WARNING -   Skipped train sample 4884 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,236 - __main__ - WARNING -   Skipped train sample 4885 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,238 - __main__ - WARNING -   Skipped train sample 4886 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,240 - __main__ - WARNING -   Skipped train sample 4887 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,242 - __main__ - WARNING -   Skipped train sample 4888 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,244 - __main__ - WARNING -   Skipped train sample 4889 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,246 - __main__ - WARNING -   Skipped train sample 4890 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,248 - __main__ - WARNING -   Skipped train sample 4891 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,250 - __main__ - WARNING -   Skipped train sample 4892 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,252 - __main__ - WARNING -   Skipped train sample 4893 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,254 - __main__ - WARNING -   Skipped train sample 4894 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,255 - __main__ - WARNING -   Skipped train sample 4895 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,257 - __main__ - WARNING -   Skipped train sample 4896 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,259 - __main__ - WARNING -   Skipped train sample 4897 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,261 - __main__ - WARNING -   Skipped train sample 4898 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,263 - __main__ - WARNING -   Skipped train sample 4899 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,265 - __main__ - WARNING -   Skipped train sample 4900 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,267 - __main__ - WARNING -   Skipped train sample 4901 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,269 - __main__ - WARNING -   Skipped train sample 4902 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,271 - __main__ - WARNING -   Skipped train sample 4903 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,273 - __main__ - WARNING -   Skipped train sample 4904 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,275 - __main__ - WARNING -   Skipped train sample 4905 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,277 - __main__ - WARNING -   Skipped train sample 4906 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,278 - __main__ - WARNING -   Skipped train sample 4907 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,280 - __main__ - WARNING -   Skipped train sample 4908 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,282 - __main__ - WARNING -   Skipped train sample 4909 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,284 - __main__ - WARNING -   Skipped train sample 4910 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,286 - __main__ - WARNING -   Skipped train sample 4911 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,288 - __main__ - WARNING -   Skipped train sample 4912 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,290 - __main__ - WARNING -   Skipped train sample 4913 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,292 - __main__ - WARNING -   Skipped train sample 4914 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:44,294 - __main__ - WARNING -   Skipped train sample 4915 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,296 - __main__ - WARNING -   Skipped train sample 4916 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,298 - __main__ - WARNING -   Skipped train sample 4917 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,300 - __main__ - WARNING -   Skipped train sample 4918 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,302 - __main__ - WARNING -   Skipped train sample 4919 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,304 - __main__ - WARNING -   Skipped train sample 4920 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,306 - __main__ - WARNING -   Skipped train sample 4921 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,308 - __main__ - WARNING -   Skipped train sample 4922 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,310 - __main__ - WARNING -   Skipped train sample 4923 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,312 - __main__ - WARNING -   Skipped train sample 4924 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,314 - __main__ - WARNING -   Skipped train sample 4925 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,316 - __main__ - WARNING -   Skipped train sample 4926 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,318 - __main__ - WARNING -   Skipped train sample 4927 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,320 - __main__ - WARNING -   Skipped train sample 4928 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,322 - __main__ - WARNING -   Skipped train sample 4929 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,323 - __main__ - WARNING -   Skipped train sample 4930 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,325 - __main__ - WARNING -   Skipped train sample 4931 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,327 - __main__ - WARNING -   Skipped train sample 4932 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,329 - __main__ - WARNING -   Skipped train sample 4933 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:44,331 - __main__ - WARNING -   Skipped train sample 4934 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,333 - __main__ - WARNING -   Skipped train sample 4935 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,335 - __main__ - WARNING -   Skipped train sample 4936 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,337 - __main__ - WARNING -   Skipped train sample 4937 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,339 - __main__ - WARNING -   Skipped train sample 4938 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,341 - __main__ - WARNING -   Skipped train sample 4939 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,342 - __main__ - WARNING -   Skipped train sample 4940 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,344 - __main__ - WARNING -   Skipped train sample 4941 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,346 - __main__ - WARNING -   Skipped train sample 4942 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,348 - __main__ - WARNING -   Skipped train sample 4943 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,350 - __main__ - WARNING -   Skipped train sample 4944 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,352 - __main__ - WARNING -   Skipped train sample 4945 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,354 - __main__ - WARNING -   Skipped train sample 4946 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,356 - __main__ - WARNING -   Skipped train sample 4947 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,358 - __main__ - WARNING -   Skipped train sample 4948 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,360 - __main__ - WARNING -   Skipped train sample 4949 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,362 - __main__ - WARNING -   Skipped train sample 4950 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,364 - __main__ - WARNING -   Skipped train sample 4951 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,366 - __main__ - WARNING -   Skipped train sample 4952 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,368 - __main__ - WARNING -   Skipped train sample 4953 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,370 - __main__ - WARNING -   Skipped train sample 4954 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,371 - __main__ - WARNING -   Skipped train sample 4955 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,373 - __main__ - WARNING -   Skipped train sample 4956 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:44,375 - __main__ - WARNING -   Skipped train sample 4957 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,377 - __main__ - WARNING -   Skipped train sample 4958 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,379 - __main__ - WARNING -   Skipped train sample 4959 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,381 - __main__ - WARNING -   Skipped train sample 4960 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,383 - __main__ - WARNING -   Skipped train sample 4961 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,384 - __main__ - WARNING -   Skipped train sample 4962 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,386 - __main__ - WARNING -   Skipped train sample 4963 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,388 - __main__ - WARNING -   Skipped train sample 4964 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,390 - __main__ - WARNING -   Skipped train sample 4965 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,392 - __main__ - WARNING -   Skipped train sample 4966 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,394 - __main__ - WARNING -   Skipped train sample 4967 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,396 - __main__ - WARNING -   Skipped train sample 4968 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,398 - __main__ - WARNING -   Skipped train sample 4969 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,400 - __main__ - WARNING -   Skipped train sample 4970 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,402 - __main__ - WARNING -   Skipped train sample 4971 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,403 - __main__ - WARNING -   Skipped train sample 4972 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,405 - __main__ - WARNING -   Skipped train sample 4973 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,407 - __main__ - WARNING -   Skipped train sample 4974 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,409 - __main__ - WARNING -   Skipped train sample 4975 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,411 - __main__ - WARNING -   Skipped train sample 4976 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,413 - __main__ - WARNING -   Skipped train sample 4977 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,415 - __main__ - WARNING -   Skipped train sample 4978 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,417 - __main__ - WARNING -   Skipped train sample 4979 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,419 - __main__ - WARNING -   Skipped train sample 4980 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,421 - __main__ - WARNING -   Skipped train sample 4981 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,423 - __main__ - WARNING -   Skipped train sample 4982 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,425 - __main__ - WARNING -   Skipped train sample 4983 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,427 - __main__ - WARNING -   Skipped train sample 4984 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,428 - __main__ - WARNING -   Skipped train sample 4985 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,430 - __main__ - WARNING -   Skipped train sample 4986 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,432 - __main__ - WARNING -   Skipped train sample 4987 due to error: invalid literal for int() with base 10: 'signer_2'
2025-09-21 22:09:44,434 - __main__ - WARNING -   Skipped train sample 4988 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,436 - __main__ - WARNING -   Skipped train sample 4989 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,438 - __main__ - WARNING -   Skipped train sample 4990 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,440 - __main__ - WARNING -   Skipped train sample 4991 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,442 - __main__ - WARNING -   Skipped train sample 4992 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,444 - __main__ - WARNING -   Skipped train sample 4993 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,446 - __main__ - WARNING -   Skipped train sample 4994 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,448 - __main__ - WARNING -   Skipped train sample 4995 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,450 - __main__ - WARNING -   Skipped train sample 4996 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,452 - __main__ - WARNING -   Skipped train sample 4997 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,454 - __main__ - WARNING -   Skipped train sample 4998 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,456 - __main__ - WARNING -   Skipped train sample 4999 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,456 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-21 22:09:44,458 - __main__ - WARNING -   Skipped train sample 5000 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,460 - __main__ - WARNING -   Skipped train sample 5001 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,461 - __main__ - WARNING -   Skipped train sample 5002 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,464 - __main__ - WARNING -   Skipped train sample 5003 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,466 - __main__ - WARNING -   Skipped train sample 5004 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,468 - __main__ - WARNING -   Skipped train sample 5005 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,470 - __main__ - WARNING -   Skipped train sample 5006 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,471 - __main__ - WARNING -   Skipped train sample 5007 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,473 - __main__ - WARNING -   Skipped train sample 5008 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,475 - __main__ - WARNING -   Skipped train sample 5009 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,477 - __main__ - WARNING -   Skipped train sample 5010 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,479 - __main__ - WARNING -   Skipped train sample 5011 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,481 - __main__ - WARNING -   Skipped train sample 5012 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,483 - __main__ - WARNING -   Skipped train sample 5013 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,484 - __main__ - WARNING -   Skipped train sample 5014 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,486 - __main__ - WARNING -   Skipped train sample 5015 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,488 - __main__ - WARNING -   Skipped train sample 5016 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,490 - __main__ - WARNING -   Skipped train sample 5017 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,492 - __main__ - WARNING -   Skipped train sample 5018 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,494 - __main__ - WARNING -   Skipped train sample 5019 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,496 - __main__ - WARNING -   Skipped train sample 5020 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,498 - __main__ - WARNING -   Skipped train sample 5021 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,500 - __main__ - WARNING -   Skipped train sample 5022 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,502 - __main__ - WARNING -   Skipped train sample 5023 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,504 - __main__ - WARNING -   Skipped train sample 5024 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,506 - __main__ - WARNING -   Skipped train sample 5025 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,508 - __main__ - WARNING -   Skipped train sample 5026 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,510 - __main__ - WARNING -   Skipped train sample 5027 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,512 - __main__ - WARNING -   Skipped train sample 5028 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,514 - __main__ - WARNING -   Skipped train sample 5029 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,516 - __main__ - WARNING -   Skipped train sample 5030 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,518 - __main__ - WARNING -   Skipped train sample 5031 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,520 - __main__ - WARNING -   Skipped train sample 5032 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,522 - __main__ - WARNING -   Skipped train sample 5033 due to error: cannot convert float NaN to integer
2025-09-21 22:09:44,523 - __main__ - WARNING -   Skipped train sample 5034 due to error: invalid literal for int() with base 10: 'signer_1'
2025-09-21 22:09:44,525 - __main__ - WARNING -   Skipped train sample 5035 due to error: invalid literal for int() with base 10: 'signer_0'
2025-09-21 22:09:44,527 - __main__ - WARNING -   Skipped train sample 5036 due to error: cannot convert float NaN to integer
2025-09-21 22:12:29,537 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-21 22:12:29,537 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 22:12:29,537 - __main__ - INFO - Starting training pipeline
2025-09-21 22:12:29,639 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-21 22:12:29,663 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-21 22:12:29,663 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-21 22:12:29,663 - __main__ - INFO - Loading training data...
2025-09-21 22:12:37,131 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-21 22:12:37,132 - __main__ - INFO - Processing train split...
2025-09-21 22:12:37,196 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-21 22:12:37,196 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-21 22:12:37,269 - __main__ - WARNING -   Skipped train sample 0 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,274 - __main__ - WARNING -   Skipped train sample 1 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,282 - __main__ - WARNING -   Skipped train sample 2 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,287 - __main__ - WARNING -   Skipped train sample 3 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,293 - __main__ - WARNING -   Skipped train sample 4 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,299 - __main__ - WARNING -   Skipped train sample 5 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,304 - __main__ - WARNING -   Skipped train sample 6 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,308 - __main__ - WARNING -   Skipped train sample 7 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,313 - __main__ - WARNING -   Skipped train sample 8 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,320 - __main__ - WARNING -   Skipped train sample 9 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,334 - __main__ - WARNING -   Skipped train sample 10 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,340 - __main__ - WARNING -   Skipped train sample 11 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,345 - __main__ - WARNING -   Skipped train sample 12 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,352 - __main__ - WARNING -   Skipped train sample 13 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,358 - __main__ - WARNING -   Skipped train sample 14 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,361 - __main__ - WARNING -   Skipped train sample 15 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,369 - __main__ - WARNING -   Skipped train sample 16 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,375 - __main__ - WARNING -   Skipped train sample 17 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,380 - __main__ - WARNING -   Skipped train sample 18 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,390 - __main__ - WARNING -   Skipped train sample 19 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,395 - __main__ - WARNING -   Skipped train sample 20 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,400 - __main__ - WARNING -   Skipped train sample 21 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,404 - __main__ - WARNING -   Skipped train sample 22 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,413 - __main__ - WARNING -   Skipped train sample 23 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,416 - __main__ - WARNING -   Skipped train sample 24 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,497 - __main__ - WARNING -   Skipped train sample 25 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,503 - __main__ - WARNING -   Skipped train sample 26 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,511 - __main__ - WARNING -   Skipped train sample 27 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,519 - __main__ - WARNING -   Skipped train sample 28 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,526 - __main__ - WARNING -   Skipped train sample 29 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,533 - __main__ - WARNING -   Skipped train sample 30 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,538 - __main__ - WARNING -   Skipped train sample 31 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,545 - __main__ - WARNING -   Skipped train sample 32 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,549 - __main__ - WARNING -   Skipped train sample 33 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,563 - __main__ - WARNING -   Skipped train sample 34 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,566 - __main__ - WARNING -   Skipped train sample 35 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,577 - __main__ - WARNING -   Skipped train sample 36 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,584 - __main__ - WARNING -   Skipped train sample 37 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,591 - __main__ - WARNING -   Skipped train sample 38 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,599 - __main__ - WARNING -   Skipped train sample 39 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,604 - __main__ - WARNING -   Skipped train sample 40 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,609 - __main__ - WARNING -   Skipped train sample 41 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,613 - __main__ - WARNING -   Skipped train sample 42 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,619 - __main__ - WARNING -   Skipped train sample 43 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,626 - __main__ - WARNING -   Skipped train sample 44 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,632 - __main__ - WARNING -   Skipped train sample 45 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,636 - __main__ - WARNING -   Skipped train sample 46 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,641 - __main__ - WARNING -   Skipped train sample 47 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,648 - __main__ - WARNING -   Skipped train sample 48 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,651 - __main__ - WARNING -   Skipped train sample 49 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,664 - __main__ - WARNING -   Skipped train sample 50 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,674 - __main__ - WARNING -   Skipped train sample 51 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,679 - __main__ - WARNING -   Skipped train sample 52 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,682 - __main__ - WARNING -   Skipped train sample 53 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,689 - __main__ - WARNING -   Skipped train sample 54 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,693 - __main__ - WARNING -   Skipped train sample 55 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,703 - __main__ - WARNING -   Skipped train sample 56 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,707 - __main__ - WARNING -   Skipped train sample 57 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,715 - __main__ - WARNING -   Skipped train sample 58 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,719 - __main__ - WARNING -   Skipped train sample 59 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,723 - __main__ - WARNING -   Skipped train sample 60 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,733 - __main__ - WARNING -   Skipped train sample 61 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,747 - __main__ - WARNING -   Skipped train sample 62 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,756 - __main__ - WARNING -   Skipped train sample 63 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,761 - __main__ - WARNING -   Skipped train sample 64 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,768 - __main__ - WARNING -   Skipped train sample 65 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,773 - __main__ - WARNING -   Skipped train sample 66 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,780 - __main__ - WARNING -   Skipped train sample 67 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,788 - __main__ - WARNING -   Skipped train sample 68 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,797 - __main__ - WARNING -   Skipped train sample 69 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,805 - __main__ - WARNING -   Skipped train sample 70 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,810 - __main__ - WARNING -   Skipped train sample 71 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,836 - __main__ - WARNING -   Skipped train sample 72 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,841 - __main__ - WARNING -   Skipped train sample 73 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,847 - __main__ - WARNING -   Skipped train sample 74 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,851 - __main__ - WARNING -   Skipped train sample 75 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,859 - __main__ - WARNING -   Skipped train sample 76 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,864 - __main__ - WARNING -   Skipped train sample 77 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,871 - __main__ - WARNING -   Skipped train sample 78 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,879 - __main__ - WARNING -   Skipped train sample 79 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,885 - __main__ - WARNING -   Skipped train sample 80 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,895 - __main__ - WARNING -   Skipped train sample 81 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,899 - __main__ - WARNING -   Skipped train sample 82 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,905 - __main__ - WARNING -   Skipped train sample 83 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,910 - __main__ - WARNING -   Skipped train sample 84 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,923 - __main__ - WARNING -   Skipped train sample 85 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,934 - __main__ - WARNING -   Skipped train sample 86 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,940 - __main__ - WARNING -   Skipped train sample 87 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,945 - __main__ - WARNING -   Skipped train sample 88 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,949 - __main__ - WARNING -   Skipped train sample 89 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,955 - __main__ - WARNING -   Skipped train sample 90 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,961 - __main__ - WARNING -   Skipped train sample 91 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,964 - __main__ - WARNING -   Skipped train sample 92 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,968 - __main__ - WARNING -   Skipped train sample 93 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,972 - __main__ - WARNING -   Skipped train sample 94 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,982 - __main__ - WARNING -   Skipped train sample 95 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:37,996 - __main__ - WARNING -   Skipped train sample 96 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,001 - __main__ - WARNING -   Skipped train sample 97 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,006 - __main__ - WARNING -   Skipped train sample 98 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,012 - __main__ - WARNING -   Skipped train sample 99 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,018 - __main__ - WARNING -   Skipped train sample 100 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,022 - __main__ - WARNING -   Skipped train sample 101 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,029 - __main__ - WARNING -   Skipped train sample 102 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,035 - __main__ - WARNING -   Skipped train sample 103 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,039 - __main__ - WARNING -   Skipped train sample 104 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,045 - __main__ - WARNING -   Skipped train sample 105 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,049 - __main__ - WARNING -   Skipped train sample 106 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,059 - __main__ - WARNING -   Skipped train sample 107 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,066 - __main__ - WARNING -   Skipped train sample 108 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,071 - __main__ - WARNING -   Skipped train sample 109 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,076 - __main__ - WARNING -   Skipped train sample 110 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,083 - __main__ - WARNING -   Skipped train sample 111 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,088 - __main__ - WARNING -   Skipped train sample 112 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,097 - __main__ - WARNING -   Skipped train sample 113 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,102 - __main__ - WARNING -   Skipped train sample 114 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,107 - __main__ - WARNING -   Skipped train sample 115 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,111 - __main__ - WARNING -   Skipped train sample 116 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,116 - __main__ - WARNING -   Skipped train sample 117 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,125 - __main__ - WARNING -   Skipped train sample 118 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,129 - __main__ - WARNING -   Skipped train sample 119 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,139 - __main__ - WARNING -   Skipped train sample 120 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,144 - __main__ - WARNING -   Skipped train sample 121 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,148 - __main__ - WARNING -   Skipped train sample 122 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,152 - __main__ - WARNING -   Skipped train sample 123 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,158 - __main__ - WARNING -   Skipped train sample 124 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,161 - __main__ - WARNING -   Skipped train sample 125 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,165 - __main__ - WARNING -   Skipped train sample 126 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,170 - __main__ - WARNING -   Skipped train sample 127 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,179 - __main__ - WARNING -   Skipped train sample 128 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,185 - __main__ - WARNING -   Skipped train sample 129 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,189 - __main__ - WARNING -   Skipped train sample 130 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,193 - __main__ - WARNING -   Skipped train sample 131 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,201 - __main__ - WARNING -   Skipped train sample 132 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,205 - __main__ - WARNING -   Skipped train sample 133 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,210 - __main__ - WARNING -   Skipped train sample 134 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,223 - __main__ - WARNING -   Skipped train sample 135 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,228 - __main__ - WARNING -   Skipped train sample 136 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,236 - __main__ - WARNING -   Skipped train sample 137 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,243 - __main__ - WARNING -   Skipped train sample 138 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,248 - __main__ - WARNING -   Skipped train sample 139 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,252 - __main__ - WARNING -   Skipped train sample 140 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,262 - __main__ - WARNING -   Skipped train sample 141 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,267 - __main__ - WARNING -   Skipped train sample 142 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,275 - __main__ - WARNING -   Skipped train sample 143 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,284 - __main__ - WARNING -   Skipped train sample 144 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,292 - __main__ - WARNING -   Skipped train sample 145 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,296 - __main__ - WARNING -   Skipped train sample 146 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,300 - __main__ - WARNING -   Skipped train sample 147 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,312 - __main__ - WARNING -   Skipped train sample 148 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,318 - __main__ - WARNING -   Skipped train sample 149 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,324 - __main__ - WARNING -   Skipped train sample 150 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,331 - __main__ - WARNING -   Skipped train sample 151 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,336 - __main__ - WARNING -   Skipped train sample 152 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,342 - __main__ - WARNING -   Skipped train sample 153 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,346 - __main__ - WARNING -   Skipped train sample 154 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,351 - __main__ - WARNING -   Skipped train sample 155 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,357 - __main__ - WARNING -   Skipped train sample 156 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,361 - __main__ - WARNING -   Skipped train sample 157 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,368 - __main__ - WARNING -   Skipped train sample 158 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,375 - __main__ - WARNING -   Skipped train sample 159 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,379 - __main__ - WARNING -   Skipped train sample 160 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,388 - __main__ - WARNING -   Skipped train sample 161 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,401 - __main__ - WARNING -   Skipped train sample 162 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,405 - __main__ - WARNING -   Skipped train sample 163 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,420 - __main__ - WARNING -   Skipped train sample 164 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,426 - __main__ - WARNING -   Skipped train sample 165 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,432 - __main__ - WARNING -   Skipped train sample 166 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,439 - __main__ - WARNING -   Skipped train sample 167 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,444 - __main__ - WARNING -   Skipped train sample 168 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,448 - __main__ - WARNING -   Skipped train sample 169 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,454 - __main__ - WARNING -   Skipped train sample 170 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,458 - __main__ - WARNING -   Skipped train sample 171 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,467 - __main__ - WARNING -   Skipped train sample 172 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,473 - __main__ - WARNING -   Skipped train sample 173 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,479 - __main__ - WARNING -   Skipped train sample 174 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,490 - __main__ - WARNING -   Skipped train sample 175 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,495 - __main__ - WARNING -   Skipped train sample 176 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,500 - __main__ - WARNING -   Skipped train sample 177 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,505 - __main__ - WARNING -   Skipped train sample 178 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,512 - __main__ - WARNING -   Skipped train sample 179 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,519 - __main__ - WARNING -   Skipped train sample 180 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,523 - __main__ - WARNING -   Skipped train sample 181 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,527 - __main__ - WARNING -   Skipped train sample 182 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,536 - __main__ - WARNING -   Skipped train sample 183 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,544 - __main__ - WARNING -   Skipped train sample 184 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,551 - __main__ - WARNING -   Skipped train sample 185 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,555 - __main__ - WARNING -   Skipped train sample 186 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,559 - __main__ - WARNING -   Skipped train sample 187 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,564 - __main__ - WARNING -   Skipped train sample 188 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,568 - __main__ - WARNING -   Skipped train sample 189 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,578 - __main__ - WARNING -   Skipped train sample 190 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,585 - __main__ - WARNING -   Skipped train sample 191 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,589 - __main__ - WARNING -   Skipped train sample 192 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,595 - __main__ - WARNING -   Skipped train sample 193 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,606 - __main__ - WARNING -   Skipped train sample 194 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,613 - __main__ - WARNING -   Skipped train sample 195 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,617 - __main__ - WARNING -   Skipped train sample 196 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,629 - __main__ - WARNING -   Skipped train sample 197 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,639 - __main__ - WARNING -   Skipped train sample 198 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,645 - __main__ - WARNING -   Skipped train sample 199 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,654 - __main__ - WARNING -   Skipped train sample 200 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,658 - __main__ - WARNING -   Skipped train sample 201 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,664 - __main__ - WARNING -   Skipped train sample 202 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,670 - __main__ - WARNING -   Skipped train sample 203 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,674 - __main__ - WARNING -   Skipped train sample 204 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,683 - __main__ - WARNING -   Skipped train sample 205 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,689 - __main__ - WARNING -   Skipped train sample 206 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,702 - __main__ - WARNING -   Skipped train sample 207 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,707 - __main__ - WARNING -   Skipped train sample 208 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,715 - __main__ - WARNING -   Skipped train sample 209 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,720 - __main__ - WARNING -   Skipped train sample 210 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,724 - __main__ - WARNING -   Skipped train sample 211 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,729 - __main__ - WARNING -   Skipped train sample 212 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,734 - __main__ - WARNING -   Skipped train sample 213 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,739 - __main__ - WARNING -   Skipped train sample 214 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,743 - __main__ - WARNING -   Skipped train sample 215 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,747 - __main__ - WARNING -   Skipped train sample 216 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,753 - __main__ - WARNING -   Skipped train sample 217 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,758 - __main__ - WARNING -   Skipped train sample 218 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,767 - __main__ - WARNING -   Skipped train sample 219 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,771 - __main__ - WARNING -   Skipped train sample 220 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,784 - __main__ - WARNING -   Skipped train sample 221 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,796 - __main__ - WARNING -   Skipped train sample 222 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,805 - __main__ - WARNING -   Skipped train sample 223 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,812 - __main__ - WARNING -   Skipped train sample 224 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,819 - __main__ - WARNING -   Skipped train sample 225 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,823 - __main__ - WARNING -   Skipped train sample 226 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,827 - __main__ - WARNING -   Skipped train sample 227 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,833 - __main__ - WARNING -   Skipped train sample 228 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,839 - __main__ - WARNING -   Skipped train sample 229 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,853 - __main__ - WARNING -   Skipped train sample 230 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,863 - __main__ - WARNING -   Skipped train sample 231 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,878 - __main__ - WARNING -   Skipped train sample 232 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,883 - __main__ - WARNING -   Skipped train sample 233 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,887 - __main__ - WARNING -   Skipped train sample 234 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,893 - __main__ - WARNING -   Skipped train sample 235 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,898 - __main__ - WARNING -   Skipped train sample 236 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,904 - __main__ - WARNING -   Skipped train sample 237 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,910 - __main__ - WARNING -   Skipped train sample 238 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,917 - __main__ - WARNING -   Skipped train sample 239 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,934 - __main__ - WARNING -   Skipped train sample 240 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,944 - __main__ - WARNING -   Skipped train sample 241 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,951 - __main__ - WARNING -   Skipped train sample 242 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,956 - __main__ - WARNING -   Skipped train sample 243 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,962 - __main__ - WARNING -   Skipped train sample 244 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,967 - __main__ - WARNING -   Skipped train sample 245 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,975 - __main__ - WARNING -   Skipped train sample 246 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:38,980 - __main__ - WARNING -   Skipped train sample 247 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,004 - __main__ - WARNING -   Skipped train sample 248 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,014 - __main__ - WARNING -   Skipped train sample 249 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,018 - __main__ - WARNING -   Skipped train sample 250 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,028 - __main__ - WARNING -   Skipped train sample 251 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,035 - __main__ - WARNING -   Skipped train sample 252 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,045 - __main__ - WARNING -   Skipped train sample 253 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,053 - __main__ - WARNING -   Skipped train sample 254 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,057 - __main__ - WARNING -   Skipped train sample 255 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,062 - __main__ - WARNING -   Skipped train sample 256 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,070 - __main__ - WARNING -   Skipped train sample 257 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,077 - __main__ - WARNING -   Skipped train sample 258 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,083 - __main__ - WARNING -   Skipped train sample 259 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,090 - __main__ - WARNING -   Skipped train sample 260 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,101 - __main__ - WARNING -   Skipped train sample 261 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,106 - __main__ - WARNING -   Skipped train sample 262 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,111 - __main__ - WARNING -   Skipped train sample 263 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,116 - __main__ - WARNING -   Skipped train sample 264 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,124 - __main__ - WARNING -   Skipped train sample 265 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,131 - __main__ - WARNING -   Skipped train sample 266 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,140 - __main__ - WARNING -   Skipped train sample 267 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,144 - __main__ - WARNING -   Skipped train sample 268 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,151 - __main__ - WARNING -   Skipped train sample 269 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,160 - __main__ - WARNING -   Skipped train sample 270 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,165 - __main__ - WARNING -   Skipped train sample 271 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,176 - __main__ - WARNING -   Skipped train sample 272 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,184 - __main__ - WARNING -   Skipped train sample 273 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,189 - __main__ - WARNING -   Skipped train sample 274 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,197 - __main__ - WARNING -   Skipped train sample 275 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,205 - __main__ - WARNING -   Skipped train sample 276 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,211 - __main__ - WARNING -   Skipped train sample 277 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,219 - __main__ - WARNING -   Skipped train sample 278 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,225 - __main__ - WARNING -   Skipped train sample 279 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,233 - __main__ - WARNING -   Skipped train sample 280 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,241 - __main__ - WARNING -   Skipped train sample 281 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,246 - __main__ - WARNING -   Skipped train sample 282 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,256 - __main__ - WARNING -   Skipped train sample 283 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,279 - __main__ - WARNING -   Skipped train sample 284 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,289 - __main__ - WARNING -   Skipped train sample 285 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,299 - __main__ - WARNING -   Skipped train sample 286 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,305 - __main__ - WARNING -   Skipped train sample 287 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,311 - __main__ - WARNING -   Skipped train sample 288 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,316 - __main__ - WARNING -   Skipped train sample 289 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,323 - __main__ - WARNING -   Skipped train sample 290 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,328 - __main__ - WARNING -   Skipped train sample 291 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,336 - __main__ - WARNING -   Skipped train sample 292 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,341 - __main__ - WARNING -   Skipped train sample 293 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,347 - __main__ - WARNING -   Skipped train sample 294 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,355 - __main__ - WARNING -   Skipped train sample 295 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,365 - __main__ - WARNING -   Skipped train sample 296 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,372 - __main__ - WARNING -   Skipped train sample 297 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,378 - __main__ - WARNING -   Skipped train sample 298 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,384 - __main__ - WARNING -   Skipped train sample 299 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,401 - __main__ - WARNING -   Skipped train sample 300 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,411 - __main__ - WARNING -   Skipped train sample 301 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,417 - __main__ - WARNING -   Skipped train sample 302 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,425 - __main__ - WARNING -   Skipped train sample 303 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,432 - __main__ - WARNING -   Skipped train sample 304 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,438 - __main__ - WARNING -   Skipped train sample 305 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,444 - __main__ - WARNING -   Skipped train sample 306 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,451 - __main__ - WARNING -   Skipped train sample 307 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,457 - __main__ - WARNING -   Skipped train sample 308 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,465 - __main__ - WARNING -   Skipped train sample 309 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,476 - __main__ - WARNING -   Skipped train sample 310 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,486 - __main__ - WARNING -   Skipped train sample 311 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,500 - __main__ - WARNING -   Skipped train sample 312 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,506 - __main__ - WARNING -   Skipped train sample 313 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,511 - __main__ - WARNING -   Skipped train sample 314 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,520 - __main__ - WARNING -   Skipped train sample 315 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,525 - __main__ - WARNING -   Skipped train sample 316 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,530 - __main__ - WARNING -   Skipped train sample 317 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,537 - __main__ - WARNING -   Skipped train sample 318 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,542 - __main__ - WARNING -   Skipped train sample 319 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,549 - __main__ - WARNING -   Skipped train sample 320 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,569 - __main__ - WARNING -   Skipped train sample 321 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,575 - __main__ - WARNING -   Skipped train sample 322 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,591 - __main__ - WARNING -   Skipped train sample 323 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,596 - __main__ - WARNING -   Skipped train sample 324 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,603 - __main__ - WARNING -   Skipped train sample 325 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,621 - __main__ - WARNING -   Skipped train sample 326 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,626 - __main__ - WARNING -   Skipped train sample 327 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,635 - __main__ - WARNING -   Skipped train sample 328 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,640 - __main__ - WARNING -   Skipped train sample 329 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,646 - __main__ - WARNING -   Skipped train sample 330 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,651 - __main__ - WARNING -   Skipped train sample 331 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,657 - __main__ - WARNING -   Skipped train sample 332 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,670 - __main__ - WARNING -   Skipped train sample 333 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,676 - __main__ - WARNING -   Skipped train sample 334 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,683 - __main__ - WARNING -   Skipped train sample 335 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,689 - __main__ - WARNING -   Skipped train sample 336 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,695 - __main__ - WARNING -   Skipped train sample 337 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,699 - __main__ - WARNING -   Skipped train sample 338 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,707 - __main__ - WARNING -   Skipped train sample 339 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,717 - __main__ - WARNING -   Skipped train sample 340 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,729 - __main__ - WARNING -   Skipped train sample 341 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,757 - __main__ - WARNING -   Skipped train sample 342 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,766 - __main__ - WARNING -   Skipped train sample 343 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,775 - __main__ - WARNING -   Skipped train sample 344 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,781 - __main__ - WARNING -   Skipped train sample 345 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,788 - __main__ - WARNING -   Skipped train sample 346 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,793 - __main__ - WARNING -   Skipped train sample 347 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,801 - __main__ - WARNING -   Skipped train sample 348 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,813 - __main__ - WARNING -   Skipped train sample 349 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,823 - __main__ - WARNING -   Skipped train sample 350 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,829 - __main__ - WARNING -   Skipped train sample 351 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,834 - __main__ - WARNING -   Skipped train sample 352 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,838 - __main__ - WARNING -   Skipped train sample 353 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,849 - __main__ - WARNING -   Skipped train sample 354 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,853 - __main__ - WARNING -   Skipped train sample 355 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,859 - __main__ - WARNING -   Skipped train sample 356 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,866 - __main__ - WARNING -   Skipped train sample 357 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,870 - __main__ - WARNING -   Skipped train sample 358 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,876 - __main__ - WARNING -   Skipped train sample 359 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,881 - __main__ - WARNING -   Skipped train sample 360 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,892 - __main__ - WARNING -   Skipped train sample 361 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,902 - __main__ - WARNING -   Skipped train sample 362 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,912 - __main__ - WARNING -   Skipped train sample 363 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,921 - __main__ - WARNING -   Skipped train sample 364 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,934 - __main__ - WARNING -   Skipped train sample 365 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,939 - __main__ - WARNING -   Skipped train sample 366 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,948 - __main__ - WARNING -   Skipped train sample 367 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,952 - __main__ - WARNING -   Skipped train sample 368 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,956 - __main__ - WARNING -   Skipped train sample 369 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,962 - __main__ - WARNING -   Skipped train sample 370 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,967 - __main__ - WARNING -   Skipped train sample 371 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,973 - __main__ - WARNING -   Skipped train sample 372 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:39,990 - __main__ - WARNING -   Skipped train sample 373 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,003 - __main__ - WARNING -   Skipped train sample 374 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,018 - __main__ - WARNING -   Skipped train sample 375 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,024 - __main__ - WARNING -   Skipped train sample 376 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,029 - __main__ - WARNING -   Skipped train sample 377 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,033 - __main__ - WARNING -   Skipped train sample 378 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,038 - __main__ - WARNING -   Skipped train sample 379 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,046 - __main__ - WARNING -   Skipped train sample 380 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,051 - __main__ - WARNING -   Skipped train sample 381 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,058 - __main__ - WARNING -   Skipped train sample 382 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,067 - __main__ - WARNING -   Skipped train sample 383 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,073 - __main__ - WARNING -   Skipped train sample 384 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,081 - __main__ - WARNING -   Skipped train sample 385 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,089 - __main__ - WARNING -   Skipped train sample 386 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,098 - __main__ - WARNING -   Skipped train sample 387 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,103 - __main__ - WARNING -   Skipped train sample 388 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,108 - __main__ - WARNING -   Skipped train sample 389 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,116 - __main__ - WARNING -   Skipped train sample 390 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,124 - __main__ - WARNING -   Skipped train sample 391 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,134 - __main__ - WARNING -   Skipped train sample 392 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,140 - __main__ - WARNING -   Skipped train sample 393 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,147 - __main__ - WARNING -   Skipped train sample 394 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,152 - __main__ - WARNING -   Skipped train sample 395 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,156 - __main__ - WARNING -   Skipped train sample 396 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,163 - __main__ - WARNING -   Skipped train sample 397 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,174 - __main__ - WARNING -   Skipped train sample 398 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,180 - __main__ - WARNING -   Skipped train sample 399 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,186 - __main__ - WARNING -   Skipped train sample 400 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,193 - __main__ - WARNING -   Skipped train sample 401 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,198 - __main__ - WARNING -   Skipped train sample 402 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,208 - __main__ - WARNING -   Skipped train sample 403 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,216 - __main__ - WARNING -   Skipped train sample 404 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,224 - __main__ - WARNING -   Skipped train sample 405 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,232 - __main__ - WARNING -   Skipped train sample 406 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,244 - __main__ - WARNING -   Skipped train sample 407 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,249 - __main__ - WARNING -   Skipped train sample 408 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,256 - __main__ - WARNING -   Skipped train sample 409 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,262 - __main__ - WARNING -   Skipped train sample 410 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,272 - __main__ - WARNING -   Skipped train sample 411 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,288 - __main__ - WARNING -   Skipped train sample 412 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,294 - __main__ - WARNING -   Skipped train sample 413 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,299 - __main__ - WARNING -   Skipped train sample 414 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,306 - __main__ - WARNING -   Skipped train sample 415 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,313 - __main__ - WARNING -   Skipped train sample 416 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,320 - __main__ - WARNING -   Skipped train sample 417 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,327 - __main__ - WARNING -   Skipped train sample 418 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,340 - __main__ - WARNING -   Skipped train sample 419 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,345 - __main__ - WARNING -   Skipped train sample 420 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,351 - __main__ - WARNING -   Skipped train sample 421 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,359 - __main__ - WARNING -   Skipped train sample 422 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,366 - __main__ - WARNING -   Skipped train sample 423 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,371 - __main__ - WARNING -   Skipped train sample 424 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,380 - __main__ - WARNING -   Skipped train sample 425 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,389 - __main__ - WARNING -   Skipped train sample 426 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,394 - __main__ - WARNING -   Skipped train sample 427 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,403 - __main__ - WARNING -   Skipped train sample 428 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,409 - __main__ - WARNING -   Skipped train sample 429 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,419 - __main__ - WARNING -   Skipped train sample 430 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,424 - __main__ - WARNING -   Skipped train sample 431 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,428 - __main__ - WARNING -   Skipped train sample 432 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,435 - __main__ - WARNING -   Skipped train sample 433 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,443 - __main__ - WARNING -   Skipped train sample 434 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,452 - __main__ - WARNING -   Skipped train sample 435 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,456 - __main__ - WARNING -   Skipped train sample 436 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,462 - __main__ - WARNING -   Skipped train sample 437 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,466 - __main__ - WARNING -   Skipped train sample 438 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,471 - __main__ - WARNING -   Skipped train sample 439 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,476 - __main__ - WARNING -   Skipped train sample 440 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,491 - __main__ - WARNING -   Skipped train sample 441 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,497 - __main__ - WARNING -   Skipped train sample 442 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,501 - __main__ - WARNING -   Skipped train sample 443 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,513 - __main__ - WARNING -   Skipped train sample 444 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,521 - __main__ - WARNING -   Skipped train sample 445 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,528 - __main__ - WARNING -   Skipped train sample 446 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,533 - __main__ - WARNING -   Skipped train sample 447 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,538 - __main__ - WARNING -   Skipped train sample 448 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,543 - __main__ - WARNING -   Skipped train sample 449 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,550 - __main__ - WARNING -   Skipped train sample 450 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,554 - __main__ - WARNING -   Skipped train sample 451 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,561 - __main__ - WARNING -   Skipped train sample 452 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,567 - __main__ - WARNING -   Skipped train sample 453 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,571 - __main__ - WARNING -   Skipped train sample 454 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,577 - __main__ - WARNING -   Skipped train sample 455 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,585 - __main__ - WARNING -   Skipped train sample 456 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,594 - __main__ - WARNING -   Skipped train sample 457 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,601 - __main__ - WARNING -   Skipped train sample 458 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,607 - __main__ - WARNING -   Skipped train sample 459 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,616 - __main__ - WARNING -   Skipped train sample 460 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,622 - __main__ - WARNING -   Skipped train sample 461 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,628 - __main__ - WARNING -   Skipped train sample 462 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,633 - __main__ - WARNING -   Skipped train sample 463 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,642 - __main__ - WARNING -   Skipped train sample 464 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,648 - __main__ - WARNING -   Skipped train sample 465 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,653 - __main__ - WARNING -   Skipped train sample 466 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,660 - __main__ - WARNING -   Skipped train sample 467 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,666 - __main__ - WARNING -   Skipped train sample 468 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,674 - __main__ - WARNING -   Skipped train sample 469 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,679 - __main__ - WARNING -   Skipped train sample 470 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,686 - __main__ - WARNING -   Skipped train sample 471 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,694 - __main__ - WARNING -   Skipped train sample 472 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,706 - __main__ - WARNING -   Skipped train sample 473 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,713 - __main__ - WARNING -   Skipped train sample 474 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,719 - __main__ - WARNING -   Skipped train sample 475 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,724 - __main__ - WARNING -   Skipped train sample 476 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,729 - __main__ - WARNING -   Skipped train sample 477 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,735 - __main__ - WARNING -   Skipped train sample 478 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,743 - __main__ - WARNING -   Skipped train sample 479 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,748 - __main__ - WARNING -   Skipped train sample 480 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,758 - __main__ - WARNING -   Skipped train sample 481 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,768 - __main__ - WARNING -   Skipped train sample 482 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,773 - __main__ - WARNING -   Skipped train sample 483 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,781 - __main__ - WARNING -   Skipped train sample 484 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,791 - __main__ - WARNING -   Skipped train sample 485 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,798 - __main__ - WARNING -   Skipped train sample 486 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,807 - __main__ - WARNING -   Skipped train sample 487 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,813 - __main__ - WARNING -   Skipped train sample 488 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,823 - __main__ - WARNING -   Skipped train sample 489 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,841 - __main__ - WARNING -   Skipped train sample 490 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,847 - __main__ - WARNING -   Skipped train sample 491 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,859 - __main__ - WARNING -   Skipped train sample 492 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,870 - __main__ - WARNING -   Skipped train sample 493 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,887 - __main__ - WARNING -   Skipped train sample 494 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,892 - __main__ - WARNING -   Skipped train sample 495 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,906 - __main__ - WARNING -   Skipped train sample 496 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,913 - __main__ - WARNING -   Skipped train sample 497 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,924 - __main__ - WARNING -   Skipped train sample 498 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,933 - __main__ - WARNING -   Skipped train sample 499 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,943 - __main__ - WARNING -   Skipped train sample 500 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:12:40,949 - __main__ - WARNING -   Skipped train sample 501 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:14:59,344 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-21 22:14:59,344 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 22:14:59,345 - __main__ - INFO - Starting training pipeline
2025-09-21 22:14:59,446 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-21 22:14:59,471 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-21 22:14:59,471 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-21 22:14:59,472 - __main__ - INFO - Loading training data...
2025-09-21 22:15:06,933 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-21 22:15:06,933 - __main__ - INFO - Processing train split...
2025-09-21 22:15:06,997 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-21 22:15:06,997 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-21 22:15:07,025 - __main__ - WARNING -   Skipped train sample 0 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,031 - __main__ - WARNING -   Skipped train sample 1 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,039 - __main__ - WARNING -   Skipped train sample 2 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,045 - __main__ - WARNING -   Skipped train sample 3 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,052 - __main__ - WARNING -   Skipped train sample 4 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,056 - __main__ - WARNING -   Skipped train sample 5 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,061 - __main__ - WARNING -   Skipped train sample 6 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,065 - __main__ - WARNING -   Skipped train sample 7 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,070 - __main__ - WARNING -   Skipped train sample 8 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,077 - __main__ - WARNING -   Skipped train sample 9 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,082 - __main__ - WARNING -   Skipped train sample 10 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,086 - __main__ - WARNING -   Skipped train sample 11 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,091 - __main__ - WARNING -   Skipped train sample 12 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,097 - __main__ - WARNING -   Skipped train sample 13 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,103 - __main__ - WARNING -   Skipped train sample 14 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,107 - __main__ - WARNING -   Skipped train sample 15 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,112 - __main__ - WARNING -   Skipped train sample 16 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,116 - __main__ - WARNING -   Skipped train sample 17 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,121 - __main__ - WARNING -   Skipped train sample 18 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,131 - __main__ - WARNING -   Skipped train sample 19 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,135 - __main__ - WARNING -   Skipped train sample 20 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,141 - __main__ - WARNING -   Skipped train sample 21 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,144 - __main__ - WARNING -   Skipped train sample 22 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,150 - __main__ - WARNING -   Skipped train sample 23 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,154 - __main__ - WARNING -   Skipped train sample 24 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,183 - __main__ - WARNING -   Skipped train sample 25 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,189 - __main__ - WARNING -   Skipped train sample 26 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,198 - __main__ - WARNING -   Skipped train sample 27 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,205 - __main__ - WARNING -   Skipped train sample 28 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,209 - __main__ - WARNING -   Skipped train sample 29 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,214 - __main__ - WARNING -   Skipped train sample 30 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,219 - __main__ - WARNING -   Skipped train sample 31 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,227 - __main__ - WARNING -   Skipped train sample 32 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,231 - __main__ - WARNING -   Skipped train sample 33 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,237 - __main__ - WARNING -   Skipped train sample 34 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,241 - __main__ - WARNING -   Skipped train sample 35 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,247 - __main__ - WARNING -   Skipped train sample 36 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,254 - __main__ - WARNING -   Skipped train sample 37 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,259 - __main__ - WARNING -   Skipped train sample 38 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,268 - __main__ - WARNING -   Skipped train sample 39 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,277 - __main__ - WARNING -   Skipped train sample 40 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,283 - __main__ - WARNING -   Skipped train sample 41 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,289 - __main__ - WARNING -   Skipped train sample 42 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,296 - __main__ - WARNING -   Skipped train sample 43 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,307 - __main__ - WARNING -   Skipped train sample 44 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,313 - __main__ - WARNING -   Skipped train sample 45 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,319 - __main__ - WARNING -   Skipped train sample 46 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,327 - __main__ - WARNING -   Skipped train sample 47 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,337 - __main__ - WARNING -   Skipped train sample 48 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,344 - __main__ - WARNING -   Skipped train sample 49 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,351 - __main__ - WARNING -   Skipped train sample 50 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,359 - __main__ - WARNING -   Skipped train sample 51 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,366 - __main__ - WARNING -   Skipped train sample 52 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,372 - __main__ - WARNING -   Skipped train sample 53 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,382 - __main__ - WARNING -   Skipped train sample 54 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,389 - __main__ - WARNING -   Skipped train sample 55 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,397 - __main__ - WARNING -   Skipped train sample 56 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,404 - __main__ - WARNING -   Skipped train sample 57 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,411 - __main__ - WARNING -   Skipped train sample 58 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,417 - __main__ - WARNING -   Skipped train sample 59 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,424 - __main__ - WARNING -   Skipped train sample 60 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,434 - __main__ - WARNING -   Skipped train sample 61 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,445 - __main__ - WARNING -   Skipped train sample 62 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,453 - __main__ - WARNING -   Skipped train sample 63 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,459 - __main__ - WARNING -   Skipped train sample 64 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,468 - __main__ - WARNING -   Skipped train sample 65 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,477 - __main__ - WARNING -   Skipped train sample 66 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,486 - __main__ - WARNING -   Skipped train sample 67 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,497 - __main__ - WARNING -   Skipped train sample 68 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,506 - __main__ - WARNING -   Skipped train sample 69 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,513 - __main__ - WARNING -   Skipped train sample 70 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,520 - __main__ - WARNING -   Skipped train sample 71 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,539 - __main__ - WARNING -   Skipped train sample 72 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,546 - __main__ - WARNING -   Skipped train sample 73 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,553 - __main__ - WARNING -   Skipped train sample 74 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,558 - __main__ - WARNING -   Skipped train sample 75 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,563 - __main__ - WARNING -   Skipped train sample 76 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,569 - __main__ - WARNING -   Skipped train sample 77 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,576 - __main__ - WARNING -   Skipped train sample 78 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,582 - __main__ - WARNING -   Skipped train sample 79 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,586 - __main__ - WARNING -   Skipped train sample 80 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,593 - __main__ - WARNING -   Skipped train sample 81 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,598 - __main__ - WARNING -   Skipped train sample 82 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,605 - __main__ - WARNING -   Skipped train sample 83 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,611 - __main__ - WARNING -   Skipped train sample 84 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,619 - __main__ - WARNING -   Skipped train sample 85 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,632 - __main__ - WARNING -   Skipped train sample 86 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,640 - __main__ - WARNING -   Skipped train sample 87 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,649 - __main__ - WARNING -   Skipped train sample 88 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,656 - __main__ - WARNING -   Skipped train sample 89 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,665 - __main__ - WARNING -   Skipped train sample 90 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,675 - __main__ - WARNING -   Skipped train sample 91 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,682 - __main__ - WARNING -   Skipped train sample 92 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,687 - __main__ - WARNING -   Skipped train sample 93 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,692 - __main__ - WARNING -   Skipped train sample 94 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,698 - __main__ - WARNING -   Skipped train sample 95 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,705 - __main__ - WARNING -   Skipped train sample 96 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,713 - __main__ - WARNING -   Skipped train sample 97 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,721 - __main__ - WARNING -   Skipped train sample 98 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,729 - __main__ - WARNING -   Skipped train sample 99 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,738 - __main__ - WARNING -   Skipped train sample 100 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,745 - __main__ - WARNING -   Skipped train sample 101 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,756 - __main__ - WARNING -   Skipped train sample 102 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,766 - __main__ - WARNING -   Skipped train sample 103 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,773 - __main__ - WARNING -   Skipped train sample 104 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,779 - __main__ - WARNING -   Skipped train sample 105 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,786 - __main__ - WARNING -   Skipped train sample 106 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,793 - __main__ - WARNING -   Skipped train sample 107 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,798 - __main__ - WARNING -   Skipped train sample 108 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,803 - __main__ - WARNING -   Skipped train sample 109 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,810 - __main__ - WARNING -   Skipped train sample 110 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,819 - __main__ - WARNING -   Skipped train sample 111 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,825 - __main__ - WARNING -   Skipped train sample 112 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,833 - __main__ - WARNING -   Skipped train sample 113 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,838 - __main__ - WARNING -   Skipped train sample 114 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,845 - __main__ - WARNING -   Skipped train sample 115 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,850 - __main__ - WARNING -   Skipped train sample 116 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,856 - __main__ - WARNING -   Skipped train sample 117 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,862 - __main__ - WARNING -   Skipped train sample 118 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,867 - __main__ - WARNING -   Skipped train sample 119 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,873 - __main__ - WARNING -   Skipped train sample 120 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,880 - __main__ - WARNING -   Skipped train sample 121 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,885 - __main__ - WARNING -   Skipped train sample 122 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,890 - __main__ - WARNING -   Skipped train sample 123 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,899 - __main__ - WARNING -   Skipped train sample 124 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,903 - __main__ - WARNING -   Skipped train sample 125 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,909 - __main__ - WARNING -   Skipped train sample 126 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,915 - __main__ - WARNING -   Skipped train sample 127 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,920 - __main__ - WARNING -   Skipped train sample 128 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,925 - __main__ - WARNING -   Skipped train sample 129 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,930 - __main__ - WARNING -   Skipped train sample 130 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,935 - __main__ - WARNING -   Skipped train sample 131 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,941 - __main__ - WARNING -   Skipped train sample 132 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,947 - __main__ - WARNING -   Skipped train sample 133 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,952 - __main__ - WARNING -   Skipped train sample 134 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,958 - __main__ - WARNING -   Skipped train sample 135 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,964 - __main__ - WARNING -   Skipped train sample 136 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,969 - __main__ - WARNING -   Skipped train sample 137 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,975 - __main__ - WARNING -   Skipped train sample 138 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,980 - __main__ - WARNING -   Skipped train sample 139 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,986 - __main__ - WARNING -   Skipped train sample 140 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:07,998 - __main__ - WARNING -   Skipped train sample 141 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,005 - __main__ - WARNING -   Skipped train sample 142 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,010 - __main__ - WARNING -   Skipped train sample 143 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,017 - __main__ - WARNING -   Skipped train sample 144 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,025 - __main__ - WARNING -   Skipped train sample 145 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,031 - __main__ - WARNING -   Skipped train sample 146 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,035 - __main__ - WARNING -   Skipped train sample 147 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,051 - __main__ - WARNING -   Skipped train sample 148 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,058 - __main__ - WARNING -   Skipped train sample 149 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,063 - __main__ - WARNING -   Skipped train sample 150 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,072 - __main__ - WARNING -   Skipped train sample 151 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,078 - __main__ - WARNING -   Skipped train sample 152 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,083 - __main__ - WARNING -   Skipped train sample 153 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,089 - __main__ - WARNING -   Skipped train sample 154 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,095 - __main__ - WARNING -   Skipped train sample 155 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,099 - __main__ - WARNING -   Skipped train sample 156 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,105 - __main__ - WARNING -   Skipped train sample 157 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,110 - __main__ - WARNING -   Skipped train sample 158 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,117 - __main__ - WARNING -   Skipped train sample 159 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,123 - __main__ - WARNING -   Skipped train sample 160 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,135 - __main__ - WARNING -   Skipped train sample 161 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,152 - __main__ - WARNING -   Skipped train sample 162 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,157 - __main__ - WARNING -   Skipped train sample 163 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,164 - __main__ - WARNING -   Skipped train sample 164 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,171 - __main__ - WARNING -   Skipped train sample 165 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,177 - __main__ - WARNING -   Skipped train sample 166 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,186 - __main__ - WARNING -   Skipped train sample 167 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,191 - __main__ - WARNING -   Skipped train sample 168 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,196 - __main__ - WARNING -   Skipped train sample 169 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,201 - __main__ - WARNING -   Skipped train sample 170 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,206 - __main__ - WARNING -   Skipped train sample 171 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,214 - __main__ - WARNING -   Skipped train sample 172 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,223 - __main__ - WARNING -   Skipped train sample 173 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,230 - __main__ - WARNING -   Skipped train sample 174 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,236 - __main__ - WARNING -   Skipped train sample 175 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,242 - __main__ - WARNING -   Skipped train sample 176 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,249 - __main__ - WARNING -   Skipped train sample 177 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,254 - __main__ - WARNING -   Skipped train sample 178 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,261 - __main__ - WARNING -   Skipped train sample 179 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,269 - __main__ - WARNING -   Skipped train sample 180 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,274 - __main__ - WARNING -   Skipped train sample 181 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,279 - __main__ - WARNING -   Skipped train sample 182 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,290 - __main__ - WARNING -   Skipped train sample 183 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,296 - __main__ - WARNING -   Skipped train sample 184 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,307 - __main__ - WARNING -   Skipped train sample 185 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,314 - __main__ - WARNING -   Skipped train sample 186 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,322 - __main__ - WARNING -   Skipped train sample 187 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,328 - __main__ - WARNING -   Skipped train sample 188 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,335 - __main__ - WARNING -   Skipped train sample 189 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,348 - __main__ - WARNING -   Skipped train sample 190 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,354 - __main__ - WARNING -   Skipped train sample 191 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,359 - __main__ - WARNING -   Skipped train sample 192 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,370 - __main__ - WARNING -   Skipped train sample 193 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,377 - __main__ - WARNING -   Skipped train sample 194 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,387 - __main__ - WARNING -   Skipped train sample 195 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,392 - __main__ - WARNING -   Skipped train sample 196 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,400 - __main__ - WARNING -   Skipped train sample 197 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,406 - __main__ - WARNING -   Skipped train sample 198 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,411 - __main__ - WARNING -   Skipped train sample 199 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,417 - __main__ - WARNING -   Skipped train sample 200 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,422 - __main__ - WARNING -   Skipped train sample 201 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,430 - __main__ - WARNING -   Skipped train sample 202 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,437 - __main__ - WARNING -   Skipped train sample 203 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,443 - __main__ - WARNING -   Skipped train sample 204 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,449 - __main__ - WARNING -   Skipped train sample 205 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,457 - __main__ - WARNING -   Skipped train sample 206 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,465 - __main__ - WARNING -   Skipped train sample 207 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,471 - __main__ - WARNING -   Skipped train sample 208 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,477 - __main__ - WARNING -   Skipped train sample 209 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,484 - __main__ - WARNING -   Skipped train sample 210 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,489 - __main__ - WARNING -   Skipped train sample 211 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,495 - __main__ - WARNING -   Skipped train sample 212 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,500 - __main__ - WARNING -   Skipped train sample 213 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,505 - __main__ - WARNING -   Skipped train sample 214 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,510 - __main__ - WARNING -   Skipped train sample 215 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,515 - __main__ - WARNING -   Skipped train sample 216 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,522 - __main__ - WARNING -   Skipped train sample 217 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,527 - __main__ - WARNING -   Skipped train sample 218 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,533 - __main__ - WARNING -   Skipped train sample 219 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,540 - __main__ - WARNING -   Skipped train sample 220 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,549 - __main__ - WARNING -   Skipped train sample 221 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,557 - __main__ - WARNING -   Skipped train sample 222 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,563 - __main__ - WARNING -   Skipped train sample 223 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,571 - __main__ - WARNING -   Skipped train sample 224 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,577 - __main__ - WARNING -   Skipped train sample 225 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,582 - __main__ - WARNING -   Skipped train sample 226 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,586 - __main__ - WARNING -   Skipped train sample 227 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,592 - __main__ - WARNING -   Skipped train sample 228 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,597 - __main__ - WARNING -   Skipped train sample 229 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,606 - __main__ - WARNING -   Skipped train sample 230 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,613 - __main__ - WARNING -   Skipped train sample 231 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,620 - __main__ - WARNING -   Skipped train sample 232 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,626 - __main__ - WARNING -   Skipped train sample 233 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,631 - __main__ - WARNING -   Skipped train sample 234 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,640 - __main__ - WARNING -   Skipped train sample 235 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,649 - __main__ - WARNING -   Skipped train sample 236 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,656 - __main__ - WARNING -   Skipped train sample 237 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,667 - __main__ - WARNING -   Skipped train sample 238 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,672 - __main__ - WARNING -   Skipped train sample 239 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,683 - __main__ - WARNING -   Skipped train sample 240 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,689 - __main__ - WARNING -   Skipped train sample 241 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,695 - __main__ - WARNING -   Skipped train sample 242 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,700 - __main__ - WARNING -   Skipped train sample 243 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,708 - __main__ - WARNING -   Skipped train sample 244 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,713 - __main__ - WARNING -   Skipped train sample 245 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,719 - __main__ - WARNING -   Skipped train sample 246 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,725 - __main__ - WARNING -   Skipped train sample 247 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,735 - __main__ - WARNING -   Skipped train sample 248 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,743 - __main__ - WARNING -   Skipped train sample 249 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,748 - __main__ - WARNING -   Skipped train sample 250 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,755 - __main__ - WARNING -   Skipped train sample 251 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,763 - __main__ - WARNING -   Skipped train sample 252 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,769 - __main__ - WARNING -   Skipped train sample 253 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,774 - __main__ - WARNING -   Skipped train sample 254 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,779 - __main__ - WARNING -   Skipped train sample 255 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,785 - __main__ - WARNING -   Skipped train sample 256 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,794 - __main__ - WARNING -   Skipped train sample 257 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,802 - __main__ - WARNING -   Skipped train sample 258 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,808 - __main__ - WARNING -   Skipped train sample 259 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,816 - __main__ - WARNING -   Skipped train sample 260 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,825 - __main__ - WARNING -   Skipped train sample 261 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,838 - __main__ - WARNING -   Skipped train sample 262 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,844 - __main__ - WARNING -   Skipped train sample 263 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,850 - __main__ - WARNING -   Skipped train sample 264 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,855 - __main__ - WARNING -   Skipped train sample 265 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,860 - __main__ - WARNING -   Skipped train sample 266 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,869 - __main__ - WARNING -   Skipped train sample 267 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,873 - __main__ - WARNING -   Skipped train sample 268 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,882 - __main__ - WARNING -   Skipped train sample 269 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,889 - __main__ - WARNING -   Skipped train sample 270 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,894 - __main__ - WARNING -   Skipped train sample 271 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,904 - __main__ - WARNING -   Skipped train sample 272 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,913 - __main__ - WARNING -   Skipped train sample 273 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,918 - __main__ - WARNING -   Skipped train sample 274 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,924 - __main__ - WARNING -   Skipped train sample 275 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,932 - __main__ - WARNING -   Skipped train sample 276 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,939 - __main__ - WARNING -   Skipped train sample 277 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,945 - __main__ - WARNING -   Skipped train sample 278 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,950 - __main__ - WARNING -   Skipped train sample 279 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,956 - __main__ - WARNING -   Skipped train sample 280 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,962 - __main__ - WARNING -   Skipped train sample 281 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,967 - __main__ - WARNING -   Skipped train sample 282 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,974 - __main__ - WARNING -   Skipped train sample 283 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,986 - __main__ - WARNING -   Skipped train sample 284 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,992 - __main__ - WARNING -   Skipped train sample 285 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:08,999 - __main__ - WARNING -   Skipped train sample 286 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,005 - __main__ - WARNING -   Skipped train sample 287 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,012 - __main__ - WARNING -   Skipped train sample 288 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,017 - __main__ - WARNING -   Skipped train sample 289 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,023 - __main__ - WARNING -   Skipped train sample 290 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,028 - __main__ - WARNING -   Skipped train sample 291 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,036 - __main__ - WARNING -   Skipped train sample 292 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,041 - __main__ - WARNING -   Skipped train sample 293 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,047 - __main__ - WARNING -   Skipped train sample 294 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,057 - __main__ - WARNING -   Skipped train sample 295 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,064 - __main__ - WARNING -   Skipped train sample 296 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,069 - __main__ - WARNING -   Skipped train sample 297 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,076 - __main__ - WARNING -   Skipped train sample 298 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,083 - __main__ - WARNING -   Skipped train sample 299 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,091 - __main__ - WARNING -   Skipped train sample 300 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,098 - __main__ - WARNING -   Skipped train sample 301 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,104 - __main__ - WARNING -   Skipped train sample 302 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,114 - __main__ - WARNING -   Skipped train sample 303 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,123 - __main__ - WARNING -   Skipped train sample 304 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,130 - __main__ - WARNING -   Skipped train sample 305 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,136 - __main__ - WARNING -   Skipped train sample 306 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,145 - __main__ - WARNING -   Skipped train sample 307 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,151 - __main__ - WARNING -   Skipped train sample 308 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,160 - __main__ - WARNING -   Skipped train sample 309 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,167 - __main__ - WARNING -   Skipped train sample 310 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,173 - __main__ - WARNING -   Skipped train sample 311 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,182 - __main__ - WARNING -   Skipped train sample 312 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,189 - __main__ - WARNING -   Skipped train sample 313 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,194 - __main__ - WARNING -   Skipped train sample 314 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,200 - __main__ - WARNING -   Skipped train sample 315 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,206 - __main__ - WARNING -   Skipped train sample 316 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,212 - __main__ - WARNING -   Skipped train sample 317 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,221 - __main__ - WARNING -   Skipped train sample 318 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,226 - __main__ - WARNING -   Skipped train sample 319 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,231 - __main__ - WARNING -   Skipped train sample 320 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,241 - __main__ - WARNING -   Skipped train sample 321 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,247 - __main__ - WARNING -   Skipped train sample 322 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,256 - __main__ - WARNING -   Skipped train sample 323 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,261 - __main__ - WARNING -   Skipped train sample 324 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,268 - __main__ - WARNING -   Skipped train sample 325 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,279 - __main__ - WARNING -   Skipped train sample 326 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,285 - __main__ - WARNING -   Skipped train sample 327 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,294 - __main__ - WARNING -   Skipped train sample 328 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,301 - __main__ - WARNING -   Skipped train sample 329 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,308 - __main__ - WARNING -   Skipped train sample 330 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,314 - __main__ - WARNING -   Skipped train sample 331 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,319 - __main__ - WARNING -   Skipped train sample 332 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,329 - __main__ - WARNING -   Skipped train sample 333 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,334 - __main__ - WARNING -   Skipped train sample 334 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,341 - __main__ - WARNING -   Skipped train sample 335 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,347 - __main__ - WARNING -   Skipped train sample 336 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,353 - __main__ - WARNING -   Skipped train sample 337 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,358 - __main__ - WARNING -   Skipped train sample 338 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,363 - __main__ - WARNING -   Skipped train sample 339 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,372 - __main__ - WARNING -   Skipped train sample 340 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,381 - __main__ - WARNING -   Skipped train sample 341 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,397 - __main__ - WARNING -   Skipped train sample 342 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,404 - __main__ - WARNING -   Skipped train sample 343 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,415 - __main__ - WARNING -   Skipped train sample 344 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,422 - __main__ - WARNING -   Skipped train sample 345 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,427 - __main__ - WARNING -   Skipped train sample 346 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,432 - __main__ - WARNING -   Skipped train sample 347 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,440 - __main__ - WARNING -   Skipped train sample 348 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,447 - __main__ - WARNING -   Skipped train sample 349 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,458 - __main__ - WARNING -   Skipped train sample 350 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,464 - __main__ - WARNING -   Skipped train sample 351 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,469 - __main__ - WARNING -   Skipped train sample 352 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,474 - __main__ - WARNING -   Skipped train sample 353 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,481 - __main__ - WARNING -   Skipped train sample 354 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,486 - __main__ - WARNING -   Skipped train sample 355 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,493 - __main__ - WARNING -   Skipped train sample 356 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,502 - __main__ - WARNING -   Skipped train sample 357 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,509 - __main__ - WARNING -   Skipped train sample 358 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,514 - __main__ - WARNING -   Skipped train sample 359 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,519 - __main__ - WARNING -   Skipped train sample 360 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,531 - __main__ - WARNING -   Skipped train sample 361 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,541 - __main__ - WARNING -   Skipped train sample 362 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,547 - __main__ - WARNING -   Skipped train sample 363 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,558 - __main__ - WARNING -   Skipped train sample 364 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,565 - __main__ - WARNING -   Skipped train sample 365 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,571 - __main__ - WARNING -   Skipped train sample 366 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,579 - __main__ - WARNING -   Skipped train sample 367 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,585 - __main__ - WARNING -   Skipped train sample 368 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,591 - __main__ - WARNING -   Skipped train sample 369 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,599 - __main__ - WARNING -   Skipped train sample 370 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,606 - __main__ - WARNING -   Skipped train sample 371 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,614 - __main__ - WARNING -   Skipped train sample 372 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,624 - __main__ - WARNING -   Skipped train sample 373 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,633 - __main__ - WARNING -   Skipped train sample 374 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,643 - __main__ - WARNING -   Skipped train sample 375 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,650 - __main__ - WARNING -   Skipped train sample 376 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,656 - __main__ - WARNING -   Skipped train sample 377 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,663 - __main__ - WARNING -   Skipped train sample 378 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,670 - __main__ - WARNING -   Skipped train sample 379 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,677 - __main__ - WARNING -   Skipped train sample 380 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,684 - __main__ - WARNING -   Skipped train sample 381 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,690 - __main__ - WARNING -   Skipped train sample 382 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,697 - __main__ - WARNING -   Skipped train sample 383 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,705 - __main__ - WARNING -   Skipped train sample 384 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,712 - __main__ - WARNING -   Skipped train sample 385 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,719 - __main__ - WARNING -   Skipped train sample 386 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,730 - __main__ - WARNING -   Skipped train sample 387 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,737 - __main__ - WARNING -   Skipped train sample 388 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,743 - __main__ - WARNING -   Skipped train sample 389 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,750 - __main__ - WARNING -   Skipped train sample 390 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,758 - __main__ - WARNING -   Skipped train sample 391 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,766 - __main__ - WARNING -   Skipped train sample 392 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,774 - __main__ - WARNING -   Skipped train sample 393 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,781 - __main__ - WARNING -   Skipped train sample 394 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,787 - __main__ - WARNING -   Skipped train sample 395 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,793 - __main__ - WARNING -   Skipped train sample 396 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,802 - __main__ - WARNING -   Skipped train sample 397 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,811 - __main__ - WARNING -   Skipped train sample 398 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,818 - __main__ - WARNING -   Skipped train sample 399 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,827 - __main__ - WARNING -   Skipped train sample 400 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,833 - __main__ - WARNING -   Skipped train sample 401 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,840 - __main__ - WARNING -   Skipped train sample 402 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,848 - __main__ - WARNING -   Skipped train sample 403 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,855 - __main__ - WARNING -   Skipped train sample 404 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,862 - __main__ - WARNING -   Skipped train sample 405 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,871 - __main__ - WARNING -   Skipped train sample 406 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,881 - __main__ - WARNING -   Skipped train sample 407 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,888 - __main__ - WARNING -   Skipped train sample 408 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,894 - __main__ - WARNING -   Skipped train sample 409 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,905 - __main__ - WARNING -   Skipped train sample 410 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,917 - __main__ - WARNING -   Skipped train sample 411 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,929 - __main__ - WARNING -   Skipped train sample 412 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,936 - __main__ - WARNING -   Skipped train sample 413 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,941 - __main__ - WARNING -   Skipped train sample 414 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,948 - __main__ - WARNING -   Skipped train sample 415 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,953 - __main__ - WARNING -   Skipped train sample 416 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,961 - __main__ - WARNING -   Skipped train sample 417 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,968 - __main__ - WARNING -   Skipped train sample 418 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,975 - __main__ - WARNING -   Skipped train sample 419 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,980 - __main__ - WARNING -   Skipped train sample 420 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,986 - __main__ - WARNING -   Skipped train sample 421 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,991 - __main__ - WARNING -   Skipped train sample 422 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:09,999 - __main__ - WARNING -   Skipped train sample 423 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,004 - __main__ - WARNING -   Skipped train sample 424 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,011 - __main__ - WARNING -   Skipped train sample 425 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,017 - __main__ - WARNING -   Skipped train sample 426 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,022 - __main__ - WARNING -   Skipped train sample 427 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,028 - __main__ - WARNING -   Skipped train sample 428 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,033 - __main__ - WARNING -   Skipped train sample 429 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,038 - __main__ - WARNING -   Skipped train sample 430 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,044 - __main__ - WARNING -   Skipped train sample 431 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,049 - __main__ - WARNING -   Skipped train sample 432 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,056 - __main__ - WARNING -   Skipped train sample 433 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,061 - __main__ - WARNING -   Skipped train sample 434 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,071 - __main__ - WARNING -   Skipped train sample 435 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,075 - __main__ - WARNING -   Skipped train sample 436 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,081 - __main__ - WARNING -   Skipped train sample 437 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,086 - __main__ - WARNING -   Skipped train sample 438 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,091 - __main__ - WARNING -   Skipped train sample 439 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,096 - __main__ - WARNING -   Skipped train sample 440 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,104 - __main__ - WARNING -   Skipped train sample 441 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,109 - __main__ - WARNING -   Skipped train sample 442 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,114 - __main__ - WARNING -   Skipped train sample 443 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,122 - __main__ - WARNING -   Skipped train sample 444 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,127 - __main__ - WARNING -   Skipped train sample 445 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,135 - __main__ - WARNING -   Skipped train sample 446 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,140 - __main__ - WARNING -   Skipped train sample 447 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,144 - __main__ - WARNING -   Skipped train sample 448 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,150 - __main__ - WARNING -   Skipped train sample 449 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,154 - __main__ - WARNING -   Skipped train sample 450 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,159 - __main__ - WARNING -   Skipped train sample 451 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,168 - __main__ - WARNING -   Skipped train sample 452 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,174 - __main__ - WARNING -   Skipped train sample 453 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,179 - __main__ - WARNING -   Skipped train sample 454 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,185 - __main__ - WARNING -   Skipped train sample 455 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,190 - __main__ - WARNING -   Skipped train sample 456 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,196 - __main__ - WARNING -   Skipped train sample 457 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,203 - __main__ - WARNING -   Skipped train sample 458 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,210 - __main__ - WARNING -   Skipped train sample 459 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,219 - __main__ - WARNING -   Skipped train sample 460 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,225 - __main__ - WARNING -   Skipped train sample 461 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,231 - __main__ - WARNING -   Skipped train sample 462 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,237 - __main__ - WARNING -   Skipped train sample 463 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,243 - __main__ - WARNING -   Skipped train sample 464 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,250 - __main__ - WARNING -   Skipped train sample 465 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,255 - __main__ - WARNING -   Skipped train sample 466 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,260 - __main__ - WARNING -   Skipped train sample 467 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,266 - __main__ - WARNING -   Skipped train sample 468 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,272 - __main__ - WARNING -   Skipped train sample 469 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,276 - __main__ - WARNING -   Skipped train sample 470 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,284 - __main__ - WARNING -   Skipped train sample 471 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,289 - __main__ - WARNING -   Skipped train sample 472 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,297 - __main__ - WARNING -   Skipped train sample 473 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,303 - __main__ - WARNING -   Skipped train sample 474 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,309 - __main__ - WARNING -   Skipped train sample 475 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,314 - __main__ - WARNING -   Skipped train sample 476 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,319 - __main__ - WARNING -   Skipped train sample 477 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,325 - __main__ - WARNING -   Skipped train sample 478 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,332 - __main__ - WARNING -   Skipped train sample 479 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,338 - __main__ - WARNING -   Skipped train sample 480 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,344 - __main__ - WARNING -   Skipped train sample 481 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,350 - __main__ - WARNING -   Skipped train sample 482 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,355 - __main__ - WARNING -   Skipped train sample 483 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,363 - __main__ - WARNING -   Skipped train sample 484 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,370 - __main__ - WARNING -   Skipped train sample 485 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,376 - __main__ - WARNING -   Skipped train sample 486 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,382 - __main__ - WARNING -   Skipped train sample 487 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,388 - __main__ - WARNING -   Skipped train sample 488 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,398 - __main__ - WARNING -   Skipped train sample 489 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,408 - __main__ - WARNING -   Skipped train sample 490 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,415 - __main__ - WARNING -   Skipped train sample 491 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,428 - __main__ - WARNING -   Skipped train sample 492 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,435 - __main__ - WARNING -   Skipped train sample 493 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,445 - __main__ - WARNING -   Skipped train sample 494 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,450 - __main__ - WARNING -   Skipped train sample 495 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,461 - __main__ - WARNING -   Skipped train sample 496 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,469 - __main__ - WARNING -   Skipped train sample 497 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,481 - __main__ - WARNING -   Skipped train sample 498 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,490 - __main__ - WARNING -   Skipped train sample 499 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,497 - __main__ - WARNING -   Skipped train sample 500 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,502 - __main__ - WARNING -   Skipped train sample 501 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,510 - __main__ - WARNING -   Skipped train sample 502 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,524 - __main__ - WARNING -   Skipped train sample 503 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,541 - __main__ - WARNING -   Skipped train sample 504 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,549 - __main__ - WARNING -   Skipped train sample 505 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,562 - __main__ - WARNING -   Skipped train sample 506 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,567 - __main__ - WARNING -   Skipped train sample 507 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,576 - __main__ - WARNING -   Skipped train sample 508 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,581 - __main__ - WARNING -   Skipped train sample 509 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,589 - __main__ - WARNING -   Skipped train sample 510 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,598 - __main__ - WARNING -   Skipped train sample 511 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,605 - __main__ - WARNING -   Skipped train sample 512 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,611 - __main__ - WARNING -   Skipped train sample 513 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,618 - __main__ - WARNING -   Skipped train sample 514 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,630 - __main__ - WARNING -   Skipped train sample 515 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,636 - __main__ - WARNING -   Skipped train sample 516 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,645 - __main__ - WARNING -   Skipped train sample 517 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,650 - __main__ - WARNING -   Skipped train sample 518 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,661 - __main__ - WARNING -   Skipped train sample 519 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,672 - __main__ - WARNING -   Skipped train sample 520 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,680 - __main__ - WARNING -   Skipped train sample 521 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,686 - __main__ - WARNING -   Skipped train sample 522 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,691 - __main__ - WARNING -   Skipped train sample 523 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,701 - __main__ - WARNING -   Skipped train sample 524 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,707 - __main__ - WARNING -   Skipped train sample 525 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,713 - __main__ - WARNING -   Skipped train sample 526 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,719 - __main__ - WARNING -   Skipped train sample 527 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,728 - __main__ - WARNING -   Skipped train sample 528 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,745 - __main__ - WARNING -   Skipped train sample 529 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,751 - __main__ - WARNING -   Skipped train sample 530 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,760 - __main__ - WARNING -   Skipped train sample 531 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,769 - __main__ - WARNING -   Skipped train sample 532 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,775 - __main__ - WARNING -   Skipped train sample 533 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,799 - __main__ - WARNING -   Skipped train sample 534 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,812 - __main__ - WARNING -   Skipped train sample 535 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,825 - __main__ - WARNING -   Skipped train sample 536 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,831 - __main__ - WARNING -   Skipped train sample 537 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,841 - __main__ - WARNING -   Skipped train sample 538 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,848 - __main__ - WARNING -   Skipped train sample 539 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,853 - __main__ - WARNING -   Skipped train sample 540 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,862 - __main__ - WARNING -   Skipped train sample 541 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,871 - __main__ - WARNING -   Skipped train sample 542 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,877 - __main__ - WARNING -   Skipped train sample 543 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,886 - __main__ - WARNING -   Skipped train sample 544 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,897 - __main__ - WARNING -   Skipped train sample 545 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,904 - __main__ - WARNING -   Skipped train sample 546 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,914 - __main__ - WARNING -   Skipped train sample 547 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,919 - __main__ - WARNING -   Skipped train sample 548 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,926 - __main__ - WARNING -   Skipped train sample 549 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,943 - __main__ - WARNING -   Skipped train sample 550 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,954 - __main__ - WARNING -   Skipped train sample 551 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,964 - __main__ - WARNING -   Skipped train sample 552 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,970 - __main__ - WARNING -   Skipped train sample 553 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,977 - __main__ - WARNING -   Skipped train sample 554 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:10,994 - __main__ - WARNING -   Skipped train sample 555 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,008 - __main__ - WARNING -   Skipped train sample 556 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,014 - __main__ - WARNING -   Skipped train sample 557 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,023 - __main__ - WARNING -   Skipped train sample 558 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,028 - __main__ - WARNING -   Skipped train sample 559 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,046 - __main__ - WARNING -   Skipped train sample 560 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,054 - __main__ - WARNING -   Skipped train sample 561 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,061 - __main__ - WARNING -   Skipped train sample 562 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,074 - __main__ - WARNING -   Skipped train sample 563 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,089 - __main__ - WARNING -   Skipped train sample 564 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,095 - __main__ - WARNING -   Skipped train sample 565 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,101 - __main__ - WARNING -   Skipped train sample 566 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,107 - __main__ - WARNING -   Skipped train sample 567 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,114 - __main__ - WARNING -   Skipped train sample 568 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,123 - __main__ - WARNING -   Skipped train sample 569 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,129 - __main__ - WARNING -   Skipped train sample 570 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,137 - __main__ - WARNING -   Skipped train sample 571 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,143 - __main__ - WARNING -   Skipped train sample 572 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,148 - __main__ - WARNING -   Skipped train sample 573 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,157 - __main__ - WARNING -   Skipped train sample 574 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,173 - __main__ - WARNING -   Skipped train sample 575 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,182 - __main__ - WARNING -   Skipped train sample 576 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,189 - __main__ - WARNING -   Skipped train sample 577 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,194 - __main__ - WARNING -   Skipped train sample 578 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,202 - __main__ - WARNING -   Skipped train sample 579 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,207 - __main__ - WARNING -   Skipped train sample 580 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,211 - __main__ - WARNING -   Skipped train sample 581 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,218 - __main__ - WARNING -   Skipped train sample 582 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,224 - __main__ - WARNING -   Skipped train sample 583 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,230 - __main__ - WARNING -   Skipped train sample 584 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,235 - __main__ - WARNING -   Skipped train sample 585 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,240 - __main__ - WARNING -   Skipped train sample 586 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,248 - __main__ - WARNING -   Skipped train sample 587 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,263 - __main__ - WARNING -   Skipped train sample 588 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,274 - __main__ - WARNING -   Skipped train sample 589 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,279 - __main__ - WARNING -   Skipped train sample 590 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,288 - __main__ - WARNING -   Skipped train sample 591 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,298 - __main__ - WARNING -   Skipped train sample 592 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,304 - __main__ - WARNING -   Skipped train sample 593 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,317 - __main__ - WARNING -   Skipped train sample 594 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,323 - __main__ - WARNING -   Skipped train sample 595 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,327 - __main__ - WARNING -   Skipped train sample 596 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,334 - __main__ - WARNING -   Skipped train sample 597 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,342 - __main__ - WARNING -   Skipped train sample 598 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,349 - __main__ - WARNING -   Skipped train sample 599 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,357 - __main__ - WARNING -   Skipped train sample 600 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,363 - __main__ - WARNING -   Skipped train sample 601 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,371 - __main__ - WARNING -   Skipped train sample 602 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,380 - __main__ - WARNING -   Skipped train sample 603 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,393 - __main__ - WARNING -   Skipped train sample 604 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,410 - __main__ - WARNING -   Skipped train sample 605 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,421 - __main__ - WARNING -   Skipped train sample 606 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,431 - __main__ - WARNING -   Skipped train sample 607 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,438 - __main__ - WARNING -   Skipped train sample 608 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,445 - __main__ - WARNING -   Skipped train sample 609 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,461 - __main__ - WARNING -   Skipped train sample 610 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,476 - __main__ - WARNING -   Skipped train sample 611 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,484 - __main__ - WARNING -   Skipped train sample 612 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,493 - __main__ - WARNING -   Skipped train sample 613 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,501 - __main__ - WARNING -   Skipped train sample 614 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,507 - __main__ - WARNING -   Skipped train sample 615 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,512 - __main__ - WARNING -   Skipped train sample 616 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,522 - __main__ - WARNING -   Skipped train sample 617 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,528 - __main__ - WARNING -   Skipped train sample 618 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,533 - __main__ - WARNING -   Skipped train sample 619 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,546 - __main__ - WARNING -   Skipped train sample 620 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,555 - __main__ - WARNING -   Skipped train sample 621 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,560 - __main__ - WARNING -   Skipped train sample 622 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,574 - __main__ - WARNING -   Skipped train sample 623 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,581 - __main__ - WARNING -   Skipped train sample 624 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,588 - __main__ - WARNING -   Skipped train sample 625 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,595 - __main__ - WARNING -   Skipped train sample 626 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,609 - __main__ - WARNING -   Skipped train sample 627 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,616 - __main__ - WARNING -   Skipped train sample 628 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,623 - __main__ - WARNING -   Skipped train sample 629 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,631 - __main__ - WARNING -   Skipped train sample 630 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,642 - __main__ - WARNING -   Skipped train sample 631 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,651 - __main__ - WARNING -   Skipped train sample 632 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,662 - __main__ - WARNING -   Skipped train sample 633 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,674 - __main__ - WARNING -   Skipped train sample 634 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,683 - __main__ - WARNING -   Skipped train sample 635 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,692 - __main__ - WARNING -   Skipped train sample 636 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,707 - __main__ - WARNING -   Skipped train sample 637 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,714 - __main__ - WARNING -   Skipped train sample 638 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,721 - __main__ - WARNING -   Skipped train sample 639 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,726 - __main__ - WARNING -   Skipped train sample 640 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,731 - __main__ - WARNING -   Skipped train sample 641 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,744 - __main__ - WARNING -   Skipped train sample 642 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,763 - __main__ - WARNING -   Skipped train sample 643 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,770 - __main__ - WARNING -   Skipped train sample 644 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,779 - __main__ - WARNING -   Skipped train sample 645 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,784 - __main__ - WARNING -   Skipped train sample 646 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,795 - __main__ - WARNING -   Skipped train sample 647 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,803 - __main__ - WARNING -   Skipped train sample 648 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,809 - __main__ - WARNING -   Skipped train sample 649 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,818 - __main__ - WARNING -   Skipped train sample 650 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,826 - __main__ - WARNING -   Skipped train sample 651 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,833 - __main__ - WARNING -   Skipped train sample 652 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,840 - __main__ - WARNING -   Skipped train sample 653 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,847 - __main__ - WARNING -   Skipped train sample 654 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,855 - __main__ - WARNING -   Skipped train sample 655 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,863 - __main__ - WARNING -   Skipped train sample 656 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,872 - __main__ - WARNING -   Skipped train sample 657 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,880 - __main__ - WARNING -   Skipped train sample 658 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,891 - __main__ - WARNING -   Skipped train sample 659 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,898 - __main__ - WARNING -   Skipped train sample 660 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,905 - __main__ - WARNING -   Skipped train sample 661 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,913 - __main__ - WARNING -   Skipped train sample 662 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,925 - __main__ - WARNING -   Skipped train sample 663 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,941 - __main__ - WARNING -   Skipped train sample 664 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,952 - __main__ - WARNING -   Skipped train sample 665 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,965 - __main__ - WARNING -   Skipped train sample 666 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,976 - __main__ - WARNING -   Skipped train sample 667 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,984 - __main__ - WARNING -   Skipped train sample 668 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:11,991 - __main__ - WARNING -   Skipped train sample 669 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,005 - __main__ - WARNING -   Skipped train sample 670 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,015 - __main__ - WARNING -   Skipped train sample 671 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,024 - __main__ - WARNING -   Skipped train sample 672 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,032 - __main__ - WARNING -   Skipped train sample 673 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,053 - __main__ - WARNING -   Skipped train sample 674 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,067 - __main__ - WARNING -   Skipped train sample 675 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,073 - __main__ - WARNING -   Skipped train sample 676 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,079 - __main__ - WARNING -   Skipped train sample 677 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,086 - __main__ - WARNING -   Skipped train sample 678 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,095 - __main__ - WARNING -   Skipped train sample 679 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,099 - __main__ - WARNING -   Skipped train sample 680 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,104 - __main__ - WARNING -   Skipped train sample 681 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,112 - __main__ - WARNING -   Skipped train sample 682 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,119 - __main__ - WARNING -   Skipped train sample 683 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,127 - __main__ - WARNING -   Skipped train sample 684 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,141 - __main__ - WARNING -   Skipped train sample 685 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,149 - __main__ - WARNING -   Skipped train sample 686 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,154 - __main__ - WARNING -   Skipped train sample 687 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,161 - __main__ - WARNING -   Skipped train sample 688 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,167 - __main__ - WARNING -   Skipped train sample 689 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,175 - __main__ - WARNING -   Skipped train sample 690 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,186 - __main__ - WARNING -   Skipped train sample 691 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,194 - __main__ - WARNING -   Skipped train sample 692 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,207 - __main__ - WARNING -   Skipped train sample 693 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,216 - __main__ - WARNING -   Skipped train sample 694 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,222 - __main__ - WARNING -   Skipped train sample 695 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,230 - __main__ - WARNING -   Skipped train sample 696 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,238 - __main__ - WARNING -   Skipped train sample 697 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,249 - __main__ - WARNING -   Skipped train sample 698 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,257 - __main__ - WARNING -   Skipped train sample 699 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,270 - __main__ - WARNING -   Skipped train sample 700 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,281 - __main__ - WARNING -   Skipped train sample 701 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,300 - __main__ - WARNING -   Skipped train sample 702 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,314 - __main__ - WARNING -   Skipped train sample 703 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,322 - __main__ - WARNING -   Skipped train sample 704 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,327 - __main__ - WARNING -   Skipped train sample 705 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,336 - __main__ - WARNING -   Skipped train sample 706 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,344 - __main__ - WARNING -   Skipped train sample 707 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,354 - __main__ - WARNING -   Skipped train sample 708 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,364 - __main__ - WARNING -   Skipped train sample 709 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:15:12,372 - __main__ - WARNING -   Skipped train sample 710 due to error: expected np.ndarray (got Tensor)
2025-09-21 22:16:02,329 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-21 22:16:02,329 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 22:16:02,329 - __main__ - INFO - Starting training pipeline
2025-09-21 22:16:02,428 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-21 22:16:02,453 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-21 22:16:02,453 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-21 22:16:02,454 - __main__ - INFO - Loading training data...
2025-09-21 22:16:10,040 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-21 22:16:10,041 - __main__ - INFO - Processing train split...
2025-09-21 22:16:10,107 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-21 22:16:10,107 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-21 22:16:10,111 - __main__ - WARNING -   Skipped train sample 0 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,114 - __main__ - WARNING -   Skipped train sample 1 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,119 - __main__ - WARNING -   Skipped train sample 2 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,123 - __main__ - WARNING -   Skipped train sample 3 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,128 - __main__ - WARNING -   Skipped train sample 4 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,129 - __main__ - WARNING -   Skipped train sample 5 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,132 - __main__ - WARNING -   Skipped train sample 6 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,133 - __main__ - WARNING -   Skipped train sample 7 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,135 - __main__ - WARNING -   Skipped train sample 8 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,140 - __main__ - WARNING -   Skipped train sample 9 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,142 - __main__ - WARNING -   Skipped train sample 10 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,161 - __main__ - WARNING -   Skipped train sample 11 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,163 - __main__ - WARNING -   Skipped train sample 12 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,167 - __main__ - WARNING -   Skipped train sample 13 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,170 - __main__ - WARNING -   Skipped train sample 14 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,172 - __main__ - WARNING -   Skipped train sample 15 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,175 - __main__ - WARNING -   Skipped train sample 16 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,177 - __main__ - WARNING -   Skipped train sample 17 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,180 - __main__ - WARNING -   Skipped train sample 18 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,188 - __main__ - WARNING -   Skipped train sample 19 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,190 - __main__ - WARNING -   Skipped train sample 20 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,193 - __main__ - WARNING -   Skipped train sample 21 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,195 - __main__ - WARNING -   Skipped train sample 22 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,198 - __main__ - WARNING -   Skipped train sample 23 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,200 - __main__ - WARNING -   Skipped train sample 24 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,241 - __main__ - WARNING -   Skipped train sample 25 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,246 - __main__ - WARNING -   Skipped train sample 26 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,252 - __main__ - WARNING -   Skipped train sample 27 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,257 - __main__ - WARNING -   Skipped train sample 28 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,259 - __main__ - WARNING -   Skipped train sample 29 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,264 - __main__ - WARNING -   Skipped train sample 30 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,267 - __main__ - WARNING -   Skipped train sample 31 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,272 - __main__ - WARNING -   Skipped train sample 32 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,274 - __main__ - WARNING -   Skipped train sample 33 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,278 - __main__ - WARNING -   Skipped train sample 34 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,280 - __main__ - WARNING -   Skipped train sample 35 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,283 - __main__ - WARNING -   Skipped train sample 36 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,288 - __main__ - WARNING -   Skipped train sample 37 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,290 - __main__ - WARNING -   Skipped train sample 38 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,296 - __main__ - WARNING -   Skipped train sample 39 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,299 - __main__ - WARNING -   Skipped train sample 40 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,302 - __main__ - WARNING -   Skipped train sample 41 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,304 - __main__ - WARNING -   Skipped train sample 42 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,309 - __main__ - WARNING -   Skipped train sample 43 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,314 - __main__ - WARNING -   Skipped train sample 44 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,318 - __main__ - WARNING -   Skipped train sample 45 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,320 - __main__ - WARNING -   Skipped train sample 46 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,324 - __main__ - WARNING -   Skipped train sample 47 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,329 - __main__ - WARNING -   Skipped train sample 48 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,331 - __main__ - WARNING -   Skipped train sample 49 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,333 - __main__ - WARNING -   Skipped train sample 50 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,336 - __main__ - WARNING -   Skipped train sample 51 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,339 - __main__ - WARNING -   Skipped train sample 52 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,340 - __main__ - WARNING -   Skipped train sample 53 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,345 - __main__ - WARNING -   Skipped train sample 54 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,347 - __main__ - WARNING -   Skipped train sample 55 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,351 - __main__ - WARNING -   Skipped train sample 56 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,353 - __main__ - WARNING -   Skipped train sample 57 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,356 - __main__ - WARNING -   Skipped train sample 58 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,358 - __main__ - WARNING -   Skipped train sample 59 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,360 - __main__ - WARNING -   Skipped train sample 60 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,367 - __main__ - WARNING -   Skipped train sample 61 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,373 - __main__ - WARNING -   Skipped train sample 62 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,376 - __main__ - WARNING -   Skipped train sample 63 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,378 - __main__ - WARNING -   Skipped train sample 64 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,382 - __main__ - WARNING -   Skipped train sample 65 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,385 - __main__ - WARNING -   Skipped train sample 66 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,390 - __main__ - WARNING -   Skipped train sample 67 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,395 - __main__ - WARNING -   Skipped train sample 68 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,399 - __main__ - WARNING -   Skipped train sample 69 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,401 - __main__ - WARNING -   Skipped train sample 70 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,403 - __main__ - WARNING -   Skipped train sample 71 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,414 - __main__ - WARNING -   Skipped train sample 72 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,416 - __main__ - WARNING -   Skipped train sample 73 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,420 - __main__ - WARNING -   Skipped train sample 74 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,422 - __main__ - WARNING -   Skipped train sample 75 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,424 - __main__ - WARNING -   Skipped train sample 76 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,427 - __main__ - WARNING -   Skipped train sample 77 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,429 - __main__ - WARNING -   Skipped train sample 78 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,432 - __main__ - WARNING -   Skipped train sample 79 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,433 - __main__ - WARNING -   Skipped train sample 80 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,437 - __main__ - WARNING -   Skipped train sample 81 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,439 - __main__ - WARNING -   Skipped train sample 82 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,443 - __main__ - WARNING -   Skipped train sample 83 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,446 - __main__ - WARNING -   Skipped train sample 84 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,456 - __main__ - WARNING -   Skipped train sample 85 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,464 - __main__ - WARNING -   Skipped train sample 86 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,469 - __main__ - WARNING -   Skipped train sample 87 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,472 - __main__ - WARNING -   Skipped train sample 88 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,474 - __main__ - WARNING -   Skipped train sample 89 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,478 - __main__ - WARNING -   Skipped train sample 90 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,482 - __main__ - WARNING -   Skipped train sample 91 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,484 - __main__ - WARNING -   Skipped train sample 92 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,486 - __main__ - WARNING -   Skipped train sample 93 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,488 - __main__ - WARNING -   Skipped train sample 94 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,492 - __main__ - WARNING -   Skipped train sample 95 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,495 - __main__ - WARNING -   Skipped train sample 96 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,499 - __main__ - WARNING -   Skipped train sample 97 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,502 - __main__ - WARNING -   Skipped train sample 98 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,504 - __main__ - WARNING -   Skipped train sample 99 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,508 - __main__ - WARNING -   Skipped train sample 100 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,510 - __main__ - WARNING -   Skipped train sample 101 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,515 - __main__ - WARNING -   Skipped train sample 102 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,519 - __main__ - WARNING -   Skipped train sample 103 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,522 - __main__ - WARNING -   Skipped train sample 104 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,524 - __main__ - WARNING -   Skipped train sample 105 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,526 - __main__ - WARNING -   Skipped train sample 106 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,530 - __main__ - WARNING -   Skipped train sample 107 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,534 - __main__ - WARNING -   Skipped train sample 108 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,537 - __main__ - WARNING -   Skipped train sample 109 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,540 - __main__ - WARNING -   Skipped train sample 110 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,546 - __main__ - WARNING -   Skipped train sample 111 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,549 - __main__ - WARNING -   Skipped train sample 112 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,552 - __main__ - WARNING -   Skipped train sample 113 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,555 - __main__ - WARNING -   Skipped train sample 114 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,558 - __main__ - WARNING -   Skipped train sample 115 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,561 - __main__ - WARNING -   Skipped train sample 116 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,563 - __main__ - WARNING -   Skipped train sample 117 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,566 - __main__ - WARNING -   Skipped train sample 118 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,569 - __main__ - WARNING -   Skipped train sample 119 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,572 - __main__ - WARNING -   Skipped train sample 120 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,575 - __main__ - WARNING -   Skipped train sample 121 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,578 - __main__ - WARNING -   Skipped train sample 122 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,580 - __main__ - WARNING -   Skipped train sample 123 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,584 - __main__ - WARNING -   Skipped train sample 124 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,585 - __main__ - WARNING -   Skipped train sample 125 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,588 - __main__ - WARNING -   Skipped train sample 126 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,591 - __main__ - WARNING -   Skipped train sample 127 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,593 - __main__ - WARNING -   Skipped train sample 128 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,596 - __main__ - WARNING -   Skipped train sample 129 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,597 - __main__ - WARNING -   Skipped train sample 130 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,599 - __main__ - WARNING -   Skipped train sample 131 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,602 - __main__ - WARNING -   Skipped train sample 132 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,605 - __main__ - WARNING -   Skipped train sample 133 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,608 - __main__ - WARNING -   Skipped train sample 134 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,610 - __main__ - WARNING -   Skipped train sample 135 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,613 - __main__ - WARNING -   Skipped train sample 136 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,616 - __main__ - WARNING -   Skipped train sample 137 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,619 - __main__ - WARNING -   Skipped train sample 138 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,621 - __main__ - WARNING -   Skipped train sample 139 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,623 - __main__ - WARNING -   Skipped train sample 140 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,631 - __main__ - WARNING -   Skipped train sample 141 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,635 - __main__ - WARNING -   Skipped train sample 142 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,637 - __main__ - WARNING -   Skipped train sample 143 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,641 - __main__ - WARNING -   Skipped train sample 144 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,646 - __main__ - WARNING -   Skipped train sample 145 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,649 - __main__ - WARNING -   Skipped train sample 146 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,651 - __main__ - WARNING -   Skipped train sample 147 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,660 - __main__ - WARNING -   Skipped train sample 148 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,664 - __main__ - WARNING -   Skipped train sample 149 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,667 - __main__ - WARNING -   Skipped train sample 150 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,672 - __main__ - WARNING -   Skipped train sample 151 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,675 - __main__ - WARNING -   Skipped train sample 152 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,677 - __main__ - WARNING -   Skipped train sample 153 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,680 - __main__ - WARNING -   Skipped train sample 154 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,682 - __main__ - WARNING -   Skipped train sample 155 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,687 - __main__ - WARNING -   Skipped train sample 156 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,689 - __main__ - WARNING -   Skipped train sample 157 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,695 - __main__ - WARNING -   Skipped train sample 158 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,700 - __main__ - WARNING -   Skipped train sample 159 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,701 - __main__ - WARNING -   Skipped train sample 160 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,707 - __main__ - WARNING -   Skipped train sample 161 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,716 - __main__ - WARNING -   Skipped train sample 162 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,719 - __main__ - WARNING -   Skipped train sample 163 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,722 - __main__ - WARNING -   Skipped train sample 164 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,726 - __main__ - WARNING -   Skipped train sample 165 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,729 - __main__ - WARNING -   Skipped train sample 166 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,734 - __main__ - WARNING -   Skipped train sample 167 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,736 - __main__ - WARNING -   Skipped train sample 168 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,739 - __main__ - WARNING -   Skipped train sample 169 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,741 - __main__ - WARNING -   Skipped train sample 170 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,743 - __main__ - WARNING -   Skipped train sample 171 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,747 - __main__ - WARNING -   Skipped train sample 172 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,752 - __main__ - WARNING -   Skipped train sample 173 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,756 - __main__ - WARNING -   Skipped train sample 174 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,760 - __main__ - WARNING -   Skipped train sample 175 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,762 - __main__ - WARNING -   Skipped train sample 176 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,767 - __main__ - WARNING -   Skipped train sample 177 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,769 - __main__ - WARNING -   Skipped train sample 178 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,771 - __main__ - WARNING -   Skipped train sample 179 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,775 - __main__ - WARNING -   Skipped train sample 180 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,777 - __main__ - WARNING -   Skipped train sample 181 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,780 - __main__ - WARNING -   Skipped train sample 182 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,786 - __main__ - WARNING -   Skipped train sample 183 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,789 - __main__ - WARNING -   Skipped train sample 184 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,794 - __main__ - WARNING -   Skipped train sample 185 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,797 - __main__ - WARNING -   Skipped train sample 186 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,799 - __main__ - WARNING -   Skipped train sample 187 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,800 - __main__ - WARNING -   Skipped train sample 188 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,803 - __main__ - WARNING -   Skipped train sample 189 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,811 - __main__ - WARNING -   Skipped train sample 190 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,814 - __main__ - WARNING -   Skipped train sample 191 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,816 - __main__ - WARNING -   Skipped train sample 192 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,821 - __main__ - WARNING -   Skipped train sample 193 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,825 - __main__ - WARNING -   Skipped train sample 194 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,831 - __main__ - WARNING -   Skipped train sample 195 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,833 - __main__ - WARNING -   Skipped train sample 196 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,837 - __main__ - WARNING -   Skipped train sample 197 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,839 - __main__ - WARNING -   Skipped train sample 198 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,842 - __main__ - WARNING -   Skipped train sample 199 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,845 - __main__ - WARNING -   Skipped train sample 200 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,847 - __main__ - WARNING -   Skipped train sample 201 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,851 - __main__ - WARNING -   Skipped train sample 202 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,855 - __main__ - WARNING -   Skipped train sample 203 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,858 - __main__ - WARNING -   Skipped train sample 204 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,861 - __main__ - WARNING -   Skipped train sample 205 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,865 - __main__ - WARNING -   Skipped train sample 206 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,869 - __main__ - WARNING -   Skipped train sample 207 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,872 - __main__ - WARNING -   Skipped train sample 208 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,875 - __main__ - WARNING -   Skipped train sample 209 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,878 - __main__ - WARNING -   Skipped train sample 210 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,880 - __main__ - WARNING -   Skipped train sample 211 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,883 - __main__ - WARNING -   Skipped train sample 212 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,885 - __main__ - WARNING -   Skipped train sample 213 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,887 - __main__ - WARNING -   Skipped train sample 214 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,889 - __main__ - WARNING -   Skipped train sample 215 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,891 - __main__ - WARNING -   Skipped train sample 216 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,895 - __main__ - WARNING -   Skipped train sample 217 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,897 - __main__ - WARNING -   Skipped train sample 218 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,903 - __main__ - WARNING -   Skipped train sample 219 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,906 - __main__ - WARNING -   Skipped train sample 220 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,909 - __main__ - WARNING -   Skipped train sample 221 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,917 - __main__ - WARNING -   Skipped train sample 222 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,921 - __main__ - WARNING -   Skipped train sample 223 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,925 - __main__ - WARNING -   Skipped train sample 224 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,928 - __main__ - WARNING -   Skipped train sample 225 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,930 - __main__ - WARNING -   Skipped train sample 226 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,932 - __main__ - WARNING -   Skipped train sample 227 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,934 - __main__ - WARNING -   Skipped train sample 228 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,937 - __main__ - WARNING -   Skipped train sample 229 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,942 - __main__ - WARNING -   Skipped train sample 230 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,945 - __main__ - WARNING -   Skipped train sample 231 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,949 - __main__ - WARNING -   Skipped train sample 232 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,951 - __main__ - WARNING -   Skipped train sample 233 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,953 - __main__ - WARNING -   Skipped train sample 234 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,957 - __main__ - WARNING -   Skipped train sample 235 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,960 - __main__ - WARNING -   Skipped train sample 236 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,964 - __main__ - WARNING -   Skipped train sample 237 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,969 - __main__ - WARNING -   Skipped train sample 238 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,971 - __main__ - WARNING -   Skipped train sample 239 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,977 - __main__ - WARNING -   Skipped train sample 240 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,981 - __main__ - WARNING -   Skipped train sample 241 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,986 - __main__ - WARNING -   Skipped train sample 242 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,989 - __main__ - WARNING -   Skipped train sample 243 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,993 - __main__ - WARNING -   Skipped train sample 244 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,995 - __main__ - WARNING -   Skipped train sample 245 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:10,998 - __main__ - WARNING -   Skipped train sample 246 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,001 - __main__ - WARNING -   Skipped train sample 247 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,007 - __main__ - WARNING -   Skipped train sample 248 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,010 - __main__ - WARNING -   Skipped train sample 249 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,013 - __main__ - WARNING -   Skipped train sample 250 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,025 - __main__ - WARNING -   Skipped train sample 251 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,029 - __main__ - WARNING -   Skipped train sample 252 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,032 - __main__ - WARNING -   Skipped train sample 253 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,034 - __main__ - WARNING -   Skipped train sample 254 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,036 - __main__ - WARNING -   Skipped train sample 255 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,039 - __main__ - WARNING -   Skipped train sample 256 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,043 - __main__ - WARNING -   Skipped train sample 257 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,047 - __main__ - WARNING -   Skipped train sample 258 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,050 - __main__ - WARNING -   Skipped train sample 259 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,054 - __main__ - WARNING -   Skipped train sample 260 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,062 - __main__ - WARNING -   Skipped train sample 261 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,065 - __main__ - WARNING -   Skipped train sample 262 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,067 - __main__ - WARNING -   Skipped train sample 263 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,070 - __main__ - WARNING -   Skipped train sample 264 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,072 - __main__ - WARNING -   Skipped train sample 265 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,077 - __main__ - WARNING -   Skipped train sample 266 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,082 - __main__ - WARNING -   Skipped train sample 267 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,084 - __main__ - WARNING -   Skipped train sample 268 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,087 - __main__ - WARNING -   Skipped train sample 269 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,094 - __main__ - WARNING -   Skipped train sample 270 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,096 - __main__ - WARNING -   Skipped train sample 271 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,102 - __main__ - WARNING -   Skipped train sample 272 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,106 - __main__ - WARNING -   Skipped train sample 273 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,109 - __main__ - WARNING -   Skipped train sample 274 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,111 - __main__ - WARNING -   Skipped train sample 275 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,116 - __main__ - WARNING -   Skipped train sample 276 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,119 - __main__ - WARNING -   Skipped train sample 277 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,122 - __main__ - WARNING -   Skipped train sample 278 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,124 - __main__ - WARNING -   Skipped train sample 279 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,127 - __main__ - WARNING -   Skipped train sample 280 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,129 - __main__ - WARNING -   Skipped train sample 281 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,132 - __main__ - WARNING -   Skipped train sample 282 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,135 - __main__ - WARNING -   Skipped train sample 283 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,142 - __main__ - WARNING -   Skipped train sample 284 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,145 - __main__ - WARNING -   Skipped train sample 285 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,148 - __main__ - WARNING -   Skipped train sample 286 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,151 - __main__ - WARNING -   Skipped train sample 287 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,154 - __main__ - WARNING -   Skipped train sample 288 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,156 - __main__ - WARNING -   Skipped train sample 289 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,159 - __main__ - WARNING -   Skipped train sample 290 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,162 - __main__ - WARNING -   Skipped train sample 291 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,166 - __main__ - WARNING -   Skipped train sample 292 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,168 - __main__ - WARNING -   Skipped train sample 293 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,171 - __main__ - WARNING -   Skipped train sample 294 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,176 - __main__ - WARNING -   Skipped train sample 295 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,179 - __main__ - WARNING -   Skipped train sample 296 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,183 - __main__ - WARNING -   Skipped train sample 297 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,187 - __main__ - WARNING -   Skipped train sample 298 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,190 - __main__ - WARNING -   Skipped train sample 299 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,196 - __main__ - WARNING -   Skipped train sample 300 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,199 - __main__ - WARNING -   Skipped train sample 301 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,202 - __main__ - WARNING -   Skipped train sample 302 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,207 - __main__ - WARNING -   Skipped train sample 303 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,211 - __main__ - WARNING -   Skipped train sample 304 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,214 - __main__ - WARNING -   Skipped train sample 305 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,217 - __main__ - WARNING -   Skipped train sample 306 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,221 - __main__ - WARNING -   Skipped train sample 307 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,224 - __main__ - WARNING -   Skipped train sample 308 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,229 - __main__ - WARNING -   Skipped train sample 309 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,232 - __main__ - WARNING -   Skipped train sample 310 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,236 - __main__ - WARNING -   Skipped train sample 311 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,239 - __main__ - WARNING -   Skipped train sample 312 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,243 - __main__ - WARNING -   Skipped train sample 313 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,245 - __main__ - WARNING -   Skipped train sample 314 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,248 - __main__ - WARNING -   Skipped train sample 315 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,250 - __main__ - WARNING -   Skipped train sample 316 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,253 - __main__ - WARNING -   Skipped train sample 317 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,257 - __main__ - WARNING -   Skipped train sample 318 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,259 - __main__ - WARNING -   Skipped train sample 319 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,261 - __main__ - WARNING -   Skipped train sample 320 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,267 - __main__ - WARNING -   Skipped train sample 321 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,270 - __main__ - WARNING -   Skipped train sample 322 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,275 - __main__ - WARNING -   Skipped train sample 323 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,277 - __main__ - WARNING -   Skipped train sample 324 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,281 - __main__ - WARNING -   Skipped train sample 325 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,286 - __main__ - WARNING -   Skipped train sample 326 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,289 - __main__ - WARNING -   Skipped train sample 327 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,294 - __main__ - WARNING -   Skipped train sample 328 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,297 - __main__ - WARNING -   Skipped train sample 329 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,300 - __main__ - WARNING -   Skipped train sample 330 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,303 - __main__ - WARNING -   Skipped train sample 331 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,305 - __main__ - WARNING -   Skipped train sample 332 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,309 - __main__ - WARNING -   Skipped train sample 333 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,311 - __main__ - WARNING -   Skipped train sample 334 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,315 - __main__ - WARNING -   Skipped train sample 335 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,318 - __main__ - WARNING -   Skipped train sample 336 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,321 - __main__ - WARNING -   Skipped train sample 337 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,323 - __main__ - WARNING -   Skipped train sample 338 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,325 - __main__ - WARNING -   Skipped train sample 339 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,330 - __main__ - WARNING -   Skipped train sample 340 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,339 - __main__ - WARNING -   Skipped train sample 341 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,350 - __main__ - WARNING -   Skipped train sample 342 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,353 - __main__ - WARNING -   Skipped train sample 343 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,358 - __main__ - WARNING -   Skipped train sample 344 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,361 - __main__ - WARNING -   Skipped train sample 345 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,363 - __main__ - WARNING -   Skipped train sample 346 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,365 - __main__ - WARNING -   Skipped train sample 347 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,370 - __main__ - WARNING -   Skipped train sample 348 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,373 - __main__ - WARNING -   Skipped train sample 349 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,380 - __main__ - WARNING -   Skipped train sample 350 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,383 - __main__ - WARNING -   Skipped train sample 351 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,385 - __main__ - WARNING -   Skipped train sample 352 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,387 - __main__ - WARNING -   Skipped train sample 353 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,390 - __main__ - WARNING -   Skipped train sample 354 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,392 - __main__ - WARNING -   Skipped train sample 355 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,395 - __main__ - WARNING -   Skipped train sample 356 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,399 - __main__ - WARNING -   Skipped train sample 357 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,402 - __main__ - WARNING -   Skipped train sample 358 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,404 - __main__ - WARNING -   Skipped train sample 359 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,406 - __main__ - WARNING -   Skipped train sample 360 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,414 - __main__ - WARNING -   Skipped train sample 361 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,420 - __main__ - WARNING -   Skipped train sample 362 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,423 - __main__ - WARNING -   Skipped train sample 363 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,428 - __main__ - WARNING -   Skipped train sample 364 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,430 - __main__ - WARNING -   Skipped train sample 365 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,432 - __main__ - WARNING -   Skipped train sample 366 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,438 - __main__ - WARNING -   Skipped train sample 367 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,440 - __main__ - WARNING -   Skipped train sample 368 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,442 - __main__ - WARNING -   Skipped train sample 369 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,445 - __main__ - WARNING -   Skipped train sample 370 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,448 - __main__ - WARNING -   Skipped train sample 371 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,451 - __main__ - WARNING -   Skipped train sample 372 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,456 - __main__ - WARNING -   Skipped train sample 373 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,460 - __main__ - WARNING -   Skipped train sample 374 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,464 - __main__ - WARNING -   Skipped train sample 375 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,467 - __main__ - WARNING -   Skipped train sample 376 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,469 - __main__ - WARNING -   Skipped train sample 377 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,471 - __main__ - WARNING -   Skipped train sample 378 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,473 - __main__ - WARNING -   Skipped train sample 379 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,475 - __main__ - WARNING -   Skipped train sample 380 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,478 - __main__ - WARNING -   Skipped train sample 381 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,480 - __main__ - WARNING -   Skipped train sample 382 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,483 - __main__ - WARNING -   Skipped train sample 383 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,485 - __main__ - WARNING -   Skipped train sample 384 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,491 - __main__ - WARNING -   Skipped train sample 385 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,493 - __main__ - WARNING -   Skipped train sample 386 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,499 - __main__ - WARNING -   Skipped train sample 387 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,501 - __main__ - WARNING -   Skipped train sample 388 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,503 - __main__ - WARNING -   Skipped train sample 389 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,506 - __main__ - WARNING -   Skipped train sample 390 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,509 - __main__ - WARNING -   Skipped train sample 391 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,512 - __main__ - WARNING -   Skipped train sample 392 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,515 - __main__ - WARNING -   Skipped train sample 393 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,517 - __main__ - WARNING -   Skipped train sample 394 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,519 - __main__ - WARNING -   Skipped train sample 395 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,521 - __main__ - WARNING -   Skipped train sample 396 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,525 - __main__ - WARNING -   Skipped train sample 397 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,528 - __main__ - WARNING -   Skipped train sample 398 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,531 - __main__ - WARNING -   Skipped train sample 399 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,533 - __main__ - WARNING -   Skipped train sample 400 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,535 - __main__ - WARNING -   Skipped train sample 401 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,537 - __main__ - WARNING -   Skipped train sample 402 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,540 - __main__ - WARNING -   Skipped train sample 403 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,542 - __main__ - WARNING -   Skipped train sample 404 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,545 - __main__ - WARNING -   Skipped train sample 405 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,550 - __main__ - WARNING -   Skipped train sample 406 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,563 - __main__ - WARNING -   Skipped train sample 407 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,565 - __main__ - WARNING -   Skipped train sample 408 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,567 - __main__ - WARNING -   Skipped train sample 409 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,570 - __main__ - WARNING -   Skipped train sample 410 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,577 - __main__ - WARNING -   Skipped train sample 411 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,590 - __main__ - WARNING -   Skipped train sample 412 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,593 - __main__ - WARNING -   Skipped train sample 413 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,596 - __main__ - WARNING -   Skipped train sample 414 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,600 - __main__ - WARNING -   Skipped train sample 415 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,602 - __main__ - WARNING -   Skipped train sample 416 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,606 - __main__ - WARNING -   Skipped train sample 417 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,610 - __main__ - WARNING -   Skipped train sample 418 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,614 - __main__ - WARNING -   Skipped train sample 419 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,616 - __main__ - WARNING -   Skipped train sample 420 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,619 - __main__ - WARNING -   Skipped train sample 421 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,622 - __main__ - WARNING -   Skipped train sample 422 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,626 - __main__ - WARNING -   Skipped train sample 423 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,628 - __main__ - WARNING -   Skipped train sample 424 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,630 - __main__ - WARNING -   Skipped train sample 425 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,633 - __main__ - WARNING -   Skipped train sample 426 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,636 - __main__ - WARNING -   Skipped train sample 427 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,638 - __main__ - WARNING -   Skipped train sample 428 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,640 - __main__ - WARNING -   Skipped train sample 429 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,643 - __main__ - WARNING -   Skipped train sample 430 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,645 - __main__ - WARNING -   Skipped train sample 431 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,647 - __main__ - WARNING -   Skipped train sample 432 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,651 - __main__ - WARNING -   Skipped train sample 433 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,654 - __main__ - WARNING -   Skipped train sample 434 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,659 - __main__ - WARNING -   Skipped train sample 435 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,661 - __main__ - WARNING -   Skipped train sample 436 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,664 - __main__ - WARNING -   Skipped train sample 437 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,666 - __main__ - WARNING -   Skipped train sample 438 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,668 - __main__ - WARNING -   Skipped train sample 439 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,670 - __main__ - WARNING -   Skipped train sample 440 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,675 - __main__ - WARNING -   Skipped train sample 441 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,678 - __main__ - WARNING -   Skipped train sample 442 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,680 - __main__ - WARNING -   Skipped train sample 443 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,684 - __main__ - WARNING -   Skipped train sample 444 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,687 - __main__ - WARNING -   Skipped train sample 445 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,691 - __main__ - WARNING -   Skipped train sample 446 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,694 - __main__ - WARNING -   Skipped train sample 447 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,696 - __main__ - WARNING -   Skipped train sample 448 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,699 - __main__ - WARNING -   Skipped train sample 449 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,700 - __main__ - WARNING -   Skipped train sample 450 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,703 - __main__ - WARNING -   Skipped train sample 451 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,707 - __main__ - WARNING -   Skipped train sample 452 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,710 - __main__ - WARNING -   Skipped train sample 453 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,712 - __main__ - WARNING -   Skipped train sample 454 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,715 - __main__ - WARNING -   Skipped train sample 455 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,717 - __main__ - WARNING -   Skipped train sample 456 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,720 - __main__ - WARNING -   Skipped train sample 457 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,724 - __main__ - WARNING -   Skipped train sample 458 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,727 - __main__ - WARNING -   Skipped train sample 459 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,733 - __main__ - WARNING -   Skipped train sample 460 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,736 - __main__ - WARNING -   Skipped train sample 461 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,739 - __main__ - WARNING -   Skipped train sample 462 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,742 - __main__ - WARNING -   Skipped train sample 463 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,745 - __main__ - WARNING -   Skipped train sample 464 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,749 - __main__ - WARNING -   Skipped train sample 465 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,751 - __main__ - WARNING -   Skipped train sample 466 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,753 - __main__ - WARNING -   Skipped train sample 467 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,757 - __main__ - WARNING -   Skipped train sample 468 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,759 - __main__ - WARNING -   Skipped train sample 469 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,761 - __main__ - WARNING -   Skipped train sample 470 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,765 - __main__ - WARNING -   Skipped train sample 471 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,769 - __main__ - WARNING -   Skipped train sample 472 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,773 - __main__ - WARNING -   Skipped train sample 473 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,776 - __main__ - WARNING -   Skipped train sample 474 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,779 - __main__ - WARNING -   Skipped train sample 475 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,781 - __main__ - WARNING -   Skipped train sample 476 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,783 - __main__ - WARNING -   Skipped train sample 477 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,786 - __main__ - WARNING -   Skipped train sample 478 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,789 - __main__ - WARNING -   Skipped train sample 479 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,791 - __main__ - WARNING -   Skipped train sample 480 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,794 - __main__ - WARNING -   Skipped train sample 481 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,797 - __main__ - WARNING -   Skipped train sample 482 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,800 - __main__ - WARNING -   Skipped train sample 483 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,804 - __main__ - WARNING -   Skipped train sample 484 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,808 - __main__ - WARNING -   Skipped train sample 485 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,811 - __main__ - WARNING -   Skipped train sample 486 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,814 - __main__ - WARNING -   Skipped train sample 487 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,817 - __main__ - WARNING -   Skipped train sample 488 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,823 - __main__ - WARNING -   Skipped train sample 489 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,828 - __main__ - WARNING -   Skipped train sample 490 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,832 - __main__ - WARNING -   Skipped train sample 491 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,840 - __main__ - WARNING -   Skipped train sample 492 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,847 - __main__ - WARNING -   Skipped train sample 493 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,853 - __main__ - WARNING -   Skipped train sample 494 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,855 - __main__ - WARNING -   Skipped train sample 495 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,862 - __main__ - WARNING -   Skipped train sample 496 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,866 - __main__ - WARNING -   Skipped train sample 497 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,874 - __main__ - WARNING -   Skipped train sample 498 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,879 - __main__ - WARNING -   Skipped train sample 499 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,882 - __main__ - WARNING -   Skipped train sample 500 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,885 - __main__ - WARNING -   Skipped train sample 501 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,888 - __main__ - WARNING -   Skipped train sample 502 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,891 - __main__ - WARNING -   Skipped train sample 503 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,896 - __main__ - WARNING -   Skipped train sample 504 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,899 - __main__ - WARNING -   Skipped train sample 505 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,902 - __main__ - WARNING -   Skipped train sample 506 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,905 - __main__ - WARNING -   Skipped train sample 507 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,910 - __main__ - WARNING -   Skipped train sample 508 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,912 - __main__ - WARNING -   Skipped train sample 509 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,915 - __main__ - WARNING -   Skipped train sample 510 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,920 - __main__ - WARNING -   Skipped train sample 511 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,922 - __main__ - WARNING -   Skipped train sample 512 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,924 - __main__ - WARNING -   Skipped train sample 513 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,927 - __main__ - WARNING -   Skipped train sample 514 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,932 - __main__ - WARNING -   Skipped train sample 515 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,935 - __main__ - WARNING -   Skipped train sample 516 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,940 - __main__ - WARNING -   Skipped train sample 517 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,942 - __main__ - WARNING -   Skipped train sample 518 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,946 - __main__ - WARNING -   Skipped train sample 519 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,949 - __main__ - WARNING -   Skipped train sample 520 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,953 - __main__ - WARNING -   Skipped train sample 521 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,956 - __main__ - WARNING -   Skipped train sample 522 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,958 - __main__ - WARNING -   Skipped train sample 523 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,961 - __main__ - WARNING -   Skipped train sample 524 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,963 - __main__ - WARNING -   Skipped train sample 525 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,967 - __main__ - WARNING -   Skipped train sample 526 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,970 - __main__ - WARNING -   Skipped train sample 527 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,975 - __main__ - WARNING -   Skipped train sample 528 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,980 - __main__ - WARNING -   Skipped train sample 529 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,983 - __main__ - WARNING -   Skipped train sample 530 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,985 - __main__ - WARNING -   Skipped train sample 531 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,990 - __main__ - WARNING -   Skipped train sample 532 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:11,993 - __main__ - WARNING -   Skipped train sample 533 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,008 - __main__ - WARNING -   Skipped train sample 534 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,012 - __main__ - WARNING -   Skipped train sample 535 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,015 - __main__ - WARNING -   Skipped train sample 536 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,017 - __main__ - WARNING -   Skipped train sample 537 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,020 - __main__ - WARNING -   Skipped train sample 538 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,022 - __main__ - WARNING -   Skipped train sample 539 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,025 - __main__ - WARNING -   Skipped train sample 540 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,027 - __main__ - WARNING -   Skipped train sample 541 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,029 - __main__ - WARNING -   Skipped train sample 542 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,032 - __main__ - WARNING -   Skipped train sample 543 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,034 - __main__ - WARNING -   Skipped train sample 544 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,037 - __main__ - WARNING -   Skipped train sample 545 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,041 - __main__ - WARNING -   Skipped train sample 546 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,044 - __main__ - WARNING -   Skipped train sample 547 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,046 - __main__ - WARNING -   Skipped train sample 548 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,050 - __main__ - WARNING -   Skipped train sample 549 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,056 - __main__ - WARNING -   Skipped train sample 550 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,062 - __main__ - WARNING -   Skipped train sample 551 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,064 - __main__ - WARNING -   Skipped train sample 552 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,067 - __main__ - WARNING -   Skipped train sample 553 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,071 - __main__ - WARNING -   Skipped train sample 554 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,075 - __main__ - WARNING -   Skipped train sample 555 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,078 - __main__ - WARNING -   Skipped train sample 556 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,081 - __main__ - WARNING -   Skipped train sample 557 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,083 - __main__ - WARNING -   Skipped train sample 558 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,085 - __main__ - WARNING -   Skipped train sample 559 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,091 - __main__ - WARNING -   Skipped train sample 560 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,093 - __main__ - WARNING -   Skipped train sample 561 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,095 - __main__ - WARNING -   Skipped train sample 562 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,099 - __main__ - WARNING -   Skipped train sample 563 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,104 - __main__ - WARNING -   Skipped train sample 564 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,106 - __main__ - WARNING -   Skipped train sample 565 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,109 - __main__ - WARNING -   Skipped train sample 566 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,112 - __main__ - WARNING -   Skipped train sample 567 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,115 - __main__ - WARNING -   Skipped train sample 568 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,119 - __main__ - WARNING -   Skipped train sample 569 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,121 - __main__ - WARNING -   Skipped train sample 570 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,125 - __main__ - WARNING -   Skipped train sample 571 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,128 - __main__ - WARNING -   Skipped train sample 572 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,131 - __main__ - WARNING -   Skipped train sample 573 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,133 - __main__ - WARNING -   Skipped train sample 574 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,137 - __main__ - WARNING -   Skipped train sample 575 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,141 - __main__ - WARNING -   Skipped train sample 576 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,145 - __main__ - WARNING -   Skipped train sample 577 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,147 - __main__ - WARNING -   Skipped train sample 578 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,150 - __main__ - WARNING -   Skipped train sample 579 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,151 - __main__ - WARNING -   Skipped train sample 580 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,153 - __main__ - WARNING -   Skipped train sample 581 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,155 - __main__ - WARNING -   Skipped train sample 582 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,158 - __main__ - WARNING -   Skipped train sample 583 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,161 - __main__ - WARNING -   Skipped train sample 584 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,163 - __main__ - WARNING -   Skipped train sample 585 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,165 - __main__ - WARNING -   Skipped train sample 586 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,167 - __main__ - WARNING -   Skipped train sample 587 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,176 - __main__ - WARNING -   Skipped train sample 588 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,180 - __main__ - WARNING -   Skipped train sample 589 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,182 - __main__ - WARNING -   Skipped train sample 590 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,187 - __main__ - WARNING -   Skipped train sample 591 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,193 - __main__ - WARNING -   Skipped train sample 592 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,196 - __main__ - WARNING -   Skipped train sample 593 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,200 - __main__ - WARNING -   Skipped train sample 594 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,203 - __main__ - WARNING -   Skipped train sample 595 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,205 - __main__ - WARNING -   Skipped train sample 596 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,208 - __main__ - WARNING -   Skipped train sample 597 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,210 - __main__ - WARNING -   Skipped train sample 598 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,213 - __main__ - WARNING -   Skipped train sample 599 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,216 - __main__ - WARNING -   Skipped train sample 600 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,219 - __main__ - WARNING -   Skipped train sample 601 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,223 - __main__ - WARNING -   Skipped train sample 602 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,225 - __main__ - WARNING -   Skipped train sample 603 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,227 - __main__ - WARNING -   Skipped train sample 604 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,232 - __main__ - WARNING -   Skipped train sample 605 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,238 - __main__ - WARNING -   Skipped train sample 606 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,241 - __main__ - WARNING -   Skipped train sample 607 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,243 - __main__ - WARNING -   Skipped train sample 608 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,247 - __main__ - WARNING -   Skipped train sample 609 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,249 - __main__ - WARNING -   Skipped train sample 610 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,251 - __main__ - WARNING -   Skipped train sample 611 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,254 - __main__ - WARNING -   Skipped train sample 612 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,258 - __main__ - WARNING -   Skipped train sample 613 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,263 - __main__ - WARNING -   Skipped train sample 614 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,265 - __main__ - WARNING -   Skipped train sample 615 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,267 - __main__ - WARNING -   Skipped train sample 616 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,273 - __main__ - WARNING -   Skipped train sample 617 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,276 - __main__ - WARNING -   Skipped train sample 618 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,277 - __main__ - WARNING -   Skipped train sample 619 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,284 - __main__ - WARNING -   Skipped train sample 620 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,295 - __main__ - WARNING -   Skipped train sample 621 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,298 - __main__ - WARNING -   Skipped train sample 622 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,302 - __main__ - WARNING -   Skipped train sample 623 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,304 - __main__ - WARNING -   Skipped train sample 624 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,307 - __main__ - WARNING -   Skipped train sample 625 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,309 - __main__ - WARNING -   Skipped train sample 626 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,313 - __main__ - WARNING -   Skipped train sample 627 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,316 - __main__ - WARNING -   Skipped train sample 628 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,319 - __main__ - WARNING -   Skipped train sample 629 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,323 - __main__ - WARNING -   Skipped train sample 630 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,326 - __main__ - WARNING -   Skipped train sample 631 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,329 - __main__ - WARNING -   Skipped train sample 632 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,335 - __main__ - WARNING -   Skipped train sample 633 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,338 - __main__ - WARNING -   Skipped train sample 634 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,341 - __main__ - WARNING -   Skipped train sample 635 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,344 - __main__ - WARNING -   Skipped train sample 636 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,348 - __main__ - WARNING -   Skipped train sample 637 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,351 - __main__ - WARNING -   Skipped train sample 638 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,354 - __main__ - WARNING -   Skipped train sample 639 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,356 - __main__ - WARNING -   Skipped train sample 640 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,359 - __main__ - WARNING -   Skipped train sample 641 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,362 - __main__ - WARNING -   Skipped train sample 642 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,370 - __main__ - WARNING -   Skipped train sample 643 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,374 - __main__ - WARNING -   Skipped train sample 644 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,380 - __main__ - WARNING -   Skipped train sample 645 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,383 - __main__ - WARNING -   Skipped train sample 646 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,386 - __main__ - WARNING -   Skipped train sample 647 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,389 - __main__ - WARNING -   Skipped train sample 648 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,392 - __main__ - WARNING -   Skipped train sample 649 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,396 - __main__ - WARNING -   Skipped train sample 650 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,397 - __main__ - WARNING -   Skipped train sample 651 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,400 - __main__ - WARNING -   Skipped train sample 652 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,402 - __main__ - WARNING -   Skipped train sample 653 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,404 - __main__ - WARNING -   Skipped train sample 654 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,408 - __main__ - WARNING -   Skipped train sample 655 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,411 - __main__ - WARNING -   Skipped train sample 656 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,416 - __main__ - WARNING -   Skipped train sample 657 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,419 - __main__ - WARNING -   Skipped train sample 658 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,422 - __main__ - WARNING -   Skipped train sample 659 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,424 - __main__ - WARNING -   Skipped train sample 660 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,426 - __main__ - WARNING -   Skipped train sample 661 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,429 - __main__ - WARNING -   Skipped train sample 662 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,435 - __main__ - WARNING -   Skipped train sample 663 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,445 - __main__ - WARNING -   Skipped train sample 664 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,448 - __main__ - WARNING -   Skipped train sample 665 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,454 - __main__ - WARNING -   Skipped train sample 666 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,460 - __main__ - WARNING -   Skipped train sample 667 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,462 - __main__ - WARNING -   Skipped train sample 668 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,464 - __main__ - WARNING -   Skipped train sample 669 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,468 - __main__ - WARNING -   Skipped train sample 670 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,470 - __main__ - WARNING -   Skipped train sample 671 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,473 - __main__ - WARNING -   Skipped train sample 672 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,475 - __main__ - WARNING -   Skipped train sample 673 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,481 - __main__ - WARNING -   Skipped train sample 674 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,485 - __main__ - WARNING -   Skipped train sample 675 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,487 - __main__ - WARNING -   Skipped train sample 676 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,491 - __main__ - WARNING -   Skipped train sample 677 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,494 - __main__ - WARNING -   Skipped train sample 678 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,497 - __main__ - WARNING -   Skipped train sample 679 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,498 - __main__ - WARNING -   Skipped train sample 680 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,500 - __main__ - WARNING -   Skipped train sample 681 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,503 - __main__ - WARNING -   Skipped train sample 682 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,505 - __main__ - WARNING -   Skipped train sample 683 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,508 - __main__ - WARNING -   Skipped train sample 684 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,512 - __main__ - WARNING -   Skipped train sample 685 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,515 - __main__ - WARNING -   Skipped train sample 686 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,517 - __main__ - WARNING -   Skipped train sample 687 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,520 - __main__ - WARNING -   Skipped train sample 688 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,523 - __main__ - WARNING -   Skipped train sample 689 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,528 - __main__ - WARNING -   Skipped train sample 690 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,530 - __main__ - WARNING -   Skipped train sample 691 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,533 - __main__ - WARNING -   Skipped train sample 692 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,537 - __main__ - WARNING -   Skipped train sample 693 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,540 - __main__ - WARNING -   Skipped train sample 694 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,543 - __main__ - WARNING -   Skipped train sample 695 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,545 - __main__ - WARNING -   Skipped train sample 696 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,547 - __main__ - WARNING -   Skipped train sample 697 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,550 - __main__ - WARNING -   Skipped train sample 698 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,552 - __main__ - WARNING -   Skipped train sample 699 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,556 - __main__ - WARNING -   Skipped train sample 700 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,559 - __main__ - WARNING -   Skipped train sample 701 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,572 - __main__ - WARNING -   Skipped train sample 702 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,575 - __main__ - WARNING -   Skipped train sample 703 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,577 - __main__ - WARNING -   Skipped train sample 704 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,579 - __main__ - WARNING -   Skipped train sample 705 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,585 - __main__ - WARNING -   Skipped train sample 706 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,589 - __main__ - WARNING -   Skipped train sample 707 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,592 - __main__ - WARNING -   Skipped train sample 708 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,596 - __main__ - WARNING -   Skipped train sample 709 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,601 - __main__ - WARNING -   Skipped train sample 710 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,608 - __main__ - WARNING -   Skipped train sample 711 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,610 - __main__ - WARNING -   Skipped train sample 712 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,616 - __main__ - WARNING -   Skipped train sample 713 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,620 - __main__ - WARNING -   Skipped train sample 714 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,626 - __main__ - WARNING -   Skipped train sample 715 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,628 - __main__ - WARNING -   Skipped train sample 716 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,637 - __main__ - WARNING -   Skipped train sample 717 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,641 - __main__ - WARNING -   Skipped train sample 718 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,645 - __main__ - WARNING -   Skipped train sample 719 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,647 - __main__ - WARNING -   Skipped train sample 720 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,652 - __main__ - WARNING -   Skipped train sample 721 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,655 - __main__ - WARNING -   Skipped train sample 722 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,657 - __main__ - WARNING -   Skipped train sample 723 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,662 - __main__ - WARNING -   Skipped train sample 724 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,667 - __main__ - WARNING -   Skipped train sample 725 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,671 - __main__ - WARNING -   Skipped train sample 726 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,673 - __main__ - WARNING -   Skipped train sample 727 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,677 - __main__ - WARNING -   Skipped train sample 728 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,681 - __main__ - WARNING -   Skipped train sample 729 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,683 - __main__ - WARNING -   Skipped train sample 730 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,686 - __main__ - WARNING -   Skipped train sample 731 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,688 - __main__ - WARNING -   Skipped train sample 732 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,690 - __main__ - WARNING -   Skipped train sample 733 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,693 - __main__ - WARNING -   Skipped train sample 734 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,701 - __main__ - WARNING -   Skipped train sample 735 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,705 - __main__ - WARNING -   Skipped train sample 736 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,708 - __main__ - WARNING -   Skipped train sample 737 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,710 - __main__ - WARNING -   Skipped train sample 738 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,712 - __main__ - WARNING -   Skipped train sample 739 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,714 - __main__ - WARNING -   Skipped train sample 740 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,718 - __main__ - WARNING -   Skipped train sample 741 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,721 - __main__ - WARNING -   Skipped train sample 742 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,724 - __main__ - WARNING -   Skipped train sample 743 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,727 - __main__ - WARNING -   Skipped train sample 744 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,739 - __main__ - WARNING -   Skipped train sample 745 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,741 - __main__ - WARNING -   Skipped train sample 746 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,745 - __main__ - WARNING -   Skipped train sample 747 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,747 - __main__ - WARNING -   Skipped train sample 748 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,749 - __main__ - WARNING -   Skipped train sample 749 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,753 - __main__ - WARNING -   Skipped train sample 750 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,756 - __main__ - WARNING -   Skipped train sample 751 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,759 - __main__ - WARNING -   Skipped train sample 752 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,762 - __main__ - WARNING -   Skipped train sample 753 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,764 - __main__ - WARNING -   Skipped train sample 754 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,769 - __main__ - WARNING -   Skipped train sample 755 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,772 - __main__ - WARNING -   Skipped train sample 756 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,775 - __main__ - WARNING -   Skipped train sample 757 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,782 - __main__ - WARNING -   Skipped train sample 758 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,784 - __main__ - WARNING -   Skipped train sample 759 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,786 - __main__ - WARNING -   Skipped train sample 760 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,789 - __main__ - WARNING -   Skipped train sample 761 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,792 - __main__ - WARNING -   Skipped train sample 762 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,801 - __main__ - WARNING -   Skipped train sample 763 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,803 - __main__ - WARNING -   Skipped train sample 764 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,807 - __main__ - WARNING -   Skipped train sample 765 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,810 - __main__ - WARNING -   Skipped train sample 766 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,816 - __main__ - WARNING -   Skipped train sample 767 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,819 - __main__ - WARNING -   Skipped train sample 768 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,822 - __main__ - WARNING -   Skipped train sample 769 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,826 - __main__ - WARNING -   Skipped train sample 770 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,830 - __main__ - WARNING -   Skipped train sample 771 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,833 - __main__ - WARNING -   Skipped train sample 772 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,835 - __main__ - WARNING -   Skipped train sample 773 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,837 - __main__ - WARNING -   Skipped train sample 774 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,889 - __main__ - WARNING -   Skipped train sample 775 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,904 - __main__ - WARNING -   Skipped train sample 776 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,906 - __main__ - WARNING -   Skipped train sample 777 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,911 - __main__ - WARNING -   Skipped train sample 778 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,915 - __main__ - WARNING -   Skipped train sample 779 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,918 - __main__ - WARNING -   Skipped train sample 780 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,920 - __main__ - WARNING -   Skipped train sample 781 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,927 - __main__ - WARNING -   Skipped train sample 782 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,930 - __main__ - WARNING -   Skipped train sample 783 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,943 - __main__ - WARNING -   Skipped train sample 784 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,948 - __main__ - WARNING -   Skipped train sample 785 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,956 - __main__ - WARNING -   Skipped train sample 786 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,961 - __main__ - WARNING -   Skipped train sample 787 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,964 - __main__ - WARNING -   Skipped train sample 788 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,969 - __main__ - WARNING -   Skipped train sample 789 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,973 - __main__ - WARNING -   Skipped train sample 790 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,976 - __main__ - WARNING -   Skipped train sample 791 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,979 - __main__ - WARNING -   Skipped train sample 792 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,982 - __main__ - WARNING -   Skipped train sample 793 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,989 - __main__ - WARNING -   Skipped train sample 794 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,995 - __main__ - WARNING -   Skipped train sample 795 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:12,998 - __main__ - WARNING -   Skipped train sample 796 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,011 - __main__ - WARNING -   Skipped train sample 797 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,025 - __main__ - WARNING -   Skipped train sample 798 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,028 - __main__ - WARNING -   Skipped train sample 799 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,032 - __main__ - WARNING -   Skipped train sample 800 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,037 - __main__ - WARNING -   Skipped train sample 801 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,039 - __main__ - WARNING -   Skipped train sample 802 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,042 - __main__ - WARNING -   Skipped train sample 803 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,048 - __main__ - WARNING -   Skipped train sample 804 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,052 - __main__ - WARNING -   Skipped train sample 805 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,055 - __main__ - WARNING -   Skipped train sample 806 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,058 - __main__ - WARNING -   Skipped train sample 807 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,061 - __main__ - WARNING -   Skipped train sample 808 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,064 - __main__ - WARNING -   Skipped train sample 809 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,072 - __main__ - WARNING -   Skipped train sample 810 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,075 - __main__ - WARNING -   Skipped train sample 811 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,077 - __main__ - WARNING -   Skipped train sample 812 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,081 - __main__ - WARNING -   Skipped train sample 813 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,086 - __main__ - WARNING -   Skipped train sample 814 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,090 - __main__ - WARNING -   Skipped train sample 815 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,093 - __main__ - WARNING -   Skipped train sample 816 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,096 - __main__ - WARNING -   Skipped train sample 817 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,100 - __main__ - WARNING -   Skipped train sample 818 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,104 - __main__ - WARNING -   Skipped train sample 819 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,108 - __main__ - WARNING -   Skipped train sample 820 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,111 - __main__ - WARNING -   Skipped train sample 821 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,113 - __main__ - WARNING -   Skipped train sample 822 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,118 - __main__ - WARNING -   Skipped train sample 823 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,120 - __main__ - WARNING -   Skipped train sample 824 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,124 - __main__ - WARNING -   Skipped train sample 825 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,129 - __main__ - WARNING -   Skipped train sample 826 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,135 - __main__ - WARNING -   Skipped train sample 827 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,149 - __main__ - WARNING -   Skipped train sample 828 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,153 - __main__ - WARNING -   Skipped train sample 829 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,157 - __main__ - WARNING -   Skipped train sample 830 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,162 - __main__ - WARNING -   Skipped train sample 831 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,166 - __main__ - WARNING -   Skipped train sample 832 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,171 - __main__ - WARNING -   Skipped train sample 833 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,174 - __main__ - WARNING -   Skipped train sample 834 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,177 - __main__ - WARNING -   Skipped train sample 835 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,181 - __main__ - WARNING -   Skipped train sample 836 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,187 - __main__ - WARNING -   Skipped train sample 837 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,191 - __main__ - WARNING -   Skipped train sample 838 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,196 - __main__ - WARNING -   Skipped train sample 839 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,199 - __main__ - WARNING -   Skipped train sample 840 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,210 - __main__ - WARNING -   Skipped train sample 841 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,214 - __main__ - WARNING -   Skipped train sample 842 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,217 - __main__ - WARNING -   Skipped train sample 843 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,219 - __main__ - WARNING -   Skipped train sample 844 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,225 - __main__ - WARNING -   Skipped train sample 845 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,231 - __main__ - WARNING -   Skipped train sample 846 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,234 - __main__ - WARNING -   Skipped train sample 847 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,238 - __main__ - WARNING -   Skipped train sample 848 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,242 - __main__ - WARNING -   Skipped train sample 849 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,244 - __main__ - WARNING -   Skipped train sample 850 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,257 - __main__ - WARNING -   Skipped train sample 851 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,262 - __main__ - WARNING -   Skipped train sample 852 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,264 - __main__ - WARNING -   Skipped train sample 853 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,267 - __main__ - WARNING -   Skipped train sample 854 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,273 - __main__ - WARNING -   Skipped train sample 855 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,277 - __main__ - WARNING -   Skipped train sample 856 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,282 - __main__ - WARNING -   Skipped train sample 857 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,285 - __main__ - WARNING -   Skipped train sample 858 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,288 - __main__ - WARNING -   Skipped train sample 859 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,306 - __main__ - WARNING -   Skipped train sample 860 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,310 - __main__ - WARNING -   Skipped train sample 861 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,315 - __main__ - WARNING -   Skipped train sample 862 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,319 - __main__ - WARNING -   Skipped train sample 863 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,328 - __main__ - WARNING -   Skipped train sample 864 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,333 - __main__ - WARNING -   Skipped train sample 865 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,340 - __main__ - WARNING -   Skipped train sample 866 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,347 - __main__ - WARNING -   Skipped train sample 867 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,351 - __main__ - WARNING -   Skipped train sample 868 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,357 - __main__ - WARNING -   Skipped train sample 869 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,361 - __main__ - WARNING -   Skipped train sample 870 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,367 - __main__ - WARNING -   Skipped train sample 871 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,370 - __main__ - WARNING -   Skipped train sample 872 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,374 - __main__ - WARNING -   Skipped train sample 873 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,380 - __main__ - WARNING -   Skipped train sample 874 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,383 - __main__ - WARNING -   Skipped train sample 875 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:13,388 - __main__ - WARNING -   Skipped train sample 876 due to error: 'LSAKeypointDataset' object has no attribute 'keypoint_ranges'
2025-09-21 22:16:59,207 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-21 22:16:59,207 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 22:16:59,207 - __main__ - INFO - Starting training pipeline
2025-09-21 22:16:59,309 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-21 22:16:59,334 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-21 22:16:59,334 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-21 22:16:59,335 - __main__ - INFO - Loading training data...
2025-09-21 22:17:07,121 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-21 22:17:07,122 - __main__ - INFO - Processing train split...
2025-09-21 22:17:07,212 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-21 22:17:07,213 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-21 22:17:35,576 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-21 22:18:05,769 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-21 22:18:36,349 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-21 22:19:06,102 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-21 22:19:28,948 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-21 22:19:28,948 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 22:19:28,948 - __main__ - INFO - Starting training pipeline
2025-09-21 22:19:29,056 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-21 22:19:29,084 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-21 22:19:29,084 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-21 22:19:29,084 - __main__ - INFO - Loading training data...
2025-09-21 22:19:37,574 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-21 22:19:37,575 - __main__ - INFO - Processing train split...
2025-09-21 22:19:37,663 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-21 22:19:37,663 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-21 22:21:19,548 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-21 22:24:25,787 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-21 22:24:25,787 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-21 22:24:25,787 - __main__ - INFO - Starting training pipeline
2025-09-21 22:24:25,887 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-21 22:24:25,912 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-21 22:24:25,912 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-21 22:24:25,913 - __main__ - INFO - Loading training data...
2025-09-21 22:24:33,524 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-21 22:24:33,525 - __main__ - INFO - Processing train split...
2025-09-21 22:24:33,609 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-21 22:24:33,609 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-21 22:25:02,006 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-21 22:25:30,860 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-21 22:25:59,975 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-21 22:26:28,251 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-21 22:26:57,246 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-21 22:27:26,140 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-21 22:27:48,542 - __main__ - INFO - Processing val split...
2025-09-21 22:27:48,800 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-21 22:27:48,800 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-21 22:28:11,928 - __main__ - INFO - Processing test split...
2025-09-21 22:28:12,165 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-21 22:28:12,165 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-21 22:28:35,523 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-21 22:28:35,524 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-21 22:28:35,542 - __main__ - INFO - ‚úÖ Vocabulary created successfully with 13664 words
2025-09-21 22:28:35,543 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-21 22:28:35,543 - __main__ - INFO - Creating model architecture...
2025-09-21 22:28:36,044 - __main__ - INFO - ‚úÖ Model created successfully
2025-09-21 22:28:36,044 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-21 22:28:36,044 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-21 22:28:36,044 - __main__ - INFO - üñ•Ô∏è  Using device: cuda
2025-09-21 22:28:36,044 - __main__ - INFO - Creating trainer...
2025-09-21 22:28:36,044 - __main__ - INFO - üîÑ Moving model to cuda...
2025-09-21 22:28:36,495 - __main__ - INFO - ‚úÖ Model moved to cuda
2025-09-21 22:28:36,495 - __main__ - INFO - üìç Model parameters are on: cuda:0
2025-09-21 22:28:38,869 - __main__ - INFO - ‚úÖ Trainer created successfully
2025-09-21 22:28:38,869 - __main__ - INFO - üìç Trainer model parameters are on: cuda:0
2025-09-21 22:28:38,869 - __main__ - INFO - üöÄ Starting training...
2025-09-21 22:28:38,869 - __main__ - INFO - Training configuration:
2025-09-21 22:28:38,869 - __main__ - INFO -   - Epochs: 100
2025-09-21 22:28:38,869 - __main__ - INFO -   - Batch size: 2
2025-09-21 22:28:38,870 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-21 22:28:38,870 - __main__ - INFO -   - Training samples: 6765
2025-09-21 22:28:38,870 - __main__ - INFO -   - Validation samples: 845
2025-09-21 22:28:38,870 - training.trainer - INFO - Starting training for 100 epochs
2025-09-21 22:28:38,870 - training.trainer - INFO - Model parameters: 16,669,280
2025-09-21 22:28:38,870 - training.trainer - INFO - Training on device: cuda
2025-09-21 22:28:50,875 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.8116, Acc=0.027, PPL=6711.72
2025-09-21 22:28:59,654 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.4527, Acc=0.024, PPL=4687.54
2025-09-21 22:29:08,351 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.9003, Acc=0.041, PPL=2698.09
2025-09-21 22:29:16,948 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.0671, Acc=0.051, PPL=1172.75
2025-09-21 22:29:25,338 - training.trainer - INFO - Epoch 0, Step 499: Loss=7.2985, Acc=0.057, PPL=1478.03
2025-09-21 22:29:33,554 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.1775, Acc=0.100, PPL=1309.61
2025-09-21 22:29:41,822 - training.trainer - INFO - Epoch 0, Step 699: Loss=7.1924, Acc=0.069, PPL=1329.35
2025-09-21 22:29:50,079 - training.trainer - INFO - Epoch 0, Step 799: Loss=7.0387, Acc=0.052, PPL=1139.85
2025-09-21 22:29:58,305 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.1167, Acc=0.083, PPL=453.35
2025-09-21 22:30:06,328 - training.trainer - INFO - Epoch 0, Step 999: Loss=6.4882, Acc=0.040, PPL=657.34
2025-09-21 22:30:14,539 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.4641, Acc=0.075, PPL=641.68
2025-09-21 22:30:22,720 - training.trainer - INFO - Epoch 0, Step 1199: Loss=7.1902, Acc=0.038, PPL=1326.34
2025-09-21 22:30:31,022 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.4955, Acc=0.111, PPL=662.14
2025-09-21 22:30:39,189 - training.trainer - INFO - Epoch 0, Step 1399: Loss=6.5859, Acc=0.061, PPL=724.78
2025-09-21 22:30:47,461 - training.trainer - INFO - Epoch 0, Step 1499: Loss=6.8726, Acc=0.167, PPL=965.42
2025-09-21 22:30:55,520 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.8843, Acc=0.091, PPL=976.79
2025-09-21 22:31:03,512 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.7530, Acc=0.148, PPL=856.64
2025-09-21 22:31:11,502 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.5977, Acc=0.111, PPL=733.40
2025-09-21 22:31:19,575 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.0729, Acc=0.200, PPL=433.92
2025-09-21 22:31:27,565 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.8502, Acc=0.119, PPL=944.05
2025-09-21 22:31:35,509 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.2357, Acc=0.111, PPL=510.64
2025-09-21 22:31:43,428 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.3267, Acc=0.100, PPL=559.32
2025-09-21 22:31:51,344 - training.trainer - INFO - Epoch 0, Step 2299: Loss=7.0277, Acc=0.087, PPL=1127.45
2025-09-21 22:31:59,260 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.1754, Acc=0.125, PPL=480.76
2025-09-21 22:32:07,149 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.9587, Acc=0.084, PPL=1052.27
2025-09-21 22:32:15,113 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.7320, Acc=0.125, PPL=838.84
2025-09-21 22:32:22,956 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.8925, Acc=0.135, PPL=984.81
2025-09-21 22:32:30,817 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.9519, Acc=0.220, PPL=1045.13
2025-09-21 22:32:38,758 - training.trainer - INFO - Epoch 0, Step 2899: Loss=7.1057, Acc=0.127, PPL=1218.85
2025-09-21 22:32:46,659 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.6513, Acc=0.073, PPL=773.76
2025-09-21 22:32:54,596 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.7663, Acc=0.125, PPL=868.07
2025-09-21 22:33:02,511 - training.trainer - INFO - Epoch 0, Step 3199: Loss=7.4009, Acc=0.125, PPL=1637.44
2025-09-21 22:33:10,313 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.6184, Acc=0.192, PPL=748.74
2025-09-21 22:33:27,875 - training.trainer - INFO - Epoch 1/100 completed in 289.00s - Train Loss: 6.9659, Train Acc: 0.097, Val Loss: 6.5458, Val Acc: 0.136
2025-09-21 22:33:28,959 - training.trainer - INFO - New best model saved with validation loss: 6.5458
2025-09-21 22:33:28,960 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-21 22:33:37,327 - training.trainer - INFO - Epoch 1, Step 3482: Loss=7.0368, Acc=0.071, PPL=1137.80
2025-09-21 22:33:45,192 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.4726, Acc=0.128, PPL=647.14
2025-09-21 22:33:53,049 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.6294, Acc=0.161, PPL=757.01
2025-09-21 22:34:00,924 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.3420, Acc=0.121, PPL=567.92
2025-09-21 22:34:08,765 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.1961, Acc=0.104, PPL=490.82
2025-09-21 22:34:16,586 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.7798, Acc=0.194, PPL=879.90
2025-09-21 22:34:24,504 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.6825, Acc=0.045, PPL=798.34
2025-09-21 22:34:32,495 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.1921, Acc=0.140, PPL=488.89
2025-09-21 22:34:40,432 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.6719, Acc=0.114, PPL=789.91
2025-09-21 22:34:48,279 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.8962, Acc=0.093, PPL=988.49
2025-09-21 22:34:56,156 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.9675, Acc=0.103, PPL=1061.61
2025-09-21 22:35:03,992 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.9570, Acc=0.100, PPL=1050.47
2025-09-21 22:35:12,011 - training.trainer - INFO - Epoch 1, Step 4682: Loss=7.0272, Acc=0.106, PPL=1126.92
2025-09-21 22:35:20,011 - training.trainer - INFO - Epoch 1, Step 4782: Loss=7.3877, Acc=0.167, PPL=1615.94
2025-09-21 22:35:27,969 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.5569, Acc=0.312, PPL=704.09
2025-09-21 22:35:35,815 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.5022, Acc=0.078, PPL=666.62
2025-09-21 22:35:43,604 - training.trainer - INFO - Epoch 1, Step 5082: Loss=5.6554, Acc=0.182, PPL=285.82
2025-09-21 22:35:51,368 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.3748, Acc=0.200, PPL=586.85
2025-09-21 22:35:59,332 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.0640, Acc=0.138, PPL=430.08
2025-09-21 22:36:07,229 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.5046, Acc=0.138, PPL=668.19
2025-09-21 22:36:15,151 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.5308, Acc=0.033, PPL=685.97
2025-09-21 22:36:23,015 - training.trainer - INFO - Epoch 1, Step 5582: Loss=6.1373, Acc=0.200, PPL=462.80
2025-09-21 22:36:30,881 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.6549, Acc=0.140, PPL=776.59
2025-09-21 22:36:38,724 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.6245, Acc=0.118, PPL=753.30
2025-09-21 22:36:46,509 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.4137, Acc=0.194, PPL=610.12
2025-09-21 22:36:54,286 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.0261, Acc=0.195, PPL=414.10
2025-09-21 22:37:02,075 - training.trainer - INFO - Epoch 1, Step 6082: Loss=7.4150, Acc=0.038, PPL=1660.79
2025-09-21 22:37:09,759 - training.trainer - INFO - Epoch 1, Step 6182: Loss=5.9424, Acc=0.205, PPL=380.86
2025-09-21 22:37:17,454 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.3450, Acc=0.167, PPL=569.63
2025-09-21 22:37:25,202 - training.trainer - INFO - Epoch 1, Step 6382: Loss=6.0719, Acc=0.226, PPL=433.49
2025-09-21 22:37:32,915 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.3974, Acc=0.154, PPL=600.28
2025-09-21 22:37:40,634 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.7823, Acc=0.184, PPL=882.09
2025-09-21 22:37:48,409 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.8230, Acc=0.156, PPL=918.71
2025-09-21 22:38:04,581 - training.trainer - INFO - Epoch 2/100 completed in 275.62s - Train Loss: 6.4945, Train Acc: 0.143, Val Loss: 6.3582, Val Acc: 0.155
2025-09-21 22:38:05,172 - training.trainer - INFO - New best model saved with validation loss: 6.3582
2025-09-21 22:38:05,172 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-21 22:38:13,071 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.5921, Acc=0.086, PPL=729.28
2025-09-21 22:38:20,897 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.5126, Acc=0.195, PPL=673.59
2025-09-21 22:38:28,752 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.7276, Acc=0.160, PPL=835.15
2025-09-21 22:38:36,550 - training.trainer - INFO - Epoch 2, Step 7165: Loss=5.5964, Acc=0.200, PPL=269.45
2025-09-21 22:38:44,339 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.8789, Acc=0.074, PPL=971.54
2025-09-21 22:38:52,089 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.3483, Acc=0.265, PPL=571.51
2025-09-21 22:38:59,949 - training.trainer - INFO - Epoch 2, Step 7465: Loss=6.8409, Acc=0.102, PPL=935.32
2025-09-21 22:39:07,638 - training.trainer - INFO - Epoch 2, Step 7565: Loss=6.0114, Acc=0.194, PPL=408.04
2025-09-21 22:39:15,307 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.0228, Acc=0.140, PPL=412.74
2025-09-21 22:39:23,108 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.4808, Acc=0.175, PPL=652.50
2025-09-21 22:39:30,899 - training.trainer - INFO - Epoch 2, Step 7865: Loss=5.7423, Acc=0.229, PPL=311.77
2025-09-21 22:39:38,712 - training.trainer - INFO - Epoch 2, Step 7965: Loss=6.8460, Acc=0.116, PPL=940.11
2025-09-21 22:39:46,499 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.4402, Acc=0.150, PPL=626.54
2025-09-21 22:39:54,197 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.7414, Acc=0.146, PPL=846.71
2025-09-21 22:40:02,328 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.5990, Acc=0.167, PPL=734.39
2025-09-21 22:40:10,313 - training.trainer - INFO - Epoch 2, Step 8365: Loss=6.2994, Acc=0.206, PPL=544.24
2025-09-21 22:40:18,363 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.2574, Acc=0.143, PPL=521.87
2025-09-21 22:40:26,363 - training.trainer - INFO - Epoch 2, Step 8565: Loss=6.7777, Acc=0.233, PPL=878.01
2025-09-21 22:40:34,414 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.5789, Acc=0.105, PPL=719.76
2025-09-21 22:40:42,537 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.5109, Acc=0.220, PPL=672.43
2025-09-21 22:40:50,479 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.2829, Acc=0.119, PPL=535.35
2025-09-21 22:40:58,351 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.7926, Acc=0.163, PPL=891.19
2025-09-21 22:41:06,192 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.5071, Acc=0.077, PPL=669.85
2025-09-21 22:41:14,106 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.6265, Acc=0.183, PPL=754.87
2025-09-21 22:41:21,894 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.8364, Acc=0.172, PPL=931.12
2025-09-21 22:41:29,828 - training.trainer - INFO - Epoch 2, Step 9365: Loss=7.2439, Acc=0.121, PPL=1399.52
2025-09-21 22:41:37,640 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.1783, Acc=0.132, PPL=482.19
2025-09-21 22:41:45,480 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.7833, Acc=0.075, PPL=882.98
2025-09-21 22:41:53,243 - training.trainer - INFO - Epoch 2, Step 9665: Loss=6.0657, Acc=0.129, PPL=430.81
2025-09-21 22:42:01,011 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.2149, Acc=0.167, PPL=500.13
2025-09-21 22:42:08,844 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.0344, Acc=0.200, PPL=417.55
2025-09-21 22:42:16,702 - training.trainer - INFO - Epoch 2, Step 9965: Loss=7.1403, Acc=0.143, PPL=1261.83
2025-09-21 22:42:24,563 - training.trainer - INFO - Epoch 2, Step 10065: Loss=6.7937, Acc=0.176, PPL=892.25
2025-09-21 22:42:40,761 - training.trainer - INFO - Epoch 3/100 completed in 275.59s - Train Loss: 6.3569, Train Acc: 0.157, Val Loss: 6.2701, Val Acc: 0.162
2025-09-21 22:42:41,438 - training.trainer - INFO - New best model saved with validation loss: 6.2701
2025-09-21 22:42:41,438 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-21 22:42:49,523 - training.trainer - INFO - Epoch 3, Step 10248: Loss=4.9323, Acc=0.100, PPL=138.70
2025-09-21 22:42:57,355 - training.trainer - INFO - Epoch 3, Step 10348: Loss=6.4742, Acc=0.167, PPL=648.21
2025-09-21 22:43:05,105 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.6011, Acc=0.143, PPL=735.94
2025-09-21 22:43:12,818 - training.trainer - INFO - Epoch 3, Step 10548: Loss=6.0384, Acc=0.100, PPL=419.22
2025-09-21 22:43:20,571 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.9257, Acc=0.127, PPL=1018.07
2025-09-21 22:43:28,288 - training.trainer - INFO - Epoch 3, Step 10748: Loss=5.8566, Acc=0.172, PPL=349.52
2025-09-21 22:43:36,293 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.4824, Acc=0.226, PPL=653.55
2025-09-21 22:43:44,404 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.4675, Acc=0.130, PPL=643.86
2025-09-21 22:43:52,731 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.1313, Acc=0.162, PPL=460.04
2025-09-21 22:44:00,865 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.9412, Acc=0.097, PPL=1034.04
2025-09-21 22:44:09,003 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.0258, Acc=0.179, PPL=413.96
2025-09-21 22:44:17,174 - training.trainer - INFO - Epoch 3, Step 11348: Loss=6.8869, Acc=0.182, PPL=979.31
2025-09-21 22:44:25,161 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.0107, Acc=0.143, PPL=407.78
2025-09-21 22:44:33,198 - training.trainer - INFO - Epoch 3, Step 11548: Loss=6.6559, Acc=0.121, PPL=777.38
2025-09-21 22:44:41,045 - training.trainer - INFO - Epoch 3, Step 11648: Loss=6.2875, Acc=0.152, PPL=537.83
2025-09-21 22:44:48,895 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.8576, Acc=0.217, PPL=349.89
2025-09-21 22:44:56,828 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.7369, Acc=0.261, PPL=310.10
2025-09-21 22:45:04,863 - training.trainer - INFO - Epoch 3, Step 11948: Loss=5.8779, Acc=0.133, PPL=357.07
2025-09-21 22:45:12,912 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.8763, Acc=0.143, PPL=969.08
2025-09-21 22:45:20,960 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.8420, Acc=0.065, PPL=936.41
2025-09-21 22:45:28,919 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.0266, Acc=0.111, PPL=414.32
2025-09-21 22:45:36,920 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.7100, Acc=0.100, PPL=820.56
2025-09-21 22:45:44,811 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.4583, Acc=0.058, PPL=637.96
2025-09-21 22:45:52,620 - training.trainer - INFO - Epoch 3, Step 12548: Loss=5.9197, Acc=0.259, PPL=372.31
2025-09-21 22:46:00,439 - training.trainer - INFO - Epoch 3, Step 12648: Loss=6.1627, Acc=0.250, PPL=474.69
2025-09-21 22:46:08,368 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.5978, Acc=0.209, PPL=733.46
2025-09-21 22:46:16,220 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.6704, Acc=0.094, PPL=788.69
2025-09-21 22:46:24,039 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.6171, Acc=0.087, PPL=747.77
2025-09-21 22:46:31,885 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.9425, Acc=0.093, PPL=1035.32
2025-09-21 22:46:39,788 - training.trainer - INFO - Epoch 3, Step 13148: Loss=5.9694, Acc=0.250, PPL=391.28
2025-09-21 22:46:47,647 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.6987, Acc=0.137, PPL=811.36
2025-09-21 22:46:55,554 - training.trainer - INFO - Epoch 3, Step 13348: Loss=6.6264, Acc=0.125, PPL=754.79
2025-09-21 22:47:03,403 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.6350, Acc=0.156, PPL=761.31
2025-09-21 22:47:20,300 - training.trainer - INFO - Epoch 4/100 completed in 278.86s - Train Loss: 6.2687, Train Acc: 0.165, Val Loss: 6.1989, Val Acc: 0.173
2025-09-21 22:47:20,939 - training.trainer - INFO - New best model saved with validation loss: 6.1989
2025-09-21 22:47:20,939 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-21 22:47:29,045 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.2208, Acc=0.164, PPL=503.09
2025-09-21 22:47:36,932 - training.trainer - INFO - Epoch 4, Step 13731: Loss=6.3882, Acc=0.222, PPL=594.77
2025-09-21 22:47:44,843 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.2581, Acc=0.154, PPL=522.23
2025-09-21 22:47:52,717 - training.trainer - INFO - Epoch 4, Step 13931: Loss=5.4736, Acc=0.233, PPL=238.33
2025-09-21 22:48:00,562 - training.trainer - INFO - Epoch 4, Step 14031: Loss=6.1041, Acc=0.103, PPL=447.71
2025-09-21 22:48:08,328 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.6345, Acc=0.158, PPL=760.91
2025-09-21 22:48:16,211 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.3802, Acc=0.134, PPL=590.04
2025-09-21 22:48:24,110 - training.trainer - INFO - Epoch 4, Step 14331: Loss=6.4302, Acc=0.146, PPL=620.33
2025-09-21 22:48:31,984 - training.trainer - INFO - Epoch 4, Step 14431: Loss=6.8208, Acc=0.163, PPL=916.73
2025-09-21 22:48:39,825 - training.trainer - INFO - Epoch 4, Step 14531: Loss=5.7221, Acc=0.130, PPL=305.55
2025-09-21 22:48:47,646 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.5076, Acc=0.152, PPL=670.22
2025-09-21 22:48:55,494 - training.trainer - INFO - Epoch 4, Step 14731: Loss=6.7344, Acc=0.111, PPL=840.84
2025-09-21 22:49:03,294 - training.trainer - INFO - Epoch 4, Step 14831: Loss=5.8625, Acc=0.211, PPL=351.59
2025-09-21 22:49:11,142 - training.trainer - INFO - Epoch 4, Step 14931: Loss=6.3749, Acc=0.225, PPL=586.93
2025-09-21 22:49:18,972 - training.trainer - INFO - Epoch 4, Step 15031: Loss=6.5080, Acc=0.139, PPL=670.51
2025-09-21 22:49:26,836 - training.trainer - INFO - Epoch 4, Step 15131: Loss=6.6954, Acc=0.233, PPL=808.69
2025-09-21 22:49:34,647 - training.trainer - INFO - Epoch 4, Step 15231: Loss=7.5062, Acc=0.174, PPL=1819.36
2025-09-21 22:49:42,454 - training.trainer - INFO - Epoch 4, Step 15331: Loss=5.8698, Acc=0.138, PPL=354.18
2025-09-21 22:49:50,253 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.2535, Acc=0.188, PPL=519.83
2025-09-21 22:49:58,098 - training.trainer - INFO - Epoch 4, Step 15531: Loss=6.8200, Acc=0.132, PPL=916.01
2025-09-21 22:50:05,931 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.1763, Acc=0.129, PPL=481.19
2025-09-21 22:50:13,740 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.7747, Acc=0.143, PPL=875.41
2025-09-21 22:50:21,612 - training.trainer - INFO - Epoch 4, Step 15831: Loss=6.4317, Acc=0.116, PPL=621.25
2025-09-21 22:50:29,497 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.6190, Acc=0.159, PPL=749.19
2025-09-21 22:50:37,365 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.3081, Acc=0.110, PPL=548.99
2025-09-21 22:50:45,298 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.2950, Acc=0.069, PPL=541.85
2025-09-21 22:50:53,317 - training.trainer - INFO - Epoch 4, Step 16231: Loss=6.0526, Acc=0.222, PPL=425.22
2025-09-21 22:51:01,278 - training.trainer - INFO - Epoch 4, Step 16331: Loss=5.9996, Acc=0.241, PPL=403.25
2025-09-21 22:51:09,296 - training.trainer - INFO - Epoch 4, Step 16431: Loss=7.0021, Acc=0.136, PPL=1098.90
2025-09-21 22:51:17,271 - training.trainer - INFO - Epoch 4, Step 16531: Loss=5.4265, Acc=0.250, PPL=227.35
2025-09-21 22:51:25,170 - training.trainer - INFO - Epoch 4, Step 16631: Loss=6.9557, Acc=0.125, PPL=1049.11
2025-09-21 22:51:33,035 - training.trainer - INFO - Epoch 4, Step 16731: Loss=6.3690, Acc=0.136, PPL=583.48
2025-09-21 22:51:40,946 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.3242, Acc=0.158, PPL=557.92
2025-09-21 22:51:58,316 - training.trainer - INFO - Epoch 5/100 completed in 277.38s - Train Loss: 6.2174, Train Acc: 0.171, Val Loss: 6.1699, Val Acc: 0.174
2025-09-21 22:51:58,702 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-21 22:51:59,500 - training.trainer - INFO - New best model saved with validation loss: 6.1699
2025-09-21 22:51:59,500 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-21 22:52:07,836 - training.trainer - INFO - Epoch 5, Step 17014: Loss=6.5205, Acc=0.102, PPL=678.92
2025-09-21 22:52:15,838 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.6361, Acc=0.091, PPL=762.15
2025-09-21 22:52:23,820 - training.trainer - INFO - Epoch 5, Step 17214: Loss=5.7318, Acc=0.200, PPL=308.51
2025-09-21 22:52:31,838 - training.trainer - INFO - Epoch 5, Step 17314: Loss=5.9682, Acc=0.286, PPL=390.82
2025-09-21 22:52:39,931 - training.trainer - INFO - Epoch 5, Step 17414: Loss=5.9779, Acc=0.190, PPL=394.62
2025-09-21 22:52:48,079 - training.trainer - INFO - Epoch 5, Step 17514: Loss=5.8534, Acc=0.111, PPL=348.40
2025-09-21 22:52:56,084 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.7949, Acc=0.119, PPL=893.28
2025-09-21 22:53:03,996 - training.trainer - INFO - Epoch 5, Step 17714: Loss=5.9209, Acc=0.250, PPL=372.76
2025-09-21 22:53:11,908 - training.trainer - INFO - Epoch 5, Step 17814: Loss=7.1780, Acc=0.110, PPL=1310.28
2025-09-21 22:53:19,823 - training.trainer - INFO - Epoch 5, Step 17914: Loss=5.3983, Acc=0.318, PPL=221.03
2025-09-21 22:53:27,726 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.7271, Acc=0.122, PPL=834.76
2025-09-21 22:53:35,526 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.0885, Acc=0.188, PPL=440.75
2025-09-21 22:53:43,476 - training.trainer - INFO - Epoch 5, Step 18214: Loss=6.1206, Acc=0.103, PPL=455.16
2025-09-21 22:53:51,264 - training.trainer - INFO - Epoch 5, Step 18314: Loss=5.6856, Acc=0.227, PPL=294.60
2025-09-21 22:53:59,043 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.6481, Acc=0.156, PPL=283.76
2025-09-21 22:54:06,854 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.0049, Acc=0.229, PPL=405.43
2025-09-21 22:54:14,779 - training.trainer - INFO - Epoch 5, Step 18614: Loss=6.1867, Acc=0.101, PPL=486.24
2025-09-21 22:54:22,586 - training.trainer - INFO - Epoch 5, Step 18714: Loss=5.9814, Acc=0.312, PPL=395.98
2025-09-21 22:54:30,375 - training.trainer - INFO - Epoch 5, Step 18814: Loss=6.3934, Acc=0.152, PPL=597.86
2025-09-21 22:54:38,138 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.7337, Acc=0.240, PPL=840.26
2025-09-21 22:54:45,890 - training.trainer - INFO - Epoch 5, Step 19014: Loss=5.9645, Acc=0.179, PPL=389.37
2025-09-21 22:54:53,739 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.1065, Acc=0.167, PPL=448.76
2025-09-21 22:55:01,490 - training.trainer - INFO - Epoch 5, Step 19214: Loss=6.6366, Acc=0.167, PPL=762.52
2025-09-21 22:55:09,218 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.4753, Acc=0.103, PPL=648.89
2025-09-21 22:55:16,910 - training.trainer - INFO - Epoch 5, Step 19414: Loss=6.0708, Acc=0.136, PPL=433.03
2025-09-21 22:55:24,713 - training.trainer - INFO - Epoch 5, Step 19514: Loss=6.6110, Acc=0.098, PPL=743.26
2025-09-21 22:55:32,447 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.3774, Acc=0.161, PPL=588.42
2025-09-21 22:55:40,502 - training.trainer - INFO - Epoch 5, Step 19714: Loss=6.3012, Acc=0.139, PPL=545.21
2025-09-21 22:55:48,500 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.0618, Acc=0.225, PPL=429.13
2025-09-21 22:55:56,521 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.7280, Acc=0.200, PPL=307.35
2025-09-21 22:56:04,455 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.2306, Acc=0.157, PPL=508.04
2025-09-21 22:56:12,546 - training.trainer - INFO - Epoch 5, Step 20114: Loss=6.4820, Acc=0.121, PPL=653.25
2025-09-21 22:56:20,596 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.4985, Acc=0.098, PPL=664.14
2025-09-21 22:56:37,200 - training.trainer - INFO - Epoch 6/100 completed in 277.70s - Train Loss: 6.1785, Train Acc: 0.176, Val Loss: 6.1178, Val Acc: 0.184
2025-09-21 22:56:37,977 - training.trainer - INFO - New best model saved with validation loss: 6.1178
2025-09-21 22:56:37,977 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-21 22:56:46,405 - training.trainer - INFO - Epoch 6, Step 20397: Loss=6.3021, Acc=0.146, PPL=545.70
2025-09-21 22:56:54,458 - training.trainer - INFO - Epoch 6, Step 20497: Loss=6.2764, Acc=0.235, PPL=531.88
2025-09-21 22:57:02,404 - training.trainer - INFO - Epoch 6, Step 20597: Loss=6.5067, Acc=0.286, PPL=669.62
2025-09-21 22:57:10,300 - training.trainer - INFO - Epoch 6, Step 20697: Loss=6.2869, Acc=0.149, PPL=537.50
2025-09-21 22:57:18,149 - training.trainer - INFO - Epoch 6, Step 20797: Loss=5.4536, Acc=0.211, PPL=233.60
2025-09-21 22:57:26,059 - training.trainer - INFO - Epoch 6, Step 20897: Loss=5.8895, Acc=0.194, PPL=361.24
2025-09-21 22:57:33,956 - training.trainer - INFO - Epoch 6, Step 20997: Loss=5.4834, Acc=0.214, PPL=240.66
2025-09-21 22:57:41,807 - training.trainer - INFO - Epoch 6, Step 21097: Loss=6.4510, Acc=0.133, PPL=633.35
2025-09-21 22:57:49,628 - training.trainer - INFO - Epoch 6, Step 21197: Loss=6.0742, Acc=0.182, PPL=434.48
2025-09-21 22:57:57,517 - training.trainer - INFO - Epoch 6, Step 21297: Loss=5.7755, Acc=0.191, PPL=322.30
2025-09-21 22:58:05,495 - training.trainer - INFO - Epoch 6, Step 21397: Loss=6.1098, Acc=0.154, PPL=450.25
2025-09-21 22:58:13,381 - training.trainer - INFO - Epoch 6, Step 21497: Loss=6.1790, Acc=0.127, PPL=482.49
2025-09-21 22:58:21,314 - training.trainer - INFO - Epoch 6, Step 21597: Loss=5.6700, Acc=0.179, PPL=290.04
2025-09-21 22:58:29,243 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.2049, Acc=0.200, PPL=495.16
2025-09-21 22:58:37,135 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.5743, Acc=0.119, PPL=716.45
2025-09-21 22:58:44,939 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.4201, Acc=0.125, PPL=614.08
2025-09-21 22:58:52,761 - training.trainer - INFO - Epoch 6, Step 21997: Loss=6.2845, Acc=0.098, PPL=536.22
2025-09-21 22:59:00,565 - training.trainer - INFO - Epoch 6, Step 22097: Loss=5.8674, Acc=0.214, PPL=353.33
2025-09-21 22:59:08,362 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.6541, Acc=0.161, PPL=775.94
2025-09-21 22:59:16,229 - training.trainer - INFO - Epoch 6, Step 22297: Loss=6.5519, Acc=0.191, PPL=700.60
2025-09-21 22:59:24,054 - training.trainer - INFO - Epoch 6, Step 22397: Loss=6.4127, Acc=0.189, PPL=609.55
2025-09-21 22:59:31,858 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.4430, Acc=0.094, PPL=628.28
2025-09-21 22:59:39,686 - training.trainer - INFO - Epoch 6, Step 22597: Loss=6.0644, Acc=0.161, PPL=430.27
2025-09-21 22:59:47,530 - training.trainer - INFO - Epoch 6, Step 22697: Loss=5.6950, Acc=0.133, PPL=297.38
2025-09-21 22:59:55,334 - training.trainer - INFO - Epoch 6, Step 22797: Loss=6.3412, Acc=0.209, PPL=567.46
2025-09-21 23:00:03,133 - training.trainer - INFO - Epoch 6, Step 22897: Loss=5.6206, Acc=0.265, PPL=276.06
2025-09-21 23:00:10,852 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.1694, Acc=0.154, PPL=477.90
2025-09-21 23:00:18,648 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.1815, Acc=0.167, PPL=483.73
2025-09-21 23:00:26,386 - training.trainer - INFO - Epoch 6, Step 23197: Loss=5.4282, Acc=0.214, PPL=227.73
2025-09-21 23:00:34,170 - training.trainer - INFO - Epoch 6, Step 23297: Loss=6.2609, Acc=0.140, PPL=523.71
2025-09-21 23:00:41,964 - training.trainer - INFO - Epoch 6, Step 23397: Loss=6.0380, Acc=0.186, PPL=419.06
2025-09-21 23:00:49,807 - training.trainer - INFO - Epoch 6, Step 23497: Loss=4.9987, Acc=0.273, PPL=148.22
2025-09-21 23:00:57,528 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.8181, Acc=0.148, PPL=914.22
2025-09-21 23:01:13,674 - training.trainer - INFO - Epoch 7/100 completed in 275.70s - Train Loss: 6.1453, Train Acc: 0.181, Val Loss: 6.0777, Val Acc: 0.184
2025-09-21 23:01:14,318 - training.trainer - INFO - New best model saved with validation loss: 6.0777
2025-09-21 23:01:14,318 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-21 23:01:22,490 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.2167, Acc=0.192, PPL=501.07
2025-09-21 23:01:30,363 - training.trainer - INFO - Epoch 7, Step 23880: Loss=6.6804, Acc=0.111, PPL=796.61
2025-09-21 23:01:38,254 - training.trainer - INFO - Epoch 7, Step 23980: Loss=5.7424, Acc=0.229, PPL=311.80
2025-09-21 23:01:46,034 - training.trainer - INFO - Epoch 7, Step 24080: Loss=5.9655, Acc=0.217, PPL=389.76
2025-09-21 23:01:53,839 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.1623, Acc=0.176, PPL=174.56
2025-09-21 23:02:01,625 - training.trainer - INFO - Epoch 7, Step 24280: Loss=6.4867, Acc=0.138, PPL=656.33
2025-09-21 23:02:09,408 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.4854, Acc=0.100, PPL=655.49
2025-09-21 23:02:17,217 - training.trainer - INFO - Epoch 7, Step 24480: Loss=5.7068, Acc=0.217, PPL=300.92
2025-09-21 23:02:24,975 - training.trainer - INFO - Epoch 7, Step 24580: Loss=5.2746, Acc=0.167, PPL=195.31
2025-09-21 23:02:32,861 - training.trainer - INFO - Epoch 7, Step 24680: Loss=6.7354, Acc=0.167, PPL=841.65
2025-09-21 23:02:40,679 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.3368, Acc=0.273, PPL=564.96
2025-09-21 23:02:48,423 - training.trainer - INFO - Epoch 7, Step 24880: Loss=5.9432, Acc=0.207, PPL=381.15
2025-09-21 23:02:56,216 - training.trainer - INFO - Epoch 7, Step 24980: Loss=6.2776, Acc=0.155, PPL=532.52
2025-09-21 23:03:04,096 - training.trainer - INFO - Epoch 7, Step 25080: Loss=5.8900, Acc=0.172, PPL=361.41
2025-09-21 23:03:11,931 - training.trainer - INFO - Epoch 7, Step 25180: Loss=5.7099, Acc=0.238, PPL=301.83
2025-09-21 23:03:19,855 - training.trainer - INFO - Epoch 7, Step 25280: Loss=6.5939, Acc=0.145, PPL=730.63
2025-09-21 23:03:27,668 - training.trainer - INFO - Epoch 7, Step 25380: Loss=6.7064, Acc=0.174, PPL=817.60
2025-09-21 23:03:35,487 - training.trainer - INFO - Epoch 7, Step 25480: Loss=5.4718, Acc=0.219, PPL=237.89
2025-09-21 23:03:43,274 - training.trainer - INFO - Epoch 7, Step 25580: Loss=6.0982, Acc=0.083, PPL=445.06
2025-09-21 23:03:51,078 - training.trainer - INFO - Epoch 7, Step 25680: Loss=5.9219, Acc=0.150, PPL=373.10
2025-09-21 23:03:58,888 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.2435, Acc=0.140, PPL=514.65
2025-09-21 23:04:06,697 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.6522, Acc=0.174, PPL=774.49
2025-09-21 23:04:14,537 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.2599, Acc=0.136, PPL=523.16
2025-09-21 23:04:22,329 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.1094, Acc=0.182, PPL=450.07
2025-09-21 23:04:30,106 - training.trainer - INFO - Epoch 7, Step 26180: Loss=6.5216, Acc=0.110, PPL=679.64
2025-09-21 23:04:37,909 - training.trainer - INFO - Epoch 7, Step 26280: Loss=5.5928, Acc=0.300, PPL=268.47
2025-09-21 23:04:45,644 - training.trainer - INFO - Epoch 7, Step 26380: Loss=6.8034, Acc=0.256, PPL=900.93
2025-09-21 23:04:53,380 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.3879, Acc=0.133, PPL=594.59
2025-09-21 23:05:01,125 - training.trainer - INFO - Epoch 7, Step 26580: Loss=5.5443, Acc=0.219, PPL=255.77
2025-09-21 23:05:08,922 - training.trainer - INFO - Epoch 7, Step 26680: Loss=6.2643, Acc=0.190, PPL=525.50
2025-09-21 23:05:16,742 - training.trainer - INFO - Epoch 7, Step 26780: Loss=5.3766, Acc=0.269, PPL=216.29
2025-09-21 23:05:24,532 - training.trainer - INFO - Epoch 7, Step 26880: Loss=6.0407, Acc=0.179, PPL=420.19
2025-09-21 23:05:32,287 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.8542, Acc=0.259, PPL=348.71
2025-09-21 23:05:49,035 - training.trainer - INFO - Epoch 8/100 completed in 274.72s - Train Loss: 6.1149, Train Acc: 0.186, Val Loss: 6.0788, Val Acc: 0.191
2025-09-21 23:05:57,466 - training.trainer - INFO - Epoch 8, Step 27163: Loss=5.7971, Acc=0.226, PPL=329.33
2025-09-21 23:06:05,431 - training.trainer - INFO - Epoch 8, Step 27263: Loss=6.1076, Acc=0.217, PPL=449.28
2025-09-21 23:06:13,374 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.2631, Acc=0.333, PPL=193.08
2025-09-21 23:06:21,446 - training.trainer - INFO - Epoch 8, Step 27463: Loss=6.5222, Acc=0.146, PPL=680.08
2025-09-21 23:06:29,381 - training.trainer - INFO - Epoch 8, Step 27563: Loss=6.2011, Acc=0.162, PPL=493.29
2025-09-21 23:06:37,347 - training.trainer - INFO - Epoch 8, Step 27663: Loss=6.3152, Acc=0.153, PPL=552.91
2025-09-21 23:06:45,185 - training.trainer - INFO - Epoch 8, Step 27763: Loss=6.7246, Acc=0.174, PPL=832.67
2025-09-21 23:06:53,142 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.0282, Acc=0.178, PPL=414.97
2025-09-21 23:07:01,008 - training.trainer - INFO - Epoch 8, Step 27963: Loss=6.4236, Acc=0.250, PPL=616.21
2025-09-21 23:07:08,856 - training.trainer - INFO - Epoch 8, Step 28063: Loss=6.4541, Acc=0.111, PPL=635.29
2025-09-21 23:07:16,706 - training.trainer - INFO - Epoch 8, Step 28163: Loss=5.5815, Acc=0.286, PPL=265.48
2025-09-21 23:07:24,620 - training.trainer - INFO - Epoch 8, Step 28263: Loss=6.9033, Acc=0.119, PPL=995.58
2025-09-21 23:07:32,439 - training.trainer - INFO - Epoch 8, Step 28363: Loss=6.1690, Acc=0.273, PPL=477.72
2025-09-21 23:07:40,203 - training.trainer - INFO - Epoch 8, Step 28463: Loss=5.5899, Acc=0.205, PPL=267.71
2025-09-21 23:07:48,006 - training.trainer - INFO - Epoch 8, Step 28563: Loss=6.0598, Acc=0.114, PPL=428.29
2025-09-21 23:07:55,848 - training.trainer - INFO - Epoch 8, Step 28663: Loss=6.8490, Acc=0.140, PPL=942.94
2025-09-21 23:08:03,679 - training.trainer - INFO - Epoch 8, Step 28763: Loss=6.2055, Acc=0.194, PPL=495.47
2025-09-21 23:08:11,512 - training.trainer - INFO - Epoch 8, Step 28863: Loss=5.4540, Acc=0.353, PPL=233.70
2025-09-21 23:08:19,438 - training.trainer - INFO - Epoch 8, Step 28963: Loss=6.0662, Acc=0.212, PPL=431.05
2025-09-21 23:08:27,343 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.2152, Acc=0.120, PPL=500.29
2025-09-21 23:08:35,113 - training.trainer - INFO - Epoch 8, Step 29163: Loss=5.9069, Acc=0.323, PPL=367.57
2025-09-21 23:08:42,847 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.3081, Acc=0.155, PPL=549.00
2025-09-21 23:08:50,625 - training.trainer - INFO - Epoch 8, Step 29363: Loss=6.4151, Acc=0.132, PPL=610.98
2025-09-21 23:08:58,406 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.4586, Acc=0.270, PPL=638.19
2025-09-21 23:09:06,174 - training.trainer - INFO - Epoch 8, Step 29563: Loss=6.9096, Acc=0.125, PPL=1001.82
2025-09-21 23:09:13,951 - training.trainer - INFO - Epoch 8, Step 29663: Loss=5.6226, Acc=0.242, PPL=276.61
2025-09-21 23:09:21,687 - training.trainer - INFO - Epoch 8, Step 29763: Loss=6.2579, Acc=0.200, PPL=522.14
2025-09-21 23:09:29,531 - training.trainer - INFO - Epoch 8, Step 29863: Loss=6.3413, Acc=0.132, PPL=567.51
2025-09-21 23:09:37,676 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.3230, Acc=0.170, PPL=557.27
2025-09-21 23:09:45,547 - training.trainer - INFO - Epoch 8, Step 30063: Loss=5.7348, Acc=0.156, PPL=309.46
2025-09-21 23:09:53,535 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.5745, Acc=0.200, PPL=263.61
2025-09-21 23:10:01,563 - training.trainer - INFO - Epoch 8, Step 30263: Loss=5.4407, Acc=0.220, PPL=230.60
2025-09-21 23:10:09,741 - training.trainer - INFO - Epoch 8, Step 30363: Loss=7.0907, Acc=0.077, PPL=1200.75
2025-09-21 23:10:27,328 - training.trainer - INFO - Epoch 9/100 completed in 278.29s - Train Loss: 6.0904, Train Acc: 0.189, Val Loss: 6.0240, Val Acc: 0.197
2025-09-21 23:10:28,070 - training.trainer - INFO - New best model saved with validation loss: 6.0240
2025-09-21 23:10:28,070 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-21 23:10:36,520 - training.trainer - INFO - Epoch 9, Step 30546: Loss=6.4639, Acc=0.189, PPL=641.55
2025-09-21 23:10:44,628 - training.trainer - INFO - Epoch 9, Step 30646: Loss=5.7627, Acc=0.318, PPL=318.19
2025-09-21 23:10:52,647 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.2382, Acc=0.179, PPL=511.94
2025-09-21 23:11:00,587 - training.trainer - INFO - Epoch 9, Step 30846: Loss=6.6052, Acc=0.174, PPL=738.95
2025-09-21 23:11:08,502 - training.trainer - INFO - Epoch 9, Step 30946: Loss=6.2323, Acc=0.190, PPL=508.92
2025-09-21 23:11:16,480 - training.trainer - INFO - Epoch 9, Step 31046: Loss=7.0589, Acc=0.093, PPL=1163.19
2025-09-21 23:11:24,315 - training.trainer - INFO - Epoch 9, Step 31146: Loss=6.2793, Acc=0.159, PPL=533.41
2025-09-21 23:11:32,120 - training.trainer - INFO - Epoch 9, Step 31246: Loss=6.4375, Acc=0.182, PPL=624.81
2025-09-21 23:11:39,967 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.3666, Acc=0.128, PPL=582.06
2025-09-21 23:11:47,805 - training.trainer - INFO - Epoch 9, Step 31446: Loss=6.5035, Acc=0.179, PPL=667.44
2025-09-21 23:11:55,602 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.1237, Acc=0.192, PPL=167.96
2025-09-21 23:12:03,460 - training.trainer - INFO - Epoch 9, Step 31646: Loss=5.2743, Acc=0.250, PPL=195.25
2025-09-21 23:12:11,221 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.8024, Acc=0.179, PPL=331.09
2025-09-21 23:12:19,151 - training.trainer - INFO - Epoch 9, Step 31846: Loss=5.1745, Acc=0.278, PPL=176.71
2025-09-21 23:12:26,898 - training.trainer - INFO - Epoch 9, Step 31946: Loss=5.2196, Acc=0.320, PPL=184.86
2025-09-21 23:12:34,675 - training.trainer - INFO - Epoch 9, Step 32046: Loss=6.8632, Acc=0.235, PPL=956.41
2025-09-21 23:12:42,493 - training.trainer - INFO - Epoch 9, Step 32146: Loss=6.4350, Acc=0.172, PPL=623.28
2025-09-21 23:12:50,357 - training.trainer - INFO - Epoch 9, Step 32246: Loss=5.6703, Acc=0.222, PPL=290.12
2025-09-21 23:12:58,121 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.8301, Acc=0.263, PPL=340.39
2025-09-21 23:13:05,964 - training.trainer - INFO - Epoch 9, Step 32446: Loss=6.4933, Acc=0.174, PPL=660.72
2025-09-21 23:13:13,739 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.3989, Acc=0.250, PPL=221.17
2025-09-21 23:13:21,604 - training.trainer - INFO - Epoch 9, Step 32646: Loss=6.0371, Acc=0.116, PPL=418.68
2025-09-21 23:13:29,410 - training.trainer - INFO - Epoch 9, Step 32746: Loss=5.6433, Acc=0.227, PPL=282.39
2025-09-21 23:13:37,195 - training.trainer - INFO - Epoch 9, Step 32846: Loss=5.2690, Acc=0.300, PPL=194.21
2025-09-21 23:13:45,025 - training.trainer - INFO - Epoch 9, Step 32946: Loss=5.8717, Acc=0.135, PPL=354.85
2025-09-21 23:13:52,756 - training.trainer - INFO - Epoch 9, Step 33046: Loss=6.5275, Acc=0.107, PPL=683.68
2025-09-21 23:14:00,626 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.4859, Acc=0.174, PPL=655.85
2025-09-21 23:14:08,379 - training.trainer - INFO - Epoch 9, Step 33246: Loss=6.6160, Acc=0.108, PPL=746.93
2025-09-21 23:14:16,102 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.2248, Acc=0.185, PPL=505.14
2025-09-21 23:14:23,885 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.3839, Acc=0.139, PPL=592.26
2025-09-21 23:14:31,715 - training.trainer - INFO - Epoch 9, Step 33546: Loss=7.2013, Acc=0.098, PPL=1341.19
2025-09-21 23:14:39,461 - training.trainer - INFO - Epoch 9, Step 33646: Loss=6.5938, Acc=0.104, PPL=730.55
2025-09-21 23:14:47,229 - training.trainer - INFO - Epoch 9, Step 33746: Loss=5.5615, Acc=0.194, PPL=260.22
2025-09-21 23:15:03,727 - training.trainer - INFO - Epoch 10/100 completed in 275.66s - Train Loss: 6.0685, Train Acc: 0.192, Val Loss: 6.0156, Val Acc: 0.196
2025-09-21 23:15:04,083 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-21 23:15:04,776 - training.trainer - INFO - New best model saved with validation loss: 6.0156
2025-09-21 23:15:04,776 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-21 23:15:13,107 - training.trainer - INFO - Epoch 10, Step 33929: Loss=5.9731, Acc=0.250, PPL=392.70
2025-09-21 23:15:21,072 - training.trainer - INFO - Epoch 10, Step 34029: Loss=6.1833, Acc=0.175, PPL=484.59
2025-09-21 23:15:29,082 - training.trainer - INFO - Epoch 10, Step 34129: Loss=5.2279, Acc=0.250, PPL=186.41
2025-09-21 23:15:37,076 - training.trainer - INFO - Epoch 10, Step 34229: Loss=5.8988, Acc=0.139, PPL=364.60
2025-09-21 23:15:45,007 - training.trainer - INFO - Epoch 10, Step 34329: Loss=5.2012, Acc=0.182, PPL=181.49
2025-09-21 23:15:52,818 - training.trainer - INFO - Epoch 10, Step 34429: Loss=5.6612, Acc=0.312, PPL=287.49
2025-09-21 23:16:00,581 - training.trainer - INFO - Epoch 10, Step 34529: Loss=6.0819, Acc=0.148, PPL=437.85
2025-09-21 23:16:08,423 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.9488, Acc=0.157, PPL=383.28
2025-09-21 23:16:16,354 - training.trainer - INFO - Epoch 10, Step 34729: Loss=6.5371, Acc=0.111, PPL=690.28
2025-09-21 23:16:24,217 - training.trainer - INFO - Epoch 10, Step 34829: Loss=5.0024, Acc=0.262, PPL=148.77
2025-09-21 23:16:32,023 - training.trainer - INFO - Epoch 10, Step 34929: Loss=6.3763, Acc=0.215, PPL=587.72
2025-09-21 23:16:39,880 - training.trainer - INFO - Epoch 10, Step 35029: Loss=5.4130, Acc=0.222, PPL=224.31
2025-09-21 23:16:47,666 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.9527, Acc=0.157, PPL=1045.98
2025-09-21 23:16:55,473 - training.trainer - INFO - Epoch 10, Step 35229: Loss=5.5205, Acc=0.200, PPL=249.75
2025-09-21 23:17:03,264 - training.trainer - INFO - Epoch 10, Step 35329: Loss=6.4311, Acc=0.200, PPL=620.84
2025-09-21 23:17:11,083 - training.trainer - INFO - Epoch 10, Step 35429: Loss=6.4179, Acc=0.167, PPL=612.74
2025-09-21 23:17:18,890 - training.trainer - INFO - Epoch 10, Step 35529: Loss=6.0628, Acc=0.222, PPL=429.60
2025-09-21 23:17:26,762 - training.trainer - INFO - Epoch 10, Step 35629: Loss=6.4479, Acc=0.194, PPL=631.35
2025-09-21 23:17:34,606 - training.trainer - INFO - Epoch 10, Step 35729: Loss=6.3879, Acc=0.159, PPL=594.58
2025-09-21 23:17:42,408 - training.trainer - INFO - Epoch 10, Step 35829: Loss=6.4882, Acc=0.250, PPL=657.37
2025-09-21 23:17:50,324 - training.trainer - INFO - Epoch 10, Step 35929: Loss=5.5203, Acc=0.320, PPL=249.70
2025-09-21 23:17:58,151 - training.trainer - INFO - Epoch 10, Step 36029: Loss=5.8260, Acc=0.231, PPL=339.00
2025-09-21 23:18:05,998 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.9777, Acc=0.211, PPL=394.52
2025-09-21 23:18:13,827 - training.trainer - INFO - Epoch 10, Step 36229: Loss=5.9062, Acc=0.171, PPL=367.30
2025-09-21 23:18:21,633 - training.trainer - INFO - Epoch 10, Step 36329: Loss=6.5663, Acc=0.158, PPL=710.75
2025-09-21 23:18:29,389 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.1854, Acc=0.156, PPL=485.63
2025-09-21 23:18:37,208 - training.trainer - INFO - Epoch 10, Step 36529: Loss=6.3569, Acc=0.193, PPL=576.45
2025-09-21 23:18:44,999 - training.trainer - INFO - Epoch 10, Step 36629: Loss=5.1244, Acc=0.370, PPL=168.07
2025-09-21 23:18:52,916 - training.trainer - INFO - Epoch 10, Step 36729: Loss=6.1373, Acc=0.174, PPL=462.78
2025-09-21 23:19:00,713 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.6549, Acc=0.191, PPL=285.70
2025-09-21 23:19:08,558 - training.trainer - INFO - Epoch 10, Step 36929: Loss=6.1719, Acc=0.135, PPL=479.08
2025-09-21 23:19:16,377 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.8365, Acc=0.353, PPL=342.57
2025-09-21 23:19:24,273 - training.trainer - INFO - Epoch 10, Step 37129: Loss=5.8119, Acc=0.333, PPL=334.24
2025-09-21 23:19:41,469 - training.trainer - INFO - Epoch 11/100 completed in 276.69s - Train Loss: 6.0432, Train Acc: 0.194, Val Loss: 5.9792, Val Acc: 0.196
2025-09-21 23:19:42,078 - training.trainer - INFO - New best model saved with validation loss: 5.9792
2025-09-21 23:19:42,078 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-21 23:19:50,160 - training.trainer - INFO - Epoch 11, Step 37312: Loss=5.8688, Acc=0.233, PPL=353.84
2025-09-21 23:19:58,047 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.3110, Acc=0.174, PPL=550.58
2025-09-21 23:20:05,997 - training.trainer - INFO - Epoch 11, Step 37512: Loss=5.4975, Acc=0.194, PPL=244.09
2025-09-21 23:20:13,988 - training.trainer - INFO - Epoch 11, Step 37612: Loss=5.9430, Acc=0.261, PPL=381.09
2025-09-21 23:20:22,103 - training.trainer - INFO - Epoch 11, Step 37712: Loss=5.7106, Acc=0.259, PPL=302.04
2025-09-21 23:20:30,154 - training.trainer - INFO - Epoch 11, Step 37812: Loss=6.2862, Acc=0.200, PPL=537.08
2025-09-21 23:20:38,177 - training.trainer - INFO - Epoch 11, Step 37912: Loss=5.6498, Acc=0.212, PPL=284.24
2025-09-21 23:20:46,224 - training.trainer - INFO - Epoch 11, Step 38012: Loss=6.5214, Acc=0.141, PPL=679.55
2025-09-21 23:20:54,093 - training.trainer - INFO - Epoch 11, Step 38112: Loss=6.2480, Acc=0.167, PPL=516.97
2025-09-21 23:21:02,095 - training.trainer - INFO - Epoch 11, Step 38212: Loss=4.9902, Acc=0.273, PPL=146.96
2025-09-21 23:21:10,027 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.2638, Acc=0.160, PPL=525.21
2025-09-21 23:21:17,917 - training.trainer - INFO - Epoch 11, Step 38412: Loss=6.1882, Acc=0.133, PPL=486.97
2025-09-21 23:21:25,893 - training.trainer - INFO - Epoch 11, Step 38512: Loss=6.0999, Acc=0.125, PPL=445.83
2025-09-21 23:21:33,844 - training.trainer - INFO - Epoch 11, Step 38612: Loss=6.1742, Acc=0.143, PPL=480.19
2025-09-21 23:21:41,798 - training.trainer - INFO - Epoch 11, Step 38712: Loss=5.6513, Acc=0.204, PPL=284.67
2025-09-21 23:21:49,700 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.2711, Acc=0.318, PPL=194.63
2025-09-21 23:21:57,614 - training.trainer - INFO - Epoch 11, Step 38912: Loss=6.2129, Acc=0.184, PPL=499.12
2025-09-21 23:22:05,528 - training.trainer - INFO - Epoch 11, Step 39012: Loss=5.5865, Acc=0.175, PPL=266.80
2025-09-21 23:22:13,424 - training.trainer - INFO - Epoch 11, Step 39112: Loss=6.2014, Acc=0.182, PPL=493.42
2025-09-21 23:22:21,336 - training.trainer - INFO - Epoch 11, Step 39212: Loss=6.6819, Acc=0.164, PPL=797.87
2025-09-21 23:22:29,232 - training.trainer - INFO - Epoch 11, Step 39312: Loss=6.3765, Acc=0.346, PPL=587.88
2025-09-21 23:22:37,151 - training.trainer - INFO - Epoch 11, Step 39412: Loss=6.2044, Acc=0.120, PPL=494.92
2025-09-21 23:22:45,228 - training.trainer - INFO - Epoch 11, Step 39512: Loss=6.1382, Acc=0.125, PPL=463.23
2025-09-21 23:22:53,308 - training.trainer - INFO - Epoch 11, Step 39612: Loss=5.2655, Acc=0.471, PPL=193.54
2025-09-21 23:23:01,227 - training.trainer - INFO - Epoch 11, Step 39712: Loss=6.2203, Acc=0.255, PPL=502.86
2025-09-21 23:23:09,172 - training.trainer - INFO - Epoch 11, Step 39812: Loss=5.6259, Acc=0.241, PPL=277.53
2025-09-21 23:23:17,240 - training.trainer - INFO - Epoch 11, Step 39912: Loss=5.8808, Acc=0.175, PPL=358.08
2025-09-21 23:23:25,118 - training.trainer - INFO - Epoch 11, Step 40012: Loss=6.2130, Acc=0.250, PPL=499.20
2025-09-21 23:23:32,947 - training.trainer - INFO - Epoch 11, Step 40112: Loss=6.5384, Acc=0.147, PPL=691.15
2025-09-21 23:23:40,791 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.2446, Acc=0.222, PPL=189.54
2025-09-21 23:23:48,707 - training.trainer - INFO - Epoch 11, Step 40312: Loss=6.3450, Acc=0.154, PPL=569.63
2025-09-21 23:23:56,571 - training.trainer - INFO - Epoch 11, Step 40412: Loss=6.0655, Acc=0.140, PPL=430.74
2025-09-21 23:24:04,388 - training.trainer - INFO - Epoch 11, Step 40512: Loss=5.4861, Acc=0.250, PPL=241.30
2025-09-21 23:24:21,775 - training.trainer - INFO - Epoch 12/100 completed in 279.70s - Train Loss: 6.0187, Train Acc: 0.198, Val Loss: 5.9800, Val Acc: 0.197
2025-09-21 23:24:29,843 - training.trainer - INFO - Epoch 12, Step 40695: Loss=5.5474, Acc=0.231, PPL=256.57
2025-09-21 23:24:37,722 - training.trainer - INFO - Epoch 12, Step 40795: Loss=5.9326, Acc=0.260, PPL=377.12
2025-09-21 23:24:45,564 - training.trainer - INFO - Epoch 12, Step 40895: Loss=6.1901, Acc=0.186, PPL=487.90
2025-09-21 23:24:53,410 - training.trainer - INFO - Epoch 12, Step 40995: Loss=5.7457, Acc=0.177, PPL=312.84
2025-09-21 23:25:01,529 - training.trainer - INFO - Epoch 12, Step 41095: Loss=5.4330, Acc=0.267, PPL=228.85
2025-09-21 23:25:09,573 - training.trainer - INFO - Epoch 12, Step 41195: Loss=4.6185, Acc=0.267, PPL=101.34
2025-09-21 23:25:17,667 - training.trainer - INFO - Epoch 12, Step 41295: Loss=5.4012, Acc=0.152, PPL=221.67
2025-09-21 23:25:25,713 - training.trainer - INFO - Epoch 12, Step 41395: Loss=4.4192, Acc=0.312, PPL=83.03
2025-09-21 23:25:33,584 - training.trainer - INFO - Epoch 12, Step 41495: Loss=6.8601, Acc=0.111, PPL=953.45
2025-09-21 23:25:41,440 - training.trainer - INFO - Epoch 12, Step 41595: Loss=5.7168, Acc=0.250, PPL=303.94
2025-09-21 23:25:49,452 - training.trainer - INFO - Epoch 12, Step 41695: Loss=5.9395, Acc=0.185, PPL=379.74
2025-09-21 23:25:57,474 - training.trainer - INFO - Epoch 12, Step 41795: Loss=6.3545, Acc=0.150, PPL=575.09
2025-09-21 23:26:05,529 - training.trainer - INFO - Epoch 12, Step 41895: Loss=5.5628, Acc=0.111, PPL=260.56
2025-09-21 23:26:13,581 - training.trainer - INFO - Epoch 12, Step 41995: Loss=6.4971, Acc=0.143, PPL=663.21
2025-09-21 23:26:21,604 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.4791, Acc=0.169, PPL=651.37
2025-09-21 23:26:29,624 - training.trainer - INFO - Epoch 12, Step 42195: Loss=6.0231, Acc=0.125, PPL=412.84
2025-09-21 23:26:37,569 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.4668, Acc=0.217, PPL=236.70
2025-09-21 23:26:45,594 - training.trainer - INFO - Epoch 12, Step 42395: Loss=6.4424, Acc=0.132, PPL=627.88
2025-09-21 23:26:53,674 - training.trainer - INFO - Epoch 12, Step 42495: Loss=5.3808, Acc=0.171, PPL=217.20
2025-09-21 23:27:01,778 - training.trainer - INFO - Epoch 12, Step 42595: Loss=5.9829, Acc=0.145, PPL=396.61
2025-09-21 23:27:09,758 - training.trainer - INFO - Epoch 12, Step 42695: Loss=5.1719, Acc=0.318, PPL=176.24
2025-09-21 23:27:17,820 - training.trainer - INFO - Epoch 12, Step 42795: Loss=6.1535, Acc=0.176, PPL=470.35
2025-09-21 23:27:25,777 - training.trainer - INFO - Epoch 12, Step 42895: Loss=6.2476, Acc=0.159, PPL=516.78
2025-09-21 23:27:33,792 - training.trainer - INFO - Epoch 12, Step 42995: Loss=6.3664, Acc=0.194, PPL=581.94
2025-09-21 23:27:41,709 - training.trainer - INFO - Epoch 12, Step 43095: Loss=5.1680, Acc=0.300, PPL=175.56
2025-09-21 23:27:49,596 - training.trainer - INFO - Epoch 12, Step 43195: Loss=5.9976, Acc=0.190, PPL=402.45
2025-09-21 23:27:57,493 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.0346, Acc=0.214, PPL=417.61
2025-09-21 23:28:05,597 - training.trainer - INFO - Epoch 12, Step 43395: Loss=5.9159, Acc=0.203, PPL=370.88
2025-09-21 23:28:13,762 - training.trainer - INFO - Epoch 12, Step 43495: Loss=5.6450, Acc=0.125, PPL=282.87
2025-09-21 23:28:21,887 - training.trainer - INFO - Epoch 12, Step 43595: Loss=6.1340, Acc=0.167, PPL=461.29
2025-09-21 23:28:29,827 - training.trainer - INFO - Epoch 12, Step 43695: Loss=6.4029, Acc=0.160, PPL=603.57
2025-09-21 23:28:37,562 - training.trainer - INFO - Epoch 12, Step 43795: Loss=5.7890, Acc=0.306, PPL=326.67
2025-09-21 23:28:45,436 - training.trainer - INFO - Epoch 12, Step 43895: Loss=6.0505, Acc=0.268, PPL=424.33
2025-09-21 23:29:02,852 - training.trainer - INFO - Epoch 13/100 completed in 281.08s - Train Loss: 6.0011, Train Acc: 0.201, Val Loss: 5.9447, Val Acc: 0.204
2025-09-21 23:29:03,574 - training.trainer - INFO - New best model saved with validation loss: 5.9447
2025-09-21 23:29:03,574 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-21 23:29:12,045 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.0848, Acc=0.211, PPL=439.13
2025-09-21 23:29:20,242 - training.trainer - INFO - Epoch 13, Step 44178: Loss=5.9244, Acc=0.240, PPL=374.06
2025-09-21 23:29:28,341 - training.trainer - INFO - Epoch 13, Step 44278: Loss=5.2906, Acc=0.273, PPL=198.46
2025-09-21 23:29:36,433 - training.trainer - INFO - Epoch 13, Step 44378: Loss=5.5249, Acc=0.273, PPL=250.85
2025-09-21 23:29:44,588 - training.trainer - INFO - Epoch 13, Step 44478: Loss=5.7848, Acc=0.176, PPL=325.33
2025-09-21 23:29:52,706 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.7805, Acc=0.261, PPL=323.91
2025-09-21 23:30:00,837 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.6183, Acc=0.286, PPL=275.42
2025-09-21 23:30:08,944 - training.trainer - INFO - Epoch 13, Step 44778: Loss=6.5850, Acc=0.116, PPL=724.15
2025-09-21 23:30:17,078 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.8669, Acc=0.208, PPL=353.15
2025-09-21 23:30:25,168 - training.trainer - INFO - Epoch 13, Step 44978: Loss=5.6629, Acc=0.235, PPL=287.97
2025-09-21 23:30:33,310 - training.trainer - INFO - Epoch 13, Step 45078: Loss=5.6667, Acc=0.280, PPL=289.07
2025-09-21 23:30:41,475 - training.trainer - INFO - Epoch 13, Step 45178: Loss=6.6144, Acc=0.137, PPL=745.76
2025-09-21 23:30:49,775 - training.trainer - INFO - Epoch 13, Step 45278: Loss=6.9140, Acc=0.096, PPL=1006.25
2025-09-21 23:30:57,978 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.5076, Acc=0.283, PPL=670.23
2025-09-21 23:31:06,092 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.5636, Acc=0.200, PPL=260.76
2025-09-21 23:31:14,234 - training.trainer - INFO - Epoch 13, Step 45578: Loss=6.1457, Acc=0.208, PPL=466.71
2025-09-21 23:31:22,254 - training.trainer - INFO - Epoch 13, Step 45678: Loss=5.5778, Acc=0.333, PPL=264.48
2025-09-21 23:31:30,351 - training.trainer - INFO - Epoch 13, Step 45778: Loss=5.7149, Acc=0.117, PPL=303.35
2025-09-21 23:31:38,370 - training.trainer - INFO - Epoch 13, Step 45878: Loss=4.1486, Acc=0.583, PPL=63.34
2025-09-21 23:31:46,418 - training.trainer - INFO - Epoch 13, Step 45978: Loss=5.7570, Acc=0.170, PPL=316.40
2025-09-21 23:31:54,333 - training.trainer - INFO - Epoch 13, Step 46078: Loss=6.9793, Acc=0.066, PPL=1074.13
2025-09-21 23:32:02,327 - training.trainer - INFO - Epoch 13, Step 46178: Loss=7.2528, Acc=0.152, PPL=1412.10
2025-09-21 23:32:10,361 - training.trainer - INFO - Epoch 13, Step 46278: Loss=6.0051, Acc=0.192, PPL=405.47
2025-09-21 23:32:18,347 - training.trainer - INFO - Epoch 13, Step 46378: Loss=5.8518, Acc=0.267, PPL=347.87
2025-09-21 23:32:26,353 - training.trainer - INFO - Epoch 13, Step 46478: Loss=6.1809, Acc=0.156, PPL=483.41
2025-09-21 23:32:34,233 - training.trainer - INFO - Epoch 13, Step 46578: Loss=6.0802, Acc=0.146, PPL=437.11
2025-09-21 23:32:42,054 - training.trainer - INFO - Epoch 13, Step 46678: Loss=5.5581, Acc=0.235, PPL=259.33
2025-09-21 23:32:49,909 - training.trainer - INFO - Epoch 13, Step 46778: Loss=6.3631, Acc=0.146, PPL=580.05
2025-09-21 23:32:57,822 - training.trainer - INFO - Epoch 13, Step 46878: Loss=5.3046, Acc=0.278, PPL=201.26
2025-09-21 23:33:05,668 - training.trainer - INFO - Epoch 13, Step 46978: Loss=5.7682, Acc=0.213, PPL=319.96
2025-09-21 23:33:13,584 - training.trainer - INFO - Epoch 13, Step 47078: Loss=5.9313, Acc=0.207, PPL=376.66
2025-09-21 23:33:21,524 - training.trainer - INFO - Epoch 13, Step 47178: Loss=6.5527, Acc=0.136, PPL=701.14
2025-09-21 23:33:29,381 - training.trainer - INFO - Epoch 13, Step 47278: Loss=6.7952, Acc=0.182, PPL=893.57
2025-09-21 23:33:46,660 - training.trainer - INFO - Epoch 14/100 completed in 283.08s - Train Loss: 5.9859, Train Acc: 0.204, Val Loss: 5.9286, Val Acc: 0.209
2025-09-21 23:33:47,486 - training.trainer - INFO - New best model saved with validation loss: 5.9286
2025-09-21 23:33:47,487 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-21 23:33:55,854 - training.trainer - INFO - Epoch 14, Step 47461: Loss=6.5392, Acc=0.099, PPL=691.75
2025-09-21 23:34:04,008 - training.trainer - INFO - Epoch 14, Step 47561: Loss=6.5045, Acc=0.149, PPL=668.13
2025-09-21 23:34:12,213 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.9107, Acc=0.200, PPL=368.97
2025-09-21 23:34:20,319 - training.trainer - INFO - Epoch 14, Step 47761: Loss=5.3689, Acc=0.220, PPL=214.63
2025-09-21 23:34:28,427 - training.trainer - INFO - Epoch 14, Step 47861: Loss=4.6519, Acc=0.304, PPL=104.79
2025-09-21 23:34:36,589 - training.trainer - INFO - Epoch 14, Step 47961: Loss=6.1340, Acc=0.191, PPL=461.29
2025-09-21 23:34:44,894 - training.trainer - INFO - Epoch 14, Step 48061: Loss=6.1197, Acc=0.175, PPL=454.73
2025-09-21 23:34:53,020 - training.trainer - INFO - Epoch 14, Step 48161: Loss=5.8438, Acc=0.176, PPL=345.10
2025-09-21 23:35:01,195 - training.trainer - INFO - Epoch 14, Step 48261: Loss=6.6847, Acc=0.079, PPL=800.06
2025-09-21 23:35:09,379 - training.trainer - INFO - Epoch 14, Step 48361: Loss=6.7069, Acc=0.119, PPL=818.04
2025-09-21 23:35:17,587 - training.trainer - INFO - Epoch 14, Step 48461: Loss=6.7221, Acc=0.179, PPL=830.57
2025-09-21 23:35:25,675 - training.trainer - INFO - Epoch 14, Step 48561: Loss=5.4807, Acc=0.259, PPL=240.01
2025-09-21 23:35:33,764 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.7632, Acc=0.160, PPL=318.38
2025-09-21 23:35:41,864 - training.trainer - INFO - Epoch 14, Step 48761: Loss=4.5554, Acc=0.357, PPL=95.15
2025-09-21 23:35:50,044 - training.trainer - INFO - Epoch 14, Step 48861: Loss=5.9180, Acc=0.238, PPL=371.67
2025-09-21 23:35:58,236 - training.trainer - INFO - Epoch 14, Step 48961: Loss=6.5889, Acc=0.133, PPL=726.97
2025-09-21 23:36:06,315 - training.trainer - INFO - Epoch 14, Step 49061: Loss=6.1983, Acc=0.216, PPL=491.92
2025-09-21 23:36:14,207 - training.trainer - INFO - Epoch 14, Step 49161: Loss=5.2209, Acc=0.273, PPL=185.10
2025-09-21 23:36:22,232 - training.trainer - INFO - Epoch 14, Step 49261: Loss=6.0310, Acc=0.200, PPL=416.13
2025-09-21 23:36:30,170 - training.trainer - INFO - Epoch 14, Step 49361: Loss=6.7560, Acc=0.227, PPL=859.22
2025-09-21 23:36:38,081 - training.trainer - INFO - Epoch 14, Step 49461: Loss=4.8986, Acc=0.333, PPL=134.10
2025-09-21 23:36:46,047 - training.trainer - INFO - Epoch 14, Step 49561: Loss=6.0086, Acc=0.237, PPL=406.91
2025-09-21 23:36:54,063 - training.trainer - INFO - Epoch 14, Step 49661: Loss=5.8729, Acc=0.167, PPL=355.27
2025-09-21 23:37:01,934 - training.trainer - INFO - Epoch 14, Step 49761: Loss=6.2504, Acc=0.240, PPL=518.21
2025-09-21 23:37:09,847 - training.trainer - INFO - Epoch 14, Step 49861: Loss=5.8247, Acc=0.242, PPL=338.54
2025-09-21 23:37:17,773 - training.trainer - INFO - Epoch 14, Step 49961: Loss=4.8623, Acc=0.300, PPL=129.32
2025-09-21 23:37:25,694 - training.trainer - INFO - Epoch 14, Step 50061: Loss=5.6788, Acc=0.265, PPL=292.59
2025-09-21 23:37:33,570 - training.trainer - INFO - Epoch 14, Step 50161: Loss=6.0831, Acc=0.220, PPL=438.37
2025-09-21 23:37:41,403 - training.trainer - INFO - Epoch 14, Step 50261: Loss=6.5271, Acc=0.171, PPL=683.41
2025-09-21 23:37:49,270 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.6491, Acc=0.227, PPL=284.04
2025-09-21 23:37:57,081 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.5274, Acc=0.290, PPL=251.49
2025-09-21 23:38:04,892 - training.trainer - INFO - Epoch 14, Step 50561: Loss=6.0040, Acc=0.185, PPL=405.06
2025-09-21 23:38:12,761 - training.trainer - INFO - Epoch 14, Step 50661: Loss=5.8514, Acc=0.182, PPL=347.70
2025-09-21 23:38:29,129 - training.trainer - INFO - Epoch 15/100 completed in 281.64s - Train Loss: 5.9590, Train Acc: 0.208, Val Loss: 5.9177, Val Acc: 0.214
2025-09-21 23:38:29,502 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-21 23:38:30,216 - training.trainer - INFO - New best model saved with validation loss: 5.9177
2025-09-21 23:38:30,217 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-21 23:38:38,257 - training.trainer - INFO - Epoch 15, Step 50844: Loss=6.6047, Acc=0.116, PPL=738.54
2025-09-21 23:38:46,075 - training.trainer - INFO - Epoch 15, Step 50944: Loss=6.1094, Acc=0.233, PPL=450.06
2025-09-21 23:38:54,224 - training.trainer - INFO - Epoch 15, Step 51044: Loss=5.9391, Acc=0.227, PPL=379.60
2025-09-21 23:39:02,360 - training.trainer - INFO - Epoch 15, Step 51144: Loss=6.0952, Acc=0.250, PPL=443.74
2025-09-21 23:39:10,441 - training.trainer - INFO - Epoch 15, Step 51244: Loss=6.0909, Acc=0.153, PPL=441.84
2025-09-21 23:39:18,462 - training.trainer - INFO - Epoch 15, Step 51344: Loss=6.1141, Acc=0.146, PPL=452.19
2025-09-21 23:39:26,719 - training.trainer - INFO - Epoch 15, Step 51444: Loss=3.9978, Acc=0.333, PPL=54.48
2025-09-21 23:39:34,901 - training.trainer - INFO - Epoch 15, Step 51544: Loss=6.2107, Acc=0.286, PPL=498.05
2025-09-21 23:39:42,917 - training.trainer - INFO - Epoch 15, Step 51644: Loss=6.2378, Acc=0.214, PPL=511.72
2025-09-21 23:39:50,913 - training.trainer - INFO - Epoch 15, Step 51744: Loss=5.7652, Acc=0.217, PPL=319.01
2025-09-21 23:39:58,867 - training.trainer - INFO - Epoch 15, Step 51844: Loss=5.0768, Acc=0.286, PPL=160.26
2025-09-21 23:40:06,797 - training.trainer - INFO - Epoch 15, Step 51944: Loss=5.6682, Acc=0.286, PPL=289.52
2025-09-21 23:40:14,625 - training.trainer - INFO - Epoch 15, Step 52044: Loss=5.9577, Acc=0.197, PPL=386.74
2025-09-21 23:40:22,510 - training.trainer - INFO - Epoch 15, Step 52144: Loss=6.0824, Acc=0.136, PPL=438.08
2025-09-21 23:40:30,414 - training.trainer - INFO - Epoch 15, Step 52244: Loss=5.2440, Acc=0.267, PPL=189.42
2025-09-21 23:40:38,341 - training.trainer - INFO - Epoch 15, Step 52344: Loss=5.0387, Acc=0.200, PPL=154.27
2025-09-21 23:40:46,283 - training.trainer - INFO - Epoch 15, Step 52444: Loss=5.3502, Acc=0.179, PPL=210.64
2025-09-21 23:40:54,188 - training.trainer - INFO - Epoch 15, Step 52544: Loss=6.4699, Acc=0.125, PPL=645.44
2025-09-21 23:41:02,056 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.0466, Acc=0.188, PPL=155.49
2025-09-21 23:41:09,943 - training.trainer - INFO - Epoch 15, Step 52744: Loss=5.8817, Acc=0.243, PPL=358.42
2025-09-21 23:41:17,902 - training.trainer - INFO - Epoch 15, Step 52844: Loss=6.3971, Acc=0.290, PPL=600.08
2025-09-21 23:41:25,849 - training.trainer - INFO - Epoch 15, Step 52944: Loss=5.7001, Acc=0.154, PPL=298.90
2025-09-21 23:41:33,740 - training.trainer - INFO - Epoch 15, Step 53044: Loss=6.4145, Acc=0.250, PPL=610.62
2025-09-21 23:41:41,624 - training.trainer - INFO - Epoch 15, Step 53144: Loss=6.2686, Acc=0.188, PPL=527.75
2025-09-21 23:41:49,546 - training.trainer - INFO - Epoch 15, Step 53244: Loss=5.8937, Acc=0.263, PPL=362.73
2025-09-21 23:41:57,452 - training.trainer - INFO - Epoch 15, Step 53344: Loss=5.8068, Acc=0.200, PPL=332.55
2025-09-21 23:42:05,403 - training.trainer - INFO - Epoch 15, Step 53444: Loss=6.2167, Acc=0.200, PPL=501.06
2025-09-21 23:42:13,358 - training.trainer - INFO - Epoch 15, Step 53544: Loss=6.2757, Acc=0.135, PPL=531.49
2025-09-21 23:42:21,339 - training.trainer - INFO - Epoch 15, Step 53644: Loss=6.1617, Acc=0.212, PPL=474.25
2025-09-21 23:42:29,239 - training.trainer - INFO - Epoch 15, Step 53744: Loss=6.2643, Acc=0.176, PPL=525.47
2025-09-21 23:42:37,103 - training.trainer - INFO - Epoch 15, Step 53844: Loss=5.8234, Acc=0.156, PPL=338.10
2025-09-21 23:42:45,006 - training.trainer - INFO - Epoch 15, Step 53944: Loss=6.6505, Acc=0.169, PPL=773.19
2025-09-21 23:42:52,939 - training.trainer - INFO - Epoch 15, Step 54044: Loss=5.6753, Acc=0.211, PPL=291.57
2025-09-21 23:43:09,950 - training.trainer - INFO - Epoch 16/100 completed in 279.73s - Train Loss: 5.9371, Train Acc: 0.212, Val Loss: 5.8901, Val Acc: 0.219
2025-09-21 23:43:10,549 - training.trainer - INFO - New best model saved with validation loss: 5.8901
2025-09-21 23:43:10,549 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-21 23:43:18,722 - training.trainer - INFO - Epoch 16, Step 54227: Loss=6.4945, Acc=0.194, PPL=661.50
2025-09-21 23:43:26,615 - training.trainer - INFO - Epoch 16, Step 54327: Loss=6.0049, Acc=0.217, PPL=405.39
2025-09-21 23:43:34,481 - training.trainer - INFO - Epoch 16, Step 54427: Loss=6.4958, Acc=0.188, PPL=662.34
2025-09-21 23:43:42,414 - training.trainer - INFO - Epoch 16, Step 54527: Loss=6.3229, Acc=0.128, PPL=557.18
2025-09-21 23:43:50,369 - training.trainer - INFO - Epoch 16, Step 54627: Loss=6.3820, Acc=0.205, PPL=591.14
2025-09-21 23:43:58,248 - training.trainer - INFO - Epoch 16, Step 54727: Loss=5.9189, Acc=0.125, PPL=372.00
2025-09-21 23:44:06,179 - training.trainer - INFO - Epoch 16, Step 54827: Loss=5.9748, Acc=0.214, PPL=393.38
2025-09-21 23:44:14,052 - training.trainer - INFO - Epoch 16, Step 54927: Loss=6.3012, Acc=0.186, PPL=545.20
2025-09-21 23:44:21,888 - training.trainer - INFO - Epoch 16, Step 55027: Loss=6.3608, Acc=0.145, PPL=578.69
2025-09-21 23:44:29,704 - training.trainer - INFO - Epoch 16, Step 55127: Loss=5.8402, Acc=0.152, PPL=343.86
2025-09-21 23:44:37,570 - training.trainer - INFO - Epoch 16, Step 55227: Loss=6.1901, Acc=0.188, PPL=487.91
2025-09-21 23:44:45,396 - training.trainer - INFO - Epoch 16, Step 55327: Loss=5.7808, Acc=0.200, PPL=324.01
2025-09-21 23:44:53,219 - training.trainer - INFO - Epoch 16, Step 55427: Loss=5.8528, Acc=0.208, PPL=348.20
2025-09-21 23:45:01,132 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.2565, Acc=0.261, PPL=191.82
2025-09-21 23:45:09,049 - training.trainer - INFO - Epoch 16, Step 55627: Loss=4.2337, Acc=0.519, PPL=68.97
2025-09-21 23:45:16,929 - training.trainer - INFO - Epoch 16, Step 55727: Loss=5.1509, Acc=0.233, PPL=172.58
2025-09-21 23:45:24,832 - training.trainer - INFO - Epoch 16, Step 55827: Loss=6.0135, Acc=0.154, PPL=408.90
2025-09-21 23:45:32,814 - training.trainer - INFO - Epoch 16, Step 55927: Loss=5.5351, Acc=0.237, PPL=253.42
2025-09-21 23:45:40,848 - training.trainer - INFO - Epoch 16, Step 56027: Loss=6.2455, Acc=0.273, PPL=515.69
2025-09-21 23:45:48,871 - training.trainer - INFO - Epoch 16, Step 56127: Loss=6.1498, Acc=0.236, PPL=468.65
2025-09-21 23:45:56,750 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.9572, Acc=0.265, PPL=386.54
2025-09-21 23:46:04,694 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.4126, Acc=0.393, PPL=224.20
2025-09-21 23:46:12,507 - training.trainer - INFO - Epoch 16, Step 56427: Loss=6.5857, Acc=0.125, PPL=724.68
2025-09-21 23:46:20,294 - training.trainer - INFO - Epoch 16, Step 56527: Loss=5.3173, Acc=0.200, PPL=203.83
2025-09-21 23:46:28,207 - training.trainer - INFO - Epoch 16, Step 56627: Loss=6.1340, Acc=0.139, PPL=461.27
2025-09-21 23:46:36,043 - training.trainer - INFO - Epoch 16, Step 56727: Loss=6.4265, Acc=0.184, PPL=618.01
2025-09-21 23:46:43,950 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.8627, Acc=0.186, PPL=351.69
2025-09-21 23:46:51,842 - training.trainer - INFO - Epoch 16, Step 56927: Loss=6.0478, Acc=0.226, PPL=423.18
2025-09-21 23:46:59,688 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.8676, Acc=0.208, PPL=353.41
2025-09-21 23:47:07,625 - training.trainer - INFO - Epoch 16, Step 57127: Loss=5.6934, Acc=0.357, PPL=296.91
2025-09-21 23:47:15,521 - training.trainer - INFO - Epoch 16, Step 57227: Loss=6.1572, Acc=0.139, PPL=472.10
2025-09-21 23:47:23,324 - training.trainer - INFO - Epoch 16, Step 57327: Loss=6.0161, Acc=0.191, PPL=409.99
2025-09-21 23:47:31,200 - training.trainer - INFO - Epoch 16, Step 57427: Loss=5.1644, Acc=0.278, PPL=174.93
2025-09-21 23:47:48,552 - training.trainer - INFO - Epoch 17/100 completed in 278.00s - Train Loss: 5.9189, Train Acc: 0.214, Val Loss: 5.8795, Val Acc: 0.221
2025-09-21 23:47:49,423 - training.trainer - INFO - New best model saved with validation loss: 5.8795
2025-09-21 23:47:49,424 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-21 23:47:57,983 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.5083, Acc=0.235, PPL=246.74
2025-09-21 23:48:05,991 - training.trainer - INFO - Epoch 17, Step 57710: Loss=6.3006, Acc=0.164, PPL=544.89
2025-09-21 23:48:13,887 - training.trainer - INFO - Epoch 17, Step 57810: Loss=5.6736, Acc=0.211, PPL=291.07
2025-09-21 23:48:21,833 - training.trainer - INFO - Epoch 17, Step 57910: Loss=5.8112, Acc=0.367, PPL=334.01
2025-09-21 23:48:29,684 - training.trainer - INFO - Epoch 17, Step 58010: Loss=6.0343, Acc=0.211, PPL=417.50
2025-09-21 23:48:37,678 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.7446, Acc=0.250, PPL=312.50
2025-09-21 23:48:45,734 - training.trainer - INFO - Epoch 17, Step 58210: Loss=6.5622, Acc=0.207, PPL=707.86
2025-09-21 23:48:53,709 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.7602, Acc=0.208, PPL=317.40
2025-09-21 23:49:01,571 - training.trainer - INFO - Epoch 17, Step 58410: Loss=5.6935, Acc=0.256, PPL=296.94
2025-09-21 23:49:09,495 - training.trainer - INFO - Epoch 17, Step 58510: Loss=5.8172, Acc=0.280, PPL=336.01
2025-09-21 23:49:17,381 - training.trainer - INFO - Epoch 17, Step 58610: Loss=5.8599, Acc=0.225, PPL=350.71
2025-09-21 23:49:25,241 - training.trainer - INFO - Epoch 17, Step 58710: Loss=5.4085, Acc=0.333, PPL=223.30
2025-09-21 23:49:33,123 - training.trainer - INFO - Epoch 17, Step 58810: Loss=6.4934, Acc=0.167, PPL=660.77
2025-09-21 23:49:41,106 - training.trainer - INFO - Epoch 17, Step 58910: Loss=6.3288, Acc=0.097, PPL=560.47
2025-09-21 23:49:49,231 - training.trainer - INFO - Epoch 17, Step 59010: Loss=3.2879, Acc=0.609, PPL=26.79
2025-09-21 23:49:57,293 - training.trainer - INFO - Epoch 17, Step 59110: Loss=6.3893, Acc=0.190, PPL=595.42
2025-09-21 23:50:05,312 - training.trainer - INFO - Epoch 17, Step 59210: Loss=6.4079, Acc=0.200, PPL=606.61
2025-09-21 23:50:13,314 - training.trainer - INFO - Epoch 17, Step 59310: Loss=5.7887, Acc=0.190, PPL=326.57
2025-09-21 23:50:21,462 - training.trainer - INFO - Epoch 17, Step 59410: Loss=6.3568, Acc=0.162, PPL=576.39
2025-09-21 23:50:29,479 - training.trainer - INFO - Epoch 17, Step 59510: Loss=6.6808, Acc=0.087, PPL=796.96
2025-09-21 23:50:37,402 - training.trainer - INFO - Epoch 17, Step 59610: Loss=6.3724, Acc=0.107, PPL=585.49
2025-09-21 23:50:45,341 - training.trainer - INFO - Epoch 17, Step 59710: Loss=5.7771, Acc=0.246, PPL=322.81
2025-09-21 23:50:53,294 - training.trainer - INFO - Epoch 17, Step 59810: Loss=5.7139, Acc=0.220, PPL=303.04
2025-09-21 23:51:01,166 - training.trainer - INFO - Epoch 17, Step 59910: Loss=6.6983, Acc=0.255, PPL=811.02
2025-09-21 23:51:09,053 - training.trainer - INFO - Epoch 17, Step 60010: Loss=5.3292, Acc=0.222, PPL=206.28
2025-09-21 23:51:16,900 - training.trainer - INFO - Epoch 17, Step 60110: Loss=5.9198, Acc=0.128, PPL=372.33
2025-09-21 23:51:24,744 - training.trainer - INFO - Epoch 17, Step 60210: Loss=6.7553, Acc=0.214, PPL=858.56
2025-09-21 23:51:32,584 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.7159, Acc=0.211, PPL=303.65
2025-09-21 23:51:40,445 - training.trainer - INFO - Epoch 17, Step 60410: Loss=6.0504, Acc=0.192, PPL=424.28
2025-09-21 23:51:48,305 - training.trainer - INFO - Epoch 17, Step 60510: Loss=6.2191, Acc=0.208, PPL=502.25
2025-09-21 23:51:56,208 - training.trainer - INFO - Epoch 17, Step 60610: Loss=6.2662, Acc=0.094, PPL=526.45
2025-09-21 23:52:04,086 - training.trainer - INFO - Epoch 17, Step 60710: Loss=6.4978, Acc=0.121, PPL=663.66
2025-09-21 23:52:12,177 - training.trainer - INFO - Epoch 17, Step 60810: Loss=6.2713, Acc=0.145, PPL=529.18
2025-09-21 23:52:28,555 - training.trainer - INFO - Epoch 18/100 completed in 279.13s - Train Loss: 5.9067, Train Acc: 0.218, Val Loss: 5.8579, Val Acc: 0.218
2025-09-21 23:52:29,248 - training.trainer - INFO - New best model saved with validation loss: 5.8579
2025-09-21 23:52:29,248 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-21 23:52:37,224 - training.trainer - INFO - Epoch 18, Step 60993: Loss=4.5492, Acc=0.207, PPL=94.56
2025-09-21 23:52:45,035 - training.trainer - INFO - Epoch 18, Step 61093: Loss=6.4606, Acc=0.145, PPL=639.42
2025-09-21 23:52:52,899 - training.trainer - INFO - Epoch 18, Step 61193: Loss=5.8756, Acc=0.212, PPL=356.24
2025-09-21 23:53:00,706 - training.trainer - INFO - Epoch 18, Step 61293: Loss=5.8685, Acc=0.212, PPL=353.71
2025-09-21 23:53:08,619 - training.trainer - INFO - Epoch 18, Step 61393: Loss=5.6087, Acc=0.289, PPL=272.80
2025-09-21 23:53:16,478 - training.trainer - INFO - Epoch 18, Step 61493: Loss=5.3916, Acc=0.250, PPL=219.56
2025-09-21 23:53:24,235 - training.trainer - INFO - Epoch 18, Step 61593: Loss=4.5733, Acc=0.381, PPL=96.86
2025-09-21 23:53:32,122 - training.trainer - INFO - Epoch 18, Step 61693: Loss=6.1105, Acc=0.208, PPL=450.55
2025-09-21 23:53:39,992 - training.trainer - INFO - Epoch 18, Step 61793: Loss=6.2832, Acc=0.132, PPL=535.50
2025-09-21 23:53:48,069 - training.trainer - INFO - Epoch 18, Step 61893: Loss=5.5021, Acc=0.225, PPL=245.22
2025-09-21 23:53:55,845 - training.trainer - INFO - Epoch 18, Step 61993: Loss=5.6670, Acc=0.333, PPL=289.15
2025-09-21 23:54:03,671 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.4409, Acc=0.265, PPL=230.65
2025-09-21 23:54:11,562 - training.trainer - INFO - Epoch 18, Step 62193: Loss=6.3054, Acc=0.256, PPL=547.53
2025-09-21 23:54:19,467 - training.trainer - INFO - Epoch 18, Step 62293: Loss=5.8398, Acc=0.188, PPL=343.72
2025-09-21 23:54:27,213 - training.trainer - INFO - Epoch 18, Step 62393: Loss=6.2277, Acc=0.208, PPL=506.58
2025-09-21 23:54:35,060 - training.trainer - INFO - Epoch 18, Step 62493: Loss=6.3073, Acc=0.156, PPL=548.57
2025-09-21 23:54:42,867 - training.trainer - INFO - Epoch 18, Step 62593: Loss=6.5287, Acc=0.194, PPL=684.53
2025-09-21 23:54:50,627 - training.trainer - INFO - Epoch 18, Step 62693: Loss=4.8169, Acc=0.143, PPL=123.58
2025-09-21 23:54:58,485 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.8187, Acc=0.343, PPL=336.53
2025-09-21 23:55:06,313 - training.trainer - INFO - Epoch 18, Step 62893: Loss=5.7449, Acc=0.350, PPL=312.59
2025-09-21 23:55:14,104 - training.trainer - INFO - Epoch 18, Step 62993: Loss=6.2717, Acc=0.143, PPL=529.40
2025-09-21 23:55:21,925 - training.trainer - INFO - Epoch 18, Step 63093: Loss=5.8799, Acc=0.209, PPL=357.78
2025-09-21 23:55:30,078 - training.trainer - INFO - Epoch 18, Step 63193: Loss=5.0047, Acc=0.273, PPL=149.11
2025-09-21 23:55:38,189 - training.trainer - INFO - Epoch 18, Step 63293: Loss=6.3010, Acc=0.143, PPL=545.11
2025-09-21 23:55:46,179 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.3830, Acc=0.290, PPL=217.68
2025-09-21 23:55:53,972 - training.trainer - INFO - Epoch 18, Step 63493: Loss=6.2440, Acc=0.216, PPL=514.92
2025-09-21 23:56:01,830 - training.trainer - INFO - Epoch 18, Step 63593: Loss=6.2579, Acc=0.214, PPL=522.10
2025-09-21 23:56:09,567 - training.trainer - INFO - Epoch 18, Step 63693: Loss=6.0127, Acc=0.179, PPL=408.57
2025-09-21 23:56:17,348 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.9871, Acc=0.209, PPL=398.24
2025-09-21 23:56:25,134 - training.trainer - INFO - Epoch 18, Step 63893: Loss=5.7436, Acc=0.333, PPL=312.19
2025-09-21 23:56:32,969 - training.trainer - INFO - Epoch 18, Step 63993: Loss=4.9922, Acc=0.300, PPL=147.27
2025-09-21 23:56:40,749 - training.trainer - INFO - Epoch 18, Step 64093: Loss=6.2264, Acc=0.273, PPL=505.92
2025-09-21 23:56:48,544 - training.trainer - INFO - Epoch 18, Step 64193: Loss=6.1767, Acc=0.135, PPL=481.42
2025-09-21 23:57:05,094 - training.trainer - INFO - Epoch 19/100 completed in 275.85s - Train Loss: 5.8793, Train Acc: 0.221, Val Loss: 5.8410, Val Acc: 0.222
2025-09-21 23:57:05,848 - training.trainer - INFO - New best model saved with validation loss: 5.8410
2025-09-21 23:57:05,849 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-21 23:57:13,955 - training.trainer - INFO - Epoch 19, Step 64376: Loss=6.0933, Acc=0.230, PPL=442.87
2025-09-21 23:57:21,750 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.6201, Acc=0.233, PPL=275.93
2025-09-21 23:57:29,551 - training.trainer - INFO - Epoch 19, Step 64576: Loss=6.0781, Acc=0.152, PPL=436.19
2025-09-21 23:57:37,468 - training.trainer - INFO - Epoch 19, Step 64676: Loss=4.7569, Acc=0.400, PPL=116.39
2025-09-21 23:57:45,282 - training.trainer - INFO - Epoch 19, Step 64776: Loss=5.1221, Acc=0.304, PPL=167.69
2025-09-21 23:57:53,062 - training.trainer - INFO - Epoch 19, Step 64876: Loss=6.2711, Acc=0.139, PPL=529.05
2025-09-21 23:58:00,841 - training.trainer - INFO - Epoch 19, Step 64976: Loss=5.9810, Acc=0.222, PPL=395.85
2025-09-21 23:58:08,701 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.5815, Acc=0.200, PPL=265.47
2025-09-21 23:58:16,493 - training.trainer - INFO - Epoch 19, Step 65176: Loss=5.3952, Acc=0.545, PPL=220.35
2025-09-21 23:58:24,249 - training.trainer - INFO - Epoch 19, Step 65276: Loss=6.1087, Acc=0.181, PPL=449.74
2025-09-21 23:58:31,987 - training.trainer - INFO - Epoch 19, Step 65376: Loss=5.5233, Acc=0.302, PPL=250.47
2025-09-21 23:58:39,831 - training.trainer - INFO - Epoch 19, Step 65476: Loss=6.2676, Acc=0.156, PPL=527.23
2025-09-21 23:58:47,743 - training.trainer - INFO - Epoch 19, Step 65576: Loss=6.0582, Acc=0.182, PPL=427.63
2025-09-21 23:58:55,590 - training.trainer - INFO - Epoch 19, Step 65676: Loss=6.3896, Acc=0.197, PPL=595.63
2025-09-21 23:59:03,500 - training.trainer - INFO - Epoch 19, Step 65776: Loss=6.1369, Acc=0.222, PPL=462.61
2025-09-21 23:59:11,568 - training.trainer - INFO - Epoch 19, Step 65876: Loss=6.4772, Acc=0.079, PPL=650.13
2025-09-21 23:59:19,766 - training.trainer - INFO - Epoch 19, Step 65976: Loss=6.3390, Acc=0.159, PPL=566.24
2025-09-21 23:59:27,945 - training.trainer - INFO - Epoch 19, Step 66076: Loss=5.7469, Acc=0.296, PPL=313.22
2025-09-21 23:59:36,103 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.8064, Acc=0.316, PPL=332.44
2025-09-21 23:59:44,150 - training.trainer - INFO - Epoch 19, Step 66276: Loss=5.7317, Acc=0.212, PPL=308.51
2025-09-21 23:59:52,179 - training.trainer - INFO - Epoch 19, Step 66376: Loss=5.3473, Acc=0.217, PPL=210.04
2025-09-22 00:00:00,246 - training.trainer - INFO - Epoch 19, Step 66476: Loss=5.5860, Acc=0.312, PPL=266.66
2025-09-22 00:00:08,275 - training.trainer - INFO - Epoch 19, Step 66576: Loss=6.1947, Acc=0.250, PPL=490.12
2025-09-22 00:00:16,207 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.4604, Acc=0.268, PPL=235.18
2025-09-22 00:00:24,228 - training.trainer - INFO - Epoch 19, Step 66776: Loss=5.8642, Acc=0.239, PPL=352.19
2025-09-22 00:00:32,415 - training.trainer - INFO - Epoch 19, Step 66876: Loss=5.9194, Acc=0.225, PPL=372.18
2025-09-22 00:00:40,527 - training.trainer - INFO - Epoch 19, Step 66976: Loss=6.0803, Acc=0.240, PPL=437.14
2025-09-22 00:00:48,459 - training.trainer - INFO - Epoch 19, Step 67076: Loss=6.3577, Acc=0.130, PPL=576.92
2025-09-22 00:00:56,454 - training.trainer - INFO - Epoch 19, Step 67176: Loss=5.7678, Acc=0.265, PPL=319.84
2025-09-22 00:01:04,471 - training.trainer - INFO - Epoch 19, Step 67276: Loss=6.4763, Acc=0.185, PPL=649.57
2025-09-22 00:01:12,336 - training.trainer - INFO - Epoch 19, Step 67376: Loss=5.4919, Acc=0.364, PPL=242.71
2025-09-22 00:01:20,466 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.9542, Acc=0.143, PPL=385.36
2025-09-22 00:01:28,405 - training.trainer - INFO - Epoch 19, Step 67576: Loss=5.4021, Acc=0.300, PPL=221.87
2025-09-22 00:01:46,311 - training.trainer - INFO - Epoch 20/100 completed in 280.46s - Train Loss: 5.8657, Train Acc: 0.224, Val Loss: 5.8378, Val Acc: 0.226
2025-09-22 00:01:46,703 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-22 00:01:47,501 - training.trainer - INFO - New best model saved with validation loss: 5.8378
2025-09-22 00:01:47,501 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-22 00:01:55,679 - training.trainer - INFO - Epoch 20, Step 67759: Loss=5.8093, Acc=0.222, PPL=333.39
2025-09-22 00:02:03,519 - training.trainer - INFO - Epoch 20, Step 67859: Loss=6.6914, Acc=0.125, PPL=805.42
2025-09-22 00:02:11,444 - training.trainer - INFO - Epoch 20, Step 67959: Loss=5.7285, Acc=0.333, PPL=307.51
2025-09-22 00:02:19,376 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.8342, Acc=0.200, PPL=341.79
2025-09-22 00:02:27,402 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.5690, Acc=0.310, PPL=262.16
2025-09-22 00:02:35,314 - training.trainer - INFO - Epoch 20, Step 68259: Loss=6.1490, Acc=0.227, PPL=468.23
2025-09-22 00:02:43,227 - training.trainer - INFO - Epoch 20, Step 68359: Loss=6.7599, Acc=0.135, PPL=862.53
2025-09-22 00:02:51,078 - training.trainer - INFO - Epoch 20, Step 68459: Loss=5.9154, Acc=0.170, PPL=370.70
2025-09-22 00:02:58,975 - training.trainer - INFO - Epoch 20, Step 68559: Loss=5.7477, Acc=0.226, PPL=313.46
2025-09-22 00:03:06,945 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.6386, Acc=0.292, PPL=281.06
2025-09-22 00:03:14,870 - training.trainer - INFO - Epoch 20, Step 68759: Loss=6.0487, Acc=0.188, PPL=423.56
2025-09-22 00:03:22,729 - training.trainer - INFO - Epoch 20, Step 68859: Loss=5.4217, Acc=0.312, PPL=226.27
2025-09-22 00:03:30,584 - training.trainer - INFO - Epoch 20, Step 68959: Loss=6.2487, Acc=0.217, PPL=517.34
2025-09-22 00:03:38,668 - training.trainer - INFO - Epoch 20, Step 69059: Loss=6.5632, Acc=0.106, PPL=708.52
2025-09-22 00:03:46,562 - training.trainer - INFO - Epoch 20, Step 69159: Loss=4.9641, Acc=0.467, PPL=143.18
2025-09-22 00:03:54,416 - training.trainer - INFO - Epoch 20, Step 69259: Loss=6.0655, Acc=0.203, PPL=430.72
2025-09-22 00:04:02,270 - training.trainer - INFO - Epoch 20, Step 69359: Loss=3.7836, Acc=0.385, PPL=43.97
2025-09-22 00:04:10,104 - training.trainer - INFO - Epoch 20, Step 69459: Loss=5.4891, Acc=0.275, PPL=242.04
2025-09-22 00:04:18,001 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.2512, Acc=0.320, PPL=190.80
2025-09-22 00:04:25,850 - training.trainer - INFO - Epoch 20, Step 69659: Loss=5.2092, Acc=0.267, PPL=182.95
2025-09-22 00:04:33,591 - training.trainer - INFO - Epoch 20, Step 69759: Loss=5.4871, Acc=0.278, PPL=241.56
2025-09-22 00:04:41,369 - training.trainer - INFO - Epoch 20, Step 69859: Loss=6.6008, Acc=0.216, PPL=735.69
2025-09-22 00:04:49,113 - training.trainer - INFO - Epoch 20, Step 69959: Loss=4.8843, Acc=0.320, PPL=132.19
2025-09-22 00:04:56,890 - training.trainer - INFO - Epoch 20, Step 70059: Loss=6.2892, Acc=0.250, PPL=538.70
2025-09-22 00:05:04,648 - training.trainer - INFO - Epoch 20, Step 70159: Loss=5.2427, Acc=0.304, PPL=189.17
2025-09-22 00:05:12,425 - training.trainer - INFO - Epoch 20, Step 70259: Loss=6.1728, Acc=0.158, PPL=479.51
2025-09-22 00:05:20,199 - training.trainer - INFO - Epoch 20, Step 70359: Loss=6.2909, Acc=0.157, PPL=539.67
2025-09-22 00:05:28,047 - training.trainer - INFO - Epoch 20, Step 70459: Loss=6.0299, Acc=0.176, PPL=415.66
2025-09-22 00:05:35,851 - training.trainer - INFO - Epoch 20, Step 70559: Loss=5.8364, Acc=0.258, PPL=342.55
2025-09-22 00:05:43,873 - training.trainer - INFO - Epoch 20, Step 70659: Loss=5.9814, Acc=0.250, PPL=396.01
2025-09-22 00:05:51,727 - training.trainer - INFO - Epoch 20, Step 70759: Loss=6.3004, Acc=0.206, PPL=544.81
2025-09-22 00:05:59,589 - training.trainer - INFO - Epoch 20, Step 70859: Loss=5.7305, Acc=0.216, PPL=308.12
2025-09-22 00:06:07,395 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.8058, Acc=0.231, PPL=332.23
2025-09-22 00:06:25,103 - training.trainer - INFO - Epoch 21/100 completed in 277.60s - Train Loss: 5.8512, Train Acc: 0.227, Val Loss: 5.8146, Val Acc: 0.230
2025-09-22 00:06:25,840 - training.trainer - INFO - New best model saved with validation loss: 5.8146
2025-09-22 00:06:25,840 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-09-22 00:06:33,968 - training.trainer - INFO - Epoch 21, Step 71142: Loss=6.1086, Acc=0.212, PPL=449.73
2025-09-22 00:06:41,787 - training.trainer - INFO - Epoch 21, Step 71242: Loss=6.0305, Acc=0.188, PPL=415.93
2025-09-22 00:06:49,692 - training.trainer - INFO - Epoch 21, Step 71342: Loss=5.7594, Acc=0.179, PPL=317.15
2025-09-22 00:06:57,478 - training.trainer - INFO - Epoch 21, Step 71442: Loss=6.2253, Acc=0.185, PPL=505.36
2025-09-22 00:07:05,296 - training.trainer - INFO - Epoch 21, Step 71542: Loss=6.5114, Acc=0.172, PPL=672.75
2025-09-22 00:07:13,099 - training.trainer - INFO - Epoch 21, Step 71642: Loss=4.7581, Acc=0.409, PPL=116.52
2025-09-22 00:07:20,889 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.7848, Acc=0.200, PPL=325.33
2025-09-22 00:07:28,709 - training.trainer - INFO - Epoch 21, Step 71842: Loss=5.9966, Acc=0.167, PPL=402.07
2025-09-22 00:07:36,545 - training.trainer - INFO - Epoch 21, Step 71942: Loss=4.5641, Acc=0.440, PPL=95.98
2025-09-22 00:07:44,433 - training.trainer - INFO - Epoch 21, Step 72042: Loss=6.4220, Acc=0.111, PPL=615.24
2025-09-22 00:07:52,199 - training.trainer - INFO - Epoch 21, Step 72142: Loss=6.0617, Acc=0.237, PPL=429.12
2025-09-22 00:07:59,969 - training.trainer - INFO - Epoch 21, Step 72242: Loss=6.0871, Acc=0.200, PPL=440.14
2025-09-22 00:08:07,769 - training.trainer - INFO - Epoch 21, Step 72342: Loss=6.2589, Acc=0.200, PPL=522.62
2025-09-22 00:08:15,558 - training.trainer - INFO - Epoch 21, Step 72442: Loss=6.4912, Acc=0.177, PPL=659.33
2025-09-22 00:08:23,362 - training.trainer - INFO - Epoch 21, Step 72542: Loss=5.4481, Acc=0.421, PPL=232.31
2025-09-22 00:08:31,182 - training.trainer - INFO - Epoch 21, Step 72642: Loss=6.1114, Acc=0.250, PPL=450.96
2025-09-22 00:08:38,997 - training.trainer - INFO - Epoch 21, Step 72742: Loss=5.7020, Acc=0.217, PPL=299.47
2025-09-22 00:08:46,830 - training.trainer - INFO - Epoch 21, Step 72842: Loss=6.2908, Acc=0.185, PPL=539.56
2025-09-22 00:08:54,714 - training.trainer - INFO - Epoch 21, Step 72942: Loss=6.0813, Acc=0.160, PPL=437.59
2025-09-22 00:09:02,592 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.2109, Acc=0.500, PPL=183.26
2025-09-22 00:09:10,405 - training.trainer - INFO - Epoch 21, Step 73142: Loss=4.4344, Acc=0.593, PPL=84.30
2025-09-22 00:09:18,198 - training.trainer - INFO - Epoch 21, Step 73242: Loss=6.1886, Acc=0.205, PPL=487.15
2025-09-22 00:09:26,138 - training.trainer - INFO - Epoch 21, Step 73342: Loss=6.6219, Acc=0.200, PPL=751.40
2025-09-22 00:09:33,980 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.6129, Acc=0.141, PPL=273.94
2025-09-22 00:09:41,886 - training.trainer - INFO - Epoch 21, Step 73542: Loss=6.2838, Acc=0.256, PPL=535.84
2025-09-22 00:09:49,782 - training.trainer - INFO - Epoch 21, Step 73642: Loss=6.2919, Acc=0.279, PPL=540.19
2025-09-22 00:09:57,754 - training.trainer - INFO - Epoch 21, Step 73742: Loss=5.6645, Acc=0.225, PPL=288.45
2025-09-22 00:10:05,638 - training.trainer - INFO - Epoch 21, Step 73842: Loss=6.0777, Acc=0.196, PPL=436.03
2025-09-22 00:10:13,554 - training.trainer - INFO - Epoch 21, Step 73942: Loss=6.3740, Acc=0.206, PPL=586.39
2025-09-22 00:10:21,451 - training.trainer - INFO - Epoch 21, Step 74042: Loss=6.3416, Acc=0.148, PPL=567.70
2025-09-22 00:10:29,385 - training.trainer - INFO - Epoch 21, Step 74142: Loss=6.4524, Acc=0.147, PPL=634.21
2025-09-22 00:10:37,296 - training.trainer - INFO - Epoch 21, Step 74242: Loss=5.5898, Acc=0.245, PPL=267.69
2025-09-22 00:10:45,225 - training.trainer - INFO - Epoch 21, Step 74342: Loss=6.1108, Acc=0.216, PPL=450.70
2025-09-22 00:11:01,899 - training.trainer - INFO - Epoch 22/100 completed in 276.06s - Train Loss: 5.8317, Train Acc: 0.228, Val Loss: 5.8059, Val Acc: 0.231
2025-09-22 00:11:02,543 - training.trainer - INFO - New best model saved with validation loss: 5.8059
2025-09-22 00:11:02,543 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-09-22 00:11:10,786 - training.trainer - INFO - Epoch 22, Step 74525: Loss=6.1550, Acc=0.189, PPL=471.07
2025-09-22 00:11:18,744 - training.trainer - INFO - Epoch 22, Step 74625: Loss=5.9663, Acc=0.184, PPL=390.04
2025-09-22 00:11:26,683 - training.trainer - INFO - Epoch 22, Step 74725: Loss=5.3146, Acc=0.353, PPL=203.28
2025-09-22 00:11:34,691 - training.trainer - INFO - Epoch 22, Step 74825: Loss=6.0919, Acc=0.122, PPL=442.24
2025-09-22 00:11:42,651 - training.trainer - INFO - Epoch 22, Step 74925: Loss=6.0224, Acc=0.278, PPL=412.56
2025-09-22 00:11:50,636 - training.trainer - INFO - Epoch 22, Step 75025: Loss=5.4487, Acc=0.263, PPL=232.45
2025-09-22 00:11:58,593 - training.trainer - INFO - Epoch 22, Step 75125: Loss=6.6576, Acc=0.163, PPL=778.67
2025-09-22 00:12:06,583 - training.trainer - INFO - Epoch 22, Step 75225: Loss=5.5227, Acc=0.242, PPL=250.31
2025-09-22 00:12:14,512 - training.trainer - INFO - Epoch 22, Step 75325: Loss=6.4194, Acc=0.167, PPL=613.65
2025-09-22 00:12:22,403 - training.trainer - INFO - Epoch 22, Step 75425: Loss=5.4581, Acc=0.182, PPL=234.65
2025-09-22 00:12:30,256 - training.trainer - INFO - Epoch 22, Step 75525: Loss=6.1606, Acc=0.250, PPL=473.73
2025-09-22 00:12:38,205 - training.trainer - INFO - Epoch 22, Step 75625: Loss=6.9155, Acc=0.175, PPL=1007.78
2025-09-22 00:12:46,175 - training.trainer - INFO - Epoch 22, Step 75725: Loss=5.2448, Acc=0.300, PPL=189.57
2025-09-22 00:12:54,170 - training.trainer - INFO - Epoch 22, Step 75825: Loss=5.4358, Acc=0.269, PPL=229.49
2025-09-22 00:13:02,043 - training.trainer - INFO - Epoch 22, Step 75925: Loss=5.6311, Acc=0.261, PPL=278.97
2025-09-22 00:13:09,976 - training.trainer - INFO - Epoch 22, Step 76025: Loss=6.1736, Acc=0.160, PPL=479.92
2025-09-22 00:13:17,931 - training.trainer - INFO - Epoch 22, Step 76125: Loss=5.3950, Acc=0.167, PPL=220.29
2025-09-22 00:13:25,911 - training.trainer - INFO - Epoch 22, Step 76225: Loss=5.1882, Acc=0.257, PPL=179.15
2025-09-22 00:13:33,797 - training.trainer - INFO - Epoch 22, Step 76325: Loss=5.1800, Acc=0.368, PPL=177.67
2025-09-22 00:13:41,677 - training.trainer - INFO - Epoch 22, Step 76425: Loss=6.2747, Acc=0.190, PPL=530.99
2025-09-22 00:13:49,622 - training.trainer - INFO - Epoch 22, Step 76525: Loss=6.0760, Acc=0.203, PPL=435.28
2025-09-22 00:13:57,587 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.7384, Acc=0.206, PPL=310.56
2025-09-22 00:14:05,593 - training.trainer - INFO - Epoch 22, Step 76725: Loss=6.7456, Acc=0.169, PPL=850.30
2025-09-22 00:14:13,499 - training.trainer - INFO - Epoch 22, Step 76825: Loss=6.6673, Acc=0.194, PPL=786.28
2025-09-22 00:14:21,472 - training.trainer - INFO - Epoch 22, Step 76925: Loss=5.2647, Acc=0.300, PPL=193.40
2025-09-22 00:14:29,404 - training.trainer - INFO - Epoch 22, Step 77025: Loss=6.0538, Acc=0.273, PPL=425.74
2025-09-22 00:14:37,273 - training.trainer - INFO - Epoch 22, Step 77125: Loss=5.8423, Acc=0.231, PPL=344.58
2025-09-22 00:14:45,161 - training.trainer - INFO - Epoch 22, Step 77225: Loss=6.0062, Acc=0.159, PPL=405.92
2025-09-22 00:14:53,050 - training.trainer - INFO - Epoch 22, Step 77325: Loss=5.7523, Acc=0.217, PPL=314.90
2025-09-22 00:15:00,914 - training.trainer - INFO - Epoch 22, Step 77425: Loss=5.6938, Acc=0.167, PPL=297.01
2025-09-22 00:15:08,779 - training.trainer - INFO - Epoch 22, Step 77525: Loss=5.6512, Acc=0.235, PPL=284.63
2025-09-22 00:15:16,699 - training.trainer - INFO - Epoch 22, Step 77625: Loss=5.4769, Acc=0.182, PPL=239.11
2025-09-22 00:15:24,589 - training.trainer - INFO - Epoch 22, Step 77725: Loss=6.1828, Acc=0.190, PPL=484.35
2025-09-22 00:15:41,384 - training.trainer - INFO - Epoch 23/100 completed in 278.84s - Train Loss: 5.8159, Train Acc: 0.232, Val Loss: 5.7900, Val Acc: 0.232
2025-09-22 00:15:42,004 - training.trainer - INFO - New best model saved with validation loss: 5.7900
2025-09-22 00:15:42,004 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-09-22 00:15:50,217 - training.trainer - INFO - Epoch 23, Step 77908: Loss=6.1119, Acc=0.222, PPL=451.20
2025-09-22 00:15:58,114 - training.trainer - INFO - Epoch 23, Step 78008: Loss=5.1653, Acc=0.227, PPL=175.09
2025-09-22 00:16:05,990 - training.trainer - INFO - Epoch 23, Step 78108: Loss=4.0011, Acc=0.375, PPL=54.66
2025-09-22 00:16:13,876 - training.trainer - INFO - Epoch 23, Step 78208: Loss=4.2971, Acc=0.385, PPL=73.48
2025-09-22 00:16:21,729 - training.trainer - INFO - Epoch 23, Step 78308: Loss=5.4604, Acc=0.241, PPL=235.18
2025-09-22 00:16:29,708 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.9667, Acc=0.132, PPL=390.21
2025-09-22 00:16:37,857 - training.trainer - INFO - Epoch 23, Step 78508: Loss=6.2586, Acc=0.208, PPL=522.46
2025-09-22 00:16:45,955 - training.trainer - INFO - Epoch 23, Step 78608: Loss=6.7938, Acc=0.125, PPL=892.31
2025-09-22 00:16:54,040 - training.trainer - INFO - Epoch 23, Step 78708: Loss=5.2904, Acc=0.238, PPL=198.43
2025-09-22 00:17:02,082 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.7407, Acc=0.279, PPL=311.28
2025-09-22 00:17:10,056 - training.trainer - INFO - Epoch 23, Step 78908: Loss=6.3497, Acc=0.200, PPL=572.29
2025-09-22 00:17:18,013 - training.trainer - INFO - Epoch 23, Step 79008: Loss=6.3064, Acc=0.333, PPL=548.08
2025-09-22 00:17:26,001 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.1167, Acc=0.281, PPL=166.79
2025-09-22 00:17:33,967 - training.trainer - INFO - Epoch 23, Step 79208: Loss=6.0530, Acc=0.151, PPL=425.41
2025-09-22 00:17:42,041 - training.trainer - INFO - Epoch 23, Step 79308: Loss=6.4337, Acc=0.140, PPL=622.47
2025-09-22 00:17:50,083 - training.trainer - INFO - Epoch 23, Step 79408: Loss=5.9558, Acc=0.217, PPL=386.00
2025-09-22 00:17:58,094 - training.trainer - INFO - Epoch 23, Step 79508: Loss=5.9048, Acc=0.195, PPL=366.79
2025-09-22 00:18:06,085 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.1909, Acc=0.306, PPL=179.63
2025-09-22 00:18:14,087 - training.trainer - INFO - Epoch 23, Step 79708: Loss=6.0143, Acc=0.245, PPL=409.25
2025-09-22 00:18:22,294 - training.trainer - INFO - Epoch 23, Step 79808: Loss=5.3830, Acc=0.259, PPL=217.66
2025-09-22 00:18:30,396 - training.trainer - INFO - Epoch 23, Step 79908: Loss=4.5533, Acc=0.306, PPL=94.95
2025-09-22 00:18:38,522 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.0738, Acc=0.350, PPL=159.78
2025-09-22 00:18:46,675 - training.trainer - INFO - Epoch 23, Step 80108: Loss=5.4853, Acc=0.150, PPL=241.11
2025-09-22 00:18:54,707 - training.trainer - INFO - Epoch 23, Step 80208: Loss=5.2968, Acc=0.409, PPL=199.70
2025-09-22 00:19:02,608 - training.trainer - INFO - Epoch 23, Step 80308: Loss=6.0258, Acc=0.191, PPL=413.96
2025-09-22 00:19:10,563 - training.trainer - INFO - Epoch 23, Step 80408: Loss=6.2610, Acc=0.121, PPL=523.74
2025-09-22 00:19:18,519 - training.trainer - INFO - Epoch 23, Step 80508: Loss=5.4393, Acc=0.300, PPL=230.28
2025-09-22 00:19:26,504 - training.trainer - INFO - Epoch 23, Step 80608: Loss=4.9689, Acc=0.174, PPL=143.87
2025-09-22 00:19:34,477 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.5576, Acc=0.197, PPL=259.21
2025-09-22 00:19:42,638 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.7136, Acc=0.265, PPL=302.97
2025-09-22 00:19:50,790 - training.trainer - INFO - Epoch 23, Step 80908: Loss=5.2948, Acc=0.273, PPL=199.30
2025-09-22 00:19:58,725 - training.trainer - INFO - Epoch 23, Step 81008: Loss=4.6619, Acc=0.409, PPL=105.83
2025-09-22 00:20:06,640 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.8126, Acc=0.143, PPL=334.48
2025-09-22 00:20:24,112 - training.trainer - INFO - Epoch 24/100 completed in 282.11s - Train Loss: 5.8021, Train Acc: 0.233, Val Loss: 5.7811, Val Acc: 0.231
2025-09-22 00:20:24,756 - training.trainer - INFO - New best model saved with validation loss: 5.7811
2025-09-22 00:20:24,757 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-09-22 00:20:32,943 - training.trainer - INFO - Epoch 24, Step 81291: Loss=6.2249, Acc=0.122, PPL=505.17
2025-09-22 00:20:40,892 - training.trainer - INFO - Epoch 24, Step 81391: Loss=3.9312, Acc=0.522, PPL=50.97
2025-09-22 00:20:48,788 - training.trainer - INFO - Epoch 24, Step 81491: Loss=6.0993, Acc=0.143, PPL=445.56
2025-09-22 00:20:56,621 - training.trainer - INFO - Epoch 24, Step 81591: Loss=6.0988, Acc=0.148, PPL=445.34
2025-09-22 00:21:04,419 - training.trainer - INFO - Epoch 24, Step 81691: Loss=5.6163, Acc=0.161, PPL=274.86
2025-09-22 00:21:12,261 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.5371, Acc=0.353, PPL=253.95
2025-09-22 00:21:20,099 - training.trainer - INFO - Epoch 24, Step 81891: Loss=5.5181, Acc=0.289, PPL=249.17
2025-09-22 00:21:27,971 - training.trainer - INFO - Epoch 24, Step 81991: Loss=5.3576, Acc=0.290, PPL=212.21
2025-09-22 00:21:35,807 - training.trainer - INFO - Epoch 24, Step 82091: Loss=5.2828, Acc=0.227, PPL=196.92
2025-09-22 00:21:43,669 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.1797, Acc=0.269, PPL=177.64
2025-09-22 00:21:51,530 - training.trainer - INFO - Epoch 24, Step 82291: Loss=6.0147, Acc=0.243, PPL=409.39
2025-09-22 00:21:59,357 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.5639, Acc=0.263, PPL=260.84
2025-09-22 00:22:07,157 - training.trainer - INFO - Epoch 24, Step 82491: Loss=3.9556, Acc=0.400, PPL=52.23
2025-09-22 00:22:15,092 - training.trainer - INFO - Epoch 24, Step 82591: Loss=5.1458, Acc=0.387, PPL=171.71
2025-09-22 00:22:22,939 - training.trainer - INFO - Epoch 24, Step 82691: Loss=5.9480, Acc=0.167, PPL=382.97
2025-09-22 00:22:30,839 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.4873, Acc=0.286, PPL=241.60
2025-09-22 00:22:38,795 - training.trainer - INFO - Epoch 24, Step 82891: Loss=6.5545, Acc=0.200, PPL=702.38
2025-09-22 00:22:46,672 - training.trainer - INFO - Epoch 24, Step 82991: Loss=4.3665, Acc=0.385, PPL=78.77
2025-09-22 00:22:54,556 - training.trainer - INFO - Epoch 24, Step 83091: Loss=5.4441, Acc=0.167, PPL=231.38
2025-09-22 00:23:02,463 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.8044, Acc=0.128, PPL=331.74
2025-09-22 00:23:10,341 - training.trainer - INFO - Epoch 24, Step 83291: Loss=5.4881, Acc=0.176, PPL=241.80
2025-09-22 00:23:18,277 - training.trainer - INFO - Epoch 24, Step 83391: Loss=5.9835, Acc=0.178, PPL=396.83
2025-09-22 00:23:26,231 - training.trainer - INFO - Epoch 24, Step 83491: Loss=6.4511, Acc=0.229, PPL=633.39
2025-09-22 00:23:34,103 - training.trainer - INFO - Epoch 24, Step 83591: Loss=6.4617, Acc=0.135, PPL=640.13
2025-09-22 00:23:42,009 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.4929, Acc=0.176, PPL=242.95
2025-09-22 00:23:49,934 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.9308, Acc=0.189, PPL=376.44
2025-09-22 00:23:57,728 - training.trainer - INFO - Epoch 24, Step 83891: Loss=4.8877, Acc=0.300, PPL=132.64
2025-09-22 00:24:05,676 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.0577, Acc=0.333, PPL=157.23
2025-09-22 00:24:13,541 - training.trainer - INFO - Epoch 24, Step 84091: Loss=6.4791, Acc=0.173, PPL=651.41
2025-09-22 00:24:21,464 - training.trainer - INFO - Epoch 24, Step 84191: Loss=5.9072, Acc=0.188, PPL=367.66
2025-09-22 00:24:29,349 - training.trainer - INFO - Epoch 24, Step 84291: Loss=6.1159, Acc=0.167, PPL=452.99
2025-09-22 00:24:37,302 - training.trainer - INFO - Epoch 24, Step 84391: Loss=5.8940, Acc=0.205, PPL=362.84
2025-09-22 00:24:45,228 - training.trainer - INFO - Epoch 24, Step 84491: Loss=5.7545, Acc=0.212, PPL=315.62
2025-09-22 00:25:02,007 - training.trainer - INFO - Epoch 25/100 completed in 277.25s - Train Loss: 5.7864, Train Acc: 0.235, Val Loss: 5.7777, Val Acc: 0.233
2025-09-22 00:25:02,343 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-22 00:25:02,912 - training.trainer - INFO - New best model saved with validation loss: 5.7777
2025-09-22 00:25:02,912 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-22 00:25:11,219 - training.trainer - INFO - Epoch 25, Step 84674: Loss=6.0761, Acc=0.200, PPL=435.32
2025-09-22 00:25:19,159 - training.trainer - INFO - Epoch 25, Step 84774: Loss=4.9793, Acc=0.480, PPL=145.37
2025-09-22 00:25:27,108 - training.trainer - INFO - Epoch 25, Step 84874: Loss=6.2791, Acc=0.167, PPL=533.31
2025-09-22 00:25:35,032 - training.trainer - INFO - Epoch 25, Step 84974: Loss=6.5987, Acc=0.119, PPL=734.12
2025-09-22 00:25:42,892 - training.trainer - INFO - Epoch 25, Step 85074: Loss=5.4858, Acc=0.294, PPL=241.25
2025-09-22 00:25:50,809 - training.trainer - INFO - Epoch 25, Step 85174: Loss=6.3066, Acc=0.176, PPL=548.18
2025-09-22 00:25:58,706 - training.trainer - INFO - Epoch 25, Step 85274: Loss=6.0002, Acc=0.222, PPL=403.49
2025-09-22 00:26:06,576 - training.trainer - INFO - Epoch 25, Step 85374: Loss=5.4722, Acc=0.270, PPL=237.99
2025-09-22 00:26:14,451 - training.trainer - INFO - Epoch 25, Step 85474: Loss=5.5444, Acc=0.232, PPL=255.80
2025-09-22 00:26:22,286 - training.trainer - INFO - Epoch 25, Step 85574: Loss=5.3986, Acc=0.200, PPL=221.11
2025-09-22 00:26:30,087 - training.trainer - INFO - Epoch 25, Step 85674: Loss=4.5145, Acc=0.368, PPL=91.33
2025-09-22 00:26:37,984 - training.trainer - INFO - Epoch 25, Step 85774: Loss=5.5342, Acc=0.474, PPL=253.22
2025-09-22 00:26:45,862 - training.trainer - INFO - Epoch 25, Step 85874: Loss=6.1504, Acc=0.234, PPL=468.89
2025-09-22 00:26:53,776 - training.trainer - INFO - Epoch 25, Step 85974: Loss=5.3853, Acc=0.308, PPL=218.16
2025-09-22 00:27:01,625 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.7067, Acc=0.250, PPL=300.88
2025-09-22 00:27:09,464 - training.trainer - INFO - Epoch 25, Step 86174: Loss=5.7030, Acc=0.241, PPL=299.77
2025-09-22 00:27:17,346 - training.trainer - INFO - Epoch 25, Step 86274: Loss=6.0705, Acc=0.176, PPL=432.88
2025-09-22 00:27:25,290 - training.trainer - INFO - Epoch 25, Step 86374: Loss=6.1272, Acc=0.194, PPL=458.16
2025-09-22 00:27:33,083 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.4441, Acc=0.267, PPL=231.38
2025-09-22 00:27:40,966 - training.trainer - INFO - Epoch 25, Step 86574: Loss=6.3118, Acc=0.238, PPL=551.03
2025-09-22 00:27:48,923 - training.trainer - INFO - Epoch 25, Step 86674: Loss=6.1968, Acc=0.217, PPL=491.16
2025-09-22 00:27:56,833 - training.trainer - INFO - Epoch 25, Step 86774: Loss=6.6071, Acc=0.243, PPL=740.37
2025-09-22 00:28:04,715 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.1600, Acc=0.173, PPL=473.44
2025-09-22 00:28:12,599 - training.trainer - INFO - Epoch 25, Step 86974: Loss=6.2783, Acc=0.167, PPL=532.87
2025-09-22 00:28:20,570 - training.trainer - INFO - Epoch 25, Step 87074: Loss=5.0670, Acc=0.316, PPL=158.70
2025-09-22 00:28:28,371 - training.trainer - INFO - Epoch 25, Step 87174: Loss=6.0795, Acc=0.225, PPL=436.81
2025-09-22 00:28:36,268 - training.trainer - INFO - Epoch 25, Step 87274: Loss=6.9312, Acc=0.136, PPL=1023.77
2025-09-22 00:28:44,104 - training.trainer - INFO - Epoch 25, Step 87374: Loss=5.0784, Acc=0.250, PPL=160.52
2025-09-22 00:28:51,975 - training.trainer - INFO - Epoch 25, Step 87474: Loss=5.8551, Acc=0.211, PPL=349.01
2025-09-22 00:28:59,820 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.4473, Acc=0.179, PPL=232.13
2025-09-22 00:29:07,693 - training.trainer - INFO - Epoch 25, Step 87674: Loss=5.2567, Acc=0.333, PPL=191.85
2025-09-22 00:29:15,595 - training.trainer - INFO - Epoch 25, Step 87774: Loss=6.5424, Acc=0.135, PPL=693.92
2025-09-22 00:29:23,398 - training.trainer - INFO - Epoch 25, Step 87874: Loss=5.5285, Acc=0.263, PPL=251.77
2025-09-22 00:29:40,219 - training.trainer - INFO - Epoch 26/100 completed in 277.31s - Train Loss: 5.7735, Train Acc: 0.238, Val Loss: 5.7708, Val Acc: 0.238
2025-09-22 00:29:40,863 - training.trainer - INFO - New best model saved with validation loss: 5.7708
2025-09-22 00:29:40,864 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_26.pt
2025-09-22 00:29:49,164 - training.trainer - INFO - Epoch 26, Step 88057: Loss=5.7291, Acc=0.282, PPL=307.69
2025-09-22 00:29:57,147 - training.trainer - INFO - Epoch 26, Step 88157: Loss=5.6424, Acc=0.350, PPL=282.15
2025-09-22 00:30:05,173 - training.trainer - INFO - Epoch 26, Step 88257: Loss=5.6440, Acc=0.182, PPL=282.60
2025-09-22 00:30:13,106 - training.trainer - INFO - Epoch 26, Step 88357: Loss=6.4008, Acc=0.209, PPL=602.32
2025-09-22 00:30:21,013 - training.trainer - INFO - Epoch 26, Step 88457: Loss=6.0309, Acc=0.179, PPL=416.09
2025-09-22 00:30:28,945 - training.trainer - INFO - Epoch 26, Step 88557: Loss=5.8642, Acc=0.323, PPL=352.21
2025-09-22 00:30:36,910 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.9382, Acc=0.204, PPL=379.23
2025-09-22 00:30:44,891 - training.trainer - INFO - Epoch 26, Step 88757: Loss=5.7580, Acc=0.257, PPL=316.70
2025-09-22 00:30:52,820 - training.trainer - INFO - Epoch 26, Step 88857: Loss=5.1441, Acc=0.269, PPL=171.43
2025-09-22 00:31:00,795 - training.trainer - INFO - Epoch 26, Step 88957: Loss=6.0259, Acc=0.200, PPL=414.00
2025-09-22 00:31:08,798 - training.trainer - INFO - Epoch 26, Step 89057: Loss=5.4912, Acc=0.235, PPL=242.54
2025-09-22 00:31:16,715 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.0612, Acc=0.300, PPL=157.78
2025-09-22 00:31:24,641 - training.trainer - INFO - Epoch 26, Step 89257: Loss=3.1638, Acc=0.520, PPL=23.66
2025-09-22 00:31:32,582 - training.trainer - INFO - Epoch 26, Step 89357: Loss=6.0904, Acc=0.226, PPL=441.62
2025-09-22 00:31:40,522 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.1863, Acc=0.222, PPL=178.81
2025-09-22 00:31:48,474 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.8198, Acc=0.315, PPL=336.91
2025-09-22 00:31:56,572 - training.trainer - INFO - Epoch 26, Step 89657: Loss=6.0254, Acc=0.188, PPL=413.79
2025-09-22 00:32:04,640 - training.trainer - INFO - Epoch 26, Step 89757: Loss=6.0328, Acc=0.186, PPL=416.87
2025-09-22 00:32:12,721 - training.trainer - INFO - Epoch 26, Step 89857: Loss=6.3230, Acc=0.173, PPL=557.22
2025-09-22 00:32:20,785 - training.trainer - INFO - Epoch 26, Step 89957: Loss=5.9002, Acc=0.196, PPL=365.10
2025-09-22 00:32:28,799 - training.trainer - INFO - Epoch 26, Step 90057: Loss=4.6735, Acc=0.258, PPL=107.07
2025-09-22 00:32:36,756 - training.trainer - INFO - Epoch 26, Step 90157: Loss=6.1770, Acc=0.206, PPL=481.53
2025-09-22 00:32:44,666 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.4848, Acc=0.294, PPL=240.99
2025-09-22 00:32:52,766 - training.trainer - INFO - Epoch 26, Step 90357: Loss=6.2228, Acc=0.191, PPL=504.09
2025-09-22 00:33:00,932 - training.trainer - INFO - Epoch 26, Step 90457: Loss=6.0537, Acc=0.194, PPL=425.68
2025-09-22 00:33:09,216 - training.trainer - INFO - Epoch 26, Step 90557: Loss=5.7854, Acc=0.256, PPL=325.50
2025-09-22 00:33:17,336 - training.trainer - INFO - Epoch 26, Step 90657: Loss=6.4039, Acc=0.161, PPL=604.18
2025-09-22 00:33:25,510 - training.trainer - INFO - Epoch 26, Step 90757: Loss=5.9131, Acc=0.256, PPL=369.84
2025-09-22 00:33:33,610 - training.trainer - INFO - Epoch 26, Step 90857: Loss=5.6225, Acc=0.222, PPL=276.57
2025-09-22 00:33:41,743 - training.trainer - INFO - Epoch 26, Step 90957: Loss=5.4039, Acc=0.250, PPL=222.26
2025-09-22 00:33:49,668 - training.trainer - INFO - Epoch 26, Step 91057: Loss=6.3516, Acc=0.200, PPL=573.41
2025-09-22 00:33:57,486 - training.trainer - INFO - Epoch 26, Step 91157: Loss=5.5473, Acc=0.417, PPL=256.54
2025-09-22 00:34:05,310 - training.trainer - INFO - Epoch 26, Step 91257: Loss=5.8608, Acc=0.158, PPL=351.00
2025-09-22 00:34:22,638 - training.trainer - INFO - Epoch 27/100 completed in 281.77s - Train Loss: 5.7628, Train Acc: 0.240, Val Loss: 5.7562, Val Acc: 0.238
2025-09-22 00:34:23,421 - training.trainer - INFO - New best model saved with validation loss: 5.7562
2025-09-22 00:34:23,422 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_27.pt
2025-09-22 00:34:31,780 - training.trainer - INFO - Epoch 27, Step 91440: Loss=5.7190, Acc=0.246, PPL=304.61
2025-09-22 00:34:39,705 - training.trainer - INFO - Epoch 27, Step 91540: Loss=5.1325, Acc=0.222, PPL=169.44
2025-09-22 00:34:47,586 - training.trainer - INFO - Epoch 27, Step 91640: Loss=6.1896, Acc=0.165, PPL=487.66
2025-09-22 00:34:55,523 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.5947, Acc=0.122, PPL=269.00
2025-09-22 00:35:03,450 - training.trainer - INFO - Epoch 27, Step 91840: Loss=6.6111, Acc=0.259, PPL=743.33
2025-09-22 00:35:11,335 - training.trainer - INFO - Epoch 27, Step 91940: Loss=5.8355, Acc=0.183, PPL=342.24
2025-09-22 00:35:19,207 - training.trainer - INFO - Epoch 27, Step 92040: Loss=6.7823, Acc=0.163, PPL=882.10
2025-09-22 00:35:27,062 - training.trainer - INFO - Epoch 27, Step 92140: Loss=4.0440, Acc=0.500, PPL=57.05
2025-09-22 00:35:35,021 - training.trainer - INFO - Epoch 27, Step 92240: Loss=5.7160, Acc=0.273, PPL=303.68
2025-09-22 00:35:42,968 - training.trainer - INFO - Epoch 27, Step 92340: Loss=5.7808, Acc=0.246, PPL=324.02
2025-09-22 00:35:50,898 - training.trainer - INFO - Epoch 27, Step 92440: Loss=5.6901, Acc=0.364, PPL=295.94
2025-09-22 00:35:58,912 - training.trainer - INFO - Epoch 27, Step 92540: Loss=6.2761, Acc=0.208, PPL=531.70
2025-09-22 00:36:07,062 - training.trainer - INFO - Epoch 27, Step 92640: Loss=6.0064, Acc=0.216, PPL=406.03
2025-09-22 00:36:15,249 - training.trainer - INFO - Epoch 27, Step 92740: Loss=6.1403, Acc=0.318, PPL=464.17
2025-09-22 00:36:23,317 - training.trainer - INFO - Epoch 27, Step 92840: Loss=6.5875, Acc=0.169, PPL=725.98
2025-09-22 00:36:31,371 - training.trainer - INFO - Epoch 27, Step 92940: Loss=5.8803, Acc=0.233, PPL=357.93
2025-09-22 00:36:39,388 - training.trainer - INFO - Epoch 27, Step 93040: Loss=6.0094, Acc=0.300, PPL=407.24
2025-09-22 00:36:47,535 - training.trainer - INFO - Epoch 27, Step 93140: Loss=6.0915, Acc=0.186, PPL=442.07
2025-09-22 00:36:55,451 - training.trainer - INFO - Epoch 27, Step 93240: Loss=4.8529, Acc=0.292, PPL=128.11
2025-09-22 00:37:03,303 - training.trainer - INFO - Epoch 27, Step 93340: Loss=4.7389, Acc=0.389, PPL=114.31
2025-09-22 00:37:11,198 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.8218, Acc=0.214, PPL=337.57
2025-09-22 00:37:19,104 - training.trainer - INFO - Epoch 27, Step 93540: Loss=4.5575, Acc=0.444, PPL=95.34
2025-09-22 00:37:26,933 - training.trainer - INFO - Epoch 27, Step 93640: Loss=6.2506, Acc=0.146, PPL=518.34
2025-09-22 00:37:34,733 - training.trainer - INFO - Epoch 27, Step 93740: Loss=5.6432, Acc=0.321, PPL=282.37
2025-09-22 00:37:42,653 - training.trainer - INFO - Epoch 27, Step 93840: Loss=5.5991, Acc=0.225, PPL=270.17
2025-09-22 00:37:50,422 - training.trainer - INFO - Epoch 27, Step 93940: Loss=5.7308, Acc=0.206, PPL=308.21
2025-09-22 00:37:58,271 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.9567, Acc=0.171, PPL=386.31
2025-09-22 00:38:06,112 - training.trainer - INFO - Epoch 27, Step 94140: Loss=5.9489, Acc=0.250, PPL=383.35
2025-09-22 00:38:13,982 - training.trainer - INFO - Epoch 27, Step 94240: Loss=6.4554, Acc=0.167, PPL=636.11
2025-09-22 00:38:21,862 - training.trainer - INFO - Epoch 27, Step 94340: Loss=6.4739, Acc=0.154, PPL=648.04
2025-09-22 00:38:29,770 - training.trainer - INFO - Epoch 27, Step 94440: Loss=6.1945, Acc=0.150, PPL=490.03
2025-09-22 00:38:37,634 - training.trainer - INFO - Epoch 27, Step 94540: Loss=6.2219, Acc=0.184, PPL=503.64
2025-09-22 00:38:45,512 - training.trainer - INFO - Epoch 27, Step 94640: Loss=6.0405, Acc=0.211, PPL=420.10
2025-09-22 00:39:02,310 - training.trainer - INFO - Epoch 28/100 completed in 278.89s - Train Loss: 5.7498, Train Acc: 0.241, Val Loss: 5.7661, Val Acc: 0.241
2025-09-22 00:39:10,473 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.4821, Acc=0.250, PPL=240.34
2025-09-22 00:39:18,408 - training.trainer - INFO - Epoch 28, Step 94923: Loss=6.5749, Acc=0.129, PPL=716.88
2025-09-22 00:39:26,469 - training.trainer - INFO - Epoch 28, Step 95023: Loss=5.4108, Acc=0.273, PPL=223.81
2025-09-22 00:39:34,431 - training.trainer - INFO - Epoch 28, Step 95123: Loss=6.1884, Acc=0.222, PPL=487.09
2025-09-22 00:39:42,344 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.8607, Acc=0.279, PPL=350.98
2025-09-22 00:39:50,266 - training.trainer - INFO - Epoch 28, Step 95323: Loss=6.0635, Acc=0.273, PPL=429.88
2025-09-22 00:39:58,252 - training.trainer - INFO - Epoch 28, Step 95423: Loss=6.4857, Acc=0.207, PPL=655.67
2025-09-22 00:40:06,284 - training.trainer - INFO - Epoch 28, Step 95523: Loss=6.0405, Acc=0.231, PPL=420.12
2025-09-22 00:40:14,480 - training.trainer - INFO - Epoch 28, Step 95623: Loss=6.1105, Acc=0.182, PPL=450.57
2025-09-22 00:40:22,492 - training.trainer - INFO - Epoch 28, Step 95723: Loss=6.3303, Acc=0.200, PPL=561.34
2025-09-22 00:40:30,628 - training.trainer - INFO - Epoch 28, Step 95823: Loss=6.1122, Acc=0.174, PPL=451.35
2025-09-22 00:40:38,786 - training.trainer - INFO - Epoch 28, Step 95923: Loss=6.1524, Acc=0.170, PPL=469.83
2025-09-22 00:40:47,024 - training.trainer - INFO - Epoch 28, Step 96023: Loss=6.1832, Acc=0.200, PPL=484.52
2025-09-22 00:40:55,117 - training.trainer - INFO - Epoch 28, Step 96123: Loss=4.5797, Acc=0.471, PPL=97.48
2025-09-22 00:41:03,233 - training.trainer - INFO - Epoch 28, Step 96223: Loss=5.3930, Acc=0.293, PPL=219.87
2025-09-22 00:41:11,270 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.6747, Acc=0.229, PPL=291.40
2025-09-22 00:41:19,233 - training.trainer - INFO - Epoch 28, Step 96423: Loss=5.5422, Acc=0.276, PPL=255.25
2025-09-22 00:41:27,097 - training.trainer - INFO - Epoch 28, Step 96523: Loss=6.0141, Acc=0.250, PPL=409.16
2025-09-22 00:41:35,024 - training.trainer - INFO - Epoch 28, Step 96623: Loss=5.1590, Acc=0.333, PPL=173.99
2025-09-22 00:41:43,102 - training.trainer - INFO - Epoch 28, Step 96723: Loss=6.0385, Acc=0.170, PPL=419.27
2025-09-22 00:41:51,006 - training.trainer - INFO - Epoch 28, Step 96823: Loss=5.6596, Acc=0.185, PPL=287.04
2025-09-22 00:41:59,096 - training.trainer - INFO - Epoch 28, Step 96923: Loss=6.2162, Acc=0.139, PPL=500.81
2025-09-22 00:42:07,228 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.0695, Acc=0.318, PPL=159.10
2025-09-22 00:42:15,161 - training.trainer - INFO - Epoch 28, Step 97123: Loss=4.8191, Acc=0.227, PPL=123.85
2025-09-22 00:42:23,132 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.0956, Acc=0.312, PPL=163.30
2025-09-22 00:42:31,108 - training.trainer - INFO - Epoch 28, Step 97323: Loss=5.8888, Acc=0.308, PPL=360.98
2025-09-22 00:42:39,198 - training.trainer - INFO - Epoch 28, Step 97423: Loss=6.4840, Acc=0.184, PPL=654.55
2025-09-22 00:42:47,078 - training.trainer - INFO - Epoch 28, Step 97523: Loss=6.2907, Acc=0.233, PPL=539.52
2025-09-22 00:42:54,894 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.5805, Acc=0.344, PPL=265.20
2025-09-22 00:43:02,724 - training.trainer - INFO - Epoch 28, Step 97723: Loss=5.8381, Acc=0.200, PPL=343.13
2025-09-22 00:43:10,506 - training.trainer - INFO - Epoch 28, Step 97823: Loss=6.2562, Acc=0.159, PPL=521.26
2025-09-22 00:43:18,366 - training.trainer - INFO - Epoch 28, Step 97923: Loss=5.6935, Acc=0.173, PPL=296.93
2025-09-22 00:43:26,315 - training.trainer - INFO - Epoch 28, Step 98023: Loss=5.8269, Acc=0.184, PPL=339.31
2025-09-22 00:43:42,820 - training.trainer - INFO - Epoch 29/100 completed in 280.51s - Train Loss: 5.7360, Train Acc: 0.242, Val Loss: 5.7391, Val Acc: 0.242
2025-09-22 00:43:43,549 - training.trainer - INFO - New best model saved with validation loss: 5.7391
2025-09-22 00:43:43,549 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_29.pt
2025-09-22 00:43:51,673 - training.trainer - INFO - Epoch 29, Step 98206: Loss=5.6431, Acc=0.203, PPL=282.34
2025-09-22 00:43:59,839 - training.trainer - INFO - Epoch 29, Step 98306: Loss=4.8663, Acc=0.350, PPL=129.84
2025-09-22 00:44:07,924 - training.trainer - INFO - Epoch 29, Step 98406: Loss=5.4886, Acc=0.235, PPL=241.92
2025-09-22 00:44:15,939 - training.trainer - INFO - Epoch 29, Step 98506: Loss=5.9099, Acc=0.190, PPL=368.68
2025-09-22 00:44:23,921 - training.trainer - INFO - Epoch 29, Step 98606: Loss=5.7855, Acc=0.238, PPL=325.53
2025-09-22 00:44:31,791 - training.trainer - INFO - Epoch 29, Step 98706: Loss=5.3328, Acc=0.225, PPL=207.02
2025-09-22 00:44:39,702 - training.trainer - INFO - Epoch 29, Step 98806: Loss=5.8597, Acc=0.258, PPL=350.61
2025-09-22 00:44:47,701 - training.trainer - INFO - Epoch 29, Step 98906: Loss=5.0954, Acc=0.385, PPL=163.27
2025-09-22 00:44:55,614 - training.trainer - INFO - Epoch 29, Step 99006: Loss=5.4644, Acc=0.268, PPL=236.13
2025-09-22 00:45:03,496 - training.trainer - INFO - Epoch 29, Step 99106: Loss=6.0728, Acc=0.167, PPL=433.91
2025-09-22 00:45:11,387 - training.trainer - INFO - Epoch 29, Step 99206: Loss=5.4570, Acc=0.267, PPL=234.40
2025-09-22 00:45:19,236 - training.trainer - INFO - Epoch 29, Step 99306: Loss=5.8549, Acc=0.215, PPL=348.93
2025-09-22 00:45:27,262 - training.trainer - INFO - Epoch 29, Step 99406: Loss=5.3879, Acc=0.184, PPL=218.74
2025-09-22 00:45:35,153 - training.trainer - INFO - Epoch 29, Step 99506: Loss=7.1826, Acc=0.143, PPL=1316.32
2025-09-22 00:45:43,095 - training.trainer - INFO - Epoch 29, Step 99606: Loss=6.0362, Acc=0.265, PPL=418.31
2025-09-22 00:45:50,975 - training.trainer - INFO - Epoch 29, Step 99706: Loss=5.5350, Acc=0.237, PPL=253.42
2025-09-22 00:45:58,864 - training.trainer - INFO - Epoch 29, Step 99806: Loss=5.6414, Acc=0.250, PPL=281.86
2025-09-22 00:46:06,775 - training.trainer - INFO - Epoch 29, Step 99906: Loss=6.0554, Acc=0.216, PPL=426.39
2025-09-22 00:46:14,669 - training.trainer - INFO - Epoch 29, Step 100006: Loss=5.5414, Acc=0.215, PPL=255.04
2025-09-22 00:46:22,485 - training.trainer - INFO - Epoch 29, Step 100106: Loss=5.9256, Acc=0.146, PPL=374.50
2025-09-22 00:46:30,493 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.7500, Acc=0.211, PPL=314.19
2025-09-22 00:46:38,567 - training.trainer - INFO - Epoch 29, Step 100306: Loss=6.5946, Acc=0.125, PPL=731.14
2025-09-22 00:46:46,534 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.8875, Acc=0.222, PPL=360.50
2025-09-22 00:46:54,511 - training.trainer - INFO - Epoch 29, Step 100506: Loss=6.2192, Acc=0.193, PPL=502.30
2025-09-22 00:47:02,552 - training.trainer - INFO - Epoch 29, Step 100606: Loss=5.8947, Acc=0.196, PPL=363.11
2025-09-22 00:47:10,552 - training.trainer - INFO - Epoch 29, Step 100706: Loss=5.3268, Acc=0.306, PPL=205.78
2025-09-22 00:47:18,572 - training.trainer - INFO - Epoch 29, Step 100806: Loss=5.4862, Acc=0.297, PPL=241.33
2025-09-22 00:47:26,640 - training.trainer - INFO - Epoch 29, Step 100906: Loss=6.0790, Acc=0.327, PPL=436.60
2025-09-22 00:47:34,666 - training.trainer - INFO - Epoch 29, Step 101006: Loss=6.5308, Acc=0.158, PPL=685.97
2025-09-22 00:47:42,796 - training.trainer - INFO - Epoch 29, Step 101106: Loss=5.9220, Acc=0.286, PPL=373.15
2025-09-22 00:47:50,769 - training.trainer - INFO - Epoch 29, Step 101206: Loss=6.2195, Acc=0.132, PPL=502.47
2025-09-22 00:47:58,640 - training.trainer - INFO - Epoch 29, Step 101306: Loss=6.4969, Acc=0.286, PPL=663.09
2025-09-22 00:48:06,734 - training.trainer - INFO - Epoch 29, Step 101406: Loss=5.2868, Acc=0.269, PPL=197.71
2025-09-22 00:48:24,142 - training.trainer - INFO - Epoch 30/100 completed in 280.59s - Train Loss: 5.7251, Train Acc: 0.245, Val Loss: 5.7423, Val Acc: 0.240
2025-09-22 00:48:24,492 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-22 00:48:33,026 - training.trainer - INFO - Epoch 30, Step 101589: Loss=4.2481, Acc=0.417, PPL=69.98
2025-09-22 00:48:41,241 - training.trainer - INFO - Epoch 30, Step 101689: Loss=6.3472, Acc=0.207, PPL=570.90
2025-09-22 00:48:49,367 - training.trainer - INFO - Epoch 30, Step 101789: Loss=5.9285, Acc=0.158, PPL=375.60
2025-09-22 00:48:57,510 - training.trainer - INFO - Epoch 30, Step 101889: Loss=5.2801, Acc=0.182, PPL=196.38
2025-09-22 00:49:05,593 - training.trainer - INFO - Epoch 30, Step 101989: Loss=6.0406, Acc=0.209, PPL=420.15
2025-09-22 00:49:13,663 - training.trainer - INFO - Epoch 30, Step 102089: Loss=4.8987, Acc=0.400, PPL=134.11
2025-09-22 00:49:21,553 - training.trainer - INFO - Epoch 30, Step 102189: Loss=3.3845, Acc=0.462, PPL=29.50
2025-09-22 00:49:29,447 - training.trainer - INFO - Epoch 30, Step 102289: Loss=5.5634, Acc=0.174, PPL=260.71
2025-09-22 00:49:37,524 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.8674, Acc=0.212, PPL=353.32
2025-09-22 00:49:45,701 - training.trainer - INFO - Epoch 30, Step 102489: Loss=5.8359, Acc=0.205, PPL=342.37
2025-09-22 00:49:53,845 - training.trainer - INFO - Epoch 30, Step 102589: Loss=4.4548, Acc=0.458, PPL=86.04
2025-09-22 00:50:02,032 - training.trainer - INFO - Epoch 30, Step 102689: Loss=5.5723, Acc=0.229, PPL=263.03
2025-09-22 00:50:10,097 - training.trainer - INFO - Epoch 30, Step 102789: Loss=5.6351, Acc=0.176, PPL=280.10
2025-09-22 00:50:18,152 - training.trainer - INFO - Epoch 30, Step 102889: Loss=6.1876, Acc=0.203, PPL=486.69
2025-09-22 00:50:26,137 - training.trainer - INFO - Epoch 30, Step 102989: Loss=5.0274, Acc=0.263, PPL=152.53
2025-09-22 00:50:34,102 - training.trainer - INFO - Epoch 30, Step 103089: Loss=6.1375, Acc=0.182, PPL=462.91
2025-09-22 00:50:42,210 - training.trainer - INFO - Epoch 30, Step 103189: Loss=4.8426, Acc=0.241, PPL=126.80
2025-09-22 00:50:50,316 - training.trainer - INFO - Epoch 30, Step 103289: Loss=6.2799, Acc=0.286, PPL=533.71
2025-09-22 00:50:58,446 - training.trainer - INFO - Epoch 30, Step 103389: Loss=5.6355, Acc=0.270, PPL=280.20
2025-09-22 00:51:06,626 - training.trainer - INFO - Epoch 30, Step 103489: Loss=6.2097, Acc=0.174, PPL=497.53
2025-09-22 00:51:14,667 - training.trainer - INFO - Epoch 30, Step 103589: Loss=3.8569, Acc=0.516, PPL=47.32
2025-09-22 00:51:22,621 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.6793, Acc=0.158, PPL=292.74
2025-09-22 00:51:30,585 - training.trainer - INFO - Epoch 30, Step 103789: Loss=6.0968, Acc=0.171, PPL=444.43
2025-09-22 00:51:38,450 - training.trainer - INFO - Epoch 30, Step 103889: Loss=5.6770, Acc=0.289, PPL=292.07
2025-09-22 00:51:46,330 - training.trainer - INFO - Epoch 30, Step 103989: Loss=5.4271, Acc=0.238, PPL=227.49
2025-09-22 00:51:54,194 - training.trainer - INFO - Epoch 30, Step 104089: Loss=5.3266, Acc=0.333, PPL=205.74
2025-09-22 00:52:02,125 - training.trainer - INFO - Epoch 30, Step 104189: Loss=5.3716, Acc=0.236, PPL=215.21
2025-09-22 00:52:09,907 - training.trainer - INFO - Epoch 30, Step 104289: Loss=6.0966, Acc=0.211, PPL=444.34
2025-09-22 00:52:17,733 - training.trainer - INFO - Epoch 30, Step 104389: Loss=5.4658, Acc=0.212, PPL=236.45
2025-09-22 00:52:25,586 - training.trainer - INFO - Epoch 30, Step 104489: Loss=5.5895, Acc=0.194, PPL=267.59
2025-09-22 00:52:33,465 - training.trainer - INFO - Epoch 30, Step 104589: Loss=6.6623, Acc=0.163, PPL=782.35
2025-09-22 00:52:41,284 - training.trainer - INFO - Epoch 30, Step 104689: Loss=5.6281, Acc=0.179, PPL=278.14
2025-09-22 00:52:49,083 - training.trainer - INFO - Epoch 30, Step 104789: Loss=5.2993, Acc=0.300, PPL=200.20
2025-09-22 00:53:05,342 - training.trainer - INFO - Epoch 31/100 completed in 280.85s - Train Loss: 5.7092, Train Acc: 0.247, Val Loss: 5.7439, Val Acc: 0.243
2025-09-22 00:53:12,986 - training.trainer - INFO - Epoch 31, Step 104972: Loss=5.5246, Acc=0.154, PPL=250.78
2025-09-22 00:53:21,065 - training.trainer - INFO - Epoch 31, Step 105072: Loss=6.2030, Acc=0.364, PPL=494.25
2025-09-22 00:53:29,142 - training.trainer - INFO - Epoch 31, Step 105172: Loss=6.2019, Acc=0.185, PPL=493.70
2025-09-22 00:53:37,226 - training.trainer - INFO - Epoch 31, Step 105272: Loss=4.5964, Acc=0.333, PPL=99.13
2025-09-22 00:53:45,218 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.5562, Acc=0.212, PPL=258.85
2025-09-22 00:53:53,373 - training.trainer - INFO - Epoch 31, Step 105472: Loss=6.6938, Acc=0.078, PPL=807.34
2025-09-22 00:54:01,421 - training.trainer - INFO - Epoch 31, Step 105572: Loss=5.8256, Acc=0.233, PPL=338.87
2025-09-22 00:54:09,556 - training.trainer - INFO - Epoch 31, Step 105672: Loss=6.6873, Acc=0.128, PPL=802.13
2025-09-22 00:54:17,501 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.3096, Acc=0.257, PPL=202.26
2025-09-22 00:54:25,426 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.5194, Acc=0.296, PPL=249.50
2025-09-22 00:54:33,497 - training.trainer - INFO - Epoch 31, Step 105972: Loss=5.1554, Acc=0.308, PPL=173.36
2025-09-22 00:54:41,572 - training.trainer - INFO - Epoch 31, Step 106072: Loss=6.0285, Acc=0.200, PPL=415.10
2025-09-22 00:54:49,569 - training.trainer - INFO - Epoch 31, Step 106172: Loss=6.1620, Acc=0.143, PPL=474.38
2025-09-22 00:54:57,619 - training.trainer - INFO - Epoch 31, Step 106272: Loss=4.9339, Acc=0.300, PPL=138.93
2025-09-22 00:55:05,740 - training.trainer - INFO - Epoch 31, Step 106372: Loss=6.2023, Acc=0.156, PPL=493.89
2025-09-22 00:55:13,746 - training.trainer - INFO - Epoch 31, Step 106472: Loss=5.8473, Acc=0.333, PPL=346.31
2025-09-22 00:55:21,732 - training.trainer - INFO - Epoch 31, Step 106572: Loss=5.6379, Acc=0.226, PPL=280.88
2025-09-22 00:55:29,697 - training.trainer - INFO - Epoch 31, Step 106672: Loss=5.1879, Acc=0.394, PPL=179.10
2025-09-22 00:55:37,593 - training.trainer - INFO - Epoch 31, Step 106772: Loss=5.7528, Acc=0.279, PPL=315.06
2025-09-22 00:55:45,493 - training.trainer - INFO - Epoch 31, Step 106872: Loss=5.6536, Acc=0.162, PPL=285.31
2025-09-22 00:55:53,332 - training.trainer - INFO - Epoch 31, Step 106972: Loss=5.8864, Acc=0.290, PPL=360.09
2025-09-22 00:56:01,090 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.8116, Acc=0.308, PPL=334.14
2025-09-22 00:56:08,911 - training.trainer - INFO - Epoch 31, Step 107172: Loss=6.2168, Acc=0.148, PPL=501.11
2025-09-22 00:56:16,928 - training.trainer - INFO - Epoch 31, Step 107272: Loss=5.5281, Acc=0.323, PPL=251.68
2025-09-22 00:56:25,065 - training.trainer - INFO - Epoch 31, Step 107372: Loss=5.6524, Acc=0.273, PPL=284.98
2025-09-22 00:56:33,122 - training.trainer - INFO - Epoch 31, Step 107472: Loss=5.1187, Acc=0.304, PPL=167.11
2025-09-22 00:56:41,159 - training.trainer - INFO - Epoch 31, Step 107572: Loss=6.0282, Acc=0.220, PPL=414.96
2025-09-22 00:56:49,293 - training.trainer - INFO - Epoch 31, Step 107672: Loss=5.4376, Acc=0.163, PPL=229.89
2025-09-22 00:56:57,518 - training.trainer - INFO - Epoch 31, Step 107772: Loss=6.2387, Acc=0.233, PPL=512.20
2025-09-22 00:57:05,604 - training.trainer - INFO - Epoch 31, Step 107872: Loss=5.2881, Acc=0.288, PPL=197.97
2025-09-22 00:57:13,788 - training.trainer - INFO - Epoch 31, Step 107972: Loss=6.0809, Acc=0.157, PPL=437.44
2025-09-22 00:57:21,822 - training.trainer - INFO - Epoch 31, Step 108072: Loss=6.0151, Acc=0.258, PPL=409.56
2025-09-22 00:57:29,803 - training.trainer - INFO - Epoch 31, Step 108172: Loss=5.4646, Acc=0.211, PPL=236.19
2025-09-22 00:57:46,819 - training.trainer - INFO - Epoch 32/100 completed in 281.48s - Train Loss: 5.6942, Train Acc: 0.250, Val Loss: 5.7263, Val Acc: 0.246
2025-09-22 00:57:47,523 - training.trainer - INFO - New best model saved with validation loss: 5.7263
2025-09-22 00:57:47,524 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_32.pt
2025-09-22 00:57:55,715 - training.trainer - INFO - Epoch 32, Step 108355: Loss=6.0672, Acc=0.161, PPL=431.49
2025-09-22 00:58:03,915 - training.trainer - INFO - Epoch 32, Step 108455: Loss=6.2894, Acc=0.233, PPL=538.83
2025-09-22 00:58:11,843 - training.trainer - INFO - Epoch 32, Step 108555: Loss=6.3470, Acc=0.182, PPL=570.77
2025-09-22 00:58:19,694 - training.trainer - INFO - Epoch 32, Step 108655: Loss=4.9725, Acc=0.294, PPL=144.38
2025-09-22 00:58:27,594 - training.trainer - INFO - Epoch 32, Step 108755: Loss=3.6696, Acc=0.542, PPL=39.24
2025-09-22 00:58:35,643 - training.trainer - INFO - Epoch 32, Step 108855: Loss=4.6773, Acc=0.385, PPL=107.48
2025-09-22 00:58:43,635 - training.trainer - INFO - Epoch 32, Step 108955: Loss=5.4053, Acc=0.286, PPL=222.59
2025-09-22 00:58:51,561 - training.trainer - INFO - Epoch 32, Step 109055: Loss=5.2308, Acc=0.253, PPL=186.94
2025-09-22 00:58:59,447 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.9364, Acc=0.290, PPL=378.55
2025-09-22 00:59:07,463 - training.trainer - INFO - Epoch 32, Step 109255: Loss=4.6871, Acc=0.346, PPL=108.54
2025-09-22 00:59:15,592 - training.trainer - INFO - Epoch 32, Step 109355: Loss=5.8739, Acc=0.289, PPL=355.64
2025-09-22 00:59:23,619 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.0241, Acc=0.375, PPL=152.04
2025-09-22 00:59:31,590 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.1059, Acc=0.343, PPL=165.00
2025-09-22 00:59:39,658 - training.trainer - INFO - Epoch 32, Step 109655: Loss=6.4026, Acc=0.207, PPL=603.44
2025-09-22 00:59:47,633 - training.trainer - INFO - Epoch 32, Step 109755: Loss=5.6486, Acc=0.238, PPL=283.90
2025-09-22 00:59:55,575 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.8281, Acc=0.238, PPL=339.71
2025-09-22 01:00:03,513 - training.trainer - INFO - Epoch 32, Step 109955: Loss=5.0208, Acc=0.320, PPL=151.53
2025-09-22 01:00:11,497 - training.trainer - INFO - Epoch 32, Step 110055: Loss=5.5734, Acc=0.308, PPL=263.33
2025-09-22 01:00:19,422 - training.trainer - INFO - Epoch 32, Step 110155: Loss=6.1821, Acc=0.157, PPL=483.98
2025-09-22 01:00:27,301 - training.trainer - INFO - Epoch 32, Step 110255: Loss=6.0397, Acc=0.145, PPL=419.75
2025-09-22 01:00:35,214 - training.trainer - INFO - Epoch 32, Step 110355: Loss=6.2887, Acc=0.157, PPL=538.46
2025-09-22 01:00:43,107 - training.trainer - INFO - Epoch 32, Step 110455: Loss=5.2300, Acc=0.222, PPL=186.80
2025-09-22 01:00:50,925 - training.trainer - INFO - Epoch 32, Step 110555: Loss=6.0286, Acc=0.250, PPL=415.12
2025-09-22 01:00:58,738 - training.trainer - INFO - Epoch 32, Step 110655: Loss=5.5516, Acc=0.279, PPL=257.65
2025-09-22 01:01:06,556 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.4964, Acc=0.247, PPL=243.80
2025-09-22 01:01:14,415 - training.trainer - INFO - Epoch 32, Step 110855: Loss=5.8341, Acc=0.171, PPL=341.76
2025-09-22 01:01:22,194 - training.trainer - INFO - Epoch 32, Step 110955: Loss=5.5952, Acc=0.364, PPL=269.14
2025-09-22 01:01:29,995 - training.trainer - INFO - Epoch 32, Step 111055: Loss=5.3721, Acc=0.194, PPL=215.31
2025-09-22 01:01:37,817 - training.trainer - INFO - Epoch 32, Step 111155: Loss=5.9038, Acc=0.323, PPL=366.43
2025-09-22 01:01:45,706 - training.trainer - INFO - Epoch 32, Step 111255: Loss=5.4278, Acc=0.286, PPL=227.64
2025-09-22 01:01:53,570 - training.trainer - INFO - Epoch 32, Step 111355: Loss=4.9580, Acc=0.304, PPL=142.31
2025-09-22 01:02:01,444 - training.trainer - INFO - Epoch 32, Step 111455: Loss=5.8949, Acc=0.227, PPL=363.17
2025-09-22 01:02:09,304 - training.trainer - INFO - Epoch 32, Step 111555: Loss=5.8856, Acc=0.300, PPL=359.82
2025-09-22 01:02:26,955 - training.trainer - INFO - Epoch 33/100 completed in 279.43s - Train Loss: 5.6829, Train Acc: 0.251, Val Loss: 5.7307, Val Acc: 0.246
2025-09-22 01:02:35,417 - training.trainer - INFO - Epoch 33, Step 111738: Loss=5.6698, Acc=0.300, PPL=289.98
2025-09-22 01:02:43,404 - training.trainer - INFO - Epoch 33, Step 111838: Loss=5.0555, Acc=0.250, PPL=156.89
2025-09-22 01:02:51,390 - training.trainer - INFO - Epoch 33, Step 111938: Loss=6.1486, Acc=0.114, PPL=468.08
2025-09-22 01:02:59,369 - training.trainer - INFO - Epoch 33, Step 112038: Loss=6.3078, Acc=0.152, PPL=548.84
2025-09-22 01:03:07,331 - training.trainer - INFO - Epoch 33, Step 112138: Loss=5.6289, Acc=0.243, PPL=278.34
2025-09-22 01:03:15,351 - training.trainer - INFO - Epoch 33, Step 112238: Loss=5.3100, Acc=0.289, PPL=202.36
2025-09-22 01:03:23,292 - training.trainer - INFO - Epoch 33, Step 112338: Loss=5.0052, Acc=0.333, PPL=149.19
2025-09-22 01:03:31,304 - training.trainer - INFO - Epoch 33, Step 112438: Loss=4.9816, Acc=0.304, PPL=145.71
2025-09-22 01:03:39,230 - training.trainer - INFO - Epoch 33, Step 112538: Loss=6.2760, Acc=0.193, PPL=531.68
2025-09-22 01:03:47,138 - training.trainer - INFO - Epoch 33, Step 112638: Loss=4.9918, Acc=0.315, PPL=147.21
2025-09-22 01:03:55,027 - training.trainer - INFO - Epoch 33, Step 112738: Loss=6.0644, Acc=0.133, PPL=430.26
2025-09-22 01:04:02,985 - training.trainer - INFO - Epoch 33, Step 112838: Loss=4.8424, Acc=0.370, PPL=126.78
2025-09-22 01:04:10,839 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.8687, Acc=0.129, PPL=353.78
2025-09-22 01:04:18,695 - training.trainer - INFO - Epoch 33, Step 113038: Loss=6.3130, Acc=0.154, PPL=551.72
2025-09-22 01:04:26,599 - training.trainer - INFO - Epoch 33, Step 113138: Loss=6.2527, Acc=0.203, PPL=519.39
2025-09-22 01:04:34,512 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.8423, Acc=0.227, PPL=344.58
2025-09-22 01:04:42,384 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.1459, Acc=0.295, PPL=171.72
2025-09-22 01:04:50,242 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.8397, Acc=0.162, PPL=343.69
2025-09-22 01:04:58,122 - training.trainer - INFO - Epoch 33, Step 113538: Loss=6.1808, Acc=0.179, PPL=483.38
2025-09-22 01:05:06,037 - training.trainer - INFO - Epoch 33, Step 113638: Loss=5.3037, Acc=0.300, PPL=201.08
2025-09-22 01:05:13,839 - training.trainer - INFO - Epoch 33, Step 113738: Loss=4.7651, Acc=0.300, PPL=117.34
2025-09-22 01:05:21,713 - training.trainer - INFO - Epoch 33, Step 113838: Loss=6.2560, Acc=0.172, PPL=521.13
2025-09-22 01:05:29,619 - training.trainer - INFO - Epoch 33, Step 113938: Loss=6.2003, Acc=0.200, PPL=492.91
2025-09-22 01:05:37,510 - training.trainer - INFO - Epoch 33, Step 114038: Loss=6.0320, Acc=0.239, PPL=416.54
2025-09-22 01:05:45,479 - training.trainer - INFO - Epoch 33, Step 114138: Loss=5.8223, Acc=0.158, PPL=337.74
2025-09-22 01:05:53,451 - training.trainer - INFO - Epoch 33, Step 114238: Loss=4.9923, Acc=0.200, PPL=147.28
2025-09-22 01:06:01,381 - training.trainer - INFO - Epoch 33, Step 114338: Loss=6.2773, Acc=0.261, PPL=532.33
2025-09-22 01:06:09,304 - training.trainer - INFO - Epoch 33, Step 114438: Loss=5.9846, Acc=0.263, PPL=397.28
2025-09-22 01:06:17,211 - training.trainer - INFO - Epoch 33, Step 114538: Loss=6.0421, Acc=0.184, PPL=420.78
2025-09-22 01:06:25,096 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.3323, Acc=0.450, PPL=206.90
2025-09-22 01:06:33,002 - training.trainer - INFO - Epoch 33, Step 114738: Loss=6.7698, Acc=0.145, PPL=871.11
2025-09-22 01:06:40,934 - training.trainer - INFO - Epoch 33, Step 114838: Loss=6.1349, Acc=0.250, PPL=461.69
2025-09-22 01:06:48,944 - training.trainer - INFO - Epoch 33, Step 114938: Loss=6.0102, Acc=0.271, PPL=407.55
2025-09-22 01:07:06,408 - training.trainer - INFO - Epoch 34/100 completed in 279.45s - Train Loss: 5.6773, Train Acc: 0.252, Val Loss: 5.7251, Val Acc: 0.243
2025-09-22 01:07:07,173 - training.trainer - INFO - New best model saved with validation loss: 5.7251
2025-09-22 01:07:07,173 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_34.pt
2025-09-22 01:07:15,582 - training.trainer - INFO - Epoch 34, Step 115121: Loss=5.9527, Acc=0.348, PPL=384.78
2025-09-22 01:07:23,466 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.8699, Acc=0.304, PPL=354.22
2025-09-22 01:07:31,345 - training.trainer - INFO - Epoch 34, Step 115321: Loss=4.5529, Acc=0.368, PPL=94.91
2025-09-22 01:07:39,193 - training.trainer - INFO - Epoch 34, Step 115421: Loss=6.2880, Acc=0.261, PPL=538.08
2025-09-22 01:07:47,129 - training.trainer - INFO - Epoch 34, Step 115521: Loss=5.5542, Acc=0.213, PPL=258.31
2025-09-22 01:07:54,991 - training.trainer - INFO - Epoch 34, Step 115621: Loss=6.2895, Acc=0.125, PPL=538.90
2025-09-22 01:08:02,879 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.4198, Acc=0.263, PPL=225.84
2025-09-22 01:08:10,721 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.8490, Acc=0.234, PPL=346.88
2025-09-22 01:08:18,647 - training.trainer - INFO - Epoch 34, Step 115921: Loss=5.0215, Acc=0.368, PPL=151.63
2025-09-22 01:08:26,592 - training.trainer - INFO - Epoch 34, Step 116021: Loss=5.6102, Acc=0.237, PPL=273.21
2025-09-22 01:08:34,495 - training.trainer - INFO - Epoch 34, Step 116121: Loss=5.0079, Acc=0.333, PPL=149.59
2025-09-22 01:08:42,414 - training.trainer - INFO - Epoch 34, Step 116221: Loss=5.7923, Acc=0.269, PPL=327.76
2025-09-22 01:08:50,294 - training.trainer - INFO - Epoch 34, Step 116321: Loss=6.3612, Acc=0.163, PPL=578.91
2025-09-22 01:08:58,223 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.9409, Acc=0.258, PPL=380.29
2025-09-22 01:09:06,170 - training.trainer - INFO - Epoch 34, Step 116521: Loss=6.4020, Acc=0.160, PPL=603.08
2025-09-22 01:09:14,094 - training.trainer - INFO - Epoch 34, Step 116621: Loss=4.9555, Acc=0.286, PPL=141.96
2025-09-22 01:09:22,022 - training.trainer - INFO - Epoch 34, Step 116721: Loss=5.7059, Acc=0.267, PPL=300.62
2025-09-22 01:09:29,985 - training.trainer - INFO - Epoch 34, Step 116821: Loss=4.9523, Acc=0.304, PPL=141.50
2025-09-22 01:09:37,838 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.9308, Acc=0.104, PPL=376.44
2025-09-22 01:09:45,660 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.4417, Acc=0.381, PPL=230.84
2025-09-22 01:09:53,585 - training.trainer - INFO - Epoch 34, Step 117121: Loss=5.7975, Acc=0.260, PPL=329.49
2025-09-22 01:10:01,543 - training.trainer - INFO - Epoch 34, Step 117221: Loss=5.9603, Acc=0.175, PPL=387.71
2025-09-22 01:10:09,459 - training.trainer - INFO - Epoch 34, Step 117321: Loss=4.7950, Acc=0.350, PPL=120.91
2025-09-22 01:10:17,355 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.8173, Acc=0.174, PPL=336.06
2025-09-22 01:10:25,227 - training.trainer - INFO - Epoch 34, Step 117521: Loss=3.4234, Acc=0.536, PPL=30.67
2025-09-22 01:10:33,219 - training.trainer - INFO - Epoch 34, Step 117621: Loss=5.0750, Acc=0.256, PPL=159.96
2025-09-22 01:10:41,355 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.9345, Acc=0.237, PPL=377.84
2025-09-22 01:10:49,431 - training.trainer - INFO - Epoch 34, Step 117821: Loss=6.0735, Acc=0.269, PPL=434.20
2025-09-22 01:10:57,333 - training.trainer - INFO - Epoch 34, Step 117921: Loss=4.9747, Acc=0.300, PPL=144.70
2025-09-22 01:11:05,300 - training.trainer - INFO - Epoch 34, Step 118021: Loss=6.1411, Acc=0.167, PPL=464.56
2025-09-22 01:11:13,228 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.5119, Acc=0.271, PPL=247.62
2025-09-22 01:11:21,197 - training.trainer - INFO - Epoch 34, Step 118221: Loss=5.6586, Acc=0.375, PPL=286.75
2025-09-22 01:11:29,130 - training.trainer - INFO - Epoch 34, Step 118321: Loss=6.2852, Acc=0.217, PPL=536.56
2025-09-22 01:11:45,852 - training.trainer - INFO - Epoch 35/100 completed in 278.68s - Train Loss: 5.6715, Train Acc: 0.254, Val Loss: 5.7366, Val Acc: 0.245
2025-09-22 01:11:46,179 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-22 01:11:54,441 - training.trainer - INFO - Epoch 35, Step 118504: Loss=6.6245, Acc=0.184, PPL=753.33
2025-09-22 01:12:02,526 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.9790, Acc=0.148, PPL=395.03
2025-09-22 01:12:10,570 - training.trainer - INFO - Epoch 35, Step 118704: Loss=5.5672, Acc=0.164, PPL=261.70
2025-09-22 01:12:18,436 - training.trainer - INFO - Epoch 35, Step 118804: Loss=6.0840, Acc=0.240, PPL=438.78
2025-09-22 01:12:26,371 - training.trainer - INFO - Epoch 35, Step 118904: Loss=6.5386, Acc=0.146, PPL=691.31
2025-09-22 01:12:34,284 - training.trainer - INFO - Epoch 35, Step 119004: Loss=5.3018, Acc=0.316, PPL=200.69
2025-09-22 01:12:42,323 - training.trainer - INFO - Epoch 35, Step 119104: Loss=6.1037, Acc=0.294, PPL=447.52
2025-09-22 01:12:50,320 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.2104, Acc=0.333, PPL=183.16
2025-09-22 01:12:58,204 - training.trainer - INFO - Epoch 35, Step 119304: Loss=5.0917, Acc=0.375, PPL=162.67
2025-09-22 01:13:06,057 - training.trainer - INFO - Epoch 35, Step 119404: Loss=6.7132, Acc=0.088, PPL=823.20
2025-09-22 01:13:13,922 - training.trainer - INFO - Epoch 35, Step 119504: Loss=5.5154, Acc=0.286, PPL=248.50
2025-09-22 01:13:21,760 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.4867, Acc=0.179, PPL=241.45
2025-09-22 01:13:29,585 - training.trainer - INFO - Epoch 35, Step 119704: Loss=4.0784, Acc=0.462, PPL=59.05
2025-09-22 01:13:37,454 - training.trainer - INFO - Epoch 35, Step 119804: Loss=3.8765, Acc=0.522, PPL=48.26
2025-09-22 01:13:45,219 - training.trainer - INFO - Epoch 35, Step 119904: Loss=4.2820, Acc=0.238, PPL=72.39
2025-09-22 01:13:53,067 - training.trainer - INFO - Epoch 35, Step 120004: Loss=5.8223, Acc=0.294, PPL=337.73
2025-09-22 01:14:00,832 - training.trainer - INFO - Epoch 35, Step 120104: Loss=5.8997, Acc=0.264, PPL=364.93
2025-09-22 01:14:08,617 - training.trainer - INFO - Epoch 35, Step 120204: Loss=5.2947, Acc=0.308, PPL=199.27
2025-09-22 01:14:16,411 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.3706, Acc=0.359, PPL=215.00
2025-09-22 01:14:24,225 - training.trainer - INFO - Epoch 35, Step 120404: Loss=6.2870, Acc=0.146, PPL=537.53
2025-09-22 01:14:32,000 - training.trainer - INFO - Epoch 35, Step 120504: Loss=5.5839, Acc=0.316, PPL=266.10
2025-09-22 01:14:39,788 - training.trainer - INFO - Epoch 35, Step 120604: Loss=5.6282, Acc=0.222, PPL=278.15
2025-09-22 01:14:47,528 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.3089, Acc=0.324, PPL=202.13
2025-09-22 01:14:55,494 - training.trainer - INFO - Epoch 35, Step 120804: Loss=6.1320, Acc=0.180, PPL=460.36
2025-09-22 01:15:03,340 - training.trainer - INFO - Epoch 35, Step 120904: Loss=6.5184, Acc=0.138, PPL=677.52
2025-09-22 01:15:11,172 - training.trainer - INFO - Epoch 35, Step 121004: Loss=5.5981, Acc=0.233, PPL=269.90
2025-09-22 01:15:18,974 - training.trainer - INFO - Epoch 35, Step 121104: Loss=5.5759, Acc=0.235, PPL=263.98
2025-09-22 01:15:26,841 - training.trainer - INFO - Epoch 35, Step 121204: Loss=4.9131, Acc=0.364, PPL=136.06
2025-09-22 01:15:34,708 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.1002, Acc=0.276, PPL=164.06
2025-09-22 01:15:42,560 - training.trainer - INFO - Epoch 35, Step 121404: Loss=4.6368, Acc=0.383, PPL=103.21
2025-09-22 01:15:50,348 - training.trainer - INFO - Epoch 35, Step 121504: Loss=6.4491, Acc=0.208, PPL=632.13
2025-09-22 01:15:58,257 - training.trainer - INFO - Epoch 35, Step 121604: Loss=5.8050, Acc=0.200, PPL=331.97
2025-09-22 01:16:06,095 - training.trainer - INFO - Epoch 35, Step 121704: Loss=4.9281, Acc=0.375, PPL=138.12
2025-09-22 01:16:23,754 - training.trainer - INFO - Epoch 36/100 completed in 277.57s - Train Loss: 5.6557, Train Acc: 0.255, Val Loss: 5.7187, Val Acc: 0.244
2025-09-22 01:16:24,569 - training.trainer - INFO - New best model saved with validation loss: 5.7187
2025-09-22 01:16:24,570 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_36.pt
2025-09-22 01:16:32,852 - training.trainer - INFO - Epoch 36, Step 121887: Loss=3.7438, Acc=0.500, PPL=42.26
2025-09-22 01:16:40,703 - training.trainer - INFO - Epoch 36, Step 121987: Loss=5.4025, Acc=0.438, PPL=221.96
2025-09-22 01:16:48,549 - training.trainer - INFO - Epoch 36, Step 122087: Loss=5.1948, Acc=0.351, PPL=180.33
2025-09-22 01:16:56,385 - training.trainer - INFO - Epoch 36, Step 122187: Loss=4.4557, Acc=0.400, PPL=86.11
2025-09-22 01:17:04,297 - training.trainer - INFO - Epoch 36, Step 122287: Loss=4.9207, Acc=0.267, PPL=137.10
2025-09-22 01:17:12,165 - training.trainer - INFO - Epoch 36, Step 122387: Loss=6.7281, Acc=0.120, PPL=835.55
2025-09-22 01:17:19,972 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.0261, Acc=0.231, PPL=152.34
2025-09-22 01:17:27,809 - training.trainer - INFO - Epoch 36, Step 122587: Loss=5.8544, Acc=0.220, PPL=348.78
2025-09-22 01:17:35,583 - training.trainer - INFO - Epoch 36, Step 122687: Loss=5.7988, Acc=0.280, PPL=329.90
2025-09-22 01:17:43,450 - training.trainer - INFO - Epoch 36, Step 122787: Loss=5.8828, Acc=0.216, PPL=358.82
2025-09-22 01:17:51,240 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.7648, Acc=0.280, PPL=318.86
2025-09-22 01:17:59,021 - training.trainer - INFO - Epoch 36, Step 122987: Loss=6.1935, Acc=0.185, PPL=489.56
2025-09-22 01:18:06,802 - training.trainer - INFO - Epoch 36, Step 123087: Loss=6.9625, Acc=0.222, PPL=1056.27
2025-09-22 01:18:14,645 - training.trainer - INFO - Epoch 36, Step 123187: Loss=6.1001, Acc=0.222, PPL=445.88
2025-09-22 01:18:22,407 - training.trainer - INFO - Epoch 36, Step 123287: Loss=6.1464, Acc=0.242, PPL=467.05
2025-09-22 01:18:30,154 - training.trainer - INFO - Epoch 36, Step 123387: Loss=6.3422, Acc=0.102, PPL=568.04
2025-09-22 01:18:37,893 - training.trainer - INFO - Epoch 36, Step 123487: Loss=6.3574, Acc=0.191, PPL=576.75
2025-09-22 01:18:45,681 - training.trainer - INFO - Epoch 36, Step 123587: Loss=6.0951, Acc=0.170, PPL=443.69
2025-09-22 01:18:53,366 - training.trainer - INFO - Epoch 36, Step 123687: Loss=5.2118, Acc=0.214, PPL=183.42
2025-09-22 01:19:01,079 - training.trainer - INFO - Epoch 36, Step 123787: Loss=5.1768, Acc=0.286, PPL=177.12
2025-09-22 01:19:08,867 - training.trainer - INFO - Epoch 36, Step 123887: Loss=5.1888, Acc=0.375, PPL=179.26
2025-09-22 01:19:16,731 - training.trainer - INFO - Epoch 36, Step 123987: Loss=4.7108, Acc=0.409, PPL=111.14
2025-09-22 01:19:24,564 - training.trainer - INFO - Epoch 36, Step 124087: Loss=4.8719, Acc=0.333, PPL=130.57
2025-09-22 01:19:32,240 - training.trainer - INFO - Epoch 36, Step 124187: Loss=6.0273, Acc=0.193, PPL=414.57
2025-09-22 01:19:40,118 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.3830, Acc=0.409, PPL=217.68
2025-09-22 01:19:48,295 - training.trainer - INFO - Epoch 36, Step 124387: Loss=6.7888, Acc=0.111, PPL=887.86
2025-09-22 01:19:56,456 - training.trainer - INFO - Epoch 36, Step 124487: Loss=5.2035, Acc=0.318, PPL=181.90
2025-09-22 01:20:04,473 - training.trainer - INFO - Epoch 36, Step 124587: Loss=4.9162, Acc=0.375, PPL=136.48
2025-09-22 01:20:12,274 - training.trainer - INFO - Epoch 36, Step 124687: Loss=6.6914, Acc=0.152, PPL=805.46
2025-09-22 01:20:20,057 - training.trainer - INFO - Epoch 36, Step 124787: Loss=5.0816, Acc=0.296, PPL=161.04
2025-09-22 01:20:27,848 - training.trainer - INFO - Epoch 36, Step 124887: Loss=6.8587, Acc=0.135, PPL=952.16
2025-09-22 01:20:35,603 - training.trainer - INFO - Epoch 36, Step 124987: Loss=5.6247, Acc=0.289, PPL=277.18
2025-09-22 01:20:43,316 - training.trainer - INFO - Epoch 36, Step 125087: Loss=4.7919, Acc=0.292, PPL=120.53
2025-09-22 01:21:00,226 - training.trainer - INFO - Epoch 37/100 completed in 275.66s - Train Loss: 5.6466, Train Acc: 0.257, Val Loss: 5.7101, Val Acc: 0.249
2025-09-22 01:21:00,989 - training.trainer - INFO - New best model saved with validation loss: 5.7101
2025-09-22 01:21:00,990 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_37.pt
2025-09-22 01:21:09,512 - training.trainer - INFO - Epoch 37, Step 125270: Loss=5.9678, Acc=0.240, PPL=390.63
2025-09-22 01:21:17,572 - training.trainer - INFO - Epoch 37, Step 125370: Loss=5.6532, Acc=0.296, PPL=285.20
2025-09-22 01:21:25,661 - training.trainer - INFO - Epoch 37, Step 125470: Loss=5.6118, Acc=0.271, PPL=273.64
2025-09-22 01:21:33,590 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.9706, Acc=0.108, PPL=391.73
2025-09-22 01:21:41,691 - training.trainer - INFO - Epoch 37, Step 125670: Loss=5.8963, Acc=0.282, PPL=363.68
2025-09-22 01:21:49,661 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.3993, Acc=0.304, PPL=221.26
2025-09-22 01:21:57,572 - training.trainer - INFO - Epoch 37, Step 125870: Loss=5.4615, Acc=0.262, PPL=235.45
2025-09-22 01:22:05,653 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.6010, Acc=0.294, PPL=270.70
2025-09-22 01:22:13,739 - training.trainer - INFO - Epoch 37, Step 126070: Loss=6.1670, Acc=0.286, PPL=476.73
2025-09-22 01:22:21,829 - training.trainer - INFO - Epoch 37, Step 126170: Loss=5.9036, Acc=0.226, PPL=366.36
2025-09-22 01:22:29,966 - training.trainer - INFO - Epoch 37, Step 126270: Loss=4.9743, Acc=0.333, PPL=144.65
2025-09-22 01:22:38,049 - training.trainer - INFO - Epoch 37, Step 126370: Loss=6.2041, Acc=0.196, PPL=494.76
2025-09-22 01:22:46,185 - training.trainer - INFO - Epoch 37, Step 126470: Loss=5.7348, Acc=0.143, PPL=309.44
2025-09-22 01:22:54,275 - training.trainer - INFO - Epoch 37, Step 126570: Loss=5.7826, Acc=0.219, PPL=324.61
2025-09-22 01:23:02,359 - training.trainer - INFO - Epoch 37, Step 126670: Loss=6.6486, Acc=0.115, PPL=771.70
2025-09-22 01:23:10,558 - training.trainer - INFO - Epoch 37, Step 126770: Loss=5.9523, Acc=0.273, PPL=384.62
2025-09-22 01:23:18,589 - training.trainer - INFO - Epoch 37, Step 126870: Loss=5.4278, Acc=0.280, PPL=227.65
2025-09-22 01:23:26,555 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.6288, Acc=0.286, PPL=278.33
2025-09-22 01:23:34,643 - training.trainer - INFO - Epoch 37, Step 127070: Loss=3.9182, Acc=0.400, PPL=50.31
2025-09-22 01:23:42,868 - training.trainer - INFO - Epoch 37, Step 127170: Loss=5.6222, Acc=0.321, PPL=276.49
2025-09-22 01:23:50,964 - training.trainer - INFO - Epoch 37, Step 127270: Loss=3.6733, Acc=0.480, PPL=39.38
2025-09-22 01:23:59,053 - training.trainer - INFO - Epoch 37, Step 127370: Loss=5.4584, Acc=0.262, PPL=234.73
2025-09-22 01:24:07,189 - training.trainer - INFO - Epoch 37, Step 127470: Loss=5.2582, Acc=0.280, PPL=192.13
2025-09-22 01:24:15,416 - training.trainer - INFO - Epoch 37, Step 127570: Loss=5.6274, Acc=0.323, PPL=277.94
2025-09-22 01:24:23,563 - training.trainer - INFO - Epoch 37, Step 127670: Loss=5.7081, Acc=0.188, PPL=301.28
2025-09-22 01:24:31,532 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.8093, Acc=0.255, PPL=333.40
2025-09-22 01:24:39,474 - training.trainer - INFO - Epoch 37, Step 127870: Loss=4.5618, Acc=0.348, PPL=95.76
2025-09-22 01:24:47,478 - training.trainer - INFO - Epoch 37, Step 127970: Loss=5.0654, Acc=0.310, PPL=158.45
2025-09-22 01:24:55,415 - training.trainer - INFO - Epoch 37, Step 128070: Loss=5.7772, Acc=0.282, PPL=322.87
2025-09-22 01:25:03,710 - training.trainer - INFO - Epoch 37, Step 128170: Loss=6.3173, Acc=0.122, PPL=554.05
2025-09-22 01:25:11,865 - training.trainer - INFO - Epoch 37, Step 128270: Loss=5.6401, Acc=0.154, PPL=281.50
2025-09-22 01:25:20,110 - training.trainer - INFO - Epoch 37, Step 128370: Loss=4.7678, Acc=0.286, PPL=117.66
2025-09-22 01:25:28,229 - training.trainer - INFO - Epoch 37, Step 128470: Loss=5.5924, Acc=0.279, PPL=268.37
2025-09-22 01:25:45,146 - training.trainer - INFO - Epoch 38/100 completed in 284.16s - Train Loss: 5.6408, Train Acc: 0.258, Val Loss: 5.7092, Val Acc: 0.246
2025-09-22 01:25:45,804 - training.trainer - INFO - New best model saved with validation loss: 5.7092
2025-09-22 01:25:45,805 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_38.pt
2025-09-22 01:25:54,223 - training.trainer - INFO - Epoch 38, Step 128653: Loss=5.4151, Acc=0.148, PPL=224.78
2025-09-22 01:26:02,321 - training.trainer - INFO - Epoch 38, Step 128753: Loss=6.3390, Acc=0.212, PPL=566.26
2025-09-22 01:26:10,285 - training.trainer - INFO - Epoch 38, Step 128853: Loss=6.3844, Acc=0.250, PPL=592.52
2025-09-22 01:26:18,452 - training.trainer - INFO - Epoch 38, Step 128953: Loss=6.1021, Acc=0.237, PPL=446.79
2025-09-22 01:26:26,645 - training.trainer - INFO - Epoch 38, Step 129053: Loss=6.5158, Acc=0.225, PPL=675.76
2025-09-22 01:26:34,743 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.9478, Acc=0.224, PPL=382.91
2025-09-22 01:26:42,796 - training.trainer - INFO - Epoch 38, Step 129253: Loss=5.9169, Acc=0.265, PPL=371.27
2025-09-22 01:26:50,726 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.8744, Acc=0.231, PPL=355.81
2025-09-22 01:26:58,757 - training.trainer - INFO - Epoch 38, Step 129453: Loss=5.9429, Acc=0.184, PPL=381.05
2025-09-22 01:27:06,684 - training.trainer - INFO - Epoch 38, Step 129553: Loss=6.3169, Acc=0.188, PPL=553.87
2025-09-22 01:27:14,518 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.1025, Acc=0.279, PPL=164.43
2025-09-22 01:27:22,410 - training.trainer - INFO - Epoch 38, Step 129753: Loss=4.5173, Acc=0.400, PPL=91.58
2025-09-22 01:27:30,652 - training.trainer - INFO - Epoch 38, Step 129853: Loss=6.1508, Acc=0.115, PPL=469.11
2025-09-22 01:27:38,816 - training.trainer - INFO - Epoch 38, Step 129953: Loss=5.7636, Acc=0.213, PPL=318.50
2025-09-22 01:27:46,843 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.7275, Acc=0.240, PPL=307.20
2025-09-22 01:27:54,845 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.8139, Acc=0.204, PPL=334.93
2025-09-22 01:28:02,837 - training.trainer - INFO - Epoch 38, Step 130253: Loss=5.5971, Acc=0.282, PPL=269.64
2025-09-22 01:28:10,723 - training.trainer - INFO - Epoch 38, Step 130353: Loss=5.0194, Acc=0.286, PPL=151.31
2025-09-22 01:28:18,822 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.5715, Acc=0.265, PPL=262.82
2025-09-22 01:28:26,867 - training.trainer - INFO - Epoch 38, Step 130553: Loss=6.1508, Acc=0.170, PPL=469.07
2025-09-22 01:28:35,133 - training.trainer - INFO - Epoch 38, Step 130653: Loss=6.0989, Acc=0.180, PPL=445.37
2025-09-22 01:28:43,134 - training.trainer - INFO - Epoch 38, Step 130753: Loss=6.2703, Acc=0.169, PPL=528.62
2025-09-22 01:28:51,018 - training.trainer - INFO - Epoch 38, Step 130853: Loss=4.6515, Acc=0.385, PPL=104.74
2025-09-22 01:28:58,926 - training.trainer - INFO - Epoch 38, Step 130953: Loss=5.5692, Acc=0.214, PPL=262.22
2025-09-22 01:29:06,886 - training.trainer - INFO - Epoch 38, Step 131053: Loss=6.1741, Acc=0.162, PPL=480.15
2025-09-22 01:29:14,738 - training.trainer - INFO - Epoch 38, Step 131153: Loss=5.6472, Acc=0.185, PPL=283.50
2025-09-22 01:29:22,650 - training.trainer - INFO - Epoch 38, Step 131253: Loss=5.0168, Acc=0.235, PPL=150.93
2025-09-22 01:29:30,526 - training.trainer - INFO - Epoch 38, Step 131353: Loss=5.3207, Acc=0.256, PPL=204.53
2025-09-22 01:29:38,459 - training.trainer - INFO - Epoch 38, Step 131453: Loss=5.8842, Acc=0.203, PPL=359.31
2025-09-22 01:29:46,395 - training.trainer - INFO - Epoch 38, Step 131553: Loss=5.0920, Acc=0.364, PPL=162.71
2025-09-22 01:29:54,257 - training.trainer - INFO - Epoch 38, Step 131653: Loss=4.9537, Acc=0.375, PPL=141.70
2025-09-22 01:30:02,150 - training.trainer - INFO - Epoch 38, Step 131753: Loss=6.3716, Acc=0.130, PPL=584.97
2025-09-22 01:30:10,060 - training.trainer - INFO - Epoch 38, Step 131853: Loss=5.3185, Acc=0.185, PPL=204.08
2025-09-22 01:30:26,897 - training.trainer - INFO - Epoch 39/100 completed in 281.09s - Train Loss: 5.6260, Train Acc: 0.258, Val Loss: 5.7100, Val Acc: 0.247
2025-09-22 01:30:34,779 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.7526, Acc=0.290, PPL=315.01
2025-09-22 01:30:42,768 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.1587, Acc=0.326, PPL=173.94
2025-09-22 01:30:50,672 - training.trainer - INFO - Epoch 39, Step 132236: Loss=5.2852, Acc=0.314, PPL=197.40
2025-09-22 01:30:58,637 - training.trainer - INFO - Epoch 39, Step 132336: Loss=5.3741, Acc=0.286, PPL=215.74
2025-09-22 01:31:06,464 - training.trainer - INFO - Epoch 39, Step 132436: Loss=6.4985, Acc=0.157, PPL=664.13
2025-09-22 01:31:14,239 - training.trainer - INFO - Epoch 39, Step 132536: Loss=6.3936, Acc=0.146, PPL=598.01
2025-09-22 01:31:22,118 - training.trainer - INFO - Epoch 39, Step 132636: Loss=5.5426, Acc=0.258, PPL=255.33
2025-09-22 01:31:29,965 - training.trainer - INFO - Epoch 39, Step 132736: Loss=5.2978, Acc=0.205, PPL=199.89
2025-09-22 01:31:37,841 - training.trainer - INFO - Epoch 39, Step 132836: Loss=5.6446, Acc=0.316, PPL=282.77
2025-09-22 01:31:45,762 - training.trainer - INFO - Epoch 39, Step 132936: Loss=6.5037, Acc=0.238, PPL=667.64
2025-09-22 01:31:53,688 - training.trainer - INFO - Epoch 39, Step 133036: Loss=6.1261, Acc=0.184, PPL=457.64
2025-09-22 01:32:01,595 - training.trainer - INFO - Epoch 39, Step 133136: Loss=4.3990, Acc=0.379, PPL=81.37
2025-09-22 01:32:09,495 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.2939, Acc=0.200, PPL=199.12
2025-09-22 01:32:17,350 - training.trainer - INFO - Epoch 39, Step 133336: Loss=5.8187, Acc=0.345, PPL=336.55
2025-09-22 01:32:25,279 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.5116, Acc=0.278, PPL=247.55
2025-09-22 01:32:33,140 - training.trainer - INFO - Epoch 39, Step 133536: Loss=5.8821, Acc=0.175, PPL=358.55
2025-09-22 01:32:40,992 - training.trainer - INFO - Epoch 39, Step 133636: Loss=6.3863, Acc=0.217, PPL=593.67
2025-09-22 01:32:48,806 - training.trainer - INFO - Epoch 39, Step 133736: Loss=5.8104, Acc=0.196, PPL=333.75
2025-09-22 01:32:56,664 - training.trainer - INFO - Epoch 39, Step 133836: Loss=5.1085, Acc=0.268, PPL=165.43
2025-09-22 01:33:04,555 - training.trainer - INFO - Epoch 39, Step 133936: Loss=5.1410, Acc=0.321, PPL=170.88
2025-09-22 01:33:12,438 - training.trainer - INFO - Epoch 39, Step 134036: Loss=4.6571, Acc=0.375, PPL=105.33
2025-09-22 01:33:20,301 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.5118, Acc=0.211, PPL=247.59
2025-09-22 01:33:28,245 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.8886, Acc=0.281, PPL=360.88
2025-09-22 01:33:36,058 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.2103, Acc=0.308, PPL=183.15
2025-09-22 01:33:43,861 - training.trainer - INFO - Epoch 39, Step 134436: Loss=5.7361, Acc=0.432, PPL=309.87
2025-09-22 01:33:51,882 - training.trainer - INFO - Epoch 39, Step 134536: Loss=5.2376, Acc=0.333, PPL=188.23
2025-09-22 01:34:00,046 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.9917, Acc=0.203, PPL=400.10
2025-09-22 01:34:08,160 - training.trainer - INFO - Epoch 39, Step 134736: Loss=5.1465, Acc=0.312, PPL=171.83
2025-09-22 01:34:16,049 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.0661, Acc=0.217, PPL=158.56
2025-09-22 01:34:23,979 - training.trainer - INFO - Epoch 39, Step 134936: Loss=5.1382, Acc=0.294, PPL=170.41
2025-09-22 01:34:31,872 - training.trainer - INFO - Epoch 39, Step 135036: Loss=5.1123, Acc=0.143, PPL=166.05
2025-09-22 01:34:39,740 - training.trainer - INFO - Epoch 39, Step 135136: Loss=6.4619, Acc=0.156, PPL=640.30
2025-09-22 01:34:47,796 - training.trainer - INFO - Epoch 39, Step 135236: Loss=5.1034, Acc=0.321, PPL=164.59
2025-09-22 01:35:05,813 - training.trainer - INFO - Epoch 40/100 completed in 278.92s - Train Loss: 5.6160, Train Acc: 0.261, Val Loss: 5.7026, Val Acc: 0.248
2025-09-22 01:35:06,176 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-22 01:35:06,895 - training.trainer - INFO - New best model saved with validation loss: 5.7026
2025-09-22 01:35:06,895 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-22 01:35:15,335 - training.trainer - INFO - Epoch 40, Step 135419: Loss=5.3731, Acc=0.233, PPL=215.52
2025-09-22 01:35:23,514 - training.trainer - INFO - Epoch 40, Step 135519: Loss=5.0919, Acc=0.314, PPL=162.70
2025-09-22 01:35:31,635 - training.trainer - INFO - Epoch 40, Step 135619: Loss=5.6293, Acc=0.250, PPL=278.47
2025-09-22 01:35:39,825 - training.trainer - INFO - Epoch 40, Step 135719: Loss=5.9542, Acc=0.180, PPL=385.35
2025-09-22 01:35:47,846 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.6669, Acc=0.143, PPL=289.14
2025-09-22 01:35:55,822 - training.trainer - INFO - Epoch 40, Step 135919: Loss=5.4233, Acc=0.318, PPL=226.63
2025-09-22 01:36:03,691 - training.trainer - INFO - Epoch 40, Step 136019: Loss=6.2100, Acc=0.183, PPL=497.71
2025-09-22 01:36:11,768 - training.trainer - INFO - Epoch 40, Step 136119: Loss=5.1754, Acc=0.316, PPL=176.87
2025-09-22 01:36:19,772 - training.trainer - INFO - Epoch 40, Step 136219: Loss=6.0417, Acc=0.200, PPL=420.62
2025-09-22 01:36:27,799 - training.trainer - INFO - Epoch 40, Step 136319: Loss=5.5065, Acc=0.209, PPL=246.29
2025-09-22 01:36:35,687 - training.trainer - INFO - Epoch 40, Step 136419: Loss=6.1245, Acc=0.184, PPL=456.89
2025-09-22 01:36:43,575 - training.trainer - INFO - Epoch 40, Step 136519: Loss=5.3070, Acc=0.267, PPL=201.75
2025-09-22 01:36:51,439 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.7509, Acc=0.261, PPL=314.48
2025-09-22 01:36:59,237 - training.trainer - INFO - Epoch 40, Step 136719: Loss=6.3700, Acc=0.171, PPL=584.07
2025-09-22 01:37:07,068 - training.trainer - INFO - Epoch 40, Step 136819: Loss=5.9857, Acc=0.243, PPL=397.69
2025-09-22 01:37:15,051 - training.trainer - INFO - Epoch 40, Step 136919: Loss=5.4141, Acc=0.280, PPL=224.56
2025-09-22 01:37:23,021 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.1508, Acc=0.263, PPL=172.57
2025-09-22 01:37:31,030 - training.trainer - INFO - Epoch 40, Step 137119: Loss=6.1654, Acc=0.127, PPL=475.99
2025-09-22 01:37:39,021 - training.trainer - INFO - Epoch 40, Step 137219: Loss=5.3137, Acc=0.312, PPL=203.10
2025-09-22 01:37:46,992 - training.trainer - INFO - Epoch 40, Step 137319: Loss=6.4111, Acc=0.200, PPL=608.56
2025-09-22 01:37:54,922 - training.trainer - INFO - Epoch 40, Step 137419: Loss=3.0245, Acc=0.632, PPL=20.58
2025-09-22 01:38:02,845 - training.trainer - INFO - Epoch 40, Step 137519: Loss=5.4236, Acc=0.317, PPL=226.70
2025-09-22 01:38:10,742 - training.trainer - INFO - Epoch 40, Step 137619: Loss=5.1297, Acc=0.385, PPL=168.97
2025-09-22 01:38:18,632 - training.trainer - INFO - Epoch 40, Step 137719: Loss=6.2019, Acc=0.200, PPL=493.69
2025-09-22 01:38:26,500 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.8218, Acc=0.184, PPL=337.59
2025-09-22 01:38:34,414 - training.trainer - INFO - Epoch 40, Step 137919: Loss=6.1199, Acc=0.118, PPL=454.82
2025-09-22 01:38:42,363 - training.trainer - INFO - Epoch 40, Step 138019: Loss=4.8961, Acc=0.296, PPL=133.76
2025-09-22 01:38:50,274 - training.trainer - INFO - Epoch 40, Step 138119: Loss=5.9975, Acc=0.160, PPL=402.43
2025-09-22 01:38:58,264 - training.trainer - INFO - Epoch 40, Step 138219: Loss=5.2793, Acc=0.241, PPL=196.23
2025-09-22 01:39:06,200 - training.trainer - INFO - Epoch 40, Step 138319: Loss=5.6505, Acc=0.130, PPL=284.43
2025-09-22 01:39:14,151 - training.trainer - INFO - Epoch 40, Step 138419: Loss=5.2165, Acc=0.278, PPL=184.28
2025-09-22 01:39:22,087 - training.trainer - INFO - Epoch 40, Step 138519: Loss=5.6740, Acc=0.185, PPL=291.19
2025-09-22 01:39:30,120 - training.trainer - INFO - Epoch 40, Step 138619: Loss=5.0130, Acc=0.242, PPL=150.36
2025-09-22 01:39:47,648 - training.trainer - INFO - Epoch 41/100 completed in 280.75s - Train Loss: 5.5994, Train Acc: 0.264, Val Loss: 5.7008, Val Acc: 0.252
2025-09-22 01:39:48,327 - training.trainer - INFO - New best model saved with validation loss: 5.7008
2025-09-22 01:39:48,327 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_41.pt
2025-09-22 01:39:56,589 - training.trainer - INFO - Epoch 41, Step 138802: Loss=4.6515, Acc=0.276, PPL=104.74
2025-09-22 01:40:04,595 - training.trainer - INFO - Epoch 41, Step 138902: Loss=5.4797, Acc=0.250, PPL=239.78
2025-09-22 01:40:12,568 - training.trainer - INFO - Epoch 41, Step 139002: Loss=4.9203, Acc=0.333, PPL=137.05
2025-09-22 01:40:20,495 - training.trainer - INFO - Epoch 41, Step 139102: Loss=5.8421, Acc=0.207, PPL=344.50
2025-09-22 01:40:28,440 - training.trainer - INFO - Epoch 41, Step 139202: Loss=4.1702, Acc=0.387, PPL=64.73
2025-09-22 01:40:36,352 - training.trainer - INFO - Epoch 41, Step 139302: Loss=5.8113, Acc=0.257, PPL=334.04
2025-09-22 01:40:44,173 - training.trainer - INFO - Epoch 41, Step 139402: Loss=5.5077, Acc=0.250, PPL=246.57
2025-09-22 01:40:52,008 - training.trainer - INFO - Epoch 41, Step 139502: Loss=5.8691, Acc=0.154, PPL=353.93
2025-09-22 01:41:00,102 - training.trainer - INFO - Epoch 41, Step 139602: Loss=5.7849, Acc=0.211, PPL=325.34
2025-09-22 01:41:08,165 - training.trainer - INFO - Epoch 41, Step 139702: Loss=6.3233, Acc=0.140, PPL=557.39
2025-09-22 01:41:16,237 - training.trainer - INFO - Epoch 41, Step 139802: Loss=6.2150, Acc=0.118, PPL=500.19
2025-09-22 01:41:24,241 - training.trainer - INFO - Epoch 41, Step 139902: Loss=5.6872, Acc=0.327, PPL=295.07
2025-09-22 01:41:32,092 - training.trainer - INFO - Epoch 41, Step 140002: Loss=5.7575, Acc=0.244, PPL=316.57
2025-09-22 01:41:40,023 - training.trainer - INFO - Epoch 41, Step 140102: Loss=5.7559, Acc=0.167, PPL=316.05
2025-09-22 01:41:47,936 - training.trainer - INFO - Epoch 41, Step 140202: Loss=3.3817, Acc=0.611, PPL=29.42
2025-09-22 01:41:55,852 - training.trainer - INFO - Epoch 41, Step 140302: Loss=5.7425, Acc=0.259, PPL=311.83
2025-09-22 01:42:03,814 - training.trainer - INFO - Epoch 41, Step 140402: Loss=5.9945, Acc=0.294, PPL=401.21
2025-09-22 01:42:11,786 - training.trainer - INFO - Epoch 41, Step 140502: Loss=5.9228, Acc=0.150, PPL=373.45
2025-09-22 01:42:19,744 - training.trainer - INFO - Epoch 41, Step 140602: Loss=5.8874, Acc=0.247, PPL=360.45
2025-09-22 01:42:27,618 - training.trainer - INFO - Epoch 41, Step 140702: Loss=5.5304, Acc=0.288, PPL=252.25
2025-09-22 01:42:35,593 - training.trainer - INFO - Epoch 41, Step 140802: Loss=6.0933, Acc=0.139, PPL=442.86
2025-09-22 01:42:43,553 - training.trainer - INFO - Epoch 41, Step 140902: Loss=6.4984, Acc=0.175, PPL=664.05
2025-09-22 01:42:51,490 - training.trainer - INFO - Epoch 41, Step 141002: Loss=5.2155, Acc=0.273, PPL=184.11
2025-09-22 01:42:59,452 - training.trainer - INFO - Epoch 41, Step 141102: Loss=5.3892, Acc=0.281, PPL=219.04
2025-09-22 01:43:07,441 - training.trainer - INFO - Epoch 41, Step 141202: Loss=5.4748, Acc=0.316, PPL=238.60
2025-09-22 01:43:15,393 - training.trainer - INFO - Epoch 41, Step 141302: Loss=4.9641, Acc=0.333, PPL=143.18
2025-09-22 01:43:23,397 - training.trainer - INFO - Epoch 41, Step 141402: Loss=2.8160, Acc=0.697, PPL=16.71
2025-09-22 01:43:31,272 - training.trainer - INFO - Epoch 41, Step 141502: Loss=6.1350, Acc=0.184, PPL=461.75
2025-09-22 01:43:39,193 - training.trainer - INFO - Epoch 41, Step 141602: Loss=5.6287, Acc=0.259, PPL=278.31
2025-09-22 01:43:47,120 - training.trainer - INFO - Epoch 41, Step 141702: Loss=5.2076, Acc=0.273, PPL=182.65
2025-09-22 01:43:55,033 - training.trainer - INFO - Epoch 41, Step 141802: Loss=6.1998, Acc=0.294, PPL=492.67
2025-09-22 01:44:02,943 - training.trainer - INFO - Epoch 41, Step 141902: Loss=5.1210, Acc=0.246, PPL=167.50
2025-09-22 01:44:10,867 - training.trainer - INFO - Epoch 41, Step 142002: Loss=5.7868, Acc=0.275, PPL=325.96
2025-09-22 01:44:28,065 - training.trainer - INFO - Epoch 42/100 completed in 279.74s - Train Loss: 5.6004, Train Acc: 0.263, Val Loss: 5.6928, Val Acc: 0.251
2025-09-22 01:44:28,738 - training.trainer - INFO - New best model saved with validation loss: 5.6928
2025-09-22 01:44:28,738 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_42.pt
2025-09-22 01:44:36,921 - training.trainer - INFO - Epoch 42, Step 142185: Loss=4.4624, Acc=0.444, PPL=86.69
2025-09-22 01:44:44,811 - training.trainer - INFO - Epoch 42, Step 142285: Loss=5.5199, Acc=0.277, PPL=249.62
2025-09-22 01:44:52,705 - training.trainer - INFO - Epoch 42, Step 142385: Loss=5.4255, Acc=0.207, PPL=227.11
2025-09-22 01:45:00,646 - training.trainer - INFO - Epoch 42, Step 142485: Loss=5.4159, Acc=0.152, PPL=224.96
2025-09-22 01:45:08,480 - training.trainer - INFO - Epoch 42, Step 142585: Loss=5.0689, Acc=0.244, PPL=159.00
2025-09-22 01:45:16,343 - training.trainer - INFO - Epoch 42, Step 142685: Loss=6.2689, Acc=0.142, PPL=527.91
2025-09-22 01:45:24,226 - training.trainer - INFO - Epoch 42, Step 142785: Loss=5.6661, Acc=0.368, PPL=288.92
2025-09-22 01:45:32,234 - training.trainer - INFO - Epoch 42, Step 142885: Loss=5.8992, Acc=0.273, PPL=364.73
2025-09-22 01:45:40,080 - training.trainer - INFO - Epoch 42, Step 142985: Loss=5.5621, Acc=0.275, PPL=260.36
2025-09-22 01:45:47,996 - training.trainer - INFO - Epoch 42, Step 143085: Loss=6.1907, Acc=0.147, PPL=488.17
2025-09-22 01:45:55,915 - training.trainer - INFO - Epoch 42, Step 143185: Loss=6.1682, Acc=0.267, PPL=477.30
2025-09-22 01:46:03,909 - training.trainer - INFO - Epoch 42, Step 143285: Loss=5.8757, Acc=0.227, PPL=356.27
2025-09-22 01:46:11,790 - training.trainer - INFO - Epoch 42, Step 143385: Loss=3.6518, Acc=0.455, PPL=38.54
2025-09-22 01:46:19,662 - training.trainer - INFO - Epoch 42, Step 143485: Loss=5.9228, Acc=0.273, PPL=373.45
2025-09-22 01:46:27,512 - training.trainer - INFO - Epoch 42, Step 143585: Loss=6.1349, Acc=0.203, PPL=461.67
2025-09-22 01:46:35,490 - training.trainer - INFO - Epoch 42, Step 143685: Loss=5.2484, Acc=0.211, PPL=190.26
2025-09-22 01:46:43,386 - training.trainer - INFO - Epoch 42, Step 143785: Loss=4.1389, Acc=0.444, PPL=62.73
2025-09-22 01:46:51,263 - training.trainer - INFO - Epoch 42, Step 143885: Loss=6.4967, Acc=0.250, PPL=662.95
2025-09-22 01:46:59,195 - training.trainer - INFO - Epoch 42, Step 143985: Loss=4.6039, Acc=0.458, PPL=99.87
2025-09-22 01:47:07,173 - training.trainer - INFO - Epoch 42, Step 144085: Loss=5.4957, Acc=0.238, PPL=243.64
2025-09-22 01:47:15,127 - training.trainer - INFO - Epoch 42, Step 144185: Loss=5.2919, Acc=0.308, PPL=198.72
2025-09-22 01:47:22,994 - training.trainer - INFO - Epoch 42, Step 144285: Loss=5.7068, Acc=0.343, PPL=300.91
2025-09-22 01:47:30,937 - training.trainer - INFO - Epoch 42, Step 144385: Loss=6.0842, Acc=0.206, PPL=438.86
2025-09-22 01:47:38,907 - training.trainer - INFO - Epoch 42, Step 144485: Loss=5.8209, Acc=0.227, PPL=337.28
2025-09-22 01:47:46,863 - training.trainer - INFO - Epoch 42, Step 144585: Loss=4.7853, Acc=0.343, PPL=119.73
2025-09-22 01:47:54,733 - training.trainer - INFO - Epoch 42, Step 144685: Loss=5.4696, Acc=0.276, PPL=237.37
2025-09-22 01:48:02,690 - training.trainer - INFO - Epoch 42, Step 144785: Loss=5.2121, Acc=0.267, PPL=183.48
2025-09-22 01:48:10,592 - training.trainer - INFO - Epoch 42, Step 144885: Loss=5.3543, Acc=0.318, PPL=211.52
2025-09-22 01:48:18,497 - training.trainer - INFO - Epoch 42, Step 144985: Loss=5.5402, Acc=0.233, PPL=254.74
2025-09-22 01:48:26,443 - training.trainer - INFO - Epoch 42, Step 145085: Loss=6.0130, Acc=0.233, PPL=408.69
2025-09-22 01:48:34,282 - training.trainer - INFO - Epoch 42, Step 145185: Loss=6.1401, Acc=0.200, PPL=464.09
2025-09-22 01:48:42,183 - training.trainer - INFO - Epoch 42, Step 145285: Loss=5.9561, Acc=0.214, PPL=386.08
2025-09-22 01:48:50,284 - training.trainer - INFO - Epoch 42, Step 145385: Loss=5.9030, Acc=0.297, PPL=366.12
2025-09-22 01:49:07,855 - training.trainer - INFO - Epoch 43/100 completed in 279.12s - Train Loss: 5.5887, Train Acc: 0.265, Val Loss: 5.6975, Val Acc: 0.253
2025-09-22 01:49:15,997 - training.trainer - INFO - Epoch 43, Step 145568: Loss=3.6674, Acc=0.588, PPL=39.15
2025-09-22 01:49:24,111 - training.trainer - INFO - Epoch 43, Step 145668: Loss=5.9555, Acc=0.208, PPL=385.88
2025-09-22 01:49:32,322 - training.trainer - INFO - Epoch 43, Step 145768: Loss=5.4326, Acc=0.277, PPL=228.74
2025-09-22 01:49:40,362 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.0470, Acc=0.255, PPL=155.56
2025-09-22 01:49:48,391 - training.trainer - INFO - Epoch 43, Step 145968: Loss=6.4301, Acc=0.162, PPL=620.22
2025-09-22 01:49:56,441 - training.trainer - INFO - Epoch 43, Step 146068: Loss=4.9599, Acc=0.341, PPL=142.58
2025-09-22 01:50:04,354 - training.trainer - INFO - Epoch 43, Step 146168: Loss=5.5040, Acc=0.216, PPL=245.66
2025-09-22 01:50:12,353 - training.trainer - INFO - Epoch 43, Step 146268: Loss=5.6919, Acc=0.394, PPL=296.45
2025-09-22 01:50:20,178 - training.trainer - INFO - Epoch 43, Step 146368: Loss=6.1170, Acc=0.308, PPL=453.50
2025-09-22 01:50:28,091 - training.trainer - INFO - Epoch 43, Step 146468: Loss=5.4648, Acc=0.236, PPL=236.23
2025-09-22 01:50:35,894 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.7229, Acc=0.290, PPL=305.79
2025-09-22 01:50:43,715 - training.trainer - INFO - Epoch 43, Step 146668: Loss=6.0174, Acc=0.211, PPL=410.51
2025-09-22 01:50:51,536 - training.trainer - INFO - Epoch 43, Step 146768: Loss=6.0903, Acc=0.229, PPL=441.56
2025-09-22 01:50:59,425 - training.trainer - INFO - Epoch 43, Step 146868: Loss=6.1546, Acc=0.156, PPL=470.90
2025-09-22 01:51:07,297 - training.trainer - INFO - Epoch 43, Step 146968: Loss=5.4578, Acc=0.290, PPL=234.59
2025-09-22 01:51:15,099 - training.trainer - INFO - Epoch 43, Step 147068: Loss=5.4703, Acc=0.333, PPL=237.53
2025-09-22 01:51:22,875 - training.trainer - INFO - Epoch 43, Step 147168: Loss=5.2827, Acc=0.381, PPL=196.90
2025-09-22 01:51:30,762 - training.trainer - INFO - Epoch 43, Step 147268: Loss=5.2334, Acc=0.333, PPL=187.43
2025-09-22 01:51:38,580 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.3859, Acc=0.317, PPL=218.31
2025-09-22 01:51:46,369 - training.trainer - INFO - Epoch 43, Step 147468: Loss=5.8131, Acc=0.170, PPL=334.65
2025-09-22 01:51:54,229 - training.trainer - INFO - Epoch 43, Step 147568: Loss=5.9278, Acc=0.238, PPL=375.32
2025-09-22 01:52:02,060 - training.trainer - INFO - Epoch 43, Step 147668: Loss=4.8125, Acc=0.389, PPL=123.04
2025-09-22 01:52:09,887 - training.trainer - INFO - Epoch 43, Step 147768: Loss=5.8738, Acc=0.233, PPL=355.61
2025-09-22 01:52:17,701 - training.trainer - INFO - Epoch 43, Step 147868: Loss=6.3831, Acc=0.194, PPL=591.78
2025-09-22 01:52:25,489 - training.trainer - INFO - Epoch 43, Step 147968: Loss=6.0572, Acc=0.200, PPL=427.16
2025-09-22 01:52:33,317 - training.trainer - INFO - Epoch 43, Step 148068: Loss=6.0103, Acc=0.260, PPL=407.61
2025-09-22 01:52:41,070 - training.trainer - INFO - Epoch 43, Step 148168: Loss=5.5671, Acc=0.359, PPL=261.66
2025-09-22 01:52:48,843 - training.trainer - INFO - Epoch 43, Step 148268: Loss=5.9832, Acc=0.286, PPL=396.72
2025-09-22 01:52:56,585 - training.trainer - INFO - Epoch 43, Step 148368: Loss=4.7627, Acc=0.370, PPL=117.07
2025-09-22 01:53:04,363 - training.trainer - INFO - Epoch 43, Step 148468: Loss=5.2431, Acc=0.369, PPL=189.25
2025-09-22 01:53:12,188 - training.trainer - INFO - Epoch 43, Step 148568: Loss=5.6754, Acc=0.312, PPL=291.59
2025-09-22 01:53:19,996 - training.trainer - INFO - Epoch 43, Step 148668: Loss=5.7023, Acc=0.250, PPL=299.56
2025-09-22 01:53:27,777 - training.trainer - INFO - Epoch 43, Step 148768: Loss=4.9399, Acc=0.375, PPL=139.76
2025-09-22 01:53:44,680 - training.trainer - INFO - Epoch 44/100 completed in 276.83s - Train Loss: 5.5787, Train Acc: 0.267, Val Loss: 5.6878, Val Acc: 0.253
2025-09-22 01:53:45,420 - training.trainer - INFO - New best model saved with validation loss: 5.6878
2025-09-22 01:53:45,420 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_44.pt
2025-09-22 01:53:53,523 - training.trainer - INFO - Epoch 44, Step 148951: Loss=5.4634, Acc=0.269, PPL=235.90
2025-09-22 01:54:01,473 - training.trainer - INFO - Epoch 44, Step 149051: Loss=5.3957, Acc=0.275, PPL=220.45
2025-09-22 01:54:09,554 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.4821, Acc=0.259, PPL=240.36
2025-09-22 01:54:17,752 - training.trainer - INFO - Epoch 44, Step 149251: Loss=6.2482, Acc=0.233, PPL=517.10
2025-09-22 01:54:25,897 - training.trainer - INFO - Epoch 44, Step 149351: Loss=6.1104, Acc=0.188, PPL=450.52
2025-09-22 01:54:33,940 - training.trainer - INFO - Epoch 44, Step 149451: Loss=5.8660, Acc=0.227, PPL=352.82
2025-09-22 01:54:41,846 - training.trainer - INFO - Epoch 44, Step 149551: Loss=5.0093, Acc=0.250, PPL=149.81
2025-09-22 01:54:49,917 - training.trainer - INFO - Epoch 44, Step 149651: Loss=5.9327, Acc=0.256, PPL=377.17
2025-09-22 01:54:57,884 - training.trainer - INFO - Epoch 44, Step 149751: Loss=5.7755, Acc=0.255, PPL=322.31
2025-09-22 01:55:05,811 - training.trainer - INFO - Epoch 44, Step 149851: Loss=5.9149, Acc=0.216, PPL=370.51
2025-09-22 01:55:13,747 - training.trainer - INFO - Epoch 44, Step 149951: Loss=6.1410, Acc=0.225, PPL=464.51
2025-09-22 01:55:21,796 - training.trainer - INFO - Epoch 44, Step 150051: Loss=5.3807, Acc=0.267, PPL=217.17
2025-09-22 01:55:29,671 - training.trainer - INFO - Epoch 44, Step 150151: Loss=5.9989, Acc=0.190, PPL=402.97
2025-09-22 01:55:37,595 - training.trainer - INFO - Epoch 44, Step 150251: Loss=6.0045, Acc=0.291, PPL=405.23
2025-09-22 01:55:45,520 - training.trainer - INFO - Epoch 44, Step 150351: Loss=5.9901, Acc=0.182, PPL=399.46
2025-09-22 01:55:53,433 - training.trainer - INFO - Epoch 44, Step 150451: Loss=5.9950, Acc=0.114, PPL=401.41
2025-09-22 01:56:01,318 - training.trainer - INFO - Epoch 44, Step 150551: Loss=6.1036, Acc=0.083, PPL=447.48
2025-09-22 01:56:09,243 - training.trainer - INFO - Epoch 44, Step 150651: Loss=4.8354, Acc=0.474, PPL=125.89
2025-09-22 01:56:17,134 - training.trainer - INFO - Epoch 44, Step 150751: Loss=5.8959, Acc=0.158, PPL=363.54
2025-09-22 01:56:25,071 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.2428, Acc=0.222, PPL=189.21
2025-09-22 01:56:32,962 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.3222, Acc=0.281, PPL=204.84
2025-09-22 01:56:40,817 - training.trainer - INFO - Epoch 44, Step 151051: Loss=5.1238, Acc=0.358, PPL=167.97
2025-09-22 01:56:48,650 - training.trainer - INFO - Epoch 44, Step 151151: Loss=6.0711, Acc=0.133, PPL=433.14
2025-09-22 01:56:56,512 - training.trainer - INFO - Epoch 44, Step 151251: Loss=4.9817, Acc=0.375, PPL=145.72
2025-09-22 01:57:04,386 - training.trainer - INFO - Epoch 44, Step 151351: Loss=6.0631, Acc=0.219, PPL=429.69
2025-09-22 01:57:12,283 - training.trainer - INFO - Epoch 44, Step 151451: Loss=5.1940, Acc=0.293, PPL=180.18
2025-09-22 01:57:20,160 - training.trainer - INFO - Epoch 44, Step 151551: Loss=6.0593, Acc=0.235, PPL=428.08
2025-09-22 01:57:28,098 - training.trainer - INFO - Epoch 44, Step 151651: Loss=5.8566, Acc=0.298, PPL=349.53
2025-09-22 01:57:35,968 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.1446, Acc=0.308, PPL=171.50
2025-09-22 01:57:43,806 - training.trainer - INFO - Epoch 44, Step 151851: Loss=5.6233, Acc=0.299, PPL=276.80
2025-09-22 01:57:51,687 - training.trainer - INFO - Epoch 44, Step 151951: Loss=6.0381, Acc=0.167, PPL=419.10
2025-09-22 01:57:59,638 - training.trainer - INFO - Epoch 44, Step 152051: Loss=5.9612, Acc=0.203, PPL=388.06
2025-09-22 01:58:07,618 - training.trainer - INFO - Epoch 44, Step 152151: Loss=5.6959, Acc=0.261, PPL=297.64
2025-09-22 01:58:24,662 - training.trainer - INFO - Epoch 45/100 completed in 279.24s - Train Loss: 5.5725, Train Acc: 0.269, Val Loss: 5.6962, Val Acc: 0.251
2025-09-22 01:58:24,956 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-22 01:58:33,114 - training.trainer - INFO - Epoch 45, Step 152334: Loss=6.3699, Acc=0.219, PPL=583.99
2025-09-22 01:58:41,213 - training.trainer - INFO - Epoch 45, Step 152434: Loss=5.1994, Acc=0.261, PPL=181.16
2025-09-22 01:58:49,226 - training.trainer - INFO - Epoch 45, Step 152534: Loss=5.5150, Acc=0.215, PPL=248.38
2025-09-22 01:58:57,175 - training.trainer - INFO - Epoch 45, Step 152634: Loss=6.2165, Acc=0.194, PPL=500.93
2025-09-22 01:59:05,097 - training.trainer - INFO - Epoch 45, Step 152734: Loss=5.2740, Acc=0.346, PPL=195.19
2025-09-22 01:59:13,137 - training.trainer - INFO - Epoch 45, Step 152834: Loss=5.8975, Acc=0.195, PPL=364.12
2025-09-22 01:59:20,957 - training.trainer - INFO - Epoch 45, Step 152934: Loss=6.0642, Acc=0.257, PPL=430.19
2025-09-22 01:59:28,790 - training.trainer - INFO - Epoch 45, Step 153034: Loss=5.6114, Acc=0.270, PPL=273.52
2025-09-22 01:59:36,590 - training.trainer - INFO - Epoch 45, Step 153134: Loss=5.6965, Acc=0.310, PPL=297.82
2025-09-22 01:59:44,464 - training.trainer - INFO - Epoch 45, Step 153234: Loss=5.5878, Acc=0.355, PPL=267.14
2025-09-22 01:59:52,406 - training.trainer - INFO - Epoch 45, Step 153334: Loss=5.6585, Acc=0.185, PPL=286.71
2025-09-22 02:00:00,237 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.6263, Acc=0.184, PPL=277.62
2025-09-22 02:00:08,066 - training.trainer - INFO - Epoch 45, Step 153534: Loss=5.4604, Acc=0.306, PPL=235.19
2025-09-22 02:00:15,951 - training.trainer - INFO - Epoch 45, Step 153634: Loss=5.7754, Acc=0.250, PPL=322.27
2025-09-22 02:00:23,886 - training.trainer - INFO - Epoch 45, Step 153734: Loss=4.0460, Acc=0.538, PPL=57.17
2025-09-22 02:00:31,772 - training.trainer - INFO - Epoch 45, Step 153834: Loss=4.6879, Acc=0.467, PPL=108.63
2025-09-22 02:00:39,628 - training.trainer - INFO - Epoch 45, Step 153934: Loss=5.9699, Acc=0.220, PPL=391.47
2025-09-22 02:00:47,508 - training.trainer - INFO - Epoch 45, Step 154034: Loss=5.7159, Acc=0.241, PPL=303.65
2025-09-22 02:00:55,477 - training.trainer - INFO - Epoch 45, Step 154134: Loss=5.8436, Acc=0.200, PPL=345.02
2025-09-22 02:01:03,554 - training.trainer - INFO - Epoch 45, Step 154234: Loss=5.8653, Acc=0.279, PPL=352.57
2025-09-22 02:01:11,659 - training.trainer - INFO - Epoch 45, Step 154334: Loss=6.3003, Acc=0.186, PPL=544.76
2025-09-22 02:01:19,651 - training.trainer - INFO - Epoch 45, Step 154434: Loss=5.6298, Acc=0.176, PPL=278.61
2025-09-22 02:01:27,591 - training.trainer - INFO - Epoch 45, Step 154534: Loss=6.1933, Acc=0.275, PPL=489.46
2025-09-22 02:01:35,473 - training.trainer - INFO - Epoch 45, Step 154634: Loss=6.3704, Acc=0.235, PPL=584.30
2025-09-22 02:01:43,376 - training.trainer - INFO - Epoch 45, Step 154734: Loss=5.8983, Acc=0.209, PPL=364.41
2025-09-22 02:01:51,383 - training.trainer - INFO - Epoch 45, Step 154834: Loss=6.2075, Acc=0.190, PPL=496.44
2025-09-22 02:01:59,353 - training.trainer - INFO - Epoch 45, Step 154934: Loss=5.6729, Acc=0.286, PPL=290.87
2025-09-22 02:02:07,362 - training.trainer - INFO - Epoch 45, Step 155034: Loss=5.6060, Acc=0.292, PPL=272.04
2025-09-22 02:02:15,273 - training.trainer - INFO - Epoch 45, Step 155134: Loss=4.9063, Acc=0.421, PPL=135.13
2025-09-22 02:02:23,274 - training.trainer - INFO - Epoch 45, Step 155234: Loss=5.1298, Acc=0.320, PPL=168.99
2025-09-22 02:02:31,221 - training.trainer - INFO - Epoch 45, Step 155334: Loss=5.8234, Acc=0.209, PPL=338.13
2025-09-22 02:02:39,139 - training.trainer - INFO - Epoch 45, Step 155434: Loss=6.1355, Acc=0.188, PPL=461.96
2025-09-22 02:02:47,061 - training.trainer - INFO - Epoch 45, Step 155534: Loss=5.9022, Acc=0.268, PPL=365.84
2025-09-22 02:03:04,003 - training.trainer - INFO - Epoch 46/100 completed in 279.05s - Train Loss: 5.5677, Train Acc: 0.269, Val Loss: 5.6895, Val Acc: 0.254
2025-09-22 02:03:12,309 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.3832, Acc=0.233, PPL=217.72
2025-09-22 02:03:20,333 - training.trainer - INFO - Epoch 46, Step 155817: Loss=5.8010, Acc=0.318, PPL=330.65
2025-09-22 02:03:28,381 - training.trainer - INFO - Epoch 46, Step 155917: Loss=5.5534, Acc=0.321, PPL=258.11
2025-09-22 02:03:36,314 - training.trainer - INFO - Epoch 46, Step 156017: Loss=6.3474, Acc=0.184, PPL=571.01
2025-09-22 02:03:44,268 - training.trainer - INFO - Epoch 46, Step 156117: Loss=5.7180, Acc=0.212, PPL=304.28
2025-09-22 02:03:52,233 - training.trainer - INFO - Epoch 46, Step 156217: Loss=5.9343, Acc=0.273, PPL=377.78
2025-09-22 02:04:00,130 - training.trainer - INFO - Epoch 46, Step 156317: Loss=5.2917, Acc=0.229, PPL=198.69
2025-09-22 02:04:08,113 - training.trainer - INFO - Epoch 46, Step 156417: Loss=5.9174, Acc=0.217, PPL=371.45
2025-09-22 02:04:16,006 - training.trainer - INFO - Epoch 46, Step 156517: Loss=5.8296, Acc=0.171, PPL=340.24
2025-09-22 02:04:23,877 - training.trainer - INFO - Epoch 46, Step 156617: Loss=5.7103, Acc=0.318, PPL=301.95
2025-09-22 02:04:31,851 - training.trainer - INFO - Epoch 46, Step 156717: Loss=6.2637, Acc=0.179, PPL=525.15
2025-09-22 02:04:39,796 - training.trainer - INFO - Epoch 46, Step 156817: Loss=4.6782, Acc=0.368, PPL=107.58
2025-09-22 02:04:47,701 - training.trainer - INFO - Epoch 46, Step 156917: Loss=5.6840, Acc=0.268, PPL=294.11
2025-09-22 02:04:55,598 - training.trainer - INFO - Epoch 46, Step 157017: Loss=4.9019, Acc=0.316, PPL=134.54
2025-09-22 02:05:03,471 - training.trainer - INFO - Epoch 46, Step 157117: Loss=5.3770, Acc=0.282, PPL=216.38
2025-09-22 02:05:11,393 - training.trainer - INFO - Epoch 46, Step 157217: Loss=4.5800, Acc=0.395, PPL=97.52
2025-09-22 02:05:19,325 - training.trainer - INFO - Epoch 46, Step 157317: Loss=6.6937, Acc=0.231, PPL=807.31
2025-09-22 02:05:27,259 - training.trainer - INFO - Epoch 46, Step 157417: Loss=5.2981, Acc=0.370, PPL=199.96
2025-09-22 02:05:35,226 - training.trainer - INFO - Epoch 46, Step 157517: Loss=4.0993, Acc=0.524, PPL=60.30
2025-09-22 02:05:43,257 - training.trainer - INFO - Epoch 46, Step 157617: Loss=5.1721, Acc=0.290, PPL=176.28
2025-09-22 02:05:51,181 - training.trainer - INFO - Epoch 46, Step 157717: Loss=5.2161, Acc=0.250, PPL=184.21
2025-09-22 02:05:59,121 - training.trainer - INFO - Epoch 46, Step 157817: Loss=5.7810, Acc=0.200, PPL=324.09
2025-09-22 02:06:07,085 - training.trainer - INFO - Epoch 46, Step 157917: Loss=5.9810, Acc=0.312, PPL=395.84
2025-09-22 02:06:14,928 - training.trainer - INFO - Epoch 46, Step 158017: Loss=5.3935, Acc=0.282, PPL=219.97
2025-09-22 02:06:22,715 - training.trainer - INFO - Epoch 46, Step 158117: Loss=5.0508, Acc=0.381, PPL=156.14
2025-09-22 02:06:30,533 - training.trainer - INFO - Epoch 46, Step 158217: Loss=4.7161, Acc=0.333, PPL=111.73
2025-09-22 02:06:38,422 - training.trainer - INFO - Epoch 46, Step 158317: Loss=5.5169, Acc=0.261, PPL=248.86
2025-09-22 02:06:46,359 - training.trainer - INFO - Epoch 46, Step 158417: Loss=6.0694, Acc=0.176, PPL=432.43
2025-09-22 02:06:54,462 - training.trainer - INFO - Epoch 46, Step 158517: Loss=3.6481, Acc=0.533, PPL=38.40
2025-09-22 02:07:02,512 - training.trainer - INFO - Epoch 46, Step 158617: Loss=6.5147, Acc=0.222, PPL=675.01
2025-09-22 02:07:10,443 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.7573, Acc=0.212, PPL=316.48
2025-09-22 02:07:18,441 - training.trainer - INFO - Epoch 46, Step 158817: Loss=4.5738, Acc=0.321, PPL=96.92
2025-09-22 02:07:26,401 - training.trainer - INFO - Epoch 46, Step 158917: Loss=5.6500, Acc=0.222, PPL=284.28
2025-09-22 02:07:43,335 - training.trainer - INFO - Epoch 47/100 completed in 279.33s - Train Loss: 5.5574, Train Acc: 0.270, Val Loss: 5.7064, Val Acc: 0.249
2025-09-22 02:07:51,207 - training.trainer - INFO - Epoch 47, Step 159100: Loss=5.4792, Acc=0.294, PPL=239.65
2025-09-22 02:07:59,147 - training.trainer - INFO - Epoch 47, Step 159200: Loss=6.0518, Acc=0.178, PPL=424.88
2025-09-22 02:08:07,062 - training.trainer - INFO - Epoch 47, Step 159300: Loss=5.5490, Acc=0.258, PPL=256.97
2025-09-22 02:08:15,011 - training.trainer - INFO - Epoch 47, Step 159400: Loss=5.2591, Acc=0.367, PPL=192.30
2025-09-22 02:08:22,913 - training.trainer - INFO - Epoch 47, Step 159500: Loss=5.2206, Acc=0.409, PPL=185.05
2025-09-22 02:08:30,843 - training.trainer - INFO - Epoch 47, Step 159600: Loss=5.5339, Acc=0.250, PPL=253.14
2025-09-22 02:08:38,736 - training.trainer - INFO - Epoch 47, Step 159700: Loss=4.8729, Acc=0.350, PPL=130.69
2025-09-22 02:08:46,642 - training.trainer - INFO - Epoch 47, Step 159800: Loss=4.8285, Acc=0.367, PPL=125.02
2025-09-22 02:08:54,514 - training.trainer - INFO - Epoch 47, Step 159900: Loss=5.9731, Acc=0.206, PPL=392.71
2025-09-22 02:09:02,446 - training.trainer - INFO - Epoch 47, Step 160000: Loss=5.7737, Acc=0.361, PPL=321.73
2025-09-22 02:09:10,352 - training.trainer - INFO - Epoch 47, Step 160100: Loss=5.2103, Acc=0.368, PPL=183.15
2025-09-22 02:09:18,254 - training.trainer - INFO - Epoch 47, Step 160200: Loss=5.9097, Acc=0.190, PPL=368.60
2025-09-22 02:09:26,278 - training.trainer - INFO - Epoch 47, Step 160300: Loss=5.3118, Acc=0.288, PPL=202.72
2025-09-22 02:09:34,449 - training.trainer - INFO - Epoch 47, Step 160400: Loss=5.9968, Acc=0.195, PPL=402.14
2025-09-22 02:09:42,541 - training.trainer - INFO - Epoch 47, Step 160500: Loss=6.1049, Acc=0.250, PPL=448.03
2025-09-22 02:09:50,582 - training.trainer - INFO - Epoch 47, Step 160600: Loss=5.8451, Acc=0.208, PPL=345.53
2025-09-22 02:09:58,500 - training.trainer - INFO - Epoch 47, Step 160700: Loss=5.5759, Acc=0.258, PPL=263.99
2025-09-22 02:10:06,498 - training.trainer - INFO - Epoch 47, Step 160800: Loss=5.9262, Acc=0.250, PPL=374.72
2025-09-22 02:10:14,429 - training.trainer - INFO - Epoch 47, Step 160900: Loss=6.5192, Acc=0.200, PPL=678.03
2025-09-22 02:10:22,299 - training.trainer - INFO - Epoch 47, Step 161000: Loss=4.8114, Acc=0.310, PPL=122.90
2025-09-22 02:10:30,162 - training.trainer - INFO - Epoch 47, Step 161100: Loss=5.9412, Acc=0.143, PPL=380.40
2025-09-22 02:10:38,047 - training.trainer - INFO - Epoch 47, Step 161200: Loss=5.2862, Acc=0.327, PPL=197.59
2025-09-22 02:10:45,960 - training.trainer - INFO - Epoch 47, Step 161300: Loss=5.1954, Acc=0.241, PPL=180.44
2025-09-22 02:10:53,870 - training.trainer - INFO - Epoch 47, Step 161400: Loss=5.4727, Acc=0.241, PPL=238.10
2025-09-22 02:11:01,727 - training.trainer - INFO - Epoch 47, Step 161500: Loss=5.5882, Acc=0.200, PPL=267.26
2025-09-22 02:11:09,663 - training.trainer - INFO - Epoch 47, Step 161600: Loss=4.3113, Acc=0.429, PPL=74.53
2025-09-22 02:11:17,549 - training.trainer - INFO - Epoch 47, Step 161700: Loss=5.7054, Acc=0.280, PPL=300.47
2025-09-22 02:11:25,401 - training.trainer - INFO - Epoch 47, Step 161800: Loss=5.6491, Acc=0.222, PPL=284.03
2025-09-22 02:11:33,298 - training.trainer - INFO - Epoch 47, Step 161900: Loss=4.9871, Acc=0.438, PPL=146.51
2025-09-22 02:11:41,285 - training.trainer - INFO - Epoch 47, Step 162000: Loss=5.6192, Acc=0.226, PPL=275.66
2025-09-22 02:11:49,167 - training.trainer - INFO - Epoch 47, Step 162100: Loss=5.0166, Acc=0.333, PPL=150.89
2025-09-22 02:11:57,111 - training.trainer - INFO - Epoch 47, Step 162200: Loss=5.1721, Acc=0.379, PPL=176.29
2025-09-22 02:12:05,002 - training.trainer - INFO - Epoch 47, Step 162300: Loss=5.8693, Acc=0.206, PPL=354.01
2025-09-22 02:12:22,155 - training.trainer - INFO - Epoch 48/100 completed in 278.82s - Train Loss: 5.5498, Train Acc: 0.273, Val Loss: 5.6846, Val Acc: 0.253
2025-09-22 02:12:22,741 - training.trainer - INFO - New best model saved with validation loss: 5.6846
2025-09-22 02:12:22,741 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_48.pt
2025-09-22 02:12:31,045 - training.trainer - INFO - Epoch 48, Step 162483: Loss=4.2930, Acc=0.474, PPL=73.18
2025-09-22 02:12:38,970 - training.trainer - INFO - Epoch 48, Step 162583: Loss=6.2497, Acc=0.250, PPL=517.85
2025-09-22 02:12:46,915 - training.trainer - INFO - Epoch 48, Step 162683: Loss=6.0439, Acc=0.246, PPL=421.53
2025-09-22 02:12:54,801 - training.trainer - INFO - Epoch 48, Step 162783: Loss=5.4718, Acc=0.250, PPL=237.89
2025-09-22 02:13:02,723 - training.trainer - INFO - Epoch 48, Step 162883: Loss=3.9980, Acc=0.417, PPL=54.49
2025-09-22 02:13:10,803 - training.trainer - INFO - Epoch 48, Step 162983: Loss=4.4278, Acc=0.364, PPL=83.75
2025-09-22 02:13:18,857 - training.trainer - INFO - Epoch 48, Step 163083: Loss=5.2110, Acc=0.286, PPL=183.27
2025-09-22 02:13:26,790 - training.trainer - INFO - Epoch 48, Step 163183: Loss=5.6410, Acc=0.254, PPL=281.74
2025-09-22 02:13:34,782 - training.trainer - INFO - Epoch 48, Step 163283: Loss=5.8076, Acc=0.229, PPL=332.83
2025-09-22 02:13:42,800 - training.trainer - INFO - Epoch 48, Step 163383: Loss=5.3290, Acc=0.400, PPL=206.23
2025-09-22 02:13:50,776 - training.trainer - INFO - Epoch 48, Step 163483: Loss=4.4837, Acc=0.417, PPL=88.56
2025-09-22 02:13:58,820 - training.trainer - INFO - Epoch 48, Step 163583: Loss=6.8453, Acc=0.182, PPL=939.46
2025-09-22 02:14:06,800 - training.trainer - INFO - Epoch 48, Step 163683: Loss=5.3451, Acc=0.270, PPL=209.58
2025-09-22 02:14:14,719 - training.trainer - INFO - Epoch 48, Step 163783: Loss=4.5840, Acc=0.323, PPL=97.90
2025-09-22 02:14:22,567 - training.trainer - INFO - Epoch 48, Step 163883: Loss=4.7263, Acc=0.312, PPL=112.88
2025-09-22 02:14:30,498 - training.trainer - INFO - Epoch 48, Step 163983: Loss=5.9063, Acc=0.295, PPL=367.35
2025-09-22 02:14:38,378 - training.trainer - INFO - Epoch 48, Step 164083: Loss=6.2373, Acc=0.178, PPL=511.49
2025-09-22 02:14:46,226 - training.trainer - INFO - Epoch 48, Step 164183: Loss=5.6680, Acc=0.196, PPL=289.46
2025-09-22 02:14:54,113 - training.trainer - INFO - Epoch 48, Step 164283: Loss=5.7622, Acc=0.250, PPL=318.03
2025-09-22 02:15:02,034 - training.trainer - INFO - Epoch 48, Step 164383: Loss=5.6270, Acc=0.286, PPL=277.82
2025-09-22 02:15:09,942 - training.trainer - INFO - Epoch 48, Step 164483: Loss=5.3268, Acc=0.250, PPL=205.77
2025-09-22 02:15:17,805 - training.trainer - INFO - Epoch 48, Step 164583: Loss=5.0780, Acc=0.250, PPL=160.46
2025-09-22 02:15:25,700 - training.trainer - INFO - Epoch 48, Step 164683: Loss=5.5192, Acc=0.222, PPL=249.44
2025-09-22 02:15:33,616 - training.trainer - INFO - Epoch 48, Step 164783: Loss=4.9066, Acc=0.350, PPL=135.18
2025-09-22 02:15:41,531 - training.trainer - INFO - Epoch 48, Step 164883: Loss=5.3762, Acc=0.192, PPL=216.19
2025-09-22 02:15:49,560 - training.trainer - INFO - Epoch 48, Step 164983: Loss=5.1804, Acc=0.310, PPL=177.76
2025-09-22 02:15:57,584 - training.trainer - INFO - Epoch 48, Step 165083: Loss=5.9646, Acc=0.235, PPL=389.42
2025-09-22 02:16:05,681 - training.trainer - INFO - Epoch 48, Step 165183: Loss=5.6085, Acc=0.279, PPL=272.74
2025-09-22 02:16:13,657 - training.trainer - INFO - Epoch 48, Step 165283: Loss=5.7389, Acc=0.182, PPL=310.74
2025-09-22 02:16:21,708 - training.trainer - INFO - Epoch 48, Step 165383: Loss=5.8276, Acc=0.289, PPL=339.54
2025-09-22 02:16:29,674 - training.trainer - INFO - Epoch 48, Step 165483: Loss=5.6175, Acc=0.238, PPL=275.20
2025-09-22 02:16:37,745 - training.trainer - INFO - Epoch 48, Step 165583: Loss=5.8403, Acc=0.300, PPL=343.88
2025-09-22 02:16:45,687 - training.trainer - INFO - Epoch 48, Step 165683: Loss=5.4558, Acc=0.240, PPL=234.11
2025-09-22 02:17:02,665 - training.trainer - INFO - Epoch 49/100 completed in 279.92s - Train Loss: 5.5428, Train Acc: 0.273, Val Loss: 5.6870, Val Acc: 0.255
2025-09-22 02:17:10,997 - training.trainer - INFO - Epoch 49, Step 165866: Loss=6.3703, Acc=0.189, PPL=584.26
2025-09-22 02:17:19,102 - training.trainer - INFO - Epoch 49, Step 165966: Loss=5.1538, Acc=0.290, PPL=173.09
2025-09-22 02:17:27,068 - training.trainer - INFO - Epoch 49, Step 166066: Loss=5.0752, Acc=0.273, PPL=160.01
2025-09-22 02:17:34,987 - training.trainer - INFO - Epoch 49, Step 166166: Loss=5.8593, Acc=0.161, PPL=350.48
2025-09-22 02:17:43,082 - training.trainer - INFO - Epoch 49, Step 166266: Loss=3.7350, Acc=0.621, PPL=41.89
2025-09-22 02:17:50,988 - training.trainer - INFO - Epoch 49, Step 166366: Loss=5.7669, Acc=0.200, PPL=319.56
2025-09-22 02:17:58,949 - training.trainer - INFO - Epoch 49, Step 166466: Loss=5.9422, Acc=0.203, PPL=380.77
2025-09-22 02:18:06,983 - training.trainer - INFO - Epoch 49, Step 166566: Loss=4.0132, Acc=0.500, PPL=55.32
2025-09-22 02:18:15,124 - training.trainer - INFO - Epoch 49, Step 166666: Loss=5.5349, Acc=0.277, PPL=253.39
2025-09-22 02:18:23,190 - training.trainer - INFO - Epoch 49, Step 166766: Loss=4.0341, Acc=0.471, PPL=56.49
2025-09-22 02:18:31,235 - training.trainer - INFO - Epoch 49, Step 166866: Loss=5.4898, Acc=0.194, PPL=242.21
2025-09-22 02:18:39,275 - training.trainer - INFO - Epoch 49, Step 166966: Loss=6.6261, Acc=0.185, PPL=754.50
2025-09-22 02:18:47,171 - training.trainer - INFO - Epoch 49, Step 167066: Loss=6.3823, Acc=0.133, PPL=591.26
2025-09-22 02:18:55,128 - training.trainer - INFO - Epoch 49, Step 167166: Loss=6.2405, Acc=0.333, PPL=513.14
2025-09-22 02:19:03,156 - training.trainer - INFO - Epoch 49, Step 167266: Loss=5.4078, Acc=0.304, PPL=223.14
2025-09-22 02:19:11,161 - training.trainer - INFO - Epoch 49, Step 167366: Loss=5.3790, Acc=0.259, PPL=216.80
2025-09-22 02:19:19,136 - training.trainer - INFO - Epoch 49, Step 167466: Loss=5.2102, Acc=0.349, PPL=183.13
2025-09-22 02:19:27,016 - training.trainer - INFO - Epoch 49, Step 167566: Loss=6.0390, Acc=0.257, PPL=419.48
2025-09-22 02:19:34,968 - training.trainer - INFO - Epoch 49, Step 167666: Loss=6.3516, Acc=0.235, PPL=573.40
2025-09-22 02:19:42,928 - training.trainer - INFO - Epoch 49, Step 167766: Loss=4.5857, Acc=0.200, PPL=98.07
2025-09-22 02:19:50,839 - training.trainer - INFO - Epoch 49, Step 167866: Loss=5.7567, Acc=0.224, PPL=316.31
2025-09-22 02:19:58,780 - training.trainer - INFO - Epoch 49, Step 167966: Loss=5.9257, Acc=0.133, PPL=374.55
2025-09-22 02:20:06,775 - training.trainer - INFO - Epoch 49, Step 168066: Loss=5.4092, Acc=0.250, PPL=223.45
2025-09-22 02:20:14,692 - training.trainer - INFO - Epoch 49, Step 168166: Loss=5.9584, Acc=0.195, PPL=387.00
2025-09-22 02:20:22,682 - training.trainer - INFO - Epoch 49, Step 168266: Loss=5.1518, Acc=0.375, PPL=172.74
2025-09-22 02:20:30,621 - training.trainer - INFO - Epoch 49, Step 168366: Loss=4.9587, Acc=0.386, PPL=142.41
2025-09-22 02:20:38,534 - training.trainer - INFO - Epoch 49, Step 168466: Loss=6.0988, Acc=0.176, PPL=445.33
2025-09-22 02:20:46,460 - training.trainer - INFO - Epoch 49, Step 168566: Loss=4.8996, Acc=0.231, PPL=134.24
2025-09-22 02:20:54,372 - training.trainer - INFO - Epoch 49, Step 168666: Loss=5.7899, Acc=0.206, PPL=326.97
2025-09-22 02:21:02,428 - training.trainer - INFO - Epoch 49, Step 168766: Loss=5.0593, Acc=0.280, PPL=157.48
2025-09-22 02:21:10,366 - training.trainer - INFO - Epoch 49, Step 168866: Loss=4.1832, Acc=0.571, PPL=65.57
2025-09-22 02:21:18,265 - training.trainer - INFO - Epoch 49, Step 168966: Loss=5.1129, Acc=0.259, PPL=166.15
2025-09-22 02:21:26,195 - training.trainer - INFO - Epoch 49, Step 169066: Loss=5.3632, Acc=0.220, PPL=213.42
2025-09-22 02:21:43,146 - training.trainer - INFO - Epoch 50/100 completed in 280.48s - Train Loss: 5.5299, Train Acc: 0.275, Val Loss: 5.6950, Val Acc: 0.254
2025-09-22 02:21:43,537 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-22 02:21:51,862 - training.trainer - INFO - Epoch 50, Step 169249: Loss=5.2469, Acc=0.229, PPL=189.97
2025-09-22 02:21:59,852 - training.trainer - INFO - Epoch 50, Step 169349: Loss=5.9531, Acc=0.140, PPL=384.96
2025-09-22 02:22:07,993 - training.trainer - INFO - Epoch 50, Step 169449: Loss=5.0763, Acc=0.440, PPL=160.18
2025-09-22 02:22:16,017 - training.trainer - INFO - Epoch 50, Step 169549: Loss=5.7902, Acc=0.246, PPL=327.08
2025-09-22 02:22:24,068 - training.trainer - INFO - Epoch 50, Step 169649: Loss=5.4500, Acc=0.409, PPL=232.77
2025-09-22 02:22:32,305 - training.trainer - INFO - Epoch 50, Step 169749: Loss=5.6781, Acc=0.269, PPL=292.39
2025-09-22 02:22:40,456 - training.trainer - INFO - Epoch 50, Step 169849: Loss=5.1779, Acc=0.323, PPL=177.31
2025-09-22 02:22:48,394 - training.trainer - INFO - Epoch 50, Step 169949: Loss=3.8912, Acc=0.412, PPL=48.97
2025-09-22 02:22:56,341 - training.trainer - INFO - Epoch 50, Step 170049: Loss=4.6892, Acc=0.417, PPL=108.77
2025-09-22 02:23:04,501 - training.trainer - INFO - Epoch 50, Step 170149: Loss=6.1486, Acc=0.235, PPL=468.04
2025-09-22 02:23:12,693 - training.trainer - INFO - Epoch 50, Step 170249: Loss=5.9794, Acc=0.156, PPL=395.19
2025-09-22 02:23:20,784 - training.trainer - INFO - Epoch 50, Step 170349: Loss=5.7963, Acc=0.244, PPL=329.08
2025-09-22 02:23:28,907 - training.trainer - INFO - Epoch 50, Step 170449: Loss=5.2279, Acc=0.333, PPL=186.40
2025-09-22 02:23:36,985 - training.trainer - INFO - Epoch 50, Step 170549: Loss=4.7229, Acc=0.333, PPL=112.49
2025-09-22 02:23:44,972 - training.trainer - INFO - Epoch 50, Step 170649: Loss=6.0359, Acc=0.256, PPL=418.17
2025-09-22 02:23:52,929 - training.trainer - INFO - Epoch 50, Step 170749: Loss=4.8595, Acc=0.478, PPL=128.95
2025-09-22 02:24:00,877 - training.trainer - INFO - Epoch 50, Step 170849: Loss=5.0951, Acc=0.311, PPL=163.22
2025-09-22 02:24:08,800 - training.trainer - INFO - Epoch 50, Step 170949: Loss=5.6380, Acc=0.381, PPL=280.91
2025-09-22 02:24:16,705 - training.trainer - INFO - Epoch 50, Step 171049: Loss=5.2776, Acc=0.350, PPL=195.90
2025-09-22 02:24:24,578 - training.trainer - INFO - Epoch 50, Step 171149: Loss=5.7929, Acc=0.240, PPL=327.95
2025-09-22 02:24:32,422 - training.trainer - INFO - Epoch 50, Step 171249: Loss=5.6566, Acc=0.231, PPL=286.18
2025-09-22 02:24:40,412 - training.trainer - INFO - Epoch 50, Step 171349: Loss=5.9259, Acc=0.221, PPL=374.61
2025-09-22 02:24:48,609 - training.trainer - INFO - Epoch 50, Step 171449: Loss=5.7800, Acc=0.200, PPL=323.74
2025-09-22 02:24:56,619 - training.trainer - INFO - Epoch 50, Step 171549: Loss=6.2509, Acc=0.250, PPL=518.48
2025-09-22 02:25:04,615 - training.trainer - INFO - Epoch 50, Step 171649: Loss=4.4747, Acc=0.300, PPL=87.77
2025-09-22 02:25:12,454 - training.trainer - INFO - Epoch 50, Step 171749: Loss=4.8655, Acc=0.304, PPL=129.74
2025-09-22 02:25:20,413 - training.trainer - INFO - Epoch 50, Step 171849: Loss=5.4008, Acc=0.258, PPL=221.57
2025-09-22 02:25:28,366 - training.trainer - INFO - Epoch 50, Step 171949: Loss=5.2411, Acc=0.300, PPL=188.87
2025-09-22 02:25:36,322 - training.trainer - INFO - Epoch 50, Step 172049: Loss=6.2167, Acc=0.269, PPL=501.03
2025-09-22 02:25:44,298 - training.trainer - INFO - Epoch 50, Step 172149: Loss=5.7090, Acc=0.344, PPL=301.56
2025-09-22 02:25:52,242 - training.trainer - INFO - Epoch 50, Step 172249: Loss=5.9901, Acc=0.257, PPL=399.45
2025-09-22 02:26:00,148 - training.trainer - INFO - Epoch 50, Step 172349: Loss=5.5421, Acc=0.235, PPL=255.21
2025-09-22 02:26:08,129 - training.trainer - INFO - Epoch 50, Step 172449: Loss=5.8613, Acc=0.235, PPL=351.19
2025-09-22 02:26:24,758 - training.trainer - INFO - Epoch 51/100 completed in 281.22s - Train Loss: 5.5262, Train Acc: 0.276, Val Loss: 5.6804, Val Acc: 0.255
2025-09-22 02:26:25,340 - training.trainer - INFO - New best model saved with validation loss: 5.6804
2025-09-22 02:26:25,340 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_51.pt
2025-09-22 02:26:33,535 - training.trainer - INFO - Epoch 51, Step 172632: Loss=5.8449, Acc=0.222, PPL=345.48
2025-09-22 02:26:41,553 - training.trainer - INFO - Epoch 51, Step 172732: Loss=4.5986, Acc=0.417, PPL=99.35
2025-09-22 02:26:49,441 - training.trainer - INFO - Epoch 51, Step 172832: Loss=6.2380, Acc=0.214, PPL=511.83
2025-09-22 02:26:57,603 - training.trainer - INFO - Epoch 51, Step 172932: Loss=6.0468, Acc=0.263, PPL=422.74
2025-09-22 02:27:05,727 - training.trainer - INFO - Epoch 51, Step 173032: Loss=6.2379, Acc=0.196, PPL=511.80
2025-09-22 02:27:13,790 - training.trainer - INFO - Epoch 51, Step 173132: Loss=5.9570, Acc=0.271, PPL=386.45
2025-09-22 02:27:21,782 - training.trainer - INFO - Epoch 51, Step 173232: Loss=6.0035, Acc=0.158, PPL=404.83
2025-09-22 02:27:29,661 - training.trainer - INFO - Epoch 51, Step 173332: Loss=5.8548, Acc=0.308, PPL=348.92
2025-09-22 02:27:37,656 - training.trainer - INFO - Epoch 51, Step 173432: Loss=5.8100, Acc=0.146, PPL=333.63
2025-09-22 02:27:45,635 - training.trainer - INFO - Epoch 51, Step 173532: Loss=6.0386, Acc=0.210, PPL=419.29
2025-09-22 02:27:53,472 - training.trainer - INFO - Epoch 51, Step 173632: Loss=5.0908, Acc=0.310, PPL=162.52
2025-09-22 02:28:01,354 - training.trainer - INFO - Epoch 51, Step 173732: Loss=5.3200, Acc=0.323, PPL=204.38
2025-09-22 02:28:09,501 - training.trainer - INFO - Epoch 51, Step 173832: Loss=5.8282, Acc=0.333, PPL=339.73
2025-09-22 02:28:17,414 - training.trainer - INFO - Epoch 51, Step 173932: Loss=6.2991, Acc=0.250, PPL=544.10
2025-09-22 02:28:25,257 - training.trainer - INFO - Epoch 51, Step 174032: Loss=5.7097, Acc=0.196, PPL=301.78
2025-09-22 02:28:33,109 - training.trainer - INFO - Epoch 51, Step 174132: Loss=4.5245, Acc=0.379, PPL=92.25
2025-09-22 02:28:41,173 - training.trainer - INFO - Epoch 51, Step 174232: Loss=6.4380, Acc=0.136, PPL=625.13
2025-09-22 02:28:49,048 - training.trainer - INFO - Epoch 51, Step 174332: Loss=5.8134, Acc=0.211, PPL=334.75
2025-09-22 02:28:56,929 - training.trainer - INFO - Epoch 51, Step 174432: Loss=5.1407, Acc=0.294, PPL=170.84
2025-09-22 02:29:04,789 - training.trainer - INFO - Epoch 51, Step 174532: Loss=5.3045, Acc=0.250, PPL=201.24
2025-09-22 02:29:12,771 - training.trainer - INFO - Epoch 51, Step 174632: Loss=6.0221, Acc=0.232, PPL=412.44
2025-09-22 02:29:20,754 - training.trainer - INFO - Epoch 51, Step 174732: Loss=4.4376, Acc=0.353, PPL=84.57
2025-09-22 02:29:28,656 - training.trainer - INFO - Epoch 51, Step 174832: Loss=5.3337, Acc=0.263, PPL=207.21
2025-09-22 02:29:36,532 - training.trainer - INFO - Epoch 51, Step 174932: Loss=4.6081, Acc=0.364, PPL=100.30
2025-09-22 02:29:44,481 - training.trainer - INFO - Epoch 51, Step 175032: Loss=5.8645, Acc=0.257, PPL=352.30
2025-09-22 02:29:52,309 - training.trainer - INFO - Epoch 51, Step 175132: Loss=5.5832, Acc=0.203, PPL=265.93
2025-09-22 02:30:00,131 - training.trainer - INFO - Epoch 51, Step 175232: Loss=5.8581, Acc=0.229, PPL=350.07
2025-09-22 02:30:07,911 - training.trainer - INFO - Epoch 51, Step 175332: Loss=6.1799, Acc=0.175, PPL=482.96
2025-09-22 02:30:15,806 - training.trainer - INFO - Epoch 51, Step 175432: Loss=4.5219, Acc=0.450, PPL=92.01
2025-09-22 02:30:23,614 - training.trainer - INFO - Epoch 51, Step 175532: Loss=6.1454, Acc=0.188, PPL=466.58
2025-09-22 02:30:31,401 - training.trainer - INFO - Epoch 51, Step 175632: Loss=6.0852, Acc=0.302, PPL=439.32
2025-09-22 02:30:39,209 - training.trainer - INFO - Epoch 51, Step 175732: Loss=5.6250, Acc=0.245, PPL=277.27
2025-09-22 02:30:47,093 - training.trainer - INFO - Epoch 51, Step 175832: Loss=6.2529, Acc=0.190, PPL=519.49
2025-09-22 02:31:03,807 - training.trainer - INFO - Epoch 52/100 completed in 278.47s - Train Loss: 5.5251, Train Acc: 0.277, Val Loss: 5.6867, Val Acc: 0.253
2025-09-22 02:31:11,665 - training.trainer - INFO - Epoch 52, Step 176015: Loss=5.6544, Acc=0.247, PPL=285.54
2025-09-22 02:31:19,511 - training.trainer - INFO - Epoch 52, Step 176115: Loss=5.8246, Acc=0.209, PPL=338.52
2025-09-22 02:31:27,553 - training.trainer - INFO - Epoch 52, Step 176215: Loss=5.8785, Acc=0.359, PPL=357.28
2025-09-22 02:31:35,400 - training.trainer - INFO - Epoch 52, Step 176315: Loss=5.4709, Acc=0.417, PPL=237.68
2025-09-22 02:31:43,211 - training.trainer - INFO - Epoch 52, Step 176415: Loss=4.9851, Acc=0.250, PPL=146.22
2025-09-22 02:31:51,078 - training.trainer - INFO - Epoch 52, Step 176515: Loss=3.9345, Acc=0.516, PPL=51.14
2025-09-22 02:31:59,276 - training.trainer - INFO - Epoch 52, Step 176615: Loss=6.1521, Acc=0.212, PPL=469.69
2025-09-22 02:32:07,382 - training.trainer - INFO - Epoch 52, Step 176715: Loss=4.7290, Acc=0.400, PPL=113.18
2025-09-22 02:32:15,462 - training.trainer - INFO - Epoch 52, Step 176815: Loss=5.5156, Acc=0.302, PPL=248.54
2025-09-22 02:32:23,566 - training.trainer - INFO - Epoch 52, Step 176915: Loss=4.7437, Acc=0.304, PPL=114.86
2025-09-22 02:32:31,595 - training.trainer - INFO - Epoch 52, Step 177015: Loss=6.1061, Acc=0.217, PPL=448.60
2025-09-22 02:32:39,522 - training.trainer - INFO - Epoch 52, Step 177115: Loss=4.8348, Acc=0.333, PPL=125.81
2025-09-22 02:32:47,569 - training.trainer - INFO - Epoch 52, Step 177215: Loss=4.8987, Acc=0.235, PPL=134.12
2025-09-22 02:32:55,656 - training.trainer - INFO - Epoch 52, Step 177315: Loss=5.9715, Acc=0.211, PPL=392.10
2025-09-22 02:33:03,900 - training.trainer - INFO - Epoch 52, Step 177415: Loss=6.4185, Acc=0.198, PPL=613.08
2025-09-22 02:33:11,835 - training.trainer - INFO - Epoch 52, Step 177515: Loss=5.9480, Acc=0.278, PPL=382.97
2025-09-22 02:33:19,667 - training.trainer - INFO - Epoch 52, Step 177615: Loss=5.1161, Acc=0.421, PPL=166.68
2025-09-22 02:33:27,436 - training.trainer - INFO - Epoch 52, Step 177715: Loss=6.0560, Acc=0.208, PPL=426.68
2025-09-22 02:33:35,273 - training.trainer - INFO - Epoch 52, Step 177815: Loss=6.1768, Acc=0.169, PPL=481.44
2025-09-22 02:33:43,016 - training.trainer - INFO - Epoch 52, Step 177915: Loss=4.1577, Acc=0.500, PPL=63.93
2025-09-22 02:33:50,820 - training.trainer - INFO - Epoch 52, Step 178015: Loss=5.8004, Acc=0.282, PPL=330.43
2025-09-22 02:33:58,546 - training.trainer - INFO - Epoch 52, Step 178115: Loss=5.7822, Acc=0.283, PPL=324.49
2025-09-22 02:34:06,410 - training.trainer - INFO - Epoch 52, Step 178215: Loss=5.9020, Acc=0.208, PPL=365.77
2025-09-22 02:34:14,192 - training.trainer - INFO - Epoch 52, Step 178315: Loss=3.0139, Acc=0.611, PPL=20.37
2025-09-22 02:34:21,946 - training.trainer - INFO - Epoch 52, Step 178415: Loss=5.6319, Acc=0.304, PPL=279.18
2025-09-22 02:34:29,717 - training.trainer - INFO - Epoch 52, Step 178515: Loss=5.9409, Acc=0.340, PPL=380.28
2025-09-22 02:34:37,589 - training.trainer - INFO - Epoch 52, Step 178615: Loss=5.7163, Acc=0.245, PPL=303.76
2025-09-22 02:34:45,443 - training.trainer - INFO - Epoch 52, Step 178715: Loss=5.9797, Acc=0.268, PPL=395.33
2025-09-22 02:34:53,285 - training.trainer - INFO - Epoch 52, Step 178815: Loss=6.1234, Acc=0.266, PPL=456.42
2025-09-22 02:35:01,080 - training.trainer - INFO - Epoch 52, Step 178915: Loss=5.1763, Acc=0.250, PPL=177.03
2025-09-22 02:35:08,918 - training.trainer - INFO - Epoch 52, Step 179015: Loss=3.4839, Acc=0.711, PPL=32.59
2025-09-22 02:35:16,743 - training.trainer - INFO - Epoch 52, Step 179115: Loss=6.0228, Acc=0.333, PPL=412.72
2025-09-22 02:35:24,590 - training.trainer - INFO - Epoch 52, Step 179215: Loss=5.7212, Acc=0.206, PPL=305.29
2025-09-22 02:35:41,803 - training.trainer - INFO - Epoch 53/100 completed in 278.00s - Train Loss: 5.5152, Train Acc: 0.278, Val Loss: 5.6797, Val Acc: 0.255
2025-09-22 02:35:42,674 - training.trainer - INFO - New best model saved with validation loss: 5.6797
2025-09-22 02:35:42,675 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_53.pt
2025-09-22 02:35:51,022 - training.trainer - INFO - Epoch 53, Step 179398: Loss=5.8922, Acc=0.280, PPL=362.19
2025-09-22 02:35:58,900 - training.trainer - INFO - Epoch 53, Step 179498: Loss=5.8955, Acc=0.217, PPL=363.39
2025-09-22 02:36:06,830 - training.trainer - INFO - Epoch 53, Step 179598: Loss=4.7609, Acc=0.286, PPL=116.85
2025-09-22 02:36:14,786 - training.trainer - INFO - Epoch 53, Step 179698: Loss=6.4710, Acc=0.188, PPL=646.16
2025-09-22 02:36:22,679 - training.trainer - INFO - Epoch 53, Step 179798: Loss=5.3809, Acc=0.357, PPL=217.23
2025-09-22 02:36:30,577 - training.trainer - INFO - Epoch 53, Step 179898: Loss=4.0957, Acc=0.333, PPL=60.08
2025-09-22 02:36:38,469 - training.trainer - INFO - Epoch 53, Step 179998: Loss=5.3894, Acc=0.235, PPL=219.08
2025-09-22 02:36:46,321 - training.trainer - INFO - Epoch 53, Step 180098: Loss=5.9789, Acc=0.182, PPL=395.01
2025-09-22 02:36:54,223 - training.trainer - INFO - Epoch 53, Step 180198: Loss=5.1652, Acc=0.304, PPL=175.08
2025-09-22 02:37:02,090 - training.trainer - INFO - Epoch 53, Step 180298: Loss=6.0345, Acc=0.254, PPL=417.60
2025-09-22 02:37:09,970 - training.trainer - INFO - Epoch 53, Step 180398: Loss=5.3761, Acc=0.298, PPL=216.17
2025-09-22 02:37:17,767 - training.trainer - INFO - Epoch 53, Step 180498: Loss=5.1792, Acc=0.267, PPL=177.54
2025-09-22 02:37:25,721 - training.trainer - INFO - Epoch 53, Step 180598: Loss=6.0324, Acc=0.327, PPL=416.73
2025-09-22 02:37:33,544 - training.trainer - INFO - Epoch 53, Step 180698: Loss=5.2763, Acc=0.350, PPL=195.64
2025-09-22 02:37:41,447 - training.trainer - INFO - Epoch 53, Step 180798: Loss=5.3830, Acc=0.326, PPL=217.68
2025-09-22 02:37:49,369 - training.trainer - INFO - Epoch 53, Step 180898: Loss=5.8892, Acc=0.188, PPL=361.13
2025-09-22 02:37:57,495 - training.trainer - INFO - Epoch 53, Step 180998: Loss=4.9280, Acc=0.421, PPL=138.10
2025-09-22 02:38:05,715 - training.trainer - INFO - Epoch 53, Step 181098: Loss=5.0197, Acc=0.368, PPL=151.37
2025-09-22 02:38:13,824 - training.trainer - INFO - Epoch 53, Step 181198: Loss=5.5574, Acc=0.216, PPL=259.14
2025-09-22 02:38:21,987 - training.trainer - INFO - Epoch 53, Step 181298: Loss=4.3902, Acc=0.476, PPL=80.66
2025-09-22 02:38:29,993 - training.trainer - INFO - Epoch 53, Step 181398: Loss=4.9755, Acc=0.200, PPL=144.82
2025-09-22 02:38:37,889 - training.trainer - INFO - Epoch 53, Step 181498: Loss=4.2619, Acc=0.421, PPL=70.95
2025-09-22 02:38:45,798 - training.trainer - INFO - Epoch 53, Step 181598: Loss=6.1797, Acc=0.140, PPL=482.87
2025-09-22 02:38:53,748 - training.trainer - INFO - Epoch 53, Step 181698: Loss=5.3770, Acc=0.382, PPL=216.37
2025-09-22 02:39:01,844 - training.trainer - INFO - Epoch 53, Step 181798: Loss=6.2694, Acc=0.320, PPL=528.18
2025-09-22 02:39:09,812 - training.trainer - INFO - Epoch 53, Step 181898: Loss=5.6065, Acc=0.222, PPL=272.18
2025-09-22 02:39:17,940 - training.trainer - INFO - Epoch 53, Step 181998: Loss=5.5111, Acc=0.222, PPL=247.42
2025-09-22 02:39:25,966 - training.trainer - INFO - Epoch 53, Step 182098: Loss=5.7018, Acc=0.200, PPL=299.42
2025-09-22 02:39:33,996 - training.trainer - INFO - Epoch 53, Step 182198: Loss=5.8506, Acc=0.240, PPL=347.46
2025-09-22 02:39:41,865 - training.trainer - INFO - Epoch 53, Step 182298: Loss=4.3318, Acc=0.357, PPL=76.08
2025-09-22 02:39:49,722 - training.trainer - INFO - Epoch 53, Step 182398: Loss=5.7098, Acc=0.194, PPL=301.80
2025-09-22 02:39:57,641 - training.trainer - INFO - Epoch 53, Step 182498: Loss=5.5893, Acc=0.233, PPL=267.55
2025-09-22 02:40:05,733 - training.trainer - INFO - Epoch 53, Step 182598: Loss=5.7630, Acc=0.186, PPL=318.31
2025-09-22 02:40:23,478 - training.trainer - INFO - Epoch 54/100 completed in 280.80s - Train Loss: 5.5081, Train Acc: 0.278, Val Loss: 5.6774, Val Acc: 0.253
2025-09-22 02:40:24,311 - training.trainer - INFO - New best model saved with validation loss: 5.6774
2025-09-22 02:40:24,312 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_54.pt
2025-09-22 02:40:32,648 - training.trainer - INFO - Epoch 54, Step 182781: Loss=5.4618, Acc=0.167, PPL=235.51
2025-09-22 02:40:40,697 - training.trainer - INFO - Epoch 54, Step 182881: Loss=4.5520, Acc=0.333, PPL=94.82
2025-09-22 02:40:48,571 - training.trainer - INFO - Epoch 54, Step 182981: Loss=5.4020, Acc=0.343, PPL=221.85
2025-09-22 02:40:56,540 - training.trainer - INFO - Epoch 54, Step 183081: Loss=5.3827, Acc=0.286, PPL=217.61
2025-09-22 02:41:04,396 - training.trainer - INFO - Epoch 54, Step 183181: Loss=5.5518, Acc=0.233, PPL=257.70
2025-09-22 02:41:12,334 - training.trainer - INFO - Epoch 54, Step 183281: Loss=5.3389, Acc=0.372, PPL=208.28
2025-09-22 02:41:20,158 - training.trainer - INFO - Epoch 54, Step 183381: Loss=5.3764, Acc=0.333, PPL=216.25
2025-09-22 02:41:28,049 - training.trainer - INFO - Epoch 54, Step 183481: Loss=6.0331, Acc=0.238, PPL=416.99
2025-09-22 02:41:35,956 - training.trainer - INFO - Epoch 54, Step 183581: Loss=4.4131, Acc=0.333, PPL=82.52
2025-09-22 02:41:43,971 - training.trainer - INFO - Epoch 54, Step 183681: Loss=5.1789, Acc=0.314, PPL=177.49
2025-09-22 02:41:51,948 - training.trainer - INFO - Epoch 54, Step 183781: Loss=6.0959, Acc=0.184, PPL=444.04
2025-09-22 02:41:59,874 - training.trainer - INFO - Epoch 54, Step 183881: Loss=6.1239, Acc=0.159, PPL=456.63
2025-09-22 02:42:07,761 - training.trainer - INFO - Epoch 54, Step 183981: Loss=6.0904, Acc=0.259, PPL=441.58
2025-09-22 02:42:15,727 - training.trainer - INFO - Epoch 54, Step 184081: Loss=5.4188, Acc=0.286, PPL=225.60
2025-09-22 02:42:23,624 - training.trainer - INFO - Epoch 54, Step 184181: Loss=5.4501, Acc=0.216, PPL=232.78
2025-09-22 02:42:31,489 - training.trainer - INFO - Epoch 54, Step 184281: Loss=5.6715, Acc=0.255, PPL=290.47
2025-09-22 02:42:39,350 - training.trainer - INFO - Epoch 54, Step 184381: Loss=5.4840, Acc=0.182, PPL=240.81
2025-09-22 02:42:47,140 - training.trainer - INFO - Epoch 54, Step 184481: Loss=3.6613, Acc=0.543, PPL=38.91
2025-09-22 02:42:55,003 - training.trainer - INFO - Epoch 54, Step 184581: Loss=5.6367, Acc=0.314, PPL=280.54
2025-09-22 02:43:02,905 - training.trainer - INFO - Epoch 54, Step 184681: Loss=5.1003, Acc=0.237, PPL=164.07
2025-09-22 02:43:10,795 - training.trainer - INFO - Epoch 54, Step 184781: Loss=5.9542, Acc=0.200, PPL=385.35
2025-09-22 02:43:18,719 - training.trainer - INFO - Epoch 54, Step 184881: Loss=5.3790, Acc=0.297, PPL=216.80
2025-09-22 02:43:26,572 - training.trainer - INFO - Epoch 54, Step 184981: Loss=6.3563, Acc=0.265, PPL=576.13
2025-09-22 02:43:34,460 - training.trainer - INFO - Epoch 54, Step 185081: Loss=5.8372, Acc=0.298, PPL=342.82
2025-09-22 02:43:42,350 - training.trainer - INFO - Epoch 54, Step 185181: Loss=5.4131, Acc=0.304, PPL=224.33
2025-09-22 02:43:50,236 - training.trainer - INFO - Epoch 54, Step 185281: Loss=5.5679, Acc=0.292, PPL=261.88
2025-09-22 02:43:58,105 - training.trainer - INFO - Epoch 54, Step 185381: Loss=5.5425, Acc=0.182, PPL=255.30
2025-09-22 02:44:05,973 - training.trainer - INFO - Epoch 54, Step 185481: Loss=5.5637, Acc=0.286, PPL=260.78
2025-09-22 02:44:13,810 - training.trainer - INFO - Epoch 54, Step 185581: Loss=6.1133, Acc=0.219, PPL=451.81
2025-09-22 02:44:21,660 - training.trainer - INFO - Epoch 54, Step 185681: Loss=5.3919, Acc=0.316, PPL=219.62
2025-09-22 02:44:29,559 - training.trainer - INFO - Epoch 54, Step 185781: Loss=6.3176, Acc=0.167, PPL=554.22
2025-09-22 02:44:37,380 - training.trainer - INFO - Epoch 54, Step 185881: Loss=5.8898, Acc=0.255, PPL=361.34
2025-09-22 02:44:45,167 - training.trainer - INFO - Epoch 54, Step 185981: Loss=5.8258, Acc=0.200, PPL=338.92
2025-09-22 02:45:01,700 - training.trainer - INFO - Epoch 55/100 completed in 277.39s - Train Loss: 5.5004, Train Acc: 0.279, Val Loss: 5.6759, Val Acc: 0.254
2025-09-22 02:45:02,014 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_55.pt
2025-09-22 02:45:02,660 - training.trainer - INFO - New best model saved with validation loss: 5.6759
2025-09-22 02:45:02,660 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_55.pt
2025-09-22 02:45:10,893 - training.trainer - INFO - Epoch 55, Step 186164: Loss=5.6759, Acc=0.333, PPL=291.75
2025-09-22 02:45:18,806 - training.trainer - INFO - Epoch 55, Step 186264: Loss=5.0712, Acc=0.257, PPL=159.37
2025-09-22 02:45:26,731 - training.trainer - INFO - Epoch 55, Step 186364: Loss=4.7836, Acc=0.310, PPL=119.53
2025-09-22 02:45:34,726 - training.trainer - INFO - Epoch 55, Step 186464: Loss=6.1821, Acc=0.219, PPL=484.01
2025-09-22 02:45:42,548 - training.trainer - INFO - Epoch 55, Step 186564: Loss=5.8076, Acc=0.220, PPL=332.82
2025-09-22 02:45:50,435 - training.trainer - INFO - Epoch 55, Step 186664: Loss=5.6954, Acc=0.295, PPL=297.51
2025-09-22 02:45:58,314 - training.trainer - INFO - Epoch 55, Step 186764: Loss=3.5850, Acc=0.600, PPL=36.05
2025-09-22 02:46:06,283 - training.trainer - INFO - Epoch 55, Step 186864: Loss=6.2859, Acc=0.240, PPL=536.96
2025-09-22 02:46:14,171 - training.trainer - INFO - Epoch 55, Step 186964: Loss=5.9642, Acc=0.341, PPL=389.26
2025-09-22 02:46:22,015 - training.trainer - INFO - Epoch 55, Step 187064: Loss=6.0707, Acc=0.174, PPL=433.00
2025-09-22 02:46:29,901 - training.trainer - INFO - Epoch 55, Step 187164: Loss=5.3104, Acc=0.333, PPL=202.44
2025-09-22 02:46:37,827 - training.trainer - INFO - Epoch 55, Step 187264: Loss=5.4087, Acc=0.316, PPL=223.33
2025-09-22 02:46:45,830 - training.trainer - INFO - Epoch 55, Step 187364: Loss=6.0001, Acc=0.174, PPL=403.48
2025-09-22 02:46:53,918 - training.trainer - INFO - Epoch 55, Step 187464: Loss=5.3918, Acc=0.278, PPL=219.60
2025-09-22 02:47:01,955 - training.trainer - INFO - Epoch 55, Step 187564: Loss=4.6798, Acc=0.321, PPL=107.75
2025-09-22 02:47:10,025 - training.trainer - INFO - Epoch 55, Step 187664: Loss=6.2531, Acc=0.190, PPL=519.65
2025-09-22 02:47:18,176 - training.trainer - INFO - Epoch 55, Step 187764: Loss=4.5679, Acc=0.500, PPL=96.34
2025-09-22 02:47:26,279 - training.trainer - INFO - Epoch 55, Step 187864: Loss=5.1962, Acc=0.167, PPL=180.59
2025-09-22 02:47:34,269 - training.trainer - INFO - Epoch 55, Step 187964: Loss=6.5640, Acc=0.200, PPL=709.08
2025-09-22 02:47:42,234 - training.trainer - INFO - Epoch 55, Step 188064: Loss=5.8665, Acc=0.143, PPL=353.01
2025-09-22 02:47:50,185 - training.trainer - INFO - Epoch 55, Step 188164: Loss=6.3696, Acc=0.149, PPL=583.81
2025-09-22 02:47:58,004 - training.trainer - INFO - Epoch 55, Step 188264: Loss=5.2335, Acc=0.393, PPL=187.45
2025-09-22 02:48:05,934 - training.trainer - INFO - Epoch 55, Step 188364: Loss=6.3288, Acc=0.151, PPL=560.47
2025-09-22 02:48:13,841 - training.trainer - INFO - Epoch 55, Step 188464: Loss=6.0997, Acc=0.186, PPL=445.74
2025-09-22 02:48:21,847 - training.trainer - INFO - Epoch 55, Step 188564: Loss=5.5830, Acc=0.276, PPL=265.87
2025-09-22 02:48:29,763 - training.trainer - INFO - Epoch 55, Step 188664: Loss=4.8149, Acc=0.429, PPL=123.34
2025-09-22 02:48:37,684 - training.trainer - INFO - Epoch 55, Step 188764: Loss=6.3829, Acc=0.188, PPL=591.67
2025-09-22 02:48:45,624 - training.trainer - INFO - Epoch 55, Step 188864: Loss=5.5563, Acc=0.273, PPL=258.87
2025-09-22 02:48:53,707 - training.trainer - INFO - Epoch 55, Step 188964: Loss=5.0050, Acc=0.192, PPL=149.16
2025-09-22 02:49:01,868 - training.trainer - INFO - Epoch 55, Step 189064: Loss=5.5950, Acc=0.267, PPL=269.08
2025-09-22 02:49:10,053 - training.trainer - INFO - Epoch 55, Step 189164: Loss=5.8673, Acc=0.304, PPL=353.30
2025-09-22 02:49:18,304 - training.trainer - INFO - Epoch 55, Step 189264: Loss=5.0333, Acc=0.258, PPL=153.44
2025-09-22 02:49:26,397 - training.trainer - INFO - Epoch 55, Step 189364: Loss=5.5630, Acc=0.333, PPL=260.60
2025-09-22 02:49:43,905 - training.trainer - INFO - Epoch 56/100 completed in 281.24s - Train Loss: 5.4915, Train Acc: 0.279, Val Loss: 5.6755, Val Acc: 0.254
2025-09-22 02:49:44,533 - training.trainer - INFO - New best model saved with validation loss: 5.6755
2025-09-22 02:49:44,533 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_56.pt
2025-09-22 02:49:52,577 - training.trainer - INFO - Epoch 56, Step 189547: Loss=6.1089, Acc=0.194, PPL=449.84
2025-09-22 02:50:00,578 - training.trainer - INFO - Epoch 56, Step 189647: Loss=5.2088, Acc=0.364, PPL=182.88
2025-09-22 02:50:08,466 - training.trainer - INFO - Epoch 56, Step 189747: Loss=5.5348, Acc=0.271, PPL=253.35
2025-09-22 02:50:16,332 - training.trainer - INFO - Epoch 56, Step 189847: Loss=5.7804, Acc=0.182, PPL=323.88
2025-09-22 02:50:24,328 - training.trainer - INFO - Epoch 56, Step 189947: Loss=4.9463, Acc=0.392, PPL=140.66
2025-09-22 02:50:32,308 - training.trainer - INFO - Epoch 56, Step 190047: Loss=4.8630, Acc=0.286, PPL=129.41
2025-09-22 02:50:40,173 - training.trainer - INFO - Epoch 56, Step 190147: Loss=5.9059, Acc=0.262, PPL=367.19
2025-09-22 02:50:48,098 - training.trainer - INFO - Epoch 56, Step 190247: Loss=6.1474, Acc=0.222, PPL=467.51
2025-09-22 02:50:55,996 - training.trainer - INFO - Epoch 56, Step 190347: Loss=4.7547, Acc=0.394, PPL=116.13
2025-09-22 02:51:04,000 - training.trainer - INFO - Epoch 56, Step 190447: Loss=6.3651, Acc=0.222, PPL=581.22
2025-09-22 02:51:12,222 - training.trainer - INFO - Epoch 56, Step 190547: Loss=5.8095, Acc=0.217, PPL=333.46
2025-09-22 02:51:20,290 - training.trainer - INFO - Epoch 56, Step 190647: Loss=5.7326, Acc=0.159, PPL=308.76
2025-09-22 02:51:28,227 - training.trainer - INFO - Epoch 56, Step 190747: Loss=6.3439, Acc=0.184, PPL=569.02
2025-09-22 02:51:36,254 - training.trainer - INFO - Epoch 56, Step 190847: Loss=5.1762, Acc=0.200, PPL=177.01
2025-09-22 02:51:44,172 - training.trainer - INFO - Epoch 56, Step 190947: Loss=6.0167, Acc=0.177, PPL=410.24
2025-09-22 02:51:52,048 - training.trainer - INFO - Epoch 56, Step 191047: Loss=5.5988, Acc=0.256, PPL=270.10
2025-09-22 02:52:00,026 - training.trainer - INFO - Epoch 56, Step 191147: Loss=4.4919, Acc=0.372, PPL=89.29
2025-09-22 02:52:07,968 - training.trainer - INFO - Epoch 56, Step 191247: Loss=4.7786, Acc=0.400, PPL=118.94
2025-09-22 02:52:15,886 - training.trainer - INFO - Epoch 56, Step 191347: Loss=5.5304, Acc=0.207, PPL=252.24
2025-09-22 02:52:23,800 - training.trainer - INFO - Epoch 56, Step 191447: Loss=4.5783, Acc=0.474, PPL=97.35
2025-09-22 02:52:31,695 - training.trainer - INFO - Epoch 56, Step 191547: Loss=5.5224, Acc=0.333, PPL=250.22
2025-09-22 02:52:39,661 - training.trainer - INFO - Epoch 56, Step 191647: Loss=5.7919, Acc=0.320, PPL=327.62
2025-09-22 02:52:47,561 - training.trainer - INFO - Epoch 56, Step 191747: Loss=5.6938, Acc=0.250, PPL=297.03
2025-09-22 02:52:55,389 - training.trainer - INFO - Epoch 56, Step 191847: Loss=5.6336, Acc=0.222, PPL=279.66
2025-09-22 02:53:03,310 - training.trainer - INFO - Epoch 56, Step 191947: Loss=5.2856, Acc=0.291, PPL=197.47
2025-09-22 02:53:11,242 - training.trainer - INFO - Epoch 56, Step 192047: Loss=5.6361, Acc=0.267, PPL=280.37
2025-09-22 02:53:19,178 - training.trainer - INFO - Epoch 56, Step 192147: Loss=5.7341, Acc=0.220, PPL=309.22
2025-09-22 02:53:27,123 - training.trainer - INFO - Epoch 56, Step 192247: Loss=4.9200, Acc=0.474, PPL=137.00
2025-09-22 02:53:34,985 - training.trainer - INFO - Epoch 56, Step 192347: Loss=4.4728, Acc=0.500, PPL=87.60
2025-09-22 02:53:42,909 - training.trainer - INFO - Epoch 56, Step 192447: Loss=5.9199, Acc=0.189, PPL=372.36
2025-09-22 02:53:50,852 - training.trainer - INFO - Epoch 56, Step 192547: Loss=5.4830, Acc=0.353, PPL=240.57
2025-09-22 02:53:58,781 - training.trainer - INFO - Epoch 56, Step 192647: Loss=5.8567, Acc=0.233, PPL=349.58
2025-09-22 02:54:06,659 - training.trainer - INFO - Epoch 56, Step 192747: Loss=5.5671, Acc=0.381, PPL=261.68
2025-09-22 02:54:23,586 - training.trainer - INFO - Epoch 57/100 completed in 279.05s - Train Loss: 5.4819, Train Acc: 0.282, Val Loss: 5.6722, Val Acc: 0.255
2025-09-22 02:54:24,231 - training.trainer - INFO - New best model saved with validation loss: 5.6722
2025-09-22 02:54:24,231 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_57.pt
2025-09-22 02:54:32,532 - training.trainer - INFO - Epoch 57, Step 192930: Loss=5.5617, Acc=0.259, PPL=260.28
2025-09-22 02:54:40,417 - training.trainer - INFO - Epoch 57, Step 193030: Loss=5.9738, Acc=0.250, PPL=393.00
2025-09-22 02:54:48,300 - training.trainer - INFO - Epoch 57, Step 193130: Loss=6.6943, Acc=0.167, PPL=807.83
2025-09-22 02:54:56,232 - training.trainer - INFO - Epoch 57, Step 193230: Loss=5.7045, Acc=0.259, PPL=300.20
2025-09-22 02:55:04,121 - training.trainer - INFO - Epoch 57, Step 193330: Loss=5.3757, Acc=0.276, PPL=216.09
2025-09-22 02:55:12,004 - training.trainer - INFO - Epoch 57, Step 193430: Loss=6.5566, Acc=0.296, PPL=703.89
2025-09-22 02:55:20,091 - training.trainer - INFO - Epoch 57, Step 193530: Loss=5.6750, Acc=0.172, PPL=291.49
2025-09-22 02:55:28,233 - training.trainer - INFO - Epoch 57, Step 193630: Loss=5.8417, Acc=0.213, PPL=344.37
2025-09-22 02:55:36,191 - training.trainer - INFO - Epoch 57, Step 193730: Loss=5.5949, Acc=0.267, PPL=269.05
2025-09-22 02:55:44,073 - training.trainer - INFO - Epoch 57, Step 193830: Loss=4.8874, Acc=0.250, PPL=132.61
2025-09-22 02:55:51,950 - training.trainer - INFO - Epoch 57, Step 193930: Loss=4.8389, Acc=0.267, PPL=126.34
2025-09-22 02:55:59,876 - training.trainer - INFO - Epoch 57, Step 194030: Loss=5.1035, Acc=0.316, PPL=164.60
2025-09-22 02:56:07,771 - training.trainer - INFO - Epoch 57, Step 194130: Loss=5.5345, Acc=0.292, PPL=253.28
2025-09-22 02:56:15,678 - training.trainer - INFO - Epoch 57, Step 194230: Loss=4.5243, Acc=0.452, PPL=92.23
2025-09-22 02:56:23,546 - training.trainer - INFO - Epoch 57, Step 194330: Loss=5.9283, Acc=0.271, PPL=375.53
2025-09-22 02:56:31,501 - training.trainer - INFO - Epoch 57, Step 194430: Loss=5.2502, Acc=0.333, PPL=190.61
2025-09-22 02:56:39,401 - training.trainer - INFO - Epoch 57, Step 194530: Loss=5.5101, Acc=0.281, PPL=247.17
2025-09-22 02:56:47,285 - training.trainer - INFO - Epoch 57, Step 194630: Loss=4.9289, Acc=0.435, PPL=138.23
2025-09-22 02:56:55,196 - training.trainer - INFO - Epoch 57, Step 194730: Loss=4.7725, Acc=0.400, PPL=118.21
2025-09-22 02:57:03,139 - training.trainer - INFO - Epoch 57, Step 194830: Loss=6.5419, Acc=0.191, PPL=693.59
2025-09-22 02:57:11,134 - training.trainer - INFO - Epoch 57, Step 194930: Loss=5.9252, Acc=0.222, PPL=374.36
2025-09-22 02:57:19,053 - training.trainer - INFO - Epoch 57, Step 195030: Loss=5.0293, Acc=0.261, PPL=152.83
2025-09-22 02:57:27,060 - training.trainer - INFO - Epoch 57, Step 195130: Loss=6.4224, Acc=0.205, PPL=615.48
2025-09-22 02:57:35,079 - training.trainer - INFO - Epoch 57, Step 195230: Loss=5.2676, Acc=0.280, PPL=193.96
2025-09-22 02:57:43,002 - training.trainer - INFO - Epoch 57, Step 195330: Loss=5.6909, Acc=0.364, PPL=296.15
2025-09-22 02:57:50,936 - training.trainer - INFO - Epoch 57, Step 195430: Loss=6.0035, Acc=0.237, PPL=404.84
2025-09-22 02:57:58,910 - training.trainer - INFO - Epoch 57, Step 195530: Loss=4.4486, Acc=0.529, PPL=85.50
2025-09-22 02:58:06,892 - training.trainer - INFO - Epoch 57, Step 195630: Loss=5.0548, Acc=0.297, PPL=156.78
2025-09-22 02:58:14,773 - training.trainer - INFO - Epoch 57, Step 195730: Loss=5.4570, Acc=0.200, PPL=234.39
2025-09-22 02:58:22,658 - training.trainer - INFO - Epoch 57, Step 195830: Loss=5.5311, Acc=0.200, PPL=252.43
2025-09-22 02:58:30,512 - training.trainer - INFO - Epoch 57, Step 195930: Loss=5.2211, Acc=0.286, PPL=185.13
2025-09-22 02:58:38,407 - training.trainer - INFO - Epoch 57, Step 196030: Loss=5.4884, Acc=0.293, PPL=241.88
2025-09-22 02:58:46,283 - training.trainer - INFO - Epoch 57, Step 196130: Loss=6.0724, Acc=0.143, PPL=433.72
2025-09-22 02:59:03,234 - training.trainer - INFO - Epoch 58/100 completed in 279.00s - Train Loss: 5.4806, Train Acc: 0.282, Val Loss: 5.6759, Val Acc: 0.252
2025-09-22 02:59:11,397 - training.trainer - INFO - Epoch 58, Step 196313: Loss=5.2838, Acc=0.350, PPL=197.12
2025-09-22 02:59:19,393 - training.trainer - INFO - Epoch 58, Step 196413: Loss=5.7144, Acc=0.265, PPL=303.20
2025-09-22 02:59:27,308 - training.trainer - INFO - Epoch 58, Step 196513: Loss=6.2682, Acc=0.321, PPL=527.52
2025-09-22 02:59:35,234 - training.trainer - INFO - Epoch 58, Step 196613: Loss=5.3222, Acc=0.245, PPL=204.84
2025-09-22 02:59:43,171 - training.trainer - INFO - Epoch 58, Step 196713: Loss=5.8225, Acc=0.196, PPL=337.81
2025-09-22 02:59:51,169 - training.trainer - INFO - Epoch 58, Step 196813: Loss=4.9070, Acc=0.286, PPL=135.24
2025-09-22 02:59:59,107 - training.trainer - INFO - Epoch 58, Step 196913: Loss=3.7832, Acc=0.357, PPL=43.96
2025-09-22 03:00:07,094 - training.trainer - INFO - Epoch 58, Step 197013: Loss=5.8436, Acc=0.235, PPL=345.00
2025-09-22 03:00:15,035 - training.trainer - INFO - Epoch 58, Step 197113: Loss=5.3926, Acc=0.353, PPL=219.77
2025-09-22 03:00:22,974 - training.trainer - INFO - Epoch 58, Step 197213: Loss=6.0153, Acc=0.211, PPL=409.67
2025-09-22 03:00:30,839 - training.trainer - INFO - Epoch 58, Step 197313: Loss=5.5520, Acc=0.312, PPL=257.75
2025-09-22 03:00:38,800 - training.trainer - INFO - Epoch 58, Step 197413: Loss=5.3501, Acc=0.389, PPL=210.63
2025-09-22 03:00:46,721 - training.trainer - INFO - Epoch 58, Step 197513: Loss=5.4341, Acc=0.296, PPL=229.08
2025-09-22 03:00:54,791 - training.trainer - INFO - Epoch 58, Step 197613: Loss=4.7724, Acc=0.439, PPL=118.20
2025-09-22 03:01:02,771 - training.trainer - INFO - Epoch 58, Step 197713: Loss=5.0062, Acc=0.296, PPL=149.33
2025-09-22 03:01:10,646 - training.trainer - INFO - Epoch 58, Step 197813: Loss=5.2627, Acc=0.356, PPL=192.99
2025-09-22 03:01:18,518 - training.trainer - INFO - Epoch 58, Step 197913: Loss=6.5286, Acc=0.234, PPL=684.45
2025-09-22 03:01:26,477 - training.trainer - INFO - Epoch 58, Step 198013: Loss=5.6079, Acc=0.345, PPL=272.57
2025-09-22 03:01:34,433 - training.trainer - INFO - Epoch 58, Step 198113: Loss=5.3562, Acc=0.360, PPL=211.92
2025-09-22 03:01:42,360 - training.trainer - INFO - Epoch 58, Step 198213: Loss=4.8866, Acc=0.324, PPL=132.51
2025-09-22 03:01:50,360 - training.trainer - INFO - Epoch 58, Step 198313: Loss=4.3831, Acc=0.409, PPL=80.09
2025-09-22 03:01:58,395 - training.trainer - INFO - Epoch 58, Step 198413: Loss=5.7966, Acc=0.241, PPL=329.19
2025-09-22 03:02:06,393 - training.trainer - INFO - Epoch 58, Step 198513: Loss=5.4337, Acc=0.290, PPL=229.00
2025-09-22 03:02:14,373 - training.trainer - INFO - Epoch 58, Step 198613: Loss=4.9809, Acc=0.250, PPL=145.60
2025-09-22 03:02:22,343 - training.trainer - INFO - Epoch 58, Step 198713: Loss=6.1238, Acc=0.189, PPL=456.58
2025-09-22 03:02:30,376 - training.trainer - INFO - Epoch 58, Step 198813: Loss=5.9622, Acc=0.208, PPL=388.45
2025-09-22 03:02:38,363 - training.trainer - INFO - Epoch 58, Step 198913: Loss=5.7313, Acc=0.391, PPL=308.38
2025-09-22 03:02:46,247 - training.trainer - INFO - Epoch 58, Step 199013: Loss=5.9084, Acc=0.274, PPL=368.12
2025-09-22 03:02:54,167 - training.trainer - INFO - Epoch 58, Step 199113: Loss=5.7160, Acc=0.210, PPL=303.69
2025-09-22 03:03:02,218 - training.trainer - INFO - Epoch 58, Step 199213: Loss=4.0211, Acc=0.367, PPL=55.76
2025-09-22 03:03:10,140 - training.trainer - INFO - Epoch 58, Step 199313: Loss=5.8393, Acc=0.333, PPL=343.55
2025-09-22 03:03:18,126 - training.trainer - INFO - Epoch 58, Step 199413: Loss=4.7963, Acc=0.300, PPL=121.06
2025-09-22 03:03:26,000 - training.trainer - INFO - Epoch 58, Step 199513: Loss=5.3118, Acc=0.318, PPL=202.72
2025-09-22 03:03:43,047 - training.trainer - INFO - Epoch 59/100 completed in 279.81s - Train Loss: 5.4730, Train Acc: 0.283, Val Loss: 5.6738, Val Acc: 0.256
2025-09-22 03:03:51,014 - training.trainer - INFO - Epoch 59, Step 199696: Loss=5.2282, Acc=0.275, PPL=186.47
2025-09-22 03:03:58,922 - training.trainer - INFO - Epoch 59, Step 199796: Loss=4.5513, Acc=0.419, PPL=94.76
2025-09-22 03:04:06,925 - training.trainer - INFO - Epoch 59, Step 199896: Loss=6.1173, Acc=0.259, PPL=453.62
2025-09-22 03:04:14,841 - training.trainer - INFO - Epoch 59, Step 199996: Loss=5.9185, Acc=0.290, PPL=371.85
2025-09-22 03:04:22,777 - training.trainer - INFO - Epoch 59, Step 200096: Loss=3.7755, Acc=0.561, PPL=43.62
2025-09-22 03:04:30,838 - training.trainer - INFO - Epoch 59, Step 200196: Loss=3.8443, Acc=0.467, PPL=46.73
2025-09-22 03:04:38,823 - training.trainer - INFO - Epoch 59, Step 200296: Loss=5.6528, Acc=0.295, PPL=285.10
2025-09-22 03:04:46,772 - training.trainer - INFO - Epoch 59, Step 200396: Loss=2.9123, Acc=0.650, PPL=18.40
2025-09-22 03:04:54,694 - training.trainer - INFO - Epoch 59, Step 200496: Loss=5.5095, Acc=0.364, PPL=247.02
2025-09-22 03:05:02,551 - training.trainer - INFO - Epoch 59, Step 200596: Loss=5.0927, Acc=0.375, PPL=162.83
2025-09-22 03:05:10,432 - training.trainer - INFO - Epoch 59, Step 200696: Loss=5.9302, Acc=0.240, PPL=376.22
2025-09-22 03:05:18,335 - training.trainer - INFO - Epoch 59, Step 200796: Loss=4.6314, Acc=0.436, PPL=102.66
2025-09-22 03:05:26,222 - training.trainer - INFO - Epoch 59, Step 200896: Loss=4.9380, Acc=0.306, PPL=139.49
2025-09-22 03:05:34,064 - training.trainer - INFO - Epoch 59, Step 200996: Loss=5.6420, Acc=0.316, PPL=282.04
2025-09-22 03:05:41,886 - training.trainer - INFO - Epoch 59, Step 201096: Loss=5.6793, Acc=0.312, PPL=292.76
2025-09-22 03:05:49,724 - training.trainer - INFO - Epoch 59, Step 201196: Loss=5.7258, Acc=0.286, PPL=306.68
2025-09-22 03:05:57,645 - training.trainer - INFO - Epoch 59, Step 201296: Loss=4.2538, Acc=0.448, PPL=70.37
2025-09-22 03:06:05,528 - training.trainer - INFO - Epoch 59, Step 201396: Loss=5.4247, Acc=0.226, PPL=226.94
2025-09-22 03:06:13,568 - training.trainer - INFO - Epoch 59, Step 201496: Loss=5.6083, Acc=0.308, PPL=272.67
2025-09-22 03:06:21,608 - training.trainer - INFO - Epoch 59, Step 201596: Loss=5.7454, Acc=0.224, PPL=312.76
2025-09-22 03:06:29,539 - training.trainer - INFO - Epoch 59, Step 201696: Loss=4.1794, Acc=0.325, PPL=65.33
2025-09-22 03:06:37,572 - training.trainer - INFO - Epoch 59, Step 201796: Loss=5.1459, Acc=0.333, PPL=171.72
2025-09-22 03:06:45,688 - training.trainer - INFO - Epoch 59, Step 201896: Loss=5.9484, Acc=0.250, PPL=383.15
2025-09-22 03:06:53,675 - training.trainer - INFO - Epoch 59, Step 201996: Loss=6.6150, Acc=0.182, PPL=746.21
2025-09-22 03:07:01,557 - training.trainer - INFO - Epoch 59, Step 202096: Loss=6.0813, Acc=0.222, PPL=437.60
2025-09-22 03:07:09,397 - training.trainer - INFO - Epoch 59, Step 202196: Loss=5.3207, Acc=0.304, PPL=204.53
2025-09-22 03:07:17,285 - training.trainer - INFO - Epoch 59, Step 202296: Loss=6.1276, Acc=0.241, PPL=458.33
2025-09-22 03:07:25,245 - training.trainer - INFO - Epoch 59, Step 202396: Loss=5.3653, Acc=0.341, PPL=213.85
2025-09-22 03:07:33,134 - training.trainer - INFO - Epoch 59, Step 202496: Loss=6.2482, Acc=0.226, PPL=517.09
2025-09-22 03:07:41,032 - training.trainer - INFO - Epoch 59, Step 202596: Loss=6.0496, Acc=0.209, PPL=423.96
2025-09-22 03:07:48,927 - training.trainer - INFO - Epoch 59, Step 202696: Loss=6.4079, Acc=0.200, PPL=606.60
2025-09-22 03:07:56,898 - training.trainer - INFO - Epoch 59, Step 202796: Loss=6.3683, Acc=0.180, PPL=583.06
2025-09-22 03:08:04,798 - training.trainer - INFO - Epoch 59, Step 202896: Loss=5.9406, Acc=0.228, PPL=380.15
2025-09-22 03:08:21,257 - training.trainer - INFO - Epoch 60/100 completed in 278.21s - Train Loss: 5.4659, Train Acc: 0.284, Val Loss: 5.6719, Val Acc: 0.256
2025-09-22 03:08:21,559 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_60.pt
2025-09-22 03:08:22,153 - training.trainer - INFO - New best model saved with validation loss: 5.6719
2025-09-22 03:08:22,153 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_60.pt
2025-09-22 03:08:30,394 - training.trainer - INFO - Epoch 60, Step 203079: Loss=5.3709, Acc=0.296, PPL=215.06
2025-09-22 03:08:38,304 - training.trainer - INFO - Epoch 60, Step 203179: Loss=5.7109, Acc=0.253, PPL=302.14
2025-09-22 03:08:46,250 - training.trainer - INFO - Epoch 60, Step 203279: Loss=5.5168, Acc=0.290, PPL=248.84
2025-09-22 03:08:54,168 - training.trainer - INFO - Epoch 60, Step 203379: Loss=5.4045, Acc=0.323, PPL=222.41
2025-09-22 03:09:02,181 - training.trainer - INFO - Epoch 60, Step 203479: Loss=6.3329, Acc=0.233, PPL=562.78
2025-09-22 03:09:10,111 - training.trainer - INFO - Epoch 60, Step 203579: Loss=4.9831, Acc=0.333, PPL=145.93
2025-09-22 03:09:18,135 - training.trainer - INFO - Epoch 60, Step 203679: Loss=6.6215, Acc=0.192, PPL=751.10
2025-09-22 03:09:26,230 - training.trainer - INFO - Epoch 60, Step 203779: Loss=4.2752, Acc=0.391, PPL=71.89
2025-09-22 03:09:34,286 - training.trainer - INFO - Epoch 60, Step 203879: Loss=4.5182, Acc=0.360, PPL=91.67
2025-09-22 03:09:42,183 - training.trainer - INFO - Epoch 60, Step 203979: Loss=5.4050, Acc=0.353, PPL=222.52
2025-09-22 03:09:50,247 - training.trainer - INFO - Epoch 60, Step 204079: Loss=4.3441, Acc=0.467, PPL=77.02
2025-09-22 03:09:58,396 - training.trainer - INFO - Epoch 60, Step 204179: Loss=4.8544, Acc=0.385, PPL=128.30
2025-09-22 03:10:06,500 - training.trainer - INFO - Epoch 60, Step 204279: Loss=5.3962, Acc=0.296, PPL=220.56
2025-09-22 03:10:14,563 - training.trainer - INFO - Epoch 60, Step 204379: Loss=5.6446, Acc=0.278, PPL=282.76
2025-09-22 03:10:22,488 - training.trainer - INFO - Epoch 60, Step 204479: Loss=6.2731, Acc=0.190, PPL=530.11
2025-09-22 03:10:30,479 - training.trainer - INFO - Epoch 60, Step 204579: Loss=4.9287, Acc=0.370, PPL=138.19
2025-09-22 03:10:38,306 - training.trainer - INFO - Epoch 60, Step 204679: Loss=6.5791, Acc=0.182, PPL=719.88
2025-09-22 03:10:46,215 - training.trainer - INFO - Epoch 60, Step 204779: Loss=5.9119, Acc=0.286, PPL=369.41
2025-09-22 03:10:54,105 - training.trainer - INFO - Epoch 60, Step 204879: Loss=5.4249, Acc=0.278, PPL=227.00
2025-09-22 03:11:02,041 - training.trainer - INFO - Epoch 60, Step 204979: Loss=2.9513, Acc=0.781, PPL=19.13
2025-09-22 03:11:09,931 - training.trainer - INFO - Epoch 60, Step 205079: Loss=5.4821, Acc=0.333, PPL=240.34
2025-09-22 03:11:17,815 - training.trainer - INFO - Epoch 60, Step 205179: Loss=6.4809, Acc=0.259, PPL=652.58
2025-09-22 03:11:25,651 - training.trainer - INFO - Epoch 60, Step 205279: Loss=5.9849, Acc=0.250, PPL=397.40
2025-09-22 03:11:33,448 - training.trainer - INFO - Epoch 60, Step 205379: Loss=4.5526, Acc=0.447, PPL=94.88
2025-09-22 03:11:41,246 - training.trainer - INFO - Epoch 60, Step 205479: Loss=6.2881, Acc=0.206, PPL=538.15
2025-09-22 03:11:49,102 - training.trainer - INFO - Epoch 60, Step 205579: Loss=5.7853, Acc=0.314, PPL=325.49
2025-09-22 03:11:57,109 - training.trainer - INFO - Epoch 60, Step 205679: Loss=6.5306, Acc=0.178, PPL=685.80
2025-09-22 03:12:05,092 - training.trainer - INFO - Epoch 60, Step 205779: Loss=5.4864, Acc=0.316, PPL=241.38
2025-09-22 03:12:13,124 - training.trainer - INFO - Epoch 60, Step 205879: Loss=5.3392, Acc=0.304, PPL=208.35
2025-09-22 03:12:21,299 - training.trainer - INFO - Epoch 60, Step 205979: Loss=5.5529, Acc=0.245, PPL=257.98
2025-09-22 03:12:29,333 - training.trainer - INFO - Epoch 60, Step 206079: Loss=5.1376, Acc=0.371, PPL=170.31
2025-09-22 03:12:37,310 - training.trainer - INFO - Epoch 60, Step 206179: Loss=5.5522, Acc=0.250, PPL=257.80
2025-09-22 03:12:45,283 - training.trainer - INFO - Epoch 60, Step 206279: Loss=5.2859, Acc=0.308, PPL=197.53
2025-09-22 03:13:01,674 - training.trainer - INFO - Epoch 61/100 completed in 279.52s - Train Loss: 5.4589, Train Acc: 0.285, Val Loss: 5.6824, Val Acc: 0.255
2025-09-22 03:13:09,149 - training.trainer - INFO - Epoch 61, Step 206462: Loss=4.3324, Acc=0.361, PPL=76.13
2025-09-22 03:13:16,965 - training.trainer - INFO - Epoch 61, Step 206562: Loss=5.6579, Acc=0.255, PPL=286.54
2025-09-22 03:13:24,935 - training.trainer - INFO - Epoch 61, Step 206662: Loss=5.1341, Acc=0.333, PPL=169.71
2025-09-22 03:13:32,802 - training.trainer - INFO - Epoch 61, Step 206762: Loss=5.9193, Acc=0.200, PPL=372.16
2025-09-22 03:13:40,621 - training.trainer - INFO - Epoch 61, Step 206862: Loss=5.3158, Acc=0.346, PPL=203.53
2025-09-22 03:13:48,428 - training.trainer - INFO - Epoch 61, Step 206962: Loss=5.9446, Acc=0.300, PPL=381.68
2025-09-22 03:13:56,328 - training.trainer - INFO - Epoch 61, Step 207062: Loss=5.3906, Acc=0.265, PPL=219.33
2025-09-22 03:14:04,182 - training.trainer - INFO - Epoch 61, Step 207162: Loss=5.0434, Acc=0.281, PPL=155.00
2025-09-22 03:14:11,989 - training.trainer - INFO - Epoch 61, Step 207262: Loss=5.6955, Acc=0.280, PPL=297.52
2025-09-22 03:14:19,841 - training.trainer - INFO - Epoch 61, Step 207362: Loss=4.6314, Acc=0.268, PPL=102.65
2025-09-22 03:14:27,680 - training.trainer - INFO - Epoch 61, Step 207462: Loss=5.5032, Acc=0.263, PPL=245.46
2025-09-22 03:14:35,591 - training.trainer - INFO - Epoch 61, Step 207562: Loss=6.1253, Acc=0.192, PPL=457.28
2025-09-22 03:14:43,558 - training.trainer - INFO - Epoch 61, Step 207662: Loss=5.9630, Acc=0.209, PPL=388.78
2025-09-22 03:14:51,379 - training.trainer - INFO - Epoch 61, Step 207762: Loss=6.4790, Acc=0.212, PPL=651.30
2025-09-22 03:14:59,133 - training.trainer - INFO - Epoch 61, Step 207862: Loss=4.9073, Acc=0.370, PPL=135.27
2025-09-22 03:15:07,046 - training.trainer - INFO - Epoch 61, Step 207962: Loss=6.0717, Acc=0.300, PPL=433.42
2025-09-22 03:15:14,921 - training.trainer - INFO - Epoch 61, Step 208062: Loss=4.5482, Acc=0.417, PPL=94.46
2025-09-22 03:15:22,761 - training.trainer - INFO - Epoch 61, Step 208162: Loss=6.0752, Acc=0.207, PPL=434.95
2025-09-22 03:15:30,653 - training.trainer - INFO - Epoch 61, Step 208262: Loss=5.8687, Acc=0.180, PPL=353.80
2025-09-22 03:15:38,609 - training.trainer - INFO - Epoch 61, Step 208362: Loss=6.1271, Acc=0.306, PPL=458.10
2025-09-22 03:15:46,441 - training.trainer - INFO - Epoch 61, Step 208462: Loss=6.0602, Acc=0.300, PPL=428.47
2025-09-22 03:15:54,226 - training.trainer - INFO - Epoch 61, Step 208562: Loss=4.9800, Acc=0.333, PPL=145.48
2025-09-22 03:16:01,979 - training.trainer - INFO - Epoch 61, Step 208662: Loss=5.6119, Acc=0.256, PPL=273.67
2025-09-22 03:16:10,035 - training.trainer - INFO - Epoch 61, Step 208762: Loss=5.0867, Acc=0.273, PPL=161.85
2025-09-22 03:16:18,088 - training.trainer - INFO - Epoch 61, Step 208862: Loss=5.7474, Acc=0.186, PPL=313.38
2025-09-22 03:16:26,172 - training.trainer - INFO - Epoch 61, Step 208962: Loss=6.3562, Acc=0.190, PPL=576.04
2025-09-22 03:16:34,146 - training.trainer - INFO - Epoch 61, Step 209062: Loss=5.6423, Acc=0.308, PPL=282.12
2025-09-22 03:16:42,211 - training.trainer - INFO - Epoch 61, Step 209162: Loss=5.6368, Acc=0.214, PPL=280.58
2025-09-22 03:16:50,252 - training.trainer - INFO - Epoch 61, Step 209262: Loss=5.8013, Acc=0.304, PPL=330.73
2025-09-22 03:16:58,368 - training.trainer - INFO - Epoch 61, Step 209362: Loss=5.4437, Acc=0.283, PPL=231.30
2025-09-22 03:17:06,456 - training.trainer - INFO - Epoch 61, Step 209462: Loss=5.3067, Acc=0.222, PPL=201.68
2025-09-22 03:17:14,737 - training.trainer - INFO - Epoch 61, Step 209562: Loss=5.8738, Acc=0.171, PPL=355.60
2025-09-22 03:17:22,914 - training.trainer - INFO - Epoch 61, Step 209662: Loss=5.5355, Acc=0.176, PPL=253.53
2025-09-22 03:17:39,750 - training.trainer - INFO - Epoch 62/100 completed in 278.08s - Train Loss: 5.4603, Train Acc: 0.285, Val Loss: 5.6668, Val Acc: 0.258
2025-09-22 03:17:40,522 - training.trainer - INFO - New best model saved with validation loss: 5.6668
2025-09-22 03:17:40,522 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_62.pt
2025-09-22 03:17:48,982 - training.trainer - INFO - Epoch 62, Step 209845: Loss=5.1177, Acc=0.308, PPL=166.96
2025-09-22 03:17:57,104 - training.trainer - INFO - Epoch 62, Step 209945: Loss=5.7567, Acc=0.350, PPL=316.31
2025-09-22 03:18:05,002 - training.trainer - INFO - Epoch 62, Step 210045: Loss=6.5562, Acc=0.216, PPL=703.60
2025-09-22 03:18:12,974 - training.trainer - INFO - Epoch 62, Step 210145: Loss=4.3073, Acc=0.500, PPL=74.24
2025-09-22 03:18:20,986 - training.trainer - INFO - Epoch 62, Step 210245: Loss=5.9055, Acc=0.194, PPL=367.06
2025-09-22 03:18:28,923 - training.trainer - INFO - Epoch 62, Step 210345: Loss=5.9199, Acc=0.250, PPL=372.39
2025-09-22 03:18:36,787 - training.trainer - INFO - Epoch 62, Step 210445: Loss=5.5017, Acc=0.267, PPL=245.12
2025-09-22 03:18:44,614 - training.trainer - INFO - Epoch 62, Step 210545: Loss=3.1212, Acc=0.686, PPL=22.67
2025-09-22 03:18:52,567 - training.trainer - INFO - Epoch 62, Step 210645: Loss=4.4812, Acc=0.439, PPL=88.34
2025-09-22 03:19:00,507 - training.trainer - INFO - Epoch 62, Step 210745: Loss=6.3587, Acc=0.282, PPL=577.47
2025-09-22 03:19:08,407 - training.trainer - INFO - Epoch 62, Step 210845: Loss=5.9156, Acc=0.267, PPL=370.78
2025-09-22 03:19:16,356 - training.trainer - INFO - Epoch 62, Step 210945: Loss=6.1669, Acc=0.269, PPL=476.70
2025-09-22 03:19:24,274 - training.trainer - INFO - Epoch 62, Step 211045: Loss=5.3599, Acc=0.423, PPL=212.71
2025-09-22 03:19:32,164 - training.trainer - INFO - Epoch 62, Step 211145: Loss=6.4912, Acc=0.226, PPL=659.33
2025-09-22 03:19:40,111 - training.trainer - INFO - Epoch 62, Step 211245: Loss=5.9015, Acc=0.292, PPL=365.59
2025-09-22 03:19:48,072 - training.trainer - INFO - Epoch 62, Step 211345: Loss=5.9070, Acc=0.214, PPL=367.59
2025-09-22 03:19:56,039 - training.trainer - INFO - Epoch 62, Step 211445: Loss=5.4496, Acc=0.333, PPL=232.66
2025-09-22 03:20:03,877 - training.trainer - INFO - Epoch 62, Step 211545: Loss=5.5776, Acc=0.259, PPL=264.44
2025-09-22 03:20:11,709 - training.trainer - INFO - Epoch 62, Step 211645: Loss=5.7100, Acc=0.262, PPL=301.88
2025-09-22 03:20:19,583 - training.trainer - INFO - Epoch 62, Step 211745: Loss=6.2497, Acc=0.278, PPL=517.88
2025-09-22 03:20:27,476 - training.trainer - INFO - Epoch 62, Step 211845: Loss=6.4558, Acc=0.229, PPL=636.40
2025-09-22 03:20:35,472 - training.trainer - INFO - Epoch 62, Step 211945: Loss=5.6499, Acc=0.278, PPL=284.26
2025-09-22 03:20:43,461 - training.trainer - INFO - Epoch 62, Step 212045: Loss=5.5681, Acc=0.255, PPL=261.94
2025-09-22 03:20:51,344 - training.trainer - INFO - Epoch 62, Step 212145: Loss=4.8766, Acc=0.423, PPL=131.18
2025-09-22 03:20:59,279 - training.trainer - INFO - Epoch 62, Step 212245: Loss=6.2383, Acc=0.250, PPL=511.99
2025-09-22 03:21:07,224 - training.trainer - INFO - Epoch 62, Step 212345: Loss=5.8886, Acc=0.182, PPL=360.89
2025-09-22 03:21:15,098 - training.trainer - INFO - Epoch 62, Step 212445: Loss=6.0075, Acc=0.238, PPL=406.45
2025-09-22 03:21:22,984 - training.trainer - INFO - Epoch 62, Step 212545: Loss=5.5249, Acc=0.270, PPL=250.87
2025-09-22 03:21:30,900 - training.trainer - INFO - Epoch 62, Step 212645: Loss=4.9286, Acc=0.444, PPL=138.19
2025-09-22 03:21:38,837 - training.trainer - INFO - Epoch 62, Step 212745: Loss=4.8735, Acc=0.273, PPL=130.78
2025-09-22 03:21:46,683 - training.trainer - INFO - Epoch 62, Step 212845: Loss=5.1124, Acc=0.333, PPL=166.06
2025-09-22 03:21:54,538 - training.trainer - INFO - Epoch 62, Step 212945: Loss=5.4130, Acc=0.263, PPL=224.30
2025-09-22 03:22:02,444 - training.trainer - INFO - Epoch 62, Step 213045: Loss=6.1185, Acc=0.246, PPL=454.19
2025-09-22 03:22:19,371 - training.trainer - INFO - Epoch 63/100 completed in 278.85s - Train Loss: 5.4445, Train Acc: 0.286, Val Loss: 5.6721, Val Acc: 0.256
2025-09-22 03:22:26,841 - training.trainer - INFO - Epoch 63, Step 213228: Loss=5.4212, Acc=0.194, PPL=226.15
2025-09-22 03:22:34,725 - training.trainer - INFO - Epoch 63, Step 213328: Loss=6.4698, Acc=0.179, PPL=645.38
2025-09-22 03:22:42,751 - training.trainer - INFO - Epoch 63, Step 213428: Loss=5.5404, Acc=0.302, PPL=254.79
2025-09-22 03:22:50,670 - training.trainer - INFO - Epoch 63, Step 213528: Loss=5.1191, Acc=0.308, PPL=167.18
2025-09-22 03:22:58,588 - training.trainer - INFO - Epoch 63, Step 213628: Loss=4.9516, Acc=0.231, PPL=141.40
2025-09-22 03:23:06,560 - training.trainer - INFO - Epoch 63, Step 213728: Loss=5.9585, Acc=0.261, PPL=387.04
2025-09-22 03:23:14,560 - training.trainer - INFO - Epoch 63, Step 213828: Loss=5.8369, Acc=0.265, PPL=342.72
2025-09-22 03:23:22,521 - training.trainer - INFO - Epoch 63, Step 213928: Loss=4.7472, Acc=0.358, PPL=115.27
2025-09-22 03:23:30,497 - training.trainer - INFO - Epoch 63, Step 214028: Loss=4.6691, Acc=0.360, PPL=106.60
2025-09-22 03:23:38,379 - training.trainer - INFO - Epoch 63, Step 214128: Loss=5.9451, Acc=0.200, PPL=381.86
2025-09-22 03:23:46,306 - training.trainer - INFO - Epoch 63, Step 214228: Loss=5.5660, Acc=0.250, PPL=261.38
2025-09-22 03:23:54,201 - training.trainer - INFO - Epoch 63, Step 214328: Loss=5.4494, Acc=0.294, PPL=232.62
2025-09-22 03:24:02,107 - training.trainer - INFO - Epoch 63, Step 214428: Loss=2.6248, Acc=0.677, PPL=13.80
2025-09-22 03:24:09,934 - training.trainer - INFO - Epoch 63, Step 214528: Loss=5.2334, Acc=0.279, PPL=187.43
2025-09-22 03:24:17,842 - training.trainer - INFO - Epoch 63, Step 214628: Loss=4.0942, Acc=0.357, PPL=59.99
2025-09-22 03:24:25,806 - training.trainer - INFO - Epoch 63, Step 214728: Loss=5.6741, Acc=0.279, PPL=291.22
2025-09-22 03:24:33,689 - training.trainer - INFO - Epoch 63, Step 214828: Loss=5.8658, Acc=0.333, PPL=352.76
2025-09-22 03:24:41,684 - training.trainer - INFO - Epoch 63, Step 214928: Loss=5.8713, Acc=0.238, PPL=354.72
2025-09-22 03:24:49,608 - training.trainer - INFO - Epoch 63, Step 215028: Loss=4.3507, Acc=0.542, PPL=77.53
2025-09-22 03:24:57,603 - training.trainer - INFO - Epoch 63, Step 215128: Loss=5.6242, Acc=0.200, PPL=277.06
2025-09-22 03:25:05,466 - training.trainer - INFO - Epoch 63, Step 215228: Loss=6.1946, Acc=0.203, PPL=490.08
2025-09-22 03:25:13,372 - training.trainer - INFO - Epoch 63, Step 215328: Loss=6.1480, Acc=0.188, PPL=467.77
2025-09-22 03:25:21,281 - training.trainer - INFO - Epoch 63, Step 215428: Loss=3.3707, Acc=0.545, PPL=29.10
2025-09-22 03:25:29,211 - training.trainer - INFO - Epoch 63, Step 215528: Loss=6.1809, Acc=0.247, PPL=483.44
2025-09-22 03:25:37,106 - training.trainer - INFO - Epoch 63, Step 215628: Loss=6.0484, Acc=0.137, PPL=423.43
2025-09-22 03:25:44,969 - training.trainer - INFO - Epoch 63, Step 215728: Loss=5.3190, Acc=0.314, PPL=204.17
2025-09-22 03:25:52,869 - training.trainer - INFO - Epoch 63, Step 215828: Loss=4.9157, Acc=0.333, PPL=136.41
2025-09-22 03:26:00,777 - training.trainer - INFO - Epoch 63, Step 215928: Loss=5.8711, Acc=0.328, PPL=354.62
2025-09-22 03:26:08,633 - training.trainer - INFO - Epoch 63, Step 216028: Loss=5.1590, Acc=0.414, PPL=173.99
2025-09-22 03:26:16,520 - training.trainer - INFO - Epoch 63, Step 216128: Loss=5.3862, Acc=0.281, PPL=218.38
2025-09-22 03:26:24,400 - training.trainer - INFO - Epoch 63, Step 216228: Loss=5.9187, Acc=0.281, PPL=371.94
2025-09-22 03:26:32,287 - training.trainer - INFO - Epoch 63, Step 216328: Loss=5.3249, Acc=0.231, PPL=205.39
2025-09-22 03:26:40,167 - training.trainer - INFO - Epoch 63, Step 216428: Loss=5.2728, Acc=0.301, PPL=194.95
2025-09-22 03:26:57,619 - training.trainer - INFO - Epoch 64/100 completed in 278.25s - Train Loss: 5.4506, Train Acc: 0.286, Val Loss: 5.6704, Val Acc: 0.258
2025-09-22 03:27:05,954 - training.trainer - INFO - Epoch 64, Step 216611: Loss=6.1995, Acc=0.169, PPL=492.48
2025-09-22 03:27:13,900 - training.trainer - INFO - Epoch 64, Step 216711: Loss=6.0425, Acc=0.205, PPL=420.93
2025-09-22 03:27:21,862 - training.trainer - INFO - Epoch 64, Step 216811: Loss=5.4031, Acc=0.306, PPL=222.09
2025-09-22 03:27:29,756 - training.trainer - INFO - Epoch 64, Step 216911: Loss=5.3644, Acc=0.310, PPL=213.66
2025-09-22 03:27:37,641 - training.trainer - INFO - Epoch 64, Step 217011: Loss=5.8497, Acc=0.254, PPL=347.12
2025-09-22 03:27:45,406 - training.trainer - INFO - Epoch 64, Step 217111: Loss=6.0883, Acc=0.270, PPL=440.69
2025-09-22 03:27:53,208 - training.trainer - INFO - Epoch 64, Step 217211: Loss=6.1245, Acc=0.176, PPL=456.90
2025-09-22 03:28:01,008 - training.trainer - INFO - Epoch 64, Step 217311: Loss=4.4466, Acc=0.364, PPL=85.34
2025-09-22 03:28:08,848 - training.trainer - INFO - Epoch 64, Step 217411: Loss=5.9953, Acc=0.190, PPL=401.55
2025-09-22 03:28:16,670 - training.trainer - INFO - Epoch 64, Step 217511: Loss=6.0746, Acc=0.265, PPL=434.67
2025-09-22 03:28:24,405 - training.trainer - INFO - Epoch 64, Step 217611: Loss=6.3435, Acc=0.174, PPL=568.77
2025-09-22 03:28:32,222 - training.trainer - INFO - Epoch 64, Step 217711: Loss=4.1932, Acc=0.513, PPL=66.23
2025-09-22 03:28:39,988 - training.trainer - INFO - Epoch 64, Step 217811: Loss=4.4740, Acc=0.429, PPL=87.70
2025-09-22 03:28:47,806 - training.trainer - INFO - Epoch 64, Step 217911: Loss=5.5313, Acc=0.263, PPL=252.47
2025-09-22 03:28:55,579 - training.trainer - INFO - Epoch 64, Step 218011: Loss=4.9710, Acc=0.316, PPL=144.17
2025-09-22 03:29:03,325 - training.trainer - INFO - Epoch 64, Step 218111: Loss=5.5247, Acc=0.165, PPL=250.82
2025-09-22 03:29:11,081 - training.trainer - INFO - Epoch 64, Step 218211: Loss=4.8042, Acc=0.365, PPL=122.02
2025-09-22 03:29:18,937 - training.trainer - INFO - Epoch 64, Step 218311: Loss=4.3025, Acc=0.545, PPL=73.88
2025-09-22 03:29:26,756 - training.trainer - INFO - Epoch 64, Step 218411: Loss=4.7434, Acc=0.423, PPL=114.83
2025-09-22 03:29:34,561 - training.trainer - INFO - Epoch 64, Step 218511: Loss=5.3918, Acc=0.281, PPL=219.59
2025-09-22 03:29:42,280 - training.trainer - INFO - Epoch 64, Step 218611: Loss=5.7220, Acc=0.391, PPL=305.51
2025-09-22 03:29:50,122 - training.trainer - INFO - Epoch 64, Step 218711: Loss=6.0236, Acc=0.241, PPL=413.07
2025-09-22 03:29:57,906 - training.trainer - INFO - Epoch 64, Step 218811: Loss=6.9013, Acc=0.185, PPL=993.57
2025-09-22 03:30:05,727 - training.trainer - INFO - Epoch 64, Step 218911: Loss=5.8303, Acc=0.326, PPL=340.45
2025-09-22 03:30:13,502 - training.trainer - INFO - Epoch 64, Step 219011: Loss=5.5807, Acc=0.231, PPL=265.25
2025-09-22 03:30:21,409 - training.trainer - INFO - Epoch 64, Step 219111: Loss=5.5658, Acc=0.303, PPL=261.33
2025-09-22 03:30:29,357 - training.trainer - INFO - Epoch 64, Step 219211: Loss=4.4683, Acc=0.452, PPL=87.21
2025-09-22 03:30:37,397 - training.trainer - INFO - Epoch 64, Step 219311: Loss=4.2120, Acc=0.429, PPL=67.49
2025-09-22 03:30:45,435 - training.trainer - INFO - Epoch 64, Step 219411: Loss=5.4009, Acc=0.269, PPL=221.60
2025-09-22 03:30:53,559 - training.trainer - INFO - Epoch 64, Step 219511: Loss=5.4108, Acc=0.258, PPL=223.81
2025-09-22 03:31:01,593 - training.trainer - INFO - Epoch 64, Step 219611: Loss=5.9389, Acc=0.179, PPL=379.50
2025-09-22 03:31:09,614 - training.trainer - INFO - Epoch 64, Step 219711: Loss=6.4523, Acc=0.250, PPL=634.18
2025-09-22 03:31:17,642 - training.trainer - INFO - Epoch 64, Step 219811: Loss=4.9672, Acc=0.333, PPL=143.62
2025-09-22 03:31:35,287 - training.trainer - INFO - Epoch 65/100 completed in 277.67s - Train Loss: 5.4399, Train Acc: 0.288, Val Loss: 5.6715, Val Acc: 0.257
2025-09-22 03:31:35,708 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_65.pt
2025-09-22 03:31:44,215 - training.trainer - INFO - Epoch 65, Step 219994: Loss=5.4552, Acc=0.298, PPL=233.98
2025-09-22 03:31:52,190 - training.trainer - INFO - Epoch 65, Step 220094: Loss=5.7369, Acc=0.263, PPL=310.10
2025-09-22 03:32:00,221 - training.trainer - INFO - Epoch 65, Step 220194: Loss=6.5327, Acc=0.222, PPL=687.26
2025-09-22 03:32:08,236 - training.trainer - INFO - Epoch 65, Step 220294: Loss=4.3777, Acc=0.364, PPL=79.65
2025-09-22 03:32:16,440 - training.trainer - INFO - Epoch 65, Step 220394: Loss=5.0955, Acc=0.310, PPL=163.28
2025-09-22 03:32:24,592 - training.trainer - INFO - Epoch 65, Step 220494: Loss=5.4179, Acc=0.320, PPL=225.41
2025-09-22 03:32:32,676 - training.trainer - INFO - Epoch 65, Step 220594: Loss=5.3889, Acc=0.276, PPL=218.96
2025-09-22 03:32:40,745 - training.trainer - INFO - Epoch 65, Step 220694: Loss=5.5793, Acc=0.345, PPL=264.87
2025-09-22 03:32:48,860 - training.trainer - INFO - Epoch 65, Step 220794: Loss=6.0504, Acc=0.258, PPL=424.27
2025-09-22 03:32:56,829 - training.trainer - INFO - Epoch 65, Step 220894: Loss=6.0867, Acc=0.179, PPL=439.98
2025-09-22 03:33:04,899 - training.trainer - INFO - Epoch 65, Step 220994: Loss=5.7054, Acc=0.242, PPL=300.48
2025-09-22 03:33:13,024 - training.trainer - INFO - Epoch 65, Step 221094: Loss=5.9275, Acc=0.272, PPL=375.22
2025-09-22 03:33:21,015 - training.trainer - INFO - Epoch 65, Step 221194: Loss=5.0053, Acc=0.303, PPL=149.20
2025-09-22 03:33:28,979 - training.trainer - INFO - Epoch 65, Step 221294: Loss=5.4710, Acc=0.250, PPL=237.70
2025-09-22 03:33:36,951 - training.trainer - INFO - Epoch 65, Step 221394: Loss=4.1726, Acc=0.500, PPL=64.89
2025-09-22 03:33:44,808 - training.trainer - INFO - Epoch 65, Step 221494: Loss=5.3151, Acc=0.333, PPL=203.39
2025-09-22 03:33:52,665 - training.trainer - INFO - Epoch 65, Step 221594: Loss=5.7922, Acc=0.238, PPL=327.72
2025-09-22 03:34:00,534 - training.trainer - INFO - Epoch 65, Step 221694: Loss=4.9146, Acc=0.333, PPL=136.26
2025-09-22 03:34:08,464 - training.trainer - INFO - Epoch 65, Step 221794: Loss=5.4570, Acc=0.184, PPL=234.39
2025-09-22 03:34:16,294 - training.trainer - INFO - Epoch 65, Step 221894: Loss=5.9556, Acc=0.238, PPL=385.92
2025-09-22 03:34:24,151 - training.trainer - INFO - Epoch 65, Step 221994: Loss=5.4991, Acc=0.214, PPL=244.46
2025-09-22 03:34:32,002 - training.trainer - INFO - Epoch 65, Step 222094: Loss=5.5471, Acc=0.292, PPL=256.49
2025-09-22 03:34:39,892 - training.trainer - INFO - Epoch 65, Step 222194: Loss=5.5772, Acc=0.224, PPL=264.32
2025-09-22 03:34:47,893 - training.trainer - INFO - Epoch 65, Step 222294: Loss=6.0681, Acc=0.182, PPL=431.87
2025-09-22 03:34:55,787 - training.trainer - INFO - Epoch 65, Step 222394: Loss=5.7874, Acc=0.206, PPL=326.16
2025-09-22 03:35:03,656 - training.trainer - INFO - Epoch 65, Step 222494: Loss=5.5004, Acc=0.344, PPL=244.79
2025-09-22 03:35:11,524 - training.trainer - INFO - Epoch 65, Step 222594: Loss=4.7453, Acc=0.419, PPL=115.04
2025-09-22 03:35:19,514 - training.trainer - INFO - Epoch 65, Step 222694: Loss=4.6885, Acc=0.346, PPL=108.69
2025-09-22 03:35:27,478 - training.trainer - INFO - Epoch 65, Step 222794: Loss=5.5493, Acc=0.381, PPL=257.05
2025-09-22 03:35:35,432 - training.trainer - INFO - Epoch 65, Step 222894: Loss=5.2698, Acc=0.235, PPL=194.37
2025-09-22 03:35:43,692 - training.trainer - INFO - Epoch 65, Step 222994: Loss=5.8054, Acc=0.250, PPL=332.08
2025-09-22 03:35:51,753 - training.trainer - INFO - Epoch 65, Step 223094: Loss=4.6817, Acc=0.455, PPL=107.95
2025-09-22 03:35:59,680 - training.trainer - INFO - Epoch 65, Step 223194: Loss=4.5790, Acc=0.348, PPL=97.41
2025-09-22 03:36:17,083 - training.trainer - INFO - Epoch 66/100 completed in 281.37s - Train Loss: 5.4337, Train Acc: 0.289, Val Loss: 5.6730, Val Acc: 0.257
2025-09-22 03:36:25,715 - training.trainer - INFO - Epoch 66, Step 223377: Loss=5.4085, Acc=0.297, PPL=223.30
2025-09-22 03:36:33,774 - training.trainer - INFO - Epoch 66, Step 223477: Loss=5.2649, Acc=0.359, PPL=193.43
2025-09-22 03:36:41,723 - training.trainer - INFO - Epoch 66, Step 223577: Loss=6.1409, Acc=0.205, PPL=464.48
2025-09-22 03:36:49,600 - training.trainer - INFO - Epoch 66, Step 223677: Loss=4.8665, Acc=0.370, PPL=129.87
2025-09-22 03:36:57,859 - training.trainer - INFO - Epoch 66, Step 223777: Loss=6.0917, Acc=0.211, PPL=442.17
2025-09-22 03:37:05,867 - training.trainer - INFO - Epoch 66, Step 223877: Loss=5.1449, Acc=0.194, PPL=171.55
2025-09-22 03:37:13,825 - training.trainer - INFO - Epoch 66, Step 223977: Loss=5.8994, Acc=0.270, PPL=364.81
2025-09-22 03:37:21,918 - training.trainer - INFO - Epoch 66, Step 224077: Loss=4.8421, Acc=0.333, PPL=126.74
2025-09-22 03:37:30,005 - training.trainer - INFO - Epoch 66, Step 224177: Loss=5.7902, Acc=0.325, PPL=327.09
2025-09-22 03:37:37,914 - training.trainer - INFO - Epoch 66, Step 224277: Loss=5.9096, Acc=0.238, PPL=368.56
2025-09-22 03:37:45,784 - training.trainer - INFO - Epoch 66, Step 224377: Loss=5.8715, Acc=0.234, PPL=354.79
2025-09-22 03:37:53,680 - training.trainer - INFO - Epoch 66, Step 224477: Loss=6.0403, Acc=0.188, PPL=420.02
2025-09-22 03:38:01,640 - training.trainer - INFO - Epoch 66, Step 224577: Loss=3.5187, Acc=0.560, PPL=33.74
2025-09-22 03:38:09,696 - training.trainer - INFO - Epoch 66, Step 224677: Loss=5.0731, Acc=0.364, PPL=159.68
2025-09-22 03:38:17,719 - training.trainer - INFO - Epoch 66, Step 224777: Loss=5.5624, Acc=0.129, PPL=260.44
2025-09-22 03:38:25,687 - training.trainer - INFO - Epoch 66, Step 224877: Loss=5.8834, Acc=0.217, PPL=359.02
2025-09-22 03:38:33,750 - training.trainer - INFO - Epoch 66, Step 224977: Loss=3.6456, Acc=0.522, PPL=38.31
2025-09-22 03:38:41,681 - training.trainer - INFO - Epoch 66, Step 225077: Loss=6.2077, Acc=0.182, PPL=496.54
2025-09-22 03:38:49,610 - training.trainer - INFO - Epoch 66, Step 225177: Loss=5.6955, Acc=0.269, PPL=297.51
2025-09-22 03:38:57,515 - training.trainer - INFO - Epoch 66, Step 225277: Loss=5.5803, Acc=0.232, PPL=265.14
2025-09-22 03:39:05,467 - training.trainer - INFO - Epoch 66, Step 225377: Loss=5.6084, Acc=0.213, PPL=272.70
2025-09-22 03:39:13,455 - training.trainer - INFO - Epoch 66, Step 225477: Loss=5.4356, Acc=0.211, PPL=229.43
2025-09-22 03:39:21,376 - training.trainer - INFO - Epoch 66, Step 225577: Loss=5.4303, Acc=0.333, PPL=228.22
2025-09-22 03:39:29,354 - training.trainer - INFO - Epoch 66, Step 225677: Loss=6.1583, Acc=0.263, PPL=472.63
2025-09-22 03:39:37,333 - training.trainer - INFO - Epoch 66, Step 225777: Loss=6.1416, Acc=0.213, PPL=464.81
2025-09-22 03:39:45,270 - training.trainer - INFO - Epoch 66, Step 225877: Loss=4.7858, Acc=0.500, PPL=119.80
2025-09-22 03:39:53,186 - training.trainer - INFO - Epoch 66, Step 225977: Loss=6.7137, Acc=0.261, PPL=823.64
2025-09-22 03:40:01,125 - training.trainer - INFO - Epoch 66, Step 226077: Loss=5.6566, Acc=0.184, PPL=286.17
2025-09-22 03:40:09,108 - training.trainer - INFO - Epoch 66, Step 226177: Loss=6.1568, Acc=0.195, PPL=471.93
2025-09-22 03:40:17,002 - training.trainer - INFO - Epoch 66, Step 226277: Loss=4.8543, Acc=0.394, PPL=128.29
2025-09-22 03:40:24,949 - training.trainer - INFO - Epoch 66, Step 226377: Loss=6.0943, Acc=0.222, PPL=443.34
2025-09-22 03:40:32,849 - training.trainer - INFO - Epoch 66, Step 226477: Loss=5.6427, Acc=0.185, PPL=282.22
2025-09-22 03:40:40,780 - training.trainer - INFO - Epoch 66, Step 226577: Loss=5.4242, Acc=0.314, PPL=226.82
2025-09-22 03:40:58,338 - training.trainer - INFO - Epoch 67/100 completed in 281.25s - Train Loss: 5.4289, Train Acc: 0.289, Val Loss: 5.6775, Val Acc: 0.255
2025-09-22 03:41:06,610 - training.trainer - INFO - Epoch 67, Step 226760: Loss=5.7539, Acc=0.238, PPL=315.42
2025-09-22 03:41:14,775 - training.trainer - INFO - Epoch 67, Step 226860: Loss=5.4837, Acc=0.290, PPL=240.74
2025-09-22 03:41:22,920 - training.trainer - INFO - Epoch 67, Step 226960: Loss=3.7359, Acc=0.368, PPL=41.93
2025-09-22 03:41:30,956 - training.trainer - INFO - Epoch 67, Step 227060: Loss=4.8801, Acc=0.387, PPL=131.64
2025-09-22 03:41:38,946 - training.trainer - INFO - Epoch 67, Step 227160: Loss=6.0277, Acc=0.208, PPL=414.77
2025-09-22 03:41:47,020 - training.trainer - INFO - Epoch 67, Step 227260: Loss=5.0625, Acc=0.353, PPL=157.98
2025-09-22 03:41:54,978 - training.trainer - INFO - Epoch 67, Step 227360: Loss=4.6727, Acc=0.348, PPL=106.98
2025-09-22 03:42:02,843 - training.trainer - INFO - Epoch 67, Step 227460: Loss=6.7219, Acc=0.205, PPL=830.41
2025-09-22 03:42:10,683 - training.trainer - INFO - Epoch 67, Step 227560: Loss=5.9861, Acc=0.279, PPL=397.86
2025-09-22 03:42:18,578 - training.trainer - INFO - Epoch 67, Step 227660: Loss=5.4747, Acc=0.238, PPL=238.58
2025-09-22 03:42:26,517 - training.trainer - INFO - Epoch 67, Step 227760: Loss=5.6345, Acc=0.250, PPL=279.92
2025-09-22 03:42:34,477 - training.trainer - INFO - Epoch 67, Step 227860: Loss=5.4860, Acc=0.231, PPL=241.28
2025-09-22 03:42:42,367 - training.trainer - INFO - Epoch 67, Step 227960: Loss=5.4155, Acc=0.314, PPL=224.86
2025-09-22 03:42:50,238 - training.trainer - INFO - Epoch 67, Step 228060: Loss=5.0116, Acc=0.310, PPL=150.14
2025-09-22 03:42:58,204 - training.trainer - INFO - Epoch 67, Step 228160: Loss=6.1112, Acc=0.250, PPL=450.89
2025-09-22 03:43:06,104 - training.trainer - INFO - Epoch 67, Step 228260: Loss=5.0392, Acc=0.286, PPL=154.35
2025-09-22 03:43:13,956 - training.trainer - INFO - Epoch 67, Step 228360: Loss=3.8876, Acc=0.562, PPL=48.79
2025-09-22 03:43:21,907 - training.trainer - INFO - Epoch 67, Step 228460: Loss=5.4042, Acc=0.269, PPL=222.33
2025-09-22 03:43:29,919 - training.trainer - INFO - Epoch 67, Step 228560: Loss=6.0413, Acc=0.303, PPL=420.42
2025-09-22 03:43:37,937 - training.trainer - INFO - Epoch 67, Step 228660: Loss=5.4754, Acc=0.333, PPL=238.75
2025-09-22 03:43:46,017 - training.trainer - INFO - Epoch 67, Step 228760: Loss=5.0479, Acc=0.318, PPL=155.70
2025-09-22 03:43:53,980 - training.trainer - INFO - Epoch 67, Step 228860: Loss=4.3935, Acc=0.421, PPL=80.92
2025-09-22 03:44:02,001 - training.trainer - INFO - Epoch 67, Step 228960: Loss=5.7551, Acc=0.298, PPL=315.81
2025-09-22 03:44:09,893 - training.trainer - INFO - Epoch 67, Step 229060: Loss=5.8416, Acc=0.150, PPL=344.35
2025-09-22 03:44:17,858 - training.trainer - INFO - Epoch 67, Step 229160: Loss=6.2606, Acc=0.200, PPL=523.51
2025-09-22 03:44:25,835 - training.trainer - INFO - Epoch 67, Step 229260: Loss=6.2870, Acc=0.171, PPL=537.56
2025-09-22 03:44:33,760 - training.trainer - INFO - Epoch 67, Step 229360: Loss=6.1489, Acc=0.174, PPL=468.19
2025-09-22 03:44:41,787 - training.trainer - INFO - Epoch 67, Step 229460: Loss=5.8094, Acc=0.184, PPL=333.41
2025-09-22 03:44:49,929 - training.trainer - INFO - Epoch 67, Step 229560: Loss=5.0701, Acc=0.361, PPL=159.19
2025-09-22 03:44:57,887 - training.trainer - INFO - Epoch 67, Step 229660: Loss=5.3162, Acc=0.224, PPL=203.61
2025-09-22 03:45:05,852 - training.trainer - INFO - Epoch 67, Step 229760: Loss=5.4475, Acc=0.229, PPL=232.18
2025-09-22 03:45:13,698 - training.trainer - INFO - Epoch 67, Step 229860: Loss=5.6646, Acc=0.296, PPL=288.47
2025-09-22 03:45:21,608 - training.trainer - INFO - Epoch 67, Step 229960: Loss=5.3922, Acc=0.357, PPL=219.69
2025-09-22 03:45:38,609 - training.trainer - INFO - Epoch 68/100 completed in 280.27s - Train Loss: 5.4314, Train Acc: 0.289, Val Loss: 5.6738, Val Acc: 0.257
2025-09-22 03:45:46,643 - training.trainer - INFO - Epoch 68, Step 230143: Loss=5.1925, Acc=0.316, PPL=179.91
2025-09-22 03:45:54,663 - training.trainer - INFO - Epoch 68, Step 230243: Loss=5.4160, Acc=0.360, PPL=224.98
2025-09-22 03:46:02,695 - training.trainer - INFO - Epoch 68, Step 230343: Loss=5.6784, Acc=0.211, PPL=292.47
2025-09-22 03:46:10,733 - training.trainer - INFO - Epoch 68, Step 230443: Loss=6.1098, Acc=0.276, PPL=450.27
2025-09-22 03:46:18,701 - training.trainer - INFO - Epoch 68, Step 230543: Loss=4.9421, Acc=0.259, PPL=140.06
2025-09-22 03:46:26,671 - training.trainer - INFO - Epoch 68, Step 230643: Loss=5.2679, Acc=0.286, PPL=194.01
2025-09-22 03:46:34,583 - training.trainer - INFO - Epoch 68, Step 230743: Loss=5.7198, Acc=0.243, PPL=304.84
2025-09-22 03:46:42,495 - training.trainer - INFO - Epoch 68, Step 230843: Loss=5.5146, Acc=0.189, PPL=248.30
2025-09-22 03:46:50,380 - training.trainer - INFO - Epoch 68, Step 230943: Loss=5.8253, Acc=0.259, PPL=338.77
2025-09-22 03:46:58,330 - training.trainer - INFO - Epoch 68, Step 231043: Loss=6.0276, Acc=0.279, PPL=414.72
2025-09-22 03:47:06,224 - training.trainer - INFO - Epoch 68, Step 231143: Loss=5.9076, Acc=0.237, PPL=367.82
2025-09-22 03:47:14,119 - training.trainer - INFO - Epoch 68, Step 231243: Loss=5.9447, Acc=0.245, PPL=381.72
2025-09-22 03:47:22,047 - training.trainer - INFO - Epoch 68, Step 231343: Loss=6.1091, Acc=0.186, PPL=449.95
2025-09-22 03:47:29,975 - training.trainer - INFO - Epoch 68, Step 231443: Loss=5.4489, Acc=0.273, PPL=232.51
2025-09-22 03:47:37,897 - training.trainer - INFO - Epoch 68, Step 231543: Loss=5.4839, Acc=0.303, PPL=240.78
2025-09-22 03:47:45,788 - training.trainer - INFO - Epoch 68, Step 231643: Loss=5.2834, Acc=0.298, PPL=197.04
2025-09-22 03:47:53,707 - training.trainer - INFO - Epoch 68, Step 231743: Loss=5.3793, Acc=0.288, PPL=216.87
2025-09-22 03:48:01,579 - training.trainer - INFO - Epoch 68, Step 231843: Loss=5.2870, Acc=0.354, PPL=197.76
2025-09-22 03:48:09,468 - training.trainer - INFO - Epoch 68, Step 231943: Loss=5.4114, Acc=0.327, PPL=223.95
2025-09-22 03:48:17,331 - training.trainer - INFO - Epoch 68, Step 232043: Loss=5.6200, Acc=0.258, PPL=275.89
2025-09-22 03:48:25,276 - training.trainer - INFO - Epoch 68, Step 232143: Loss=4.5442, Acc=0.414, PPL=94.08
2025-09-22 03:48:33,187 - training.trainer - INFO - Epoch 68, Step 232243: Loss=5.0107, Acc=0.327, PPL=150.00
2025-09-22 03:48:41,126 - training.trainer - INFO - Epoch 68, Step 232343: Loss=5.1759, Acc=0.412, PPL=176.95
2025-09-22 03:48:49,033 - training.trainer - INFO - Epoch 68, Step 232443: Loss=5.3740, Acc=0.242, PPL=215.73
2025-09-22 03:48:56,983 - training.trainer - INFO - Epoch 68, Step 232543: Loss=5.6143, Acc=0.260, PPL=274.32
2025-09-22 03:49:04,819 - training.trainer - INFO - Epoch 68, Step 232643: Loss=5.4284, Acc=0.303, PPL=227.79
2025-09-22 03:49:12,713 - training.trainer - INFO - Epoch 68, Step 232743: Loss=6.0959, Acc=0.250, PPL=444.04
2025-09-22 03:49:20,759 - training.trainer - INFO - Epoch 68, Step 232843: Loss=4.9644, Acc=0.353, PPL=143.22
2025-09-22 03:49:28,880 - training.trainer - INFO - Epoch 68, Step 232943: Loss=5.2263, Acc=0.364, PPL=186.10
2025-09-22 03:49:36,932 - training.trainer - INFO - Epoch 68, Step 233043: Loss=6.4376, Acc=0.149, PPL=624.90
2025-09-22 03:49:44,926 - training.trainer - INFO - Epoch 68, Step 233143: Loss=6.6551, Acc=0.173, PPL=776.76
2025-09-22 03:49:52,844 - training.trainer - INFO - Epoch 68, Step 233243: Loss=5.6118, Acc=0.280, PPL=273.64
2025-09-22 03:50:00,909 - training.trainer - INFO - Epoch 68, Step 233343: Loss=5.1080, Acc=0.421, PPL=165.35
2025-09-22 03:50:18,580 - training.trainer - INFO - Epoch 69/100 completed in 279.97s - Train Loss: 5.4252, Train Acc: 0.290, Val Loss: 5.6711, Val Acc: 0.257
2025-09-22 03:50:26,908 - training.trainer - INFO - Epoch 69, Step 233526: Loss=5.5773, Acc=0.250, PPL=264.37
2025-09-22 03:50:34,886 - training.trainer - INFO - Epoch 69, Step 233626: Loss=5.5584, Acc=0.220, PPL=259.42
2025-09-22 03:50:42,813 - training.trainer - INFO - Epoch 69, Step 233726: Loss=4.8833, Acc=0.318, PPL=132.07
2025-09-22 03:50:50,636 - training.trainer - INFO - Epoch 69, Step 233826: Loss=3.7566, Acc=0.538, PPL=42.80
2025-09-22 03:50:58,501 - training.trainer - INFO - Epoch 69, Step 233926: Loss=5.9501, Acc=0.217, PPL=383.80
2025-09-22 03:51:06,468 - training.trainer - INFO - Epoch 69, Step 234026: Loss=5.5641, Acc=0.344, PPL=260.89
2025-09-22 03:51:14,271 - training.trainer - INFO - Epoch 69, Step 234126: Loss=5.0093, Acc=0.286, PPL=149.79
2025-09-22 03:51:22,087 - training.trainer - INFO - Epoch 69, Step 234226: Loss=5.9148, Acc=0.290, PPL=370.49
2025-09-22 03:51:29,957 - training.trainer - INFO - Epoch 69, Step 234326: Loss=4.7736, Acc=0.500, PPL=118.34
2025-09-22 03:51:37,903 - training.trainer - INFO - Epoch 69, Step 234426: Loss=4.4592, Acc=0.500, PPL=86.41
2025-09-22 03:51:45,738 - training.trainer - INFO - Epoch 69, Step 234526: Loss=5.4470, Acc=0.244, PPL=232.06
2025-09-22 03:51:53,608 - training.trainer - INFO - Epoch 69, Step 234626: Loss=4.8511, Acc=0.371, PPL=127.88
2025-09-22 03:52:01,458 - training.trainer - INFO - Epoch 69, Step 234726: Loss=5.2415, Acc=0.273, PPL=188.95
2025-09-22 03:52:09,414 - training.trainer - INFO - Epoch 69, Step 234826: Loss=6.0949, Acc=0.169, PPL=443.57
2025-09-22 03:52:17,255 - training.trainer - INFO - Epoch 69, Step 234926: Loss=5.7994, Acc=0.229, PPL=330.10
2025-09-22 03:52:25,116 - training.trainer - INFO - Epoch 69, Step 235026: Loss=5.7656, Acc=0.229, PPL=319.12
2025-09-22 03:52:32,863 - training.trainer - INFO - Epoch 69, Step 235126: Loss=6.1060, Acc=0.276, PPL=448.56
2025-09-22 03:52:40,680 - training.trainer - INFO - Epoch 69, Step 235226: Loss=5.6528, Acc=0.267, PPL=285.08
2025-09-22 03:52:48,550 - training.trainer - INFO - Epoch 69, Step 235326: Loss=6.0297, Acc=0.255, PPL=415.60
2025-09-22 03:52:56,336 - training.trainer - INFO - Epoch 69, Step 235426: Loss=5.9850, Acc=0.140, PPL=397.40
2025-09-22 03:53:04,110 - training.trainer - INFO - Epoch 69, Step 235526: Loss=4.9966, Acc=0.360, PPL=147.91
2025-09-22 03:53:12,172 - training.trainer - INFO - Epoch 69, Step 235626: Loss=5.5451, Acc=0.250, PPL=255.99
2025-09-22 03:53:20,298 - training.trainer - INFO - Epoch 69, Step 235726: Loss=6.4622, Acc=0.190, PPL=640.45
2025-09-22 03:53:28,331 - training.trainer - INFO - Epoch 69, Step 235826: Loss=3.7184, Acc=0.500, PPL=41.20
2025-09-22 03:53:36,386 - training.trainer - INFO - Epoch 69, Step 235926: Loss=6.2530, Acc=0.250, PPL=519.56
2025-09-22 03:53:44,374 - training.trainer - INFO - Epoch 69, Step 236026: Loss=4.2940, Acc=0.364, PPL=73.26
2025-09-22 03:53:52,404 - training.trainer - INFO - Epoch 69, Step 236126: Loss=5.6013, Acc=0.300, PPL=270.78
2025-09-22 03:54:00,437 - training.trainer - INFO - Epoch 69, Step 236226: Loss=5.7628, Acc=0.220, PPL=318.24
2025-09-22 03:54:08,400 - training.trainer - INFO - Epoch 69, Step 236326: Loss=6.0789, Acc=0.222, PPL=436.57
2025-09-22 03:54:16,377 - training.trainer - INFO - Epoch 69, Step 236426: Loss=4.8374, Acc=0.348, PPL=126.14
2025-09-22 03:54:24,396 - training.trainer - INFO - Epoch 69, Step 236526: Loss=6.1347, Acc=0.208, PPL=461.59
2025-09-22 03:54:32,423 - training.trainer - INFO - Epoch 69, Step 236626: Loss=5.7402, Acc=0.238, PPL=311.14
2025-09-22 03:54:40,535 - training.trainer - INFO - Epoch 69, Step 236726: Loss=5.5145, Acc=0.352, PPL=248.26
2025-09-22 03:54:58,103 - training.trainer - INFO - Epoch 70/100 completed in 279.52s - Train Loss: 5.4252, Train Acc: 0.290, Val Loss: 5.6700, Val Acc: 0.255
2025-09-22 03:54:58,533 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_70.pt
2025-09-22 03:55:06,995 - training.trainer - INFO - Epoch 70, Step 236909: Loss=5.4498, Acc=0.308, PPL=232.70
2025-09-22 03:55:15,091 - training.trainer - INFO - Epoch 70, Step 237009: Loss=5.9837, Acc=0.232, PPL=396.91
2025-09-22 03:55:23,081 - training.trainer - INFO - Epoch 70, Step 237109: Loss=6.0835, Acc=0.233, PPL=438.56
2025-09-22 03:55:31,047 - training.trainer - INFO - Epoch 70, Step 237209: Loss=3.4311, Acc=0.455, PPL=30.91
2025-09-22 03:55:39,228 - training.trainer - INFO - Epoch 70, Step 237309: Loss=5.5773, Acc=0.250, PPL=264.36
2025-09-22 03:55:47,371 - training.trainer - INFO - Epoch 70, Step 237409: Loss=5.9552, Acc=0.172, PPL=385.75
2025-09-22 03:55:55,284 - training.trainer - INFO - Epoch 70, Step 237509: Loss=5.5211, Acc=0.293, PPL=249.91
2025-09-22 03:56:03,204 - training.trainer - INFO - Epoch 70, Step 237609: Loss=5.0084, Acc=0.333, PPL=149.67
2025-09-22 03:56:11,171 - training.trainer - INFO - Epoch 70, Step 237709: Loss=6.1812, Acc=0.233, PPL=483.57
2025-09-22 03:56:19,120 - training.trainer - INFO - Epoch 70, Step 237809: Loss=4.7815, Acc=0.379, PPL=119.28
2025-09-22 03:56:27,274 - training.trainer - INFO - Epoch 70, Step 237909: Loss=3.7557, Acc=0.524, PPL=42.77
2025-09-22 03:56:35,443 - training.trainer - INFO - Epoch 70, Step 238009: Loss=5.0053, Acc=0.300, PPL=149.20
2025-09-22 03:56:43,586 - training.trainer - INFO - Epoch 70, Step 238109: Loss=5.5507, Acc=0.260, PPL=257.42
2025-09-22 03:56:51,742 - training.trainer - INFO - Epoch 70, Step 238209: Loss=6.5127, Acc=0.226, PPL=673.65
2025-09-22 03:56:59,913 - training.trainer - INFO - Epoch 70, Step 238309: Loss=5.0337, Acc=0.310, PPL=153.51
2025-09-22 03:57:08,099 - training.trainer - INFO - Epoch 70, Step 238409: Loss=4.4571, Acc=0.400, PPL=86.23
2025-09-22 03:57:16,218 - training.trainer - INFO - Epoch 70, Step 238509: Loss=5.2885, Acc=0.324, PPL=198.04
2025-09-22 03:57:24,194 - training.trainer - INFO - Epoch 70, Step 238609: Loss=5.2030, Acc=0.293, PPL=181.82
2025-09-22 03:57:32,361 - training.trainer - INFO - Epoch 70, Step 238709: Loss=5.6485, Acc=0.344, PPL=283.86
2025-09-22 03:57:40,663 - training.trainer - INFO - Epoch 70, Step 238809: Loss=5.1913, Acc=0.316, PPL=179.70
2025-09-22 03:57:48,925 - training.trainer - INFO - Epoch 70, Step 238909: Loss=5.0242, Acc=0.235, PPL=152.05
2025-09-22 03:57:57,067 - training.trainer - INFO - Epoch 70, Step 239009: Loss=4.1295, Acc=0.476, PPL=62.15
2025-09-22 03:58:05,231 - training.trainer - INFO - Epoch 70, Step 239109: Loss=4.7628, Acc=0.421, PPL=117.07
2025-09-22 03:58:13,265 - training.trainer - INFO - Epoch 70, Step 239209: Loss=4.3582, Acc=0.423, PPL=78.11
2025-09-22 03:58:21,240 - training.trainer - INFO - Epoch 70, Step 239309: Loss=5.4644, Acc=0.239, PPL=236.13
2025-09-22 03:58:29,230 - training.trainer - INFO - Epoch 70, Step 239409: Loss=5.5700, Acc=0.225, PPL=262.43
2025-09-22 03:58:37,128 - training.trainer - INFO - Epoch 70, Step 239509: Loss=5.2636, Acc=0.340, PPL=193.18
2025-09-22 03:58:45,080 - training.trainer - INFO - Epoch 70, Step 239609: Loss=5.4344, Acc=0.254, PPL=229.16
2025-09-22 03:58:53,030 - training.trainer - INFO - Epoch 70, Step 239709: Loss=5.8105, Acc=0.270, PPL=333.79
2025-09-22 03:59:01,067 - training.trainer - INFO - Epoch 70, Step 239809: Loss=5.2907, Acc=0.250, PPL=198.48
2025-09-22 03:59:09,109 - training.trainer - INFO - Epoch 70, Step 239909: Loss=5.7510, Acc=0.364, PPL=314.51
2025-09-22 03:59:17,174 - training.trainer - INFO - Epoch 70, Step 240009: Loss=5.0474, Acc=0.448, PPL=155.61
2025-09-22 03:59:25,162 - training.trainer - INFO - Epoch 70, Step 240109: Loss=4.8529, Acc=0.370, PPL=128.11
2025-09-22 03:59:42,776 - training.trainer - INFO - Epoch 71/100 completed in 284.24s - Train Loss: 5.4175, Train Acc: 0.292, Val Loss: 5.6669, Val Acc: 0.256
2025-09-22 03:59:51,390 - training.trainer - INFO - Epoch 71, Step 240292: Loss=5.8882, Acc=0.239, PPL=360.74
2025-09-22 03:59:59,536 - training.trainer - INFO - Epoch 71, Step 240392: Loss=5.8825, Acc=0.212, PPL=358.72
2025-09-22 04:00:07,669 - training.trainer - INFO - Epoch 71, Step 240492: Loss=4.8726, Acc=0.370, PPL=130.66
2025-09-22 04:00:15,695 - training.trainer - INFO - Epoch 71, Step 240592: Loss=5.5227, Acc=0.236, PPL=250.30
2025-09-22 04:00:23,674 - training.trainer - INFO - Epoch 71, Step 240692: Loss=4.8238, Acc=0.296, PPL=124.43
2025-09-22 04:00:31,753 - training.trainer - INFO - Epoch 71, Step 240792: Loss=5.2574, Acc=0.385, PPL=191.97
2025-09-22 04:00:39,652 - training.trainer - INFO - Epoch 71, Step 240892: Loss=5.8272, Acc=0.241, PPL=339.39
2025-09-22 04:00:47,570 - training.trainer - INFO - Epoch 71, Step 240992: Loss=5.4879, Acc=0.261, PPL=241.75
2025-09-22 04:00:55,500 - training.trainer - INFO - Epoch 71, Step 241092: Loss=5.8017, Acc=0.273, PPL=330.87
2025-09-22 04:01:03,358 - training.trainer - INFO - Epoch 71, Step 241192: Loss=4.6577, Acc=0.407, PPL=105.39
2025-09-22 04:01:11,287 - training.trainer - INFO - Epoch 71, Step 241292: Loss=5.4071, Acc=0.261, PPL=222.98
2025-09-22 04:01:19,301 - training.trainer - INFO - Epoch 71, Step 241392: Loss=5.0947, Acc=0.375, PPL=163.15
2025-09-22 04:01:27,278 - training.trainer - INFO - Epoch 71, Step 241492: Loss=5.0653, Acc=0.259, PPL=158.43
2025-09-22 04:01:35,368 - training.trainer - INFO - Epoch 71, Step 241592: Loss=3.7888, Acc=0.455, PPL=44.20
2025-09-22 04:01:43,453 - training.trainer - INFO - Epoch 71, Step 241692: Loss=5.5721, Acc=0.278, PPL=262.98
2025-09-22 04:01:51,362 - training.trainer - INFO - Epoch 71, Step 241792: Loss=5.7803, Acc=0.255, PPL=323.85
2025-09-22 04:01:59,356 - training.trainer - INFO - Epoch 71, Step 241892: Loss=5.3825, Acc=0.308, PPL=217.57
2025-09-22 04:02:07,417 - training.trainer - INFO - Epoch 71, Step 241992: Loss=5.8122, Acc=0.219, PPL=334.34
2025-09-22 04:02:15,526 - training.trainer - INFO - Epoch 71, Step 242092: Loss=5.4800, Acc=0.182, PPL=239.86
2025-09-22 04:02:23,467 - training.trainer - INFO - Epoch 71, Step 242192: Loss=5.3767, Acc=0.323, PPL=216.30
2025-09-22 04:02:31,367 - training.trainer - INFO - Epoch 71, Step 242292: Loss=5.5435, Acc=0.322, PPL=255.57
2025-09-22 04:02:39,358 - training.trainer - INFO - Epoch 71, Step 242392: Loss=5.7920, Acc=0.156, PPL=327.67
2025-09-22 04:02:47,345 - training.trainer - INFO - Epoch 71, Step 242492: Loss=5.8610, Acc=0.275, PPL=351.06
2025-09-22 04:02:55,211 - training.trainer - INFO - Epoch 71, Step 242592: Loss=5.4882, Acc=0.308, PPL=241.83
2025-09-22 04:03:03,046 - training.trainer - INFO - Epoch 71, Step 242692: Loss=5.3422, Acc=0.238, PPL=208.97
2025-09-22 04:03:10,996 - training.trainer - INFO - Epoch 71, Step 242792: Loss=5.1230, Acc=0.254, PPL=167.84
2025-09-22 04:03:18,844 - training.trainer - INFO - Epoch 71, Step 242892: Loss=4.8340, Acc=0.250, PPL=125.72
2025-09-22 04:03:26,669 - training.trainer - INFO - Epoch 71, Step 242992: Loss=3.8157, Acc=0.370, PPL=45.41
2025-09-22 04:03:34,501 - training.trainer - INFO - Epoch 71, Step 243092: Loss=5.9842, Acc=0.270, PPL=397.12
2025-09-22 04:03:42,350 - training.trainer - INFO - Epoch 71, Step 243192: Loss=4.6639, Acc=0.342, PPL=106.05
2025-09-22 04:03:50,183 - training.trainer - INFO - Epoch 71, Step 243292: Loss=5.7114, Acc=0.167, PPL=302.31
2025-09-22 04:03:58,078 - training.trainer - INFO - Epoch 71, Step 243392: Loss=4.4381, Acc=0.294, PPL=84.61
2025-09-22 04:04:05,892 - training.trainer - INFO - Epoch 71, Step 243492: Loss=4.0850, Acc=0.526, PPL=59.44
2025-09-22 04:04:22,230 - training.trainer - INFO - Epoch 72/100 completed in 279.45s - Train Loss: 5.4110, Train Acc: 0.293, Val Loss: 5.6673, Val Acc: 0.257
2025-09-22 04:04:30,138 - training.trainer - INFO - Epoch 72, Step 243675: Loss=5.3623, Acc=0.300, PPL=213.21
2025-09-22 04:04:38,080 - training.trainer - INFO - Epoch 72, Step 243775: Loss=5.4746, Acc=0.306, PPL=238.55
2025-09-22 04:04:46,092 - training.trainer - INFO - Epoch 72, Step 243875: Loss=5.0647, Acc=0.407, PPL=158.34
2025-09-22 04:04:54,030 - training.trainer - INFO - Epoch 72, Step 243975: Loss=5.0377, Acc=0.283, PPL=154.12
2025-09-22 04:05:01,979 - training.trainer - INFO - Epoch 72, Step 244075: Loss=3.2481, Acc=0.500, PPL=25.74
2025-09-22 04:05:09,913 - training.trainer - INFO - Epoch 72, Step 244175: Loss=3.9454, Acc=0.524, PPL=51.70
2025-09-22 04:05:17,841 - training.trainer - INFO - Epoch 72, Step 244275: Loss=5.6958, Acc=0.254, PPL=297.61
2025-09-22 04:05:25,747 - training.trainer - INFO - Epoch 72, Step 244375: Loss=5.7689, Acc=0.361, PPL=320.17
2025-09-22 04:05:33,601 - training.trainer - INFO - Epoch 72, Step 244475: Loss=4.6300, Acc=0.400, PPL=102.51
2025-09-22 04:05:41,420 - training.trainer - INFO - Epoch 72, Step 244575: Loss=5.4962, Acc=0.286, PPL=243.77
2025-09-22 04:05:49,273 - training.trainer - INFO - Epoch 72, Step 244675: Loss=4.6821, Acc=0.280, PPL=107.99
2025-09-22 04:05:57,094 - training.trainer - INFO - Epoch 72, Step 244775: Loss=5.0439, Acc=0.257, PPL=155.07
2025-09-22 04:06:04,898 - training.trainer - INFO - Epoch 72, Step 244875: Loss=5.7680, Acc=0.250, PPL=319.89
2025-09-22 04:06:12,748 - training.trainer - INFO - Epoch 72, Step 244975: Loss=5.0795, Acc=0.367, PPL=160.69
2025-09-22 04:06:20,537 - training.trainer - INFO - Epoch 72, Step 245075: Loss=6.1121, Acc=0.217, PPL=451.29
2025-09-22 04:06:28,423 - training.trainer - INFO - Epoch 72, Step 245175: Loss=5.7417, Acc=0.259, PPL=311.59
2025-09-22 04:06:36,230 - training.trainer - INFO - Epoch 72, Step 245275: Loss=6.3398, Acc=0.247, PPL=566.71
2025-09-22 04:06:44,045 - training.trainer - INFO - Epoch 72, Step 245375: Loss=5.3014, Acc=0.276, PPL=200.62
2025-09-22 04:06:51,876 - training.trainer - INFO - Epoch 72, Step 245475: Loss=6.1381, Acc=0.162, PPL=463.18
2025-09-22 04:06:59,754 - training.trainer - INFO - Epoch 72, Step 245575: Loss=5.4796, Acc=0.231, PPL=239.75
2025-09-22 04:07:07,546 - training.trainer - INFO - Epoch 72, Step 245675: Loss=5.7079, Acc=0.264, PPL=301.24
2025-09-22 04:07:15,428 - training.trainer - INFO - Epoch 72, Step 245775: Loss=5.4227, Acc=0.381, PPL=226.48
2025-09-22 04:07:23,385 - training.trainer - INFO - Epoch 72, Step 245875: Loss=4.8397, Acc=0.257, PPL=126.44
2025-09-22 04:07:31,250 - training.trainer - INFO - Epoch 72, Step 245975: Loss=5.9765, Acc=0.220, PPL=394.04
2025-09-22 04:07:39,040 - training.trainer - INFO - Epoch 72, Step 246075: Loss=4.8621, Acc=0.319, PPL=129.30
2025-09-22 04:07:46,912 - training.trainer - INFO - Epoch 72, Step 246175: Loss=5.2830, Acc=0.268, PPL=196.96
2025-09-22 04:07:54,788 - training.trainer - INFO - Epoch 72, Step 246275: Loss=4.5605, Acc=0.333, PPL=95.63
2025-09-22 04:08:02,732 - training.trainer - INFO - Epoch 72, Step 246375: Loss=5.0934, Acc=0.302, PPL=162.94
2025-09-22 04:08:10,611 - training.trainer - INFO - Epoch 72, Step 246475: Loss=5.8392, Acc=0.231, PPL=343.51
2025-09-22 04:08:18,592 - training.trainer - INFO - Epoch 72, Step 246575: Loss=3.7928, Acc=0.548, PPL=44.38
2025-09-22 04:08:26,552 - training.trainer - INFO - Epoch 72, Step 246675: Loss=5.2809, Acc=0.289, PPL=196.55
2025-09-22 04:08:34,484 - training.trainer - INFO - Epoch 72, Step 246775: Loss=4.4052, Acc=0.368, PPL=81.88
2025-09-22 04:08:42,372 - training.trainer - INFO - Epoch 72, Step 246875: Loss=5.6637, Acc=0.284, PPL=288.23
2025-09-22 04:08:59,770 - training.trainer - INFO - Epoch 73/100 completed in 277.54s - Train Loss: 5.4063, Train Acc: 0.292, Val Loss: 5.6675, Val Acc: 0.256
2025-09-22 04:09:07,980 - training.trainer - INFO - Epoch 73, Step 247058: Loss=5.2972, Acc=0.277, PPL=199.78
2025-09-22 04:09:15,880 - training.trainer - INFO - Epoch 73, Step 247158: Loss=4.5831, Acc=0.409, PPL=97.82
2025-09-22 04:09:23,822 - training.trainer - INFO - Epoch 73, Step 247258: Loss=5.3730, Acc=0.228, PPL=215.51
2025-09-22 04:09:31,741 - training.trainer - INFO - Epoch 73, Step 247358: Loss=6.0154, Acc=0.205, PPL=409.69
2025-09-22 04:09:39,719 - training.trainer - INFO - Epoch 73, Step 247458: Loss=6.2553, Acc=0.375, PPL=520.76
2025-09-22 04:09:47,606 - training.trainer - INFO - Epoch 73, Step 247558: Loss=6.0495, Acc=0.167, PPL=423.89
2025-09-22 04:09:55,505 - training.trainer - INFO - Epoch 73, Step 247658: Loss=5.5063, Acc=0.306, PPL=246.24
2025-09-22 04:10:03,353 - training.trainer - INFO - Epoch 73, Step 247758: Loss=3.3530, Acc=0.464, PPL=28.59
2025-09-22 04:10:11,278 - training.trainer - INFO - Epoch 73, Step 247858: Loss=4.9727, Acc=0.333, PPL=144.41
2025-09-22 04:10:19,083 - training.trainer - INFO - Epoch 73, Step 247958: Loss=6.1274, Acc=0.167, PPL=458.22
2025-09-22 04:10:27,015 - training.trainer - INFO - Epoch 73, Step 248058: Loss=5.7845, Acc=0.317, PPL=325.21
2025-09-22 04:10:35,156 - training.trainer - INFO - Epoch 73, Step 248158: Loss=5.1417, Acc=0.350, PPL=171.00
2025-09-22 04:10:43,103 - training.trainer - INFO - Epoch 73, Step 248258: Loss=5.1960, Acc=0.471, PPL=180.55
2025-09-22 04:10:51,053 - training.trainer - INFO - Epoch 73, Step 248358: Loss=5.0051, Acc=0.250, PPL=149.18
2025-09-22 04:10:58,951 - training.trainer - INFO - Epoch 73, Step 248458: Loss=5.4345, Acc=0.286, PPL=229.18
2025-09-22 04:11:06,838 - training.trainer - INFO - Epoch 73, Step 248558: Loss=5.0490, Acc=0.321, PPL=155.86
2025-09-22 04:11:14,689 - training.trainer - INFO - Epoch 73, Step 248658: Loss=5.7125, Acc=0.283, PPL=302.63
2025-09-22 04:11:22,585 - training.trainer - INFO - Epoch 73, Step 248758: Loss=5.7099, Acc=0.298, PPL=301.83
2025-09-22 04:11:30,453 - training.trainer - INFO - Epoch 73, Step 248858: Loss=5.5970, Acc=0.259, PPL=269.63
2025-09-22 04:11:38,347 - training.trainer - INFO - Epoch 73, Step 248958: Loss=5.9346, Acc=0.191, PPL=377.88
2025-09-22 04:11:46,281 - training.trainer - INFO - Epoch 73, Step 249058: Loss=5.2985, Acc=0.294, PPL=200.03
2025-09-22 04:11:54,202 - training.trainer - INFO - Epoch 73, Step 249158: Loss=5.7028, Acc=0.237, PPL=299.70
2025-09-22 04:12:02,087 - training.trainer - INFO - Epoch 73, Step 249258: Loss=6.1406, Acc=0.222, PPL=464.35
2025-09-22 04:12:09,994 - training.trainer - INFO - Epoch 73, Step 249358: Loss=5.2631, Acc=0.312, PPL=193.09
2025-09-22 04:12:17,840 - training.trainer - INFO - Epoch 73, Step 249458: Loss=5.6731, Acc=0.357, PPL=290.95
2025-09-22 04:12:25,730 - training.trainer - INFO - Epoch 73, Step 249558: Loss=5.6333, Acc=0.278, PPL=279.58
2025-09-22 04:12:33,832 - training.trainer - INFO - Epoch 73, Step 249658: Loss=5.6937, Acc=0.222, PPL=296.99
2025-09-22 04:12:41,981 - training.trainer - INFO - Epoch 73, Step 249758: Loss=6.3045, Acc=0.149, PPL=547.01
2025-09-22 04:12:49,986 - training.trainer - INFO - Epoch 73, Step 249858: Loss=5.2968, Acc=0.333, PPL=199.69
2025-09-22 04:12:58,056 - training.trainer - INFO - Epoch 73, Step 249958: Loss=4.8602, Acc=0.333, PPL=129.05
2025-09-22 04:13:05,969 - training.trainer - INFO - Epoch 73, Step 250058: Loss=3.8000, Acc=0.500, PPL=44.70
2025-09-22 04:13:13,968 - training.trainer - INFO - Epoch 73, Step 250158: Loss=5.1654, Acc=0.208, PPL=175.10
2025-09-22 04:13:21,920 - training.trainer - INFO - Epoch 73, Step 250258: Loss=5.1221, Acc=0.235, PPL=167.68
2025-09-22 04:13:39,045 - training.trainer - INFO - Epoch 74/100 completed in 279.27s - Train Loss: 5.4005, Train Acc: 0.294, Val Loss: 5.6733, Val Acc: 0.256
2025-09-22 04:13:46,704 - training.trainer - INFO - Epoch 74, Step 250441: Loss=5.3263, Acc=0.250, PPL=205.68
2025-09-22 04:13:54,579 - training.trainer - INFO - Epoch 74, Step 250541: Loss=5.3106, Acc=0.333, PPL=202.48
2025-09-22 04:14:02,510 - training.trainer - INFO - Epoch 74, Step 250641: Loss=5.1491, Acc=0.356, PPL=172.27
2025-09-22 04:14:10,402 - training.trainer - INFO - Epoch 74, Step 250741: Loss=5.8148, Acc=0.345, PPL=335.21
2025-09-22 04:14:18,272 - training.trainer - INFO - Epoch 74, Step 250841: Loss=5.0191, Acc=0.357, PPL=151.27
2025-09-22 04:14:26,180 - training.trainer - INFO - Epoch 74, Step 250941: Loss=6.1157, Acc=0.175, PPL=452.90
2025-09-22 04:14:34,106 - training.trainer - INFO - Epoch 74, Step 251041: Loss=4.5090, Acc=0.478, PPL=90.83
2025-09-22 04:14:42,041 - training.trainer - INFO - Epoch 74, Step 251141: Loss=5.8721, Acc=0.208, PPL=354.98
2025-09-22 04:14:49,947 - training.trainer - INFO - Epoch 74, Step 251241: Loss=5.8913, Acc=0.135, PPL=361.88
2025-09-22 04:14:57,845 - training.trainer - INFO - Epoch 74, Step 251341: Loss=5.2683, Acc=0.275, PPL=194.08
2025-09-22 04:15:05,804 - training.trainer - INFO - Epoch 74, Step 251441: Loss=6.2095, Acc=0.143, PPL=497.47
2025-09-22 04:15:13,703 - training.trainer - INFO - Epoch 74, Step 251541: Loss=6.3969, Acc=0.190, PPL=599.99
2025-09-22 04:15:21,597 - training.trainer - INFO - Epoch 74, Step 251641: Loss=4.1308, Acc=0.350, PPL=62.23
2025-09-22 04:15:29,407 - training.trainer - INFO - Epoch 74, Step 251741: Loss=3.9113, Acc=0.615, PPL=49.96
2025-09-22 04:15:37,267 - training.trainer - INFO - Epoch 74, Step 251841: Loss=5.4912, Acc=0.192, PPL=242.56
2025-09-22 04:15:45,182 - training.trainer - INFO - Epoch 74, Step 251941: Loss=6.0068, Acc=0.267, PPL=406.16
2025-09-22 04:15:53,047 - training.trainer - INFO - Epoch 74, Step 252041: Loss=6.1475, Acc=0.190, PPL=467.55
2025-09-22 04:16:00,989 - training.trainer - INFO - Epoch 74, Step 252141: Loss=5.9038, Acc=0.261, PPL=366.44
2025-09-22 04:16:09,112 - training.trainer - INFO - Epoch 74, Step 252241: Loss=5.9342, Acc=0.208, PPL=377.73
2025-09-22 04:16:17,230 - training.trainer - INFO - Epoch 74, Step 252341: Loss=4.6928, Acc=0.435, PPL=109.16
2025-09-22 04:16:25,196 - training.trainer - INFO - Epoch 74, Step 252441: Loss=4.3376, Acc=0.393, PPL=76.52
2025-09-22 04:16:33,266 - training.trainer - INFO - Epoch 74, Step 252541: Loss=4.2267, Acc=0.462, PPL=68.49
2025-09-22 04:16:41,227 - training.trainer - INFO - Epoch 74, Step 252641: Loss=6.6486, Acc=0.224, PPL=771.69
2025-09-22 04:16:49,305 - training.trainer - INFO - Epoch 74, Step 252741: Loss=4.9768, Acc=0.308, PPL=145.01
2025-09-22 04:16:57,477 - training.trainer - INFO - Epoch 74, Step 252841: Loss=6.3217, Acc=0.161, PPL=556.53
2025-09-22 04:17:05,635 - training.trainer - INFO - Epoch 74, Step 252941: Loss=6.1598, Acc=0.146, PPL=473.35
2025-09-22 04:17:13,663 - training.trainer - INFO - Epoch 74, Step 253041: Loss=4.4264, Acc=0.357, PPL=83.63
2025-09-22 04:17:21,660 - training.trainer - INFO - Epoch 74, Step 253141: Loss=5.6039, Acc=0.303, PPL=271.48
2025-09-22 04:17:29,539 - training.trainer - INFO - Epoch 74, Step 253241: Loss=5.6648, Acc=0.196, PPL=288.54
2025-09-22 04:17:37,488 - training.trainer - INFO - Epoch 74, Step 253341: Loss=6.2185, Acc=0.171, PPL=501.95
2025-09-22 04:17:45,493 - training.trainer - INFO - Epoch 74, Step 253441: Loss=6.7449, Acc=0.170, PPL=849.74
2025-09-22 04:17:53,488 - training.trainer - INFO - Epoch 74, Step 253541: Loss=5.5434, Acc=0.278, PPL=255.54
2025-09-22 04:18:01,533 - training.trainer - INFO - Epoch 74, Step 253641: Loss=5.8986, Acc=0.243, PPL=364.54
2025-09-22 04:18:17,963 - training.trainer - INFO - Epoch 75/100 completed in 278.92s - Train Loss: 5.4032, Train Acc: 0.293, Val Loss: 5.6750, Val Acc: 0.255
2025-09-22 04:18:18,275 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_75.pt
2025-09-22 04:18:26,601 - training.trainer - INFO - Epoch 75, Step 253824: Loss=4.1101, Acc=0.368, PPL=60.95
2025-09-22 04:18:34,545 - training.trainer - INFO - Epoch 75, Step 253924: Loss=5.8552, Acc=0.185, PPL=349.05
2025-09-22 04:18:42,457 - training.trainer - INFO - Epoch 75, Step 254024: Loss=4.5730, Acc=0.483, PPL=96.84
2025-09-22 04:18:50,380 - training.trainer - INFO - Epoch 75, Step 254124: Loss=6.0397, Acc=0.341, PPL=419.78
2025-09-22 04:18:58,419 - training.trainer - INFO - Epoch 75, Step 254224: Loss=5.3768, Acc=0.381, PPL=216.34
2025-09-22 04:19:06,470 - training.trainer - INFO - Epoch 75, Step 254324: Loss=6.2627, Acc=0.263, PPL=524.65
2025-09-22 04:19:14,439 - training.trainer - INFO - Epoch 75, Step 254424: Loss=3.7904, Acc=0.625, PPL=44.27
2025-09-22 04:19:22,338 - training.trainer - INFO - Epoch 75, Step 254524: Loss=6.2198, Acc=0.143, PPL=502.60
2025-09-22 04:19:30,340 - training.trainer - INFO - Epoch 75, Step 254624: Loss=4.6884, Acc=0.391, PPL=108.68
2025-09-22 04:19:38,240 - training.trainer - INFO - Epoch 75, Step 254724: Loss=4.3347, Acc=0.357, PPL=76.30
2025-09-22 04:19:46,153 - training.trainer - INFO - Epoch 75, Step 254824: Loss=5.2732, Acc=0.298, PPL=195.05
2025-09-22 04:19:54,093 - training.trainer - INFO - Epoch 75, Step 254924: Loss=5.1027, Acc=0.261, PPL=164.47
2025-09-22 04:20:02,089 - training.trainer - INFO - Epoch 75, Step 255024: Loss=5.2326, Acc=0.231, PPL=187.28
2025-09-22 04:20:10,060 - training.trainer - INFO - Epoch 75, Step 255124: Loss=5.8288, Acc=0.304, PPL=339.94
2025-09-22 04:20:17,973 - training.trainer - INFO - Epoch 75, Step 255224: Loss=5.4433, Acc=0.235, PPL=231.21
2025-09-22 04:20:25,829 - training.trainer - INFO - Epoch 75, Step 255324: Loss=5.2175, Acc=0.391, PPL=184.47
2025-09-22 04:20:33,777 - training.trainer - INFO - Epoch 75, Step 255424: Loss=4.3937, Acc=0.433, PPL=80.94
2025-09-22 04:20:41,697 - training.trainer - INFO - Epoch 75, Step 255524: Loss=5.5958, Acc=0.233, PPL=269.31
2025-09-22 04:20:49,623 - training.trainer - INFO - Epoch 75, Step 255624: Loss=4.9830, Acc=0.281, PPL=145.92
2025-09-22 04:20:57,690 - training.trainer - INFO - Epoch 75, Step 255724: Loss=5.9215, Acc=0.234, PPL=372.98
2025-09-22 04:21:05,531 - training.trainer - INFO - Epoch 75, Step 255824: Loss=5.5361, Acc=0.254, PPL=253.68
2025-09-22 04:21:13,334 - training.trainer - INFO - Epoch 75, Step 255924: Loss=5.7125, Acc=0.250, PPL=302.62
2025-09-22 04:21:21,222 - training.trainer - INFO - Epoch 75, Step 256024: Loss=5.4695, Acc=0.219, PPL=237.33
2025-09-22 04:21:29,236 - training.trainer - INFO - Epoch 75, Step 256124: Loss=6.6571, Acc=0.184, PPL=778.32
2025-09-22 04:21:37,138 - training.trainer - INFO - Epoch 75, Step 256224: Loss=5.2872, Acc=0.371, PPL=197.80
2025-09-22 04:21:45,046 - training.trainer - INFO - Epoch 75, Step 256324: Loss=5.4007, Acc=0.310, PPL=221.56
2025-09-22 04:21:52,945 - training.trainer - INFO - Epoch 75, Step 256424: Loss=5.2471, Acc=0.250, PPL=190.01
2025-09-22 04:22:00,985 - training.trainer - INFO - Epoch 75, Step 256524: Loss=3.2131, Acc=0.600, PPL=24.86
2025-09-22 04:22:08,931 - training.trainer - INFO - Epoch 75, Step 256624: Loss=6.1300, Acc=0.227, PPL=459.46
2025-09-22 04:22:16,835 - training.trainer - INFO - Epoch 75, Step 256724: Loss=5.6748, Acc=0.255, PPL=291.42
2025-09-22 04:22:24,762 - training.trainer - INFO - Epoch 75, Step 256824: Loss=5.6808, Acc=0.213, PPL=293.19
2025-09-22 04:22:32,730 - training.trainer - INFO - Epoch 75, Step 256924: Loss=5.6642, Acc=0.265, PPL=288.37
2025-09-22 04:22:40,694 - training.trainer - INFO - Epoch 75, Step 257024: Loss=5.6839, Acc=0.226, PPL=294.09
2025-09-22 04:22:58,278 - training.trainer - INFO - Epoch 76/100 completed in 280.00s - Train Loss: 5.4005, Train Acc: 0.294, Val Loss: 5.6689, Val Acc: 0.257
2025-09-22 04:23:06,519 - training.trainer - INFO - Epoch 76, Step 257207: Loss=5.2048, Acc=0.323, PPL=182.15
2025-09-22 04:23:14,458 - training.trainer - INFO - Epoch 76, Step 257307: Loss=5.8150, Acc=0.227, PPL=335.28
2025-09-22 04:23:22,450 - training.trainer - INFO - Epoch 76, Step 257407: Loss=5.4251, Acc=0.192, PPL=227.03
2025-09-22 04:23:30,436 - training.trainer - INFO - Epoch 76, Step 257507: Loss=5.9207, Acc=0.296, PPL=372.66
2025-09-22 04:23:38,531 - training.trainer - INFO - Epoch 76, Step 257607: Loss=5.6142, Acc=0.269, PPL=274.29
2025-09-22 04:23:46,489 - training.trainer - INFO - Epoch 76, Step 257707: Loss=5.8521, Acc=0.375, PPL=347.96
2025-09-22 04:23:54,445 - training.trainer - INFO - Epoch 76, Step 257807: Loss=6.4846, Acc=0.182, PPL=655.00
2025-09-22 04:24:02,480 - training.trainer - INFO - Epoch 76, Step 257907: Loss=6.4517, Acc=0.203, PPL=633.78
2025-09-22 04:24:10,437 - training.trainer - INFO - Epoch 76, Step 258007: Loss=5.8758, Acc=0.272, PPL=356.32
2025-09-22 04:24:18,436 - training.trainer - INFO - Epoch 76, Step 258107: Loss=5.2756, Acc=0.310, PPL=195.50
2025-09-22 04:24:26,406 - training.trainer - INFO - Epoch 76, Step 258207: Loss=5.4778, Acc=0.297, PPL=239.32
2025-09-22 04:24:34,279 - training.trainer - INFO - Epoch 76, Step 258307: Loss=5.1242, Acc=0.290, PPL=168.04
2025-09-22 04:24:42,258 - training.trainer - INFO - Epoch 76, Step 258407: Loss=5.5338, Acc=0.306, PPL=253.09
2025-09-22 04:24:50,204 - training.trainer - INFO - Epoch 76, Step 258507: Loss=5.4097, Acc=0.333, PPL=223.58
2025-09-22 04:24:58,236 - training.trainer - INFO - Epoch 76, Step 258607: Loss=4.2751, Acc=0.404, PPL=71.89
2025-09-22 04:25:06,303 - training.trainer - INFO - Epoch 76, Step 258707: Loss=6.0176, Acc=0.209, PPL=410.59
2025-09-22 04:25:14,397 - training.trainer - INFO - Epoch 76, Step 258807: Loss=4.9692, Acc=0.321, PPL=143.91
2025-09-22 04:25:22,530 - training.trainer - INFO - Epoch 76, Step 258907: Loss=5.6185, Acc=0.140, PPL=275.47
2025-09-22 04:25:30,648 - training.trainer - INFO - Epoch 76, Step 259007: Loss=5.1223, Acc=0.400, PPL=167.72
2025-09-22 04:25:38,645 - training.trainer - INFO - Epoch 76, Step 259107: Loss=6.0742, Acc=0.162, PPL=434.50
2025-09-22 04:25:46,697 - training.trainer - INFO - Epoch 76, Step 259207: Loss=5.7645, Acc=0.350, PPL=318.79
2025-09-22 04:25:54,645 - training.trainer - INFO - Epoch 76, Step 259307: Loss=6.4182, Acc=0.227, PPL=612.87
2025-09-22 04:26:02,611 - training.trainer - INFO - Epoch 76, Step 259407: Loss=6.5040, Acc=0.132, PPL=667.82
2025-09-22 04:26:10,520 - training.trainer - INFO - Epoch 76, Step 259507: Loss=6.4122, Acc=0.200, PPL=609.25
2025-09-22 04:26:18,516 - training.trainer - INFO - Epoch 76, Step 259607: Loss=5.0754, Acc=0.211, PPL=160.04
2025-09-22 04:26:26,611 - training.trainer - INFO - Epoch 76, Step 259707: Loss=5.0849, Acc=0.367, PPL=161.57
2025-09-22 04:26:34,615 - training.trainer - INFO - Epoch 76, Step 259807: Loss=5.5853, Acc=0.300, PPL=266.47
2025-09-22 04:26:42,573 - training.trainer - INFO - Epoch 76, Step 259907: Loss=5.1612, Acc=0.250, PPL=174.37
2025-09-22 04:26:50,478 - training.trainer - INFO - Epoch 76, Step 260007: Loss=5.0407, Acc=0.312, PPL=154.58
2025-09-22 04:26:58,388 - training.trainer - INFO - Epoch 76, Step 260107: Loss=5.6954, Acc=0.394, PPL=297.50
2025-09-22 04:27:06,308 - training.trainer - INFO - Epoch 76, Step 260207: Loss=5.3112, Acc=0.320, PPL=202.59
2025-09-22 04:27:14,243 - training.trainer - INFO - Epoch 76, Step 260307: Loss=5.4263, Acc=0.294, PPL=227.30
2025-09-22 04:27:22,139 - training.trainer - INFO - Epoch 76, Step 260407: Loss=6.1353, Acc=0.350, PPL=461.88
2025-09-22 04:27:39,237 - training.trainer - INFO - Epoch 77/100 completed in 280.96s - Train Loss: 5.3989, Train Acc: 0.295, Val Loss: 5.6701, Val Acc: 0.258
2025-09-22 04:27:39,237 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-09-22 04:27:39,237 - training.trainer - INFO - Training completed!
2025-09-22 04:27:39,237 - __main__ - INFO - Training completed successfully!
2025-09-22 04:27:39,333 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-22 04:27:39,365 - __main__ - INFO - Process completed!
2025-09-22 04:27:44,579 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-22 04:27:44,579 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 04:27:44,579 - __main__ - INFO - Starting model evaluation
2025-09-22 04:27:45,221 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-22 04:29:34,602 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-22 04:29:34,620 - __main__ - INFO - Process completed!
2025-09-22 04:29:40,137 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-22 04:29:40,137 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 04:29:40,137 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-09-22 04:29:40,769 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-22 04:29:42,939 - __main__ - INFO - Inference completed successfully!
2025-09-22 04:29:42,949 - __main__ - INFO - Process completed!
2025-09-22 21:51:32,373 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 21:51:32,374 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 21:51:32,374 - __main__ - INFO - Starting training pipeline
2025-09-22 21:51:32,403 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 21:51:32,429 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 21:51:32,429 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 21:51:32,429 - __main__ - INFO - Loading training data...
2025-09-22 21:51:35,920 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-22 21:51:35,920 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 21:51:35,920 - __main__ - INFO - Starting model evaluation
2025-09-22 21:51:37,735 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-22 21:51:38,815 - __main__ - ERROR - Failed to load test data: cannot import name 'create_lsa_data_loaders' from 'utils.lsa_dataset' (/users/jbratti/keypoints-transformer-model-slt/utils/lsa_dataset.py)
2025-09-22 21:51:38,824 - __main__ - INFO - Process completed!
2025-09-22 21:52:27,115 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 21:52:27,115 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 21:52:27,115 - __main__ - INFO - Starting training pipeline
2025-09-22 21:52:27,141 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 21:52:27,165 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 21:52:27,165 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 21:52:27,166 - __main__ - INFO - Loading training data...
2025-09-22 21:52:44,074 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 21:52:44,074 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 21:52:44,074 - __main__ - INFO - Starting training pipeline
2025-09-22 21:52:44,098 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 21:52:44,122 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 21:52:44,122 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 21:52:44,122 - __main__ - INFO - Loading training data...
2025-09-22 21:52:47,205 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-22 21:52:47,205 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 21:52:47,205 - __main__ - INFO - Starting model evaluation
2025-09-22 21:56:27,143 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 21:56:27,143 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 21:56:27,144 - __main__ - INFO - Starting training pipeline
2025-09-22 21:56:27,252 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 21:56:27,273 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 21:56:27,273 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 21:56:27,273 - __main__ - INFO - Loading training data...
2025-09-22 21:56:27,671 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-22 21:56:27,671 - __main__ - INFO - Processing train split...
2025-09-22 21:56:27,730 - __main__ - INFO - Processing ALL 6767 samples from train split...
2025-09-22 21:56:27,730 - __main__ - INFO -   Processed 0/6767 samples from train...
2025-09-22 21:56:52,465 - __main__ - WARNING -   Skipped train sample 757 due to error: list index out of range
2025-09-22 21:57:00,040 - __main__ - INFO -   Processed 1000/6767 samples from train...
2025-09-22 21:57:30,050 - __main__ - INFO -   Processed 2000/6767 samples from train...
2025-09-22 21:58:51,701 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 21:58:51,701 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 21:58:51,701 - __main__ - INFO - Starting training pipeline
2025-09-22 21:58:51,801 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 21:58:51,822 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 21:58:51,823 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 21:58:51,823 - __main__ - INFO - Loading training data...
2025-09-22 21:58:52,191 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-22 21:58:52,191 - __main__ - INFO - Processing train split...
2025-09-22 21:58:52,251 - __main__ - INFO - Processing ALL 6767 samples from train split...
2025-09-22 21:58:52,251 - __main__ - INFO -   Processed 0/6767 samples from train...
2025-09-22 22:01:48,959 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 22:01:48,960 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 22:01:48,960 - __main__ - INFO - Starting training pipeline
2025-09-22 22:01:49,059 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 22:01:49,080 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 22:01:49,080 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 22:01:49,081 - __main__ - INFO - Loading training data...
2025-09-22 22:01:49,466 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-22 22:01:49,467 - __main__ - INFO - Processing train split...
2025-09-22 22:01:49,529 - __main__ - INFO - Processing ALL 6767 samples from train split...
2025-09-22 22:01:49,530 - __main__ - INFO -   Processed 0/6767 samples from train...
2025-09-22 22:02:06,996 - __main__ - WARNING -   Skipped train sample 757 due to error: list index out of range
2025-09-22 22:02:46,531 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 22:02:46,531 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 22:02:46,531 - __main__ - INFO - Starting training pipeline
2025-09-22 22:02:46,630 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 22:02:46,652 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 22:02:46,653 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 22:02:46,653 - __main__ - INFO - Loading training data...
2025-09-22 22:02:47,023 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-22 22:02:47,023 - __main__ - INFO - Processing train split...
2025-09-22 22:02:47,082 - __main__ - INFO - Processing ALL 6767 samples from train split...
2025-09-22 22:02:47,082 - __main__ - INFO -   Processed 0/6767 samples from train...
2025-09-22 22:03:05,139 - __main__ - WARNING -   Skipped train sample 757 due to error: list index out of range
2025-09-22 22:03:11,024 - __main__ - INFO -   Processed 1000/6767 samples from train...
2025-09-22 22:03:33,764 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 22:03:33,765 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 22:03:33,765 - __main__ - INFO - Starting training pipeline
2025-09-22 22:03:33,873 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 22:03:33,899 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 22:03:33,899 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 22:03:33,899 - __main__ - INFO - Loading training data...
2025-09-22 22:03:34,366 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-22 22:03:34,366 - __main__ - INFO - Processing train split...
2025-09-22 22:03:34,438 - __main__ - INFO - Processing ALL 6767 samples from train split...
2025-09-22 22:03:34,438 - __main__ - INFO -   Processed 0/6767 samples from train...
2025-09-22 22:04:57,782 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 22:04:57,783 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 22:04:57,783 - __main__ - INFO - Starting training pipeline
2025-09-22 22:04:57,887 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 22:04:57,911 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 22:04:57,911 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 22:04:57,911 - __main__ - INFO - Loading training data...
2025-09-22 22:05:27,864 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-22 22:05:27,864 - __main__ - INFO - Processing train split...
2025-09-22 22:05:27,970 - __main__ - INFO - Processing ALL 6764 samples from train split...
2025-09-22 22:05:27,970 - __main__ - INFO -   Processed 0/6764 samples from train...
2025-09-22 22:05:59,192 - __main__ - INFO -   Processed 1000/6764 samples from train...
2025-09-22 22:06:29,068 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 22:06:29,069 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 22:06:29,069 - __main__ - INFO - Starting training pipeline
2025-09-22 22:06:29,175 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 22:06:29,200 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 22:06:29,200 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 22:06:29,201 - __main__ - INFO - Loading training data...
2025-09-22 22:06:37,113 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-22 22:06:37,113 - __main__ - INFO - Processing train split...
2025-09-22 22:06:37,200 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-22 22:06:37,200 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-22 22:07:45,207 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-22 22:07:45,207 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-22 22:07:45,207 - __main__ - INFO - Starting training pipeline
2025-09-22 22:07:45,312 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-22 22:07:45,336 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-22 22:07:45,336 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 22:07:45,336 - __main__ - INFO - Loading training data...
2025-09-22 22:07:53,039 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-22 22:07:53,040 - __main__ - INFO - Processing train split...
2025-09-22 22:07:53,123 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-22 22:07:53,124 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-22 22:08:35,188 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-22 22:09:18,266 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-22 22:10:04,882 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-22 22:10:49,265 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-22 22:11:33,843 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-22 22:12:19,339 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-22 22:12:52,790 - __main__ - INFO - Processing val split...
2025-09-22 22:12:53,006 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-22 22:12:53,006 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-22 22:13:29,007 - __main__ - INFO - Processing test split...
2025-09-22 22:13:29,219 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-22 22:13:29,219 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-22 22:14:05,859 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-22 22:14:05,859 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-22 22:14:05,874 - __main__ - INFO - ‚úÖ Vocabulary created successfully with 13664 words
2025-09-22 22:14:05,874 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-22 22:14:05,874 - __main__ - INFO - Creating model architecture...
2025-09-22 22:14:06,165 - __main__ - INFO - ‚úÖ Model created successfully
2025-09-22 22:14:06,166 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-22 22:14:06,166 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-22 22:14:06,166 - __main__ - INFO - üñ•Ô∏è  Using device: cuda
2025-09-22 22:14:06,166 - __main__ - INFO - Creating trainer...
2025-09-22 22:14:06,166 - __main__ - INFO - üîÑ Moving model to cuda...
2025-09-22 22:14:06,463 - __main__ - INFO - ‚úÖ Model moved to cuda
2025-09-22 22:14:06,464 - __main__ - INFO - üìç Model parameters are on: cuda:0
2025-09-22 22:14:08,103 - __main__ - INFO - ‚úÖ Trainer created successfully
2025-09-22 22:14:08,104 - __main__ - INFO - üìç Trainer model parameters are on: cuda:0
2025-09-22 22:14:08,104 - __main__ - INFO - üöÄ Starting training...
2025-09-22 22:14:08,104 - __main__ - INFO - Training configuration:
2025-09-22 22:14:08,104 - __main__ - INFO -   - Epochs: 100
2025-09-22 22:14:08,104 - __main__ - INFO -   - Batch size: 2
2025-09-22 22:14:08,104 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-22 22:14:08,104 - __main__ - INFO -   - Training samples: 6765
2025-09-22 22:14:08,104 - __main__ - INFO -   - Validation samples: 845
2025-09-22 22:14:08,105 - training.trainer - INFO - Starting training for 100 epochs
2025-09-22 22:14:08,105 - training.trainer - INFO - Model parameters: 16,669,280
2025-09-22 22:14:08,105 - training.trainer - INFO - Training on device: cuda
2025-09-22 22:14:18,737 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.8329, Acc=0.067, PPL=6856.23
2025-09-22 22:14:27,697 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.4115, Acc=0.036, PPL=4498.64
2025-09-22 22:14:36,749 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.5947, Acc=0.050, PPL=1987.57
2025-09-22 22:14:45,621 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.4147, Acc=0.061, PPL=1660.14
2025-09-22 22:14:54,268 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.8685, Acc=0.087, PPL=961.48
2025-09-22 22:15:02,818 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.3744, Acc=0.048, PPL=1594.64
2025-09-22 22:15:11,378 - training.trainer - INFO - Epoch 0, Step 699: Loss=7.3017, Acc=0.051, PPL=1482.77
2025-09-22 22:15:19,894 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.5581, Acc=0.067, PPL=704.90
2025-09-22 22:15:28,203 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.9497, Acc=0.048, PPL=1042.84
2025-09-22 22:15:36,409 - training.trainer - INFO - Epoch 0, Step 999: Loss=7.2843, Acc=0.088, PPL=1457.27
2025-09-22 22:15:44,909 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.9189, Acc=0.040, PPL=1011.23
2025-09-22 22:15:53,282 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.7330, Acc=0.057, PPL=839.70
2025-09-22 22:16:01,585 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.8445, Acc=0.095, PPL=938.67
2025-09-22 22:16:10,079 - training.trainer - INFO - Epoch 0, Step 1399: Loss=7.1822, Acc=0.049, PPL=1315.79
2025-09-22 22:16:18,619 - training.trainer - INFO - Epoch 0, Step 1499: Loss=7.0762, Acc=0.097, PPL=1183.52
2025-09-22 22:16:27,166 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.9198, Acc=0.100, PPL=1012.11
2025-09-22 22:16:35,349 - training.trainer - INFO - Epoch 0, Step 1699: Loss=7.0321, Acc=0.108, PPL=1132.40
2025-09-22 22:16:43,717 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.5327, Acc=0.143, PPL=687.25
2025-09-22 22:16:52,203 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.7403, Acc=0.160, PPL=845.85
2025-09-22 22:17:00,545 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.2255, Acc=0.135, PPL=505.50
2025-09-22 22:17:08,904 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.0807, Acc=0.143, PPL=437.33
2025-09-22 22:17:17,299 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.8923, Acc=0.214, PPL=984.70
2025-09-22 22:17:25,690 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.7618, Acc=0.182, PPL=864.17
2025-09-22 22:17:34,005 - training.trainer - INFO - Epoch 0, Step 2399: Loss=7.0791, Acc=0.207, PPL=1186.85
2025-09-22 22:17:42,360 - training.trainer - INFO - Epoch 0, Step 2499: Loss=7.2549, Acc=0.068, PPL=1415.08
2025-09-22 22:17:50,637 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.5670, Acc=0.128, PPL=711.24
2025-09-22 22:17:58,973 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.3646, Acc=0.154, PPL=580.89
2025-09-22 22:18:07,212 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.8436, Acc=0.082, PPL=937.88
2025-09-22 22:18:15,427 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.8137, Acc=0.145, PPL=910.25
2025-09-22 22:18:23,611 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.5283, Acc=0.091, PPL=684.22
2025-09-22 22:18:31,784 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.9316, Acc=0.067, PPL=1024.13
2025-09-22 22:18:39,892 - training.trainer - INFO - Epoch 0, Step 3199: Loss=6.5527, Acc=0.103, PPL=701.17
2025-09-22 22:18:48,208 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.0900, Acc=0.158, PPL=441.42
2025-09-22 22:19:08,756 - training.trainer - INFO - Epoch 1/100 completed in 300.65s - Train Loss: 6.9401, Train Acc: 0.103, Val Loss: 6.5433, Val Acc: 0.145
2025-09-22 22:19:09,662 - training.trainer - INFO - New best model saved with validation loss: 6.5433
2025-09-22 22:19:09,663 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-22 22:19:18,115 - training.trainer - INFO - Epoch 1, Step 3482: Loss=6.2521, Acc=0.163, PPL=519.09
2025-09-22 22:19:26,158 - training.trainer - INFO - Epoch 1, Step 3582: Loss=7.1009, Acc=0.074, PPL=1213.04
2025-09-22 22:19:34,161 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.5553, Acc=0.139, PPL=702.97
2025-09-22 22:19:42,111 - training.trainer - INFO - Epoch 1, Step 3782: Loss=5.7242, Acc=0.125, PPL=306.20
2025-09-22 22:19:50,003 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.4537, Acc=0.103, PPL=635.06
2025-09-22 22:19:57,854 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.6004, Acc=0.171, PPL=735.40
2025-09-22 22:20:05,760 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.4809, Acc=0.130, PPL=652.54
2025-09-22 22:20:13,636 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.6906, Acc=0.138, PPL=804.78
2025-09-22 22:20:21,448 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.4190, Acc=0.208, PPL=613.39
2025-09-22 22:20:29,306 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.5498, Acc=0.192, PPL=699.07
2025-09-22 22:20:37,264 - training.trainer - INFO - Epoch 1, Step 4482: Loss=7.0407, Acc=0.063, PPL=1142.20
2025-09-22 22:20:45,194 - training.trainer - INFO - Epoch 1, Step 4582: Loss=4.7867, Acc=0.333, PPL=119.90
2025-09-22 22:20:53,042 - training.trainer - INFO - Epoch 1, Step 4682: Loss=6.3997, Acc=0.129, PPL=601.64
2025-09-22 22:21:01,032 - training.trainer - INFO - Epoch 1, Step 4782: Loss=6.0419, Acc=0.192, PPL=420.68
2025-09-22 22:21:09,028 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.5863, Acc=0.125, PPL=725.10
2025-09-22 22:21:17,030 - training.trainer - INFO - Epoch 1, Step 4982: Loss=5.9527, Acc=0.118, PPL=384.78
2025-09-22 22:21:24,934 - training.trainer - INFO - Epoch 1, Step 5082: Loss=7.4331, Acc=0.087, PPL=1691.02
2025-09-22 22:21:32,835 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.1138, Acc=0.133, PPL=452.07
2025-09-22 22:21:40,719 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.7217, Acc=0.080, PPL=830.23
2025-09-22 22:21:48,685 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.1953, Acc=0.160, PPL=490.44
2025-09-22 22:21:56,588 - training.trainer - INFO - Epoch 1, Step 5482: Loss=7.0756, Acc=0.139, PPL=1182.78
2025-09-22 22:22:04,602 - training.trainer - INFO - Epoch 1, Step 5582: Loss=5.9672, Acc=0.167, PPL=390.43
2025-09-22 22:22:12,644 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.3921, Acc=0.150, PPL=597.14
2025-09-22 22:22:21,031 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.4419, Acc=0.109, PPL=627.59
2025-09-22 22:22:28,891 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.8327, Acc=0.204, PPL=927.68
2025-09-22 22:22:36,734 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.7413, Acc=0.102, PPL=846.65
2025-09-22 22:22:44,590 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.5113, Acc=0.194, PPL=672.72
2025-09-22 22:22:52,533 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.5314, Acc=0.182, PPL=686.33
2025-09-22 22:23:00,416 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.6572, Acc=0.111, PPL=778.38
2025-09-22 22:23:08,229 - training.trainer - INFO - Epoch 1, Step 6382: Loss=6.2371, Acc=0.190, PPL=511.35
2025-09-22 22:23:16,247 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.5480, Acc=0.143, PPL=697.85
2025-09-22 22:23:24,310 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.7187, Acc=0.054, PPL=827.77
2025-09-22 22:23:32,209 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.9741, Acc=0.140, PPL=1068.60
2025-09-22 22:23:52,107 - training.trainer - INFO - Epoch 2/100 completed in 282.44s - Train Loss: 6.4840, Train Acc: 0.148, Val Loss: 6.3602, Val Acc: 0.160
2025-09-22 22:23:52,786 - training.trainer - INFO - New best model saved with validation loss: 6.3602
2025-09-22 22:23:52,786 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-22 22:24:00,348 - training.trainer - INFO - Epoch 2, Step 6865: Loss=5.9279, Acc=0.200, PPL=375.38
2025-09-22 22:24:08,241 - training.trainer - INFO - Epoch 2, Step 6965: Loss=7.1642, Acc=0.194, PPL=1292.39
2025-09-22 22:24:16,361 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.4353, Acc=0.174, PPL=623.48
2025-09-22 22:24:24,442 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.2676, Acc=0.123, PPL=527.23
2025-09-22 22:24:32,394 - training.trainer - INFO - Epoch 2, Step 7265: Loss=5.5508, Acc=0.188, PPL=257.45
2025-09-22 22:24:40,244 - training.trainer - INFO - Epoch 2, Step 7365: Loss=5.7972, Acc=0.143, PPL=329.38
2025-09-22 22:24:48,063 - training.trainer - INFO - Epoch 2, Step 7465: Loss=6.9577, Acc=0.136, PPL=1051.23
2025-09-22 22:24:55,898 - training.trainer - INFO - Epoch 2, Step 7565: Loss=6.5124, Acc=0.156, PPL=673.46
2025-09-22 22:25:03,842 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.5536, Acc=0.096, PPL=701.79
2025-09-22 22:25:11,650 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.5466, Acc=0.139, PPL=696.87
2025-09-22 22:25:19,391 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.7162, Acc=0.106, PPL=825.69
2025-09-22 22:25:27,274 - training.trainer - INFO - Epoch 2, Step 7965: Loss=6.5822, Acc=0.091, PPL=722.13
2025-09-22 22:25:35,108 - training.trainer - INFO - Epoch 2, Step 8065: Loss=5.8931, Acc=0.222, PPL=362.53
2025-09-22 22:25:42,981 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.3776, Acc=0.207, PPL=588.51
2025-09-22 22:25:50,806 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.0871, Acc=0.214, PPL=440.16
2025-09-22 22:25:58,739 - training.trainer - INFO - Epoch 2, Step 8365: Loss=6.1609, Acc=0.215, PPL=473.85
2025-09-22 22:26:06,603 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.6737, Acc=0.106, PPL=791.33
2025-09-22 22:26:14,423 - training.trainer - INFO - Epoch 2, Step 8565: Loss=5.7985, Acc=0.200, PPL=329.81
2025-09-22 22:26:22,258 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.2024, Acc=0.091, PPL=493.92
2025-09-22 22:26:30,061 - training.trainer - INFO - Epoch 2, Step 8765: Loss=5.9010, Acc=0.182, PPL=365.39
2025-09-22 22:26:37,915 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.9340, Acc=0.150, PPL=1026.61
2025-09-22 22:26:45,727 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.8277, Acc=0.125, PPL=923.04
2025-09-22 22:26:53,480 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.5955, Acc=0.167, PPL=731.81
2025-09-22 22:27:01,397 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.0199, Acc=0.258, PPL=411.53
2025-09-22 22:27:09,256 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.7716, Acc=0.082, PPL=872.70
2025-09-22 22:27:17,118 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.5131, Acc=0.200, PPL=673.92
2025-09-22 22:27:25,100 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.1861, Acc=0.143, PPL=485.93
2025-09-22 22:27:33,043 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.1744, Acc=0.161, PPL=480.31
2025-09-22 22:27:40,992 - training.trainer - INFO - Epoch 2, Step 9665: Loss=6.2859, Acc=0.167, PPL=536.97
2025-09-22 22:27:49,124 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.4991, Acc=0.146, PPL=664.53
2025-09-22 22:27:57,143 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.5842, Acc=0.132, PPL=723.55
2025-09-22 22:28:05,035 - training.trainer - INFO - Epoch 2, Step 9965: Loss=6.9402, Acc=0.139, PPL=1033.00
2025-09-22 22:28:13,115 - training.trainer - INFO - Epoch 2, Step 10065: Loss=6.9088, Acc=0.114, PPL=1001.04
2025-09-22 22:28:33,057 - training.trainer - INFO - Epoch 3/100 completed in 280.27s - Train Loss: 6.3499, Train Acc: 0.161, Val Loss: 6.2505, Val Acc: 0.168
2025-09-22 22:28:33,825 - training.trainer - INFO - New best model saved with validation loss: 6.2505
2025-09-22 22:28:33,825 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-22 22:28:41,957 - training.trainer - INFO - Epoch 3, Step 10248: Loss=6.2587, Acc=0.162, PPL=522.56
2025-09-22 22:28:49,164 - training.trainer - INFO - Epoch 3, Step 10348: Loss=5.7710, Acc=0.174, PPL=320.85
2025-09-22 22:28:56,859 - training.trainer - INFO - Epoch 3, Step 10448: Loss=5.8837, Acc=0.208, PPL=359.13
2025-09-22 22:29:04,343 - training.trainer - INFO - Epoch 3, Step 10548: Loss=5.7332, Acc=0.216, PPL=308.94
2025-09-22 22:29:12,483 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.1821, Acc=0.118, PPL=484.03
2025-09-22 22:29:20,690 - training.trainer - INFO - Epoch 3, Step 10748: Loss=6.4805, Acc=0.098, PPL=652.33
2025-09-22 22:29:28,829 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.5422, Acc=0.127, PPL=693.84
2025-09-22 22:29:36,988 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.1365, Acc=0.286, PPL=462.45
2025-09-22 22:29:44,958 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.6915, Acc=0.093, PPL=805.51
2025-09-22 22:29:53,006 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.3044, Acc=0.188, PPL=546.98
2025-09-22 22:30:00,960 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.8527, Acc=0.096, PPL=946.43
2025-09-22 22:30:08,870 - training.trainer - INFO - Epoch 3, Step 11348: Loss=6.1819, Acc=0.381, PPL=483.92
2025-09-22 22:30:16,688 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.2574, Acc=0.154, PPL=521.86
2025-09-22 22:30:24,567 - training.trainer - INFO - Epoch 3, Step 11548: Loss=7.0437, Acc=0.125, PPL=1145.61
2025-09-22 22:30:32,586 - training.trainer - INFO - Epoch 3, Step 11648: Loss=6.4680, Acc=0.194, PPL=644.21
2025-09-22 22:30:40,579 - training.trainer - INFO - Epoch 3, Step 11748: Loss=6.5913, Acc=0.156, PPL=728.69
2025-09-22 22:30:48,634 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.9170, Acc=0.128, PPL=371.29
2025-09-22 22:30:56,898 - training.trainer - INFO - Epoch 3, Step 11948: Loss=4.2835, Acc=0.400, PPL=72.49
2025-09-22 22:31:04,929 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.3450, Acc=0.158, PPL=569.62
2025-09-22 22:31:12,821 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.5760, Acc=0.160, PPL=717.68
2025-09-22 22:31:20,667 - training.trainer - INFO - Epoch 3, Step 12248: Loss=5.5398, Acc=0.240, PPL=254.62
2025-09-22 22:31:28,485 - training.trainer - INFO - Epoch 3, Step 12348: Loss=5.9786, Acc=0.074, PPL=394.89
2025-09-22 22:31:36,555 - training.trainer - INFO - Epoch 3, Step 12448: Loss=5.6599, Acc=0.167, PPL=287.11
2025-09-22 22:31:44,423 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.1078, Acc=0.162, PPL=449.36
2025-09-22 22:31:52,242 - training.trainer - INFO - Epoch 3, Step 12648: Loss=5.9005, Acc=0.129, PPL=365.20
2025-09-22 22:32:00,108 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.5723, Acc=0.235, PPL=715.05
2025-09-22 22:32:08,371 - training.trainer - INFO - Epoch 3, Step 12848: Loss=5.7738, Acc=0.088, PPL=321.76
2025-09-22 22:32:16,148 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.4594, Acc=0.113, PPL=638.67
2025-09-22 22:32:23,937 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.3768, Acc=0.098, PPL=588.07
2025-09-22 22:32:31,712 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.3072, Acc=0.140, PPL=548.51
2025-09-22 22:32:39,500 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.8033, Acc=0.100, PPL=900.81
2025-09-22 22:32:47,372 - training.trainer - INFO - Epoch 3, Step 13348: Loss=6.8308, Acc=0.159, PPL=925.97
2025-09-22 22:32:55,096 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.8930, Acc=0.172, PPL=985.38
2025-09-22 22:33:14,950 - training.trainer - INFO - Epoch 4/100 completed in 281.12s - Train Loss: 6.2741, Train Acc: 0.167, Val Loss: 6.1894, Val Acc: 0.172
2025-09-22 22:33:15,693 - training.trainer - INFO - New best model saved with validation loss: 6.1894
2025-09-22 22:33:15,693 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-22 22:33:24,202 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.2891, Acc=0.116, PPL=538.67
2025-09-22 22:33:32,102 - training.trainer - INFO - Epoch 4, Step 13731: Loss=5.7868, Acc=0.172, PPL=325.97
2025-09-22 22:33:40,070 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.1712, Acc=0.143, PPL=478.75
2025-09-22 22:33:48,027 - training.trainer - INFO - Epoch 4, Step 13931: Loss=6.1094, Acc=0.214, PPL=450.05
2025-09-22 22:33:55,857 - training.trainer - INFO - Epoch 4, Step 14031: Loss=6.8977, Acc=0.183, PPL=989.97
2025-09-22 22:34:03,674 - training.trainer - INFO - Epoch 4, Step 14131: Loss=5.7301, Acc=0.146, PPL=308.01
2025-09-22 22:34:11,810 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.0860, Acc=0.133, PPL=439.68
2025-09-22 22:34:20,002 - training.trainer - INFO - Epoch 4, Step 14331: Loss=5.8602, Acc=0.211, PPL=350.79
2025-09-22 22:34:27,833 - training.trainer - INFO - Epoch 4, Step 14431: Loss=6.4335, Acc=0.209, PPL=622.34
2025-09-22 22:34:35,574 - training.trainer - INFO - Epoch 4, Step 14531: Loss=5.8623, Acc=0.286, PPL=351.55
2025-09-22 22:34:43,267 - training.trainer - INFO - Epoch 4, Step 14631: Loss=5.8969, Acc=0.152, PPL=363.89
2025-09-22 22:34:51,041 - training.trainer - INFO - Epoch 4, Step 14731: Loss=5.9686, Acc=0.171, PPL=390.97
2025-09-22 22:34:58,871 - training.trainer - INFO - Epoch 4, Step 14831: Loss=6.7714, Acc=0.129, PPL=872.57
2025-09-22 22:35:06,843 - training.trainer - INFO - Epoch 4, Step 14931: Loss=5.6913, Acc=0.189, PPL=296.26
2025-09-22 22:35:14,936 - training.trainer - INFO - Epoch 4, Step 15031: Loss=6.5140, Acc=0.200, PPL=674.50
2025-09-22 22:35:23,080 - training.trainer - INFO - Epoch 4, Step 15131: Loss=7.0718, Acc=0.068, PPL=1178.31
2025-09-22 22:35:31,014 - training.trainer - INFO - Epoch 4, Step 15231: Loss=5.3839, Acc=0.256, PPL=217.86
2025-09-22 22:35:38,821 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.2532, Acc=0.225, PPL=519.68
2025-09-22 22:35:46,632 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.4440, Acc=0.156, PPL=628.93
2025-09-22 22:35:54,547 - training.trainer - INFO - Epoch 4, Step 15531: Loss=6.5203, Acc=0.103, PPL=678.77
2025-09-22 22:36:02,406 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.4120, Acc=0.125, PPL=609.09
2025-09-22 22:36:10,177 - training.trainer - INFO - Epoch 4, Step 15731: Loss=5.8249, Acc=0.175, PPL=338.64
2025-09-22 22:36:17,987 - training.trainer - INFO - Epoch 4, Step 15831: Loss=6.7827, Acc=0.093, PPL=882.41
2025-09-22 22:36:25,745 - training.trainer - INFO - Epoch 4, Step 15931: Loss=5.6485, Acc=0.200, PPL=283.87
2025-09-22 22:36:33,640 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.6046, Acc=0.150, PPL=738.49
2025-09-22 22:36:41,528 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.0647, Acc=0.194, PPL=430.40
2025-09-22 22:36:49,364 - training.trainer - INFO - Epoch 4, Step 16231: Loss=6.3337, Acc=0.161, PPL=563.21
2025-09-22 22:36:57,267 - training.trainer - INFO - Epoch 4, Step 16331: Loss=6.1167, Acc=0.100, PPL=453.35
2025-09-22 22:37:05,331 - training.trainer - INFO - Epoch 4, Step 16431: Loss=6.6465, Acc=0.111, PPL=770.06
2025-09-22 22:37:13,074 - training.trainer - INFO - Epoch 4, Step 16531: Loss=6.2201, Acc=0.185, PPL=502.73
2025-09-22 22:37:21,023 - training.trainer - INFO - Epoch 4, Step 16631: Loss=5.6655, Acc=0.158, PPL=288.73
2025-09-22 22:37:28,807 - training.trainer - INFO - Epoch 4, Step 16731: Loss=5.2327, Acc=0.333, PPL=187.30
2025-09-22 22:37:36,677 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.0637, Acc=0.128, PPL=429.98
2025-09-22 22:37:56,890 - training.trainer - INFO - Epoch 5/100 completed in 281.20s - Train Loss: 6.2228, Train Acc: 0.172, Val Loss: 6.1450, Val Acc: 0.180
2025-09-22 22:37:57,207 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-22 22:37:57,836 - training.trainer - INFO - New best model saved with validation loss: 6.1450
2025-09-22 22:37:57,836 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-22 22:38:05,630 - training.trainer - INFO - Epoch 5, Step 17014: Loss=6.3117, Acc=0.190, PPL=550.98
2025-09-22 22:38:13,720 - training.trainer - INFO - Epoch 5, Step 17114: Loss=5.8716, Acc=0.250, PPL=354.82
2025-09-22 22:38:21,956 - training.trainer - INFO - Epoch 5, Step 17214: Loss=5.6885, Acc=0.250, PPL=295.46
2025-09-22 22:38:30,412 - training.trainer - INFO - Epoch 5, Step 17314: Loss=6.2828, Acc=0.222, PPL=535.31
2025-09-22 22:38:38,463 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.1114, Acc=0.121, PPL=450.98
2025-09-22 22:38:46,463 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.1882, Acc=0.263, PPL=486.97
2025-09-22 22:38:54,288 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.0935, Acc=0.125, PPL=442.95
2025-09-22 22:39:02,136 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.7942, Acc=0.118, PPL=892.69
2025-09-22 22:39:10,038 - training.trainer - INFO - Epoch 5, Step 17814: Loss=5.9254, Acc=0.192, PPL=374.43
2025-09-22 22:39:17,907 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.8839, Acc=0.211, PPL=976.46
2025-09-22 22:39:25,680 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.2990, Acc=0.081, PPL=544.02
2025-09-22 22:39:33,466 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.6180, Acc=0.192, PPL=748.43
2025-09-22 22:39:41,550 - training.trainer - INFO - Epoch 5, Step 18214: Loss=6.2620, Acc=0.207, PPL=524.27
2025-09-22 22:39:49,387 - training.trainer - INFO - Epoch 5, Step 18314: Loss=5.8238, Acc=0.196, PPL=338.27
2025-09-22 22:39:57,170 - training.trainer - INFO - Epoch 5, Step 18414: Loss=6.3980, Acc=0.250, PPL=600.65
2025-09-22 22:40:04,882 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.3763, Acc=0.167, PPL=587.76
2025-09-22 22:40:12,621 - training.trainer - INFO - Epoch 5, Step 18614: Loss=5.6054, Acc=0.219, PPL=271.89
2025-09-22 22:40:20,643 - training.trainer - INFO - Epoch 5, Step 18714: Loss=5.7492, Acc=0.300, PPL=313.93
2025-09-22 22:40:28,702 - training.trainer - INFO - Epoch 5, Step 18814: Loss=5.9240, Acc=0.143, PPL=373.89
2025-09-22 22:40:36,775 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.1511, Acc=0.173, PPL=469.23
2025-09-22 22:40:44,754 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.3990, Acc=0.143, PPL=601.23
2025-09-22 22:40:52,957 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.5489, Acc=0.164, PPL=698.50
2025-09-22 22:41:00,958 - training.trainer - INFO - Epoch 5, Step 19214: Loss=6.2071, Acc=0.200, PPL=496.24
2025-09-22 22:41:09,003 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.0340, Acc=0.250, PPL=417.39
2025-09-22 22:41:16,987 - training.trainer - INFO - Epoch 5, Step 19414: Loss=6.0063, Acc=0.138, PPL=405.96
2025-09-22 22:41:25,197 - training.trainer - INFO - Epoch 5, Step 19514: Loss=5.9710, Acc=0.222, PPL=391.89
2025-09-22 22:41:33,228 - training.trainer - INFO - Epoch 5, Step 19614: Loss=5.8820, Acc=0.211, PPL=358.53
2025-09-22 22:41:41,282 - training.trainer - INFO - Epoch 5, Step 19714: Loss=6.2170, Acc=0.132, PPL=501.19
2025-09-22 22:41:49,235 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.2925, Acc=0.151, PPL=540.52
2025-09-22 22:41:57,318 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.8279, Acc=0.255, PPL=339.64
2025-09-22 22:42:05,467 - training.trainer - INFO - Epoch 5, Step 20014: Loss=5.6919, Acc=0.242, PPL=296.44
2025-09-22 22:42:13,615 - training.trainer - INFO - Epoch 5, Step 20114: Loss=6.7348, Acc=0.091, PPL=841.20
2025-09-22 22:42:21,771 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.6806, Acc=0.143, PPL=796.77
2025-09-22 22:42:41,728 - training.trainer - INFO - Epoch 6/100 completed in 283.89s - Train Loss: 6.1861, Train Acc: 0.176, Val Loss: 6.1099, Val Acc: 0.183
2025-09-22 22:42:42,373 - training.trainer - INFO - New best model saved with validation loss: 6.1099
2025-09-22 22:42:42,374 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-22 22:42:50,899 - training.trainer - INFO - Epoch 6, Step 20397: Loss=5.7666, Acc=0.206, PPL=319.46
2025-09-22 22:42:59,017 - training.trainer - INFO - Epoch 6, Step 20497: Loss=6.5538, Acc=0.078, PPL=701.89
2025-09-22 22:43:07,191 - training.trainer - INFO - Epoch 6, Step 20597: Loss=6.2331, Acc=0.154, PPL=509.32
2025-09-22 22:43:15,383 - training.trainer - INFO - Epoch 6, Step 20697: Loss=6.3748, Acc=0.211, PPL=586.85
2025-09-22 22:43:23,455 - training.trainer - INFO - Epoch 6, Step 20797: Loss=6.0374, Acc=0.137, PPL=418.79
2025-09-22 22:43:31,403 - training.trainer - INFO - Epoch 6, Step 20897: Loss=6.3892, Acc=0.125, PPL=595.40
2025-09-22 22:43:39,622 - training.trainer - INFO - Epoch 6, Step 20997: Loss=6.0829, Acc=0.167, PPL=438.28
2025-09-22 22:43:47,517 - training.trainer - INFO - Epoch 6, Step 21097: Loss=5.9887, Acc=0.179, PPL=398.91
2025-09-22 22:43:55,268 - training.trainer - INFO - Epoch 6, Step 21197: Loss=6.6520, Acc=0.121, PPL=774.34
2025-09-22 22:44:03,101 - training.trainer - INFO - Epoch 6, Step 21297: Loss=6.9267, Acc=0.104, PPL=1019.15
2025-09-22 22:44:11,073 - training.trainer - INFO - Epoch 6, Step 21397: Loss=6.3510, Acc=0.143, PPL=573.09
2025-09-22 22:44:18,938 - training.trainer - INFO - Epoch 6, Step 21497: Loss=5.5455, Acc=0.333, PPL=256.07
2025-09-22 22:44:26,866 - training.trainer - INFO - Epoch 6, Step 21597: Loss=6.4294, Acc=0.079, PPL=619.80
2025-09-22 22:44:34,733 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.7146, Acc=0.105, PPL=824.38
2025-09-22 22:44:42,773 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.5295, Acc=0.125, PPL=685.08
2025-09-22 22:44:50,541 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.7841, Acc=0.136, PPL=883.70
2025-09-22 22:44:58,172 - training.trainer - INFO - Epoch 6, Step 21997: Loss=4.6941, Acc=0.286, PPL=109.30
2025-09-22 22:45:06,208 - training.trainer - INFO - Epoch 6, Step 22097: Loss=6.0174, Acc=0.192, PPL=410.49
2025-09-22 22:45:14,227 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.7702, Acc=0.087, PPL=871.47
2025-09-22 22:45:22,288 - training.trainer - INFO - Epoch 6, Step 22297: Loss=6.8570, Acc=0.139, PPL=950.51
2025-09-22 22:45:30,721 - training.trainer - INFO - Epoch 6, Step 22397: Loss=6.2139, Acc=0.125, PPL=499.64
2025-09-22 22:45:38,849 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.2213, Acc=0.143, PPL=503.36
2025-09-22 22:45:46,963 - training.trainer - INFO - Epoch 6, Step 22597: Loss=6.4135, Acc=0.085, PPL=610.01
2025-09-22 22:45:55,119 - training.trainer - INFO - Epoch 6, Step 22697: Loss=6.0260, Acc=0.200, PPL=414.03
2025-09-22 22:46:03,389 - training.trainer - INFO - Epoch 6, Step 22797: Loss=5.4619, Acc=0.261, PPL=235.54
2025-09-22 22:46:11,482 - training.trainer - INFO - Epoch 6, Step 22897: Loss=6.9768, Acc=0.193, PPL=1071.45
2025-09-22 22:46:19,475 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.3246, Acc=0.147, PPL=558.15
2025-09-22 22:46:27,496 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.2846, Acc=0.152, PPL=536.25
2025-09-22 22:46:35,422 - training.trainer - INFO - Epoch 6, Step 23197: Loss=6.5384, Acc=0.145, PPL=691.19
2025-09-22 22:46:43,323 - training.trainer - INFO - Epoch 6, Step 23297: Loss=5.7088, Acc=0.263, PPL=301.50
2025-09-22 22:46:51,283 - training.trainer - INFO - Epoch 6, Step 23397: Loss=6.5664, Acc=0.133, PPL=710.84
2025-09-22 22:46:59,277 - training.trainer - INFO - Epoch 6, Step 23497: Loss=6.5620, Acc=0.116, PPL=707.68
2025-09-22 22:47:07,280 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.0528, Acc=0.200, PPL=425.31
2025-09-22 22:47:27,431 - training.trainer - INFO - Epoch 7/100 completed in 285.06s - Train Loss: 6.1554, Train Acc: 0.180, Val Loss: 6.0927, Val Acc: 0.186
2025-09-22 22:47:28,180 - training.trainer - INFO - New best model saved with validation loss: 6.0927
2025-09-22 22:47:28,180 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-22 22:47:36,762 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.4960, Acc=0.175, PPL=662.50
2025-09-22 22:47:44,658 - training.trainer - INFO - Epoch 7, Step 23880: Loss=6.5761, Acc=0.060, PPL=717.71
2025-09-22 22:47:52,508 - training.trainer - INFO - Epoch 7, Step 23980: Loss=6.3898, Acc=0.146, PPL=595.76
2025-09-22 22:48:00,460 - training.trainer - INFO - Epoch 7, Step 24080: Loss=6.1129, Acc=0.146, PPL=451.65
2025-09-22 22:48:08,297 - training.trainer - INFO - Epoch 7, Step 24180: Loss=6.5729, Acc=0.111, PPL=715.47
2025-09-22 22:48:16,275 - training.trainer - INFO - Epoch 7, Step 24280: Loss=5.9838, Acc=0.135, PPL=396.94
2025-09-22 22:48:24,163 - training.trainer - INFO - Epoch 7, Step 24380: Loss=5.5680, Acc=0.205, PPL=261.91
2025-09-22 22:48:32,294 - training.trainer - INFO - Epoch 7, Step 24480: Loss=6.2530, Acc=0.135, PPL=519.58
2025-09-22 22:48:40,375 - training.trainer - INFO - Epoch 7, Step 24580: Loss=5.8836, Acc=0.121, PPL=359.11
2025-09-22 22:48:48,352 - training.trainer - INFO - Epoch 7, Step 24680: Loss=5.9628, Acc=0.162, PPL=388.71
2025-09-22 22:48:56,351 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.6086, Acc=0.161, PPL=741.48
2025-09-22 22:49:04,348 - training.trainer - INFO - Epoch 7, Step 24880: Loss=5.7388, Acc=0.128, PPL=310.68
2025-09-22 22:49:12,259 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.7232, Acc=0.185, PPL=305.88
2025-09-22 22:49:20,268 - training.trainer - INFO - Epoch 7, Step 25080: Loss=6.1796, Acc=0.222, PPL=482.80
2025-09-22 22:49:28,475 - training.trainer - INFO - Epoch 7, Step 25180: Loss=6.1580, Acc=0.167, PPL=472.48
2025-09-22 22:49:36,376 - training.trainer - INFO - Epoch 7, Step 25280: Loss=5.9626, Acc=0.186, PPL=388.61
2025-09-22 22:49:44,379 - training.trainer - INFO - Epoch 7, Step 25380: Loss=6.6144, Acc=0.108, PPL=745.75
2025-09-22 22:49:52,293 - training.trainer - INFO - Epoch 7, Step 25480: Loss=6.0527, Acc=0.185, PPL=425.26
2025-09-22 22:50:00,234 - training.trainer - INFO - Epoch 7, Step 25580: Loss=5.5946, Acc=0.357, PPL=268.96
2025-09-22 22:50:08,266 - training.trainer - INFO - Epoch 7, Step 25680: Loss=5.8845, Acc=0.143, PPL=359.41
2025-09-22 22:50:16,282 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.6312, Acc=0.177, PPL=758.41
2025-09-22 22:50:24,243 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.2502, Acc=0.250, PPL=518.09
2025-09-22 22:50:32,334 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.4147, Acc=0.114, PPL=610.75
2025-09-22 22:50:40,412 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.6765, Acc=0.172, PPL=793.54
2025-09-22 22:50:48,525 - training.trainer - INFO - Epoch 7, Step 26180: Loss=6.2553, Acc=0.200, PPL=520.79
2025-09-22 22:50:56,438 - training.trainer - INFO - Epoch 7, Step 26280: Loss=6.2636, Acc=0.263, PPL=525.11
2025-09-22 22:51:04,428 - training.trainer - INFO - Epoch 7, Step 26380: Loss=5.6975, Acc=0.204, PPL=298.12
2025-09-22 22:51:12,406 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.1955, Acc=0.312, PPL=490.52
2025-09-22 22:51:20,378 - training.trainer - INFO - Epoch 7, Step 26580: Loss=4.8567, Acc=0.312, PPL=128.60
2025-09-22 22:51:28,419 - training.trainer - INFO - Epoch 7, Step 26680: Loss=6.1012, Acc=0.158, PPL=446.39
2025-09-22 22:51:36,383 - training.trainer - INFO - Epoch 7, Step 26780: Loss=6.3450, Acc=0.129, PPL=569.66
2025-09-22 22:51:44,272 - training.trainer - INFO - Epoch 7, Step 26880: Loss=5.7884, Acc=0.224, PPL=326.50
2025-09-22 22:51:52,294 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.4253, Acc=0.200, PPL=227.09
2025-09-22 22:52:12,656 - training.trainer - INFO - Epoch 8/100 completed in 284.48s - Train Loss: 6.1276, Train Acc: 0.185, Val Loss: 6.0674, Val Acc: 0.191
2025-09-22 22:52:13,433 - training.trainer - INFO - New best model saved with validation loss: 6.0674
2025-09-22 22:52:13,433 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-09-22 22:52:22,135 - training.trainer - INFO - Epoch 8, Step 27163: Loss=6.6708, Acc=0.133, PPL=789.01
2025-09-22 22:52:30,203 - training.trainer - INFO - Epoch 8, Step 27263: Loss=6.6896, Acc=0.143, PPL=804.00
2025-09-22 22:52:38,143 - training.trainer - INFO - Epoch 8, Step 27363: Loss=6.5525, Acc=0.149, PPL=701.00
2025-09-22 22:52:46,070 - training.trainer - INFO - Epoch 8, Step 27463: Loss=6.6237, Acc=0.113, PPL=752.73
2025-09-22 22:52:54,268 - training.trainer - INFO - Epoch 8, Step 27563: Loss=6.1319, Acc=0.265, PPL=460.30
2025-09-22 22:53:02,279 - training.trainer - INFO - Epoch 8, Step 27663: Loss=6.9573, Acc=0.100, PPL=1050.83
2025-09-22 22:53:10,707 - training.trainer - INFO - Epoch 8, Step 27763: Loss=6.4758, Acc=0.189, PPL=649.22
2025-09-22 22:53:18,657 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.3371, Acc=0.125, PPL=565.18
2025-09-22 22:53:26,676 - training.trainer - INFO - Epoch 8, Step 27963: Loss=6.2220, Acc=0.167, PPL=503.70
2025-09-22 22:53:34,579 - training.trainer - INFO - Epoch 8, Step 28063: Loss=6.6321, Acc=0.096, PPL=759.10
2025-09-22 22:53:42,621 - training.trainer - INFO - Epoch 8, Step 28163: Loss=6.4451, Acc=0.180, PPL=629.60
2025-09-22 22:53:50,544 - training.trainer - INFO - Epoch 8, Step 28263: Loss=5.9667, Acc=0.194, PPL=390.21
2025-09-22 22:53:58,481 - training.trainer - INFO - Epoch 8, Step 28363: Loss=5.8619, Acc=0.161, PPL=351.38
2025-09-22 22:54:06,424 - training.trainer - INFO - Epoch 8, Step 28463: Loss=6.1256, Acc=0.245, PPL=457.42
2025-09-22 22:54:14,335 - training.trainer - INFO - Epoch 8, Step 28563: Loss=6.2857, Acc=0.219, PPL=536.86
2025-09-22 22:54:22,238 - training.trainer - INFO - Epoch 8, Step 28663: Loss=6.4450, Acc=0.130, PPL=629.52
2025-09-22 22:54:30,163 - training.trainer - INFO - Epoch 8, Step 28763: Loss=5.3989, Acc=0.276, PPL=221.16
2025-09-22 22:54:38,247 - training.trainer - INFO - Epoch 8, Step 28863: Loss=6.3891, Acc=0.212, PPL=595.30
2025-09-22 22:54:46,160 - training.trainer - INFO - Epoch 8, Step 28963: Loss=6.3786, Acc=0.146, PPL=589.13
2025-09-22 22:54:54,054 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.6818, Acc=0.083, PPL=797.77
2025-09-22 22:55:02,086 - training.trainer - INFO - Epoch 8, Step 29163: Loss=6.5747, Acc=0.220, PPL=716.72
2025-09-22 22:55:10,386 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.9667, Acc=0.105, PPL=1060.71
2025-09-22 22:55:18,300 - training.trainer - INFO - Epoch 8, Step 29363: Loss=6.1356, Acc=0.143, PPL=462.00
2025-09-22 22:55:26,086 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.0765, Acc=0.128, PPL=435.50
2025-09-22 22:55:33,995 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.3646, Acc=0.250, PPL=213.71
2025-09-22 22:55:42,008 - training.trainer - INFO - Epoch 8, Step 29663: Loss=6.6232, Acc=0.125, PPL=752.34
2025-09-22 22:55:50,019 - training.trainer - INFO - Epoch 8, Step 29763: Loss=5.9314, Acc=0.156, PPL=376.67
2025-09-22 22:55:58,113 - training.trainer - INFO - Epoch 8, Step 29863: Loss=5.9139, Acc=0.194, PPL=370.16
2025-09-22 22:56:06,119 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.1081, Acc=0.125, PPL=449.50
2025-09-22 22:56:14,051 - training.trainer - INFO - Epoch 8, Step 30063: Loss=6.8954, Acc=0.250, PPL=987.76
2025-09-22 22:56:21,881 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.6172, Acc=0.242, PPL=275.12
2025-09-22 22:56:29,727 - training.trainer - INFO - Epoch 8, Step 30263: Loss=6.1982, Acc=0.214, PPL=491.85
2025-09-22 22:56:37,699 - training.trainer - INFO - Epoch 8, Step 30363: Loss=6.0754, Acc=0.121, PPL=435.04
2025-09-22 22:56:57,865 - training.trainer - INFO - Epoch 9/100 completed in 284.43s - Train Loss: 6.1007, Train Acc: 0.189, Val Loss: 6.0469, Val Acc: 0.194
2025-09-22 22:56:58,598 - training.trainer - INFO - New best model saved with validation loss: 6.0469
2025-09-22 22:56:58,599 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-22 22:57:06,944 - training.trainer - INFO - Epoch 9, Step 30546: Loss=5.8438, Acc=0.234, PPL=345.10
2025-09-22 22:57:15,073 - training.trainer - INFO - Epoch 9, Step 30646: Loss=6.3206, Acc=0.189, PPL=555.90
2025-09-22 22:57:23,097 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.4371, Acc=0.069, PPL=624.59
2025-09-22 22:57:30,961 - training.trainer - INFO - Epoch 9, Step 30846: Loss=5.6970, Acc=0.250, PPL=297.98
2025-09-22 22:57:38,841 - training.trainer - INFO - Epoch 9, Step 30946: Loss=5.7761, Acc=0.364, PPL=322.48
2025-09-22 22:57:46,797 - training.trainer - INFO - Epoch 9, Step 31046: Loss=5.9054, Acc=0.132, PPL=367.02
2025-09-22 22:57:54,760 - training.trainer - INFO - Epoch 9, Step 31146: Loss=6.4241, Acc=0.154, PPL=616.53
2025-09-22 22:58:02,723 - training.trainer - INFO - Epoch 9, Step 31246: Loss=5.7666, Acc=0.172, PPL=319.44
2025-09-22 22:58:10,636 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.1473, Acc=0.154, PPL=467.44
2025-09-22 22:58:18,494 - training.trainer - INFO - Epoch 9, Step 31446: Loss=6.2511, Acc=0.189, PPL=518.57
2025-09-22 22:58:26,328 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.9087, Acc=0.257, PPL=368.24
2025-09-22 22:58:34,171 - training.trainer - INFO - Epoch 9, Step 31646: Loss=5.6728, Acc=0.156, PPL=290.85
2025-09-22 22:58:41,968 - training.trainer - INFO - Epoch 9, Step 31746: Loss=6.6842, Acc=0.091, PPL=799.69
2025-09-22 22:58:49,889 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.2245, Acc=0.153, PPL=504.96
2025-09-22 22:58:57,828 - training.trainer - INFO - Epoch 9, Step 31946: Loss=6.2902, Acc=0.173, PPL=539.25
2025-09-22 22:59:05,752 - training.trainer - INFO - Epoch 9, Step 32046: Loss=6.7213, Acc=0.085, PPL=829.90
2025-09-22 22:59:13,833 - training.trainer - INFO - Epoch 9, Step 32146: Loss=5.3903, Acc=0.265, PPL=219.27
2025-09-22 22:59:22,261 - training.trainer - INFO - Epoch 9, Step 32246: Loss=5.7989, Acc=0.200, PPL=329.95
2025-09-22 22:59:30,340 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.8937, Acc=0.148, PPL=362.75
2025-09-22 22:59:38,141 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.5527, Acc=0.190, PPL=257.94
2025-09-22 22:59:45,923 - training.trainer - INFO - Epoch 9, Step 32546: Loss=6.4266, Acc=0.120, PPL=618.08
2025-09-22 22:59:53,728 - training.trainer - INFO - Epoch 9, Step 32646: Loss=6.2585, Acc=0.125, PPL=522.45
2025-09-22 23:00:01,664 - training.trainer - INFO - Epoch 9, Step 32746: Loss=6.1335, Acc=0.170, PPL=461.04
2025-09-22 23:00:09,464 - training.trainer - INFO - Epoch 9, Step 32846: Loss=6.1244, Acc=0.162, PPL=456.86
2025-09-22 23:00:17,314 - training.trainer - INFO - Epoch 9, Step 32946: Loss=5.1959, Acc=0.385, PPL=180.53
2025-09-22 23:00:25,411 - training.trainer - INFO - Epoch 9, Step 33046: Loss=6.4370, Acc=0.156, PPL=624.53
2025-09-22 23:00:33,413 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.6066, Acc=0.152, PPL=739.93
2025-09-22 23:00:41,659 - training.trainer - INFO - Epoch 9, Step 33246: Loss=6.3703, Acc=0.159, PPL=584.21
2025-09-22 23:00:49,596 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.1577, Acc=0.146, PPL=472.35
2025-09-22 23:00:57,554 - training.trainer - INFO - Epoch 9, Step 33446: Loss=4.9115, Acc=0.429, PPL=135.85
2025-09-22 23:01:05,491 - training.trainer - INFO - Epoch 9, Step 33546: Loss=6.1291, Acc=0.143, PPL=459.04
2025-09-22 23:01:13,409 - training.trainer - INFO - Epoch 9, Step 33646: Loss=6.1836, Acc=0.157, PPL=484.71
2025-09-22 23:01:21,350 - training.trainer - INFO - Epoch 9, Step 33746: Loss=5.6943, Acc=0.300, PPL=297.17
2025-09-22 23:01:41,016 - training.trainer - INFO - Epoch 10/100 completed in 282.42s - Train Loss: 6.0746, Train Acc: 0.192, Val Loss: 6.0166, Val Acc: 0.199
2025-09-22 23:01:41,414 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-22 23:01:42,208 - training.trainer - INFO - New best model saved with validation loss: 6.0166
2025-09-22 23:01:42,208 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-22 23:01:49,428 - training.trainer - INFO - Epoch 10, Step 33929: Loss=5.5168, Acc=0.172, PPL=248.84
2025-09-22 23:01:56,100 - training.trainer - INFO - Epoch 10, Step 34029: Loss=5.8246, Acc=0.156, PPL=338.52
2025-09-22 23:02:02,899 - training.trainer - INFO - Epoch 10, Step 34129: Loss=6.6577, Acc=0.196, PPL=778.76
2025-09-22 23:02:09,619 - training.trainer - INFO - Epoch 10, Step 34229: Loss=6.7524, Acc=0.141, PPL=856.15
2025-09-22 23:02:16,469 - training.trainer - INFO - Epoch 10, Step 34329: Loss=5.4388, Acc=0.257, PPL=230.16
2025-09-22 23:02:24,179 - training.trainer - INFO - Epoch 10, Step 34429: Loss=6.3379, Acc=0.174, PPL=565.59
2025-09-22 23:02:32,256 - training.trainer - INFO - Epoch 10, Step 34529: Loss=6.5337, Acc=0.208, PPL=687.95
2025-09-22 23:02:40,385 - training.trainer - INFO - Epoch 10, Step 34629: Loss=6.3604, Acc=0.157, PPL=578.45
2025-09-22 23:02:48,330 - training.trainer - INFO - Epoch 10, Step 34729: Loss=6.0945, Acc=0.191, PPL=443.39
2025-09-22 23:02:56,131 - training.trainer - INFO - Epoch 10, Step 34829: Loss=6.0194, Acc=0.216, PPL=411.31
2025-09-22 23:03:03,977 - training.trainer - INFO - Epoch 10, Step 34929: Loss=5.7443, Acc=0.130, PPL=312.42
2025-09-22 23:03:11,957 - training.trainer - INFO - Epoch 10, Step 35029: Loss=6.0056, Acc=0.178, PPL=405.69
2025-09-22 23:03:20,009 - training.trainer - INFO - Epoch 10, Step 35129: Loss=4.7250, Acc=0.278, PPL=112.73
2025-09-22 23:03:27,844 - training.trainer - INFO - Epoch 10, Step 35229: Loss=5.9557, Acc=0.222, PPL=385.94
2025-09-22 23:03:35,831 - training.trainer - INFO - Epoch 10, Step 35329: Loss=6.0817, Acc=0.276, PPL=437.75
2025-09-22 23:03:43,676 - training.trainer - INFO - Epoch 10, Step 35429: Loss=6.2498, Acc=0.102, PPL=517.91
2025-09-22 23:03:51,679 - training.trainer - INFO - Epoch 10, Step 35529: Loss=6.3977, Acc=0.119, PPL=600.45
2025-09-22 23:03:59,657 - training.trainer - INFO - Epoch 10, Step 35629: Loss=4.6082, Acc=0.391, PPL=100.30
2025-09-22 23:04:07,598 - training.trainer - INFO - Epoch 10, Step 35729: Loss=6.9079, Acc=0.105, PPL=1000.11
2025-09-22 23:04:15,634 - training.trainer - INFO - Epoch 10, Step 35829: Loss=6.6039, Acc=0.136, PPL=737.99
2025-09-22 23:04:23,791 - training.trainer - INFO - Epoch 10, Step 35929: Loss=6.2317, Acc=0.167, PPL=508.63
2025-09-22 23:04:31,712 - training.trainer - INFO - Epoch 10, Step 36029: Loss=6.6567, Acc=0.093, PPL=777.98
2025-09-22 23:04:39,607 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.7419, Acc=0.182, PPL=311.65
2025-09-22 23:04:47,649 - training.trainer - INFO - Epoch 10, Step 36229: Loss=5.3937, Acc=0.174, PPL=220.01
2025-09-22 23:04:55,655 - training.trainer - INFO - Epoch 10, Step 36329: Loss=6.6401, Acc=0.113, PPL=765.18
2025-09-22 23:05:03,571 - training.trainer - INFO - Epoch 10, Step 36429: Loss=5.0537, Acc=0.462, PPL=156.60
2025-09-22 23:05:11,483 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.8051, Acc=0.240, PPL=332.00
2025-09-22 23:05:19,552 - training.trainer - INFO - Epoch 10, Step 36629: Loss=6.1154, Acc=0.238, PPL=452.79
2025-09-22 23:05:27,895 - training.trainer - INFO - Epoch 10, Step 36729: Loss=6.4547, Acc=0.130, PPL=635.69
2025-09-22 23:05:35,859 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.8954, Acc=0.208, PPL=363.37
2025-09-22 23:05:43,944 - training.trainer - INFO - Epoch 10, Step 36929: Loss=5.9538, Acc=0.182, PPL=385.20
2025-09-22 23:05:51,961 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.7261, Acc=0.179, PPL=306.77
2025-09-22 23:06:00,089 - training.trainer - INFO - Epoch 10, Step 37129: Loss=5.7274, Acc=0.231, PPL=307.18
2025-09-22 23:06:20,386 - training.trainer - INFO - Epoch 11/100 completed in 278.18s - Train Loss: 6.0473, Train Acc: 0.195, Val Loss: 5.9848, Val Acc: 0.203
2025-09-22 23:06:21,272 - training.trainer - INFO - New best model saved with validation loss: 5.9848
2025-09-22 23:06:21,273 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-22 23:06:29,794 - training.trainer - INFO - Epoch 11, Step 37312: Loss=5.3821, Acc=0.222, PPL=217.49
2025-09-22 23:06:37,722 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.0201, Acc=0.167, PPL=411.61
2025-09-22 23:06:45,609 - training.trainer - INFO - Epoch 11, Step 37512: Loss=6.1596, Acc=0.203, PPL=473.25
2025-09-22 23:06:53,479 - training.trainer - INFO - Epoch 11, Step 37612: Loss=6.6478, Acc=0.159, PPL=771.11
2025-09-22 23:07:01,561 - training.trainer - INFO - Epoch 11, Step 37712: Loss=6.0267, Acc=0.122, PPL=414.36
2025-09-22 23:07:09,605 - training.trainer - INFO - Epoch 11, Step 37812: Loss=4.6863, Acc=0.381, PPL=108.45
2025-09-22 23:07:17,570 - training.trainer - INFO - Epoch 11, Step 37912: Loss=5.2070, Acc=0.190, PPL=182.55
2025-09-22 23:07:25,444 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.8233, Acc=0.381, PPL=338.07
2025-09-22 23:07:33,254 - training.trainer - INFO - Epoch 11, Step 38112: Loss=6.5308, Acc=0.110, PPL=685.96
2025-09-22 23:07:41,234 - training.trainer - INFO - Epoch 11, Step 38212: Loss=6.2731, Acc=0.258, PPL=530.13
2025-09-22 23:07:49,247 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.1451, Acc=0.136, PPL=466.45
2025-09-22 23:07:57,207 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.9578, Acc=0.217, PPL=386.75
2025-09-22 23:08:05,135 - training.trainer - INFO - Epoch 11, Step 38512: Loss=5.1513, Acc=0.167, PPL=172.66
2025-09-22 23:08:13,194 - training.trainer - INFO - Epoch 11, Step 38612: Loss=6.7726, Acc=0.222, PPL=873.57
2025-09-22 23:08:21,206 - training.trainer - INFO - Epoch 11, Step 38712: Loss=6.1429, Acc=0.160, PPL=465.39
2025-09-22 23:08:29,094 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.4029, Acc=0.317, PPL=222.04
2025-09-22 23:08:36,940 - training.trainer - INFO - Epoch 11, Step 38912: Loss=6.5174, Acc=0.175, PPL=676.84
2025-09-22 23:08:44,883 - training.trainer - INFO - Epoch 11, Step 39012: Loss=6.0291, Acc=0.233, PPL=415.34
2025-09-22 23:08:52,765 - training.trainer - INFO - Epoch 11, Step 39112: Loss=5.3378, Acc=0.357, PPL=208.06
2025-09-22 23:09:00,692 - training.trainer - INFO - Epoch 11, Step 39212: Loss=5.7619, Acc=0.346, PPL=317.96
2025-09-22 23:09:08,565 - training.trainer - INFO - Epoch 11, Step 39312: Loss=6.7862, Acc=0.150, PPL=885.56
2025-09-22 23:09:16,611 - training.trainer - INFO - Epoch 11, Step 39412: Loss=5.6875, Acc=0.267, PPL=295.15
2025-09-22 23:09:24,689 - training.trainer - INFO - Epoch 11, Step 39512: Loss=5.8444, Acc=0.175, PPL=345.29
2025-09-22 23:09:32,712 - training.trainer - INFO - Epoch 11, Step 39612: Loss=6.8225, Acc=0.140, PPL=918.28
2025-09-22 23:09:40,914 - training.trainer - INFO - Epoch 11, Step 39712: Loss=6.4891, Acc=0.133, PPL=657.93
2025-09-22 23:09:48,726 - training.trainer - INFO - Epoch 11, Step 39812: Loss=6.4583, Acc=0.104, PPL=637.99
2025-09-22 23:09:56,658 - training.trainer - INFO - Epoch 11, Step 39912: Loss=5.2472, Acc=0.286, PPL=190.03
2025-09-22 23:10:04,696 - training.trainer - INFO - Epoch 11, Step 40012: Loss=5.9436, Acc=0.176, PPL=381.29
2025-09-22 23:10:12,594 - training.trainer - INFO - Epoch 11, Step 40112: Loss=6.0485, Acc=0.226, PPL=423.46
2025-09-22 23:10:20,421 - training.trainer - INFO - Epoch 11, Step 40212: Loss=6.5704, Acc=0.108, PPL=713.65
2025-09-22 23:10:28,378 - training.trainer - INFO - Epoch 11, Step 40312: Loss=5.1006, Acc=0.250, PPL=164.12
2025-09-22 23:10:36,442 - training.trainer - INFO - Epoch 11, Step 40412: Loss=5.7561, Acc=0.217, PPL=316.13
2025-09-22 23:10:44,433 - training.trainer - INFO - Epoch 11, Step 40512: Loss=6.9903, Acc=0.156, PPL=1086.02
2025-09-22 23:11:05,436 - training.trainer - INFO - Epoch 12/100 completed in 284.16s - Train Loss: 6.0295, Train Acc: 0.199, Val Loss: 5.9862, Val Acc: 0.201
2025-09-22 23:11:13,898 - training.trainer - INFO - Epoch 12, Step 40695: Loss=5.5946, Acc=0.172, PPL=268.97
2025-09-22 23:11:21,718 - training.trainer - INFO - Epoch 12, Step 40795: Loss=5.9235, Acc=0.278, PPL=373.72
2025-09-22 23:11:29,838 - training.trainer - INFO - Epoch 12, Step 40895: Loss=6.4870, Acc=0.146, PPL=656.56
2025-09-22 23:11:37,758 - training.trainer - INFO - Epoch 12, Step 40995: Loss=4.6385, Acc=0.385, PPL=103.39
2025-09-22 23:11:45,648 - training.trainer - INFO - Epoch 12, Step 41095: Loss=6.4545, Acc=0.240, PPL=635.54
2025-09-22 23:11:53,575 - training.trainer - INFO - Epoch 12, Step 41195: Loss=6.6394, Acc=0.143, PPL=764.60
2025-09-22 23:12:01,683 - training.trainer - INFO - Epoch 12, Step 41295: Loss=6.4217, Acc=0.171, PPL=615.04
2025-09-22 23:12:09,596 - training.trainer - INFO - Epoch 12, Step 41395: Loss=6.0507, Acc=0.152, PPL=424.43
2025-09-22 23:12:17,518 - training.trainer - INFO - Epoch 12, Step 41495: Loss=6.5228, Acc=0.150, PPL=680.50
2025-09-22 23:12:25,558 - training.trainer - INFO - Epoch 12, Step 41595: Loss=6.1500, Acc=0.216, PPL=468.71
2025-09-22 23:12:33,480 - training.trainer - INFO - Epoch 12, Step 41695: Loss=4.4051, Acc=0.474, PPL=81.87
2025-09-22 23:12:41,429 - training.trainer - INFO - Epoch 12, Step 41795: Loss=5.3089, Acc=0.300, PPL=202.14
2025-09-22 23:12:49,277 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.5566, Acc=0.155, PPL=703.88
2025-09-22 23:12:57,195 - training.trainer - INFO - Epoch 12, Step 41995: Loss=5.4067, Acc=0.156, PPL=222.89
2025-09-22 23:13:05,044 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.0274, Acc=0.238, PPL=414.65
2025-09-22 23:13:13,033 - training.trainer - INFO - Epoch 12, Step 42195: Loss=7.1134, Acc=0.143, PPL=1228.33
2025-09-22 23:13:20,884 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.2443, Acc=0.250, PPL=189.49
2025-09-22 23:13:28,740 - training.trainer - INFO - Epoch 12, Step 42395: Loss=6.5272, Acc=0.125, PPL=683.46
2025-09-22 23:13:36,702 - training.trainer - INFO - Epoch 12, Step 42495: Loss=6.1815, Acc=0.107, PPL=483.69
2025-09-22 23:13:44,634 - training.trainer - INFO - Epoch 12, Step 42595: Loss=6.3282, Acc=0.145, PPL=560.15
2025-09-22 23:13:52,497 - training.trainer - INFO - Epoch 12, Step 42695: Loss=6.5396, Acc=0.172, PPL=692.00
2025-09-22 23:14:00,376 - training.trainer - INFO - Epoch 12, Step 42795: Loss=6.2729, Acc=0.137, PPL=529.99
2025-09-22 23:14:08,293 - training.trainer - INFO - Epoch 12, Step 42895: Loss=6.2967, Acc=0.152, PPL=542.76
2025-09-22 23:14:16,290 - training.trainer - INFO - Epoch 12, Step 42995: Loss=5.6983, Acc=0.212, PPL=298.36
2025-09-22 23:14:24,385 - training.trainer - INFO - Epoch 12, Step 43095: Loss=4.3049, Acc=0.333, PPL=74.06
2025-09-22 23:14:32,450 - training.trainer - INFO - Epoch 12, Step 43195: Loss=5.8396, Acc=0.189, PPL=343.64
2025-09-22 23:14:40,531 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.2772, Acc=0.156, PPL=532.28
2025-09-22 23:14:48,435 - training.trainer - INFO - Epoch 12, Step 43395: Loss=6.5312, Acc=0.138, PPL=686.23
2025-09-22 23:14:56,259 - training.trainer - INFO - Epoch 12, Step 43495: Loss=6.0987, Acc=0.278, PPL=445.28
2025-09-22 23:15:04,184 - training.trainer - INFO - Epoch 12, Step 43595: Loss=6.7739, Acc=0.130, PPL=874.70
2025-09-22 23:15:12,204 - training.trainer - INFO - Epoch 12, Step 43695: Loss=6.6086, Acc=0.095, PPL=741.44
2025-09-22 23:15:20,239 - training.trainer - INFO - Epoch 12, Step 43795: Loss=5.6329, Acc=0.269, PPL=279.46
2025-09-22 23:15:28,567 - training.trainer - INFO - Epoch 12, Step 43895: Loss=5.9338, Acc=0.214, PPL=377.59
2025-09-22 23:15:49,709 - training.trainer - INFO - Epoch 13/100 completed in 284.27s - Train Loss: 6.0016, Train Acc: 0.202, Val Loss: 5.9585, Val Acc: 0.207
2025-09-22 23:15:50,561 - training.trainer - INFO - New best model saved with validation loss: 5.9585
2025-09-22 23:15:50,561 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-22 23:15:58,345 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.0983, Acc=0.261, PPL=445.08
2025-09-22 23:16:06,030 - training.trainer - INFO - Epoch 13, Step 44178: Loss=5.8920, Acc=0.100, PPL=362.12
2025-09-22 23:16:13,809 - training.trainer - INFO - Epoch 13, Step 44278: Loss=6.0270, Acc=0.171, PPL=414.48
2025-09-22 23:16:21,935 - training.trainer - INFO - Epoch 13, Step 44378: Loss=6.7975, Acc=0.096, PPL=895.57
2025-09-22 23:16:30,073 - training.trainer - INFO - Epoch 13, Step 44478: Loss=6.1671, Acc=0.116, PPL=476.82
2025-09-22 23:16:38,002 - training.trainer - INFO - Epoch 13, Step 44578: Loss=6.4425, Acc=0.211, PPL=627.97
2025-09-22 23:16:45,846 - training.trainer - INFO - Epoch 13, Step 44678: Loss=6.1993, Acc=0.200, PPL=492.40
2025-09-22 23:16:53,830 - training.trainer - INFO - Epoch 13, Step 44778: Loss=6.5010, Acc=0.127, PPL=665.83
2025-09-22 23:17:01,930 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.3546, Acc=0.200, PPL=211.59
2025-09-22 23:17:10,012 - training.trainer - INFO - Epoch 13, Step 44978: Loss=6.1866, Acc=0.194, PPL=486.18
2025-09-22 23:17:18,026 - training.trainer - INFO - Epoch 13, Step 45078: Loss=5.6423, Acc=0.200, PPL=282.10
2025-09-22 23:17:25,973 - training.trainer - INFO - Epoch 13, Step 45178: Loss=4.9021, Acc=0.350, PPL=134.57
2025-09-22 23:17:34,028 - training.trainer - INFO - Epoch 13, Step 45278: Loss=6.0931, Acc=0.219, PPL=442.80
2025-09-22 23:17:41,925 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.1446, Acc=0.167, PPL=466.19
2025-09-22 23:17:49,821 - training.trainer - INFO - Epoch 13, Step 45478: Loss=6.2591, Acc=0.165, PPL=522.73
2025-09-22 23:17:57,833 - training.trainer - INFO - Epoch 13, Step 45578: Loss=6.1459, Acc=0.189, PPL=466.79
2025-09-22 23:18:05,744 - training.trainer - INFO - Epoch 13, Step 45678: Loss=6.1316, Acc=0.109, PPL=460.15
2025-09-22 23:18:13,625 - training.trainer - INFO - Epoch 13, Step 45778: Loss=5.8345, Acc=0.154, PPL=341.89
2025-09-22 23:18:21,503 - training.trainer - INFO - Epoch 13, Step 45878: Loss=5.8952, Acc=0.250, PPL=363.29
2025-09-22 23:18:29,428 - training.trainer - INFO - Epoch 13, Step 45978: Loss=4.7793, Acc=0.318, PPL=119.02
2025-09-22 23:18:37,523 - training.trainer - INFO - Epoch 13, Step 46078: Loss=6.8168, Acc=0.222, PPL=913.02
2025-09-22 23:18:45,592 - training.trainer - INFO - Epoch 13, Step 46178: Loss=5.7653, Acc=0.214, PPL=319.05
2025-09-22 23:18:53,671 - training.trainer - INFO - Epoch 13, Step 46278: Loss=5.2497, Acc=0.391, PPL=190.51
2025-09-22 23:19:01,696 - training.trainer - INFO - Epoch 13, Step 46378: Loss=5.4811, Acc=0.182, PPL=240.12
2025-09-22 23:19:09,762 - training.trainer - INFO - Epoch 13, Step 46478: Loss=6.1474, Acc=0.129, PPL=467.51
2025-09-22 23:19:17,718 - training.trainer - INFO - Epoch 13, Step 46578: Loss=6.4879, Acc=0.140, PPL=657.11
2025-09-22 23:19:25,614 - training.trainer - INFO - Epoch 13, Step 46678: Loss=6.3665, Acc=0.200, PPL=582.02
2025-09-22 23:19:33,558 - training.trainer - INFO - Epoch 13, Step 46778: Loss=6.2327, Acc=0.175, PPL=509.14
2025-09-22 23:19:41,723 - training.trainer - INFO - Epoch 13, Step 46878: Loss=4.6960, Acc=0.190, PPL=109.51
2025-09-22 23:19:49,764 - training.trainer - INFO - Epoch 13, Step 46978: Loss=6.5374, Acc=0.152, PPL=690.52
2025-09-22 23:19:57,705 - training.trainer - INFO - Epoch 13, Step 47078: Loss=5.7851, Acc=0.375, PPL=325.40
2025-09-22 23:20:06,261 - training.trainer - INFO - Epoch 13, Step 47178: Loss=5.2895, Acc=0.190, PPL=198.24
2025-09-22 23:20:14,366 - training.trainer - INFO - Epoch 13, Step 47278: Loss=5.5979, Acc=0.231, PPL=269.85
2025-09-22 23:20:35,127 - training.trainer - INFO - Epoch 14/100 completed in 284.57s - Train Loss: 5.9848, Train Acc: 0.204, Val Loss: 5.9410, Val Acc: 0.206
2025-09-22 23:20:36,038 - training.trainer - INFO - New best model saved with validation loss: 5.9410
2025-09-22 23:20:36,038 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-22 23:20:44,428 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.1801, Acc=0.207, PPL=177.70
2025-09-22 23:20:52,355 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.4430, Acc=0.238, PPL=231.15
2025-09-22 23:21:00,251 - training.trainer - INFO - Epoch 14, Step 47661: Loss=6.4136, Acc=0.190, PPL=610.06
2025-09-22 23:21:08,305 - training.trainer - INFO - Epoch 14, Step 47761: Loss=6.4271, Acc=0.133, PPL=618.37
2025-09-22 23:21:16,413 - training.trainer - INFO - Epoch 14, Step 47861: Loss=5.2382, Acc=0.235, PPL=188.33
2025-09-22 23:21:24,669 - training.trainer - INFO - Epoch 14, Step 47961: Loss=5.6575, Acc=0.182, PPL=286.44
2025-09-22 23:21:32,689 - training.trainer - INFO - Epoch 14, Step 48061: Loss=6.2710, Acc=0.157, PPL=529.00
2025-09-22 23:21:40,688 - training.trainer - INFO - Epoch 14, Step 48161: Loss=5.2033, Acc=0.208, PPL=181.87
2025-09-22 23:21:48,725 - training.trainer - INFO - Epoch 14, Step 48261: Loss=6.2747, Acc=0.304, PPL=530.94
2025-09-22 23:21:56,822 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.6758, Acc=0.227, PPL=291.73
2025-09-22 23:22:04,716 - training.trainer - INFO - Epoch 14, Step 48461: Loss=7.0583, Acc=0.178, PPL=1162.44
2025-09-22 23:22:12,580 - training.trainer - INFO - Epoch 14, Step 48561: Loss=5.4875, Acc=0.280, PPL=241.64
2025-09-22 23:22:20,585 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.1570, Acc=0.333, PPL=173.64
2025-09-22 23:22:28,631 - training.trainer - INFO - Epoch 14, Step 48761: Loss=5.3409, Acc=0.211, PPL=208.69
2025-09-22 23:22:36,524 - training.trainer - INFO - Epoch 14, Step 48861: Loss=4.7304, Acc=0.250, PPL=113.35
2025-09-22 23:22:44,458 - training.trainer - INFO - Epoch 14, Step 48961: Loss=5.0725, Acc=0.261, PPL=159.58
2025-09-22 23:22:52,402 - training.trainer - INFO - Epoch 14, Step 49061: Loss=6.0984, Acc=0.136, PPL=445.14
2025-09-22 23:23:00,382 - training.trainer - INFO - Epoch 14, Step 49161: Loss=5.8388, Acc=0.139, PPL=343.36
2025-09-22 23:23:08,292 - training.trainer - INFO - Epoch 14, Step 49261: Loss=5.8998, Acc=0.179, PPL=364.95
2025-09-22 23:23:16,374 - training.trainer - INFO - Epoch 14, Step 49361: Loss=6.7820, Acc=0.151, PPL=881.79
2025-09-22 23:23:24,504 - training.trainer - INFO - Epoch 14, Step 49461: Loss=5.9578, Acc=0.185, PPL=386.76
2025-09-22 23:23:32,517 - training.trainer - INFO - Epoch 14, Step 49561: Loss=5.9494, Acc=0.148, PPL=383.53
2025-09-22 23:23:40,422 - training.trainer - INFO - Epoch 14, Step 49661: Loss=6.2877, Acc=0.178, PPL=537.91
2025-09-22 23:23:48,495 - training.trainer - INFO - Epoch 14, Step 49761: Loss=6.6264, Acc=0.100, PPL=754.79
2025-09-22 23:23:56,457 - training.trainer - INFO - Epoch 14, Step 49861: Loss=4.0957, Acc=0.396, PPL=60.08
2025-09-22 23:24:04,526 - training.trainer - INFO - Epoch 14, Step 49961: Loss=5.6532, Acc=0.296, PPL=285.19
2025-09-22 23:24:12,755 - training.trainer - INFO - Epoch 14, Step 50061: Loss=6.5600, Acc=0.153, PPL=706.27
2025-09-22 23:24:20,776 - training.trainer - INFO - Epoch 14, Step 50161: Loss=5.8557, Acc=0.177, PPL=349.22
2025-09-22 23:24:29,046 - training.trainer - INFO - Epoch 14, Step 50261: Loss=5.2738, Acc=0.212, PPL=195.16
2025-09-22 23:24:37,167 - training.trainer - INFO - Epoch 14, Step 50361: Loss=6.1094, Acc=0.259, PPL=450.05
2025-09-22 23:24:45,184 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.7109, Acc=0.304, PPL=302.15
2025-09-22 23:24:53,401 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.9342, Acc=0.217, PPL=377.73
2025-09-22 23:25:01,436 - training.trainer - INFO - Epoch 14, Step 50661: Loss=5.3358, Acc=0.297, PPL=207.65
2025-09-22 23:25:21,982 - training.trainer - INFO - Epoch 15/100 completed in 285.94s - Train Loss: 5.9627, Train Acc: 0.208, Val Loss: 5.9153, Val Acc: 0.210
2025-09-22 23:25:22,431 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-22 23:25:23,149 - training.trainer - INFO - New best model saved with validation loss: 5.9153
2025-09-22 23:25:23,150 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-22 23:25:31,566 - training.trainer - INFO - Epoch 15, Step 50844: Loss=6.0396, Acc=0.200, PPL=419.74
2025-09-22 23:25:39,692 - training.trainer - INFO - Epoch 15, Step 50944: Loss=6.0673, Acc=0.132, PPL=431.52
2025-09-22 23:25:48,128 - training.trainer - INFO - Epoch 15, Step 51044: Loss=5.4143, Acc=0.257, PPL=224.59
2025-09-22 23:25:56,123 - training.trainer - INFO - Epoch 15, Step 51144: Loss=6.4031, Acc=0.125, PPL=603.71
2025-09-22 23:26:03,981 - training.trainer - INFO - Epoch 15, Step 51244: Loss=5.8547, Acc=0.244, PPL=348.86
2025-09-22 23:26:11,874 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.2990, Acc=0.346, PPL=200.13
2025-09-22 23:26:19,788 - training.trainer - INFO - Epoch 15, Step 51444: Loss=5.8862, Acc=0.211, PPL=360.02
2025-09-22 23:26:27,664 - training.trainer - INFO - Epoch 15, Step 51544: Loss=5.4757, Acc=0.241, PPL=238.82
2025-09-22 23:26:35,580 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.6534, Acc=0.348, PPL=285.25
2025-09-22 23:26:43,489 - training.trainer - INFO - Epoch 15, Step 51744: Loss=6.6913, Acc=0.114, PPL=805.34
2025-09-22 23:26:51,446 - training.trainer - INFO - Epoch 15, Step 51844: Loss=6.0965, Acc=0.160, PPL=444.31
2025-09-22 23:26:59,326 - training.trainer - INFO - Epoch 15, Step 51944: Loss=6.1386, Acc=0.179, PPL=463.38
2025-09-22 23:27:07,123 - training.trainer - INFO - Epoch 15, Step 52044: Loss=4.8766, Acc=0.387, PPL=131.18
2025-09-22 23:27:14,998 - training.trainer - INFO - Epoch 15, Step 52144: Loss=4.7356, Acc=0.333, PPL=113.93
2025-09-22 23:27:22,959 - training.trainer - INFO - Epoch 15, Step 52244: Loss=5.7134, Acc=0.195, PPL=302.91
2025-09-22 23:27:30,884 - training.trainer - INFO - Epoch 15, Step 52344: Loss=5.2612, Acc=0.267, PPL=192.72
2025-09-22 23:27:38,830 - training.trainer - INFO - Epoch 15, Step 52444: Loss=5.4831, Acc=0.300, PPL=240.58
2025-09-22 23:27:46,727 - training.trainer - INFO - Epoch 15, Step 52544: Loss=5.2672, Acc=0.300, PPL=193.87
2025-09-22 23:27:54,637 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.9021, Acc=0.200, PPL=365.82
2025-09-22 23:28:02,457 - training.trainer - INFO - Epoch 15, Step 52744: Loss=6.2533, Acc=0.188, PPL=519.70
2025-09-22 23:28:10,431 - training.trainer - INFO - Epoch 15, Step 52844: Loss=6.1550, Acc=0.176, PPL=471.05
2025-09-22 23:28:18,367 - training.trainer - INFO - Epoch 15, Step 52944: Loss=6.4605, Acc=0.146, PPL=639.39
2025-09-22 23:28:26,493 - training.trainer - INFO - Epoch 15, Step 53044: Loss=5.4858, Acc=0.190, PPL=241.25
2025-09-22 23:28:34,622 - training.trainer - INFO - Epoch 15, Step 53144: Loss=5.8784, Acc=0.185, PPL=357.23
2025-09-22 23:28:42,667 - training.trainer - INFO - Epoch 15, Step 53244: Loss=5.9859, Acc=0.196, PPL=397.77
2025-09-22 23:28:50,836 - training.trainer - INFO - Epoch 15, Step 53344: Loss=5.6677, Acc=0.250, PPL=289.37
2025-09-22 23:28:59,064 - training.trainer - INFO - Epoch 15, Step 53444: Loss=6.7022, Acc=0.160, PPL=814.23
2025-09-22 23:29:07,120 - training.trainer - INFO - Epoch 15, Step 53544: Loss=5.1218, Acc=0.333, PPL=167.64
2025-09-22 23:29:15,035 - training.trainer - INFO - Epoch 15, Step 53644: Loss=5.3261, Acc=0.130, PPL=205.64
2025-09-22 23:29:23,053 - training.trainer - INFO - Epoch 15, Step 53744: Loss=6.2092, Acc=0.105, PPL=497.32
2025-09-22 23:29:31,095 - training.trainer - INFO - Epoch 15, Step 53844: Loss=6.2712, Acc=0.217, PPL=529.13
2025-09-22 23:29:39,024 - training.trainer - INFO - Epoch 15, Step 53944: Loss=5.7687, Acc=0.297, PPL=320.12
2025-09-22 23:29:46,851 - training.trainer - INFO - Epoch 15, Step 54044: Loss=5.5161, Acc=0.174, PPL=248.66
2025-09-22 23:30:06,828 - training.trainer - INFO - Epoch 16/100 completed in 283.68s - Train Loss: 5.9505, Train Acc: 0.209, Val Loss: 5.9072, Val Acc: 0.214
2025-09-22 23:30:07,619 - training.trainer - INFO - New best model saved with validation loss: 5.9072
2025-09-22 23:30:07,619 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-22 23:30:16,034 - training.trainer - INFO - Epoch 16, Step 54227: Loss=6.1511, Acc=0.137, PPL=469.22
2025-09-22 23:30:23,961 - training.trainer - INFO - Epoch 16, Step 54327: Loss=5.9325, Acc=0.180, PPL=377.09
2025-09-22 23:30:32,077 - training.trainer - INFO - Epoch 16, Step 54427: Loss=5.5053, Acc=0.245, PPL=246.00
2025-09-22 23:30:39,992 - training.trainer - INFO - Epoch 16, Step 54527: Loss=6.5571, Acc=0.129, PPL=704.22
2025-09-22 23:30:48,044 - training.trainer - INFO - Epoch 16, Step 54627: Loss=5.8221, Acc=0.103, PPL=337.68
2025-09-22 23:30:56,133 - training.trainer - INFO - Epoch 16, Step 54727: Loss=5.7025, Acc=0.132, PPL=299.63
2025-09-22 23:31:04,253 - training.trainer - INFO - Epoch 16, Step 54827: Loss=5.9791, Acc=0.196, PPL=395.07
2025-09-22 23:31:12,291 - training.trainer - INFO - Epoch 16, Step 54927: Loss=5.4219, Acc=0.250, PPL=226.31
2025-09-22 23:31:20,256 - training.trainer - INFO - Epoch 16, Step 55027: Loss=5.6249, Acc=0.250, PPL=277.23
2025-09-22 23:31:28,055 - training.trainer - INFO - Epoch 16, Step 55127: Loss=7.0295, Acc=0.111, PPL=1129.49
2025-09-22 23:31:36,231 - training.trainer - INFO - Epoch 16, Step 55227: Loss=5.4247, Acc=0.235, PPL=226.95
2025-09-22 23:31:44,167 - training.trainer - INFO - Epoch 16, Step 55327: Loss=6.9849, Acc=0.179, PPL=1080.15
2025-09-22 23:31:52,091 - training.trainer - INFO - Epoch 16, Step 55427: Loss=5.8995, Acc=0.231, PPL=364.84
2025-09-22 23:31:59,958 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.9056, Acc=0.212, PPL=367.10
2025-09-22 23:32:07,961 - training.trainer - INFO - Epoch 16, Step 55627: Loss=5.6556, Acc=0.200, PPL=285.88
2025-09-22 23:32:15,998 - training.trainer - INFO - Epoch 16, Step 55727: Loss=5.2053, Acc=0.333, PPL=182.24
2025-09-22 23:32:23,870 - training.trainer - INFO - Epoch 16, Step 55827: Loss=6.1544, Acc=0.175, PPL=470.76
2025-09-22 23:32:31,774 - training.trainer - INFO - Epoch 16, Step 55927: Loss=6.6427, Acc=0.148, PPL=767.14
2025-09-22 23:32:39,750 - training.trainer - INFO - Epoch 16, Step 56027: Loss=5.4593, Acc=0.310, PPL=234.94
2025-09-22 23:32:47,807 - training.trainer - INFO - Epoch 16, Step 56127: Loss=5.9773, Acc=0.227, PPL=394.39
2025-09-22 23:32:55,693 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.3905, Acc=0.222, PPL=219.32
2025-09-22 23:33:03,557 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.7516, Acc=0.205, PPL=314.69
2025-09-22 23:33:11,406 - training.trainer - INFO - Epoch 16, Step 56427: Loss=5.0420, Acc=0.267, PPL=154.78
2025-09-22 23:33:19,526 - training.trainer - INFO - Epoch 16, Step 56527: Loss=6.0357, Acc=0.243, PPL=418.11
2025-09-22 23:33:27,484 - training.trainer - INFO - Epoch 16, Step 56627: Loss=6.5464, Acc=0.128, PPL=696.74
2025-09-22 23:33:35,479 - training.trainer - INFO - Epoch 16, Step 56727: Loss=5.9410, Acc=0.182, PPL=380.33
2025-09-22 23:33:43,379 - training.trainer - INFO - Epoch 16, Step 56827: Loss=6.4470, Acc=0.255, PPL=630.80
2025-09-22 23:33:51,417 - training.trainer - INFO - Epoch 16, Step 56927: Loss=6.0432, Acc=0.194, PPL=421.24
2025-09-22 23:33:59,408 - training.trainer - INFO - Epoch 16, Step 57027: Loss=6.8602, Acc=0.095, PPL=953.55
2025-09-22 23:34:07,325 - training.trainer - INFO - Epoch 16, Step 57127: Loss=6.3161, Acc=0.125, PPL=553.42
2025-09-22 23:34:15,357 - training.trainer - INFO - Epoch 16, Step 57227: Loss=5.7408, Acc=0.292, PPL=311.32
2025-09-22 23:34:23,271 - training.trainer - INFO - Epoch 16, Step 57327: Loss=6.2251, Acc=0.143, PPL=505.26
2025-09-22 23:34:31,441 - training.trainer - INFO - Epoch 16, Step 57427: Loss=6.2816, Acc=0.174, PPL=534.64
2025-09-22 23:34:51,647 - training.trainer - INFO - Epoch 17/100 completed in 284.03s - Train Loss: 5.9315, Train Acc: 0.213, Val Loss: 5.8963, Val Acc: 0.216
2025-09-22 23:34:52,320 - training.trainer - INFO - New best model saved with validation loss: 5.8963
2025-09-22 23:34:52,321 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-22 23:35:00,174 - training.trainer - INFO - Epoch 17, Step 57610: Loss=6.0785, Acc=0.216, PPL=436.39
2025-09-22 23:35:07,097 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.9059, Acc=0.167, PPL=367.20
2025-09-22 23:35:13,991 - training.trainer - INFO - Epoch 17, Step 57810: Loss=6.4873, Acc=0.160, PPL=656.74
2025-09-22 23:35:21,455 - training.trainer - INFO - Epoch 17, Step 57910: Loss=5.7942, Acc=0.273, PPL=328.39
2025-09-22 23:35:28,179 - training.trainer - INFO - Epoch 17, Step 58010: Loss=5.6155, Acc=0.229, PPL=274.66
2025-09-22 23:35:35,018 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.8970, Acc=0.220, PPL=363.96
2025-09-22 23:35:42,444 - training.trainer - INFO - Epoch 17, Step 58210: Loss=5.5535, Acc=0.300, PPL=258.13
2025-09-22 23:35:49,272 - training.trainer - INFO - Epoch 17, Step 58310: Loss=6.3780, Acc=0.189, PPL=588.74
2025-09-22 23:35:55,986 - training.trainer - INFO - Epoch 17, Step 58410: Loss=6.1983, Acc=0.180, PPL=491.93
2025-09-22 23:36:02,930 - training.trainer - INFO - Epoch 17, Step 58510: Loss=6.8540, Acc=0.160, PPL=947.71
2025-09-22 23:36:09,600 - training.trainer - INFO - Epoch 17, Step 58610: Loss=6.3769, Acc=0.229, PPL=588.13
2025-09-22 23:36:17,173 - training.trainer - INFO - Epoch 17, Step 58710: Loss=5.7256, Acc=0.160, PPL=306.61
2025-09-22 23:36:25,122 - training.trainer - INFO - Epoch 17, Step 58810: Loss=6.6735, Acc=0.136, PPL=791.19
2025-09-22 23:36:33,079 - training.trainer - INFO - Epoch 17, Step 58910: Loss=5.7658, Acc=0.194, PPL=319.19
2025-09-22 23:36:40,969 - training.trainer - INFO - Epoch 17, Step 59010: Loss=6.2428, Acc=0.130, PPL=514.30
2025-09-22 23:36:49,004 - training.trainer - INFO - Epoch 17, Step 59110: Loss=6.1939, Acc=0.138, PPL=489.73
2025-09-22 23:36:57,073 - training.trainer - INFO - Epoch 17, Step 59210: Loss=6.2544, Acc=0.196, PPL=520.31
2025-09-22 23:37:05,084 - training.trainer - INFO - Epoch 17, Step 59310: Loss=6.2481, Acc=0.136, PPL=517.05
2025-09-22 23:37:13,085 - training.trainer - INFO - Epoch 17, Step 59410: Loss=5.8756, Acc=0.172, PPL=356.24
2025-09-22 23:37:21,006 - training.trainer - INFO - Epoch 17, Step 59510: Loss=5.5712, Acc=0.238, PPL=262.75
2025-09-22 23:37:29,019 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.8563, Acc=0.206, PPL=349.44
2025-09-22 23:37:36,836 - training.trainer - INFO - Epoch 17, Step 59710: Loss=5.1267, Acc=0.400, PPL=168.47
2025-09-22 23:37:44,891 - training.trainer - INFO - Epoch 17, Step 59810: Loss=6.2705, Acc=0.256, PPL=528.76
2025-09-22 23:37:52,875 - training.trainer - INFO - Epoch 17, Step 59910: Loss=6.4295, Acc=0.141, PPL=619.86
2025-09-22 23:38:00,907 - training.trainer - INFO - Epoch 17, Step 60010: Loss=6.1694, Acc=0.182, PPL=477.90
2025-09-22 23:38:09,055 - training.trainer - INFO - Epoch 17, Step 60110: Loss=4.9457, Acc=0.231, PPL=140.57
2025-09-22 23:38:17,092 - training.trainer - INFO - Epoch 17, Step 60210: Loss=6.3505, Acc=0.155, PPL=572.80
2025-09-22 23:38:25,073 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.9121, Acc=0.178, PPL=369.47
2025-09-22 23:38:32,881 - training.trainer - INFO - Epoch 17, Step 60410: Loss=5.9399, Acc=0.194, PPL=379.89
2025-09-22 23:38:40,913 - training.trainer - INFO - Epoch 17, Step 60510: Loss=5.9749, Acc=0.227, PPL=393.42
2025-09-22 23:38:48,920 - training.trainer - INFO - Epoch 17, Step 60610: Loss=6.6923, Acc=0.192, PPL=806.16
2025-09-22 23:38:56,741 - training.trainer - INFO - Epoch 17, Step 60710: Loss=6.4654, Acc=0.143, PPL=642.52
2025-09-22 23:39:04,660 - training.trainer - INFO - Epoch 17, Step 60810: Loss=5.1870, Acc=0.364, PPL=178.92
2025-09-22 23:39:24,269 - training.trainer - INFO - Epoch 18/100 completed in 271.95s - Train Loss: 5.9075, Train Acc: 0.216, Val Loss: 5.8766, Val Acc: 0.215
2025-09-22 23:39:25,127 - training.trainer - INFO - New best model saved with validation loss: 5.8766
2025-09-22 23:39:25,127 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-22 23:39:33,459 - training.trainer - INFO - Epoch 18, Step 60993: Loss=5.9344, Acc=0.259, PPL=377.80
2025-09-22 23:39:41,345 - training.trainer - INFO - Epoch 18, Step 61093: Loss=5.8312, Acc=0.189, PPL=340.76
2025-09-22 23:39:49,424 - training.trainer - INFO - Epoch 18, Step 61193: Loss=6.3331, Acc=0.237, PPL=562.88
2025-09-22 23:39:57,338 - training.trainer - INFO - Epoch 18, Step 61293: Loss=6.5728, Acc=0.154, PPL=715.40
2025-09-22 23:40:05,176 - training.trainer - INFO - Epoch 18, Step 61393: Loss=6.4383, Acc=0.149, PPL=625.33
2025-09-22 23:40:13,056 - training.trainer - INFO - Epoch 18, Step 61493: Loss=6.5952, Acc=0.212, PPL=731.59
2025-09-22 23:40:20,948 - training.trainer - INFO - Epoch 18, Step 61593: Loss=6.2073, Acc=0.119, PPL=496.36
2025-09-22 23:40:28,836 - training.trainer - INFO - Epoch 18, Step 61693: Loss=5.8619, Acc=0.212, PPL=351.38
2025-09-22 23:40:36,675 - training.trainer - INFO - Epoch 18, Step 61793: Loss=5.8337, Acc=0.135, PPL=341.62
2025-09-22 23:40:44,471 - training.trainer - INFO - Epoch 18, Step 61893: Loss=6.4350, Acc=0.262, PPL=623.30
2025-09-22 23:40:52,287 - training.trainer - INFO - Epoch 18, Step 61993: Loss=6.2148, Acc=0.158, PPL=500.10
2025-09-22 23:41:00,167 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.4954, Acc=0.161, PPL=243.56
2025-09-22 23:41:07,981 - training.trainer - INFO - Epoch 18, Step 62193: Loss=6.3506, Acc=0.235, PPL=572.82
2025-09-22 23:41:15,863 - training.trainer - INFO - Epoch 18, Step 62293: Loss=5.7712, Acc=0.214, PPL=320.91
2025-09-22 23:41:23,701 - training.trainer - INFO - Epoch 18, Step 62393: Loss=5.7066, Acc=0.219, PPL=300.84
2025-09-22 23:41:31,679 - training.trainer - INFO - Epoch 18, Step 62493: Loss=4.4251, Acc=0.474, PPL=83.52
2025-09-22 23:41:39,525 - training.trainer - INFO - Epoch 18, Step 62593: Loss=5.1103, Acc=0.205, PPL=165.72
2025-09-22 23:41:47,329 - training.trainer - INFO - Epoch 18, Step 62693: Loss=6.1312, Acc=0.163, PPL=459.98
2025-09-22 23:41:55,144 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.7863, Acc=0.167, PPL=325.81
2025-09-22 23:42:03,105 - training.trainer - INFO - Epoch 18, Step 62893: Loss=5.4430, Acc=0.244, PPL=231.14
2025-09-22 23:42:11,011 - training.trainer - INFO - Epoch 18, Step 62993: Loss=7.0313, Acc=0.111, PPL=1131.52
2025-09-22 23:42:18,864 - training.trainer - INFO - Epoch 18, Step 63093: Loss=6.3954, Acc=0.196, PPL=599.06
2025-09-22 23:42:26,691 - training.trainer - INFO - Epoch 18, Step 63193: Loss=6.5486, Acc=0.200, PPL=698.26
2025-09-22 23:42:34,513 - training.trainer - INFO - Epoch 18, Step 63293: Loss=6.1394, Acc=0.213, PPL=463.78
2025-09-22 23:42:42,431 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.3591, Acc=0.333, PPL=212.53
2025-09-22 23:42:50,233 - training.trainer - INFO - Epoch 18, Step 63493: Loss=5.7250, Acc=0.191, PPL=306.43
2025-09-22 23:42:58,017 - training.trainer - INFO - Epoch 18, Step 63593: Loss=6.3800, Acc=0.158, PPL=589.95
2025-09-22 23:43:05,881 - training.trainer - INFO - Epoch 18, Step 63693: Loss=5.9999, Acc=0.203, PPL=403.40
2025-09-22 23:43:13,796 - training.trainer - INFO - Epoch 18, Step 63793: Loss=6.6851, Acc=0.170, PPL=800.35
2025-09-22 23:43:21,608 - training.trainer - INFO - Epoch 18, Step 63893: Loss=5.0608, Acc=0.255, PPL=157.72
2025-09-22 23:43:29,454 - training.trainer - INFO - Epoch 18, Step 63993: Loss=5.3187, Acc=0.292, PPL=204.12
2025-09-22 23:43:37,295 - training.trainer - INFO - Epoch 18, Step 64093: Loss=5.5807, Acc=0.450, PPL=265.26
2025-09-22 23:43:45,204 - training.trainer - INFO - Epoch 18, Step 64193: Loss=6.0126, Acc=0.167, PPL=408.54
2025-09-22 23:44:05,016 - training.trainer - INFO - Epoch 19/100 completed in 279.89s - Train Loss: 5.8909, Train Acc: 0.219, Val Loss: 5.8551, Val Acc: 0.219
2025-09-22 23:44:05,823 - training.trainer - INFO - New best model saved with validation loss: 5.8551
2025-09-22 23:44:05,823 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-22 23:44:13,376 - training.trainer - INFO - Epoch 19, Step 64376: Loss=4.5766, Acc=0.348, PPL=97.19
2025-09-22 23:44:21,189 - training.trainer - INFO - Epoch 19, Step 64476: Loss=6.0029, Acc=0.179, PPL=404.60
2025-09-22 23:44:29,250 - training.trainer - INFO - Epoch 19, Step 64576: Loss=6.1556, Acc=0.273, PPL=471.35
2025-09-22 23:44:37,415 - training.trainer - INFO - Epoch 19, Step 64676: Loss=4.9013, Acc=0.375, PPL=134.47
2025-09-22 23:44:45,383 - training.trainer - INFO - Epoch 19, Step 64776: Loss=5.5227, Acc=0.258, PPL=250.31
2025-09-22 23:44:53,432 - training.trainer - INFO - Epoch 19, Step 64876: Loss=6.1388, Acc=0.167, PPL=463.51
2025-09-22 23:45:01,347 - training.trainer - INFO - Epoch 19, Step 64976: Loss=6.4896, Acc=0.188, PPL=658.24
2025-09-22 23:45:09,249 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.9099, Acc=0.188, PPL=368.68
2025-09-22 23:45:17,431 - training.trainer - INFO - Epoch 19, Step 65176: Loss=5.5125, Acc=0.240, PPL=247.76
2025-09-22 23:45:25,457 - training.trainer - INFO - Epoch 19, Step 65276: Loss=6.5929, Acc=0.121, PPL=729.86
2025-09-22 23:45:33,462 - training.trainer - INFO - Epoch 19, Step 65376: Loss=6.4884, Acc=0.231, PPL=657.46
2025-09-22 23:45:41,427 - training.trainer - INFO - Epoch 19, Step 65476: Loss=6.8920, Acc=0.093, PPL=984.32
2025-09-22 23:45:49,298 - training.trainer - INFO - Epoch 19, Step 65576: Loss=5.8063, Acc=0.167, PPL=332.40
2025-09-22 23:45:57,320 - training.trainer - INFO - Epoch 19, Step 65676: Loss=6.7401, Acc=0.150, PPL=845.68
2025-09-22 23:46:05,148 - training.trainer - INFO - Epoch 19, Step 65776: Loss=6.0357, Acc=0.294, PPL=418.08
2025-09-22 23:46:12,935 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.7728, Acc=0.206, PPL=321.45
2025-09-22 23:46:20,716 - training.trainer - INFO - Epoch 19, Step 65976: Loss=6.0647, Acc=0.174, PPL=430.41
2025-09-22 23:46:28,763 - training.trainer - INFO - Epoch 19, Step 66076: Loss=6.1845, Acc=0.147, PPL=485.15
2025-09-22 23:46:36,598 - training.trainer - INFO - Epoch 19, Step 66176: Loss=6.5156, Acc=0.098, PPL=675.61
2025-09-22 23:46:44,470 - training.trainer - INFO - Epoch 19, Step 66276: Loss=4.6503, Acc=0.341, PPL=104.62
2025-09-22 23:46:52,292 - training.trainer - INFO - Epoch 19, Step 66376: Loss=6.1183, Acc=0.214, PPL=454.08
2025-09-22 23:47:00,262 - training.trainer - INFO - Epoch 19, Step 66476: Loss=5.8364, Acc=0.294, PPL=342.53
2025-09-22 23:47:08,134 - training.trainer - INFO - Epoch 19, Step 66576: Loss=6.0527, Acc=0.175, PPL=425.25
2025-09-22 23:47:15,986 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.3150, Acc=0.300, PPL=203.36
2025-09-22 23:47:23,946 - training.trainer - INFO - Epoch 19, Step 66776: Loss=5.7783, Acc=0.280, PPL=323.20
2025-09-22 23:47:31,864 - training.trainer - INFO - Epoch 19, Step 66876: Loss=6.0549, Acc=0.222, PPL=426.21
2025-09-22 23:47:39,910 - training.trainer - INFO - Epoch 19, Step 66976: Loss=6.2400, Acc=0.143, PPL=512.84
2025-09-22 23:47:47,823 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.4042, Acc=0.238, PPL=222.34
2025-09-22 23:47:55,879 - training.trainer - INFO - Epoch 19, Step 67176: Loss=6.0939, Acc=0.173, PPL=443.14
2025-09-22 23:48:04,062 - training.trainer - INFO - Epoch 19, Step 67276: Loss=5.8719, Acc=0.296, PPL=354.91
2025-09-22 23:48:12,035 - training.trainer - INFO - Epoch 19, Step 67376: Loss=5.8617, Acc=0.300, PPL=351.31
2025-09-22 23:48:20,006 - training.trainer - INFO - Epoch 19, Step 67476: Loss=6.2417, Acc=0.145, PPL=513.74
2025-09-22 23:48:28,086 - training.trainer - INFO - Epoch 19, Step 67576: Loss=6.2676, Acc=0.158, PPL=527.24
2025-09-22 23:48:47,838 - training.trainer - INFO - Epoch 20/100 completed in 282.01s - Train Loss: 5.8812, Train Acc: 0.220, Val Loss: 5.8532, Val Acc: 0.221
2025-09-22 23:48:48,252 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-22 23:48:48,998 - training.trainer - INFO - New best model saved with validation loss: 5.8532
2025-09-22 23:48:48,998 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-22 23:48:56,593 - training.trainer - INFO - Epoch 20, Step 67759: Loss=6.6707, Acc=0.131, PPL=788.91
2025-09-22 23:49:04,182 - training.trainer - INFO - Epoch 20, Step 67859: Loss=6.0378, Acc=0.188, PPL=418.95
2025-09-22 23:49:12,263 - training.trainer - INFO - Epoch 20, Step 67959: Loss=4.0682, Acc=0.417, PPL=58.45
2025-09-22 23:49:20,198 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.2251, Acc=0.350, PPL=185.87
2025-09-22 23:49:28,104 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.6425, Acc=0.167, PPL=282.16
2025-09-22 23:49:36,134 - training.trainer - INFO - Epoch 20, Step 68259: Loss=6.0353, Acc=0.160, PPL=417.93
2025-09-22 23:49:44,235 - training.trainer - INFO - Epoch 20, Step 68359: Loss=4.6640, Acc=0.319, PPL=106.06
2025-09-22 23:49:52,269 - training.trainer - INFO - Epoch 20, Step 68459: Loss=6.1770, Acc=0.308, PPL=481.56
2025-09-22 23:50:00,416 - training.trainer - INFO - Epoch 20, Step 68559: Loss=6.3646, Acc=0.261, PPL=580.91
2025-09-22 23:50:08,440 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.5620, Acc=0.230, PPL=260.35
2025-09-22 23:50:16,567 - training.trainer - INFO - Epoch 20, Step 68759: Loss=6.0702, Acc=0.167, PPL=432.76
2025-09-22 23:50:24,633 - training.trainer - INFO - Epoch 20, Step 68859: Loss=6.3076, Acc=0.168, PPL=548.71
2025-09-22 23:50:32,616 - training.trainer - INFO - Epoch 20, Step 68959: Loss=6.5443, Acc=0.132, PPL=695.27
2025-09-22 23:50:40,476 - training.trainer - INFO - Epoch 20, Step 69059: Loss=5.8687, Acc=0.212, PPL=353.78
2025-09-22 23:50:48,378 - training.trainer - INFO - Epoch 20, Step 69159: Loss=6.7218, Acc=0.159, PPL=830.29
2025-09-22 23:50:56,445 - training.trainer - INFO - Epoch 20, Step 69259: Loss=5.9843, Acc=0.261, PPL=397.16
2025-09-22 23:51:04,355 - training.trainer - INFO - Epoch 20, Step 69359: Loss=6.1426, Acc=0.217, PPL=465.24
2025-09-22 23:51:12,465 - training.trainer - INFO - Epoch 20, Step 69459: Loss=6.2953, Acc=0.233, PPL=542.01
2025-09-22 23:51:20,535 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.3622, Acc=0.317, PPL=213.20
2025-09-22 23:51:28,557 - training.trainer - INFO - Epoch 20, Step 69659: Loss=4.8666, Acc=0.333, PPL=129.88
2025-09-22 23:51:36,509 - training.trainer - INFO - Epoch 20, Step 69759: Loss=6.0992, Acc=0.316, PPL=445.51
2025-09-22 23:51:44,597 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.6902, Acc=0.226, PPL=295.95
2025-09-22 23:51:52,822 - training.trainer - INFO - Epoch 20, Step 69959: Loss=5.3946, Acc=0.235, PPL=220.21
2025-09-22 23:52:00,998 - training.trainer - INFO - Epoch 20, Step 70059: Loss=6.4463, Acc=0.270, PPL=630.39
2025-09-22 23:52:09,001 - training.trainer - INFO - Epoch 20, Step 70159: Loss=4.9778, Acc=0.353, PPL=145.16
2025-09-22 23:52:16,815 - training.trainer - INFO - Epoch 20, Step 70259: Loss=5.9635, Acc=0.184, PPL=388.97
2025-09-22 23:52:25,122 - training.trainer - INFO - Epoch 20, Step 70359: Loss=6.2482, Acc=0.159, PPL=517.09
2025-09-22 23:52:33,315 - training.trainer - INFO - Epoch 20, Step 70459: Loss=4.6348, Acc=0.258, PPL=103.00
2025-09-22 23:52:41,256 - training.trainer - INFO - Epoch 20, Step 70559: Loss=6.3574, Acc=0.132, PPL=576.76
2025-09-22 23:52:49,011 - training.trainer - INFO - Epoch 20, Step 70659: Loss=5.7067, Acc=0.273, PPL=300.89
2025-09-22 23:52:56,834 - training.trainer - INFO - Epoch 20, Step 70759: Loss=6.4199, Acc=0.102, PPL=613.94
2025-09-22 23:53:04,713 - training.trainer - INFO - Epoch 20, Step 70859: Loss=6.0946, Acc=0.241, PPL=443.44
2025-09-22 23:53:12,526 - training.trainer - INFO - Epoch 20, Step 70959: Loss=4.0301, Acc=0.400, PPL=56.27
2025-09-22 23:53:32,150 - training.trainer - INFO - Epoch 21/100 completed in 283.15s - Train Loss: 5.8620, Train Acc: 0.224, Val Loss: 5.8252, Val Acc: 0.227
2025-09-22 23:53:32,936 - training.trainer - INFO - New best model saved with validation loss: 5.8252
2025-09-22 23:53:32,937 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-09-22 23:53:41,414 - training.trainer - INFO - Epoch 21, Step 71142: Loss=6.2320, Acc=0.120, PPL=508.79
2025-09-22 23:53:49,240 - training.trainer - INFO - Epoch 21, Step 71242: Loss=5.9026, Acc=0.191, PPL=366.01
2025-09-22 23:53:57,204 - training.trainer - INFO - Epoch 21, Step 71342: Loss=5.6749, Acc=0.185, PPL=291.45
2025-09-22 23:54:05,181 - training.trainer - INFO - Epoch 21, Step 71442: Loss=6.1305, Acc=0.231, PPL=459.68
2025-09-22 23:54:13,171 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.3332, Acc=0.308, PPL=207.11
2025-09-22 23:54:21,087 - training.trainer - INFO - Epoch 21, Step 71642: Loss=5.7205, Acc=0.225, PPL=305.06
2025-09-22 23:54:28,936 - training.trainer - INFO - Epoch 21, Step 71742: Loss=4.9170, Acc=0.261, PPL=136.59
2025-09-22 23:54:36,952 - training.trainer - INFO - Epoch 21, Step 71842: Loss=3.8052, Acc=0.444, PPL=44.93
2025-09-22 23:54:44,996 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.4731, Acc=0.265, PPL=238.19
2025-09-22 23:54:52,935 - training.trainer - INFO - Epoch 21, Step 72042: Loss=4.5960, Acc=0.318, PPL=99.09
2025-09-22 23:55:00,893 - training.trainer - INFO - Epoch 21, Step 72142: Loss=5.2882, Acc=0.167, PPL=197.98
2025-09-22 23:55:08,906 - training.trainer - INFO - Epoch 21, Step 72242: Loss=6.2378, Acc=0.211, PPL=511.71
2025-09-22 23:55:16,904 - training.trainer - INFO - Epoch 21, Step 72342: Loss=6.3175, Acc=0.157, PPL=554.19
2025-09-22 23:55:24,848 - training.trainer - INFO - Epoch 21, Step 72442: Loss=4.6375, Acc=0.321, PPL=103.28
2025-09-22 23:55:33,074 - training.trainer - INFO - Epoch 21, Step 72542: Loss=6.4381, Acc=0.214, PPL=625.21
2025-09-22 23:55:41,352 - training.trainer - INFO - Epoch 21, Step 72642: Loss=5.7295, Acc=0.174, PPL=307.82
2025-09-22 23:55:49,457 - training.trainer - INFO - Epoch 21, Step 72742: Loss=5.3041, Acc=0.250, PPL=201.17
2025-09-22 23:55:57,514 - training.trainer - INFO - Epoch 21, Step 72842: Loss=5.6622, Acc=0.339, PPL=287.77
2025-09-22 23:56:05,566 - training.trainer - INFO - Epoch 21, Step 72942: Loss=5.4964, Acc=0.323, PPL=243.81
2025-09-22 23:56:13,791 - training.trainer - INFO - Epoch 21, Step 73042: Loss=6.1081, Acc=0.167, PPL=449.51
2025-09-22 23:56:21,958 - training.trainer - INFO - Epoch 21, Step 73142: Loss=5.9730, Acc=0.127, PPL=392.69
2025-09-22 23:56:30,584 - training.trainer - INFO - Epoch 21, Step 73242: Loss=6.3905, Acc=0.189, PPL=596.14
2025-09-22 23:56:38,580 - training.trainer - INFO - Epoch 21, Step 73342: Loss=5.7649, Acc=0.250, PPL=318.89
2025-09-22 23:56:46,635 - training.trainer - INFO - Epoch 21, Step 73442: Loss=3.8571, Acc=0.364, PPL=47.33
2025-09-22 23:56:54,836 - training.trainer - INFO - Epoch 21, Step 73542: Loss=6.1354, Acc=0.151, PPL=461.91
2025-09-22 23:57:02,913 - training.trainer - INFO - Epoch 21, Step 73642: Loss=6.2002, Acc=0.148, PPL=492.86
2025-09-22 23:57:10,861 - training.trainer - INFO - Epoch 21, Step 73742: Loss=6.0195, Acc=0.298, PPL=411.37
2025-09-22 23:57:18,955 - training.trainer - INFO - Epoch 21, Step 73842: Loss=5.1065, Acc=0.381, PPL=165.09
2025-09-22 23:57:27,059 - training.trainer - INFO - Epoch 21, Step 73942: Loss=6.2844, Acc=0.290, PPL=536.13
2025-09-22 23:57:34,998 - training.trainer - INFO - Epoch 21, Step 74042: Loss=6.3607, Acc=0.194, PPL=578.66
2025-09-22 23:57:43,336 - training.trainer - INFO - Epoch 21, Step 74142: Loss=6.1524, Acc=0.250, PPL=469.83
2025-09-22 23:57:51,349 - training.trainer - INFO - Epoch 21, Step 74242: Loss=6.2972, Acc=0.194, PPL=543.07
2025-09-22 23:57:59,510 - training.trainer - INFO - Epoch 21, Step 74342: Loss=5.9925, Acc=0.214, PPL=400.41
2025-09-22 23:58:19,698 - training.trainer - INFO - Epoch 22/100 completed in 286.76s - Train Loss: 5.8399, Train Acc: 0.228, Val Loss: 5.8250, Val Acc: 0.229
2025-09-22 23:58:20,464 - training.trainer - INFO - New best model saved with validation loss: 5.8250
2025-09-22 23:58:20,464 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-09-22 23:58:28,826 - training.trainer - INFO - Epoch 22, Step 74525: Loss=7.2210, Acc=0.098, PPL=1367.80
2025-09-22 23:58:36,954 - training.trainer - INFO - Epoch 22, Step 74625: Loss=6.2181, Acc=0.242, PPL=501.75
2025-09-22 23:58:45,466 - training.trainer - INFO - Epoch 22, Step 74725: Loss=5.4540, Acc=0.296, PPL=233.70
2025-09-22 23:58:53,458 - training.trainer - INFO - Epoch 22, Step 74825: Loss=6.3986, Acc=0.320, PPL=601.00
2025-09-22 23:59:01,406 - training.trainer - INFO - Epoch 22, Step 74925: Loss=6.5919, Acc=0.148, PPL=729.16
2025-09-22 23:59:09,507 - training.trainer - INFO - Epoch 22, Step 75025: Loss=6.1518, Acc=0.258, PPL=469.56
2025-09-22 23:59:17,402 - training.trainer - INFO - Epoch 22, Step 75125: Loss=5.8144, Acc=0.171, PPL=335.09
2025-09-22 23:59:25,452 - training.trainer - INFO - Epoch 22, Step 75225: Loss=5.4327, Acc=0.250, PPL=228.76
2025-09-22 23:59:33,461 - training.trainer - INFO - Epoch 22, Step 75325: Loss=6.3161, Acc=0.200, PPL=553.44
2025-09-22 23:59:41,491 - training.trainer - INFO - Epoch 22, Step 75425: Loss=5.8549, Acc=0.219, PPL=348.93
2025-09-22 23:59:49,414 - training.trainer - INFO - Epoch 22, Step 75525: Loss=5.7858, Acc=0.174, PPL=325.64
2025-09-22 23:59:57,371 - training.trainer - INFO - Epoch 22, Step 75625: Loss=6.7407, Acc=0.148, PPL=846.13
2025-09-23 00:00:05,371 - training.trainer - INFO - Epoch 22, Step 75725: Loss=5.3022, Acc=0.276, PPL=200.77
2025-09-23 00:00:13,458 - training.trainer - INFO - Epoch 22, Step 75825: Loss=6.0992, Acc=0.270, PPL=445.50
2025-09-23 00:00:21,514 - training.trainer - INFO - Epoch 22, Step 75925: Loss=4.6089, Acc=0.529, PPL=100.37
2025-09-23 00:00:29,625 - training.trainer - INFO - Epoch 22, Step 76025: Loss=6.2291, Acc=0.153, PPL=507.29
2025-09-23 00:00:37,853 - training.trainer - INFO - Epoch 22, Step 76125: Loss=6.6165, Acc=0.136, PPL=747.32
2025-09-23 00:00:45,907 - training.trainer - INFO - Epoch 22, Step 76225: Loss=5.7848, Acc=0.179, PPL=325.31
2025-09-23 00:00:53,906 - training.trainer - INFO - Epoch 22, Step 76325: Loss=6.5155, Acc=0.220, PPL=675.50
2025-09-23 00:01:02,060 - training.trainer - INFO - Epoch 22, Step 76425: Loss=4.7250, Acc=0.357, PPL=112.73
2025-09-23 00:01:10,319 - training.trainer - INFO - Epoch 22, Step 76525: Loss=6.0676, Acc=0.246, PPL=431.66
2025-09-23 00:01:18,537 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.5072, Acc=0.269, PPL=246.45
2025-09-23 00:01:26,635 - training.trainer - INFO - Epoch 22, Step 76725: Loss=5.9981, Acc=0.278, PPL=402.66
2025-09-23 00:01:34,709 - training.trainer - INFO - Epoch 22, Step 76825: Loss=6.5781, Acc=0.155, PPL=719.18
2025-09-23 00:01:42,717 - training.trainer - INFO - Epoch 22, Step 76925: Loss=4.6729, Acc=0.467, PPL=107.00
2025-09-23 00:01:50,924 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.5921, Acc=0.220, PPL=268.30
2025-09-23 00:01:59,103 - training.trainer - INFO - Epoch 22, Step 77125: Loss=4.7828, Acc=0.375, PPL=119.44
2025-09-23 00:02:07,251 - training.trainer - INFO - Epoch 22, Step 77225: Loss=5.4567, Acc=0.346, PPL=234.33
2025-09-23 00:02:15,317 - training.trainer - INFO - Epoch 22, Step 77325: Loss=6.2022, Acc=0.224, PPL=493.82
2025-09-23 00:02:23,318 - training.trainer - INFO - Epoch 22, Step 77425: Loss=5.9350, Acc=0.217, PPL=378.05
2025-09-23 00:02:31,544 - training.trainer - INFO - Epoch 22, Step 77525: Loss=5.6885, Acc=0.188, PPL=295.46
2025-09-23 00:02:39,559 - training.trainer - INFO - Epoch 22, Step 77625: Loss=6.6977, Acc=0.227, PPL=810.56
2025-09-23 00:02:47,499 - training.trainer - INFO - Epoch 22, Step 77725: Loss=4.3895, Acc=0.400, PPL=80.60
2025-09-23 00:03:07,913 - training.trainer - INFO - Epoch 23/100 completed in 287.45s - Train Loss: 5.8248, Train Acc: 0.229, Val Loss: 5.8143, Val Acc: 0.230
2025-09-23 00:03:08,530 - training.trainer - INFO - New best model saved with validation loss: 5.8143
2025-09-23 00:03:08,530 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-09-23 00:03:16,081 - training.trainer - INFO - Epoch 23, Step 77908: Loss=6.0403, Acc=0.241, PPL=420.01
2025-09-23 00:03:23,323 - training.trainer - INFO - Epoch 23, Step 78008: Loss=6.1842, Acc=0.162, PPL=485.01
2025-09-23 00:03:31,170 - training.trainer - INFO - Epoch 23, Step 78108: Loss=5.9568, Acc=0.200, PPL=386.39
2025-09-23 00:03:38,380 - training.trainer - INFO - Epoch 23, Step 78208: Loss=6.0965, Acc=0.158, PPL=444.31
2025-09-23 00:03:45,503 - training.trainer - INFO - Epoch 23, Step 78308: Loss=4.9979, Acc=0.250, PPL=148.11
2025-09-23 00:03:52,665 - training.trainer - INFO - Epoch 23, Step 78408: Loss=6.1719, Acc=0.185, PPL=479.11
2025-09-23 00:04:00,492 - training.trainer - INFO - Epoch 23, Step 78508: Loss=6.0647, Acc=0.184, PPL=430.40
2025-09-23 00:04:08,708 - training.trainer - INFO - Epoch 23, Step 78608: Loss=6.0538, Acc=0.133, PPL=425.73
2025-09-23 00:04:16,682 - training.trainer - INFO - Epoch 23, Step 78708: Loss=6.3702, Acc=0.212, PPL=584.15
2025-09-23 00:04:24,709 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.8728, Acc=0.238, PPL=355.26
2025-09-23 00:04:33,107 - training.trainer - INFO - Epoch 23, Step 78908: Loss=5.7549, Acc=0.250, PPL=315.73
2025-09-23 00:04:41,017 - training.trainer - INFO - Epoch 23, Step 79008: Loss=4.6321, Acc=0.353, PPL=102.73
2025-09-23 00:04:49,127 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.9521, Acc=0.160, PPL=384.57
2025-09-23 00:04:57,086 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.7248, Acc=0.242, PPL=306.38
2025-09-23 00:05:05,145 - training.trainer - INFO - Epoch 23, Step 79308: Loss=6.4273, Acc=0.250, PPL=618.52
2025-09-23 00:05:13,019 - training.trainer - INFO - Epoch 23, Step 79408: Loss=6.4451, Acc=0.183, PPL=629.61
2025-09-23 00:05:20,928 - training.trainer - INFO - Epoch 23, Step 79508: Loss=6.3506, Acc=0.186, PPL=572.84
2025-09-23 00:05:28,886 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.6560, Acc=0.256, PPL=285.99
2025-09-23 00:05:37,168 - training.trainer - INFO - Epoch 23, Step 79708: Loss=6.0743, Acc=0.292, PPL=434.54
2025-09-23 00:05:45,393 - training.trainer - INFO - Epoch 23, Step 79808: Loss=4.9427, Acc=0.261, PPL=140.14
2025-09-23 00:05:53,932 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.5331, Acc=0.240, PPL=252.94
2025-09-23 00:06:02,408 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.9397, Acc=0.242, PPL=379.83
2025-09-23 00:06:10,746 - training.trainer - INFO - Epoch 23, Step 80108: Loss=5.8543, Acc=0.273, PPL=348.74
2025-09-23 00:06:18,988 - training.trainer - INFO - Epoch 23, Step 80208: Loss=6.2622, Acc=0.186, PPL=524.38
2025-09-23 00:06:27,091 - training.trainer - INFO - Epoch 23, Step 80308: Loss=6.1711, Acc=0.222, PPL=478.72
2025-09-23 00:06:35,098 - training.trainer - INFO - Epoch 23, Step 80408: Loss=4.6265, Acc=0.348, PPL=102.15
2025-09-23 00:06:43,203 - training.trainer - INFO - Epoch 23, Step 80508: Loss=6.1362, Acc=0.158, PPL=462.30
2025-09-23 00:06:51,332 - training.trainer - INFO - Epoch 23, Step 80608: Loss=6.0433, Acc=0.227, PPL=421.27
2025-09-23 00:06:59,806 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.6340, Acc=0.204, PPL=279.79
2025-09-23 00:07:07,939 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.8869, Acc=0.194, PPL=360.27
2025-09-23 00:07:16,154 - training.trainer - INFO - Epoch 23, Step 80908: Loss=6.4051, Acc=0.207, PPL=604.90
2025-09-23 00:07:24,222 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.1198, Acc=0.243, PPL=167.31
2025-09-23 00:07:32,400 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.7595, Acc=0.250, PPL=317.19
2025-09-23 00:07:53,297 - training.trainer - INFO - Epoch 24/100 completed in 284.77s - Train Loss: 5.8071, Train Acc: 0.231, Val Loss: 5.7995, Val Acc: 0.232
2025-09-23 00:07:53,972 - training.trainer - INFO - New best model saved with validation loss: 5.7995
2025-09-23 00:07:53,973 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-09-23 00:08:02,701 - training.trainer - INFO - Epoch 24, Step 81291: Loss=3.9940, Acc=0.478, PPL=54.27
2025-09-23 00:08:10,924 - training.trainer - INFO - Epoch 24, Step 81391: Loss=6.0597, Acc=0.261, PPL=428.26
2025-09-23 00:08:18,982 - training.trainer - INFO - Epoch 24, Step 81491: Loss=6.8142, Acc=0.222, PPL=910.69
2025-09-23 00:08:27,116 - training.trainer - INFO - Epoch 24, Step 81591: Loss=4.6755, Acc=0.333, PPL=107.29
2025-09-23 00:08:35,242 - training.trainer - INFO - Epoch 24, Step 81691: Loss=5.7456, Acc=0.263, PPL=312.80
2025-09-23 00:08:43,467 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.7556, Acc=0.250, PPL=315.94
2025-09-23 00:08:51,617 - training.trainer - INFO - Epoch 24, Step 81891: Loss=6.1298, Acc=0.104, PPL=459.35
2025-09-23 00:08:59,676 - training.trainer - INFO - Epoch 24, Step 81991: Loss=5.8592, Acc=0.200, PPL=350.45
2025-09-23 00:09:07,742 - training.trainer - INFO - Epoch 24, Step 82091: Loss=6.1059, Acc=0.290, PPL=448.50
2025-09-23 00:09:15,905 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.6206, Acc=0.174, PPL=276.05
2025-09-23 00:09:23,954 - training.trainer - INFO - Epoch 24, Step 82291: Loss=5.8969, Acc=0.226, PPL=363.92
2025-09-23 00:09:32,040 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.7578, Acc=0.222, PPL=316.66
2025-09-23 00:09:40,164 - training.trainer - INFO - Epoch 24, Step 82491: Loss=5.8074, Acc=0.213, PPL=332.75
2025-09-23 00:09:48,417 - training.trainer - INFO - Epoch 24, Step 82591: Loss=5.5153, Acc=0.294, PPL=248.46
2025-09-23 00:09:56,430 - training.trainer - INFO - Epoch 24, Step 82691: Loss=5.7658, Acc=0.267, PPL=319.19
2025-09-23 00:10:04,408 - training.trainer - INFO - Epoch 24, Step 82791: Loss=6.4614, Acc=0.143, PPL=639.96
2025-09-23 00:10:12,518 - training.trainer - INFO - Epoch 24, Step 82891: Loss=5.9407, Acc=0.111, PPL=380.21
2025-09-23 00:10:20,479 - training.trainer - INFO - Epoch 24, Step 82991: Loss=5.9978, Acc=0.278, PPL=402.56
2025-09-23 00:10:28,391 - training.trainer - INFO - Epoch 24, Step 83091: Loss=6.7031, Acc=0.132, PPL=814.96
2025-09-23 00:10:36,453 - training.trainer - INFO - Epoch 24, Step 83191: Loss=6.2286, Acc=0.243, PPL=507.03
2025-09-23 00:10:44,575 - training.trainer - INFO - Epoch 24, Step 83291: Loss=6.3004, Acc=0.154, PPL=544.82
2025-09-23 00:10:52,881 - training.trainer - INFO - Epoch 24, Step 83391: Loss=6.1019, Acc=0.214, PPL=446.72
2025-09-23 00:11:00,790 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.5488, Acc=0.196, PPL=256.93
2025-09-23 00:11:08,681 - training.trainer - INFO - Epoch 24, Step 83591: Loss=5.7355, Acc=0.244, PPL=309.65
2025-09-23 00:11:16,619 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.5027, Acc=0.308, PPL=245.36
2025-09-23 00:11:24,577 - training.trainer - INFO - Epoch 24, Step 83791: Loss=4.8576, Acc=0.333, PPL=128.71
2025-09-23 00:11:32,393 - training.trainer - INFO - Epoch 24, Step 83891: Loss=5.5070, Acc=0.250, PPL=246.40
2025-09-23 00:11:40,293 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.5052, Acc=0.209, PPL=245.98
2025-09-23 00:11:48,131 - training.trainer - INFO - Epoch 24, Step 84091: Loss=5.8747, Acc=0.174, PPL=355.92
2025-09-23 00:11:56,002 - training.trainer - INFO - Epoch 24, Step 84191: Loss=6.5268, Acc=0.167, PPL=683.18
2025-09-23 00:12:03,886 - training.trainer - INFO - Epoch 24, Step 84291: Loss=5.1718, Acc=0.278, PPL=176.23
2025-09-23 00:12:11,848 - training.trainer - INFO - Epoch 24, Step 84391: Loss=6.7218, Acc=0.117, PPL=830.32
2025-09-23 00:12:19,881 - training.trainer - INFO - Epoch 24, Step 84491: Loss=6.6946, Acc=0.175, PPL=808.07
2025-09-23 00:12:39,703 - training.trainer - INFO - Epoch 25/100 completed in 285.73s - Train Loss: 5.7868, Train Acc: 0.235, Val Loss: 5.7864, Val Acc: 0.234
2025-09-23 00:12:39,995 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-23 00:12:40,601 - training.trainer - INFO - New best model saved with validation loss: 5.7864
2025-09-23 00:12:40,602 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-23 00:12:47,965 - training.trainer - INFO - Epoch 25, Step 84674: Loss=5.1622, Acc=0.265, PPL=174.54
2025-09-23 00:12:55,516 - training.trainer - INFO - Epoch 25, Step 84774: Loss=5.5377, Acc=0.302, PPL=254.10
2025-09-23 00:13:03,249 - training.trainer - INFO - Epoch 25, Step 84874: Loss=5.7026, Acc=0.364, PPL=299.64
2025-09-23 00:13:10,406 - training.trainer - INFO - Epoch 25, Step 84974: Loss=5.9259, Acc=0.322, PPL=374.62
2025-09-23 00:13:18,372 - training.trainer - INFO - Epoch 25, Step 85074: Loss=6.4010, Acc=0.145, PPL=602.46
2025-09-23 00:13:26,298 - training.trainer - INFO - Epoch 25, Step 85174: Loss=6.1656, Acc=0.190, PPL=476.09
2025-09-23 00:13:34,384 - training.trainer - INFO - Epoch 25, Step 85274: Loss=5.8781, Acc=0.283, PPL=357.11
2025-09-23 00:13:42,587 - training.trainer - INFO - Epoch 25, Step 85374: Loss=5.4395, Acc=0.333, PPL=230.33
2025-09-23 00:13:50,796 - training.trainer - INFO - Epoch 25, Step 85474: Loss=5.2897, Acc=0.227, PPL=198.28
2025-09-23 00:13:58,867 - training.trainer - INFO - Epoch 25, Step 85574: Loss=6.2672, Acc=0.286, PPL=526.98
2025-09-23 00:14:07,288 - training.trainer - INFO - Epoch 25, Step 85674: Loss=3.8079, Acc=0.450, PPL=45.06
2025-09-23 00:14:15,386 - training.trainer - INFO - Epoch 25, Step 85774: Loss=5.9580, Acc=0.300, PPL=386.85
2025-09-23 00:14:23,381 - training.trainer - INFO - Epoch 25, Step 85874: Loss=5.2825, Acc=0.286, PPL=196.86
2025-09-23 00:14:31,426 - training.trainer - INFO - Epoch 25, Step 85974: Loss=6.2084, Acc=0.186, PPL=496.90
2025-09-23 00:14:39,506 - training.trainer - INFO - Epoch 25, Step 86074: Loss=4.0830, Acc=0.333, PPL=59.32
2025-09-23 00:14:47,848 - training.trainer - INFO - Epoch 25, Step 86174: Loss=6.4745, Acc=0.286, PPL=648.38
2025-09-23 00:14:55,899 - training.trainer - INFO - Epoch 25, Step 86274: Loss=6.0625, Acc=0.231, PPL=429.46
2025-09-23 00:15:03,866 - training.trainer - INFO - Epoch 25, Step 86374: Loss=3.4371, Acc=0.522, PPL=31.10
2025-09-23 00:15:11,878 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.7372, Acc=0.175, PPL=310.20
2025-09-23 00:15:19,896 - training.trainer - INFO - Epoch 25, Step 86574: Loss=5.6876, Acc=0.256, PPL=295.19
2025-09-23 00:15:27,919 - training.trainer - INFO - Epoch 25, Step 86674: Loss=6.1875, Acc=0.209, PPL=486.61
2025-09-23 00:15:35,847 - training.trainer - INFO - Epoch 25, Step 86774: Loss=4.6848, Acc=0.409, PPL=108.29
2025-09-23 00:15:43,775 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.3033, Acc=0.229, PPL=546.38
2025-09-23 00:15:51,619 - training.trainer - INFO - Epoch 25, Step 86974: Loss=4.7001, Acc=0.258, PPL=109.95
2025-09-23 00:15:59,515 - training.trainer - INFO - Epoch 25, Step 87074: Loss=4.6461, Acc=0.294, PPL=104.18
2025-09-23 00:16:07,489 - training.trainer - INFO - Epoch 25, Step 87174: Loss=5.5985, Acc=0.235, PPL=270.02
2025-09-23 00:16:15,436 - training.trainer - INFO - Epoch 25, Step 87274: Loss=5.4320, Acc=0.286, PPL=228.62
2025-09-23 00:16:23,263 - training.trainer - INFO - Epoch 25, Step 87374: Loss=6.0796, Acc=0.261, PPL=436.86
2025-09-23 00:16:31,187 - training.trainer - INFO - Epoch 25, Step 87474: Loss=5.2203, Acc=0.235, PPL=184.98
2025-09-23 00:16:38,927 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.9003, Acc=0.150, PPL=365.15
2025-09-23 00:16:46,874 - training.trainer - INFO - Epoch 25, Step 87674: Loss=5.4521, Acc=0.282, PPL=233.24
2025-09-23 00:16:54,676 - training.trainer - INFO - Epoch 25, Step 87774: Loss=5.4287, Acc=0.222, PPL=227.85
2025-09-23 00:17:02,763 - training.trainer - INFO - Epoch 25, Step 87874: Loss=5.9365, Acc=0.195, PPL=378.62
2025-09-23 00:17:22,617 - training.trainer - INFO - Epoch 26/100 completed in 282.01s - Train Loss: 5.7775, Train Acc: 0.236, Val Loss: 5.7869, Val Acc: 0.232
2025-09-23 00:17:30,331 - training.trainer - INFO - Epoch 26, Step 88057: Loss=5.9406, Acc=0.170, PPL=380.15
2025-09-23 00:17:37,800 - training.trainer - INFO - Epoch 26, Step 88157: Loss=6.5765, Acc=0.165, PPL=718.02
2025-09-23 00:17:45,736 - training.trainer - INFO - Epoch 26, Step 88257: Loss=6.4715, Acc=0.222, PPL=646.47
2025-09-23 00:17:53,725 - training.trainer - INFO - Epoch 26, Step 88357: Loss=5.8888, Acc=0.200, PPL=360.96
2025-09-23 00:18:01,684 - training.trainer - INFO - Epoch 26, Step 88457: Loss=4.1665, Acc=0.478, PPL=64.49
2025-09-23 00:18:09,620 - training.trainer - INFO - Epoch 26, Step 88557: Loss=4.8844, Acc=0.268, PPL=132.21
2025-09-23 00:18:17,449 - training.trainer - INFO - Epoch 26, Step 88657: Loss=6.5038, Acc=0.136, PPL=667.66
2025-09-23 00:18:25,251 - training.trainer - INFO - Epoch 26, Step 88757: Loss=5.8025, Acc=0.200, PPL=331.14
2025-09-23 00:18:33,142 - training.trainer - INFO - Epoch 26, Step 88857: Loss=5.6089, Acc=0.233, PPL=272.83
2025-09-23 00:18:41,123 - training.trainer - INFO - Epoch 26, Step 88957: Loss=6.2851, Acc=0.176, PPL=536.51
2025-09-23 00:18:49,110 - training.trainer - INFO - Epoch 26, Step 89057: Loss=5.8880, Acc=0.214, PPL=360.70
2025-09-23 00:18:57,024 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.2366, Acc=0.303, PPL=188.02
2025-09-23 00:19:04,908 - training.trainer - INFO - Epoch 26, Step 89257: Loss=5.5515, Acc=0.276, PPL=257.63
2025-09-23 00:19:12,883 - training.trainer - INFO - Epoch 26, Step 89357: Loss=5.2773, Acc=0.195, PPL=195.85
2025-09-23 00:19:20,796 - training.trainer - INFO - Epoch 26, Step 89457: Loss=6.2066, Acc=0.182, PPL=496.03
2025-09-23 00:19:28,765 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.8588, Acc=0.162, PPL=350.30
2025-09-23 00:19:36,683 - training.trainer - INFO - Epoch 26, Step 89657: Loss=6.3438, Acc=0.196, PPL=568.97
2025-09-23 00:19:44,613 - training.trainer - INFO - Epoch 26, Step 89757: Loss=6.1960, Acc=0.133, PPL=490.79
2025-09-23 00:19:52,427 - training.trainer - INFO - Epoch 26, Step 89857: Loss=6.7819, Acc=0.161, PPL=881.70
2025-09-23 00:20:00,325 - training.trainer - INFO - Epoch 26, Step 89957: Loss=6.2969, Acc=0.148, PPL=542.90
2025-09-23 00:20:08,180 - training.trainer - INFO - Epoch 26, Step 90057: Loss=6.0062, Acc=0.259, PPL=405.94
2025-09-23 00:20:16,138 - training.trainer - INFO - Epoch 26, Step 90157: Loss=4.8798, Acc=0.353, PPL=131.61
2025-09-23 00:20:23,974 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.9879, Acc=0.176, PPL=398.59
2025-09-23 00:20:31,867 - training.trainer - INFO - Epoch 26, Step 90357: Loss=6.2404, Acc=0.164, PPL=513.08
2025-09-23 00:20:39,664 - training.trainer - INFO - Epoch 26, Step 90457: Loss=6.1203, Acc=0.194, PPL=454.99
2025-09-23 00:20:47,526 - training.trainer - INFO - Epoch 26, Step 90557: Loss=5.3694, Acc=0.273, PPL=214.74
2025-09-23 00:20:55,328 - training.trainer - INFO - Epoch 26, Step 90657: Loss=5.2377, Acc=0.268, PPL=188.23
2025-09-23 00:21:03,139 - training.trainer - INFO - Epoch 26, Step 90757: Loss=6.0650, Acc=0.152, PPL=430.51
2025-09-23 00:21:10,984 - training.trainer - INFO - Epoch 26, Step 90857: Loss=5.7354, Acc=0.217, PPL=309.63
2025-09-23 00:21:18,978 - training.trainer - INFO - Epoch 26, Step 90957: Loss=5.6943, Acc=0.182, PPL=297.16
2025-09-23 00:21:27,195 - training.trainer - INFO - Epoch 26, Step 91057: Loss=5.0748, Acc=0.409, PPL=159.95
2025-09-23 00:21:35,092 - training.trainer - INFO - Epoch 26, Step 91157: Loss=5.6088, Acc=0.333, PPL=272.81
2025-09-23 00:21:43,000 - training.trainer - INFO - Epoch 26, Step 91257: Loss=6.1298, Acc=0.222, PPL=459.34
2025-09-23 00:22:02,874 - training.trainer - INFO - Epoch 27/100 completed in 280.26s - Train Loss: 5.7685, Train Acc: 0.238, Val Loss: 5.7726, Val Acc: 0.236
2025-09-23 00:22:03,593 - training.trainer - INFO - New best model saved with validation loss: 5.7726
2025-09-23 00:22:03,594 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_27.pt
2025-09-23 00:22:11,019 - training.trainer - INFO - Epoch 27, Step 91440: Loss=6.3517, Acc=0.156, PPL=573.45
2025-09-23 00:22:18,619 - training.trainer - INFO - Epoch 27, Step 91540: Loss=5.5911, Acc=0.303, PPL=268.04
2025-09-23 00:22:26,101 - training.trainer - INFO - Epoch 27, Step 91640: Loss=4.9361, Acc=0.292, PPL=139.23
2025-09-23 00:22:33,677 - training.trainer - INFO - Epoch 27, Step 91740: Loss=6.1853, Acc=0.157, PPL=485.57
2025-09-23 00:22:41,588 - training.trainer - INFO - Epoch 27, Step 91840: Loss=6.5657, Acc=0.239, PPL=710.34
2025-09-23 00:22:49,571 - training.trainer - INFO - Epoch 27, Step 91940: Loss=5.5810, Acc=0.232, PPL=265.34
2025-09-23 00:22:57,518 - training.trainer - INFO - Epoch 27, Step 92040: Loss=4.6606, Acc=0.409, PPL=105.70
2025-09-23 00:23:05,815 - training.trainer - INFO - Epoch 27, Step 92140: Loss=5.4754, Acc=0.208, PPL=238.75
2025-09-23 00:23:13,663 - training.trainer - INFO - Epoch 27, Step 92240: Loss=5.5752, Acc=0.270, PPL=263.80
2025-09-23 00:23:21,684 - training.trainer - INFO - Epoch 27, Step 92340: Loss=5.5779, Acc=0.236, PPL=264.51
2025-09-23 00:23:30,114 - training.trainer - INFO - Epoch 27, Step 92440: Loss=5.5611, Acc=0.320, PPL=260.10
2025-09-23 00:23:38,307 - training.trainer - INFO - Epoch 27, Step 92540: Loss=4.4994, Acc=0.400, PPL=89.97
2025-09-23 00:23:46,714 - training.trainer - INFO - Epoch 27, Step 92640: Loss=5.5754, Acc=0.286, PPL=263.85
2025-09-23 00:23:54,950 - training.trainer - INFO - Epoch 27, Step 92740: Loss=6.0389, Acc=0.219, PPL=419.45
2025-09-23 00:24:03,314 - training.trainer - INFO - Epoch 27, Step 92840: Loss=6.5406, Acc=0.129, PPL=692.69
2025-09-23 00:24:11,374 - training.trainer - INFO - Epoch 27, Step 92940: Loss=5.3487, Acc=0.333, PPL=210.33
2025-09-23 00:24:19,420 - training.trainer - INFO - Epoch 27, Step 93040: Loss=3.8850, Acc=0.600, PPL=48.66
2025-09-23 00:24:27,062 - training.trainer - INFO - Epoch 27, Step 93140: Loss=6.3304, Acc=0.185, PPL=561.39
2025-09-23 00:24:34,887 - training.trainer - INFO - Epoch 27, Step 93240: Loss=5.9777, Acc=0.189, PPL=394.55
2025-09-23 00:24:42,587 - training.trainer - INFO - Epoch 27, Step 93340: Loss=6.9111, Acc=0.205, PPL=1003.33
2025-09-23 00:24:50,511 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.5054, Acc=0.207, PPL=246.01
2025-09-23 00:24:58,613 - training.trainer - INFO - Epoch 27, Step 93540: Loss=5.2766, Acc=0.333, PPL=195.70
2025-09-23 00:25:06,354 - training.trainer - INFO - Epoch 27, Step 93640: Loss=5.9404, Acc=0.174, PPL=380.10
2025-09-23 00:25:14,098 - training.trainer - INFO - Epoch 27, Step 93740: Loss=6.2207, Acc=0.170, PPL=503.03
2025-09-23 00:25:22,440 - training.trainer - INFO - Epoch 27, Step 93840: Loss=4.8045, Acc=0.333, PPL=122.06
2025-09-23 00:25:30,213 - training.trainer - INFO - Epoch 27, Step 93940: Loss=6.6619, Acc=0.122, PPL=782.06
2025-09-23 00:25:38,096 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.2698, Acc=0.261, PPL=194.37
2025-09-23 00:25:46,427 - training.trainer - INFO - Epoch 27, Step 94140: Loss=6.3086, Acc=0.115, PPL=549.27
2025-09-23 00:25:54,423 - training.trainer - INFO - Epoch 27, Step 94240: Loss=4.8574, Acc=0.391, PPL=128.69
2025-09-23 00:26:02,687 - training.trainer - INFO - Epoch 27, Step 94340: Loss=5.5944, Acc=0.304, PPL=268.90
2025-09-23 00:26:10,354 - training.trainer - INFO - Epoch 27, Step 94440: Loss=6.7569, Acc=0.189, PPL=859.95
2025-09-23 00:26:18,632 - training.trainer - INFO - Epoch 27, Step 94540: Loss=6.2485, Acc=0.250, PPL=517.22
2025-09-23 00:26:26,840 - training.trainer - INFO - Epoch 27, Step 94640: Loss=5.4815, Acc=0.143, PPL=240.21
2025-09-23 00:26:47,443 - training.trainer - INFO - Epoch 28/100 completed in 283.85s - Train Loss: 5.7558, Train Acc: 0.240, Val Loss: 5.7772, Val Acc: 0.236
2025-09-23 00:26:55,703 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.9240, Acc=0.196, PPL=373.92
2025-09-23 00:27:03,305 - training.trainer - INFO - Epoch 28, Step 94923: Loss=5.5443, Acc=0.268, PPL=255.78
2025-09-23 00:27:11,162 - training.trainer - INFO - Epoch 28, Step 95023: Loss=5.9594, Acc=0.176, PPL=387.38
2025-09-23 00:27:18,844 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.6992, Acc=0.276, PPL=298.63
2025-09-23 00:27:26,528 - training.trainer - INFO - Epoch 28, Step 95223: Loss=4.1194, Acc=0.333, PPL=61.52
2025-09-23 00:27:34,127 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.8721, Acc=0.203, PPL=354.98
2025-09-23 00:27:41,775 - training.trainer - INFO - Epoch 28, Step 95423: Loss=5.3940, Acc=0.318, PPL=220.09
2025-09-23 00:27:49,449 - training.trainer - INFO - Epoch 28, Step 95523: Loss=5.4918, Acc=0.250, PPL=242.69
2025-09-23 00:27:57,310 - training.trainer - INFO - Epoch 28, Step 95623: Loss=5.3313, Acc=0.256, PPL=206.70
2025-09-23 00:28:04,852 - training.trainer - INFO - Epoch 28, Step 95723: Loss=5.9966, Acc=0.169, PPL=402.07
2025-09-23 00:28:12,745 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.3418, Acc=0.250, PPL=208.89
2025-09-23 00:28:20,275 - training.trainer - INFO - Epoch 28, Step 95923: Loss=5.9509, Acc=0.239, PPL=384.11
2025-09-23 00:28:27,656 - training.trainer - INFO - Epoch 28, Step 96023: Loss=5.3831, Acc=0.237, PPL=217.70
2025-09-23 00:28:35,261 - training.trainer - INFO - Epoch 28, Step 96123: Loss=5.9745, Acc=0.182, PPL=393.26
2025-09-23 00:28:42,956 - training.trainer - INFO - Epoch 28, Step 96223: Loss=5.7023, Acc=0.216, PPL=299.57
2025-09-23 00:28:50,357 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.2071, Acc=0.250, PPL=182.56
2025-09-23 00:28:57,718 - training.trainer - INFO - Epoch 28, Step 96423: Loss=5.9143, Acc=0.262, PPL=370.30
2025-09-23 00:29:05,295 - training.trainer - INFO - Epoch 28, Step 96523: Loss=4.7771, Acc=0.318, PPL=118.76
2025-09-23 00:29:12,757 - training.trainer - INFO - Epoch 28, Step 96623: Loss=6.0030, Acc=0.172, PPL=404.65
2025-09-23 00:29:21,445 - training.trainer - INFO - Epoch 28, Step 96723: Loss=5.8944, Acc=0.271, PPL=363.00
2025-09-23 00:29:30,346 - training.trainer - INFO - Epoch 28, Step 96823: Loss=5.9116, Acc=0.164, PPL=369.30
2025-09-23 00:29:38,908 - training.trainer - INFO - Epoch 28, Step 96923: Loss=5.4170, Acc=0.350, PPL=225.19
2025-09-23 00:29:47,143 - training.trainer - INFO - Epoch 28, Step 97023: Loss=6.1067, Acc=0.159, PPL=448.87
2025-09-23 00:29:55,097 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.7925, Acc=0.221, PPL=327.82
2025-09-23 00:30:02,946 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.8196, Acc=0.273, PPL=336.83
2025-09-23 00:30:11,082 - training.trainer - INFO - Epoch 28, Step 97323: Loss=5.9690, Acc=0.176, PPL=391.13
2025-09-23 00:30:18,699 - training.trainer - INFO - Epoch 28, Step 97423: Loss=6.1246, Acc=0.333, PPL=456.97
2025-09-23 00:30:26,188 - training.trainer - INFO - Epoch 28, Step 97523: Loss=5.5346, Acc=0.346, PPL=253.30
2025-09-23 00:30:33,713 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.2462, Acc=0.276, PPL=189.84
2025-09-23 00:30:41,521 - training.trainer - INFO - Epoch 28, Step 97723: Loss=5.5089, Acc=0.292, PPL=246.88
2025-09-23 00:30:48,975 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.9216, Acc=0.258, PPL=373.00
2025-09-23 00:30:56,652 - training.trainer - INFO - Epoch 28, Step 97923: Loss=6.0764, Acc=0.192, PPL=435.45
2025-09-23 00:31:04,947 - training.trainer - INFO - Epoch 28, Step 98023: Loss=5.6488, Acc=0.262, PPL=283.94
2025-09-23 00:31:25,711 - training.trainer - INFO - Epoch 29/100 completed in 278.27s - Train Loss: 5.7443, Train Acc: 0.241, Val Loss: 5.7632, Val Acc: 0.234
2025-09-23 00:31:26,566 - training.trainer - INFO - New best model saved with validation loss: 5.7632
2025-09-23 00:31:26,566 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_29.pt
2025-09-23 00:31:35,063 - training.trainer - INFO - Epoch 29, Step 98206: Loss=6.2754, Acc=0.229, PPL=531.33
2025-09-23 00:31:43,314 - training.trainer - INFO - Epoch 29, Step 98306: Loss=6.0586, Acc=0.189, PPL=427.76
2025-09-23 00:31:51,553 - training.trainer - INFO - Epoch 29, Step 98406: Loss=6.3709, Acc=0.118, PPL=584.58
2025-09-23 00:31:59,492 - training.trainer - INFO - Epoch 29, Step 98506: Loss=4.4813, Acc=0.438, PPL=88.35
2025-09-23 00:32:07,458 - training.trainer - INFO - Epoch 29, Step 98606: Loss=5.4737, Acc=0.333, PPL=238.35
2025-09-23 00:32:15,623 - training.trainer - INFO - Epoch 29, Step 98706: Loss=5.4752, Acc=0.277, PPL=238.70
2025-09-23 00:32:23,663 - training.trainer - INFO - Epoch 29, Step 98806: Loss=6.0319, Acc=0.185, PPL=416.51
2025-09-23 00:32:31,684 - training.trainer - INFO - Epoch 29, Step 98906: Loss=6.1600, Acc=0.271, PPL=473.44
2025-09-23 00:32:39,768 - training.trainer - INFO - Epoch 29, Step 99006: Loss=6.2069, Acc=0.157, PPL=496.15
2025-09-23 00:32:48,032 - training.trainer - INFO - Epoch 29, Step 99106: Loss=5.0816, Acc=0.347, PPL=161.03
2025-09-23 00:32:56,076 - training.trainer - INFO - Epoch 29, Step 99206: Loss=5.5328, Acc=0.316, PPL=252.86
2025-09-23 00:33:04,152 - training.trainer - INFO - Epoch 29, Step 99306: Loss=6.0746, Acc=0.195, PPL=434.69
2025-09-23 00:33:12,201 - training.trainer - INFO - Epoch 29, Step 99406: Loss=6.1742, Acc=0.200, PPL=480.19
2025-09-23 00:33:20,233 - training.trainer - INFO - Epoch 29, Step 99506: Loss=5.6527, Acc=0.237, PPL=285.06
2025-09-23 00:33:28,308 - training.trainer - INFO - Epoch 29, Step 99606: Loss=6.5230, Acc=0.140, PPL=680.59
2025-09-23 00:33:36,287 - training.trainer - INFO - Epoch 29, Step 99706: Loss=4.3261, Acc=0.400, PPL=75.65
2025-09-23 00:33:44,214 - training.trainer - INFO - Epoch 29, Step 99806: Loss=4.3550, Acc=0.533, PPL=77.87
2025-09-23 00:33:52,346 - training.trainer - INFO - Epoch 29, Step 99906: Loss=5.9186, Acc=0.286, PPL=371.89
2025-09-23 00:34:00,388 - training.trainer - INFO - Epoch 29, Step 100006: Loss=4.5528, Acc=0.423, PPL=94.90
2025-09-23 00:34:08,508 - training.trainer - INFO - Epoch 29, Step 100106: Loss=5.3746, Acc=0.278, PPL=215.86
2025-09-23 00:34:16,426 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.3130, Acc=0.269, PPL=202.97
2025-09-23 00:34:24,339 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.8094, Acc=0.316, PPL=333.42
2025-09-23 00:34:32,419 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.4439, Acc=0.286, PPL=231.35
2025-09-23 00:34:40,416 - training.trainer - INFO - Epoch 29, Step 100506: Loss=6.0242, Acc=0.222, PPL=413.30
2025-09-23 00:34:48,280 - training.trainer - INFO - Epoch 29, Step 100606: Loss=5.0276, Acc=0.296, PPL=152.57
2025-09-23 00:34:56,269 - training.trainer - INFO - Epoch 29, Step 100706: Loss=5.8740, Acc=0.154, PPL=355.68
2025-09-23 00:35:04,351 - training.trainer - INFO - Epoch 29, Step 100806: Loss=6.1965, Acc=0.171, PPL=491.03
2025-09-23 00:35:12,380 - training.trainer - INFO - Epoch 29, Step 100906: Loss=5.0350, Acc=0.217, PPL=153.69
2025-09-23 00:35:20,572 - training.trainer - INFO - Epoch 29, Step 101006: Loss=5.7544, Acc=0.265, PPL=315.59
2025-09-23 00:35:28,721 - training.trainer - INFO - Epoch 29, Step 101106: Loss=5.8454, Acc=0.233, PPL=345.65
2025-09-23 00:35:36,719 - training.trainer - INFO - Epoch 29, Step 101206: Loss=6.1702, Acc=0.229, PPL=478.28
2025-09-23 00:35:44,761 - training.trainer - INFO - Epoch 29, Step 101306: Loss=5.8715, Acc=0.255, PPL=354.77
2025-09-23 00:35:52,637 - training.trainer - INFO - Epoch 29, Step 101406: Loss=4.9270, Acc=0.350, PPL=137.96
2025-09-23 00:36:12,248 - training.trainer - INFO - Epoch 30/100 completed in 285.68s - Train Loss: 5.7258, Train Acc: 0.244, Val Loss: 5.7511, Val Acc: 0.239
2025-09-23 00:36:12,651 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-23 00:36:13,383 - training.trainer - INFO - New best model saved with validation loss: 5.7511
2025-09-23 00:36:13,383 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-23 00:36:20,716 - training.trainer - INFO - Epoch 30, Step 101589: Loss=6.3185, Acc=0.155, PPL=554.73
2025-09-23 00:36:28,571 - training.trainer - INFO - Epoch 30, Step 101689: Loss=6.5406, Acc=0.235, PPL=692.70
2025-09-23 00:36:36,944 - training.trainer - INFO - Epoch 30, Step 101789: Loss=5.7614, Acc=0.277, PPL=317.79
2025-09-23 00:36:44,940 - training.trainer - INFO - Epoch 30, Step 101889: Loss=5.7891, Acc=0.224, PPL=326.71
2025-09-23 00:36:53,127 - training.trainer - INFO - Epoch 30, Step 101989: Loss=6.5569, Acc=0.185, PPL=704.09
2025-09-23 00:37:01,112 - training.trainer - INFO - Epoch 30, Step 102089: Loss=5.9118, Acc=0.185, PPL=369.37
2025-09-23 00:37:09,114 - training.trainer - INFO - Epoch 30, Step 102189: Loss=5.7795, Acc=0.160, PPL=323.61
2025-09-23 00:37:16,922 - training.trainer - INFO - Epoch 30, Step 102289: Loss=6.1185, Acc=0.204, PPL=454.20
2025-09-23 00:37:24,880 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.6244, Acc=0.308, PPL=277.10
2025-09-23 00:37:32,941 - training.trainer - INFO - Epoch 30, Step 102489: Loss=6.2835, Acc=0.250, PPL=535.63
2025-09-23 00:37:40,928 - training.trainer - INFO - Epoch 30, Step 102589: Loss=6.3347, Acc=0.194, PPL=563.81
2025-09-23 00:37:48,692 - training.trainer - INFO - Epoch 30, Step 102689: Loss=6.4887, Acc=0.185, PPL=657.69
2025-09-23 00:37:56,793 - training.trainer - INFO - Epoch 30, Step 102789: Loss=5.9395, Acc=0.286, PPL=379.76
2025-09-23 00:38:04,459 - training.trainer - INFO - Epoch 30, Step 102889: Loss=6.5446, Acc=0.159, PPL=695.47
2025-09-23 00:38:11,943 - training.trainer - INFO - Epoch 30, Step 102989: Loss=5.9655, Acc=0.235, PPL=389.76
2025-09-23 00:38:19,707 - training.trainer - INFO - Epoch 30, Step 103089: Loss=5.8790, Acc=0.279, PPL=357.46
2025-09-23 00:38:27,727 - training.trainer - INFO - Epoch 30, Step 103189: Loss=5.6472, Acc=0.200, PPL=283.50
2025-09-23 00:38:35,557 - training.trainer - INFO - Epoch 30, Step 103289: Loss=5.9987, Acc=0.182, PPL=402.92
2025-09-23 00:38:43,416 - training.trainer - INFO - Epoch 30, Step 103389: Loss=5.4901, Acc=0.167, PPL=242.29
2025-09-23 00:38:50,964 - training.trainer - INFO - Epoch 30, Step 103489: Loss=5.2378, Acc=0.275, PPL=188.25
2025-09-23 00:38:58,389 - training.trainer - INFO - Epoch 30, Step 103589: Loss=5.4358, Acc=0.200, PPL=229.47
2025-09-23 00:39:05,988 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.4473, Acc=0.276, PPL=232.13
2025-09-23 00:39:13,443 - training.trainer - INFO - Epoch 30, Step 103789: Loss=6.7808, Acc=0.222, PPL=880.78
2025-09-23 00:39:21,122 - training.trainer - INFO - Epoch 30, Step 103889: Loss=5.9868, Acc=0.098, PPL=398.12
2025-09-23 00:39:28,889 - training.trainer - INFO - Epoch 30, Step 103989: Loss=5.7975, Acc=0.194, PPL=329.49
2025-09-23 00:39:36,622 - training.trainer - INFO - Epoch 30, Step 104089: Loss=6.6060, Acc=0.174, PPL=739.50
2025-09-23 00:39:44,173 - training.trainer - INFO - Epoch 30, Step 104189: Loss=5.9558, Acc=0.250, PPL=385.97
2025-09-23 00:39:51,666 - training.trainer - INFO - Epoch 30, Step 104289: Loss=5.5533, Acc=0.250, PPL=258.09
2025-09-23 00:39:59,215 - training.trainer - INFO - Epoch 30, Step 104389: Loss=6.6929, Acc=0.163, PPL=806.62
2025-09-23 00:40:06,703 - training.trainer - INFO - Epoch 30, Step 104489: Loss=6.0293, Acc=0.259, PPL=415.43
2025-09-23 00:40:13,984 - training.trainer - INFO - Epoch 30, Step 104589: Loss=5.3077, Acc=0.250, PPL=201.89
2025-09-23 00:40:21,545 - training.trainer - INFO - Epoch 30, Step 104689: Loss=5.5050, Acc=0.216, PPL=245.91
2025-09-23 00:40:29,215 - training.trainer - INFO - Epoch 30, Step 104789: Loss=5.8242, Acc=0.156, PPL=338.40
2025-09-23 00:40:48,767 - training.trainer - INFO - Epoch 31/100 completed in 275.38s - Train Loss: 5.7154, Train Acc: 0.246, Val Loss: 5.7426, Val Acc: 0.238
2025-09-23 00:40:49,381 - training.trainer - INFO - New best model saved with validation loss: 5.7426
2025-09-23 00:40:49,381 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_31.pt
2025-09-23 00:40:57,585 - training.trainer - INFO - Epoch 31, Step 104972: Loss=4.4974, Acc=0.455, PPL=89.78
2025-09-23 00:41:05,469 - training.trainer - INFO - Epoch 31, Step 105072: Loss=5.4730, Acc=0.259, PPL=238.18
2025-09-23 00:41:13,371 - training.trainer - INFO - Epoch 31, Step 105172: Loss=5.7972, Acc=0.256, PPL=329.38
2025-09-23 00:41:20,757 - training.trainer - INFO - Epoch 31, Step 105272: Loss=5.9151, Acc=0.177, PPL=370.58
2025-09-23 00:41:28,028 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.9845, Acc=0.263, PPL=397.21
2025-09-23 00:41:35,261 - training.trainer - INFO - Epoch 31, Step 105472: Loss=6.1934, Acc=0.200, PPL=489.52
2025-09-23 00:41:42,668 - training.trainer - INFO - Epoch 31, Step 105572: Loss=6.3935, Acc=0.175, PPL=597.95
2025-09-23 00:41:49,863 - training.trainer - INFO - Epoch 31, Step 105672: Loss=3.6653, Acc=0.667, PPL=39.07
2025-09-23 00:41:57,293 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.7299, Acc=0.311, PPL=307.95
2025-09-23 00:42:04,724 - training.trainer - INFO - Epoch 31, Step 105872: Loss=6.1890, Acc=0.170, PPL=487.35
2025-09-23 00:42:12,149 - training.trainer - INFO - Epoch 31, Step 105972: Loss=5.9109, Acc=0.214, PPL=369.05
2025-09-23 00:42:19,599 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.7216, Acc=0.263, PPL=305.39
2025-09-23 00:42:27,033 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.6399, Acc=0.195, PPL=281.44
2025-09-23 00:42:34,112 - training.trainer - INFO - Epoch 31, Step 106272: Loss=5.7471, Acc=0.214, PPL=313.29
2025-09-23 00:42:41,120 - training.trainer - INFO - Epoch 31, Step 106372: Loss=5.2969, Acc=0.244, PPL=199.71
2025-09-23 00:42:48,317 - training.trainer - INFO - Epoch 31, Step 106472: Loss=4.6759, Acc=0.394, PPL=107.33
2025-09-23 00:42:56,297 - training.trainer - INFO - Epoch 31, Step 106572: Loss=5.9834, Acc=0.250, PPL=396.77
2025-09-23 00:43:03,770 - training.trainer - INFO - Epoch 31, Step 106672: Loss=5.8760, Acc=0.281, PPL=356.37
2025-09-23 00:43:11,121 - training.trainer - INFO - Epoch 31, Step 106772: Loss=6.3786, Acc=0.194, PPL=589.10
2025-09-23 00:43:18,160 - training.trainer - INFO - Epoch 31, Step 106872: Loss=5.8324, Acc=0.194, PPL=341.18
2025-09-23 00:43:25,408 - training.trainer - INFO - Epoch 31, Step 106972: Loss=6.2814, Acc=0.219, PPL=534.53
2025-09-23 00:43:32,520 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.8092, Acc=0.226, PPL=333.37
2025-09-23 00:43:39,539 - training.trainer - INFO - Epoch 31, Step 107172: Loss=4.2363, Acc=0.400, PPL=69.15
2025-09-23 00:43:46,708 - training.trainer - INFO - Epoch 31, Step 107272: Loss=6.4379, Acc=0.184, PPL=625.12
2025-09-23 00:43:53,885 - training.trainer - INFO - Epoch 31, Step 107372: Loss=4.4271, Acc=0.333, PPL=83.68
2025-09-23 00:44:01,606 - training.trainer - INFO - Epoch 31, Step 107472: Loss=5.9547, Acc=0.238, PPL=385.57
2025-09-23 00:44:08,890 - training.trainer - INFO - Epoch 31, Step 107572: Loss=6.1380, Acc=0.318, PPL=463.12
2025-09-23 00:44:16,074 - training.trainer - INFO - Epoch 31, Step 107672: Loss=6.8244, Acc=0.100, PPL=920.04
2025-09-23 00:44:23,672 - training.trainer - INFO - Epoch 31, Step 107772: Loss=6.0655, Acc=0.306, PPL=430.75
2025-09-23 00:44:31,313 - training.trainer - INFO - Epoch 31, Step 107872: Loss=5.3070, Acc=0.267, PPL=201.74
2025-09-23 00:44:38,837 - training.trainer - INFO - Epoch 31, Step 107972: Loss=6.0392, Acc=0.333, PPL=419.56
2025-09-23 00:44:46,768 - training.trainer - INFO - Epoch 31, Step 108072: Loss=5.2791, Acc=0.217, PPL=196.18
2025-09-23 00:44:54,904 - training.trainer - INFO - Epoch 31, Step 108172: Loss=6.5241, Acc=0.145, PPL=681.34
2025-09-23 00:45:17,069 - training.trainer - INFO - Epoch 32/100 completed in 267.69s - Train Loss: 5.7021, Train Acc: 0.248, Val Loss: 5.7434, Val Acc: 0.239
2025-09-23 00:45:25,580 - training.trainer - INFO - Epoch 32, Step 108355: Loss=6.7169, Acc=0.188, PPL=826.27
2025-09-23 00:45:33,668 - training.trainer - INFO - Epoch 32, Step 108455: Loss=6.2912, Acc=0.213, PPL=539.83
2025-09-23 00:45:42,079 - training.trainer - INFO - Epoch 32, Step 108555: Loss=5.7069, Acc=0.295, PPL=300.93
2025-09-23 00:45:50,139 - training.trainer - INFO - Epoch 32, Step 108655: Loss=5.8290, Acc=0.183, PPL=340.01
2025-09-23 00:45:58,333 - training.trainer - INFO - Epoch 32, Step 108755: Loss=5.2968, Acc=0.233, PPL=199.69
2025-09-23 00:46:06,470 - training.trainer - INFO - Epoch 32, Step 108855: Loss=5.2836, Acc=0.269, PPL=197.07
2025-09-23 00:46:14,585 - training.trainer - INFO - Epoch 32, Step 108955: Loss=5.5859, Acc=0.167, PPL=266.65
2025-09-23 00:46:22,761 - training.trainer - INFO - Epoch 32, Step 109055: Loss=4.7825, Acc=0.333, PPL=119.40
2025-09-23 00:46:30,916 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.9571, Acc=0.300, PPL=386.48
2025-09-23 00:46:39,087 - training.trainer - INFO - Epoch 32, Step 109255: Loss=5.6612, Acc=0.234, PPL=287.48
2025-09-23 00:46:47,311 - training.trainer - INFO - Epoch 32, Step 109355: Loss=5.5689, Acc=0.344, PPL=262.15
2025-09-23 00:46:55,451 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.0599, Acc=0.261, PPL=157.58
2025-09-23 00:47:03,620 - training.trainer - INFO - Epoch 32, Step 109555: Loss=6.5982, Acc=0.109, PPL=733.78
2025-09-23 00:47:11,720 - training.trainer - INFO - Epoch 32, Step 109655: Loss=5.8612, Acc=0.276, PPL=351.16
2025-09-23 00:47:19,766 - training.trainer - INFO - Epoch 32, Step 109755: Loss=4.7713, Acc=0.309, PPL=118.07
2025-09-23 00:47:27,842 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.7764, Acc=0.163, PPL=322.60
2025-09-23 00:47:35,861 - training.trainer - INFO - Epoch 32, Step 109955: Loss=5.0068, Acc=0.257, PPL=149.42
2025-09-23 00:47:43,968 - training.trainer - INFO - Epoch 32, Step 110055: Loss=3.9548, Acc=0.519, PPL=52.18
2025-09-23 00:47:51,982 - training.trainer - INFO - Epoch 32, Step 110155: Loss=5.9445, Acc=0.209, PPL=381.66
2025-09-23 00:48:00,011 - training.trainer - INFO - Epoch 32, Step 110255: Loss=5.4266, Acc=0.276, PPL=227.37
2025-09-23 00:48:08,089 - training.trainer - INFO - Epoch 32, Step 110355: Loss=5.6151, Acc=0.289, PPL=274.53
2025-09-23 00:48:16,176 - training.trainer - INFO - Epoch 32, Step 110455: Loss=5.7780, Acc=0.240, PPL=323.13
2025-09-23 00:48:24,171 - training.trainer - INFO - Epoch 32, Step 110555: Loss=3.6498, Acc=0.419, PPL=38.47
2025-09-23 00:48:32,227 - training.trainer - INFO - Epoch 32, Step 110655: Loss=6.4621, Acc=0.163, PPL=640.44
2025-09-23 00:48:40,484 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.3745, Acc=0.211, PPL=215.83
2025-09-23 00:48:48,607 - training.trainer - INFO - Epoch 32, Step 110855: Loss=3.8115, Acc=0.542, PPL=45.22
2025-09-23 00:48:56,694 - training.trainer - INFO - Epoch 32, Step 110955: Loss=6.4557, Acc=0.125, PPL=636.31
2025-09-23 00:49:04,597 - training.trainer - INFO - Epoch 32, Step 111055: Loss=5.4621, Acc=0.245, PPL=235.59
2025-09-23 00:49:12,622 - training.trainer - INFO - Epoch 32, Step 111155: Loss=6.3978, Acc=0.174, PPL=600.52
2025-09-23 00:49:20,616 - training.trainer - INFO - Epoch 32, Step 111255: Loss=5.0637, Acc=0.211, PPL=158.18
2025-09-23 00:49:28,620 - training.trainer - INFO - Epoch 32, Step 111355: Loss=6.5499, Acc=0.100, PPL=699.17
2025-09-23 00:49:36,505 - training.trainer - INFO - Epoch 32, Step 111455: Loss=6.4630, Acc=0.158, PPL=640.95
2025-09-23 00:49:44,405 - training.trainer - INFO - Epoch 32, Step 111555: Loss=5.2985, Acc=0.286, PPL=200.03
2025-09-23 00:50:03,338 - training.trainer - INFO - Epoch 33/100 completed in 286.27s - Train Loss: 5.6924, Train Acc: 0.249, Val Loss: 5.7263, Val Acc: 0.239
2025-09-23 00:50:04,109 - training.trainer - INFO - New best model saved with validation loss: 5.7263
2025-09-23 00:50:04,109 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_33.pt
2025-09-23 00:50:11,805 - training.trainer - INFO - Epoch 33, Step 111738: Loss=6.6222, Acc=0.170, PPL=751.60
2025-09-23 00:50:19,798 - training.trainer - INFO - Epoch 33, Step 111838: Loss=6.3104, Acc=0.209, PPL=550.28
2025-09-23 00:50:27,795 - training.trainer - INFO - Epoch 33, Step 111938: Loss=5.2037, Acc=0.333, PPL=181.94
2025-09-23 00:50:35,852 - training.trainer - INFO - Epoch 33, Step 112038: Loss=6.3468, Acc=0.194, PPL=570.69
2025-09-23 00:50:43,807 - training.trainer - INFO - Epoch 33, Step 112138: Loss=6.0047, Acc=0.180, PPL=405.34
2025-09-23 00:50:51,846 - training.trainer - INFO - Epoch 33, Step 112238: Loss=6.1163, Acc=0.280, PPL=453.20
2025-09-23 00:50:59,904 - training.trainer - INFO - Epoch 33, Step 112338: Loss=4.3171, Acc=0.405, PPL=74.97
2025-09-23 00:51:07,877 - training.trainer - INFO - Epoch 33, Step 112438: Loss=5.5789, Acc=0.213, PPL=264.78
2025-09-23 00:51:15,784 - training.trainer - INFO - Epoch 33, Step 112538: Loss=5.7332, Acc=0.163, PPL=308.96
2025-09-23 00:51:23,865 - training.trainer - INFO - Epoch 33, Step 112638: Loss=5.5144, Acc=0.200, PPL=248.24
2025-09-23 00:51:31,836 - training.trainer - INFO - Epoch 33, Step 112738: Loss=5.3114, Acc=0.318, PPL=202.63
2025-09-23 00:51:39,847 - training.trainer - INFO - Epoch 33, Step 112838: Loss=5.4840, Acc=0.273, PPL=240.80
2025-09-23 00:51:47,694 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.9540, Acc=0.276, PPL=385.27
2025-09-23 00:51:55,678 - training.trainer - INFO - Epoch 33, Step 113038: Loss=5.4887, Acc=0.241, PPL=241.93
2025-09-23 00:52:03,653 - training.trainer - INFO - Epoch 33, Step 113138: Loss=5.7794, Acc=0.233, PPL=323.57
2025-09-23 00:52:11,817 - training.trainer - INFO - Epoch 33, Step 113238: Loss=6.3077, Acc=0.102, PPL=548.75
2025-09-23 00:52:19,948 - training.trainer - INFO - Epoch 33, Step 113338: Loss=6.3309, Acc=0.250, PPL=561.67
2025-09-23 00:52:27,774 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.6580, Acc=0.324, PPL=286.56
2025-09-23 00:52:35,574 - training.trainer - INFO - Epoch 33, Step 113538: Loss=6.5283, Acc=0.225, PPL=684.22
2025-09-23 00:52:43,488 - training.trainer - INFO - Epoch 33, Step 113638: Loss=6.0303, Acc=0.167, PPL=415.85
2025-09-23 00:52:51,397 - training.trainer - INFO - Epoch 33, Step 113738: Loss=6.0066, Acc=0.163, PPL=406.10
2025-09-23 00:52:59,357 - training.trainer - INFO - Epoch 33, Step 113838: Loss=6.2483, Acc=0.196, PPL=517.13
2025-09-23 00:53:07,355 - training.trainer - INFO - Epoch 33, Step 113938: Loss=5.8383, Acc=0.270, PPL=343.20
2025-09-23 00:53:15,286 - training.trainer - INFO - Epoch 33, Step 114038: Loss=6.5758, Acc=0.195, PPL=717.49
2025-09-23 00:53:23,148 - training.trainer - INFO - Epoch 33, Step 114138: Loss=5.9360, Acc=0.188, PPL=378.42
2025-09-23 00:53:31,041 - training.trainer - INFO - Epoch 33, Step 114238: Loss=3.8002, Acc=0.565, PPL=44.71
2025-09-23 00:53:38,912 - training.trainer - INFO - Epoch 33, Step 114338: Loss=6.0340, Acc=0.183, PPL=417.38
2025-09-23 00:53:46,848 - training.trainer - INFO - Epoch 33, Step 114438: Loss=5.6610, Acc=0.364, PPL=287.44
2025-09-23 00:53:54,739 - training.trainer - INFO - Epoch 33, Step 114538: Loss=4.4131, Acc=0.350, PPL=82.52
2025-09-23 00:54:02,643 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.5295, Acc=0.314, PPL=252.02
2025-09-23 00:54:10,622 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.8755, Acc=0.238, PPL=356.19
2025-09-23 00:54:18,640 - training.trainer - INFO - Epoch 33, Step 114838: Loss=5.6708, Acc=0.333, PPL=290.27
2025-09-23 00:54:26,586 - training.trainer - INFO - Epoch 33, Step 114938: Loss=5.8164, Acc=0.203, PPL=335.76
2025-09-23 00:54:46,028 - training.trainer - INFO - Epoch 34/100 completed in 281.92s - Train Loss: 5.6816, Train Acc: 0.250, Val Loss: 5.7275, Val Acc: 0.245
2025-09-23 00:54:52,974 - training.trainer - INFO - Epoch 34, Step 115121: Loss=5.7768, Acc=0.207, PPL=322.73
2025-09-23 00:54:59,652 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.5927, Acc=0.154, PPL=268.45
2025-09-23 00:55:06,330 - training.trainer - INFO - Epoch 34, Step 115321: Loss=5.8692, Acc=0.267, PPL=353.97
2025-09-23 00:55:13,023 - training.trainer - INFO - Epoch 34, Step 115421: Loss=4.1307, Acc=0.414, PPL=62.22
2025-09-23 00:55:19,687 - training.trainer - INFO - Epoch 34, Step 115521: Loss=4.9056, Acc=0.320, PPL=135.04
2025-09-23 00:55:26,364 - training.trainer - INFO - Epoch 34, Step 115621: Loss=4.3663, Acc=0.450, PPL=78.75
2025-09-23 00:55:33,136 - training.trainer - INFO - Epoch 34, Step 115721: Loss=6.2420, Acc=0.207, PPL=513.89
2025-09-23 00:55:39,805 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.9258, Acc=0.297, PPL=374.58
2025-09-23 00:55:46,622 - training.trainer - INFO - Epoch 34, Step 115921: Loss=5.9409, Acc=0.208, PPL=380.29
2025-09-23 00:55:53,572 - training.trainer - INFO - Epoch 34, Step 116021: Loss=5.0562, Acc=0.409, PPL=156.99
2025-09-23 00:56:01,130 - training.trainer - INFO - Epoch 34, Step 116121: Loss=6.2249, Acc=0.218, PPL=505.19
2025-09-23 00:56:09,054 - training.trainer - INFO - Epoch 34, Step 116221: Loss=6.3719, Acc=0.261, PPL=585.16
2025-09-23 00:56:17,063 - training.trainer - INFO - Epoch 34, Step 116321: Loss=4.8105, Acc=0.250, PPL=122.79
2025-09-23 00:56:24,986 - training.trainer - INFO - Epoch 34, Step 116421: Loss=4.6410, Acc=0.438, PPL=103.65
2025-09-23 00:56:32,926 - training.trainer - INFO - Epoch 34, Step 116521: Loss=6.2239, Acc=0.136, PPL=504.66
2025-09-23 00:56:40,810 - training.trainer - INFO - Epoch 34, Step 116621: Loss=4.5176, Acc=0.381, PPL=91.61
2025-09-23 00:56:48,710 - training.trainer - INFO - Epoch 34, Step 116721: Loss=5.6108, Acc=0.286, PPL=273.36
2025-09-23 00:56:56,811 - training.trainer - INFO - Epoch 34, Step 116821: Loss=5.9954, Acc=0.206, PPL=401.59
2025-09-23 00:57:04,976 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.5988, Acc=0.295, PPL=270.09
2025-09-23 00:57:13,036 - training.trainer - INFO - Epoch 34, Step 117021: Loss=6.3116, Acc=0.308, PPL=550.90
2025-09-23 00:57:21,031 - training.trainer - INFO - Epoch 34, Step 117121: Loss=5.8714, Acc=0.167, PPL=354.75
2025-09-23 00:57:29,023 - training.trainer - INFO - Epoch 34, Step 117221: Loss=3.8362, Acc=0.514, PPL=46.35
2025-09-23 00:57:37,123 - training.trainer - INFO - Epoch 34, Step 117321: Loss=5.1162, Acc=0.300, PPL=166.70
2025-09-23 00:57:45,122 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.4209, Acc=0.318, PPL=226.07
2025-09-23 00:57:53,152 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.9024, Acc=0.186, PPL=365.92
2025-09-23 00:58:01,197 - training.trainer - INFO - Epoch 34, Step 117621: Loss=5.4906, Acc=0.241, PPL=242.40
2025-09-23 00:58:09,190 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.6928, Acc=0.160, PPL=296.72
2025-09-23 00:58:17,114 - training.trainer - INFO - Epoch 34, Step 117821: Loss=6.2081, Acc=0.193, PPL=496.77
2025-09-23 00:58:25,203 - training.trainer - INFO - Epoch 34, Step 117921: Loss=5.3111, Acc=0.409, PPL=202.57
2025-09-23 00:58:33,114 - training.trainer - INFO - Epoch 34, Step 118021: Loss=5.5729, Acc=0.241, PPL=263.19
2025-09-23 00:58:41,151 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.8545, Acc=0.226, PPL=348.81
2025-09-23 00:58:49,164 - training.trainer - INFO - Epoch 34, Step 118221: Loss=6.4841, Acc=0.164, PPL=654.64
2025-09-23 00:58:57,046 - training.trainer - INFO - Epoch 34, Step 118321: Loss=5.7621, Acc=0.214, PPL=318.02
2025-09-23 00:59:16,542 - training.trainer - INFO - Epoch 35/100 completed in 270.51s - Train Loss: 5.6685, Train Acc: 0.251, Val Loss: 5.7236, Val Acc: 0.245
2025-09-23 00:59:16,922 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-23 00:59:17,668 - training.trainer - INFO - New best model saved with validation loss: 5.7236
2025-09-23 00:59:17,668 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-23 00:59:25,948 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.4969, Acc=0.219, PPL=243.92
2025-09-23 00:59:33,844 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.6822, Acc=0.273, PPL=293.60
2025-09-23 00:59:41,756 - training.trainer - INFO - Epoch 35, Step 118704: Loss=4.9675, Acc=0.388, PPL=143.67
2025-09-23 00:59:49,740 - training.trainer - INFO - Epoch 35, Step 118804: Loss=5.2115, Acc=0.286, PPL=183.37
2025-09-23 00:59:57,889 - training.trainer - INFO - Epoch 35, Step 118904: Loss=5.7930, Acc=0.225, PPL=328.00
2025-09-23 01:00:05,802 - training.trainer - INFO - Epoch 35, Step 119004: Loss=6.1314, Acc=0.163, PPL=460.07
2025-09-23 01:00:13,684 - training.trainer - INFO - Epoch 35, Step 119104: Loss=5.1956, Acc=0.300, PPL=180.47
2025-09-23 01:00:21,599 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.0452, Acc=0.278, PPL=155.27
2025-09-23 01:00:29,436 - training.trainer - INFO - Epoch 35, Step 119304: Loss=4.6613, Acc=0.462, PPL=105.78
2025-09-23 01:00:37,262 - training.trainer - INFO - Epoch 35, Step 119404: Loss=5.4740, Acc=0.250, PPL=238.42
2025-09-23 01:00:45,599 - training.trainer - INFO - Epoch 35, Step 119504: Loss=4.9783, Acc=0.391, PPL=145.22
2025-09-23 01:00:53,526 - training.trainer - INFO - Epoch 35, Step 119604: Loss=6.1978, Acc=0.133, PPL=491.66
2025-09-23 01:01:01,355 - training.trainer - INFO - Epoch 35, Step 119704: Loss=6.5661, Acc=0.125, PPL=710.58
2025-09-23 01:01:09,288 - training.trainer - INFO - Epoch 35, Step 119804: Loss=6.1429, Acc=0.170, PPL=465.38
2025-09-23 01:01:17,177 - training.trainer - INFO - Epoch 35, Step 119904: Loss=4.8069, Acc=0.278, PPL=122.36
2025-09-23 01:01:25,240 - training.trainer - INFO - Epoch 35, Step 120004: Loss=6.1165, Acc=0.212, PPL=453.28
2025-09-23 01:01:33,158 - training.trainer - INFO - Epoch 35, Step 120104: Loss=5.3794, Acc=0.286, PPL=216.90
2025-09-23 01:01:41,106 - training.trainer - INFO - Epoch 35, Step 120204: Loss=6.1523, Acc=0.192, PPL=469.79
2025-09-23 01:01:49,057 - training.trainer - INFO - Epoch 35, Step 120304: Loss=6.1909, Acc=0.150, PPL=488.30
2025-09-23 01:01:56,992 - training.trainer - INFO - Epoch 35, Step 120404: Loss=4.8834, Acc=0.214, PPL=132.08
2025-09-23 01:02:04,801 - training.trainer - INFO - Epoch 35, Step 120504: Loss=5.2145, Acc=0.325, PPL=183.93
2025-09-23 01:02:12,677 - training.trainer - INFO - Epoch 35, Step 120604: Loss=5.0989, Acc=0.333, PPL=163.85
2025-09-23 01:02:20,769 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.6837, Acc=0.316, PPL=294.03
2025-09-23 01:02:28,803 - training.trainer - INFO - Epoch 35, Step 120804: Loss=5.5478, Acc=0.333, PPL=256.67
2025-09-23 01:02:36,673 - training.trainer - INFO - Epoch 35, Step 120904: Loss=3.4897, Acc=0.528, PPL=32.78
2025-09-23 01:02:44,536 - training.trainer - INFO - Epoch 35, Step 121004: Loss=5.8494, Acc=0.184, PPL=347.04
2025-09-23 01:02:52,572 - training.trainer - INFO - Epoch 35, Step 121104: Loss=5.7893, Acc=0.211, PPL=326.78
2025-09-23 01:03:00,575 - training.trainer - INFO - Epoch 35, Step 121204: Loss=5.3425, Acc=0.355, PPL=209.03
2025-09-23 01:03:08,456 - training.trainer - INFO - Epoch 35, Step 121304: Loss=4.5545, Acc=0.323, PPL=95.06
2025-09-23 01:03:16,436 - training.trainer - INFO - Epoch 35, Step 121404: Loss=5.0759, Acc=0.296, PPL=160.11
2025-09-23 01:03:24,385 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.7912, Acc=0.231, PPL=327.41
2025-09-23 01:03:32,321 - training.trainer - INFO - Epoch 35, Step 121604: Loss=5.4678, Acc=0.179, PPL=236.95
2025-09-23 01:03:40,275 - training.trainer - INFO - Epoch 35, Step 121704: Loss=6.5668, Acc=0.160, PPL=711.09
2025-09-23 01:03:59,782 - training.trainer - INFO - Epoch 36/100 completed in 282.11s - Train Loss: 5.6552, Train Acc: 0.255, Val Loss: 5.7181, Val Acc: 0.245
2025-09-23 01:04:00,566 - training.trainer - INFO - New best model saved with validation loss: 5.7181
2025-09-23 01:04:00,566 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_36.pt
2025-09-23 01:04:07,916 - training.trainer - INFO - Epoch 36, Step 121887: Loss=5.7426, Acc=0.250, PPL=311.86
2025-09-23 01:04:14,944 - training.trainer - INFO - Epoch 36, Step 121987: Loss=6.0712, Acc=0.250, PPL=433.21
2025-09-23 01:04:21,954 - training.trainer - INFO - Epoch 36, Step 122087: Loss=5.8792, Acc=0.245, PPL=357.51
2025-09-23 01:04:29,659 - training.trainer - INFO - Epoch 36, Step 122187: Loss=5.7172, Acc=0.364, PPL=304.06
2025-09-23 01:04:37,179 - training.trainer - INFO - Epoch 36, Step 122287: Loss=6.1019, Acc=0.170, PPL=446.73
2025-09-23 01:04:44,136 - training.trainer - INFO - Epoch 36, Step 122387: Loss=5.3165, Acc=0.353, PPL=203.66
2025-09-23 01:04:51,219 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.7034, Acc=0.366, PPL=299.88
2025-09-23 01:04:58,664 - training.trainer - INFO - Epoch 36, Step 122587: Loss=5.3012, Acc=0.292, PPL=200.57
2025-09-23 01:05:06,155 - training.trainer - INFO - Epoch 36, Step 122687: Loss=5.8675, Acc=0.131, PPL=353.36
2025-09-23 01:05:14,051 - training.trainer - INFO - Epoch 36, Step 122787: Loss=6.1835, Acc=0.162, PPL=484.69
2025-09-23 01:05:21,945 - training.trainer - INFO - Epoch 36, Step 122887: Loss=6.4303, Acc=0.220, PPL=620.33
2025-09-23 01:05:29,901 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.4389, Acc=0.216, PPL=230.20
2025-09-23 01:05:37,791 - training.trainer - INFO - Epoch 36, Step 123087: Loss=5.4765, Acc=0.194, PPL=239.02
2025-09-23 01:05:45,682 - training.trainer - INFO - Epoch 36, Step 123187: Loss=5.3095, Acc=0.375, PPL=202.25
2025-09-23 01:05:53,439 - training.trainer - INFO - Epoch 36, Step 123287: Loss=5.9297, Acc=0.262, PPL=376.06
2025-09-23 01:06:01,203 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.5943, Acc=0.235, PPL=268.88
2025-09-23 01:06:09,022 - training.trainer - INFO - Epoch 36, Step 123487: Loss=6.0706, Acc=0.154, PPL=432.96
2025-09-23 01:06:16,815 - training.trainer - INFO - Epoch 36, Step 123587: Loss=5.3140, Acc=0.351, PPL=203.16
2025-09-23 01:06:24,676 - training.trainer - INFO - Epoch 36, Step 123687: Loss=5.9629, Acc=0.200, PPL=388.75
2025-09-23 01:06:32,573 - training.trainer - INFO - Epoch 36, Step 123787: Loss=4.8987, Acc=0.353, PPL=134.11
2025-09-23 01:06:40,402 - training.trainer - INFO - Epoch 36, Step 123887: Loss=5.2432, Acc=0.296, PPL=189.28
2025-09-23 01:06:48,278 - training.trainer - INFO - Epoch 36, Step 123987: Loss=6.2814, Acc=0.308, PPL=534.54
2025-09-23 01:06:56,186 - training.trainer - INFO - Epoch 36, Step 124087: Loss=4.2241, Acc=0.214, PPL=68.31
2025-09-23 01:07:04,210 - training.trainer - INFO - Epoch 36, Step 124187: Loss=5.8715, Acc=0.250, PPL=354.78
2025-09-23 01:07:11,997 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.4708, Acc=0.283, PPL=237.66
2025-09-23 01:07:19,862 - training.trainer - INFO - Epoch 36, Step 124387: Loss=6.5945, Acc=0.214, PPL=731.07
2025-09-23 01:07:27,756 - training.trainer - INFO - Epoch 36, Step 124487: Loss=5.9712, Acc=0.242, PPL=391.98
2025-09-23 01:07:35,543 - training.trainer - INFO - Epoch 36, Step 124587: Loss=5.9852, Acc=0.171, PPL=397.51
2025-09-23 01:07:43,239 - training.trainer - INFO - Epoch 36, Step 124687: Loss=6.0240, Acc=0.162, PPL=413.21
2025-09-23 01:07:51,002 - training.trainer - INFO - Epoch 36, Step 124787: Loss=4.0385, Acc=0.455, PPL=56.74
2025-09-23 01:07:58,865 - training.trainer - INFO - Epoch 36, Step 124887: Loss=6.1503, Acc=0.194, PPL=468.88
2025-09-23 01:08:06,613 - training.trainer - INFO - Epoch 36, Step 124987: Loss=6.3674, Acc=0.188, PPL=582.53
2025-09-23 01:08:14,478 - training.trainer - INFO - Epoch 36, Step 125087: Loss=6.2013, Acc=0.194, PPL=493.40
2025-09-23 01:08:33,371 - training.trainer - INFO - Epoch 37/100 completed in 272.80s - Train Loss: 5.6455, Train Acc: 0.256, Val Loss: 5.7147, Val Acc: 0.244
2025-09-23 01:08:34,032 - training.trainer - INFO - New best model saved with validation loss: 5.7147
2025-09-23 01:08:34,032 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_37.pt
2025-09-23 01:08:42,055 - training.trainer - INFO - Epoch 37, Step 125270: Loss=6.4286, Acc=0.170, PPL=619.33
2025-09-23 01:08:49,901 - training.trainer - INFO - Epoch 37, Step 125370: Loss=5.0698, Acc=0.297, PPL=159.14
2025-09-23 01:08:57,868 - training.trainer - INFO - Epoch 37, Step 125470: Loss=6.1154, Acc=0.255, PPL=452.77
2025-09-23 01:09:05,761 - training.trainer - INFO - Epoch 37, Step 125570: Loss=6.4709, Acc=0.164, PPL=646.05
2025-09-23 01:09:13,570 - training.trainer - INFO - Epoch 37, Step 125670: Loss=5.4529, Acc=0.229, PPL=233.43
2025-09-23 01:09:21,367 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.9758, Acc=0.235, PPL=393.78
2025-09-23 01:09:29,198 - training.trainer - INFO - Epoch 37, Step 125870: Loss=5.6767, Acc=0.231, PPL=291.98
2025-09-23 01:09:37,037 - training.trainer - INFO - Epoch 37, Step 125970: Loss=6.0264, Acc=0.167, PPL=414.22
2025-09-23 01:09:44,825 - training.trainer - INFO - Epoch 37, Step 126070: Loss=5.7902, Acc=0.278, PPL=327.08
2025-09-23 01:09:52,603 - training.trainer - INFO - Epoch 37, Step 126170: Loss=5.4008, Acc=0.288, PPL=221.58
2025-09-23 01:10:00,501 - training.trainer - INFO - Epoch 37, Step 126270: Loss=5.4543, Acc=0.222, PPL=233.76
2025-09-23 01:10:08,471 - training.trainer - INFO - Epoch 37, Step 126370: Loss=5.1495, Acc=0.429, PPL=172.35
2025-09-23 01:10:16,336 - training.trainer - INFO - Epoch 37, Step 126470: Loss=5.6846, Acc=0.188, PPL=294.29
2025-09-23 01:10:24,313 - training.trainer - INFO - Epoch 37, Step 126570: Loss=6.0122, Acc=0.234, PPL=408.40
2025-09-23 01:10:32,417 - training.trainer - INFO - Epoch 37, Step 126670: Loss=6.6547, Acc=0.233, PPL=776.45
2025-09-23 01:10:40,391 - training.trainer - INFO - Epoch 37, Step 126770: Loss=5.7947, Acc=0.209, PPL=328.55
2025-09-23 01:10:48,152 - training.trainer - INFO - Epoch 37, Step 126870: Loss=5.9570, Acc=0.260, PPL=386.43
2025-09-23 01:10:56,134 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.6821, Acc=0.300, PPL=293.57
2025-09-23 01:11:04,273 - training.trainer - INFO - Epoch 37, Step 127070: Loss=5.5749, Acc=0.226, PPL=263.73
2025-09-23 01:11:12,365 - training.trainer - INFO - Epoch 37, Step 127170: Loss=5.7283, Acc=0.246, PPL=307.43
2025-09-23 01:11:20,311 - training.trainer - INFO - Epoch 37, Step 127270: Loss=6.5889, Acc=0.159, PPL=726.95
2025-09-23 01:11:28,236 - training.trainer - INFO - Epoch 37, Step 127370: Loss=4.9762, Acc=0.371, PPL=144.92
2025-09-23 01:11:36,054 - training.trainer - INFO - Epoch 37, Step 127470: Loss=4.7856, Acc=0.289, PPL=119.77
2025-09-23 01:11:44,075 - training.trainer - INFO - Epoch 37, Step 127570: Loss=6.5776, Acc=0.100, PPL=718.79
2025-09-23 01:11:52,055 - training.trainer - INFO - Epoch 37, Step 127670: Loss=5.9755, Acc=0.219, PPL=393.66
2025-09-23 01:11:59,932 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.6508, Acc=0.163, PPL=284.50
2025-09-23 01:12:07,789 - training.trainer - INFO - Epoch 37, Step 127870: Loss=6.1574, Acc=0.205, PPL=472.18
2025-09-23 01:12:15,753 - training.trainer - INFO - Epoch 37, Step 127970: Loss=5.4294, Acc=0.227, PPL=228.02
2025-09-23 01:12:23,731 - training.trainer - INFO - Epoch 37, Step 128070: Loss=6.0903, Acc=0.194, PPL=441.55
2025-09-23 01:12:31,640 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.5278, Acc=0.282, PPL=251.58
2025-09-23 01:12:39,895 - training.trainer - INFO - Epoch 37, Step 128270: Loss=6.1311, Acc=0.182, PPL=459.94
2025-09-23 01:12:48,037 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.4206, Acc=0.259, PPL=226.01
2025-09-23 01:12:56,411 - training.trainer - INFO - Epoch 37, Step 128470: Loss=4.9040, Acc=0.361, PPL=134.83
2025-09-23 01:13:16,101 - training.trainer - INFO - Epoch 38/100 completed in 282.07s - Train Loss: 5.6368, Train Acc: 0.257, Val Loss: 5.7213, Val Acc: 0.246
2025-09-23 01:13:24,513 - training.trainer - INFO - Epoch 38, Step 128653: Loss=5.7742, Acc=0.290, PPL=321.89
2025-09-23 01:13:32,425 - training.trainer - INFO - Epoch 38, Step 128753: Loss=5.7375, Acc=0.195, PPL=310.30
2025-09-23 01:13:40,477 - training.trainer - INFO - Epoch 38, Step 128853: Loss=6.0271, Acc=0.200, PPL=414.52
2025-09-23 01:13:48,946 - training.trainer - INFO - Epoch 38, Step 128953: Loss=5.9837, Acc=0.200, PPL=396.89
2025-09-23 01:13:56,750 - training.trainer - INFO - Epoch 38, Step 129053: Loss=5.1925, Acc=0.348, PPL=179.92
2025-09-23 01:14:04,757 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.3982, Acc=0.238, PPL=221.00
2025-09-23 01:14:12,669 - training.trainer - INFO - Epoch 38, Step 129253: Loss=6.1983, Acc=0.237, PPL=491.89
2025-09-23 01:14:20,632 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.8052, Acc=0.208, PPL=332.03
2025-09-23 01:14:28,602 - training.trainer - INFO - Epoch 38, Step 129453: Loss=6.1786, Acc=0.188, PPL=482.30
2025-09-23 01:14:36,492 - training.trainer - INFO - Epoch 38, Step 129553: Loss=6.6407, Acc=0.182, PPL=765.65
2025-09-23 01:14:44,454 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.5524, Acc=0.320, PPL=257.86
2025-09-23 01:14:52,361 - training.trainer - INFO - Epoch 38, Step 129753: Loss=4.4086, Acc=0.350, PPL=82.16
2025-09-23 01:15:00,330 - training.trainer - INFO - Epoch 38, Step 129853: Loss=6.7286, Acc=0.196, PPL=835.99
2025-09-23 01:15:08,287 - training.trainer - INFO - Epoch 38, Step 129953: Loss=6.0364, Acc=0.176, PPL=418.36
2025-09-23 01:15:16,293 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.4419, Acc=0.205, PPL=230.88
2025-09-23 01:15:24,196 - training.trainer - INFO - Epoch 38, Step 130153: Loss=6.0252, Acc=0.200, PPL=413.71
2025-09-23 01:15:32,118 - training.trainer - INFO - Epoch 38, Step 130253: Loss=4.5436, Acc=0.370, PPL=94.03
2025-09-23 01:15:40,048 - training.trainer - INFO - Epoch 38, Step 130353: Loss=6.3400, Acc=0.190, PPL=566.77
2025-09-23 01:15:47,955 - training.trainer - INFO - Epoch 38, Step 130453: Loss=6.3927, Acc=0.143, PPL=597.44
2025-09-23 01:15:55,872 - training.trainer - INFO - Epoch 38, Step 130553: Loss=5.4537, Acc=0.293, PPL=233.63
2025-09-23 01:16:03,787 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.9116, Acc=0.200, PPL=369.31
2025-09-23 01:16:11,723 - training.trainer - INFO - Epoch 38, Step 130753: Loss=3.2546, Acc=0.778, PPL=25.91
2025-09-23 01:16:19,809 - training.trainer - INFO - Epoch 38, Step 130853: Loss=5.1836, Acc=0.300, PPL=178.33
2025-09-23 01:16:27,725 - training.trainer - INFO - Epoch 38, Step 130953: Loss=5.0785, Acc=0.250, PPL=160.54
2025-09-23 01:16:35,587 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.3960, Acc=0.271, PPL=220.52
2025-09-23 01:16:43,480 - training.trainer - INFO - Epoch 38, Step 131153: Loss=5.8823, Acc=0.194, PPL=358.63
2025-09-23 01:16:51,337 - training.trainer - INFO - Epoch 38, Step 131253: Loss=5.5335, Acc=0.353, PPL=253.03
2025-09-23 01:16:59,375 - training.trainer - INFO - Epoch 38, Step 131353: Loss=6.1738, Acc=0.151, PPL=480.02
2025-09-23 01:17:07,262 - training.trainer - INFO - Epoch 38, Step 131453: Loss=6.3336, Acc=0.265, PPL=563.18
2025-09-23 01:17:15,310 - training.trainer - INFO - Epoch 38, Step 131553: Loss=6.1910, Acc=0.156, PPL=488.36
2025-09-23 01:17:23,442 - training.trainer - INFO - Epoch 38, Step 131653: Loss=4.3527, Acc=0.400, PPL=77.69
2025-09-23 01:17:31,533 - training.trainer - INFO - Epoch 38, Step 131753: Loss=5.0141, Acc=0.302, PPL=150.53
2025-09-23 01:17:39,684 - training.trainer - INFO - Epoch 38, Step 131853: Loss=6.0609, Acc=0.283, PPL=428.75
2025-09-23 01:17:59,726 - training.trainer - INFO - Epoch 39/100 completed in 283.62s - Train Loss: 5.6341, Train Acc: 0.259, Val Loss: 5.7112, Val Acc: 0.248
2025-09-23 01:18:00,635 - training.trainer - INFO - New best model saved with validation loss: 5.7112
2025-09-23 01:18:00,635 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_39.pt
2025-09-23 01:18:08,996 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.9267, Acc=0.234, PPL=374.91
2025-09-23 01:18:17,053 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.9529, Acc=0.121, PPL=384.87
2025-09-23 01:18:25,021 - training.trainer - INFO - Epoch 39, Step 132236: Loss=5.3681, Acc=0.208, PPL=214.45
2025-09-23 01:18:32,872 - training.trainer - INFO - Epoch 39, Step 132336: Loss=5.8047, Acc=0.222, PPL=331.85
2025-09-23 01:18:40,727 - training.trainer - INFO - Epoch 39, Step 132436: Loss=5.1046, Acc=0.421, PPL=164.79
2025-09-23 01:18:48,716 - training.trainer - INFO - Epoch 39, Step 132536: Loss=5.9341, Acc=0.256, PPL=377.71
2025-09-23 01:18:56,849 - training.trainer - INFO - Epoch 39, Step 132636: Loss=6.0151, Acc=0.192, PPL=409.55
2025-09-23 01:19:04,921 - training.trainer - INFO - Epoch 39, Step 132736: Loss=6.7647, Acc=0.200, PPL=866.75
2025-09-23 01:19:13,141 - training.trainer - INFO - Epoch 39, Step 132836: Loss=5.1919, Acc=0.346, PPL=179.81
2025-09-23 01:19:21,075 - training.trainer - INFO - Epoch 39, Step 132936: Loss=6.2677, Acc=0.191, PPL=527.25
2025-09-23 01:19:29,081 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.4418, Acc=0.294, PPL=230.86
2025-09-23 01:19:37,013 - training.trainer - INFO - Epoch 39, Step 133136: Loss=5.9685, Acc=0.236, PPL=390.92
2025-09-23 01:19:44,865 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.5831, Acc=0.162, PPL=265.89
2025-09-23 01:19:52,783 - training.trainer - INFO - Epoch 39, Step 133336: Loss=5.7014, Acc=0.200, PPL=299.29
2025-09-23 01:20:00,728 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.1821, Acc=0.407, PPL=178.07
2025-09-23 01:20:08,568 - training.trainer - INFO - Epoch 39, Step 133536: Loss=5.6943, Acc=0.244, PPL=297.16
2025-09-23 01:20:16,440 - training.trainer - INFO - Epoch 39, Step 133636: Loss=6.3818, Acc=0.196, PPL=591.01
2025-09-23 01:20:24,379 - training.trainer - INFO - Epoch 39, Step 133736: Loss=5.5971, Acc=0.208, PPL=269.65
2025-09-23 01:20:32,360 - training.trainer - INFO - Epoch 39, Step 133836: Loss=5.4504, Acc=0.234, PPL=232.85
2025-09-23 01:20:40,239 - training.trainer - INFO - Epoch 39, Step 133936: Loss=5.1112, Acc=0.333, PPL=165.87
2025-09-23 01:20:48,045 - training.trainer - INFO - Epoch 39, Step 134036: Loss=5.9928, Acc=0.224, PPL=400.55
2025-09-23 01:20:55,976 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.5700, Acc=0.275, PPL=262.43
2025-09-23 01:21:03,930 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.8727, Acc=0.259, PPL=355.22
2025-09-23 01:21:11,797 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.5980, Acc=0.240, PPL=269.89
2025-09-23 01:21:19,990 - training.trainer - INFO - Epoch 39, Step 134436: Loss=5.9460, Acc=0.143, PPL=382.21
2025-09-23 01:21:27,788 - training.trainer - INFO - Epoch 39, Step 134536: Loss=6.2099, Acc=0.207, PPL=497.63
2025-09-23 01:21:35,679 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.8224, Acc=0.224, PPL=337.78
2025-09-23 01:21:43,605 - training.trainer - INFO - Epoch 39, Step 134736: Loss=5.8716, Acc=0.192, PPL=354.82
2025-09-23 01:21:51,609 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.9225, Acc=0.273, PPL=373.36
2025-09-23 01:21:59,581 - training.trainer - INFO - Epoch 39, Step 134936: Loss=6.0912, Acc=0.266, PPL=441.96
2025-09-23 01:22:07,638 - training.trainer - INFO - Epoch 39, Step 135036: Loss=5.6095, Acc=0.259, PPL=273.00
2025-09-23 01:22:15,479 - training.trainer - INFO - Epoch 39, Step 135136: Loss=5.9968, Acc=0.243, PPL=402.15
2025-09-23 01:22:23,296 - training.trainer - INFO - Epoch 39, Step 135236: Loss=6.1935, Acc=0.200, PPL=489.57
2025-09-23 01:22:43,304 - training.trainer - INFO - Epoch 40/100 completed in 282.67s - Train Loss: 5.6163, Train Acc: 0.260, Val Loss: 5.7041, Val Acc: 0.251
2025-09-23 01:22:43,758 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-23 01:22:44,594 - training.trainer - INFO - New best model saved with validation loss: 5.7041
2025-09-23 01:22:44,594 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-23 01:22:51,732 - training.trainer - INFO - Epoch 40, Step 135419: Loss=5.3065, Acc=0.421, PPL=201.64
2025-09-23 01:22:58,562 - training.trainer - INFO - Epoch 40, Step 135519: Loss=5.4008, Acc=0.257, PPL=221.59
2025-09-23 01:23:06,242 - training.trainer - INFO - Epoch 40, Step 135619: Loss=5.4439, Acc=0.179, PPL=231.35
2025-09-23 01:23:14,366 - training.trainer - INFO - Epoch 40, Step 135719: Loss=4.1784, Acc=0.474, PPL=65.26
2025-09-23 01:23:22,287 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.9451, Acc=0.261, PPL=381.87
2025-09-23 01:23:30,344 - training.trainer - INFO - Epoch 40, Step 135919: Loss=5.9322, Acc=0.209, PPL=376.97
2025-09-23 01:23:38,334 - training.trainer - INFO - Epoch 40, Step 136019: Loss=5.2236, Acc=0.500, PPL=185.61
2025-09-23 01:23:46,283 - training.trainer - INFO - Epoch 40, Step 136119: Loss=4.8226, Acc=0.350, PPL=124.29
2025-09-23 01:23:54,180 - training.trainer - INFO - Epoch 40, Step 136219: Loss=6.1268, Acc=0.194, PPL=457.98
2025-09-23 01:24:02,100 - training.trainer - INFO - Epoch 40, Step 136319: Loss=5.3867, Acc=0.233, PPL=218.49
2025-09-23 01:24:09,893 - training.trainer - INFO - Epoch 40, Step 136419: Loss=5.8344, Acc=0.216, PPL=341.85
2025-09-23 01:24:17,807 - training.trainer - INFO - Epoch 40, Step 136519: Loss=4.8512, Acc=0.333, PPL=127.89
2025-09-23 01:24:25,675 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.8815, Acc=0.256, PPL=358.36
2025-09-23 01:24:33,479 - training.trainer - INFO - Epoch 40, Step 136719: Loss=6.4083, Acc=0.133, PPL=606.83
2025-09-23 01:24:41,556 - training.trainer - INFO - Epoch 40, Step 136819: Loss=5.8302, Acc=0.270, PPL=340.41
2025-09-23 01:24:49,426 - training.trainer - INFO - Epoch 40, Step 136919: Loss=6.3791, Acc=0.130, PPL=589.40
2025-09-23 01:24:57,326 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.9436, Acc=0.333, PPL=381.31
2025-09-23 01:25:05,149 - training.trainer - INFO - Epoch 40, Step 137119: Loss=6.4480, Acc=0.174, PPL=631.43
2025-09-23 01:25:12,971 - training.trainer - INFO - Epoch 40, Step 137219: Loss=6.1305, Acc=0.261, PPL=459.66
2025-09-23 01:25:20,809 - training.trainer - INFO - Epoch 40, Step 137319: Loss=6.1457, Acc=0.188, PPL=466.72
2025-09-23 01:25:28,639 - training.trainer - INFO - Epoch 40, Step 137419: Loss=5.7070, Acc=0.214, PPL=300.97
2025-09-23 01:25:36,493 - training.trainer - INFO - Epoch 40, Step 137519: Loss=5.1913, Acc=0.318, PPL=179.71
2025-09-23 01:25:44,289 - training.trainer - INFO - Epoch 40, Step 137619: Loss=5.0288, Acc=0.438, PPL=152.75
2025-09-23 01:25:52,162 - training.trainer - INFO - Epoch 40, Step 137719: Loss=5.9864, Acc=0.270, PPL=397.99
2025-09-23 01:26:00,034 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.5490, Acc=0.288, PPL=256.98
2025-09-23 01:26:07,914 - training.trainer - INFO - Epoch 40, Step 137919: Loss=6.1102, Acc=0.205, PPL=450.42
2025-09-23 01:26:15,792 - training.trainer - INFO - Epoch 40, Step 138019: Loss=4.9284, Acc=0.261, PPL=138.16
2025-09-23 01:26:23,691 - training.trainer - INFO - Epoch 40, Step 138119: Loss=6.0077, Acc=0.250, PPL=406.55
2025-09-23 01:26:31,618 - training.trainer - INFO - Epoch 40, Step 138219: Loss=6.1774, Acc=0.235, PPL=481.72
2025-09-23 01:26:39,529 - training.trainer - INFO - Epoch 40, Step 138319: Loss=5.0140, Acc=0.312, PPL=150.50
2025-09-23 01:26:47,385 - training.trainer - INFO - Epoch 40, Step 138419: Loss=5.2847, Acc=0.469, PPL=197.30
2025-09-23 01:26:55,201 - training.trainer - INFO - Epoch 40, Step 138519: Loss=6.4405, Acc=0.183, PPL=626.70
2025-09-23 01:27:03,142 - training.trainer - INFO - Epoch 40, Step 138619: Loss=5.5399, Acc=0.259, PPL=254.65
2025-09-23 01:27:22,556 - training.trainer - INFO - Epoch 41/100 completed in 277.96s - Train Loss: 5.6025, Train Acc: 0.262, Val Loss: 5.7059, Val Acc: 0.251
2025-09-23 01:27:30,935 - training.trainer - INFO - Epoch 41, Step 138802: Loss=6.4028, Acc=0.152, PPL=603.53
2025-09-23 01:27:39,055 - training.trainer - INFO - Epoch 41, Step 138902: Loss=5.3648, Acc=0.291, PPL=213.74
2025-09-23 01:27:46,834 - training.trainer - INFO - Epoch 41, Step 139002: Loss=6.0724, Acc=0.143, PPL=433.74
2025-09-23 01:27:54,581 - training.trainer - INFO - Epoch 41, Step 139102: Loss=4.8946, Acc=0.356, PPL=133.56
2025-09-23 01:28:02,374 - training.trainer - INFO - Epoch 41, Step 139202: Loss=5.8838, Acc=0.162, PPL=359.17
2025-09-23 01:28:10,181 - training.trainer - INFO - Epoch 41, Step 139302: Loss=5.3579, Acc=0.152, PPL=212.27
2025-09-23 01:28:17,976 - training.trainer - INFO - Epoch 41, Step 139402: Loss=5.3661, Acc=0.220, PPL=214.03
2025-09-23 01:28:25,835 - training.trainer - INFO - Epoch 41, Step 139502: Loss=5.7303, Acc=0.209, PPL=308.06
2025-09-23 01:28:33,772 - training.trainer - INFO - Epoch 41, Step 139602: Loss=6.4993, Acc=0.127, PPL=664.65
2025-09-23 01:28:41,680 - training.trainer - INFO - Epoch 41, Step 139702: Loss=5.6166, Acc=0.228, PPL=274.94
2025-09-23 01:28:49,513 - training.trainer - INFO - Epoch 41, Step 139802: Loss=6.7630, Acc=0.154, PPL=865.28
2025-09-23 01:28:57,335 - training.trainer - INFO - Epoch 41, Step 139902: Loss=5.0082, Acc=0.278, PPL=149.63
2025-09-23 01:29:05,129 - training.trainer - INFO - Epoch 41, Step 140002: Loss=5.9427, Acc=0.217, PPL=380.98
2025-09-23 01:29:13,146 - training.trainer - INFO - Epoch 41, Step 140102: Loss=5.2295, Acc=0.269, PPL=186.70
2025-09-23 01:29:21,250 - training.trainer - INFO - Epoch 41, Step 140202: Loss=5.5770, Acc=0.324, PPL=264.27
2025-09-23 01:29:29,287 - training.trainer - INFO - Epoch 41, Step 140302: Loss=5.0268, Acc=0.500, PPL=152.45
2025-09-23 01:29:37,138 - training.trainer - INFO - Epoch 41, Step 140402: Loss=6.0559, Acc=0.220, PPL=426.63
2025-09-23 01:29:44,973 - training.trainer - INFO - Epoch 41, Step 140502: Loss=5.8740, Acc=0.171, PPL=355.68
2025-09-23 01:29:52,871 - training.trainer - INFO - Epoch 41, Step 140602: Loss=5.8848, Acc=0.219, PPL=359.53
2025-09-23 01:30:00,702 - training.trainer - INFO - Epoch 41, Step 140702: Loss=6.2923, Acc=0.255, PPL=540.38
2025-09-23 01:30:08,530 - training.trainer - INFO - Epoch 41, Step 140802: Loss=5.1629, Acc=0.286, PPL=174.67
2025-09-23 01:30:16,447 - training.trainer - INFO - Epoch 41, Step 140902: Loss=6.0284, Acc=0.255, PPL=415.07
2025-09-23 01:30:24,390 - training.trainer - INFO - Epoch 41, Step 141002: Loss=6.0596, Acc=0.258, PPL=428.20
2025-09-23 01:30:32,247 - training.trainer - INFO - Epoch 41, Step 141102: Loss=5.8073, Acc=0.184, PPL=332.71
2025-09-23 01:30:40,085 - training.trainer - INFO - Epoch 41, Step 141202: Loss=5.5738, Acc=0.294, PPL=263.45
2025-09-23 01:30:48,117 - training.trainer - INFO - Epoch 41, Step 141302: Loss=5.5381, Acc=0.306, PPL=254.18
2025-09-23 01:30:56,038 - training.trainer - INFO - Epoch 41, Step 141402: Loss=5.9902, Acc=0.263, PPL=399.51
2025-09-23 01:31:03,875 - training.trainer - INFO - Epoch 41, Step 141502: Loss=5.5872, Acc=0.258, PPL=266.99
2025-09-23 01:31:11,810 - training.trainer - INFO - Epoch 41, Step 141602: Loss=6.2002, Acc=0.211, PPL=492.82
2025-09-23 01:31:19,720 - training.trainer - INFO - Epoch 41, Step 141702: Loss=5.8810, Acc=0.196, PPL=358.18
2025-09-23 01:31:27,707 - training.trainer - INFO - Epoch 41, Step 141802: Loss=5.9244, Acc=0.191, PPL=374.05
2025-09-23 01:31:35,543 - training.trainer - INFO - Epoch 41, Step 141902: Loss=5.6480, Acc=0.207, PPL=283.73
2025-09-23 01:31:43,420 - training.trainer - INFO - Epoch 41, Step 142002: Loss=5.9973, Acc=0.169, PPL=402.34
2025-09-23 01:32:03,483 - training.trainer - INFO - Epoch 42/100 completed in 280.93s - Train Loss: 5.5987, Train Acc: 0.262, Val Loss: 5.6874, Val Acc: 0.249
2025-09-23 01:32:04,421 - training.trainer - INFO - New best model saved with validation loss: 5.6874
2025-09-23 01:32:04,422 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_42.pt
2025-09-23 01:32:12,766 - training.trainer - INFO - Epoch 42, Step 142185: Loss=5.9107, Acc=0.231, PPL=368.95
2025-09-23 01:32:20,725 - training.trainer - INFO - Epoch 42, Step 142285: Loss=5.9446, Acc=0.278, PPL=381.69
2025-09-23 01:32:28,751 - training.trainer - INFO - Epoch 42, Step 142385: Loss=5.2228, Acc=0.269, PPL=185.45
2025-09-23 01:32:36,685 - training.trainer - INFO - Epoch 42, Step 142485: Loss=5.7786, Acc=0.250, PPL=323.32
2025-09-23 01:32:44,592 - training.trainer - INFO - Epoch 42, Step 142585: Loss=5.4241, Acc=0.179, PPL=226.82
2025-09-23 01:32:52,479 - training.trainer - INFO - Epoch 42, Step 142685: Loss=6.4017, Acc=0.238, PPL=602.87
2025-09-23 01:33:00,469 - training.trainer - INFO - Epoch 42, Step 142785: Loss=6.0301, Acc=0.200, PPL=415.74
2025-09-23 01:33:08,637 - training.trainer - INFO - Epoch 42, Step 142885: Loss=5.5383, Acc=0.310, PPL=254.23
2025-09-23 01:33:16,519 - training.trainer - INFO - Epoch 42, Step 142985: Loss=6.3847, Acc=0.163, PPL=592.70
2025-09-23 01:33:24,423 - training.trainer - INFO - Epoch 42, Step 143085: Loss=5.7407, Acc=0.174, PPL=311.29
2025-09-23 01:33:32,469 - training.trainer - INFO - Epoch 42, Step 143185: Loss=5.1680, Acc=0.409, PPL=175.56
2025-09-23 01:33:40,401 - training.trainer - INFO - Epoch 42, Step 143285: Loss=6.4169, Acc=0.150, PPL=612.10
2025-09-23 01:33:48,158 - training.trainer - INFO - Epoch 42, Step 143385: Loss=4.7669, Acc=0.222, PPL=117.55
2025-09-23 01:33:55,926 - training.trainer - INFO - Epoch 42, Step 143485: Loss=6.7397, Acc=0.167, PPL=845.34
2025-09-23 01:34:03,677 - training.trainer - INFO - Epoch 42, Step 143585: Loss=6.0833, Acc=0.212, PPL=438.46
2025-09-23 01:34:11,540 - training.trainer - INFO - Epoch 42, Step 143685: Loss=6.1805, Acc=0.160, PPL=483.23
2025-09-23 01:34:19,297 - training.trainer - INFO - Epoch 42, Step 143785: Loss=6.8154, Acc=0.135, PPL=911.82
2025-09-23 01:34:27,068 - training.trainer - INFO - Epoch 42, Step 143885: Loss=5.5201, Acc=0.320, PPL=249.66
2025-09-23 01:34:34,868 - training.trainer - INFO - Epoch 42, Step 143985: Loss=5.4452, Acc=0.217, PPL=231.64
2025-09-23 01:34:42,691 - training.trainer - INFO - Epoch 42, Step 144085: Loss=5.8878, Acc=0.192, PPL=360.62
2025-09-23 01:34:50,559 - training.trainer - INFO - Epoch 42, Step 144185: Loss=5.7610, Acc=0.250, PPL=317.68
2025-09-23 01:34:58,364 - training.trainer - INFO - Epoch 42, Step 144285: Loss=5.9402, Acc=0.222, PPL=379.99
2025-09-23 01:35:06,496 - training.trainer - INFO - Epoch 42, Step 144385: Loss=6.0399, Acc=0.238, PPL=419.83
2025-09-23 01:35:14,515 - training.trainer - INFO - Epoch 42, Step 144485: Loss=5.5294, Acc=0.286, PPL=251.98
2025-09-23 01:35:22,378 - training.trainer - INFO - Epoch 42, Step 144585: Loss=5.2105, Acc=0.421, PPL=183.19
2025-09-23 01:35:30,293 - training.trainer - INFO - Epoch 42, Step 144685: Loss=6.2618, Acc=0.222, PPL=524.15
2025-09-23 01:35:38,122 - training.trainer - INFO - Epoch 42, Step 144785: Loss=5.3991, Acc=0.308, PPL=221.20
2025-09-23 01:35:46,021 - training.trainer - INFO - Epoch 42, Step 144885: Loss=6.4202, Acc=0.222, PPL=614.12
2025-09-23 01:35:53,922 - training.trainer - INFO - Epoch 42, Step 144985: Loss=4.6646, Acc=0.400, PPL=106.12
2025-09-23 01:36:01,684 - training.trainer - INFO - Epoch 42, Step 145085: Loss=5.2419, Acc=0.325, PPL=189.03
2025-09-23 01:36:09,535 - training.trainer - INFO - Epoch 42, Step 145185: Loss=6.4832, Acc=0.146, PPL=654.04
2025-09-23 01:36:17,496 - training.trainer - INFO - Epoch 42, Step 145285: Loss=5.4558, Acc=0.233, PPL=234.11
2025-09-23 01:36:25,416 - training.trainer - INFO - Epoch 42, Step 145385: Loss=6.1420, Acc=0.150, PPL=465.00
2025-09-23 01:36:44,556 - training.trainer - INFO - Epoch 43/100 completed in 280.13s - Train Loss: 5.5917, Train Acc: 0.264, Val Loss: 5.6916, Val Acc: 0.252
2025-09-23 01:36:52,160 - training.trainer - INFO - Epoch 43, Step 145568: Loss=6.5508, Acc=0.200, PPL=699.83
2025-09-23 01:36:59,582 - training.trainer - INFO - Epoch 43, Step 145668: Loss=6.1439, Acc=0.191, PPL=465.87
2025-09-23 01:37:07,182 - training.trainer - INFO - Epoch 43, Step 145768: Loss=5.5280, Acc=0.321, PPL=251.64
2025-09-23 01:37:15,197 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.5216, Acc=0.213, PPL=250.05
2025-09-23 01:37:23,489 - training.trainer - INFO - Epoch 43, Step 145968: Loss=5.7555, Acc=0.270, PPL=315.93
2025-09-23 01:37:31,531 - training.trainer - INFO - Epoch 43, Step 146068: Loss=5.1588, Acc=0.345, PPL=173.95
2025-09-23 01:37:39,510 - training.trainer - INFO - Epoch 43, Step 146168: Loss=5.7156, Acc=0.342, PPL=303.58
2025-09-23 01:37:47,448 - training.trainer - INFO - Epoch 43, Step 146268: Loss=5.0645, Acc=0.206, PPL=158.31
2025-09-23 01:37:55,462 - training.trainer - INFO - Epoch 43, Step 146368: Loss=4.7112, Acc=0.375, PPL=111.19
2025-09-23 01:38:03,505 - training.trainer - INFO - Epoch 43, Step 146468: Loss=5.5935, Acc=0.256, PPL=268.67
2025-09-23 01:38:11,432 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.7798, Acc=0.204, PPL=323.69
2025-09-23 01:38:19,319 - training.trainer - INFO - Epoch 43, Step 146668: Loss=6.3143, Acc=0.214, PPL=552.41
2025-09-23 01:38:27,326 - training.trainer - INFO - Epoch 43, Step 146768: Loss=5.3682, Acc=0.333, PPL=214.48
2025-09-23 01:38:35,503 - training.trainer - INFO - Epoch 43, Step 146868: Loss=6.1001, Acc=0.095, PPL=445.90
2025-09-23 01:38:43,520 - training.trainer - INFO - Epoch 43, Step 146968: Loss=5.3955, Acc=0.238, PPL=220.42
2025-09-23 01:38:51,452 - training.trainer - INFO - Epoch 43, Step 147068: Loss=4.6651, Acc=0.444, PPL=106.17
2025-09-23 01:38:59,350 - training.trainer - INFO - Epoch 43, Step 147168: Loss=5.6960, Acc=0.233, PPL=297.67
2025-09-23 01:39:07,353 - training.trainer - INFO - Epoch 43, Step 147268: Loss=4.7793, Acc=0.476, PPL=119.02
2025-09-23 01:39:15,321 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.0616, Acc=0.340, PPL=157.85
2025-09-23 01:39:23,227 - training.trainer - INFO - Epoch 43, Step 147468: Loss=5.6944, Acc=0.262, PPL=297.20
2025-09-23 01:39:31,133 - training.trainer - INFO - Epoch 43, Step 147568: Loss=5.3344, Acc=0.323, PPL=207.35
2025-09-23 01:39:39,159 - training.trainer - INFO - Epoch 43, Step 147668: Loss=4.9229, Acc=0.478, PPL=137.40
2025-09-23 01:39:47,113 - training.trainer - INFO - Epoch 43, Step 147768: Loss=5.3769, Acc=0.333, PPL=216.35
2025-09-23 01:39:53,907 - training.trainer - INFO - Epoch 43, Step 147868: Loss=5.7495, Acc=0.250, PPL=314.02
2025-09-23 01:40:00,687 - training.trainer - INFO - Epoch 43, Step 147968: Loss=5.2796, Acc=0.320, PPL=196.29
2025-09-23 01:40:07,497 - training.trainer - INFO - Epoch 43, Step 148068: Loss=6.2592, Acc=0.231, PPL=522.80
2025-09-23 01:40:14,325 - training.trainer - INFO - Epoch 43, Step 148168: Loss=5.1846, Acc=0.214, PPL=178.50
2025-09-23 01:40:21,013 - training.trainer - INFO - Epoch 43, Step 148268: Loss=4.7993, Acc=0.350, PPL=121.42
2025-09-23 01:40:27,831 - training.trainer - INFO - Epoch 43, Step 148368: Loss=4.3549, Acc=0.375, PPL=77.86
2025-09-23 01:40:34,561 - training.trainer - INFO - Epoch 43, Step 148468: Loss=6.3008, Acc=0.190, PPL=545.02
2025-09-23 01:40:41,519 - training.trainer - INFO - Epoch 43, Step 148568: Loss=5.1758, Acc=0.256, PPL=176.94
2025-09-23 01:40:48,905 - training.trainer - INFO - Epoch 43, Step 148668: Loss=5.8631, Acc=0.250, PPL=351.81
2025-09-23 01:40:56,825 - training.trainer - INFO - Epoch 43, Step 148768: Loss=6.4432, Acc=0.302, PPL=628.44
2025-09-23 01:41:16,483 - training.trainer - INFO - Epoch 44/100 completed in 271.93s - Train Loss: 5.5843, Train Acc: 0.264, Val Loss: 5.6884, Val Acc: 0.249
2025-09-23 01:41:24,417 - training.trainer - INFO - Epoch 44, Step 148951: Loss=5.7126, Acc=0.286, PPL=302.66
2025-09-23 01:41:32,427 - training.trainer - INFO - Epoch 44, Step 149051: Loss=5.0714, Acc=0.174, PPL=159.40
2025-09-23 01:41:40,414 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.6079, Acc=0.233, PPL=272.57
2025-09-23 01:41:48,515 - training.trainer - INFO - Epoch 44, Step 149251: Loss=5.9997, Acc=0.200, PPL=403.30
2025-09-23 01:41:56,424 - training.trainer - INFO - Epoch 44, Step 149351: Loss=6.1272, Acc=0.136, PPL=458.15
2025-09-23 01:42:04,622 - training.trainer - INFO - Epoch 44, Step 149451: Loss=5.4600, Acc=0.297, PPL=235.09
2025-09-23 01:42:12,620 - training.trainer - INFO - Epoch 44, Step 149551: Loss=6.2370, Acc=0.280, PPL=511.33
2025-09-23 01:42:20,853 - training.trainer - INFO - Epoch 44, Step 149651: Loss=4.8681, Acc=0.273, PPL=130.08
2025-09-23 01:42:28,921 - training.trainer - INFO - Epoch 44, Step 149751: Loss=6.3527, Acc=0.176, PPL=574.05
2025-09-23 01:42:36,959 - training.trainer - INFO - Epoch 44, Step 149851: Loss=5.7722, Acc=0.175, PPL=321.25
2025-09-23 01:42:45,015 - training.trainer - INFO - Epoch 44, Step 149951: Loss=4.8977, Acc=0.280, PPL=133.99
2025-09-23 01:42:53,171 - training.trainer - INFO - Epoch 44, Step 150051: Loss=5.9667, Acc=0.200, PPL=390.21
2025-09-23 01:43:01,195 - training.trainer - INFO - Epoch 44, Step 150151: Loss=4.8001, Acc=0.400, PPL=121.53
2025-09-23 01:43:09,235 - training.trainer - INFO - Epoch 44, Step 150251: Loss=4.6321, Acc=0.440, PPL=102.73
2025-09-23 01:43:17,150 - training.trainer - INFO - Epoch 44, Step 150351: Loss=5.5482, Acc=0.309, PPL=256.79
2025-09-23 01:43:25,151 - training.trainer - INFO - Epoch 44, Step 150451: Loss=5.8023, Acc=0.203, PPL=331.04
2025-09-23 01:43:33,066 - training.trainer - INFO - Epoch 44, Step 150551: Loss=5.6651, Acc=0.239, PPL=288.63
2025-09-23 01:43:40,972 - training.trainer - INFO - Epoch 44, Step 150651: Loss=6.5695, Acc=0.154, PPL=713.02
2025-09-23 01:43:48,955 - training.trainer - INFO - Epoch 44, Step 150751: Loss=5.5548, Acc=0.294, PPL=258.49
2025-09-23 01:43:57,010 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.3735, Acc=0.214, PPL=215.62
2025-09-23 01:44:05,158 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.5857, Acc=0.250, PPL=266.60
2025-09-23 01:44:13,083 - training.trainer - INFO - Epoch 44, Step 151051: Loss=5.8680, Acc=0.200, PPL=353.52
2025-09-23 01:44:20,937 - training.trainer - INFO - Epoch 44, Step 151151: Loss=5.3725, Acc=0.340, PPL=215.41
2025-09-23 01:44:28,885 - training.trainer - INFO - Epoch 44, Step 151251: Loss=5.2617, Acc=0.310, PPL=192.80
2025-09-23 01:44:36,857 - training.trainer - INFO - Epoch 44, Step 151351: Loss=6.5947, Acc=0.164, PPL=731.23
2025-09-23 01:44:44,837 - training.trainer - INFO - Epoch 44, Step 151451: Loss=4.9110, Acc=0.316, PPL=135.78
2025-09-23 01:44:52,711 - training.trainer - INFO - Epoch 44, Step 151551: Loss=4.9898, Acc=0.400, PPL=146.90
2025-09-23 01:45:00,683 - training.trainer - INFO - Epoch 44, Step 151651: Loss=5.6118, Acc=0.350, PPL=273.63
2025-09-23 01:45:08,620 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.7760, Acc=0.250, PPL=322.47
2025-09-23 01:45:16,481 - training.trainer - INFO - Epoch 44, Step 151851: Loss=5.6052, Acc=0.237, PPL=271.84
2025-09-23 01:45:24,332 - training.trainer - INFO - Epoch 44, Step 151951: Loss=6.0120, Acc=0.170, PPL=408.31
2025-09-23 01:45:32,327 - training.trainer - INFO - Epoch 44, Step 152051: Loss=4.9133, Acc=0.375, PPL=136.09
2025-09-23 01:45:40,323 - training.trainer - INFO - Epoch 44, Step 152151: Loss=6.3485, Acc=0.162, PPL=571.64
2025-09-23 01:46:00,091 - training.trainer - INFO - Epoch 45/100 completed in 283.61s - Train Loss: 5.5754, Train Acc: 0.266, Val Loss: 5.6832, Val Acc: 0.251
2025-09-23 01:46:00,421 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-23 01:46:01,033 - training.trainer - INFO - New best model saved with validation loss: 5.6832
2025-09-23 01:46:01,033 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-23 01:46:08,147 - training.trainer - INFO - Epoch 45, Step 152334: Loss=5.6048, Acc=0.192, PPL=271.72
2025-09-23 01:46:15,141 - training.trainer - INFO - Epoch 45, Step 152434: Loss=5.5526, Acc=0.250, PPL=257.90
2025-09-23 01:46:22,549 - training.trainer - INFO - Epoch 45, Step 152534: Loss=6.9889, Acc=0.125, PPL=1084.51
2025-09-23 01:46:30,667 - training.trainer - INFO - Epoch 45, Step 152634: Loss=5.7072, Acc=0.261, PPL=301.04
2025-09-23 01:46:38,644 - training.trainer - INFO - Epoch 45, Step 152734: Loss=5.1154, Acc=0.227, PPL=166.57
2025-09-23 01:46:46,643 - training.trainer - INFO - Epoch 45, Step 152834: Loss=5.5795, Acc=0.156, PPL=264.93
2025-09-23 01:46:54,728 - training.trainer - INFO - Epoch 45, Step 152934: Loss=5.0509, Acc=0.421, PPL=156.17
2025-09-23 01:47:02,582 - training.trainer - INFO - Epoch 45, Step 153034: Loss=5.2963, Acc=0.280, PPL=199.60
2025-09-23 01:47:10,648 - training.trainer - INFO - Epoch 45, Step 153134: Loss=5.3774, Acc=0.286, PPL=216.47
2025-09-23 01:47:18,916 - training.trainer - INFO - Epoch 45, Step 153234: Loss=3.6511, Acc=0.545, PPL=38.52
2025-09-23 01:47:26,770 - training.trainer - INFO - Epoch 45, Step 153334: Loss=4.9864, Acc=0.296, PPL=146.41
2025-09-23 01:47:34,609 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.2786, Acc=0.298, PPL=196.10
2025-09-23 01:47:42,505 - training.trainer - INFO - Epoch 45, Step 153534: Loss=5.5136, Acc=0.245, PPL=248.05
2025-09-23 01:47:50,483 - training.trainer - INFO - Epoch 45, Step 153634: Loss=4.4518, Acc=0.370, PPL=85.78
2025-09-23 01:47:58,387 - training.trainer - INFO - Epoch 45, Step 153734: Loss=6.4390, Acc=0.158, PPL=625.81
2025-09-23 01:48:06,372 - training.trainer - INFO - Epoch 45, Step 153834: Loss=4.8025, Acc=0.300, PPL=121.81
2025-09-23 01:48:14,249 - training.trainer - INFO - Epoch 45, Step 153934: Loss=5.2884, Acc=0.241, PPL=198.02
2025-09-23 01:48:22,209 - training.trainer - INFO - Epoch 45, Step 154034: Loss=6.3071, Acc=0.182, PPL=548.45
2025-09-23 01:48:30,089 - training.trainer - INFO - Epoch 45, Step 154134: Loss=6.2095, Acc=0.200, PPL=497.43
2025-09-23 01:48:37,992 - training.trainer - INFO - Epoch 45, Step 154234: Loss=5.9351, Acc=0.234, PPL=378.07
2025-09-23 01:48:45,867 - training.trainer - INFO - Epoch 45, Step 154334: Loss=6.4788, Acc=0.188, PPL=651.21
2025-09-23 01:48:53,943 - training.trainer - INFO - Epoch 45, Step 154434: Loss=5.2791, Acc=0.257, PPL=196.20
2025-09-23 01:49:01,757 - training.trainer - INFO - Epoch 45, Step 154534: Loss=6.1260, Acc=0.227, PPL=457.60
2025-09-23 01:49:09,569 - training.trainer - INFO - Epoch 45, Step 154634: Loss=4.9323, Acc=0.304, PPL=138.70
2025-09-23 01:49:17,353 - training.trainer - INFO - Epoch 45, Step 154734: Loss=5.4483, Acc=0.292, PPL=232.36
2025-09-23 01:49:25,247 - training.trainer - INFO - Epoch 45, Step 154834: Loss=6.7670, Acc=0.177, PPL=868.70
2025-09-23 01:49:33,227 - training.trainer - INFO - Epoch 45, Step 154934: Loss=6.8560, Acc=0.200, PPL=949.54
2025-09-23 01:49:41,097 - training.trainer - INFO - Epoch 45, Step 155034: Loss=5.9380, Acc=0.220, PPL=379.16
2025-09-23 01:49:49,114 - training.trainer - INFO - Epoch 45, Step 155134: Loss=5.7644, Acc=0.211, PPL=318.74
2025-09-23 01:49:57,208 - training.trainer - INFO - Epoch 45, Step 155234: Loss=6.5767, Acc=0.167, PPL=718.15
2025-09-23 01:50:05,251 - training.trainer - INFO - Epoch 45, Step 155334: Loss=6.0195, Acc=0.174, PPL=411.39
2025-09-23 01:50:13,137 - training.trainer - INFO - Epoch 45, Step 155434: Loss=6.5345, Acc=0.185, PPL=688.48
2025-09-23 01:50:21,003 - training.trainer - INFO - Epoch 45, Step 155534: Loss=5.4995, Acc=0.333, PPL=244.57
2025-09-23 01:50:40,841 - training.trainer - INFO - Epoch 46/100 completed in 279.81s - Train Loss: 5.5642, Train Acc: 0.268, Val Loss: 5.6899, Val Acc: 0.248
2025-09-23 01:50:49,055 - training.trainer - INFO - Epoch 46, Step 155717: Loss=6.2652, Acc=0.167, PPL=525.94
2025-09-23 01:50:56,936 - training.trainer - INFO - Epoch 46, Step 155817: Loss=5.1400, Acc=0.316, PPL=170.72
2025-09-23 01:51:05,105 - training.trainer - INFO - Epoch 46, Step 155917: Loss=5.5906, Acc=0.267, PPL=267.90
2025-09-23 01:51:13,088 - training.trainer - INFO - Epoch 46, Step 156017: Loss=6.7256, Acc=0.188, PPL=833.45
2025-09-23 01:51:21,034 - training.trainer - INFO - Epoch 46, Step 156117: Loss=5.0752, Acc=0.357, PPL=160.00
2025-09-23 01:51:28,981 - training.trainer - INFO - Epoch 46, Step 156217: Loss=5.9634, Acc=0.280, PPL=388.95
2025-09-23 01:51:37,039 - training.trainer - INFO - Epoch 46, Step 156317: Loss=5.4520, Acc=0.208, PPL=233.22
2025-09-23 01:51:44,958 - training.trainer - INFO - Epoch 46, Step 156417: Loss=6.0911, Acc=0.125, PPL=441.92
2025-09-23 01:51:52,845 - training.trainer - INFO - Epoch 46, Step 156517: Loss=5.4837, Acc=0.250, PPL=240.74
2025-09-23 01:52:00,801 - training.trainer - INFO - Epoch 46, Step 156617: Loss=5.6830, Acc=0.263, PPL=293.84
2025-09-23 01:52:08,869 - training.trainer - INFO - Epoch 46, Step 156717: Loss=4.0190, Acc=0.353, PPL=55.65
2025-09-23 01:52:16,889 - training.trainer - INFO - Epoch 46, Step 156817: Loss=6.5114, Acc=0.176, PPL=672.77
2025-09-23 01:52:24,852 - training.trainer - INFO - Epoch 46, Step 156917: Loss=5.6536, Acc=0.204, PPL=285.33
2025-09-23 01:52:32,776 - training.trainer - INFO - Epoch 46, Step 157017: Loss=5.6399, Acc=0.208, PPL=281.43
2025-09-23 01:52:40,786 - training.trainer - INFO - Epoch 46, Step 157117: Loss=4.7818, Acc=0.280, PPL=119.32
2025-09-23 01:52:48,838 - training.trainer - INFO - Epoch 46, Step 157217: Loss=6.0010, Acc=0.129, PPL=403.84
2025-09-23 01:52:56,754 - training.trainer - INFO - Epoch 46, Step 157317: Loss=5.1151, Acc=0.220, PPL=166.52
2025-09-23 01:53:04,608 - training.trainer - INFO - Epoch 46, Step 157417: Loss=5.8334, Acc=0.304, PPL=341.52
2025-09-23 01:53:12,543 - training.trainer - INFO - Epoch 46, Step 157517: Loss=5.5102, Acc=0.357, PPL=247.19
2025-09-23 01:53:20,635 - training.trainer - INFO - Epoch 46, Step 157617: Loss=5.4258, Acc=0.211, PPL=227.19
2025-09-23 01:53:28,471 - training.trainer - INFO - Epoch 46, Step 157717: Loss=4.5633, Acc=0.278, PPL=95.90
2025-09-23 01:53:36,311 - training.trainer - INFO - Epoch 46, Step 157817: Loss=4.9639, Acc=0.269, PPL=143.15
2025-09-23 01:53:44,244 - training.trainer - INFO - Epoch 46, Step 157917: Loss=5.6783, Acc=0.333, PPL=292.46
2025-09-23 01:53:52,082 - training.trainer - INFO - Epoch 46, Step 158017: Loss=5.4437, Acc=0.214, PPL=231.29
2025-09-23 01:53:59,864 - training.trainer - INFO - Epoch 46, Step 158117: Loss=6.0098, Acc=0.226, PPL=407.40
2025-09-23 01:54:07,713 - training.trainer - INFO - Epoch 46, Step 158217: Loss=5.5226, Acc=0.341, PPL=250.28
2025-09-23 01:54:15,539 - training.trainer - INFO - Epoch 46, Step 158317: Loss=5.8522, Acc=0.200, PPL=348.00
2025-09-23 01:54:23,453 - training.trainer - INFO - Epoch 46, Step 158417: Loss=5.8987, Acc=0.250, PPL=364.56
2025-09-23 01:54:31,325 - training.trainer - INFO - Epoch 46, Step 158517: Loss=5.8124, Acc=0.200, PPL=334.43
2025-09-23 01:54:39,150 - training.trainer - INFO - Epoch 46, Step 158617: Loss=5.2100, Acc=0.235, PPL=183.10
2025-09-23 01:54:47,022 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.4605, Acc=0.295, PPL=235.21
2025-09-23 01:54:55,253 - training.trainer - INFO - Epoch 46, Step 158817: Loss=5.7666, Acc=0.234, PPL=319.45
2025-09-23 01:55:03,112 - training.trainer - INFO - Epoch 46, Step 158917: Loss=5.8522, Acc=0.292, PPL=348.00
2025-09-23 01:55:22,601 - training.trainer - INFO - Epoch 47/100 completed in 281.76s - Train Loss: 5.5519, Train Acc: 0.269, Val Loss: 5.6892, Val Acc: 0.249
2025-09-23 01:55:29,688 - training.trainer - INFO - Epoch 47, Step 159100: Loss=5.2162, Acc=0.389, PPL=184.24
2025-09-23 01:55:36,320 - training.trainer - INFO - Epoch 47, Step 159200: Loss=5.6684, Acc=0.188, PPL=289.57
2025-09-23 01:55:42,906 - training.trainer - INFO - Epoch 47, Step 159300: Loss=6.1163, Acc=0.227, PPL=453.20
2025-09-23 01:55:49,795 - training.trainer - INFO - Epoch 47, Step 159400: Loss=5.9486, Acc=0.270, PPL=383.23
2025-09-23 01:55:56,594 - training.trainer - INFO - Epoch 47, Step 159500: Loss=6.3885, Acc=0.161, PPL=594.98
2025-09-23 01:56:03,281 - training.trainer - INFO - Epoch 47, Step 159600: Loss=5.7140, Acc=0.265, PPL=303.09
2025-09-23 01:56:09,922 - training.trainer - INFO - Epoch 47, Step 159700: Loss=6.5593, Acc=0.206, PPL=705.74
2025-09-23 01:56:16,477 - training.trainer - INFO - Epoch 47, Step 159800: Loss=5.7131, Acc=0.207, PPL=302.82
2025-09-23 01:56:22,987 - training.trainer - INFO - Epoch 47, Step 159900: Loss=5.3192, Acc=0.283, PPL=204.21
2025-09-23 01:56:29,579 - training.trainer - INFO - Epoch 47, Step 160000: Loss=5.8628, Acc=0.167, PPL=351.70
2025-09-23 01:56:36,261 - training.trainer - INFO - Epoch 47, Step 160100: Loss=5.7935, Acc=0.208, PPL=328.17
2025-09-23 01:56:42,905 - training.trainer - INFO - Epoch 47, Step 160200: Loss=6.0255, Acc=0.244, PPL=413.84
2025-09-23 01:56:49,500 - training.trainer - INFO - Epoch 47, Step 160300: Loss=4.2661, Acc=0.375, PPL=71.24
2025-09-23 01:56:56,127 - training.trainer - INFO - Epoch 47, Step 160400: Loss=4.7415, Acc=0.323, PPL=114.61
2025-09-23 01:57:02,803 - training.trainer - INFO - Epoch 47, Step 160500: Loss=4.5484, Acc=0.211, PPL=94.48
2025-09-23 01:57:09,519 - training.trainer - INFO - Epoch 47, Step 160600: Loss=5.8877, Acc=0.222, PPL=360.56
2025-09-23 01:57:16,144 - training.trainer - INFO - Epoch 47, Step 160700: Loss=6.4127, Acc=0.250, PPL=609.53
2025-09-23 01:57:22,844 - training.trainer - INFO - Epoch 47, Step 160800: Loss=6.0872, Acc=0.241, PPL=440.18
2025-09-23 01:57:30,609 - training.trainer - INFO - Epoch 47, Step 160900: Loss=5.3200, Acc=0.265, PPL=204.39
2025-09-23 01:57:38,776 - training.trainer - INFO - Epoch 47, Step 161000: Loss=5.0367, Acc=0.300, PPL=153.96
2025-09-23 01:57:46,607 - training.trainer - INFO - Epoch 47, Step 161100: Loss=5.6241, Acc=0.277, PPL=277.01
2025-09-23 01:57:54,483 - training.trainer - INFO - Epoch 47, Step 161200: Loss=5.0620, Acc=0.263, PPL=157.91
2025-09-23 01:58:02,327 - training.trainer - INFO - Epoch 47, Step 161300: Loss=6.1728, Acc=0.294, PPL=479.50
2025-09-23 01:58:10,254 - training.trainer - INFO - Epoch 47, Step 161400: Loss=5.6968, Acc=0.231, PPL=297.92
2025-09-23 01:58:18,189 - training.trainer - INFO - Epoch 47, Step 161500: Loss=5.6623, Acc=0.229, PPL=287.80
2025-09-23 01:58:26,021 - training.trainer - INFO - Epoch 47, Step 161600: Loss=4.9085, Acc=0.267, PPL=135.44
2025-09-23 01:58:34,007 - training.trainer - INFO - Epoch 47, Step 161700: Loss=5.6834, Acc=0.286, PPL=293.96
2025-09-23 01:58:41,873 - training.trainer - INFO - Epoch 47, Step 161800: Loss=6.1688, Acc=0.265, PPL=477.64
2025-09-23 01:58:49,918 - training.trainer - INFO - Epoch 47, Step 161900: Loss=5.0188, Acc=0.256, PPL=151.23
2025-09-23 01:58:58,028 - training.trainer - INFO - Epoch 47, Step 162000: Loss=5.9682, Acc=0.239, PPL=390.78
2025-09-23 01:59:05,955 - training.trainer - INFO - Epoch 47, Step 162100: Loss=5.5796, Acc=0.184, PPL=264.96
2025-09-23 01:59:13,982 - training.trainer - INFO - Epoch 47, Step 162200: Loss=4.6284, Acc=0.296, PPL=102.35
2025-09-23 01:59:22,021 - training.trainer - INFO - Epoch 47, Step 162300: Loss=5.7065, Acc=0.237, PPL=300.81
2025-09-23 01:59:41,679 - training.trainer - INFO - Epoch 48/100 completed in 259.08s - Train Loss: 5.5449, Train Acc: 0.270, Val Loss: 5.6849, Val Acc: 0.253
2025-09-23 01:59:49,528 - training.trainer - INFO - Epoch 48, Step 162483: Loss=6.2067, Acc=0.224, PPL=496.07
2025-09-23 01:59:57,458 - training.trainer - INFO - Epoch 48, Step 162583: Loss=5.8987, Acc=0.320, PPL=364.55
2025-09-23 02:00:05,305 - training.trainer - INFO - Epoch 48, Step 162683: Loss=4.9702, Acc=0.375, PPL=144.06
2025-09-23 02:00:13,243 - training.trainer - INFO - Epoch 48, Step 162783: Loss=5.9723, Acc=0.243, PPL=392.42
2025-09-23 02:00:21,227 - training.trainer - INFO - Epoch 48, Step 162883: Loss=5.7579, Acc=0.222, PPL=316.67
2025-09-23 02:00:29,075 - training.trainer - INFO - Epoch 48, Step 162983: Loss=5.6309, Acc=0.190, PPL=278.92
2025-09-23 02:00:37,058 - training.trainer - INFO - Epoch 48, Step 163083: Loss=6.4517, Acc=0.140, PPL=633.75
2025-09-23 02:00:45,037 - training.trainer - INFO - Epoch 48, Step 163183: Loss=5.5878, Acc=0.256, PPL=267.15
2025-09-23 02:00:53,028 - training.trainer - INFO - Epoch 48, Step 163283: Loss=5.6347, Acc=0.200, PPL=279.96
2025-09-23 02:01:01,014 - training.trainer - INFO - Epoch 48, Step 163383: Loss=4.9446, Acc=0.250, PPL=140.41
2025-09-23 02:01:09,024 - training.trainer - INFO - Epoch 48, Step 163483: Loss=4.9644, Acc=0.342, PPL=143.23
2025-09-23 02:01:16,407 - training.trainer - INFO - Epoch 48, Step 163583: Loss=5.3728, Acc=0.280, PPL=215.46
2025-09-23 02:01:23,434 - training.trainer - INFO - Epoch 48, Step 163683: Loss=5.5742, Acc=0.323, PPL=263.53
2025-09-23 02:01:31,301 - training.trainer - INFO - Epoch 48, Step 163783: Loss=5.1658, Acc=0.179, PPL=175.18
2025-09-23 02:01:39,178 - training.trainer - INFO - Epoch 48, Step 163883: Loss=4.7617, Acc=0.323, PPL=116.94
2025-09-23 02:01:47,133 - training.trainer - INFO - Epoch 48, Step 163983: Loss=4.2105, Acc=0.500, PPL=67.39
2025-09-23 02:01:55,133 - training.trainer - INFO - Epoch 48, Step 164083: Loss=5.5596, Acc=0.250, PPL=259.73
2025-09-23 02:02:03,366 - training.trainer - INFO - Epoch 48, Step 164183: Loss=5.0939, Acc=0.391, PPL=163.02
2025-09-23 02:02:11,564 - training.trainer - INFO - Epoch 48, Step 164283: Loss=5.4859, Acc=0.310, PPL=241.27
2025-09-23 02:02:19,522 - training.trainer - INFO - Epoch 48, Step 164383: Loss=3.3597, Acc=0.619, PPL=28.78
2025-09-23 02:02:27,380 - training.trainer - INFO - Epoch 48, Step 164483: Loss=5.7672, Acc=0.257, PPL=319.64
2025-09-23 02:02:35,349 - training.trainer - INFO - Epoch 48, Step 164583: Loss=6.3911, Acc=0.150, PPL=596.51
2025-09-23 02:02:43,162 - training.trainer - INFO - Epoch 48, Step 164683: Loss=4.9227, Acc=0.318, PPL=137.38
2025-09-23 02:02:50,987 - training.trainer - INFO - Epoch 48, Step 164783: Loss=5.6706, Acc=0.200, PPL=290.19
2025-09-23 02:02:58,800 - training.trainer - INFO - Epoch 48, Step 164883: Loss=5.5077, Acc=0.210, PPL=246.59
2025-09-23 02:03:06,727 - training.trainer - INFO - Epoch 48, Step 164983: Loss=5.0703, Acc=0.286, PPL=159.22
2025-09-23 02:03:14,528 - training.trainer - INFO - Epoch 48, Step 165083: Loss=6.0753, Acc=0.184, PPL=434.97
2025-09-23 02:03:22,352 - training.trainer - INFO - Epoch 48, Step 165183: Loss=5.6291, Acc=0.356, PPL=278.41
2025-09-23 02:03:30,234 - training.trainer - INFO - Epoch 48, Step 165283: Loss=6.0165, Acc=0.300, PPL=410.15
2025-09-23 02:03:38,130 - training.trainer - INFO - Epoch 48, Step 165383: Loss=5.7394, Acc=0.208, PPL=310.86
2025-09-23 02:03:46,004 - training.trainer - INFO - Epoch 48, Step 165483: Loss=6.1965, Acc=0.229, PPL=491.04
2025-09-23 02:03:53,894 - training.trainer - INFO - Epoch 48, Step 165583: Loss=5.8382, Acc=0.312, PPL=343.16
2025-09-23 02:04:01,679 - training.trainer - INFO - Epoch 48, Step 165683: Loss=5.2040, Acc=0.308, PPL=182.01
2025-09-23 02:04:20,956 - training.trainer - INFO - Epoch 49/100 completed in 279.28s - Train Loss: 5.5375, Train Acc: 0.272, Val Loss: 5.6863, Val Acc: 0.252
2025-09-23 02:04:28,403 - training.trainer - INFO - Epoch 49, Step 165866: Loss=5.3022, Acc=0.295, PPL=200.79
2025-09-23 02:04:36,317 - training.trainer - INFO - Epoch 49, Step 165966: Loss=4.3521, Acc=0.455, PPL=77.64
2025-09-23 02:04:44,197 - training.trainer - INFO - Epoch 49, Step 166066: Loss=5.4957, Acc=0.216, PPL=243.65
2025-09-23 02:04:52,236 - training.trainer - INFO - Epoch 49, Step 166166: Loss=5.5889, Acc=0.235, PPL=267.45
2025-09-23 02:05:00,177 - training.trainer - INFO - Epoch 49, Step 166266: Loss=5.3973, Acc=0.278, PPL=220.82
2025-09-23 02:05:08,220 - training.trainer - INFO - Epoch 49, Step 166366: Loss=5.7469, Acc=0.200, PPL=313.22
2025-09-23 02:05:16,222 - training.trainer - INFO - Epoch 49, Step 166466: Loss=5.3422, Acc=0.271, PPL=208.96
2025-09-23 02:05:24,115 - training.trainer - INFO - Epoch 49, Step 166566: Loss=5.4193, Acc=0.235, PPL=225.72
2025-09-23 02:05:32,033 - training.trainer - INFO - Epoch 49, Step 166666: Loss=5.6925, Acc=0.250, PPL=296.64
2025-09-23 02:05:39,925 - training.trainer - INFO - Epoch 49, Step 166766: Loss=6.4145, Acc=0.154, PPL=610.61
2025-09-23 02:05:47,934 - training.trainer - INFO - Epoch 49, Step 166866: Loss=6.0167, Acc=0.189, PPL=410.21
2025-09-23 02:05:55,845 - training.trainer - INFO - Epoch 49, Step 166966: Loss=5.3578, Acc=0.200, PPL=212.25
2025-09-23 02:06:03,831 - training.trainer - INFO - Epoch 49, Step 167066: Loss=5.0428, Acc=0.389, PPL=154.90
2025-09-23 02:06:11,793 - training.trainer - INFO - Epoch 49, Step 167166: Loss=5.5523, Acc=0.241, PPL=257.82
2025-09-23 02:06:19,801 - training.trainer - INFO - Epoch 49, Step 167266: Loss=4.6262, Acc=0.421, PPL=102.13
2025-09-23 02:06:27,864 - training.trainer - INFO - Epoch 49, Step 167366: Loss=5.6015, Acc=0.261, PPL=270.85
2025-09-23 02:06:35,813 - training.trainer - INFO - Epoch 49, Step 167466: Loss=5.7541, Acc=0.182, PPL=315.47
2025-09-23 02:06:43,828 - training.trainer - INFO - Epoch 49, Step 167566: Loss=4.7352, Acc=0.250, PPL=113.88
2025-09-23 02:06:51,804 - training.trainer - INFO - Epoch 49, Step 167666: Loss=5.3166, Acc=0.236, PPL=203.70
2025-09-23 02:06:59,936 - training.trainer - INFO - Epoch 49, Step 167766: Loss=6.2176, Acc=0.231, PPL=501.52
2025-09-23 02:07:08,165 - training.trainer - INFO - Epoch 49, Step 167866: Loss=5.0285, Acc=0.364, PPL=152.70
2025-09-23 02:07:15,998 - training.trainer - INFO - Epoch 49, Step 167966: Loss=4.4144, Acc=0.435, PPL=82.63
2025-09-23 02:07:23,993 - training.trainer - INFO - Epoch 49, Step 168066: Loss=5.3174, Acc=0.312, PPL=203.85
2025-09-23 02:07:31,999 - training.trainer - INFO - Epoch 49, Step 168166: Loss=5.3162, Acc=0.250, PPL=203.61
2025-09-23 02:07:39,930 - training.trainer - INFO - Epoch 49, Step 168266: Loss=6.0514, Acc=0.217, PPL=424.72
2025-09-23 02:07:47,848 - training.trainer - INFO - Epoch 49, Step 168366: Loss=4.1423, Acc=0.474, PPL=62.95
2025-09-23 02:07:55,786 - training.trainer - INFO - Epoch 49, Step 168466: Loss=5.4426, Acc=0.282, PPL=231.04
2025-09-23 02:08:03,777 - training.trainer - INFO - Epoch 49, Step 168566: Loss=5.8991, Acc=0.333, PPL=364.72
2025-09-23 02:08:11,700 - training.trainer - INFO - Epoch 49, Step 168666: Loss=6.5271, Acc=0.229, PPL=683.42
2025-09-23 02:08:19,603 - training.trainer - INFO - Epoch 49, Step 168766: Loss=5.6124, Acc=0.178, PPL=273.81
2025-09-23 02:08:27,573 - training.trainer - INFO - Epoch 49, Step 168866: Loss=6.0572, Acc=0.147, PPL=427.19
2025-09-23 02:08:35,664 - training.trainer - INFO - Epoch 49, Step 168966: Loss=5.8884, Acc=0.184, PPL=360.84
2025-09-23 02:08:43,613 - training.trainer - INFO - Epoch 49, Step 169066: Loss=5.4920, Acc=0.320, PPL=242.74
2025-09-23 02:09:03,061 - training.trainer - INFO - Epoch 50/100 completed in 282.10s - Train Loss: 5.5350, Train Acc: 0.272, Val Loss: 5.6769, Val Acc: 0.251
2025-09-23 02:09:03,490 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-23 02:09:04,420 - training.trainer - INFO - New best model saved with validation loss: 5.6769
2025-09-23 02:09:04,421 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-23 02:09:13,170 - training.trainer - INFO - Epoch 50, Step 169249: Loss=5.1521, Acc=0.292, PPL=172.79
2025-09-23 02:09:21,145 - training.trainer - INFO - Epoch 50, Step 169349: Loss=5.8718, Acc=0.244, PPL=354.90
2025-09-23 02:09:29,163 - training.trainer - INFO - Epoch 50, Step 169449: Loss=5.9355, Acc=0.139, PPL=378.23
2025-09-23 02:09:37,255 - training.trainer - INFO - Epoch 50, Step 169549: Loss=5.1168, Acc=0.273, PPL=166.79
2025-09-23 02:09:45,235 - training.trainer - INFO - Epoch 50, Step 169649: Loss=5.5193, Acc=0.242, PPL=249.47
2025-09-23 02:09:53,324 - training.trainer - INFO - Epoch 50, Step 169749: Loss=5.3144, Acc=0.167, PPL=203.25
2025-09-23 02:10:01,390 - training.trainer - INFO - Epoch 50, Step 169849: Loss=5.3829, Acc=0.338, PPL=217.65
2025-09-23 02:10:09,273 - training.trainer - INFO - Epoch 50, Step 169949: Loss=5.7071, Acc=0.250, PPL=300.99
2025-09-23 02:10:17,215 - training.trainer - INFO - Epoch 50, Step 170049: Loss=5.1700, Acc=0.333, PPL=175.92
2025-09-23 02:10:25,206 - training.trainer - INFO - Epoch 50, Step 170149: Loss=6.0871, Acc=0.167, PPL=440.13
2025-09-23 02:10:33,280 - training.trainer - INFO - Epoch 50, Step 170249: Loss=6.1515, Acc=0.308, PPL=469.43
2025-09-23 02:10:41,483 - training.trainer - INFO - Epoch 50, Step 170349: Loss=6.5815, Acc=0.190, PPL=721.62
2025-09-23 02:10:49,633 - training.trainer - INFO - Epoch 50, Step 170449: Loss=6.3188, Acc=0.196, PPL=554.92
2025-09-23 02:10:57,729 - training.trainer - INFO - Epoch 50, Step 170549: Loss=5.8457, Acc=0.169, PPL=345.73
2025-09-23 02:11:05,650 - training.trainer - INFO - Epoch 50, Step 170649: Loss=6.0044, Acc=0.209, PPL=405.19
2025-09-23 02:11:13,565 - training.trainer - INFO - Epoch 50, Step 170749: Loss=6.0601, Acc=0.263, PPL=428.40
2025-09-23 02:11:21,495 - training.trainer - INFO - Epoch 50, Step 170849: Loss=5.6592, Acc=0.250, PPL=286.91
2025-09-23 02:11:29,352 - training.trainer - INFO - Epoch 50, Step 170949: Loss=5.9314, Acc=0.312, PPL=376.67
2025-09-23 02:11:37,297 - training.trainer - INFO - Epoch 50, Step 171049: Loss=5.6549, Acc=0.222, PPL=285.70
2025-09-23 02:11:45,155 - training.trainer - INFO - Epoch 50, Step 171149: Loss=6.0534, Acc=0.224, PPL=425.55
2025-09-23 02:11:53,080 - training.trainer - INFO - Epoch 50, Step 171249: Loss=5.0100, Acc=0.400, PPL=149.90
2025-09-23 02:12:00,987 - training.trainer - INFO - Epoch 50, Step 171349: Loss=5.9938, Acc=0.250, PPL=400.95
2025-09-23 02:12:08,794 - training.trainer - INFO - Epoch 50, Step 171449: Loss=5.2453, Acc=0.237, PPL=189.68
2025-09-23 02:12:16,641 - training.trainer - INFO - Epoch 50, Step 171549: Loss=6.1192, Acc=0.133, PPL=454.52
2025-09-23 02:12:24,582 - training.trainer - INFO - Epoch 50, Step 171649: Loss=6.1557, Acc=0.200, PPL=471.38
2025-09-23 02:12:32,707 - training.trainer - INFO - Epoch 50, Step 171749: Loss=5.3402, Acc=0.353, PPL=208.54
2025-09-23 02:12:40,654 - training.trainer - INFO - Epoch 50, Step 171849: Loss=4.5746, Acc=0.407, PPL=96.99
2025-09-23 02:12:48,624 - training.trainer - INFO - Epoch 50, Step 171949: Loss=5.3129, Acc=0.292, PPL=202.94
2025-09-23 02:12:56,804 - training.trainer - INFO - Epoch 50, Step 172049: Loss=5.6242, Acc=0.222, PPL=277.05
2025-09-23 02:13:04,825 - training.trainer - INFO - Epoch 50, Step 172149: Loss=6.3484, Acc=0.239, PPL=571.60
2025-09-23 02:13:12,775 - training.trainer - INFO - Epoch 50, Step 172249: Loss=5.6313, Acc=0.240, PPL=279.02
2025-09-23 02:13:20,787 - training.trainer - INFO - Epoch 50, Step 172349: Loss=5.9635, Acc=0.231, PPL=388.98
2025-09-23 02:13:28,897 - training.trainer - INFO - Epoch 50, Step 172449: Loss=5.8088, Acc=0.283, PPL=333.22
2025-09-23 02:13:49,163 - training.trainer - INFO - Epoch 51/100 completed in 284.74s - Train Loss: 5.5273, Train Acc: 0.275, Val Loss: 5.6820, Val Acc: 0.252
2025-09-23 02:13:57,333 - training.trainer - INFO - Epoch 51, Step 172632: Loss=5.7473, Acc=0.421, PPL=313.34
2025-09-23 02:14:05,224 - training.trainer - INFO - Epoch 51, Step 172732: Loss=5.8405, Acc=0.216, PPL=343.94
2025-09-23 02:14:13,144 - training.trainer - INFO - Epoch 51, Step 172832: Loss=4.8894, Acc=0.400, PPL=132.87
2025-09-23 02:14:21,020 - training.trainer - INFO - Epoch 51, Step 172932: Loss=5.2170, Acc=0.220, PPL=184.37
2025-09-23 02:14:29,043 - training.trainer - INFO - Epoch 51, Step 173032: Loss=6.3897, Acc=0.190, PPL=595.69
2025-09-23 02:14:37,109 - training.trainer - INFO - Epoch 51, Step 173132: Loss=5.6807, Acc=0.250, PPL=293.14
2025-09-23 02:14:45,083 - training.trainer - INFO - Epoch 51, Step 173232: Loss=5.9867, Acc=0.175, PPL=398.09
2025-09-23 02:14:53,069 - training.trainer - INFO - Epoch 51, Step 173332: Loss=5.9436, Acc=0.233, PPL=381.32
2025-09-23 02:15:01,088 - training.trainer - INFO - Epoch 51, Step 173432: Loss=5.5334, Acc=0.300, PPL=253.00
2025-09-23 02:15:09,212 - training.trainer - INFO - Epoch 51, Step 173532: Loss=5.9690, Acc=0.118, PPL=391.11
2025-09-23 02:15:17,320 - training.trainer - INFO - Epoch 51, Step 173632: Loss=5.5368, Acc=0.234, PPL=253.86
2025-09-23 02:15:25,356 - training.trainer - INFO - Epoch 51, Step 173732: Loss=5.7570, Acc=0.294, PPL=316.40
2025-09-23 02:15:33,365 - training.trainer - INFO - Epoch 51, Step 173832: Loss=5.2025, Acc=0.294, PPL=181.72
2025-09-23 02:15:41,461 - training.trainer - INFO - Epoch 51, Step 173932: Loss=5.7993, Acc=0.159, PPL=330.06
2025-09-23 02:15:49,721 - training.trainer - INFO - Epoch 51, Step 174032: Loss=5.0213, Acc=0.273, PPL=151.61
2025-09-23 02:15:57,684 - training.trainer - INFO - Epoch 51, Step 174132: Loss=6.3657, Acc=0.222, PPL=581.57
2025-09-23 02:16:05,713 - training.trainer - INFO - Epoch 51, Step 174232: Loss=5.0238, Acc=0.360, PPL=151.98
2025-09-23 02:16:13,789 - training.trainer - INFO - Epoch 51, Step 174332: Loss=5.2604, Acc=0.304, PPL=192.55
2025-09-23 02:16:21,710 - training.trainer - INFO - Epoch 51, Step 174432: Loss=5.4913, Acc=0.278, PPL=242.58
2025-09-23 02:16:29,737 - training.trainer - INFO - Epoch 51, Step 174532: Loss=3.9881, Acc=0.457, PPL=53.95
2025-09-23 02:16:37,691 - training.trainer - INFO - Epoch 51, Step 174632: Loss=6.3822, Acc=0.250, PPL=591.24
2025-09-23 02:16:45,658 - training.trainer - INFO - Epoch 51, Step 174732: Loss=5.5098, Acc=0.200, PPL=247.09
2025-09-23 02:16:53,603 - training.trainer - INFO - Epoch 51, Step 174832: Loss=5.5892, Acc=0.286, PPL=267.51
2025-09-23 02:17:01,540 - training.trainer - INFO - Epoch 51, Step 174932: Loss=6.3618, Acc=0.196, PPL=579.26
2025-09-23 02:17:09,562 - training.trainer - INFO - Epoch 51, Step 175032: Loss=5.4861, Acc=0.304, PPL=241.32
2025-09-23 02:17:17,695 - training.trainer - INFO - Epoch 51, Step 175132: Loss=4.3024, Acc=0.519, PPL=73.87
2025-09-23 02:17:25,628 - training.trainer - INFO - Epoch 51, Step 175232: Loss=5.3946, Acc=0.213, PPL=220.21
2025-09-23 02:17:33,623 - training.trainer - INFO - Epoch 51, Step 175332: Loss=6.0899, Acc=0.237, PPL=441.36
2025-09-23 02:17:41,630 - training.trainer - INFO - Epoch 51, Step 175432: Loss=4.6879, Acc=0.478, PPL=108.63
2025-09-23 02:17:49,746 - training.trainer - INFO - Epoch 51, Step 175532: Loss=5.2060, Acc=0.333, PPL=182.36
2025-09-23 02:17:57,564 - training.trainer - INFO - Epoch 51, Step 175632: Loss=4.9603, Acc=0.357, PPL=142.64
2025-09-23 02:18:05,462 - training.trainer - INFO - Epoch 51, Step 175732: Loss=4.5467, Acc=0.389, PPL=94.32
2025-09-23 02:18:13,574 - training.trainer - INFO - Epoch 51, Step 175832: Loss=5.8530, Acc=0.279, PPL=348.28
2025-09-23 02:18:33,428 - training.trainer - INFO - Epoch 52/100 completed in 284.26s - Train Loss: 5.5185, Train Acc: 0.275, Val Loss: 5.6702, Val Acc: 0.252
2025-09-23 02:18:34,195 - training.trainer - INFO - New best model saved with validation loss: 5.6702
2025-09-23 02:18:34,195 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_52.pt
2025-09-23 02:18:42,411 - training.trainer - INFO - Epoch 52, Step 176015: Loss=5.9283, Acc=0.196, PPL=375.53
2025-09-23 02:18:50,251 - training.trainer - INFO - Epoch 52, Step 176115: Loss=6.7410, Acc=0.178, PPL=846.42
2025-09-23 02:18:58,447 - training.trainer - INFO - Epoch 52, Step 176215: Loss=6.0553, Acc=0.188, PPL=426.37
2025-09-23 02:19:06,477 - training.trainer - INFO - Epoch 52, Step 176315: Loss=4.6136, Acc=0.423, PPL=100.84
2025-09-23 02:19:14,478 - training.trainer - INFO - Epoch 52, Step 176415: Loss=5.2801, Acc=0.273, PPL=196.39
2025-09-23 02:19:22,586 - training.trainer - INFO - Epoch 52, Step 176515: Loss=4.7574, Acc=0.310, PPL=116.44
2025-09-23 02:19:30,806 - training.trainer - INFO - Epoch 52, Step 176615: Loss=5.8466, Acc=0.306, PPL=346.05
2025-09-23 02:19:38,943 - training.trainer - INFO - Epoch 52, Step 176715: Loss=4.5062, Acc=0.350, PPL=90.57
2025-09-23 02:19:46,818 - training.trainer - INFO - Epoch 52, Step 176815: Loss=5.2025, Acc=0.318, PPL=181.73
2025-09-23 02:19:54,695 - training.trainer - INFO - Epoch 52, Step 176915: Loss=5.5615, Acc=0.231, PPL=260.21
2025-09-23 02:20:02,653 - training.trainer - INFO - Epoch 52, Step 177015: Loss=5.7156, Acc=0.250, PPL=303.57
2025-09-23 02:20:10,483 - training.trainer - INFO - Epoch 52, Step 177115: Loss=6.0346, Acc=0.262, PPL=417.62
2025-09-23 02:20:18,358 - training.trainer - INFO - Epoch 52, Step 177215: Loss=5.4921, Acc=0.282, PPL=242.76
2025-09-23 02:20:26,164 - training.trainer - INFO - Epoch 52, Step 177315: Loss=5.9982, Acc=0.171, PPL=402.70
2025-09-23 02:20:34,143 - training.trainer - INFO - Epoch 52, Step 177415: Loss=5.2260, Acc=0.308, PPL=186.04
2025-09-23 02:20:42,065 - training.trainer - INFO - Epoch 52, Step 177515: Loss=6.0346, Acc=0.224, PPL=417.64
2025-09-23 02:20:49,908 - training.trainer - INFO - Epoch 52, Step 177615: Loss=5.5315, Acc=0.261, PPL=252.53
2025-09-23 02:20:57,988 - training.trainer - INFO - Epoch 52, Step 177715: Loss=5.4801, Acc=0.367, PPL=239.88
2025-09-23 02:21:05,975 - training.trainer - INFO - Epoch 52, Step 177815: Loss=5.6133, Acc=0.300, PPL=274.06
2025-09-23 02:21:13,941 - training.trainer - INFO - Epoch 52, Step 177915: Loss=4.2330, Acc=0.438, PPL=68.93
2025-09-23 02:21:21,875 - training.trainer - INFO - Epoch 52, Step 178015: Loss=5.2645, Acc=0.222, PPL=193.35
2025-09-23 02:21:29,682 - training.trainer - INFO - Epoch 52, Step 178115: Loss=5.8666, Acc=0.333, PPL=353.06
2025-09-23 02:21:37,509 - training.trainer - INFO - Epoch 52, Step 178215: Loss=6.0156, Acc=0.246, PPL=409.76
2025-09-23 02:21:45,384 - training.trainer - INFO - Epoch 52, Step 178315: Loss=5.2621, Acc=0.290, PPL=192.89
2025-09-23 02:21:53,431 - training.trainer - INFO - Epoch 52, Step 178415: Loss=5.6128, Acc=0.368, PPL=273.91
2025-09-23 02:22:01,316 - training.trainer - INFO - Epoch 52, Step 178515: Loss=5.2041, Acc=0.333, PPL=182.03
2025-09-23 02:22:09,184 - training.trainer - INFO - Epoch 52, Step 178615: Loss=5.7287, Acc=0.323, PPL=307.56
2025-09-23 02:22:17,073 - training.trainer - INFO - Epoch 52, Step 178715: Loss=5.3454, Acc=0.267, PPL=209.65
2025-09-23 02:22:25,151 - training.trainer - INFO - Epoch 52, Step 178815: Loss=6.3618, Acc=0.147, PPL=579.26
2025-09-23 02:22:32,988 - training.trainer - INFO - Epoch 52, Step 178915: Loss=4.7309, Acc=0.286, PPL=113.40
2025-09-23 02:22:41,042 - training.trainer - INFO - Epoch 52, Step 179015: Loss=4.7193, Acc=0.303, PPL=112.09
2025-09-23 02:22:49,045 - training.trainer - INFO - Epoch 52, Step 179115: Loss=6.6538, Acc=0.200, PPL=775.69
2025-09-23 02:22:56,872 - training.trainer - INFO - Epoch 52, Step 179215: Loss=6.1185, Acc=0.158, PPL=454.18
2025-09-23 02:23:16,655 - training.trainer - INFO - Epoch 53/100 completed in 282.46s - Train Loss: 5.5137, Train Acc: 0.276, Val Loss: 5.6773, Val Acc: 0.253
2025-09-23 02:23:24,828 - training.trainer - INFO - Epoch 53, Step 179398: Loss=5.6511, Acc=0.288, PPL=284.61
2025-09-23 02:23:32,686 - training.trainer - INFO - Epoch 53, Step 179498: Loss=5.6871, Acc=0.236, PPL=295.02
2025-09-23 02:23:40,443 - training.trainer - INFO - Epoch 53, Step 179598: Loss=5.1931, Acc=0.281, PPL=180.02
2025-09-23 02:23:48,324 - training.trainer - INFO - Epoch 53, Step 179698: Loss=5.7926, Acc=0.212, PPL=327.86
2025-09-23 02:23:56,211 - training.trainer - INFO - Epoch 53, Step 179798: Loss=5.5641, Acc=0.294, PPL=260.90
2025-09-23 02:24:04,023 - training.trainer - INFO - Epoch 53, Step 179898: Loss=5.5531, Acc=0.189, PPL=258.05
2025-09-23 02:24:11,769 - training.trainer - INFO - Epoch 53, Step 179998: Loss=6.1934, Acc=0.205, PPL=489.49
2025-09-23 02:24:19,713 - training.trainer - INFO - Epoch 53, Step 180098: Loss=5.3442, Acc=0.333, PPL=209.40
2025-09-23 02:24:27,580 - training.trainer - INFO - Epoch 53, Step 180198: Loss=5.5297, Acc=0.205, PPL=252.06
2025-09-23 02:24:35,420 - training.trainer - INFO - Epoch 53, Step 180298: Loss=5.6893, Acc=0.265, PPL=295.68
2025-09-23 02:24:43,354 - training.trainer - INFO - Epoch 53, Step 180398: Loss=5.5859, Acc=0.357, PPL=266.63
2025-09-23 02:24:51,105 - training.trainer - INFO - Epoch 53, Step 180498: Loss=4.4037, Acc=0.524, PPL=81.76
2025-09-23 02:24:58,998 - training.trainer - INFO - Epoch 53, Step 180598: Loss=5.9616, Acc=0.250, PPL=388.24
2025-09-23 02:25:06,796 - training.trainer - INFO - Epoch 53, Step 180698: Loss=5.5418, Acc=0.200, PPL=255.14
2025-09-23 02:25:14,639 - training.trainer - INFO - Epoch 53, Step 180798: Loss=4.9795, Acc=0.333, PPL=145.40
2025-09-23 02:25:22,638 - training.trainer - INFO - Epoch 53, Step 180898: Loss=5.5583, Acc=0.182, PPL=259.38
2025-09-23 02:25:30,810 - training.trainer - INFO - Epoch 53, Step 180998: Loss=5.7647, Acc=0.224, PPL=318.86
2025-09-23 02:25:38,756 - training.trainer - INFO - Epoch 53, Step 181098: Loss=5.1582, Acc=0.234, PPL=173.84
2025-09-23 02:25:46,718 - training.trainer - INFO - Epoch 53, Step 181198: Loss=3.9834, Acc=0.529, PPL=53.70
2025-09-23 02:25:54,648 - training.trainer - INFO - Epoch 53, Step 181298: Loss=3.6582, Acc=0.500, PPL=38.79
2025-09-23 02:26:02,613 - training.trainer - INFO - Epoch 53, Step 181398: Loss=6.0366, Acc=0.209, PPL=418.47
2025-09-23 02:26:10,520 - training.trainer - INFO - Epoch 53, Step 181498: Loss=5.7157, Acc=0.294, PPL=303.58
2025-09-23 02:26:18,500 - training.trainer - INFO - Epoch 53, Step 181598: Loss=5.1974, Acc=0.277, PPL=180.81
2025-09-23 02:26:26,547 - training.trainer - INFO - Epoch 53, Step 181698: Loss=5.6412, Acc=0.294, PPL=281.80
2025-09-23 02:26:34,728 - training.trainer - INFO - Epoch 53, Step 181798: Loss=4.9906, Acc=0.438, PPL=147.02
2025-09-23 02:26:42,704 - training.trainer - INFO - Epoch 53, Step 181898: Loss=5.0665, Acc=0.212, PPL=158.62
2025-09-23 02:26:50,738 - training.trainer - INFO - Epoch 53, Step 181998: Loss=4.1507, Acc=0.460, PPL=63.48
2025-09-23 02:26:58,789 - training.trainer - INFO - Epoch 53, Step 182098: Loss=5.1347, Acc=0.206, PPL=169.82
2025-09-23 02:27:06,810 - training.trainer - INFO - Epoch 53, Step 182198: Loss=4.6854, Acc=0.344, PPL=108.35
2025-09-23 02:27:14,635 - training.trainer - INFO - Epoch 53, Step 182298: Loss=5.8014, Acc=0.292, PPL=330.77
2025-09-23 02:27:22,459 - training.trainer - INFO - Epoch 53, Step 182398: Loss=6.1873, Acc=0.172, PPL=486.51
2025-09-23 02:27:30,227 - training.trainer - INFO - Epoch 53, Step 182498: Loss=6.8380, Acc=0.177, PPL=932.60
2025-09-23 02:27:38,058 - training.trainer - INFO - Epoch 53, Step 182598: Loss=5.6127, Acc=0.250, PPL=273.90
2025-09-23 02:27:57,600 - training.trainer - INFO - Epoch 54/100 completed in 280.94s - Train Loss: 5.5043, Train Acc: 0.276, Val Loss: 5.6840, Val Acc: 0.252
2025-09-23 02:28:06,114 - training.trainer - INFO - Epoch 54, Step 182781: Loss=5.5614, Acc=0.278, PPL=260.19
2025-09-23 02:28:14,291 - training.trainer - INFO - Epoch 54, Step 182881: Loss=5.3849, Acc=0.333, PPL=218.08
2025-09-23 02:28:22,212 - training.trainer - INFO - Epoch 54, Step 182981: Loss=6.3241, Acc=0.189, PPL=557.83
2025-09-23 02:28:30,042 - training.trainer - INFO - Epoch 54, Step 183081: Loss=5.1765, Acc=0.231, PPL=177.06
2025-09-23 02:28:37,841 - training.trainer - INFO - Epoch 54, Step 183181: Loss=5.3096, Acc=0.304, PPL=202.27
2025-09-23 02:28:45,724 - training.trainer - INFO - Epoch 54, Step 183281: Loss=5.0735, Acc=0.237, PPL=159.73
2025-09-23 02:28:53,585 - training.trainer - INFO - Epoch 54, Step 183381: Loss=5.3841, Acc=0.265, PPL=217.91
2025-09-23 02:29:01,410 - training.trainer - INFO - Epoch 54, Step 183481: Loss=5.7243, Acc=0.197, PPL=306.23
2025-09-23 02:29:09,445 - training.trainer - INFO - Epoch 54, Step 183581: Loss=6.5918, Acc=0.190, PPL=729.06
2025-09-23 02:29:17,305 - training.trainer - INFO - Epoch 54, Step 183681: Loss=6.0087, Acc=0.275, PPL=406.94
2025-09-23 02:29:25,293 - training.trainer - INFO - Epoch 54, Step 183781: Loss=4.4807, Acc=0.318, PPL=88.30
2025-09-23 02:29:33,096 - training.trainer - INFO - Epoch 54, Step 183881: Loss=5.4985, Acc=0.278, PPL=244.32
2025-09-23 02:29:40,980 - training.trainer - INFO - Epoch 54, Step 183981: Loss=6.3704, Acc=0.237, PPL=584.31
2025-09-23 02:29:49,001 - training.trainer - INFO - Epoch 54, Step 184081: Loss=4.7954, Acc=0.357, PPL=120.95
2025-09-23 02:29:57,020 - training.trainer - INFO - Epoch 54, Step 184181: Loss=5.5643, Acc=0.278, PPL=260.96
2025-09-23 02:30:04,932 - training.trainer - INFO - Epoch 54, Step 184281: Loss=6.7303, Acc=0.222, PPL=837.39
2025-09-23 02:30:12,925 - training.trainer - INFO - Epoch 54, Step 184381: Loss=3.6405, Acc=0.545, PPL=38.11
2025-09-23 02:30:20,903 - training.trainer - INFO - Epoch 54, Step 184481: Loss=5.1546, Acc=0.300, PPL=173.23
2025-09-23 02:30:29,010 - training.trainer - INFO - Epoch 54, Step 184581: Loss=3.6024, Acc=0.560, PPL=36.69
2025-09-23 02:30:36,852 - training.trainer - INFO - Epoch 54, Step 184681: Loss=6.0703, Acc=0.279, PPL=432.80
2025-09-23 02:30:44,621 - training.trainer - INFO - Epoch 54, Step 184781: Loss=5.5414, Acc=0.222, PPL=255.04
2025-09-23 02:30:52,469 - training.trainer - INFO - Epoch 54, Step 184881: Loss=4.8787, Acc=0.333, PPL=131.46
2025-09-23 02:31:00,370 - training.trainer - INFO - Epoch 54, Step 184981: Loss=6.1340, Acc=0.200, PPL=461.29
2025-09-23 02:31:08,157 - training.trainer - INFO - Epoch 54, Step 185081: Loss=5.6355, Acc=0.273, PPL=280.20
2025-09-23 02:31:15,930 - training.trainer - INFO - Epoch 54, Step 185181: Loss=5.9345, Acc=0.143, PPL=377.87
2025-09-23 02:31:23,722 - training.trainer - INFO - Epoch 54, Step 185281: Loss=5.9816, Acc=0.219, PPL=396.07
2025-09-23 02:31:31,585 - training.trainer - INFO - Epoch 54, Step 185381: Loss=4.6185, Acc=0.480, PPL=101.34
2025-09-23 02:31:39,393 - training.trainer - INFO - Epoch 54, Step 185481: Loss=4.4824, Acc=0.476, PPL=88.45
2025-09-23 02:31:47,257 - training.trainer - INFO - Epoch 54, Step 185581: Loss=5.3086, Acc=0.317, PPL=202.07
2025-09-23 02:31:55,129 - training.trainer - INFO - Epoch 54, Step 185681: Loss=6.2687, Acc=0.189, PPL=527.78
2025-09-23 02:32:03,123 - training.trainer - INFO - Epoch 54, Step 185781: Loss=5.0071, Acc=0.269, PPL=149.47
2025-09-23 02:32:10,956 - training.trainer - INFO - Epoch 54, Step 185881: Loss=5.5233, Acc=0.200, PPL=250.47
2025-09-23 02:32:18,813 - training.trainer - INFO - Epoch 54, Step 185981: Loss=5.5334, Acc=0.240, PPL=253.01
2025-09-23 02:32:37,852 - training.trainer - INFO - Epoch 55/100 completed in 280.25s - Train Loss: 5.4999, Train Acc: 0.278, Val Loss: 5.6871, Val Acc: 0.253
2025-09-23 02:32:38,182 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_55.pt
2025-09-23 02:32:45,308 - training.trainer - INFO - Epoch 55, Step 186164: Loss=5.6677, Acc=0.290, PPL=289.37
2025-09-23 02:32:51,905 - training.trainer - INFO - Epoch 55, Step 186264: Loss=5.7655, Acc=0.270, PPL=319.11
2025-09-23 02:32:58,506 - training.trainer - INFO - Epoch 55, Step 186364: Loss=5.7974, Acc=0.182, PPL=329.43
2025-09-23 02:33:05,433 - training.trainer - INFO - Epoch 55, Step 186464: Loss=5.1192, Acc=0.296, PPL=167.19
2025-09-23 02:33:12,312 - training.trainer - INFO - Epoch 55, Step 186564: Loss=5.0467, Acc=0.308, PPL=155.51
2025-09-23 02:33:19,652 - training.trainer - INFO - Epoch 55, Step 186664: Loss=5.8415, Acc=0.258, PPL=344.30
2025-09-23 02:33:26,534 - training.trainer - INFO - Epoch 55, Step 186764: Loss=6.1187, Acc=0.188, PPL=454.28
2025-09-23 02:33:33,421 - training.trainer - INFO - Epoch 55, Step 186864: Loss=5.3510, Acc=0.254, PPL=210.82
2025-09-23 02:33:40,398 - training.trainer - INFO - Epoch 55, Step 186964: Loss=5.2935, Acc=0.234, PPL=199.03
2025-09-23 02:33:47,707 - training.trainer - INFO - Epoch 55, Step 187064: Loss=5.8338, Acc=0.297, PPL=341.65
2025-09-23 02:33:55,090 - training.trainer - INFO - Epoch 55, Step 187164: Loss=5.9570, Acc=0.269, PPL=386.46
2025-09-23 02:34:02,983 - training.trainer - INFO - Epoch 55, Step 187264: Loss=5.6182, Acc=0.231, PPL=275.39
2025-09-23 02:34:10,909 - training.trainer - INFO - Epoch 55, Step 187364: Loss=5.6163, Acc=0.318, PPL=274.88
2025-09-23 02:34:18,902 - training.trainer - INFO - Epoch 55, Step 187464: Loss=6.5237, Acc=0.107, PPL=681.10
2025-09-23 02:34:26,927 - training.trainer - INFO - Epoch 55, Step 187564: Loss=5.4986, Acc=0.308, PPL=244.35
2025-09-23 02:34:34,835 - training.trainer - INFO - Epoch 55, Step 187664: Loss=4.9763, Acc=0.244, PPL=144.94
2025-09-23 02:34:42,776 - training.trainer - INFO - Epoch 55, Step 187764: Loss=5.4352, Acc=0.324, PPL=229.33
2025-09-23 02:34:50,919 - training.trainer - INFO - Epoch 55, Step 187864: Loss=5.9095, Acc=0.196, PPL=368.54
2025-09-23 02:34:58,957 - training.trainer - INFO - Epoch 55, Step 187964: Loss=5.9024, Acc=0.234, PPL=365.90
2025-09-23 02:35:06,873 - training.trainer - INFO - Epoch 55, Step 188064: Loss=5.0887, Acc=0.212, PPL=162.18
2025-09-23 02:35:14,826 - training.trainer - INFO - Epoch 55, Step 188164: Loss=4.1523, Acc=0.433, PPL=63.58
2025-09-23 02:35:22,912 - training.trainer - INFO - Epoch 55, Step 188264: Loss=4.9772, Acc=0.322, PPL=145.06
2025-09-23 02:35:30,912 - training.trainer - INFO - Epoch 55, Step 188364: Loss=6.2170, Acc=0.244, PPL=501.18
2025-09-23 02:35:38,936 - training.trainer - INFO - Epoch 55, Step 188464: Loss=5.8473, Acc=0.246, PPL=346.29
2025-09-23 02:35:46,935 - training.trainer - INFO - Epoch 55, Step 188564: Loss=5.1168, Acc=0.312, PPL=166.81
2025-09-23 02:35:54,929 - training.trainer - INFO - Epoch 55, Step 188664: Loss=5.5328, Acc=0.348, PPL=252.85
2025-09-23 02:36:03,010 - training.trainer - INFO - Epoch 55, Step 188764: Loss=4.8211, Acc=0.357, PPL=124.11
2025-09-23 02:36:10,927 - training.trainer - INFO - Epoch 55, Step 188864: Loss=6.2136, Acc=0.213, PPL=499.49
2025-09-23 02:36:18,725 - training.trainer - INFO - Epoch 55, Step 188964: Loss=5.0417, Acc=0.292, PPL=154.73
2025-09-23 02:36:26,772 - training.trainer - INFO - Epoch 55, Step 189064: Loss=5.5206, Acc=0.250, PPL=249.78
2025-09-23 02:36:34,713 - training.trainer - INFO - Epoch 55, Step 189164: Loss=4.3863, Acc=0.360, PPL=80.35
2025-09-23 02:36:42,586 - training.trainer - INFO - Epoch 55, Step 189264: Loss=4.7613, Acc=0.391, PPL=116.90
2025-09-23 02:36:50,461 - training.trainer - INFO - Epoch 55, Step 189364: Loss=5.5375, Acc=0.304, PPL=254.05
2025-09-23 02:37:09,993 - training.trainer - INFO - Epoch 56/100 completed in 271.81s - Train Loss: 5.4915, Train Acc: 0.279, Val Loss: 5.6777, Val Acc: 0.253
2025-09-23 02:37:16,935 - training.trainer - INFO - Epoch 56, Step 189547: Loss=6.0353, Acc=0.129, PPL=417.94
2025-09-23 02:37:23,583 - training.trainer - INFO - Epoch 56, Step 189647: Loss=4.8172, Acc=0.279, PPL=123.62
2025-09-23 02:37:30,486 - training.trainer - INFO - Epoch 56, Step 189747: Loss=5.8576, Acc=0.300, PPL=349.88
2025-09-23 02:37:37,171 - training.trainer - INFO - Epoch 56, Step 189847: Loss=5.0075, Acc=0.395, PPL=149.53
2025-09-23 02:37:44,332 - training.trainer - INFO - Epoch 56, Step 189947: Loss=5.6385, Acc=0.333, PPL=281.05
2025-09-23 02:37:51,723 - training.trainer - INFO - Epoch 56, Step 190047: Loss=5.0963, Acc=0.212, PPL=163.41
2025-09-23 02:37:59,472 - training.trainer - INFO - Epoch 56, Step 190147: Loss=5.3571, Acc=0.291, PPL=212.11
2025-09-23 02:38:07,383 - training.trainer - INFO - Epoch 56, Step 190247: Loss=5.2285, Acc=0.267, PPL=186.52
2025-09-23 02:38:15,362 - training.trainer - INFO - Epoch 56, Step 190347: Loss=5.7780, Acc=0.381, PPL=323.11
2025-09-23 02:38:23,201 - training.trainer - INFO - Epoch 56, Step 190447: Loss=5.2266, Acc=0.278, PPL=186.17
2025-09-23 02:38:31,111 - training.trainer - INFO - Epoch 56, Step 190547: Loss=5.9893, Acc=0.294, PPL=399.14
2025-09-23 02:38:39,163 - training.trainer - INFO - Epoch 56, Step 190647: Loss=5.9925, Acc=0.283, PPL=400.43
2025-09-23 02:38:47,475 - training.trainer - INFO - Epoch 56, Step 190747: Loss=5.4938, Acc=0.277, PPL=243.19
2025-09-23 02:38:55,492 - training.trainer - INFO - Epoch 56, Step 190847: Loss=6.0476, Acc=0.244, PPL=423.10
2025-09-23 02:39:03,356 - training.trainer - INFO - Epoch 56, Step 190947: Loss=5.9288, Acc=0.324, PPL=375.72
2025-09-23 02:39:11,294 - training.trainer - INFO - Epoch 56, Step 191047: Loss=5.7370, Acc=0.311, PPL=310.12
2025-09-23 02:39:19,181 - training.trainer - INFO - Epoch 56, Step 191147: Loss=5.6412, Acc=0.190, PPL=281.80
2025-09-23 02:39:27,055 - training.trainer - INFO - Epoch 56, Step 191247: Loss=5.8479, Acc=0.231, PPL=346.52
2025-09-23 02:39:34,943 - training.trainer - INFO - Epoch 56, Step 191347: Loss=5.6415, Acc=0.255, PPL=281.88
2025-09-23 02:39:42,965 - training.trainer - INFO - Epoch 56, Step 191447: Loss=5.7094, Acc=0.286, PPL=301.70
2025-09-23 02:39:50,919 - training.trainer - INFO - Epoch 56, Step 191547: Loss=5.7819, Acc=0.273, PPL=324.38
2025-09-23 02:39:58,739 - training.trainer - INFO - Epoch 56, Step 191647: Loss=5.9342, Acc=0.179, PPL=377.74
2025-09-23 02:40:06,477 - training.trainer - INFO - Epoch 56, Step 191747: Loss=5.6261, Acc=0.317, PPL=277.59
2025-09-23 02:40:14,424 - training.trainer - INFO - Epoch 56, Step 191847: Loss=3.4383, Acc=0.551, PPL=31.13
2025-09-23 02:40:22,367 - training.trainer - INFO - Epoch 56, Step 191947: Loss=4.4934, Acc=0.300, PPL=89.43
2025-09-23 02:40:30,401 - training.trainer - INFO - Epoch 56, Step 192047: Loss=5.3885, Acc=0.240, PPL=218.88
2025-09-23 02:40:38,406 - training.trainer - INFO - Epoch 56, Step 192147: Loss=6.1052, Acc=0.245, PPL=448.17
2025-09-23 02:40:46,384 - training.trainer - INFO - Epoch 56, Step 192247: Loss=5.5298, Acc=0.250, PPL=252.10
2025-09-23 02:40:54,186 - training.trainer - INFO - Epoch 56, Step 192347: Loss=5.4074, Acc=0.286, PPL=223.05
2025-09-23 02:41:01,996 - training.trainer - INFO - Epoch 56, Step 192447: Loss=4.7412, Acc=0.432, PPL=114.57
2025-09-23 02:41:09,758 - training.trainer - INFO - Epoch 56, Step 192547: Loss=6.1563, Acc=0.228, PPL=471.66
2025-09-23 02:41:17,603 - training.trainer - INFO - Epoch 56, Step 192647: Loss=5.4873, Acc=0.320, PPL=241.60
2025-09-23 02:41:25,488 - training.trainer - INFO - Epoch 56, Step 192747: Loss=6.0275, Acc=0.261, PPL=414.70
2025-09-23 02:41:44,283 - training.trainer - INFO - Epoch 57/100 completed in 274.29s - Train Loss: 5.4872, Train Acc: 0.281, Val Loss: 5.6654, Val Acc: 0.254
2025-09-23 02:41:45,037 - training.trainer - INFO - New best model saved with validation loss: 5.6654
2025-09-23 02:41:45,037 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_57.pt
2025-09-23 02:41:52,871 - training.trainer - INFO - Epoch 57, Step 192930: Loss=5.5425, Acc=0.250, PPL=255.31
2025-09-23 02:42:00,260 - training.trainer - INFO - Epoch 57, Step 193030: Loss=5.8588, Acc=0.190, PPL=350.31
2025-09-23 02:42:07,662 - training.trainer - INFO - Epoch 57, Step 193130: Loss=5.5795, Acc=0.333, PPL=264.93
2025-09-23 02:42:15,037 - training.trainer - INFO - Epoch 57, Step 193230: Loss=5.8141, Acc=0.208, PPL=334.99
2025-09-23 02:42:23,105 - training.trainer - INFO - Epoch 57, Step 193330: Loss=5.6212, Acc=0.310, PPL=276.23
2025-09-23 02:42:31,097 - training.trainer - INFO - Epoch 57, Step 193430: Loss=6.0385, Acc=0.171, PPL=419.27
2025-09-23 02:42:38,989 - training.trainer - INFO - Epoch 57, Step 193530: Loss=6.5409, Acc=0.189, PPL=692.89
2025-09-23 02:42:46,921 - training.trainer - INFO - Epoch 57, Step 193630: Loss=6.0522, Acc=0.270, PPL=425.05
2025-09-23 02:42:54,876 - training.trainer - INFO - Epoch 57, Step 193730: Loss=6.0736, Acc=0.244, PPL=434.23
2025-09-23 02:43:02,915 - training.trainer - INFO - Epoch 57, Step 193830: Loss=5.3446, Acc=0.389, PPL=209.46
2025-09-23 02:43:10,737 - training.trainer - INFO - Epoch 57, Step 193930: Loss=4.1086, Acc=0.529, PPL=60.86
2025-09-23 02:43:18,620 - training.trainer - INFO - Epoch 57, Step 194030: Loss=5.3512, Acc=0.235, PPL=210.87
2025-09-23 02:43:26,499 - training.trainer - INFO - Epoch 57, Step 194130: Loss=5.8675, Acc=0.278, PPL=353.37
2025-09-23 02:43:34,566 - training.trainer - INFO - Epoch 57, Step 194230: Loss=5.7820, Acc=0.200, PPL=324.42
2025-09-23 02:43:42,531 - training.trainer - INFO - Epoch 57, Step 194330: Loss=4.1991, Acc=0.389, PPL=66.63
2025-09-23 02:43:50,623 - training.trainer - INFO - Epoch 57, Step 194430: Loss=5.5369, Acc=0.180, PPL=253.89
2025-09-23 02:43:58,567 - training.trainer - INFO - Epoch 57, Step 194530: Loss=5.8793, Acc=0.321, PPL=357.56
2025-09-23 02:44:06,618 - training.trainer - INFO - Epoch 57, Step 194630: Loss=5.1305, Acc=0.355, PPL=169.10
2025-09-23 02:44:14,554 - training.trainer - INFO - Epoch 57, Step 194730: Loss=5.2960, Acc=0.320, PPL=199.54
2025-09-23 02:44:22,560 - training.trainer - INFO - Epoch 57, Step 194830: Loss=5.5041, Acc=0.250, PPL=245.69
2025-09-23 02:44:30,449 - training.trainer - INFO - Epoch 57, Step 194930: Loss=6.1968, Acc=0.288, PPL=491.19
2025-09-23 02:44:38,649 - training.trainer - INFO - Epoch 57, Step 195030: Loss=6.4285, Acc=0.240, PPL=619.24
2025-09-23 02:44:46,689 - training.trainer - INFO - Epoch 57, Step 195130: Loss=6.2860, Acc=0.140, PPL=536.99
2025-09-23 02:44:54,587 - training.trainer - INFO - Epoch 57, Step 195230: Loss=5.8229, Acc=0.212, PPL=337.94
2025-09-23 02:45:02,503 - training.trainer - INFO - Epoch 57, Step 195330: Loss=5.5378, Acc=0.259, PPL=254.11
2025-09-23 02:45:10,470 - training.trainer - INFO - Epoch 57, Step 195430: Loss=5.2738, Acc=0.357, PPL=195.15
2025-09-23 02:45:18,272 - training.trainer - INFO - Epoch 57, Step 195530: Loss=6.3055, Acc=0.242, PPL=547.57
2025-09-23 02:45:26,100 - training.trainer - INFO - Epoch 57, Step 195630: Loss=5.8566, Acc=0.273, PPL=349.55
2025-09-23 02:45:34,024 - training.trainer - INFO - Epoch 57, Step 195730: Loss=5.9939, Acc=0.269, PPL=400.97
2025-09-23 02:45:41,976 - training.trainer - INFO - Epoch 57, Step 195830: Loss=4.3302, Acc=0.429, PPL=75.96
2025-09-23 02:45:49,768 - training.trainer - INFO - Epoch 57, Step 195930: Loss=5.5749, Acc=0.261, PPL=263.71
2025-09-23 02:45:57,657 - training.trainer - INFO - Epoch 57, Step 196030: Loss=5.3662, Acc=0.302, PPL=214.05
2025-09-23 02:46:05,516 - training.trainer - INFO - Epoch 57, Step 196130: Loss=5.3777, Acc=0.250, PPL=216.53
2025-09-23 02:46:24,660 - training.trainer - INFO - Epoch 58/100 completed in 279.62s - Train Loss: 5.4820, Train Acc: 0.280, Val Loss: 5.6709, Val Acc: 0.255
2025-09-23 02:46:31,788 - training.trainer - INFO - Epoch 58, Step 196313: Loss=5.8422, Acc=0.217, PPL=344.53
2025-09-23 02:46:38,439 - training.trainer - INFO - Epoch 58, Step 196413: Loss=4.9609, Acc=0.316, PPL=142.72
2025-09-23 02:46:45,208 - training.trainer - INFO - Epoch 58, Step 196513: Loss=6.0068, Acc=0.206, PPL=406.19
2025-09-23 02:46:52,153 - training.trainer - INFO - Epoch 58, Step 196613: Loss=6.1871, Acc=0.283, PPL=486.46
2025-09-23 02:46:59,718 - training.trainer - INFO - Epoch 58, Step 196713: Loss=5.0509, Acc=0.240, PPL=156.17
2025-09-23 02:47:07,782 - training.trainer - INFO - Epoch 58, Step 196813: Loss=6.5993, Acc=0.231, PPL=734.60
2025-09-23 02:47:15,873 - training.trainer - INFO - Epoch 58, Step 196913: Loss=3.6877, Acc=0.418, PPL=39.95
2025-09-23 02:47:23,910 - training.trainer - INFO - Epoch 58, Step 197013: Loss=5.3812, Acc=0.300, PPL=217.28
2025-09-23 02:47:31,877 - training.trainer - INFO - Epoch 58, Step 197113: Loss=5.2416, Acc=0.269, PPL=188.98
2025-09-23 02:47:39,867 - training.trainer - INFO - Epoch 58, Step 197213: Loss=5.6660, Acc=0.292, PPL=288.87
2025-09-23 02:47:48,011 - training.trainer - INFO - Epoch 58, Step 197313: Loss=4.6529, Acc=0.321, PPL=104.89
2025-09-23 02:47:56,115 - training.trainer - INFO - Epoch 58, Step 197413: Loss=6.1495, Acc=0.250, PPL=468.47
2025-09-23 02:48:04,071 - training.trainer - INFO - Epoch 58, Step 197513: Loss=5.9567, Acc=0.292, PPL=386.34
2025-09-23 02:48:11,973 - training.trainer - INFO - Epoch 58, Step 197613: Loss=5.8220, Acc=0.238, PPL=337.66
2025-09-23 02:48:19,951 - training.trainer - INFO - Epoch 58, Step 197713: Loss=6.5435, Acc=0.214, PPL=694.69
2025-09-23 02:48:28,114 - training.trainer - INFO - Epoch 58, Step 197813: Loss=6.4016, Acc=0.226, PPL=602.80
2025-09-23 02:48:36,090 - training.trainer - INFO - Epoch 58, Step 197913: Loss=5.9030, Acc=0.242, PPL=366.12
2025-09-23 02:48:43,987 - training.trainer - INFO - Epoch 58, Step 198013: Loss=5.9364, Acc=0.219, PPL=378.58
2025-09-23 02:48:51,829 - training.trainer - INFO - Epoch 58, Step 198113: Loss=5.3456, Acc=0.383, PPL=209.69
2025-09-23 02:48:59,956 - training.trainer - INFO - Epoch 58, Step 198213: Loss=5.9598, Acc=0.179, PPL=387.55
2025-09-23 02:49:08,183 - training.trainer - INFO - Epoch 58, Step 198313: Loss=6.0662, Acc=0.273, PPL=431.02
2025-09-23 02:49:16,084 - training.trainer - INFO - Epoch 58, Step 198413: Loss=6.0403, Acc=0.233, PPL=420.01
2025-09-23 02:49:23,961 - training.trainer - INFO - Epoch 58, Step 198513: Loss=4.8773, Acc=0.318, PPL=131.27
2025-09-23 02:49:31,947 - training.trainer - INFO - Epoch 58, Step 198613: Loss=5.6639, Acc=0.241, PPL=288.28
2025-09-23 02:49:39,735 - training.trainer - INFO - Epoch 58, Step 198713: Loss=4.7781, Acc=0.308, PPL=118.88
2025-09-23 02:49:47,550 - training.trainer - INFO - Epoch 58, Step 198813: Loss=5.3953, Acc=0.259, PPL=220.36
2025-09-23 02:49:55,330 - training.trainer - INFO - Epoch 58, Step 198913: Loss=4.3698, Acc=0.474, PPL=79.03
2025-09-23 02:50:03,267 - training.trainer - INFO - Epoch 58, Step 199013: Loss=5.6708, Acc=0.257, PPL=290.26
2025-09-23 02:50:11,064 - training.trainer - INFO - Epoch 58, Step 199113: Loss=6.0419, Acc=0.235, PPL=420.70
2025-09-23 02:50:18,895 - training.trainer - INFO - Epoch 58, Step 199213: Loss=5.6294, Acc=0.276, PPL=278.48
2025-09-23 02:50:26,943 - training.trainer - INFO - Epoch 58, Step 199313: Loss=5.7235, Acc=0.206, PPL=305.97
2025-09-23 02:50:35,017 - training.trainer - INFO - Epoch 58, Step 199413: Loss=5.5651, Acc=0.241, PPL=261.16
2025-09-23 02:50:43,227 - training.trainer - INFO - Epoch 58, Step 199513: Loss=5.9433, Acc=0.250, PPL=381.17
2025-09-23 02:51:02,892 - training.trainer - INFO - Epoch 59/100 completed in 278.23s - Train Loss: 5.4694, Train Acc: 0.282, Val Loss: 5.6745, Val Acc: 0.255
2025-09-23 02:51:11,866 - training.trainer - INFO - Epoch 59, Step 199696: Loss=6.0425, Acc=0.208, PPL=420.95
2025-09-23 02:51:19,965 - training.trainer - INFO - Epoch 59, Step 199796: Loss=5.4849, Acc=0.286, PPL=241.04
2025-09-23 02:51:27,848 - training.trainer - INFO - Epoch 59, Step 199896: Loss=5.1063, Acc=0.471, PPL=165.05
2025-09-23 02:51:35,638 - training.trainer - INFO - Epoch 59, Step 199996: Loss=4.9419, Acc=0.333, PPL=140.03
2025-09-23 02:51:43,562 - training.trainer - INFO - Epoch 59, Step 200096: Loss=6.0431, Acc=0.237, PPL=421.19
2025-09-23 02:51:51,414 - training.trainer - INFO - Epoch 59, Step 200196: Loss=5.8410, Acc=0.250, PPL=344.12
2025-09-23 02:51:59,273 - training.trainer - INFO - Epoch 59, Step 200296: Loss=6.5880, Acc=0.186, PPL=726.30
2025-09-23 02:52:07,049 - training.trainer - INFO - Epoch 59, Step 200396: Loss=6.0731, Acc=0.194, PPL=434.03
2025-09-23 02:52:14,951 - training.trainer - INFO - Epoch 59, Step 200496: Loss=5.9907, Acc=0.224, PPL=399.68
2025-09-23 02:52:22,811 - training.trainer - INFO - Epoch 59, Step 200596: Loss=6.3044, Acc=0.286, PPL=546.96
2025-09-23 02:52:30,605 - training.trainer - INFO - Epoch 59, Step 200696: Loss=5.3353, Acc=0.282, PPL=207.54
2025-09-23 02:52:38,423 - training.trainer - INFO - Epoch 59, Step 200796: Loss=6.0363, Acc=0.231, PPL=418.35
2025-09-23 02:52:46,432 - training.trainer - INFO - Epoch 59, Step 200896: Loss=5.8651, Acc=0.206, PPL=352.52
2025-09-23 02:52:54,362 - training.trainer - INFO - Epoch 59, Step 200996: Loss=4.9562, Acc=0.167, PPL=142.05
2025-09-23 02:53:02,209 - training.trainer - INFO - Epoch 59, Step 201096: Loss=5.3469, Acc=0.391, PPL=209.97
2025-09-23 02:53:10,061 - training.trainer - INFO - Epoch 59, Step 201196: Loss=4.7829, Acc=0.375, PPL=119.46
2025-09-23 02:53:17,970 - training.trainer - INFO - Epoch 59, Step 201296: Loss=5.8412, Acc=0.235, PPL=344.18
2025-09-23 02:53:25,944 - training.trainer - INFO - Epoch 59, Step 201396: Loss=5.4954, Acc=0.271, PPL=243.56
2025-09-23 02:53:34,004 - training.trainer - INFO - Epoch 59, Step 201496: Loss=5.9106, Acc=0.188, PPL=368.94
2025-09-23 02:53:41,901 - training.trainer - INFO - Epoch 59, Step 201596: Loss=5.7879, Acc=0.235, PPL=326.32
2025-09-23 02:53:49,770 - training.trainer - INFO - Epoch 59, Step 201696: Loss=5.7529, Acc=0.210, PPL=315.10
2025-09-23 02:53:57,632 - training.trainer - INFO - Epoch 59, Step 201796: Loss=6.0642, Acc=0.188, PPL=430.19
2025-09-23 02:54:05,428 - training.trainer - INFO - Epoch 59, Step 201896: Loss=5.4112, Acc=0.233, PPL=223.90
2025-09-23 02:54:13,238 - training.trainer - INFO - Epoch 59, Step 201996: Loss=5.5992, Acc=0.220, PPL=270.20
2025-09-23 02:54:21,314 - training.trainer - INFO - Epoch 59, Step 202096: Loss=6.8911, Acc=0.143, PPL=983.46
2025-09-23 02:54:29,518 - training.trainer - INFO - Epoch 59, Step 202196: Loss=5.7797, Acc=0.235, PPL=323.66
2025-09-23 02:54:37,419 - training.trainer - INFO - Epoch 59, Step 202296: Loss=4.6455, Acc=0.429, PPL=104.12
2025-09-23 02:54:45,296 - training.trainer - INFO - Epoch 59, Step 202396: Loss=5.7849, Acc=0.207, PPL=325.36
2025-09-23 02:54:53,300 - training.trainer - INFO - Epoch 59, Step 202496: Loss=5.2013, Acc=0.405, PPL=181.52
2025-09-23 02:55:01,222 - training.trainer - INFO - Epoch 59, Step 202596: Loss=5.2362, Acc=0.270, PPL=187.95
2025-09-23 02:55:09,051 - training.trainer - INFO - Epoch 59, Step 202696: Loss=5.7933, Acc=0.286, PPL=328.10
2025-09-23 02:55:17,032 - training.trainer - INFO - Epoch 59, Step 202796: Loss=4.6668, Acc=0.371, PPL=106.36
2025-09-23 02:55:24,878 - training.trainer - INFO - Epoch 59, Step 202896: Loss=5.8140, Acc=0.270, PPL=334.94
2025-09-23 02:55:44,448 - training.trainer - INFO - Epoch 60/100 completed in 281.55s - Train Loss: 5.4723, Train Acc: 0.281, Val Loss: 5.6783, Val Acc: 0.253
2025-09-23 02:55:44,839 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_60.pt
2025-09-23 02:55:51,875 - training.trainer - INFO - Epoch 60, Step 203079: Loss=5.2029, Acc=0.310, PPL=181.80
2025-09-23 02:55:59,112 - training.trainer - INFO - Epoch 60, Step 203179: Loss=5.4326, Acc=0.299, PPL=228.75
2025-09-23 02:56:06,811 - training.trainer - INFO - Epoch 60, Step 203279: Loss=4.3843, Acc=0.500, PPL=80.18
2025-09-23 02:56:14,821 - training.trainer - INFO - Epoch 60, Step 203379: Loss=5.5764, Acc=0.316, PPL=264.11
2025-09-23 02:56:22,809 - training.trainer - INFO - Epoch 60, Step 203479: Loss=5.4262, Acc=0.227, PPL=227.29
2025-09-23 02:56:30,734 - training.trainer - INFO - Epoch 60, Step 203579: Loss=5.6865, Acc=0.240, PPL=294.86
2025-09-23 02:56:38,690 - training.trainer - INFO - Epoch 60, Step 203679: Loss=5.3704, Acc=0.317, PPL=214.94
2025-09-23 02:56:46,663 - training.trainer - INFO - Epoch 60, Step 203779: Loss=5.7718, Acc=0.167, PPL=321.12
2025-09-23 02:56:54,669 - training.trainer - INFO - Epoch 60, Step 203879: Loss=6.2498, Acc=0.191, PPL=517.88
2025-09-23 02:57:02,658 - training.trainer - INFO - Epoch 60, Step 203979: Loss=5.3928, Acc=0.267, PPL=219.81
2025-09-23 02:57:10,891 - training.trainer - INFO - Epoch 60, Step 204079: Loss=5.6813, Acc=0.300, PPL=293.34
2025-09-23 02:57:18,982 - training.trainer - INFO - Epoch 60, Step 204179: Loss=5.6498, Acc=0.267, PPL=284.24
2025-09-23 02:57:26,927 - training.trainer - INFO - Epoch 60, Step 204279: Loss=3.4563, Acc=0.389, PPL=31.70
2025-09-23 02:57:34,801 - training.trainer - INFO - Epoch 60, Step 204379: Loss=5.8812, Acc=0.250, PPL=358.26
2025-09-23 02:57:42,843 - training.trainer - INFO - Epoch 60, Step 204479: Loss=5.3619, Acc=0.361, PPL=213.12
2025-09-23 02:57:50,785 - training.trainer - INFO - Epoch 60, Step 204579: Loss=4.8178, Acc=0.333, PPL=123.69
2025-09-23 02:57:58,726 - training.trainer - INFO - Epoch 60, Step 204679: Loss=4.9740, Acc=0.333, PPL=144.60
2025-09-23 02:58:06,836 - training.trainer - INFO - Epoch 60, Step 204779: Loss=6.2990, Acc=0.176, PPL=544.00
2025-09-23 02:58:14,869 - training.trainer - INFO - Epoch 60, Step 204879: Loss=5.7676, Acc=0.265, PPL=319.78
2025-09-23 02:58:22,760 - training.trainer - INFO - Epoch 60, Step 204979: Loss=5.9606, Acc=0.267, PPL=387.84
2025-09-23 02:58:30,704 - training.trainer - INFO - Epoch 60, Step 205079: Loss=5.1444, Acc=0.471, PPL=171.47
2025-09-23 02:58:38,659 - training.trainer - INFO - Epoch 60, Step 205179: Loss=5.4303, Acc=0.229, PPL=228.22
2025-09-23 02:58:46,538 - training.trainer - INFO - Epoch 60, Step 205279: Loss=5.6347, Acc=0.273, PPL=279.96
2025-09-23 02:58:54,467 - training.trainer - INFO - Epoch 60, Step 205379: Loss=5.2677, Acc=0.370, PPL=193.98
2025-09-23 02:59:02,289 - training.trainer - INFO - Epoch 60, Step 205479: Loss=4.0602, Acc=0.375, PPL=57.99
2025-09-23 02:59:10,059 - training.trainer - INFO - Epoch 60, Step 205579: Loss=4.2358, Acc=0.483, PPL=69.12
2025-09-23 02:59:17,943 - training.trainer - INFO - Epoch 60, Step 205679: Loss=5.8606, Acc=0.250, PPL=350.92
2025-09-23 02:59:25,968 - training.trainer - INFO - Epoch 60, Step 205779: Loss=4.9798, Acc=0.375, PPL=145.44
2025-09-23 02:59:33,964 - training.trainer - INFO - Epoch 60, Step 205879: Loss=4.7204, Acc=0.364, PPL=112.21
2025-09-23 02:59:41,786 - training.trainer - INFO - Epoch 60, Step 205979: Loss=5.6834, Acc=0.286, PPL=293.95
2025-09-23 02:59:49,682 - training.trainer - INFO - Epoch 60, Step 206079: Loss=5.1514, Acc=0.200, PPL=172.68
2025-09-23 02:59:57,726 - training.trainer - INFO - Epoch 60, Step 206179: Loss=5.0645, Acc=0.385, PPL=158.30
2025-09-23 03:00:05,589 - training.trainer - INFO - Epoch 60, Step 206279: Loss=4.3989, Acc=0.435, PPL=81.36
2025-09-23 03:00:25,078 - training.trainer - INFO - Epoch 61/100 completed in 280.24s - Train Loss: 5.4653, Train Acc: 0.283, Val Loss: 5.6709, Val Acc: 0.254
2025-09-23 03:00:32,112 - training.trainer - INFO - Epoch 61, Step 206462: Loss=5.8871, Acc=0.250, PPL=360.35
2025-09-23 03:00:38,903 - training.trainer - INFO - Epoch 61, Step 206562: Loss=5.3010, Acc=0.216, PPL=200.54
2025-09-23 03:00:45,599 - training.trainer - INFO - Epoch 61, Step 206662: Loss=5.8744, Acc=0.241, PPL=355.82
2025-09-23 03:00:52,766 - training.trainer - INFO - Epoch 61, Step 206762: Loss=4.5118, Acc=0.400, PPL=91.08
2025-09-23 03:01:00,867 - training.trainer - INFO - Epoch 61, Step 206862: Loss=5.2639, Acc=0.260, PPL=193.23
2025-09-23 03:01:08,852 - training.trainer - INFO - Epoch 61, Step 206962: Loss=5.4716, Acc=0.349, PPL=237.84
2025-09-23 03:01:16,702 - training.trainer - INFO - Epoch 61, Step 207062: Loss=3.5837, Acc=0.630, PPL=36.01
2025-09-23 03:01:24,624 - training.trainer - INFO - Epoch 61, Step 207162: Loss=5.6050, Acc=0.257, PPL=271.77
2025-09-23 03:01:32,598 - training.trainer - INFO - Epoch 61, Step 207262: Loss=5.9013, Acc=0.208, PPL=365.51
2025-09-23 03:01:40,433 - training.trainer - INFO - Epoch 61, Step 207362: Loss=5.5829, Acc=0.267, PPL=265.84
2025-09-23 03:01:48,291 - training.trainer - INFO - Epoch 61, Step 207462: Loss=6.0166, Acc=0.103, PPL=410.18
2025-09-23 03:01:56,233 - training.trainer - INFO - Epoch 61, Step 207562: Loss=5.1298, Acc=0.281, PPL=168.99
2025-09-23 03:02:04,596 - training.trainer - INFO - Epoch 61, Step 207662: Loss=5.2465, Acc=0.292, PPL=189.91
2025-09-23 03:02:12,829 - training.trainer - INFO - Epoch 61, Step 207762: Loss=5.8044, Acc=0.254, PPL=331.76
2025-09-23 03:02:20,709 - training.trainer - INFO - Epoch 61, Step 207862: Loss=4.7464, Acc=0.517, PPL=115.17
2025-09-23 03:02:28,816 - training.trainer - INFO - Epoch 61, Step 207962: Loss=4.7718, Acc=0.387, PPL=118.14
2025-09-23 03:02:36,872 - training.trainer - INFO - Epoch 61, Step 208062: Loss=5.3101, Acc=0.250, PPL=202.36
2025-09-23 03:02:44,856 - training.trainer - INFO - Epoch 61, Step 208162: Loss=4.4288, Acc=0.345, PPL=83.83
2025-09-23 03:02:52,813 - training.trainer - INFO - Epoch 61, Step 208262: Loss=5.3863, Acc=0.342, PPL=218.39
2025-09-23 03:03:00,770 - training.trainer - INFO - Epoch 61, Step 208362: Loss=4.7791, Acc=0.474, PPL=119.00
2025-09-23 03:03:08,694 - training.trainer - INFO - Epoch 61, Step 208462: Loss=5.3346, Acc=0.349, PPL=207.39
2025-09-23 03:03:16,562 - training.trainer - INFO - Epoch 61, Step 208562: Loss=5.9575, Acc=0.203, PPL=386.65
2025-09-23 03:03:24,465 - training.trainer - INFO - Epoch 61, Step 208662: Loss=4.1361, Acc=0.448, PPL=62.56
2025-09-23 03:03:32,299 - training.trainer - INFO - Epoch 61, Step 208762: Loss=5.9796, Acc=0.276, PPL=395.30
2025-09-23 03:03:40,224 - training.trainer - INFO - Epoch 61, Step 208862: Loss=5.5507, Acc=0.158, PPL=257.41
2025-09-23 03:03:48,125 - training.trainer - INFO - Epoch 61, Step 208962: Loss=6.2001, Acc=0.205, PPL=492.80
2025-09-23 03:03:55,950 - training.trainer - INFO - Epoch 61, Step 209062: Loss=5.4801, Acc=0.269, PPL=239.87
2025-09-23 03:04:03,927 - training.trainer - INFO - Epoch 61, Step 209162: Loss=5.2820, Acc=0.268, PPL=196.77
2025-09-23 03:04:11,838 - training.trainer - INFO - Epoch 61, Step 209262: Loss=5.6559, Acc=0.231, PPL=285.98
2025-09-23 03:04:19,872 - training.trainer - INFO - Epoch 61, Step 209362: Loss=5.5964, Acc=0.297, PPL=269.44
2025-09-23 03:04:27,799 - training.trainer - INFO - Epoch 61, Step 209462: Loss=4.8638, Acc=0.350, PPL=129.51
2025-09-23 03:04:35,585 - training.trainer - INFO - Epoch 61, Step 209562: Loss=5.7655, Acc=0.208, PPL=319.11
2025-09-23 03:04:43,389 - training.trainer - INFO - Epoch 61, Step 209662: Loss=6.2950, Acc=0.200, PPL=541.86
2025-09-23 03:05:03,168 - training.trainer - INFO - Epoch 62/100 completed in 278.09s - Train Loss: 5.4540, Train Acc: 0.285, Val Loss: 5.6786, Val Acc: 0.252
2025-09-23 03:05:11,544 - training.trainer - INFO - Epoch 62, Step 209845: Loss=5.2584, Acc=0.314, PPL=192.18
2025-09-23 03:05:19,455 - training.trainer - INFO - Epoch 62, Step 209945: Loss=4.9735, Acc=0.375, PPL=144.54
2025-09-23 03:05:27,583 - training.trainer - INFO - Epoch 62, Step 210045: Loss=5.2432, Acc=0.192, PPL=189.27
2025-09-23 03:05:35,536 - training.trainer - INFO - Epoch 62, Step 210145: Loss=3.8096, Acc=0.400, PPL=45.13
2025-09-23 03:05:43,512 - training.trainer - INFO - Epoch 62, Step 210245: Loss=5.4173, Acc=0.324, PPL=225.28
2025-09-23 03:05:51,484 - training.trainer - INFO - Epoch 62, Step 210345: Loss=4.1282, Acc=0.467, PPL=62.06
2025-09-23 03:05:59,491 - training.trainer - INFO - Epoch 62, Step 210445: Loss=5.5278, Acc=0.154, PPL=251.58
2025-09-23 03:06:07,481 - training.trainer - INFO - Epoch 62, Step 210545: Loss=5.1587, Acc=0.276, PPL=173.94
2025-09-23 03:06:15,572 - training.trainer - INFO - Epoch 62, Step 210645: Loss=5.1874, Acc=0.250, PPL=179.00
2025-09-23 03:06:23,640 - training.trainer - INFO - Epoch 62, Step 210745: Loss=5.9215, Acc=0.214, PPL=372.98
2025-09-23 03:06:31,606 - training.trainer - INFO - Epoch 62, Step 210845: Loss=4.3091, Acc=0.409, PPL=74.37
2025-09-23 03:06:39,670 - training.trainer - INFO - Epoch 62, Step 210945: Loss=5.7109, Acc=0.227, PPL=302.13
2025-09-23 03:06:47,600 - training.trainer - INFO - Epoch 62, Step 211045: Loss=4.1637, Acc=0.423, PPL=64.31
2025-09-23 03:06:55,581 - training.trainer - INFO - Epoch 62, Step 211145: Loss=5.2387, Acc=0.250, PPL=188.43
2025-09-23 03:07:03,629 - training.trainer - INFO - Epoch 62, Step 211245: Loss=5.9551, Acc=0.194, PPL=385.73
2025-09-23 03:07:11,612 - training.trainer - INFO - Epoch 62, Step 211345: Loss=5.0749, Acc=0.258, PPL=159.95
2025-09-23 03:07:19,615 - training.trainer - INFO - Epoch 62, Step 211445: Loss=6.3116, Acc=0.210, PPL=550.93
2025-09-23 03:07:27,593 - training.trainer - INFO - Epoch 62, Step 211545: Loss=4.8515, Acc=0.336, PPL=127.93
2025-09-23 03:07:35,622 - training.trainer - INFO - Epoch 62, Step 211645: Loss=5.5069, Acc=0.262, PPL=246.39
2025-09-23 03:07:43,561 - training.trainer - INFO - Epoch 62, Step 211745: Loss=5.3980, Acc=0.257, PPL=220.97
2025-09-23 03:07:51,411 - training.trainer - INFO - Epoch 62, Step 211845: Loss=6.1503, Acc=0.245, PPL=468.87
2025-09-23 03:07:59,329 - training.trainer - INFO - Epoch 62, Step 211945: Loss=5.8842, Acc=0.171, PPL=359.32
2025-09-23 03:08:07,424 - training.trainer - INFO - Epoch 62, Step 212045: Loss=5.6361, Acc=0.189, PPL=280.37
2025-09-23 03:08:15,391 - training.trainer - INFO - Epoch 62, Step 212145: Loss=5.4338, Acc=0.200, PPL=229.02
2025-09-23 03:08:23,208 - training.trainer - INFO - Epoch 62, Step 212245: Loss=5.6336, Acc=0.364, PPL=279.66
2025-09-23 03:08:31,107 - training.trainer - INFO - Epoch 62, Step 212345: Loss=5.3453, Acc=0.279, PPL=209.62
2025-09-23 03:08:39,164 - training.trainer - INFO - Epoch 62, Step 212445: Loss=5.5929, Acc=0.275, PPL=268.51
2025-09-23 03:08:47,085 - training.trainer - INFO - Epoch 62, Step 212545: Loss=5.2856, Acc=0.371, PPL=197.47
2025-09-23 03:08:54,914 - training.trainer - INFO - Epoch 62, Step 212645: Loss=5.3679, Acc=0.281, PPL=214.42
2025-09-23 03:09:02,772 - training.trainer - INFO - Epoch 62, Step 212745: Loss=5.3836, Acc=0.300, PPL=217.81
2025-09-23 03:09:11,082 - training.trainer - INFO - Epoch 62, Step 212845: Loss=5.2925, Acc=0.275, PPL=198.83
2025-09-23 03:09:18,936 - training.trainer - INFO - Epoch 62, Step 212945: Loss=6.0053, Acc=0.208, PPL=405.57
2025-09-23 03:09:26,814 - training.trainer - INFO - Epoch 62, Step 213045: Loss=5.4775, Acc=0.422, PPL=239.26
2025-09-23 03:09:46,677 - training.trainer - INFO - Epoch 63/100 completed in 283.51s - Train Loss: 5.4465, Train Acc: 0.286, Val Loss: 5.6652, Val Acc: 0.254
2025-09-23 03:09:47,515 - training.trainer - INFO - New best model saved with validation loss: 5.6652
2025-09-23 03:09:47,515 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_63.pt
2025-09-23 03:09:55,703 - training.trainer - INFO - Epoch 63, Step 213228: Loss=6.5661, Acc=0.173, PPL=710.58
2025-09-23 03:10:03,739 - training.trainer - INFO - Epoch 63, Step 213328: Loss=5.8873, Acc=0.160, PPL=360.42
2025-09-23 03:10:11,898 - training.trainer - INFO - Epoch 63, Step 213428: Loss=4.9622, Acc=0.304, PPL=142.90
2025-09-23 03:10:19,842 - training.trainer - INFO - Epoch 63, Step 213528: Loss=6.1517, Acc=0.333, PPL=469.52
2025-09-23 03:10:27,754 - training.trainer - INFO - Epoch 63, Step 213628: Loss=5.4669, Acc=0.308, PPL=236.72
2025-09-23 03:10:35,646 - training.trainer - INFO - Epoch 63, Step 213728: Loss=4.7353, Acc=0.385, PPL=113.90
2025-09-23 03:10:43,624 - training.trainer - INFO - Epoch 63, Step 213828: Loss=5.2630, Acc=0.317, PPL=193.07
2025-09-23 03:10:51,847 - training.trainer - INFO - Epoch 63, Step 213928: Loss=5.5838, Acc=0.347, PPL=266.08
2025-09-23 03:10:59,807 - training.trainer - INFO - Epoch 63, Step 214028: Loss=4.6344, Acc=0.349, PPL=102.97
2025-09-23 03:11:07,737 - training.trainer - INFO - Epoch 63, Step 214128: Loss=5.1765, Acc=0.340, PPL=177.07
2025-09-23 03:11:15,595 - training.trainer - INFO - Epoch 63, Step 214228: Loss=5.1986, Acc=0.231, PPL=181.01
2025-09-23 03:11:23,675 - training.trainer - INFO - Epoch 63, Step 214328: Loss=5.3523, Acc=0.250, PPL=211.10
2025-09-23 03:11:31,569 - training.trainer - INFO - Epoch 63, Step 214428: Loss=4.0615, Acc=0.385, PPL=58.06
2025-09-23 03:11:39,485 - training.trainer - INFO - Epoch 63, Step 214528: Loss=6.2633, Acc=0.167, PPL=524.96
2025-09-23 03:11:47,619 - training.trainer - INFO - Epoch 63, Step 214628: Loss=6.0091, Acc=0.188, PPL=407.11
2025-09-23 03:11:55,622 - training.trainer - INFO - Epoch 63, Step 214728: Loss=5.3601, Acc=0.262, PPL=212.74
2025-09-23 03:12:03,497 - training.trainer - INFO - Epoch 63, Step 214828: Loss=6.0335, Acc=0.224, PPL=417.18
2025-09-23 03:12:11,399 - training.trainer - INFO - Epoch 63, Step 214928: Loss=3.6770, Acc=0.593, PPL=39.53
2025-09-23 03:12:19,302 - training.trainer - INFO - Epoch 63, Step 215028: Loss=5.2983, Acc=0.234, PPL=200.01
2025-09-23 03:12:27,232 - training.trainer - INFO - Epoch 63, Step 215128: Loss=5.3987, Acc=0.302, PPL=221.12
2025-09-23 03:12:35,003 - training.trainer - INFO - Epoch 63, Step 215228: Loss=4.5325, Acc=0.469, PPL=92.99
2025-09-23 03:12:42,875 - training.trainer - INFO - Epoch 63, Step 215328: Loss=5.6512, Acc=0.207, PPL=284.64
2025-09-23 03:12:50,688 - training.trainer - INFO - Epoch 63, Step 215428: Loss=5.7778, Acc=0.220, PPL=323.06
2025-09-23 03:12:58,617 - training.trainer - INFO - Epoch 63, Step 215528: Loss=6.4558, Acc=0.192, PPL=636.37
2025-09-23 03:13:06,572 - training.trainer - INFO - Epoch 63, Step 215628: Loss=5.5432, Acc=0.308, PPL=255.48
2025-09-23 03:13:14,393 - training.trainer - INFO - Epoch 63, Step 215728: Loss=5.7413, Acc=0.276, PPL=311.46
2025-09-23 03:13:22,242 - training.trainer - INFO - Epoch 63, Step 215828: Loss=5.0577, Acc=0.357, PPL=157.23
2025-09-23 03:13:30,148 - training.trainer - INFO - Epoch 63, Step 215928: Loss=5.9173, Acc=0.276, PPL=371.41
2025-09-23 03:13:38,029 - training.trainer - INFO - Epoch 63, Step 216028: Loss=3.6870, Acc=0.444, PPL=39.92
2025-09-23 03:13:45,931 - training.trainer - INFO - Epoch 63, Step 216128: Loss=4.9706, Acc=0.240, PPL=144.12
2025-09-23 03:13:53,836 - training.trainer - INFO - Epoch 63, Step 216228: Loss=4.5935, Acc=0.438, PPL=98.84
2025-09-23 03:14:01,772 - training.trainer - INFO - Epoch 63, Step 216328: Loss=5.5183, Acc=0.324, PPL=249.21
2025-09-23 03:14:09,691 - training.trainer - INFO - Epoch 63, Step 216428: Loss=6.1778, Acc=0.140, PPL=481.91
2025-09-23 03:14:29,026 - training.trainer - INFO - Epoch 64/100 completed in 281.51s - Train Loss: 5.4531, Train Acc: 0.286, Val Loss: 5.6648, Val Acc: 0.257
2025-09-23 03:14:29,851 - training.trainer - INFO - New best model saved with validation loss: 5.6648
2025-09-23 03:14:29,851 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_64.pt
2025-09-23 03:14:37,085 - training.trainer - INFO - Epoch 64, Step 216611: Loss=5.4449, Acc=0.217, PPL=231.57
2025-09-23 03:14:44,806 - training.trainer - INFO - Epoch 64, Step 216711: Loss=5.1373, Acc=0.281, PPL=170.25
2025-09-23 03:14:52,925 - training.trainer - INFO - Epoch 64, Step 216811: Loss=5.9687, Acc=0.268, PPL=390.99
2025-09-23 03:15:01,040 - training.trainer - INFO - Epoch 64, Step 216911: Loss=5.4167, Acc=0.310, PPL=225.14
2025-09-23 03:15:08,979 - training.trainer - INFO - Epoch 64, Step 217011: Loss=5.3441, Acc=0.294, PPL=209.36
2025-09-23 03:15:17,011 - training.trainer - INFO - Epoch 64, Step 217111: Loss=5.7289, Acc=0.214, PPL=307.63
2025-09-23 03:15:24,678 - training.trainer - INFO - Epoch 64, Step 217211: Loss=5.6235, Acc=0.316, PPL=276.86
2025-09-23 03:15:32,584 - training.trainer - INFO - Epoch 64, Step 217311: Loss=4.6744, Acc=0.344, PPL=107.17
2025-09-23 03:15:40,648 - training.trainer - INFO - Epoch 64, Step 217411: Loss=5.5752, Acc=0.233, PPL=263.81
2025-09-23 03:15:48,692 - training.trainer - INFO - Epoch 64, Step 217511: Loss=4.7851, Acc=0.308, PPL=119.72
2025-09-23 03:15:56,585 - training.trainer - INFO - Epoch 64, Step 217611: Loss=5.8227, Acc=0.130, PPL=337.87
2025-09-23 03:16:04,455 - training.trainer - INFO - Epoch 64, Step 217711: Loss=5.6962, Acc=0.300, PPL=297.72
2025-09-23 03:16:12,463 - training.trainer - INFO - Epoch 64, Step 217811: Loss=5.6665, Acc=0.345, PPL=289.01
2025-09-23 03:16:20,380 - training.trainer - INFO - Epoch 64, Step 217911: Loss=4.2483, Acc=0.474, PPL=69.99
2025-09-23 03:16:28,276 - training.trainer - INFO - Epoch 64, Step 218011: Loss=5.7914, Acc=0.276, PPL=327.48
2025-09-23 03:16:36,235 - training.trainer - INFO - Epoch 64, Step 218111: Loss=6.1318, Acc=0.237, PPL=460.28
2025-09-23 03:16:44,084 - training.trainer - INFO - Epoch 64, Step 218211: Loss=5.5786, Acc=0.257, PPL=264.71
2025-09-23 03:16:52,050 - training.trainer - INFO - Epoch 64, Step 218311: Loss=6.1383, Acc=0.231, PPL=463.26
2025-09-23 03:16:59,983 - training.trainer - INFO - Epoch 64, Step 218411: Loss=5.4580, Acc=0.242, PPL=234.63
2025-09-23 03:17:07,874 - training.trainer - INFO - Epoch 64, Step 218511: Loss=4.5076, Acc=0.500, PPL=90.70
2025-09-23 03:17:15,774 - training.trainer - INFO - Epoch 64, Step 218611: Loss=6.0987, Acc=0.245, PPL=445.30
2025-09-23 03:17:23,821 - training.trainer - INFO - Epoch 64, Step 218711: Loss=5.6868, Acc=0.333, PPL=294.94
2025-09-23 03:17:31,767 - training.trainer - INFO - Epoch 64, Step 218811: Loss=5.4792, Acc=0.250, PPL=239.67
2025-09-23 03:17:39,736 - training.trainer - INFO - Epoch 64, Step 218911: Loss=5.1880, Acc=0.325, PPL=179.11
2025-09-23 03:17:47,639 - training.trainer - INFO - Epoch 64, Step 219011: Loss=6.0270, Acc=0.236, PPL=414.45
2025-09-23 03:17:55,696 - training.trainer - INFO - Epoch 64, Step 219111: Loss=4.9156, Acc=0.231, PPL=136.40
2025-09-23 03:18:03,588 - training.trainer - INFO - Epoch 64, Step 219211: Loss=4.9417, Acc=0.333, PPL=140.00
2025-09-23 03:18:11,439 - training.trainer - INFO - Epoch 64, Step 219311: Loss=5.2158, Acc=0.292, PPL=184.16
2025-09-23 03:18:19,280 - training.trainer - INFO - Epoch 64, Step 219411: Loss=5.4868, Acc=0.348, PPL=241.49
2025-09-23 03:18:27,427 - training.trainer - INFO - Epoch 64, Step 219511: Loss=6.6719, Acc=0.167, PPL=789.92
2025-09-23 03:18:35,324 - training.trainer - INFO - Epoch 64, Step 219611: Loss=4.2794, Acc=0.382, PPL=72.20
2025-09-23 03:18:43,133 - training.trainer - INFO - Epoch 64, Step 219711: Loss=5.4106, Acc=0.302, PPL=223.78
2025-09-23 03:18:50,962 - training.trainer - INFO - Epoch 64, Step 219811: Loss=4.7862, Acc=0.333, PPL=119.84
2025-09-23 03:19:10,602 - training.trainer - INFO - Epoch 65/100 completed in 280.75s - Train Loss: 5.4483, Train Acc: 0.286, Val Loss: 5.6765, Val Acc: 0.256
2025-09-23 03:19:11,015 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_65.pt
2025-09-23 03:19:19,362 - training.trainer - INFO - Epoch 65, Step 219994: Loss=5.4241, Acc=0.286, PPL=226.81
2025-09-23 03:19:27,348 - training.trainer - INFO - Epoch 65, Step 220094: Loss=5.9692, Acc=0.229, PPL=391.21
2025-09-23 03:19:35,474 - training.trainer - INFO - Epoch 65, Step 220194: Loss=5.1641, Acc=0.367, PPL=174.87
2025-09-23 03:19:43,490 - training.trainer - INFO - Epoch 65, Step 220294: Loss=4.2289, Acc=0.400, PPL=68.64
2025-09-23 03:19:51,566 - training.trainer - INFO - Epoch 65, Step 220394: Loss=5.5444, Acc=0.311, PPL=255.80
2025-09-23 03:19:59,576 - training.trainer - INFO - Epoch 65, Step 220494: Loss=5.7212, Acc=0.283, PPL=305.26
2025-09-23 03:20:07,675 - training.trainer - INFO - Epoch 65, Step 220594: Loss=5.5024, Acc=0.231, PPL=245.28
2025-09-23 03:20:15,615 - training.trainer - INFO - Epoch 65, Step 220694: Loss=5.4072, Acc=0.179, PPL=223.01
2025-09-23 03:20:23,675 - training.trainer - INFO - Epoch 65, Step 220794: Loss=5.8283, Acc=0.289, PPL=339.79
2025-09-23 03:20:31,610 - training.trainer - INFO - Epoch 65, Step 220894: Loss=5.0972, Acc=0.235, PPL=163.57
2025-09-23 03:20:39,603 - training.trainer - INFO - Epoch 65, Step 220994: Loss=5.2898, Acc=0.342, PPL=198.30
2025-09-23 03:20:47,455 - training.trainer - INFO - Epoch 65, Step 221094: Loss=3.7453, Acc=0.515, PPL=42.32
2025-09-23 03:20:55,321 - training.trainer - INFO - Epoch 65, Step 221194: Loss=5.8313, Acc=0.273, PPL=340.80
2025-09-23 03:21:03,196 - training.trainer - INFO - Epoch 65, Step 221294: Loss=5.7255, Acc=0.450, PPL=306.59
2025-09-23 03:21:11,197 - training.trainer - INFO - Epoch 65, Step 221394: Loss=5.6216, Acc=0.289, PPL=276.34
2025-09-23 03:21:19,115 - training.trainer - INFO - Epoch 65, Step 221494: Loss=5.6363, Acc=0.200, PPL=280.41
2025-09-23 03:21:27,089 - training.trainer - INFO - Epoch 65, Step 221594: Loss=5.6469, Acc=0.250, PPL=283.42
2025-09-23 03:21:35,034 - training.trainer - INFO - Epoch 65, Step 221694: Loss=5.5571, Acc=0.273, PPL=259.07
2025-09-23 03:21:42,992 - training.trainer - INFO - Epoch 65, Step 221794: Loss=4.7500, Acc=0.385, PPL=115.58
2025-09-23 03:21:51,040 - training.trainer - INFO - Epoch 65, Step 221894: Loss=4.5137, Acc=0.435, PPL=91.26
2025-09-23 03:21:59,278 - training.trainer - INFO - Epoch 65, Step 221994: Loss=5.8378, Acc=0.239, PPL=343.03
2025-09-23 03:22:07,473 - training.trainer - INFO - Epoch 65, Step 222094: Loss=3.8128, Acc=0.545, PPL=45.28
2025-09-23 03:22:15,687 - training.trainer - INFO - Epoch 65, Step 222194: Loss=5.5499, Acc=0.306, PPL=257.22
2025-09-23 03:22:23,712 - training.trainer - INFO - Epoch 65, Step 222294: Loss=5.1771, Acc=0.268, PPL=177.16
2025-09-23 03:22:31,590 - training.trainer - INFO - Epoch 65, Step 222394: Loss=5.3149, Acc=0.314, PPL=203.35
2025-09-23 03:22:39,633 - training.trainer - INFO - Epoch 65, Step 222494: Loss=5.6741, Acc=0.267, PPL=291.22
2025-09-23 03:22:47,640 - training.trainer - INFO - Epoch 65, Step 222594: Loss=5.8905, Acc=0.286, PPL=361.60
2025-09-23 03:22:55,636 - training.trainer - INFO - Epoch 65, Step 222694: Loss=5.4569, Acc=0.291, PPL=234.36
2025-09-23 03:23:03,542 - training.trainer - INFO - Epoch 65, Step 222794: Loss=5.9381, Acc=0.120, PPL=379.19
2025-09-23 03:23:11,457 - training.trainer - INFO - Epoch 65, Step 222894: Loss=4.9596, Acc=0.310, PPL=142.53
2025-09-23 03:23:19,417 - training.trainer - INFO - Epoch 65, Step 222994: Loss=6.0083, Acc=0.311, PPL=406.79
2025-09-23 03:23:27,533 - training.trainer - INFO - Epoch 65, Step 223094: Loss=5.4736, Acc=0.312, PPL=238.31
2025-09-23 03:23:35,424 - training.trainer - INFO - Epoch 65, Step 223194: Loss=5.3595, Acc=0.222, PPL=212.61
2025-09-23 03:23:55,026 - training.trainer - INFO - Epoch 66/100 completed in 284.01s - Train Loss: 5.4373, Train Acc: 0.288, Val Loss: 5.6675, Val Acc: 0.256
2025-09-23 03:24:02,277 - training.trainer - INFO - Epoch 66, Step 223377: Loss=5.4941, Acc=0.255, PPL=243.24
2025-09-23 03:24:09,686 - training.trainer - INFO - Epoch 66, Step 223477: Loss=6.3241, Acc=0.197, PPL=557.86
2025-09-23 03:24:16,787 - training.trainer - INFO - Epoch 66, Step 223577: Loss=5.7748, Acc=0.214, PPL=322.08
2025-09-23 03:24:24,616 - training.trainer - INFO - Epoch 66, Step 223677: Loss=4.9561, Acc=0.350, PPL=142.04
2025-09-23 03:24:32,421 - training.trainer - INFO - Epoch 66, Step 223777: Loss=3.7375, Acc=0.607, PPL=41.99
2025-09-23 03:24:40,348 - training.trainer - INFO - Epoch 66, Step 223877: Loss=4.2068, Acc=0.407, PPL=67.14
2025-09-23 03:24:48,273 - training.trainer - INFO - Epoch 66, Step 223977: Loss=5.9586, Acc=0.231, PPL=387.09
2025-09-23 03:24:56,423 - training.trainer - INFO - Epoch 66, Step 224077: Loss=4.4542, Acc=0.360, PPL=85.98
2025-09-23 03:25:04,648 - training.trainer - INFO - Epoch 66, Step 224177: Loss=5.4047, Acc=0.241, PPL=222.45
2025-09-23 03:25:12,746 - training.trainer - INFO - Epoch 66, Step 224277: Loss=5.6275, Acc=0.250, PPL=277.97
2025-09-23 03:25:20,832 - training.trainer - INFO - Epoch 66, Step 224377: Loss=5.3169, Acc=0.309, PPL=203.74
2025-09-23 03:25:29,170 - training.trainer - INFO - Epoch 66, Step 224477: Loss=4.8428, Acc=0.478, PPL=126.83
2025-09-23 03:25:37,250 - training.trainer - INFO - Epoch 66, Step 224577: Loss=6.1741, Acc=0.300, PPL=480.13
2025-09-23 03:25:45,054 - training.trainer - INFO - Epoch 66, Step 224677: Loss=5.0706, Acc=0.333, PPL=159.27
2025-09-23 03:25:52,795 - training.trainer - INFO - Epoch 66, Step 224777: Loss=5.7047, Acc=0.300, PPL=300.28
2025-09-23 03:26:00,654 - training.trainer - INFO - Epoch 66, Step 224877: Loss=3.8707, Acc=0.512, PPL=47.98
2025-09-23 03:26:08,655 - training.trainer - INFO - Epoch 66, Step 224977: Loss=5.8876, Acc=0.270, PPL=360.55
2025-09-23 03:26:16,436 - training.trainer - INFO - Epoch 66, Step 225077: Loss=5.4374, Acc=0.243, PPL=229.85
2025-09-23 03:26:24,189 - training.trainer - INFO - Epoch 66, Step 225177: Loss=4.3964, Acc=0.296, PPL=81.16
2025-09-23 03:26:32,012 - training.trainer - INFO - Epoch 66, Step 225277: Loss=5.7049, Acc=0.244, PPL=300.34
2025-09-23 03:26:40,102 - training.trainer - INFO - Epoch 66, Step 225377: Loss=6.2962, Acc=0.125, PPL=542.51
2025-09-23 03:26:48,013 - training.trainer - INFO - Epoch 66, Step 225477: Loss=5.4282, Acc=0.111, PPL=227.73
2025-09-23 03:26:55,833 - training.trainer - INFO - Epoch 66, Step 225577: Loss=4.8490, Acc=0.286, PPL=127.61
2025-09-23 03:27:03,646 - training.trainer - INFO - Epoch 66, Step 225677: Loss=3.9517, Acc=0.400, PPL=52.02
2025-09-23 03:27:11,611 - training.trainer - INFO - Epoch 66, Step 225777: Loss=4.9303, Acc=0.302, PPL=138.42
2025-09-23 03:27:19,441 - training.trainer - INFO - Epoch 66, Step 225877: Loss=6.1857, Acc=0.233, PPL=485.73
2025-09-23 03:27:27,221 - training.trainer - INFO - Epoch 66, Step 225977: Loss=6.3143, Acc=0.213, PPL=552.39
2025-09-23 03:27:35,037 - training.trainer - INFO - Epoch 66, Step 226077: Loss=5.4979, Acc=0.250, PPL=244.18
2025-09-23 03:27:42,896 - training.trainer - INFO - Epoch 66, Step 226177: Loss=5.5498, Acc=0.349, PPL=257.18
2025-09-23 03:27:50,885 - training.trainer - INFO - Epoch 66, Step 226277: Loss=5.2497, Acc=0.257, PPL=190.51
2025-09-23 03:27:58,752 - training.trainer - INFO - Epoch 66, Step 226377: Loss=4.4080, Acc=0.400, PPL=82.11
2025-09-23 03:28:06,596 - training.trainer - INFO - Epoch 66, Step 226477: Loss=6.6158, Acc=0.144, PPL=746.78
2025-09-23 03:28:14,407 - training.trainer - INFO - Epoch 66, Step 226577: Loss=5.6662, Acc=0.239, PPL=288.93
2025-09-23 03:28:33,925 - training.trainer - INFO - Epoch 67/100 completed in 278.90s - Train Loss: 5.4367, Train Acc: 0.287, Val Loss: 5.6798, Val Acc: 0.255
2025-09-23 03:28:40,849 - training.trainer - INFO - Epoch 67, Step 226760: Loss=5.2410, Acc=0.250, PPL=188.86
2025-09-23 03:28:47,547 - training.trainer - INFO - Epoch 67, Step 226860: Loss=5.2836, Acc=0.328, PPL=197.07
2025-09-23 03:28:54,266 - training.trainer - INFO - Epoch 67, Step 226960: Loss=5.8441, Acc=0.217, PPL=345.20
2025-09-23 03:29:00,894 - training.trainer - INFO - Epoch 67, Step 227060: Loss=5.8122, Acc=0.263, PPL=334.36
2025-09-23 03:29:07,587 - training.trainer - INFO - Epoch 67, Step 227160: Loss=5.4057, Acc=0.273, PPL=222.66
2025-09-23 03:29:15,518 - training.trainer - INFO - Epoch 67, Step 227260: Loss=5.3325, Acc=0.275, PPL=206.96
2025-09-23 03:29:23,602 - training.trainer - INFO - Epoch 67, Step 227360: Loss=5.4816, Acc=0.269, PPL=240.22
2025-09-23 03:29:31,517 - training.trainer - INFO - Epoch 67, Step 227460: Loss=3.9696, Acc=0.533, PPL=52.96
2025-09-23 03:29:39,489 - training.trainer - INFO - Epoch 67, Step 227560: Loss=5.6381, Acc=0.195, PPL=280.92
2025-09-23 03:29:47,378 - training.trainer - INFO - Epoch 67, Step 227660: Loss=3.3539, Acc=0.565, PPL=28.62
2025-09-23 03:29:55,321 - training.trainer - INFO - Epoch 67, Step 227760: Loss=4.8155, Acc=0.265, PPL=123.41
2025-09-23 03:30:03,103 - training.trainer - INFO - Epoch 67, Step 227860: Loss=5.3193, Acc=0.265, PPL=204.23
2025-09-23 03:30:10,960 - training.trainer - INFO - Epoch 67, Step 227960: Loss=5.4534, Acc=0.235, PPL=233.56
2025-09-23 03:30:18,780 - training.trainer - INFO - Epoch 67, Step 228060: Loss=4.7580, Acc=0.318, PPL=116.52
2025-09-23 03:30:26,616 - training.trainer - INFO - Epoch 67, Step 228160: Loss=5.1551, Acc=0.324, PPL=173.31
2025-09-23 03:30:34,615 - training.trainer - INFO - Epoch 67, Step 228260: Loss=4.9269, Acc=0.333, PPL=137.95
2025-09-23 03:30:42,536 - training.trainer - INFO - Epoch 67, Step 228360: Loss=5.5031, Acc=0.214, PPL=245.45
2025-09-23 03:30:50,440 - training.trainer - INFO - Epoch 67, Step 228460: Loss=6.5776, Acc=0.196, PPL=718.84
2025-09-23 03:30:58,312 - training.trainer - INFO - Epoch 67, Step 228560: Loss=6.0845, Acc=0.244, PPL=438.99
2025-09-23 03:31:06,260 - training.trainer - INFO - Epoch 67, Step 228660: Loss=4.5922, Acc=0.469, PPL=98.71
2025-09-23 03:31:14,305 - training.trainer - INFO - Epoch 67, Step 228760: Loss=4.8373, Acc=0.368, PPL=126.13
2025-09-23 03:31:22,202 - training.trainer - INFO - Epoch 67, Step 228860: Loss=6.2272, Acc=0.227, PPL=506.35
2025-09-23 03:31:30,104 - training.trainer - INFO - Epoch 67, Step 228960: Loss=6.2064, Acc=0.226, PPL=495.91
2025-09-23 03:31:38,190 - training.trainer - INFO - Epoch 67, Step 229060: Loss=5.7278, Acc=0.242, PPL=307.28
2025-09-23 03:31:45,914 - training.trainer - INFO - Epoch 67, Step 229160: Loss=5.3151, Acc=0.273, PPL=203.38
2025-09-23 03:31:53,762 - training.trainer - INFO - Epoch 67, Step 229260: Loss=5.1418, Acc=0.282, PPL=171.02
2025-09-23 03:32:01,599 - training.trainer - INFO - Epoch 67, Step 229360: Loss=5.4080, Acc=0.200, PPL=223.18
2025-09-23 03:32:09,514 - training.trainer - INFO - Epoch 67, Step 229460: Loss=5.9151, Acc=0.176, PPL=370.60
2025-09-23 03:32:17,520 - training.trainer - INFO - Epoch 67, Step 229560: Loss=5.7354, Acc=0.253, PPL=309.64
2025-09-23 03:32:25,306 - training.trainer - INFO - Epoch 67, Step 229660: Loss=5.8170, Acc=0.273, PPL=335.97
2025-09-23 03:32:33,082 - training.trainer - INFO - Epoch 67, Step 229760: Loss=5.7160, Acc=0.350, PPL=303.68
2025-09-23 03:32:40,994 - training.trainer - INFO - Epoch 67, Step 229860: Loss=5.9228, Acc=0.214, PPL=373.47
2025-09-23 03:32:48,796 - training.trainer - INFO - Epoch 67, Step 229960: Loss=5.5820, Acc=0.257, PPL=265.60
2025-09-23 03:33:08,530 - training.trainer - INFO - Epoch 68/100 completed in 274.61s - Train Loss: 5.4319, Train Acc: 0.287, Val Loss: 5.6677, Val Acc: 0.255
2025-09-23 03:33:15,493 - training.trainer - INFO - Epoch 68, Step 230143: Loss=4.7038, Acc=0.429, PPL=110.37
2025-09-23 03:33:22,160 - training.trainer - INFO - Epoch 68, Step 230243: Loss=5.6919, Acc=0.279, PPL=296.45
2025-09-23 03:33:29,015 - training.trainer - INFO - Epoch 68, Step 230343: Loss=5.7639, Acc=0.257, PPL=318.58
2025-09-23 03:33:35,774 - training.trainer - INFO - Epoch 68, Step 230443: Loss=5.7518, Acc=0.229, PPL=314.74
2025-09-23 03:33:42,446 - training.trainer - INFO - Epoch 68, Step 230543: Loss=5.6845, Acc=0.277, PPL=294.26
2025-09-23 03:33:50,067 - training.trainer - INFO - Epoch 68, Step 230643: Loss=5.3037, Acc=0.455, PPL=201.07
2025-09-23 03:33:58,025 - training.trainer - INFO - Epoch 68, Step 230743: Loss=5.0337, Acc=0.286, PPL=153.50
2025-09-23 03:34:05,844 - training.trainer - INFO - Epoch 68, Step 230843: Loss=4.3673, Acc=0.393, PPL=78.83
2025-09-23 03:34:13,689 - training.trainer - INFO - Epoch 68, Step 230943: Loss=6.1689, Acc=0.191, PPL=477.66
2025-09-23 03:34:21,581 - training.trainer - INFO - Epoch 68, Step 231043: Loss=5.6860, Acc=0.300, PPL=294.72
2025-09-23 03:34:29,418 - training.trainer - INFO - Epoch 68, Step 231143: Loss=5.2426, Acc=0.274, PPL=189.17
2025-09-23 03:34:37,224 - training.trainer - INFO - Epoch 68, Step 231243: Loss=5.5068, Acc=0.200, PPL=246.37
2025-09-23 03:34:45,012 - training.trainer - INFO - Epoch 68, Step 231343: Loss=5.4330, Acc=0.300, PPL=228.83
2025-09-23 03:34:53,100 - training.trainer - INFO - Epoch 68, Step 231443: Loss=6.6582, Acc=0.151, PPL=779.17
2025-09-23 03:35:00,891 - training.trainer - INFO - Epoch 68, Step 231543: Loss=5.1144, Acc=0.288, PPL=166.39
2025-09-23 03:35:08,695 - training.trainer - INFO - Epoch 68, Step 231643: Loss=5.1529, Acc=0.214, PPL=172.93
2025-09-23 03:35:16,448 - training.trainer - INFO - Epoch 68, Step 231743: Loss=4.9730, Acc=0.310, PPL=144.46
2025-09-23 03:35:24,215 - training.trainer - INFO - Epoch 68, Step 231843: Loss=5.6251, Acc=0.262, PPL=277.30
2025-09-23 03:35:32,041 - training.trainer - INFO - Epoch 68, Step 231943: Loss=5.2958, Acc=0.267, PPL=199.49
2025-09-23 03:35:39,866 - training.trainer - INFO - Epoch 68, Step 232043: Loss=6.1744, Acc=0.256, PPL=480.28
2025-09-23 03:35:47,658 - training.trainer - INFO - Epoch 68, Step 232143: Loss=5.4427, Acc=0.259, PPL=231.07
2025-09-23 03:35:55,597 - training.trainer - INFO - Epoch 68, Step 232243: Loss=6.2242, Acc=0.185, PPL=504.81
2025-09-23 03:36:03,700 - training.trainer - INFO - Epoch 68, Step 232343: Loss=5.4875, Acc=0.269, PPL=241.65
2025-09-23 03:36:11,512 - training.trainer - INFO - Epoch 68, Step 232443: Loss=5.3717, Acc=0.294, PPL=215.23
2025-09-23 03:36:19,256 - training.trainer - INFO - Epoch 68, Step 232543: Loss=5.2333, Acc=0.256, PPL=187.40
2025-09-23 03:36:27,284 - training.trainer - INFO - Epoch 68, Step 232643: Loss=5.5522, Acc=0.266, PPL=257.80
2025-09-23 03:36:35,666 - training.trainer - INFO - Epoch 68, Step 232743: Loss=5.0754, Acc=0.368, PPL=160.03
2025-09-23 03:36:43,604 - training.trainer - INFO - Epoch 68, Step 232843: Loss=5.6168, Acc=0.277, PPL=275.01
2025-09-23 03:36:51,416 - training.trainer - INFO - Epoch 68, Step 232943: Loss=5.8542, Acc=0.222, PPL=348.68
2025-09-23 03:36:59,337 - training.trainer - INFO - Epoch 68, Step 233043: Loss=6.2783, Acc=0.206, PPL=532.91
2025-09-23 03:37:07,212 - training.trainer - INFO - Epoch 68, Step 233143: Loss=5.6895, Acc=0.120, PPL=295.74
2025-09-23 03:37:15,163 - training.trainer - INFO - Epoch 68, Step 233243: Loss=4.9820, Acc=0.365, PPL=145.76
2025-09-23 03:37:23,164 - training.trainer - INFO - Epoch 68, Step 233343: Loss=4.9789, Acc=0.343, PPL=145.32
2025-09-23 03:37:42,610 - training.trainer - INFO - Epoch 69/100 completed in 274.08s - Train Loss: 5.4310, Train Acc: 0.287, Val Loss: 5.6681, Val Acc: 0.255
2025-09-23 03:37:50,900 - training.trainer - INFO - Epoch 69, Step 233526: Loss=5.7314, Acc=0.281, PPL=308.39
2025-09-23 03:37:59,035 - training.trainer - INFO - Epoch 69, Step 233626: Loss=5.4684, Acc=0.302, PPL=237.09
2025-09-23 03:38:07,183 - training.trainer - INFO - Epoch 69, Step 233726: Loss=5.9910, Acc=0.215, PPL=399.82
2025-09-23 03:38:15,307 - training.trainer - INFO - Epoch 69, Step 233826: Loss=5.4678, Acc=0.400, PPL=236.94
2025-09-23 03:38:23,309 - training.trainer - INFO - Epoch 69, Step 233926: Loss=5.3950, Acc=0.184, PPL=220.30
2025-09-23 03:38:31,323 - training.trainer - INFO - Epoch 69, Step 234026: Loss=5.4836, Acc=0.167, PPL=240.71
2025-09-23 03:38:39,403 - training.trainer - INFO - Epoch 69, Step 234126: Loss=5.4884, Acc=0.268, PPL=241.86
2025-09-23 03:38:47,501 - training.trainer - INFO - Epoch 69, Step 234226: Loss=5.1711, Acc=0.294, PPL=176.11
2025-09-23 03:38:55,808 - training.trainer - INFO - Epoch 69, Step 234326: Loss=4.9408, Acc=0.360, PPL=139.88
2025-09-23 03:39:03,733 - training.trainer - INFO - Epoch 69, Step 234426: Loss=5.3586, Acc=0.296, PPL=212.43
2025-09-23 03:39:11,813 - training.trainer - INFO - Epoch 69, Step 234526: Loss=6.9317, Acc=0.162, PPL=1024.28
2025-09-23 03:39:19,831 - training.trainer - INFO - Epoch 69, Step 234626: Loss=5.7942, Acc=0.242, PPL=328.38
2025-09-23 03:39:27,752 - training.trainer - INFO - Epoch 69, Step 234726: Loss=5.9672, Acc=0.364, PPL=390.39
2025-09-23 03:39:35,596 - training.trainer - INFO - Epoch 69, Step 234826: Loss=5.7266, Acc=0.172, PPL=306.94
2025-09-23 03:39:43,523 - training.trainer - INFO - Epoch 69, Step 234926: Loss=5.5771, Acc=0.267, PPL=264.30
2025-09-23 03:39:51,630 - training.trainer - INFO - Epoch 69, Step 235026: Loss=6.3859, Acc=0.205, PPL=593.42
2025-09-23 03:39:59,729 - training.trainer - INFO - Epoch 69, Step 235126: Loss=4.8036, Acc=0.321, PPL=121.95
2025-09-23 03:40:07,825 - training.trainer - INFO - Epoch 69, Step 235226: Loss=4.3382, Acc=0.421, PPL=76.57
2025-09-23 03:40:15,874 - training.trainer - INFO - Epoch 69, Step 235326: Loss=5.2329, Acc=0.297, PPL=187.33
2025-09-23 03:40:23,894 - training.trainer - INFO - Epoch 69, Step 235426: Loss=6.2861, Acc=0.188, PPL=537.06
2025-09-23 03:40:31,929 - training.trainer - INFO - Epoch 69, Step 235526: Loss=4.8128, Acc=0.360, PPL=123.08
2025-09-23 03:40:39,875 - training.trainer - INFO - Epoch 69, Step 235626: Loss=5.1659, Acc=0.231, PPL=175.20
2025-09-23 03:40:47,834 - training.trainer - INFO - Epoch 69, Step 235726: Loss=5.8340, Acc=0.238, PPL=341.71
2025-09-23 03:40:55,819 - training.trainer - INFO - Epoch 69, Step 235826: Loss=5.0359, Acc=0.300, PPL=153.84
2025-09-23 03:41:03,719 - training.trainer - INFO - Epoch 69, Step 235926: Loss=4.9353, Acc=0.294, PPL=139.11
2025-09-23 03:41:11,616 - training.trainer - INFO - Epoch 69, Step 236026: Loss=5.6958, Acc=0.293, PPL=297.62
2025-09-23 03:41:19,601 - training.trainer - INFO - Epoch 69, Step 236126: Loss=6.5373, Acc=0.138, PPL=690.40
2025-09-23 03:41:27,709 - training.trainer - INFO - Epoch 69, Step 236226: Loss=5.7339, Acc=0.303, PPL=309.16
2025-09-23 03:41:35,725 - training.trainer - INFO - Epoch 69, Step 236326: Loss=4.0936, Acc=0.476, PPL=59.96
2025-09-23 03:41:43,636 - training.trainer - INFO - Epoch 69, Step 236426: Loss=4.8638, Acc=0.412, PPL=129.51
2025-09-23 03:41:51,641 - training.trainer - INFO - Epoch 69, Step 236526: Loss=5.5204, Acc=0.273, PPL=249.73
2025-09-23 03:41:59,795 - training.trainer - INFO - Epoch 69, Step 236626: Loss=4.1628, Acc=0.389, PPL=64.25
2025-09-23 03:42:07,940 - training.trainer - INFO - Epoch 69, Step 236726: Loss=5.5562, Acc=0.260, PPL=258.84
2025-09-23 03:42:27,642 - training.trainer - INFO - Epoch 70/100 completed in 285.03s - Train Loss: 5.4275, Train Acc: 0.289, Val Loss: 5.6693, Val Acc: 0.257
2025-09-23 03:42:28,025 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_70.pt
2025-09-23 03:42:35,157 - training.trainer - INFO - Epoch 70, Step 236909: Loss=6.0168, Acc=0.194, PPL=410.25
2025-09-23 03:42:41,915 - training.trainer - INFO - Epoch 70, Step 237009: Loss=4.8736, Acc=0.400, PPL=130.79
2025-09-23 03:42:48,570 - training.trainer - INFO - Epoch 70, Step 237109: Loss=5.4545, Acc=0.275, PPL=233.80
2025-09-23 03:42:55,267 - training.trainer - INFO - Epoch 70, Step 237209: Loss=3.8462, Acc=0.500, PPL=46.82
2025-09-23 03:43:02,761 - training.trainer - INFO - Epoch 70, Step 237309: Loss=5.3608, Acc=0.327, PPL=212.90
2025-09-23 03:43:10,757 - training.trainer - INFO - Epoch 70, Step 237409: Loss=4.6903, Acc=0.394, PPL=108.88
2025-09-23 03:43:18,598 - training.trainer - INFO - Epoch 70, Step 237509: Loss=4.7989, Acc=0.304, PPL=121.37
2025-09-23 03:43:26,409 - training.trainer - INFO - Epoch 70, Step 237609: Loss=5.2189, Acc=0.320, PPL=184.73
2025-09-23 03:43:34,359 - training.trainer - INFO - Epoch 70, Step 237709: Loss=5.6794, Acc=0.295, PPL=292.77
2025-09-23 03:43:42,418 - training.trainer - INFO - Epoch 70, Step 237809: Loss=5.3376, Acc=0.267, PPL=208.01
2025-09-23 03:43:50,355 - training.trainer - INFO - Epoch 70, Step 237909: Loss=6.1972, Acc=0.200, PPL=491.37
2025-09-23 03:43:58,191 - training.trainer - INFO - Epoch 70, Step 238009: Loss=5.0012, Acc=0.333, PPL=148.59
2025-09-23 03:44:06,290 - training.trainer - INFO - Epoch 70, Step 238109: Loss=5.3585, Acc=0.348, PPL=212.41
2025-09-23 03:44:14,352 - training.trainer - INFO - Epoch 70, Step 238209: Loss=5.6537, Acc=0.360, PPL=285.34
2025-09-23 03:44:22,603 - training.trainer - INFO - Epoch 70, Step 238309: Loss=6.5223, Acc=0.200, PPL=680.11
2025-09-23 03:44:30,734 - training.trainer - INFO - Epoch 70, Step 238409: Loss=5.8806, Acc=0.241, PPL=358.02
2025-09-23 03:44:38,917 - training.trainer - INFO - Epoch 70, Step 238509: Loss=6.5948, Acc=0.156, PPL=731.28
2025-09-23 03:44:46,873 - training.trainer - INFO - Epoch 70, Step 238609: Loss=5.1832, Acc=0.270, PPL=178.25
2025-09-23 03:44:54,821 - training.trainer - INFO - Epoch 70, Step 238709: Loss=4.7157, Acc=0.391, PPL=111.69
2025-09-23 03:45:02,931 - training.trainer - INFO - Epoch 70, Step 238809: Loss=5.9180, Acc=0.269, PPL=371.68
2025-09-23 03:45:10,784 - training.trainer - INFO - Epoch 70, Step 238909: Loss=4.5188, Acc=0.349, PPL=91.72
2025-09-23 03:45:18,800 - training.trainer - INFO - Epoch 70, Step 239009: Loss=4.9960, Acc=0.386, PPL=147.81
2025-09-23 03:45:26,780 - training.trainer - INFO - Epoch 70, Step 239109: Loss=5.7988, Acc=0.225, PPL=329.91
2025-09-23 03:45:34,768 - training.trainer - INFO - Epoch 70, Step 239209: Loss=5.6255, Acc=0.222, PPL=277.40
2025-09-23 03:45:42,646 - training.trainer - INFO - Epoch 70, Step 239309: Loss=5.6136, Acc=0.323, PPL=274.12
2025-09-23 03:45:50,629 - training.trainer - INFO - Epoch 70, Step 239409: Loss=5.2274, Acc=0.350, PPL=186.32
2025-09-23 03:45:58,719 - training.trainer - INFO - Epoch 70, Step 239509: Loss=5.5650, Acc=0.167, PPL=261.12
2025-09-23 03:46:06,720 - training.trainer - INFO - Epoch 70, Step 239609: Loss=5.0253, Acc=0.333, PPL=152.22
2025-09-23 03:46:14,692 - training.trainer - INFO - Epoch 70, Step 239709: Loss=5.4653, Acc=0.318, PPL=236.35
2025-09-23 03:46:22,596 - training.trainer - INFO - Epoch 70, Step 239809: Loss=5.1646, Acc=0.195, PPL=174.98
2025-09-23 03:46:30,463 - training.trainer - INFO - Epoch 70, Step 239909: Loss=5.5206, Acc=0.324, PPL=249.79
2025-09-23 03:46:38,240 - training.trainer - INFO - Epoch 70, Step 240009: Loss=3.4853, Acc=0.500, PPL=32.63
2025-09-23 03:46:46,097 - training.trainer - INFO - Epoch 70, Step 240109: Loss=4.7569, Acc=0.257, PPL=116.38
2025-09-23 03:47:05,773 - training.trainer - INFO - Epoch 71/100 completed in 277.75s - Train Loss: 5.4276, Train Acc: 0.289, Val Loss: 5.6614, Val Acc: 0.258
2025-09-23 03:47:06,513 - training.trainer - INFO - New best model saved with validation loss: 5.6614
2025-09-23 03:47:06,513 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_71.pt
2025-09-23 03:47:13,726 - training.trainer - INFO - Epoch 71, Step 240292: Loss=4.3719, Acc=0.522, PPL=79.19
2025-09-23 03:47:21,054 - training.trainer - INFO - Epoch 71, Step 240392: Loss=6.1443, Acc=0.229, PPL=466.04
2025-09-23 03:47:28,956 - training.trainer - INFO - Epoch 71, Step 240492: Loss=5.3753, Acc=0.280, PPL=216.01
2025-09-23 03:47:36,780 - training.trainer - INFO - Epoch 71, Step 240592: Loss=5.9262, Acc=0.256, PPL=374.73
2025-09-23 03:47:44,643 - training.trainer - INFO - Epoch 71, Step 240692: Loss=5.9305, Acc=0.295, PPL=376.33
2025-09-23 03:47:51,903 - training.trainer - INFO - Epoch 71, Step 240792: Loss=5.6528, Acc=0.250, PPL=285.09
2025-09-23 03:47:59,974 - training.trainer - INFO - Epoch 71, Step 240892: Loss=5.5881, Acc=0.333, PPL=267.24
2025-09-23 03:48:07,778 - training.trainer - INFO - Epoch 71, Step 240992: Loss=5.1165, Acc=0.324, PPL=166.75
2025-09-23 03:48:15,593 - training.trainer - INFO - Epoch 71, Step 241092: Loss=4.9017, Acc=0.317, PPL=134.52
2025-09-23 03:48:23,496 - training.trainer - INFO - Epoch 71, Step 241192: Loss=5.6509, Acc=0.189, PPL=284.56
2025-09-23 03:48:31,442 - training.trainer - INFO - Epoch 71, Step 241292: Loss=4.8534, Acc=0.395, PPL=128.18
2025-09-23 03:48:39,204 - training.trainer - INFO - Epoch 71, Step 241392: Loss=6.0159, Acc=0.304, PPL=409.90
2025-09-23 03:48:47,031 - training.trainer - INFO - Epoch 71, Step 241492: Loss=6.3878, Acc=0.281, PPL=594.53
2025-09-23 03:48:55,168 - training.trainer - INFO - Epoch 71, Step 241592: Loss=4.7695, Acc=0.360, PPL=117.86
2025-09-23 03:49:03,206 - training.trainer - INFO - Epoch 71, Step 241692: Loss=5.0823, Acc=0.333, PPL=161.15
2025-09-23 03:49:11,142 - training.trainer - INFO - Epoch 71, Step 241792: Loss=4.8503, Acc=0.367, PPL=127.77
2025-09-23 03:49:19,062 - training.trainer - INFO - Epoch 71, Step 241892: Loss=5.4968, Acc=0.303, PPL=243.90
2025-09-23 03:49:26,974 - training.trainer - INFO - Epoch 71, Step 241992: Loss=5.9604, Acc=0.198, PPL=387.75
2025-09-23 03:49:34,847 - training.trainer - INFO - Epoch 71, Step 242092: Loss=5.9442, Acc=0.278, PPL=381.54
2025-09-23 03:49:42,722 - training.trainer - INFO - Epoch 71, Step 242192: Loss=6.0048, Acc=0.217, PPL=405.36
2025-09-23 03:49:50,555 - training.trainer - INFO - Epoch 71, Step 242292: Loss=5.5033, Acc=0.250, PPL=245.49
2025-09-23 03:49:58,581 - training.trainer - INFO - Epoch 71, Step 242392: Loss=5.5508, Acc=0.200, PPL=257.43
2025-09-23 03:50:06,744 - training.trainer - INFO - Epoch 71, Step 242492: Loss=5.5759, Acc=0.222, PPL=263.99
2025-09-23 03:50:14,776 - training.trainer - INFO - Epoch 71, Step 242592: Loss=5.7480, Acc=0.292, PPL=313.56
2025-09-23 03:50:22,634 - training.trainer - INFO - Epoch 71, Step 242692: Loss=5.9671, Acc=0.222, PPL=390.39
2025-09-23 03:50:30,398 - training.trainer - INFO - Epoch 71, Step 242792: Loss=6.3078, Acc=0.154, PPL=548.81
2025-09-23 03:50:38,234 - training.trainer - INFO - Epoch 71, Step 242892: Loss=4.1661, Acc=0.476, PPL=64.46
2025-09-23 03:50:46,336 - training.trainer - INFO - Epoch 71, Step 242992: Loss=5.8633, Acc=0.208, PPL=351.87
2025-09-23 03:50:54,426 - training.trainer - INFO - Epoch 71, Step 243092: Loss=5.5636, Acc=0.194, PPL=260.76
2025-09-23 03:51:02,370 - training.trainer - INFO - Epoch 71, Step 243192: Loss=5.4476, Acc=0.333, PPL=232.20
2025-09-23 03:51:10,226 - training.trainer - INFO - Epoch 71, Step 243292: Loss=5.6122, Acc=0.262, PPL=273.76
2025-09-23 03:51:18,234 - training.trainer - INFO - Epoch 71, Step 243392: Loss=5.9775, Acc=0.154, PPL=394.46
2025-09-23 03:51:26,232 - training.trainer - INFO - Epoch 71, Step 243492: Loss=5.2166, Acc=0.364, PPL=184.30
2025-09-23 03:51:46,168 - training.trainer - INFO - Epoch 72/100 completed in 279.65s - Train Loss: 5.4218, Train Acc: 0.289, Val Loss: 5.6666, Val Acc: 0.257
2025-09-23 03:51:54,512 - training.trainer - INFO - Epoch 72, Step 243675: Loss=5.5018, Acc=0.283, PPL=245.13
2025-09-23 03:52:02,350 - training.trainer - INFO - Epoch 72, Step 243775: Loss=4.2252, Acc=0.519, PPL=68.39
2025-09-23 03:52:10,180 - training.trainer - INFO - Epoch 72, Step 243875: Loss=5.6998, Acc=0.159, PPL=298.82
2025-09-23 03:52:17,986 - training.trainer - INFO - Epoch 72, Step 243975: Loss=5.2820, Acc=0.323, PPL=196.76
2025-09-23 03:52:25,838 - training.trainer - INFO - Epoch 72, Step 244075: Loss=5.4920, Acc=0.156, PPL=242.73
2025-09-23 03:52:33,612 - training.trainer - INFO - Epoch 72, Step 244175: Loss=4.4255, Acc=0.417, PPL=83.56
2025-09-23 03:52:41,376 - training.trainer - INFO - Epoch 72, Step 244275: Loss=6.0773, Acc=0.286, PPL=435.86
2025-09-23 03:52:49,262 - training.trainer - INFO - Epoch 72, Step 244375: Loss=6.1034, Acc=0.183, PPL=447.40
2025-09-23 03:52:57,136 - training.trainer - INFO - Epoch 72, Step 244475: Loss=5.5850, Acc=0.238, PPL=266.39
2025-09-23 03:53:04,907 - training.trainer - INFO - Epoch 72, Step 244575: Loss=4.8321, Acc=0.357, PPL=125.48
2025-09-23 03:53:12,691 - training.trainer - INFO - Epoch 72, Step 244675: Loss=5.0647, Acc=0.283, PPL=158.34
2025-09-23 03:53:20,580 - training.trainer - INFO - Epoch 72, Step 244775: Loss=5.8212, Acc=0.205, PPL=337.36
2025-09-23 03:53:28,736 - training.trainer - INFO - Epoch 72, Step 244875: Loss=4.7914, Acc=0.317, PPL=120.46
2025-09-23 03:53:36,795 - training.trainer - INFO - Epoch 72, Step 244975: Loss=5.2685, Acc=0.250, PPL=194.13
2025-09-23 03:53:44,727 - training.trainer - INFO - Epoch 72, Step 245075: Loss=5.2375, Acc=0.283, PPL=188.19
2025-09-23 03:53:52,701 - training.trainer - INFO - Epoch 72, Step 245175: Loss=5.4957, Acc=0.273, PPL=243.64
2025-09-23 03:54:00,756 - training.trainer - INFO - Epoch 72, Step 245275: Loss=5.4146, Acc=0.171, PPL=224.67
2025-09-23 03:54:08,801 - training.trainer - INFO - Epoch 72, Step 245375: Loss=5.5129, Acc=0.214, PPL=247.87
2025-09-23 03:54:16,783 - training.trainer - INFO - Epoch 72, Step 245475: Loss=6.1371, Acc=0.298, PPL=462.69
2025-09-23 03:54:24,734 - training.trainer - INFO - Epoch 72, Step 245575: Loss=4.7137, Acc=0.462, PPL=111.46
2025-09-23 03:54:33,064 - training.trainer - INFO - Epoch 72, Step 245675: Loss=5.6383, Acc=0.281, PPL=280.99
2025-09-23 03:54:41,106 - training.trainer - INFO - Epoch 72, Step 245775: Loss=6.2617, Acc=0.177, PPL=524.13
2025-09-23 03:54:49,011 - training.trainer - INFO - Epoch 72, Step 245875: Loss=3.7170, Acc=0.552, PPL=41.14
2025-09-23 03:54:56,923 - training.trainer - INFO - Epoch 72, Step 245975: Loss=5.3377, Acc=0.292, PPL=208.04
2025-09-23 03:55:05,097 - training.trainer - INFO - Epoch 72, Step 246075: Loss=5.2658, Acc=0.310, PPL=193.59
2025-09-23 03:55:12,971 - training.trainer - INFO - Epoch 72, Step 246175: Loss=5.3785, Acc=0.391, PPL=216.70
2025-09-23 03:55:20,865 - training.trainer - INFO - Epoch 72, Step 246275: Loss=6.4211, Acc=0.183, PPL=614.69
2025-09-23 03:55:28,733 - training.trainer - INFO - Epoch 72, Step 246375: Loss=5.0065, Acc=0.298, PPL=149.38
2025-09-23 03:55:36,886 - training.trainer - INFO - Epoch 72, Step 246475: Loss=4.5130, Acc=0.389, PPL=91.19
2025-09-23 03:55:44,588 - training.trainer - INFO - Epoch 72, Step 246575: Loss=5.8105, Acc=0.211, PPL=333.79
2025-09-23 03:55:52,073 - training.trainer - INFO - Epoch 72, Step 246675: Loss=3.6457, Acc=0.684, PPL=38.31
2025-09-23 03:55:59,742 - training.trainer - INFO - Epoch 72, Step 246775: Loss=6.2462, Acc=0.263, PPL=516.04
2025-09-23 03:56:07,644 - training.trainer - INFO - Epoch 72, Step 246875: Loss=5.2709, Acc=0.211, PPL=194.59
2025-09-23 03:56:27,341 - training.trainer - INFO - Epoch 73/100 completed in 281.17s - Train Loss: 5.4184, Train Acc: 0.290, Val Loss: 5.6707, Val Acc: 0.257
2025-09-23 03:56:35,000 - training.trainer - INFO - Epoch 73, Step 247058: Loss=4.3599, Acc=0.533, PPL=78.25
2025-09-23 03:56:42,475 - training.trainer - INFO - Epoch 73, Step 247158: Loss=5.6240, Acc=0.293, PPL=276.99
2025-09-23 03:56:50,090 - training.trainer - INFO - Epoch 73, Step 247258: Loss=5.4799, Acc=0.245, PPL=239.82
2025-09-23 03:56:57,672 - training.trainer - INFO - Epoch 73, Step 247358: Loss=5.5764, Acc=0.222, PPL=264.12
2025-09-23 03:57:05,342 - training.trainer - INFO - Epoch 73, Step 247458: Loss=5.2060, Acc=0.304, PPL=182.35
2025-09-23 03:57:13,224 - training.trainer - INFO - Epoch 73, Step 247558: Loss=6.2018, Acc=0.360, PPL=493.64
2025-09-23 03:57:21,172 - training.trainer - INFO - Epoch 73, Step 247658: Loss=5.5436, Acc=0.222, PPL=255.61
2025-09-23 03:57:29,089 - training.trainer - INFO - Epoch 73, Step 247758: Loss=5.9803, Acc=0.226, PPL=395.57
2025-09-23 03:57:36,974 - training.trainer - INFO - Epoch 73, Step 247858: Loss=5.6293, Acc=0.136, PPL=278.48
2025-09-23 03:57:44,840 - training.trainer - INFO - Epoch 73, Step 247958: Loss=6.0863, Acc=0.269, PPL=439.78
2025-09-23 03:57:52,778 - training.trainer - INFO - Epoch 73, Step 248058: Loss=5.7467, Acc=0.312, PPL=313.14
2025-09-23 03:58:00,674 - training.trainer - INFO - Epoch 73, Step 248158: Loss=5.5469, Acc=0.205, PPL=256.44
2025-09-23 03:58:08,531 - training.trainer - INFO - Epoch 73, Step 248258: Loss=4.1923, Acc=0.391, PPL=66.18
2025-09-23 03:58:16,405 - training.trainer - INFO - Epoch 73, Step 248358: Loss=4.6822, Acc=0.375, PPL=108.00
2025-09-23 03:58:24,364 - training.trainer - INFO - Epoch 73, Step 248458: Loss=5.3364, Acc=0.220, PPL=207.77
2025-09-23 03:58:32,132 - training.trainer - INFO - Epoch 73, Step 248558: Loss=4.7188, Acc=0.370, PPL=112.04
2025-09-23 03:58:39,971 - training.trainer - INFO - Epoch 73, Step 248658: Loss=6.0054, Acc=0.188, PPL=405.62
2025-09-23 03:58:47,887 - training.trainer - INFO - Epoch 73, Step 248758: Loss=5.3710, Acc=0.317, PPL=215.07
2025-09-23 03:58:55,946 - training.trainer - INFO - Epoch 73, Step 248858: Loss=5.9399, Acc=0.211, PPL=379.88
2025-09-23 03:59:03,579 - training.trainer - INFO - Epoch 73, Step 248958: Loss=5.3505, Acc=0.255, PPL=210.72
2025-09-23 03:59:10,538 - training.trainer - INFO - Epoch 73, Step 249058: Loss=5.7873, Acc=0.247, PPL=326.12
2025-09-23 03:59:17,195 - training.trainer - INFO - Epoch 73, Step 249158: Loss=5.1318, Acc=0.409, PPL=169.33
2025-09-23 03:59:23,910 - training.trainer - INFO - Epoch 73, Step 249258: Loss=5.4793, Acc=0.273, PPL=239.69
2025-09-23 03:59:30,739 - training.trainer - INFO - Epoch 73, Step 249358: Loss=4.9455, Acc=0.324, PPL=140.55
2025-09-23 03:59:37,736 - training.trainer - INFO - Epoch 73, Step 249458: Loss=5.9622, Acc=0.250, PPL=388.45
2025-09-23 03:59:44,399 - training.trainer - INFO - Epoch 73, Step 249558: Loss=5.9251, Acc=0.234, PPL=374.30
2025-09-23 03:59:51,069 - training.trainer - INFO - Epoch 73, Step 249658: Loss=5.3985, Acc=0.205, PPL=221.08
2025-09-23 03:59:57,802 - training.trainer - INFO - Epoch 73, Step 249758: Loss=6.0269, Acc=0.154, PPL=414.42
2025-09-23 04:00:04,536 - training.trainer - INFO - Epoch 73, Step 249858: Loss=4.7994, Acc=0.406, PPL=121.44
2025-09-23 04:00:11,562 - training.trainer - INFO - Epoch 73, Step 249958: Loss=5.6933, Acc=0.250, PPL=296.88
2025-09-23 04:00:19,336 - training.trainer - INFO - Epoch 73, Step 250058: Loss=6.2566, Acc=0.294, PPL=521.43
2025-09-23 04:00:27,225 - training.trainer - INFO - Epoch 73, Step 250158: Loss=6.0475, Acc=0.250, PPL=423.07
2025-09-23 04:00:35,365 - training.trainer - INFO - Epoch 73, Step 250258: Loss=5.4542, Acc=0.258, PPL=233.74
2025-09-23 04:00:54,866 - training.trainer - INFO - Epoch 74/100 completed in 267.52s - Train Loss: 5.4211, Train Acc: 0.290, Val Loss: 5.6696, Val Acc: 0.258
2025-09-23 04:01:02,269 - training.trainer - INFO - Epoch 74, Step 250441: Loss=5.9928, Acc=0.188, PPL=400.54
2025-09-23 04:01:10,129 - training.trainer - INFO - Epoch 74, Step 250541: Loss=4.9475, Acc=0.404, PPL=140.82
2025-09-23 04:01:18,221 - training.trainer - INFO - Epoch 74, Step 250641: Loss=5.4988, Acc=0.312, PPL=244.40
2025-09-23 04:01:26,155 - training.trainer - INFO - Epoch 74, Step 250741: Loss=5.8906, Acc=0.286, PPL=361.63
2025-09-23 04:01:34,113 - training.trainer - INFO - Epoch 74, Step 250841: Loss=5.7891, Acc=0.222, PPL=326.71
2025-09-23 04:01:42,122 - training.trainer - INFO - Epoch 74, Step 250941: Loss=4.6384, Acc=0.409, PPL=103.38
2025-09-23 04:01:50,135 - training.trainer - INFO - Epoch 74, Step 251041: Loss=5.0710, Acc=0.345, PPL=159.33
2025-09-23 04:01:58,133 - training.trainer - INFO - Epoch 74, Step 251141: Loss=4.9379, Acc=0.417, PPL=139.48
2025-09-23 04:02:06,228 - training.trainer - INFO - Epoch 74, Step 251241: Loss=5.3451, Acc=0.250, PPL=209.58
2025-09-23 04:02:14,195 - training.trainer - INFO - Epoch 74, Step 251341: Loss=5.1357, Acc=0.240, PPL=169.98
2025-09-23 04:02:22,160 - training.trainer - INFO - Epoch 74, Step 251441: Loss=5.2218, Acc=0.300, PPL=185.27
2025-09-23 04:02:30,170 - training.trainer - INFO - Epoch 74, Step 251541: Loss=4.6352, Acc=0.409, PPL=103.04
2025-09-23 04:02:38,279 - training.trainer - INFO - Epoch 74, Step 251641: Loss=5.2887, Acc=0.400, PPL=198.09
2025-09-23 04:02:46,435 - training.trainer - INFO - Epoch 74, Step 251741: Loss=6.1069, Acc=0.203, PPL=448.96
2025-09-23 04:02:54,446 - training.trainer - INFO - Epoch 74, Step 251841: Loss=5.9001, Acc=0.233, PPL=365.08
2025-09-23 04:03:02,427 - training.trainer - INFO - Epoch 74, Step 251941: Loss=5.1101, Acc=0.261, PPL=165.68
2025-09-23 04:03:10,367 - training.trainer - INFO - Epoch 74, Step 252041: Loss=6.5796, Acc=0.240, PPL=720.23
2025-09-23 04:03:18,364 - training.trainer - INFO - Epoch 74, Step 252141: Loss=5.8355, Acc=0.286, PPL=342.23
2025-09-23 04:03:26,254 - training.trainer - INFO - Epoch 74, Step 252241: Loss=5.1474, Acc=0.167, PPL=171.98
2025-09-23 04:03:34,155 - training.trainer - INFO - Epoch 74, Step 252341: Loss=5.3879, Acc=0.286, PPL=218.74
2025-09-23 04:03:42,116 - training.trainer - INFO - Epoch 74, Step 252441: Loss=5.2991, Acc=0.345, PPL=200.15
2025-09-23 04:03:50,260 - training.trainer - INFO - Epoch 74, Step 252541: Loss=5.4275, Acc=0.320, PPL=227.59
2025-09-23 04:03:58,423 - training.trainer - INFO - Epoch 74, Step 252641: Loss=5.8894, Acc=0.308, PPL=361.18
2025-09-23 04:04:06,434 - training.trainer - INFO - Epoch 74, Step 252741: Loss=4.9387, Acc=0.361, PPL=139.59
2025-09-23 04:04:14,486 - training.trainer - INFO - Epoch 74, Step 252841: Loss=5.6023, Acc=0.255, PPL=271.04
2025-09-23 04:04:22,536 - training.trainer - INFO - Epoch 74, Step 252941: Loss=5.8090, Acc=0.250, PPL=333.28
2025-09-23 04:04:30,441 - training.trainer - INFO - Epoch 74, Step 253041: Loss=5.5825, Acc=0.224, PPL=265.73
2025-09-23 04:04:38,367 - training.trainer - INFO - Epoch 74, Step 253141: Loss=4.8973, Acc=0.294, PPL=133.93
2025-09-23 04:04:46,284 - training.trainer - INFO - Epoch 74, Step 253241: Loss=5.7722, Acc=0.200, PPL=321.26
2025-09-23 04:04:54,316 - training.trainer - INFO - Epoch 74, Step 253341: Loss=4.5125, Acc=0.368, PPL=91.15
2025-09-23 04:05:02,338 - training.trainer - INFO - Epoch 74, Step 253441: Loss=5.3360, Acc=0.280, PPL=207.69
2025-09-23 04:05:10,449 - training.trainer - INFO - Epoch 74, Step 253541: Loss=5.5442, Acc=0.250, PPL=255.76
2025-09-23 04:05:18,474 - training.trainer - INFO - Epoch 74, Step 253641: Loss=5.1867, Acc=0.310, PPL=178.88
2025-09-23 04:05:38,231 - training.trainer - INFO - Epoch 75/100 completed in 283.36s - Train Loss: 5.4131, Train Acc: 0.292, Val Loss: 5.6686, Val Acc: 0.256
2025-09-23 04:05:38,616 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_75.pt
2025-09-23 04:05:47,258 - training.trainer - INFO - Epoch 75, Step 253824: Loss=4.9953, Acc=0.444, PPL=147.72
2025-09-23 04:05:55,176 - training.trainer - INFO - Epoch 75, Step 253924: Loss=5.4814, Acc=0.333, PPL=240.19
2025-09-23 04:06:03,264 - training.trainer - INFO - Epoch 75, Step 254024: Loss=4.9670, Acc=0.391, PPL=143.60
2025-09-23 04:06:11,236 - training.trainer - INFO - Epoch 75, Step 254124: Loss=5.8062, Acc=0.262, PPL=332.36
2025-09-23 04:06:19,173 - training.trainer - INFO - Epoch 75, Step 254224: Loss=5.0306, Acc=0.314, PPL=153.03
2025-09-23 04:06:27,102 - training.trainer - INFO - Epoch 75, Step 254324: Loss=5.5503, Acc=0.267, PPL=257.31
2025-09-23 04:06:35,197 - training.trainer - INFO - Epoch 75, Step 254424: Loss=5.6482, Acc=0.269, PPL=283.79
2025-09-23 04:06:43,239 - training.trainer - INFO - Epoch 75, Step 254524: Loss=5.9748, Acc=0.180, PPL=393.39
2025-09-23 04:06:51,266 - training.trainer - INFO - Epoch 75, Step 254624: Loss=4.4397, Acc=0.458, PPL=84.75
2025-09-23 04:06:59,228 - training.trainer - INFO - Epoch 75, Step 254724: Loss=4.8665, Acc=0.333, PPL=129.86
2025-09-23 04:07:07,256 - training.trainer - INFO - Epoch 75, Step 254824: Loss=5.9681, Acc=0.250, PPL=390.76
2025-09-23 04:07:15,296 - training.trainer - INFO - Epoch 75, Step 254924: Loss=5.8254, Acc=0.250, PPL=338.78
2025-09-23 04:07:23,196 - training.trainer - INFO - Epoch 75, Step 255024: Loss=6.1571, Acc=0.182, PPL=472.06
2025-09-23 04:07:31,090 - training.trainer - INFO - Epoch 75, Step 255124: Loss=6.0991, Acc=0.250, PPL=445.46
2025-09-23 04:07:39,084 - training.trainer - INFO - Epoch 75, Step 255224: Loss=5.6668, Acc=0.312, PPL=289.10
2025-09-23 04:07:46,981 - training.trainer - INFO - Epoch 75, Step 255324: Loss=5.9507, Acc=0.279, PPL=384.02
2025-09-23 04:07:54,920 - training.trainer - INFO - Epoch 75, Step 255424: Loss=4.2237, Acc=0.436, PPL=68.29
2025-09-23 04:08:02,903 - training.trainer - INFO - Epoch 75, Step 255524: Loss=4.8866, Acc=0.351, PPL=132.50
2025-09-23 04:08:10,951 - training.trainer - INFO - Epoch 75, Step 255624: Loss=4.8282, Acc=0.306, PPL=124.99
2025-09-23 04:08:18,925 - training.trainer - INFO - Epoch 75, Step 255724: Loss=5.7721, Acc=0.234, PPL=321.21
2025-09-23 04:08:26,804 - training.trainer - INFO - Epoch 75, Step 255824: Loss=5.9746, Acc=0.250, PPL=393.32
2025-09-23 04:08:34,670 - training.trainer - INFO - Epoch 75, Step 255924: Loss=4.6879, Acc=0.444, PPL=108.62
2025-09-23 04:08:42,588 - training.trainer - INFO - Epoch 75, Step 256024: Loss=5.7017, Acc=0.400, PPL=299.37
2025-09-23 04:08:50,492 - training.trainer - INFO - Epoch 75, Step 256124: Loss=5.2662, Acc=0.238, PPL=193.68
2025-09-23 04:08:58,714 - training.trainer - INFO - Epoch 75, Step 256224: Loss=5.1080, Acc=0.300, PPL=165.34
2025-09-23 04:09:06,593 - training.trainer - INFO - Epoch 75, Step 256324: Loss=5.6931, Acc=0.171, PPL=296.82
2025-09-23 04:09:14,554 - training.trainer - INFO - Epoch 75, Step 256424: Loss=5.9384, Acc=0.196, PPL=379.34
2025-09-23 04:09:22,544 - training.trainer - INFO - Epoch 75, Step 256524: Loss=5.0065, Acc=0.333, PPL=149.38
2025-09-23 04:09:30,453 - training.trainer - INFO - Epoch 75, Step 256624: Loss=4.6612, Acc=0.359, PPL=105.76
2025-09-23 04:09:38,446 - training.trainer - INFO - Epoch 75, Step 256724: Loss=5.4505, Acc=0.247, PPL=232.88
2025-09-23 04:09:46,499 - training.trainer - INFO - Epoch 75, Step 256824: Loss=5.6393, Acc=0.279, PPL=281.27
2025-09-23 04:09:54,505 - training.trainer - INFO - Epoch 75, Step 256924: Loss=4.4533, Acc=0.333, PPL=85.91
2025-09-23 04:10:02,422 - training.trainer - INFO - Epoch 75, Step 257024: Loss=6.0285, Acc=0.250, PPL=415.11
2025-09-23 04:10:22,001 - training.trainer - INFO - Epoch 76/100 completed in 283.38s - Train Loss: 5.4095, Train Acc: 0.292, Val Loss: 5.6661, Val Acc: 0.257
2025-09-23 04:10:29,123 - training.trainer - INFO - Epoch 76, Step 257207: Loss=2.8033, Acc=0.650, PPL=16.50
2025-09-23 04:10:36,038 - training.trainer - INFO - Epoch 76, Step 257307: Loss=4.8035, Acc=0.267, PPL=121.94
2025-09-23 04:10:42,932 - training.trainer - INFO - Epoch 76, Step 257407: Loss=6.3567, Acc=0.222, PPL=576.36
2025-09-23 04:10:50,776 - training.trainer - INFO - Epoch 76, Step 257507: Loss=6.1477, Acc=0.212, PPL=467.62
2025-09-23 04:10:58,801 - training.trainer - INFO - Epoch 76, Step 257607: Loss=5.4688, Acc=0.222, PPL=237.17
2025-09-23 04:11:06,743 - training.trainer - INFO - Epoch 76, Step 257707: Loss=5.4669, Acc=0.364, PPL=236.73
2025-09-23 04:11:14,723 - training.trainer - INFO - Epoch 76, Step 257807: Loss=5.0189, Acc=0.364, PPL=151.25
2025-09-23 04:11:22,841 - training.trainer - INFO - Epoch 76, Step 257907: Loss=5.8072, Acc=0.225, PPL=332.70
2025-09-23 04:11:30,956 - training.trainer - INFO - Epoch 76, Step 258007: Loss=5.4561, Acc=0.261, PPL=234.19
2025-09-23 04:11:38,993 - training.trainer - INFO - Epoch 76, Step 258107: Loss=5.2905, Acc=0.324, PPL=198.45
2025-09-23 04:11:46,894 - training.trainer - INFO - Epoch 76, Step 258207: Loss=3.1559, Acc=0.560, PPL=23.47
2025-09-23 04:11:54,934 - training.trainer - INFO - Epoch 76, Step 258307: Loss=4.9260, Acc=0.295, PPL=137.82
2025-09-23 04:12:03,012 - training.trainer - INFO - Epoch 76, Step 258407: Loss=4.7958, Acc=0.333, PPL=121.00
2025-09-23 04:12:10,948 - training.trainer - INFO - Epoch 76, Step 258507: Loss=4.7882, Acc=0.302, PPL=120.08
2025-09-23 04:12:19,064 - training.trainer - INFO - Epoch 76, Step 258607: Loss=5.7200, Acc=0.258, PPL=304.91
2025-09-23 04:12:26,895 - training.trainer - INFO - Epoch 76, Step 258707: Loss=3.3539, Acc=0.556, PPL=28.61
2025-09-23 04:12:34,827 - training.trainer - INFO - Epoch 76, Step 258807: Loss=6.2405, Acc=0.286, PPL=513.10
2025-09-23 04:12:42,639 - training.trainer - INFO - Epoch 76, Step 258907: Loss=5.0381, Acc=0.450, PPL=154.18
2025-09-23 04:12:50,502 - training.trainer - INFO - Epoch 76, Step 259007: Loss=4.6670, Acc=0.242, PPL=106.38
2025-09-23 04:12:58,400 - training.trainer - INFO - Epoch 76, Step 259107: Loss=5.2270, Acc=0.319, PPL=186.23
2025-09-23 04:13:06,353 - training.trainer - INFO - Epoch 76, Step 259207: Loss=5.5764, Acc=0.300, PPL=264.11
2025-09-23 04:13:14,237 - training.trainer - INFO - Epoch 76, Step 259307: Loss=5.4744, Acc=0.294, PPL=238.52
2025-09-23 04:13:22,082 - training.trainer - INFO - Epoch 76, Step 259407: Loss=4.6267, Acc=0.333, PPL=102.18
2025-09-23 04:13:29,980 - training.trainer - INFO - Epoch 76, Step 259507: Loss=5.1946, Acc=0.362, PPL=180.30
2025-09-23 04:13:38,051 - training.trainer - INFO - Epoch 76, Step 259607: Loss=5.9202, Acc=0.255, PPL=372.49
2025-09-23 04:13:46,116 - training.trainer - INFO - Epoch 76, Step 259707: Loss=5.8855, Acc=0.286, PPL=359.77
2025-09-23 04:13:54,133 - training.trainer - INFO - Epoch 76, Step 259807: Loss=5.9574, Acc=0.163, PPL=386.59
2025-09-23 04:14:01,966 - training.trainer - INFO - Epoch 76, Step 259907: Loss=5.3590, Acc=0.278, PPL=212.51
2025-09-23 04:14:10,131 - training.trainer - INFO - Epoch 76, Step 260007: Loss=5.3530, Acc=0.307, PPL=211.24
2025-09-23 04:14:18,064 - training.trainer - INFO - Epoch 76, Step 260107: Loss=5.8471, Acc=0.278, PPL=346.22
2025-09-23 04:14:25,966 - training.trainer - INFO - Epoch 76, Step 260207: Loss=5.8570, Acc=0.192, PPL=349.66
2025-09-23 04:14:33,864 - training.trainer - INFO - Epoch 76, Step 260307: Loss=5.5979, Acc=0.232, PPL=269.85
2025-09-23 04:14:41,792 - training.trainer - INFO - Epoch 76, Step 260407: Loss=5.1218, Acc=0.318, PPL=167.64
2025-09-23 04:15:01,169 - training.trainer - INFO - Epoch 77/100 completed in 279.17s - Train Loss: 5.4070, Train Acc: 0.290, Val Loss: 5.6721, Val Acc: 0.256
2025-09-23 04:15:09,649 - training.trainer - INFO - Epoch 77, Step 260590: Loss=5.7683, Acc=0.314, PPL=319.99
2025-09-23 04:15:17,843 - training.trainer - INFO - Epoch 77, Step 260690: Loss=5.4990, Acc=0.259, PPL=244.45
2025-09-23 04:15:25,857 - training.trainer - INFO - Epoch 77, Step 260790: Loss=4.2827, Acc=0.381, PPL=72.44
2025-09-23 04:15:33,865 - training.trainer - INFO - Epoch 77, Step 260890: Loss=6.0237, Acc=0.191, PPL=413.11
2025-09-23 04:15:41,862 - training.trainer - INFO - Epoch 77, Step 260990: Loss=5.3775, Acc=0.303, PPL=216.49
2025-09-23 04:15:50,071 - training.trainer - INFO - Epoch 77, Step 261090: Loss=5.5780, Acc=0.323, PPL=264.54
2025-09-23 04:15:58,091 - training.trainer - INFO - Epoch 77, Step 261190: Loss=5.6586, Acc=0.269, PPL=286.74
2025-09-23 04:16:06,087 - training.trainer - INFO - Epoch 77, Step 261290: Loss=4.6684, Acc=0.381, PPL=106.53
2025-09-23 04:16:14,144 - training.trainer - INFO - Epoch 77, Step 261390: Loss=5.9749, Acc=0.160, PPL=393.45
2025-09-23 04:16:22,096 - training.trainer - INFO - Epoch 77, Step 261490: Loss=3.8139, Acc=0.625, PPL=45.33
2025-09-23 04:16:30,052 - training.trainer - INFO - Epoch 77, Step 261590: Loss=5.4856, Acc=0.279, PPL=241.19
2025-09-23 04:16:37,877 - training.trainer - INFO - Epoch 77, Step 261690: Loss=4.8055, Acc=0.383, PPL=122.18
2025-09-23 04:16:45,759 - training.trainer - INFO - Epoch 77, Step 261790: Loss=5.4817, Acc=0.289, PPL=240.26
2025-09-23 04:16:53,728 - training.trainer - INFO - Epoch 77, Step 261890: Loss=3.9228, Acc=0.556, PPL=50.54
2025-09-23 04:17:01,694 - training.trainer - INFO - Epoch 77, Step 261990: Loss=5.7112, Acc=0.243, PPL=302.22
2025-09-23 04:17:09,531 - training.trainer - INFO - Epoch 77, Step 262090: Loss=6.2242, Acc=0.196, PPL=504.84
2025-09-23 04:17:17,409 - training.trainer - INFO - Epoch 77, Step 262190: Loss=6.3725, Acc=0.193, PPL=585.54
2025-09-23 04:17:25,277 - training.trainer - INFO - Epoch 77, Step 262290: Loss=5.7485, Acc=0.333, PPL=313.72
2025-09-23 04:17:33,251 - training.trainer - INFO - Epoch 77, Step 262390: Loss=4.6936, Acc=0.440, PPL=109.25
2025-09-23 04:17:41,150 - training.trainer - INFO - Epoch 77, Step 262490: Loss=5.9864, Acc=0.273, PPL=397.96
2025-09-23 04:17:49,365 - training.trainer - INFO - Epoch 77, Step 262590: Loss=6.3818, Acc=0.217, PPL=591.00
2025-09-23 04:17:57,320 - training.trainer - INFO - Epoch 77, Step 262690: Loss=5.9417, Acc=0.273, PPL=380.57
2025-09-23 04:18:05,397 - training.trainer - INFO - Epoch 77, Step 262790: Loss=4.3413, Acc=0.400, PPL=76.81
2025-09-23 04:18:13,287 - training.trainer - INFO - Epoch 77, Step 262890: Loss=3.5031, Acc=0.500, PPL=33.22
2025-09-23 04:18:21,173 - training.trainer - INFO - Epoch 77, Step 262990: Loss=5.1680, Acc=0.208, PPL=175.56
2025-09-23 04:18:29,046 - training.trainer - INFO - Epoch 77, Step 263090: Loss=5.6862, Acc=0.250, PPL=294.78
2025-09-23 04:18:37,020 - training.trainer - INFO - Epoch 77, Step 263190: Loss=5.5938, Acc=0.262, PPL=268.76
2025-09-23 04:18:44,923 - training.trainer - INFO - Epoch 77, Step 263290: Loss=4.5261, Acc=0.358, PPL=92.40
2025-09-23 04:18:52,777 - training.trainer - INFO - Epoch 77, Step 263390: Loss=5.2832, Acc=0.268, PPL=197.00
2025-09-23 04:19:00,625 - training.trainer - INFO - Epoch 77, Step 263490: Loss=5.6991, Acc=0.300, PPL=298.61
2025-09-23 04:19:08,564 - training.trainer - INFO - Epoch 77, Step 263590: Loss=5.4192, Acc=0.321, PPL=225.71
2025-09-23 04:19:16,473 - training.trainer - INFO - Epoch 77, Step 263690: Loss=6.0582, Acc=0.259, PPL=427.61
2025-09-23 04:19:24,445 - training.trainer - INFO - Epoch 77, Step 263790: Loss=5.2806, Acc=0.280, PPL=196.48
2025-09-23 04:19:43,910 - training.trainer - INFO - Epoch 78/100 completed in 282.74s - Train Loss: 5.4053, Train Acc: 0.292, Val Loss: 5.6665, Val Acc: 0.257
2025-09-23 04:19:51,585 - training.trainer - INFO - Epoch 78, Step 263973: Loss=6.1384, Acc=0.239, PPL=463.32
2025-09-23 04:19:58,439 - training.trainer - INFO - Epoch 78, Step 264073: Loss=4.6723, Acc=0.370, PPL=106.95
2025-09-23 04:20:05,350 - training.trainer - INFO - Epoch 78, Step 264173: Loss=6.0546, Acc=0.244, PPL=426.08
2025-09-23 04:20:12,463 - training.trainer - INFO - Epoch 78, Step 264273: Loss=5.6691, Acc=0.188, PPL=289.76
2025-09-23 04:20:20,433 - training.trainer - INFO - Epoch 78, Step 264373: Loss=5.9285, Acc=0.217, PPL=375.59
2025-09-23 04:20:28,364 - training.trainer - INFO - Epoch 78, Step 264473: Loss=5.5518, Acc=0.320, PPL=257.69
2025-09-23 04:20:36,375 - training.trainer - INFO - Epoch 78, Step 264573: Loss=4.2446, Acc=0.463, PPL=69.73
2025-09-23 04:20:44,451 - training.trainer - INFO - Epoch 78, Step 264673: Loss=4.9599, Acc=0.355, PPL=142.58
2025-09-23 04:20:52,463 - training.trainer - INFO - Epoch 78, Step 264773: Loss=5.2277, Acc=0.236, PPL=186.36
2025-09-23 04:21:00,519 - training.trainer - INFO - Epoch 78, Step 264873: Loss=5.7887, Acc=0.286, PPL=326.59
2025-09-23 04:21:07,970 - training.trainer - INFO - Epoch 78, Step 264973: Loss=4.1294, Acc=0.333, PPL=62.14
2025-09-23 04:21:14,997 - training.trainer - INFO - Epoch 78, Step 265073: Loss=5.5887, Acc=0.278, PPL=267.38
2025-09-23 04:21:22,361 - training.trainer - INFO - Epoch 78, Step 265173: Loss=5.5487, Acc=0.282, PPL=256.90
2025-09-23 04:21:29,876 - training.trainer - INFO - Epoch 78, Step 265273: Loss=5.9794, Acc=0.250, PPL=395.21
2025-09-23 04:21:37,770 - training.trainer - INFO - Epoch 78, Step 265373: Loss=5.0224, Acc=0.259, PPL=151.78
2025-09-23 04:21:45,546 - training.trainer - INFO - Epoch 78, Step 265473: Loss=6.1737, Acc=0.214, PPL=479.97
2025-09-23 04:21:53,536 - training.trainer - INFO - Epoch 78, Step 265573: Loss=5.9416, Acc=0.220, PPL=380.53
2025-09-23 04:22:01,329 - training.trainer - INFO - Epoch 78, Step 265673: Loss=5.2873, Acc=0.260, PPL=197.81
2025-09-23 04:22:09,652 - training.trainer - INFO - Epoch 78, Step 265773: Loss=4.7193, Acc=0.354, PPL=112.09
2025-09-23 04:22:17,467 - training.trainer - INFO - Epoch 78, Step 265873: Loss=5.8215, Acc=0.222, PPL=337.48
2025-09-23 04:22:25,389 - training.trainer - INFO - Epoch 78, Step 265973: Loss=6.3261, Acc=0.214, PPL=558.95
2025-09-23 04:22:33,215 - training.trainer - INFO - Epoch 78, Step 266073: Loss=5.6974, Acc=0.250, PPL=298.10
2025-09-23 04:22:41,016 - training.trainer - INFO - Epoch 78, Step 266173: Loss=5.2127, Acc=0.283, PPL=183.58
2025-09-23 04:22:48,813 - training.trainer - INFO - Epoch 78, Step 266273: Loss=4.8684, Acc=0.357, PPL=130.11
2025-09-23 04:22:56,830 - training.trainer - INFO - Epoch 78, Step 266373: Loss=4.3352, Acc=0.432, PPL=76.34
2025-09-23 04:23:04,891 - training.trainer - INFO - Epoch 78, Step 266473: Loss=4.8263, Acc=0.280, PPL=124.75
2025-09-23 04:23:12,890 - training.trainer - INFO - Epoch 78, Step 266573: Loss=5.4094, Acc=0.245, PPL=223.50
2025-09-23 04:23:20,944 - training.trainer - INFO - Epoch 78, Step 266673: Loss=5.6219, Acc=0.292, PPL=276.41
2025-09-23 04:23:28,899 - training.trainer - INFO - Epoch 78, Step 266773: Loss=5.3466, Acc=0.244, PPL=209.90
2025-09-23 04:23:36,748 - training.trainer - INFO - Epoch 78, Step 266873: Loss=4.0986, Acc=0.455, PPL=60.26
2025-09-23 04:23:44,685 - training.trainer - INFO - Epoch 78, Step 266973: Loss=6.0719, Acc=0.180, PPL=433.50
2025-09-23 04:23:52,623 - training.trainer - INFO - Epoch 78, Step 267073: Loss=6.3061, Acc=0.220, PPL=547.89
2025-09-23 04:24:00,764 - training.trainer - INFO - Epoch 78, Step 267173: Loss=4.9696, Acc=0.458, PPL=143.97
2025-09-23 04:24:20,319 - training.trainer - INFO - Epoch 79/100 completed in 276.41s - Train Loss: 5.3994, Train Acc: 0.292, Val Loss: 5.6663, Val Acc: 0.256
2025-09-23 04:24:27,291 - training.trainer - INFO - Epoch 79, Step 267356: Loss=5.5382, Acc=0.393, PPL=254.22
2025-09-23 04:24:34,218 - training.trainer - INFO - Epoch 79, Step 267456: Loss=5.6856, Acc=0.210, PPL=294.60
2025-09-23 04:24:42,138 - training.trainer - INFO - Epoch 79, Step 267556: Loss=5.4533, Acc=0.271, PPL=233.52
2025-09-23 04:24:50,206 - training.trainer - INFO - Epoch 79, Step 267656: Loss=5.0085, Acc=0.333, PPL=149.68
2025-09-23 04:24:58,188 - training.trainer - INFO - Epoch 79, Step 267756: Loss=5.4349, Acc=0.286, PPL=229.26
2025-09-23 04:25:06,202 - training.trainer - INFO - Epoch 79, Step 267856: Loss=5.6332, Acc=0.312, PPL=279.54
2025-09-23 04:25:14,246 - training.trainer - INFO - Epoch 79, Step 267956: Loss=5.0538, Acc=0.273, PPL=156.62
2025-09-23 04:25:22,258 - training.trainer - INFO - Epoch 79, Step 268056: Loss=5.2308, Acc=0.243, PPL=186.95
2025-09-23 04:25:30,299 - training.trainer - INFO - Epoch 79, Step 268156: Loss=5.8754, Acc=0.261, PPL=356.16
2025-09-23 04:25:38,272 - training.trainer - INFO - Epoch 79, Step 268256: Loss=5.1750, Acc=0.280, PPL=176.80
2025-09-23 04:25:46,440 - training.trainer - INFO - Epoch 79, Step 268356: Loss=6.2045, Acc=0.186, PPL=494.99
2025-09-23 04:25:54,400 - training.trainer - INFO - Epoch 79, Step 268456: Loss=2.6327, Acc=0.714, PPL=13.91
2025-09-23 04:26:02,278 - training.trainer - INFO - Epoch 79, Step 268556: Loss=6.2166, Acc=0.300, PPL=501.00
2025-09-23 04:26:10,277 - training.trainer - INFO - Epoch 79, Step 268656: Loss=6.0430, Acc=0.316, PPL=421.17
2025-09-23 04:26:18,406 - training.trainer - INFO - Epoch 79, Step 268756: Loss=6.1450, Acc=0.296, PPL=466.36
2025-09-23 04:26:26,472 - training.trainer - INFO - Epoch 79, Step 268856: Loss=5.4030, Acc=0.194, PPL=222.07
2025-09-23 04:26:34,488 - training.trainer - INFO - Epoch 79, Step 268956: Loss=5.8728, Acc=0.256, PPL=355.25
2025-09-23 04:26:42,408 - training.trainer - INFO - Epoch 79, Step 269056: Loss=5.3556, Acc=0.231, PPL=211.80
2025-09-23 04:26:50,447 - training.trainer - INFO - Epoch 79, Step 269156: Loss=4.8626, Acc=0.395, PPL=129.36
2025-09-23 04:26:58,356 - training.trainer - INFO - Epoch 79, Step 269256: Loss=6.0524, Acc=0.167, PPL=425.12
2025-09-23 04:27:06,453 - training.trainer - INFO - Epoch 79, Step 269356: Loss=5.7401, Acc=0.306, PPL=311.08
2025-09-23 04:27:14,598 - training.trainer - INFO - Epoch 79, Step 269456: Loss=5.9439, Acc=0.135, PPL=381.42
2025-09-23 04:27:22,771 - training.trainer - INFO - Epoch 79, Step 269556: Loss=6.0235, Acc=0.156, PPL=413.01
2025-09-23 04:27:30,734 - training.trainer - INFO - Epoch 79, Step 269656: Loss=5.1666, Acc=0.320, PPL=175.32
2025-09-23 04:27:38,644 - training.trainer - INFO - Epoch 79, Step 269756: Loss=5.7202, Acc=0.308, PPL=304.97
2025-09-23 04:27:46,537 - training.trainer - INFO - Epoch 79, Step 269856: Loss=5.1809, Acc=0.355, PPL=177.84
2025-09-23 04:27:54,435 - training.trainer - INFO - Epoch 79, Step 269956: Loss=6.0131, Acc=0.237, PPL=408.76
2025-09-23 04:28:02,313 - training.trainer - INFO - Epoch 79, Step 270056: Loss=6.1562, Acc=0.231, PPL=471.65
2025-09-23 04:28:10,140 - training.trainer - INFO - Epoch 79, Step 270156: Loss=5.8222, Acc=0.154, PPL=337.72
2025-09-23 04:28:18,014 - training.trainer - INFO - Epoch 79, Step 270256: Loss=5.2384, Acc=0.194, PPL=188.37
2025-09-23 04:28:26,048 - training.trainer - INFO - Epoch 79, Step 270356: Loss=4.5984, Acc=0.364, PPL=99.33
2025-09-23 04:28:34,030 - training.trainer - INFO - Epoch 79, Step 270456: Loss=5.4320, Acc=0.238, PPL=228.61
2025-09-23 04:28:41,858 - training.trainer - INFO - Epoch 79, Step 270556: Loss=5.2143, Acc=0.325, PPL=183.87
2025-09-23 04:29:01,144 - training.trainer - INFO - Epoch 80/100 completed in 280.82s - Train Loss: 5.4031, Train Acc: 0.292, Val Loss: 5.6654, Val Acc: 0.257
2025-09-23 04:29:01,589 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_80.pt
2025-09-23 04:29:10,005 - training.trainer - INFO - Epoch 80, Step 270739: Loss=5.9334, Acc=0.300, PPL=377.44
2025-09-23 04:29:18,081 - training.trainer - INFO - Epoch 80, Step 270839: Loss=5.9240, Acc=0.206, PPL=373.89
2025-09-23 04:29:26,225 - training.trainer - INFO - Epoch 80, Step 270939: Loss=5.2081, Acc=0.300, PPL=182.74
2025-09-23 04:29:34,358 - training.trainer - INFO - Epoch 80, Step 271039: Loss=6.0894, Acc=0.236, PPL=441.14
2025-09-23 04:29:42,418 - training.trainer - INFO - Epoch 80, Step 271139: Loss=5.7300, Acc=0.162, PPL=307.97
2025-09-23 04:29:50,532 - training.trainer - INFO - Epoch 80, Step 271239: Loss=5.9268, Acc=0.220, PPL=374.96
2025-09-23 04:29:58,573 - training.trainer - INFO - Epoch 80, Step 271339: Loss=3.6992, Acc=0.667, PPL=40.41
2025-09-23 04:30:06,652 - training.trainer - INFO - Epoch 80, Step 271439: Loss=5.6775, Acc=0.258, PPL=292.23
2025-09-23 04:30:14,611 - training.trainer - INFO - Epoch 80, Step 271539: Loss=5.9824, Acc=0.263, PPL=396.40
2025-09-23 04:30:22,691 - training.trainer - INFO - Epoch 80, Step 271639: Loss=3.4930, Acc=0.583, PPL=32.88
2025-09-23 04:30:30,703 - training.trainer - INFO - Epoch 80, Step 271739: Loss=6.3750, Acc=0.217, PPL=586.99
2025-09-23 04:30:38,779 - training.trainer - INFO - Epoch 80, Step 271839: Loss=5.9289, Acc=0.200, PPL=375.74
2025-09-23 04:30:46,942 - training.trainer - INFO - Epoch 80, Step 271939: Loss=5.6267, Acc=0.250, PPL=277.75
2025-09-23 04:30:54,812 - training.trainer - INFO - Epoch 80, Step 272039: Loss=6.3820, Acc=0.200, PPL=591.11
2025-09-23 04:31:02,706 - training.trainer - INFO - Epoch 80, Step 272139: Loss=5.8480, Acc=0.276, PPL=346.56
2025-09-23 04:31:10,727 - training.trainer - INFO - Epoch 80, Step 272239: Loss=6.7224, Acc=0.120, PPL=830.82
2025-09-23 04:31:18,642 - training.trainer - INFO - Epoch 80, Step 272339: Loss=4.8505, Acc=0.409, PPL=127.81
2025-09-23 04:31:26,504 - training.trainer - INFO - Epoch 80, Step 272439: Loss=5.6434, Acc=0.261, PPL=282.42
2025-09-23 04:31:34,315 - training.trainer - INFO - Epoch 80, Step 272539: Loss=5.9232, Acc=0.208, PPL=373.61
2025-09-23 04:31:42,335 - training.trainer - INFO - Epoch 80, Step 272639: Loss=6.0689, Acc=0.206, PPL=432.19
2025-09-23 04:31:50,498 - training.trainer - INFO - Epoch 80, Step 272739: Loss=5.9123, Acc=0.282, PPL=369.55
2025-09-23 04:31:58,379 - training.trainer - INFO - Epoch 80, Step 272839: Loss=4.9248, Acc=0.444, PPL=137.66
2025-09-23 04:32:06,296 - training.trainer - INFO - Epoch 80, Step 272939: Loss=5.2041, Acc=0.260, PPL=182.03
2025-09-23 04:32:14,349 - training.trainer - INFO - Epoch 80, Step 273039: Loss=5.5884, Acc=0.214, PPL=267.32
2025-09-23 04:32:22,218 - training.trainer - INFO - Epoch 80, Step 273139: Loss=5.4243, Acc=0.243, PPL=226.85
2025-09-23 04:32:30,151 - training.trainer - INFO - Epoch 80, Step 273239: Loss=3.6840, Acc=0.571, PPL=39.81
2025-09-23 04:32:38,142 - training.trainer - INFO - Epoch 80, Step 273339: Loss=6.2343, Acc=0.151, PPL=509.95
2025-09-23 04:32:46,187 - training.trainer - INFO - Epoch 80, Step 273439: Loss=5.8136, Acc=0.261, PPL=334.83
2025-09-23 04:32:54,214 - training.trainer - INFO - Epoch 80, Step 273539: Loss=5.9881, Acc=0.213, PPL=398.64
2025-09-23 04:33:02,145 - training.trainer - INFO - Epoch 80, Step 273639: Loss=5.5951, Acc=0.312, PPL=269.11
2025-09-23 04:33:10,034 - training.trainer - INFO - Epoch 80, Step 273739: Loss=5.4600, Acc=0.381, PPL=235.09
2025-09-23 04:33:18,068 - training.trainer - INFO - Epoch 80, Step 273839: Loss=5.8555, Acc=0.198, PPL=349.16
2025-09-23 04:33:25,986 - training.trainer - INFO - Epoch 80, Step 273939: Loss=5.4196, Acc=0.412, PPL=225.79
2025-09-23 04:33:45,230 - training.trainer - INFO - Epoch 81/100 completed in 283.64s - Train Loss: 5.4010, Train Acc: 0.293, Val Loss: 5.6672, Val Acc: 0.256
2025-09-23 04:33:53,661 - training.trainer - INFO - Epoch 81, Step 274122: Loss=5.4230, Acc=0.308, PPL=226.55
2025-09-23 04:34:01,390 - training.trainer - INFO - Epoch 81, Step 274222: Loss=5.6473, Acc=0.263, PPL=283.52
2025-09-23 04:34:09,245 - training.trainer - INFO - Epoch 81, Step 274322: Loss=5.5389, Acc=0.271, PPL=254.40
2025-09-23 04:34:17,129 - training.trainer - INFO - Epoch 81, Step 274422: Loss=5.5486, Acc=0.241, PPL=256.88
2025-09-23 04:34:25,088 - training.trainer - INFO - Epoch 81, Step 274522: Loss=5.3003, Acc=0.300, PPL=200.39
2025-09-23 04:34:33,053 - training.trainer - INFO - Epoch 81, Step 274622: Loss=5.5441, Acc=0.389, PPL=255.73
2025-09-23 04:34:41,090 - training.trainer - INFO - Epoch 81, Step 274722: Loss=5.2720, Acc=0.293, PPL=194.81
2025-09-23 04:34:49,164 - training.trainer - INFO - Epoch 81, Step 274822: Loss=4.6812, Acc=0.386, PPL=107.90
2025-09-23 04:34:57,141 - training.trainer - INFO - Epoch 81, Step 274922: Loss=5.3394, Acc=0.280, PPL=208.39
2025-09-23 04:35:05,098 - training.trainer - INFO - Epoch 81, Step 275022: Loss=5.5150, Acc=0.233, PPL=248.40
2025-09-23 04:35:12,986 - training.trainer - INFO - Epoch 81, Step 275122: Loss=5.2888, Acc=0.279, PPL=198.10
2025-09-23 04:35:20,946 - training.trainer - INFO - Epoch 81, Step 275222: Loss=4.3396, Acc=0.409, PPL=76.68
2025-09-23 04:35:28,996 - training.trainer - INFO - Epoch 81, Step 275322: Loss=5.1142, Acc=0.409, PPL=166.37
2025-09-23 04:35:37,055 - training.trainer - INFO - Epoch 81, Step 275422: Loss=4.3304, Acc=0.412, PPL=75.98
2025-09-23 04:35:45,027 - training.trainer - INFO - Epoch 81, Step 275522: Loss=4.8439, Acc=0.324, PPL=126.96
2025-09-23 04:35:53,058 - training.trainer - INFO - Epoch 81, Step 275622: Loss=5.0771, Acc=0.409, PPL=160.30
2025-09-23 04:36:01,152 - training.trainer - INFO - Epoch 81, Step 275722: Loss=5.4668, Acc=0.280, PPL=236.70
2025-09-23 04:36:09,080 - training.trainer - INFO - Epoch 81, Step 275822: Loss=6.0214, Acc=0.200, PPL=412.15
2025-09-23 04:36:16,882 - training.trainer - INFO - Epoch 81, Step 275922: Loss=5.2072, Acc=0.268, PPL=182.58
2025-09-23 04:36:24,766 - training.trainer - INFO - Epoch 81, Step 276022: Loss=6.0663, Acc=0.208, PPL=431.08
2025-09-23 04:36:32,661 - training.trainer - INFO - Epoch 81, Step 276122: Loss=4.7038, Acc=0.316, PPL=110.36
2025-09-23 04:36:40,521 - training.trainer - INFO - Epoch 81, Step 276222: Loss=5.6920, Acc=0.387, PPL=296.49
2025-09-23 04:36:48,392 - training.trainer - INFO - Epoch 81, Step 276322: Loss=5.7153, Acc=0.231, PPL=303.48
2025-09-23 04:36:56,145 - training.trainer - INFO - Epoch 81, Step 276422: Loss=5.6193, Acc=0.317, PPL=275.70
2025-09-23 04:37:03,915 - training.trainer - INFO - Epoch 81, Step 276522: Loss=3.7327, Acc=0.444, PPL=41.79
2025-09-23 04:37:11,821 - training.trainer - INFO - Epoch 81, Step 276622: Loss=5.5356, Acc=0.259, PPL=253.55
2025-09-23 04:37:19,639 - training.trainer - INFO - Epoch 81, Step 276722: Loss=6.0211, Acc=0.194, PPL=412.05
2025-09-23 04:37:27,524 - training.trainer - INFO - Epoch 81, Step 276822: Loss=5.6274, Acc=0.231, PPL=277.93
2025-09-23 04:37:35,362 - training.trainer - INFO - Epoch 81, Step 276922: Loss=5.7305, Acc=0.324, PPL=308.13
2025-09-23 04:37:43,327 - training.trainer - INFO - Epoch 81, Step 277022: Loss=5.1911, Acc=0.286, PPL=179.67
2025-09-23 04:37:51,125 - training.trainer - INFO - Epoch 81, Step 277122: Loss=5.9880, Acc=0.186, PPL=398.62
2025-09-23 04:37:58,885 - training.trainer - INFO - Epoch 81, Step 277222: Loss=5.7227, Acc=0.348, PPL=305.73
2025-09-23 04:38:06,915 - training.trainer - INFO - Epoch 81, Step 277322: Loss=5.5033, Acc=0.173, PPL=245.50
2025-09-23 04:38:26,316 - training.trainer - INFO - Epoch 82/100 completed in 281.08s - Train Loss: 5.3964, Train Acc: 0.293, Val Loss: 5.6660, Val Acc: 0.255
2025-09-23 04:38:33,982 - training.trainer - INFO - Epoch 82, Step 277505: Loss=5.5826, Acc=0.444, PPL=265.77
2025-09-23 04:38:40,798 - training.trainer - INFO - Epoch 82, Step 277605: Loss=5.8671, Acc=0.318, PPL=353.21
2025-09-23 04:38:48,200 - training.trainer - INFO - Epoch 82, Step 277705: Loss=3.7851, Acc=0.371, PPL=44.04
2025-09-23 04:38:55,978 - training.trainer - INFO - Epoch 82, Step 277805: Loss=5.2596, Acc=0.256, PPL=192.41
2025-09-23 04:39:03,877 - training.trainer - INFO - Epoch 82, Step 277905: Loss=5.3420, Acc=0.400, PPL=208.94
2025-09-23 04:39:11,840 - training.trainer - INFO - Epoch 82, Step 278005: Loss=5.9736, Acc=0.250, PPL=392.93
2025-09-23 04:39:19,781 - training.trainer - INFO - Epoch 82, Step 278105: Loss=5.8627, Acc=0.250, PPL=351.68
2025-09-23 04:39:27,625 - training.trainer - INFO - Epoch 82, Step 278205: Loss=5.2428, Acc=0.283, PPL=189.19
2025-09-23 04:39:35,420 - training.trainer - INFO - Epoch 82, Step 278305: Loss=5.1766, Acc=0.372, PPL=177.08
2025-09-23 04:39:43,302 - training.trainer - INFO - Epoch 82, Step 278405: Loss=4.9174, Acc=0.429, PPL=136.65
2025-09-23 04:39:51,307 - training.trainer - INFO - Epoch 82, Step 278505: Loss=5.7005, Acc=0.267, PPL=299.02
2025-09-23 04:39:59,207 - training.trainer - INFO - Epoch 82, Step 278605: Loss=5.6136, Acc=0.225, PPL=274.13
2025-09-23 04:40:07,158 - training.trainer - INFO - Epoch 82, Step 278705: Loss=5.7409, Acc=0.324, PPL=311.34
2025-09-23 04:40:15,092 - training.trainer - INFO - Epoch 82, Step 278805: Loss=5.8164, Acc=0.242, PPL=335.77
2025-09-23 04:40:23,045 - training.trainer - INFO - Epoch 82, Step 278905: Loss=4.9498, Acc=0.325, PPL=141.15
2025-09-23 04:40:31,016 - training.trainer - INFO - Epoch 82, Step 279005: Loss=4.3447, Acc=0.370, PPL=77.07
2025-09-23 04:40:38,867 - training.trainer - INFO - Epoch 82, Step 279105: Loss=5.4164, Acc=0.250, PPL=225.08
2025-09-23 04:40:46,769 - training.trainer - INFO - Epoch 82, Step 279205: Loss=5.5524, Acc=0.250, PPL=257.85
2025-09-23 04:40:54,600 - training.trainer - INFO - Epoch 82, Step 279305: Loss=5.3351, Acc=0.222, PPL=207.49
2025-09-23 04:41:02,538 - training.trainer - INFO - Epoch 82, Step 279405: Loss=4.9396, Acc=0.389, PPL=139.72
2025-09-23 04:41:10,474 - training.trainer - INFO - Epoch 82, Step 279505: Loss=4.8290, Acc=0.455, PPL=125.09
2025-09-23 04:41:18,395 - training.trainer - INFO - Epoch 82, Step 279605: Loss=5.5970, Acc=0.333, PPL=269.62
2025-09-23 04:41:26,294 - training.trainer - INFO - Epoch 82, Step 279705: Loss=5.0198, Acc=0.360, PPL=151.38
2025-09-23 04:41:34,227 - training.trainer - INFO - Epoch 82, Step 279805: Loss=5.5474, Acc=0.292, PPL=256.58
2025-09-23 04:41:42,146 - training.trainer - INFO - Epoch 82, Step 279905: Loss=5.5479, Acc=0.315, PPL=256.69
2025-09-23 04:41:49,990 - training.trainer - INFO - Epoch 82, Step 280005: Loss=4.9863, Acc=0.375, PPL=146.39
2025-09-23 04:41:57,884 - training.trainer - INFO - Epoch 82, Step 280105: Loss=5.4137, Acc=0.353, PPL=224.46
2025-09-23 04:42:05,868 - training.trainer - INFO - Epoch 82, Step 280205: Loss=5.2909, Acc=0.269, PPL=198.52
2025-09-23 04:42:13,931 - training.trainer - INFO - Epoch 82, Step 280305: Loss=5.5692, Acc=0.250, PPL=262.22
2025-09-23 04:42:21,842 - training.trainer - INFO - Epoch 82, Step 280405: Loss=5.8361, Acc=0.216, PPL=342.43
2025-09-23 04:42:29,733 - training.trainer - INFO - Epoch 82, Step 280505: Loss=5.6193, Acc=0.214, PPL=275.70
2025-09-23 04:42:37,771 - training.trainer - INFO - Epoch 82, Step 280605: Loss=5.1904, Acc=0.250, PPL=179.55
2025-09-23 04:42:45,751 - training.trainer - INFO - Epoch 82, Step 280705: Loss=5.4828, Acc=0.359, PPL=240.53
2025-09-23 04:43:05,721 - training.trainer - INFO - Epoch 83/100 completed in 279.40s - Train Loss: 5.3915, Train Acc: 0.294, Val Loss: 5.6676, Val Acc: 0.256
2025-09-23 04:43:13,083 - training.trainer - INFO - Epoch 83, Step 280888: Loss=5.5238, Acc=0.250, PPL=250.59
2025-09-23 04:43:20,792 - training.trainer - INFO - Epoch 83, Step 280988: Loss=5.2383, Acc=0.276, PPL=188.34
2025-09-23 04:43:28,851 - training.trainer - INFO - Epoch 83, Step 281088: Loss=5.4097, Acc=0.262, PPL=223.57
2025-09-23 04:43:36,946 - training.trainer - INFO - Epoch 83, Step 281188: Loss=6.2280, Acc=0.172, PPL=506.75
2025-09-23 04:43:45,163 - training.trainer - INFO - Epoch 83, Step 281288: Loss=5.3531, Acc=0.432, PPL=211.25
2025-09-23 04:43:53,286 - training.trainer - INFO - Epoch 83, Step 281388: Loss=6.1606, Acc=0.182, PPL=473.72
2025-09-23 04:44:01,239 - training.trainer - INFO - Epoch 83, Step 281488: Loss=6.2430, Acc=0.185, PPL=514.39
2025-09-23 04:44:09,284 - training.trainer - INFO - Epoch 83, Step 281588: Loss=5.3906, Acc=0.324, PPL=219.32
2025-09-23 04:44:17,323 - training.trainer - INFO - Epoch 83, Step 281688: Loss=5.7350, Acc=0.314, PPL=309.51
2025-09-23 04:44:25,391 - training.trainer - INFO - Epoch 83, Step 281788: Loss=5.1186, Acc=0.382, PPL=167.11
2025-09-23 04:44:33,454 - training.trainer - INFO - Epoch 83, Step 281888: Loss=5.8928, Acc=0.333, PPL=362.42
2025-09-23 04:44:41,462 - training.trainer - INFO - Epoch 83, Step 281988: Loss=6.1312, Acc=0.209, PPL=460.00
2025-09-23 04:44:49,680 - training.trainer - INFO - Epoch 83, Step 282088: Loss=5.8625, Acc=0.143, PPL=351.61
2025-09-23 04:44:57,745 - training.trainer - INFO - Epoch 83, Step 282188: Loss=5.4435, Acc=0.214, PPL=231.26
2025-09-23 04:45:05,752 - training.trainer - INFO - Epoch 83, Step 282288: Loss=5.3171, Acc=0.282, PPL=203.80
2025-09-23 04:45:13,740 - training.trainer - INFO - Epoch 83, Step 282388: Loss=5.4419, Acc=0.356, PPL=230.88
2025-09-23 04:45:21,907 - training.trainer - INFO - Epoch 83, Step 282488: Loss=5.5724, Acc=0.179, PPL=263.07
2025-09-23 04:45:29,981 - training.trainer - INFO - Epoch 83, Step 282588: Loss=4.1523, Acc=0.424, PPL=63.58
2025-09-23 04:45:37,977 - training.trainer - INFO - Epoch 83, Step 282688: Loss=5.8797, Acc=0.205, PPL=357.71
2025-09-23 04:45:46,000 - training.trainer - INFO - Epoch 83, Step 282788: Loss=4.8460, Acc=0.389, PPL=127.24
2025-09-23 04:45:54,167 - training.trainer - INFO - Epoch 83, Step 282888: Loss=4.5116, Acc=0.440, PPL=91.07
2025-09-23 04:46:02,099 - training.trainer - INFO - Epoch 83, Step 282988: Loss=6.3945, Acc=0.154, PPL=598.55
2025-09-23 04:46:10,142 - training.trainer - INFO - Epoch 83, Step 283088: Loss=4.7711, Acc=0.364, PPL=118.05
2025-09-23 04:46:18,125 - training.trainer - INFO - Epoch 83, Step 283188: Loss=5.9130, Acc=0.241, PPL=369.81
2025-09-23 04:46:26,192 - training.trainer - INFO - Epoch 83, Step 283288: Loss=4.8954, Acc=0.326, PPL=133.68
2025-09-23 04:46:34,164 - training.trainer - INFO - Epoch 83, Step 283388: Loss=5.4840, Acc=0.333, PPL=240.81
2025-09-23 04:46:42,122 - training.trainer - INFO - Epoch 83, Step 283488: Loss=5.8663, Acc=0.153, PPL=352.95
2025-09-23 04:46:50,100 - training.trainer - INFO - Epoch 83, Step 283588: Loss=4.6291, Acc=0.324, PPL=102.42
2025-09-23 04:46:58,189 - training.trainer - INFO - Epoch 83, Step 283688: Loss=5.1197, Acc=0.280, PPL=167.29
2025-09-23 04:47:06,136 - training.trainer - INFO - Epoch 83, Step 283788: Loss=4.8050, Acc=0.286, PPL=122.12
2025-09-23 04:47:14,216 - training.trainer - INFO - Epoch 83, Step 283888: Loss=5.3820, Acc=0.298, PPL=217.45
2025-09-23 04:47:22,601 - training.trainer - INFO - Epoch 83, Step 283988: Loss=5.2079, Acc=0.368, PPL=182.71
2025-09-23 04:47:30,630 - training.trainer - INFO - Epoch 83, Step 284088: Loss=5.8414, Acc=0.195, PPL=344.25
2025-09-23 04:47:50,341 - training.trainer - INFO - Epoch 84/100 completed in 284.62s - Train Loss: 5.3917, Train Acc: 0.295, Val Loss: 5.6646, Val Acc: 0.256
2025-09-23 04:47:57,603 - training.trainer - INFO - Epoch 84, Step 284271: Loss=5.6074, Acc=0.281, PPL=272.44
2025-09-23 04:48:04,479 - training.trainer - INFO - Epoch 84, Step 284371: Loss=5.0047, Acc=0.269, PPL=149.11
2025-09-23 04:48:11,124 - training.trainer - INFO - Epoch 84, Step 284471: Loss=5.7332, Acc=0.191, PPL=308.96
2025-09-23 04:48:17,857 - training.trainer - INFO - Epoch 84, Step 284571: Loss=5.5787, Acc=0.250, PPL=264.74
2025-09-23 04:48:24,588 - training.trainer - INFO - Epoch 84, Step 284671: Loss=6.5340, Acc=0.267, PPL=688.16
2025-09-23 04:48:31,282 - training.trainer - INFO - Epoch 84, Step 284771: Loss=5.5838, Acc=0.263, PPL=266.07
2025-09-23 04:48:38,111 - training.trainer - INFO - Epoch 84, Step 284871: Loss=5.9214, Acc=0.222, PPL=372.94
2025-09-23 04:48:44,940 - training.trainer - INFO - Epoch 84, Step 284971: Loss=4.6867, Acc=0.349, PPL=108.50
2025-09-23 04:48:51,646 - training.trainer - INFO - Epoch 84, Step 285071: Loss=6.6115, Acc=0.205, PPL=743.60
2025-09-23 04:48:58,360 - training.trainer - INFO - Epoch 84, Step 285171: Loss=5.4096, Acc=0.229, PPL=223.54
2025-09-23 04:49:05,142 - training.trainer - INFO - Epoch 84, Step 285271: Loss=5.8574, Acc=0.255, PPL=349.80
2025-09-23 04:49:11,897 - training.trainer - INFO - Epoch 84, Step 285371: Loss=4.6042, Acc=0.333, PPL=99.90
2025-09-23 04:49:19,219 - training.trainer - INFO - Epoch 84, Step 285471: Loss=5.7144, Acc=0.323, PPL=303.22
2025-09-23 04:49:26,476 - training.trainer - INFO - Epoch 84, Step 285571: Loss=5.1254, Acc=0.314, PPL=168.23
2025-09-23 04:49:33,251 - training.trainer - INFO - Epoch 84, Step 285671: Loss=5.9722, Acc=0.226, PPL=392.35
2025-09-23 04:49:40,647 - training.trainer - INFO - Epoch 84, Step 285771: Loss=5.6548, Acc=0.242, PPL=285.66
2025-09-23 04:49:48,462 - training.trainer - INFO - Epoch 84, Step 285871: Loss=5.7468, Acc=0.296, PPL=313.18
2025-09-23 04:49:56,371 - training.trainer - INFO - Epoch 84, Step 285971: Loss=5.2925, Acc=0.275, PPL=198.84
2025-09-23 04:50:04,246 - training.trainer - INFO - Epoch 84, Step 286071: Loss=4.9292, Acc=0.265, PPL=138.27
2025-09-23 04:50:12,153 - training.trainer - INFO - Epoch 84, Step 286171: Loss=6.3224, Acc=0.211, PPL=556.92
2025-09-23 04:50:20,104 - training.trainer - INFO - Epoch 84, Step 286271: Loss=6.1102, Acc=0.113, PPL=450.44
2025-09-23 04:50:27,969 - training.trainer - INFO - Epoch 84, Step 286371: Loss=5.4228, Acc=0.200, PPL=226.52
2025-09-23 04:50:35,986 - training.trainer - INFO - Epoch 84, Step 286471: Loss=4.6874, Acc=0.379, PPL=108.57
2025-09-23 04:50:44,155 - training.trainer - INFO - Epoch 84, Step 286571: Loss=5.0388, Acc=0.333, PPL=154.28
2025-09-23 04:50:52,625 - training.trainer - INFO - Epoch 84, Step 286671: Loss=5.0459, Acc=0.333, PPL=155.38
2025-09-23 04:51:00,510 - training.trainer - INFO - Epoch 84, Step 286771: Loss=5.8664, Acc=0.227, PPL=352.99
2025-09-23 04:51:08,421 - training.trainer - INFO - Epoch 84, Step 286871: Loss=5.6778, Acc=0.333, PPL=292.29
2025-09-23 04:51:16,348 - training.trainer - INFO - Epoch 84, Step 286971: Loss=5.1853, Acc=0.280, PPL=178.63
2025-09-23 04:51:24,331 - training.trainer - INFO - Epoch 84, Step 287071: Loss=6.0326, Acc=0.143, PPL=416.81
2025-09-23 04:51:32,317 - training.trainer - INFO - Epoch 84, Step 287171: Loss=2.6716, Acc=0.700, PPL=14.46
2025-09-23 04:51:40,221 - training.trainer - INFO - Epoch 84, Step 287271: Loss=5.4081, Acc=0.242, PPL=223.21
2025-09-23 04:51:48,154 - training.trainer - INFO - Epoch 84, Step 287371: Loss=4.4332, Acc=0.462, PPL=84.20
2025-09-23 04:51:56,055 - training.trainer - INFO - Epoch 84, Step 287471: Loss=4.5018, Acc=0.405, PPL=90.18
2025-09-23 04:52:15,371 - training.trainer - INFO - Epoch 85/100 completed in 265.03s - Train Loss: 5.3901, Train Acc: 0.294, Val Loss: 5.6631, Val Acc: 0.257
2025-09-23 04:52:15,697 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_85.pt
2025-09-23 04:52:23,323 - training.trainer - INFO - Epoch 85, Step 287654: Loss=5.3096, Acc=0.375, PPL=202.28
2025-09-23 04:52:31,390 - training.trainer - INFO - Epoch 85, Step 287754: Loss=4.8566, Acc=0.333, PPL=128.58
2025-09-23 04:52:39,322 - training.trainer - INFO - Epoch 85, Step 287854: Loss=6.4120, Acc=0.136, PPL=609.14
2025-09-23 04:52:47,159 - training.trainer - INFO - Epoch 85, Step 287954: Loss=4.3157, Acc=0.345, PPL=74.87
2025-09-23 04:52:55,103 - training.trainer - INFO - Epoch 85, Step 288054: Loss=4.9256, Acc=0.160, PPL=137.78
2025-09-23 04:53:03,162 - training.trainer - INFO - Epoch 85, Step 288154: Loss=5.8777, Acc=0.283, PPL=356.99
2025-09-23 04:53:11,275 - training.trainer - INFO - Epoch 85, Step 288254: Loss=5.1538, Acc=0.200, PPL=173.08
2025-09-23 04:53:19,193 - training.trainer - INFO - Epoch 85, Step 288354: Loss=5.7901, Acc=0.286, PPL=327.06
2025-09-23 04:53:27,299 - training.trainer - INFO - Epoch 85, Step 288454: Loss=5.0057, Acc=0.348, PPL=149.26
2025-09-23 04:53:35,318 - training.trainer - INFO - Epoch 85, Step 288554: Loss=5.4667, Acc=0.282, PPL=236.69
2025-09-23 04:53:43,232 - training.trainer - INFO - Epoch 85, Step 288654: Loss=4.7274, Acc=0.364, PPL=113.00
2025-09-23 04:53:51,161 - training.trainer - INFO - Epoch 85, Step 288754: Loss=4.9679, Acc=0.250, PPL=143.73
2025-09-23 04:53:59,358 - training.trainer - INFO - Epoch 85, Step 288854: Loss=6.1260, Acc=0.222, PPL=457.62
2025-09-23 04:54:07,446 - training.trainer - INFO - Epoch 85, Step 288954: Loss=5.2124, Acc=0.309, PPL=183.53
2025-09-23 04:54:15,674 - training.trainer - INFO - Epoch 85, Step 289054: Loss=5.4398, Acc=0.291, PPL=230.40
2025-09-23 04:54:23,613 - training.trainer - INFO - Epoch 85, Step 289154: Loss=5.8728, Acc=0.227, PPL=355.25
2025-09-23 04:54:31,648 - training.trainer - INFO - Epoch 85, Step 289254: Loss=4.1708, Acc=0.526, PPL=64.77
2025-09-23 04:54:39,692 - training.trainer - INFO - Epoch 85, Step 289354: Loss=4.6138, Acc=0.433, PPL=100.87
2025-09-23 04:54:47,707 - training.trainer - INFO - Epoch 85, Step 289454: Loss=6.2096, Acc=0.167, PPL=497.49
2025-09-23 04:54:55,656 - training.trainer - INFO - Epoch 85, Step 289554: Loss=4.1877, Acc=0.444, PPL=65.87
2025-09-23 04:55:03,622 - training.trainer - INFO - Epoch 85, Step 289654: Loss=6.3542, Acc=0.306, PPL=574.90
2025-09-23 04:55:11,686 - training.trainer - INFO - Epoch 85, Step 289754: Loss=5.3606, Acc=0.273, PPL=212.85
2025-09-23 04:55:19,787 - training.trainer - INFO - Epoch 85, Step 289854: Loss=5.5626, Acc=0.233, PPL=260.51
2025-09-23 04:55:27,777 - training.trainer - INFO - Epoch 85, Step 289954: Loss=5.7918, Acc=0.250, PPL=327.59
2025-09-23 04:55:35,683 - training.trainer - INFO - Epoch 85, Step 290054: Loss=5.5598, Acc=0.235, PPL=259.76
2025-09-23 04:55:43,682 - training.trainer - INFO - Epoch 85, Step 290154: Loss=5.3845, Acc=0.239, PPL=217.99
2025-09-23 04:55:51,527 - training.trainer - INFO - Epoch 85, Step 290254: Loss=5.1878, Acc=0.259, PPL=179.07
2025-09-23 04:55:59,430 - training.trainer - INFO - Epoch 85, Step 290354: Loss=5.5517, Acc=0.281, PPL=257.68
2025-09-23 04:56:07,323 - training.trainer - INFO - Epoch 85, Step 290454: Loss=6.0783, Acc=0.155, PPL=436.30
2025-09-23 04:56:15,277 - training.trainer - INFO - Epoch 85, Step 290554: Loss=5.4914, Acc=0.263, PPL=242.59
2025-09-23 04:56:23,408 - training.trainer - INFO - Epoch 85, Step 290654: Loss=6.5184, Acc=0.305, PPL=677.49
2025-09-23 04:56:31,311 - training.trainer - INFO - Epoch 85, Step 290754: Loss=6.4806, Acc=0.185, PPL=652.39
2025-09-23 04:56:39,213 - training.trainer - INFO - Epoch 85, Step 290854: Loss=6.0866, Acc=0.236, PPL=439.92
2025-09-23 04:56:58,583 - training.trainer - INFO - Epoch 86/100 completed in 282.88s - Train Loss: 5.3863, Train Acc: 0.295, Val Loss: 5.6657, Val Acc: 0.257
2025-09-23 04:56:58,583 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-09-23 04:56:58,589 - training.trainer - INFO - Training completed!
2025-09-23 04:56:58,590 - __main__ - INFO - Training completed successfully!
2025-09-23 04:56:58,716 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-23 04:56:58,991 - __main__ - INFO - Process completed!
2025-09-23 04:57:11,999 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-23 04:57:11,999 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-23 04:57:12,000 - __main__ - INFO - Starting model evaluation
2025-09-23 04:57:12,974 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-23 04:58:54,502 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-23 04:58:54,518 - __main__ - INFO - Process completed!
2025-09-23 04:58:59,764 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-23 04:58:59,765 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-23 04:58:59,765 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-09-23 04:59:00,749 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-23 04:59:02,991 - __main__ - INFO - Inference completed successfully!
2025-09-23 04:59:02,998 - __main__ - INFO - Process completed!
2025-09-24 23:32:59,485 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-24 23:32:59,485 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-24 23:32:59,486 - __main__ - INFO - Starting training pipeline
2025-09-24 23:32:59,587 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-24 23:32:59,610 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-24 23:32:59,610 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-24 23:32:59,611 - __main__ - INFO - Loading training data...
2025-09-24 23:33:43,620 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-24 23:33:43,621 - __main__ - INFO - Processing train split...
2025-09-24 23:33:43,730 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-24 23:33:43,731 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-24 23:34:30,032 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-24 23:35:15,385 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-24 23:36:01,034 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-24 23:36:44,905 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-24 23:37:28,569 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-24 23:38:11,180 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-24 23:38:44,111 - __main__ - INFO - Processing val split...
2025-09-24 23:38:44,334 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-24 23:38:44,334 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-24 23:39:20,340 - __main__ - INFO - Processing test split...
2025-09-24 23:39:20,558 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-24 23:39:20,558 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-24 23:40:05,457 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-24 23:40:05,457 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-24 23:40:05,478 - __main__ - INFO - ‚úÖ Vocabulary created successfully with 13664 words
2025-09-24 23:40:05,478 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-24 23:40:05,478 - __main__ - INFO - Creating model architecture...
2025-09-24 23:40:05,959 - __main__ - INFO - ‚úÖ Model created successfully
2025-09-24 23:40:05,960 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-24 23:40:05,960 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-24 23:40:05,960 - __main__ - INFO - üñ•Ô∏è  Using device: cuda
2025-09-24 23:40:05,960 - __main__ - INFO - Creating trainer...
2025-09-24 23:40:05,960 - __main__ - INFO - üîÑ Moving model to cuda...
2025-09-24 23:40:06,288 - __main__ - INFO - ‚úÖ Model moved to cuda
2025-09-24 23:40:06,288 - __main__ - INFO - üìç Model parameters are on: cuda:0
2025-09-24 23:40:08,338 - __main__ - INFO - ‚úÖ Trainer created successfully
2025-09-24 23:40:08,338 - __main__ - INFO - üìç Trainer model parameters are on: cuda:0
2025-09-24 23:40:08,339 - __main__ - INFO - üöÄ Starting training...
2025-09-24 23:40:08,339 - __main__ - INFO - Training configuration:
2025-09-24 23:40:08,339 - __main__ - INFO -   - Epochs: 100
2025-09-24 23:40:08,339 - __main__ - INFO -   - Batch size: 2
2025-09-24 23:40:08,339 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-24 23:40:08,339 - __main__ - INFO -   - Training samples: 6765
2025-09-24 23:40:08,339 - __main__ - INFO -   - Validation samples: 845
2025-09-24 23:40:08,339 - training.trainer - INFO - Starting training for 100 epochs
2025-09-24 23:40:08,340 - training.trainer - INFO - Model parameters: 16,680,032
2025-09-24 23:40:08,340 - training.trainer - INFO - Training on device: cuda
2025-09-24 23:40:19,935 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.9506, Acc=0.053, PPL=7712.24
2025-09-24 23:40:28,418 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.2589, Acc=0.067, PPL=3861.95
2025-09-24 23:40:36,584 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.9839, Acc=0.058, PPL=2933.43
2025-09-24 23:40:44,596 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.0100, Acc=0.100, PPL=1107.68
2025-09-24 23:40:52,555 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.7248, Acc=0.059, PPL=832.84
2025-09-24 23:41:00,621 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.4946, Acc=0.039, PPL=1798.27
2025-09-24 23:41:08,494 - training.trainer - INFO - Epoch 0, Step 699: Loss=7.0826, Acc=0.114, PPL=1191.01
2025-09-24 23:41:16,235 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.7491, Acc=0.089, PPL=853.30
2025-09-24 23:41:24,017 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.5438, Acc=0.081, PPL=694.94
2025-09-24 23:41:31,935 - training.trainer - INFO - Epoch 0, Step 999: Loss=5.8746, Acc=0.312, PPL=355.90
2025-09-24 23:41:39,615 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.8445, Acc=0.118, PPL=938.68
2025-09-24 23:41:47,432 - training.trainer - INFO - Epoch 0, Step 1199: Loss=7.0797, Acc=0.106, PPL=1187.56
2025-09-24 23:41:55,306 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.8128, Acc=0.150, PPL=909.41
2025-09-24 23:42:03,142 - training.trainer - INFO - Epoch 0, Step 1399: Loss=6.2292, Acc=0.138, PPL=507.36
2025-09-24 23:42:10,883 - training.trainer - INFO - Epoch 0, Step 1499: Loss=7.0059, Acc=0.069, PPL=1103.14
2025-09-24 23:42:18,805 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.4665, Acc=0.091, PPL=643.20
2025-09-24 23:42:26,458 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.3964, Acc=0.103, PPL=599.71
2025-09-24 23:42:34,116 - training.trainer - INFO - Epoch 0, Step 1799: Loss=5.9475, Acc=0.179, PPL=382.81
2025-09-24 23:42:41,723 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.7060, Acc=0.093, PPL=817.26
2025-09-24 23:42:49,378 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.4173, Acc=0.171, PPL=612.36
2025-09-24 23:42:56,937 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.6652, Acc=0.184, PPL=784.62
2025-09-24 23:43:04,551 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.4145, Acc=0.143, PPL=610.64
2025-09-24 23:43:12,305 - training.trainer - INFO - Epoch 0, Step 2299: Loss=7.4090, Acc=0.088, PPL=1650.76
2025-09-24 23:43:19,784 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.5789, Acc=0.158, PPL=719.72
2025-09-24 23:43:27,381 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.9756, Acc=0.098, PPL=1070.25
2025-09-24 23:43:34,830 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.5506, Acc=0.200, PPL=699.63
2025-09-24 23:43:42,385 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.5936, Acc=0.158, PPL=730.40
2025-09-24 23:43:50,093 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.6198, Acc=0.214, PPL=749.80
2025-09-24 23:43:57,683 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.4240, Acc=0.235, PPL=616.48
2025-09-24 23:44:05,249 - training.trainer - INFO - Epoch 0, Step 2999: Loss=5.9307, Acc=0.182, PPL=376.41
2025-09-24 23:44:12,893 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.3576, Acc=0.146, PPL=576.84
2025-09-24 23:44:20,380 - training.trainer - INFO - Epoch 0, Step 3199: Loss=6.3392, Acc=0.154, PPL=566.37
2025-09-24 23:44:27,954 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.6312, Acc=0.115, PPL=758.40
2025-09-24 23:44:47,161 - training.trainer - INFO - Epoch 1/100 completed in 278.82s - Train Loss: 6.8420, Train Acc: 0.128, Val Loss: 6.3642, Val Acc: 0.166
2025-09-24 23:44:48,131 - training.trainer - INFO - New best model saved with validation loss: 6.3642
2025-09-24 23:44:48,131 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-24 23:44:54,944 - training.trainer - INFO - Epoch 1, Step 3482: Loss=6.5788, Acc=0.154, PPL=719.70
2025-09-24 23:45:01,218 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.9270, Acc=0.147, PPL=1019.43
2025-09-24 23:45:07,426 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.2556, Acc=0.143, PPL=520.94
2025-09-24 23:45:14,151 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.4103, Acc=0.125, PPL=608.08
2025-09-24 23:45:21,780 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.6287, Acc=0.132, PPL=756.48
2025-09-24 23:45:29,363 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.1218, Acc=0.176, PPL=455.71
2025-09-24 23:45:36,864 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.0053, Acc=0.269, PPL=405.57
2025-09-24 23:45:44,236 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.1021, Acc=0.167, PPL=446.82
2025-09-24 23:45:51,915 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.2361, Acc=0.141, PPL=510.87
2025-09-24 23:45:59,484 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.4591, Acc=0.143, PPL=638.51
2025-09-24 23:46:07,001 - training.trainer - INFO - Epoch 1, Step 4482: Loss=5.8874, Acc=0.167, PPL=360.48
2025-09-24 23:46:14,625 - training.trainer - INFO - Epoch 1, Step 4582: Loss=5.6823, Acc=0.167, PPL=293.63
2025-09-24 23:46:22,211 - training.trainer - INFO - Epoch 1, Step 4682: Loss=6.3557, Acc=0.220, PPL=575.79
2025-09-24 23:46:29,726 - training.trainer - INFO - Epoch 1, Step 4782: Loss=6.5013, Acc=0.167, PPL=666.01
2025-09-24 23:46:37,205 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.8515, Acc=0.140, PPL=945.27
2025-09-24 23:46:44,548 - training.trainer - INFO - Epoch 1, Step 4982: Loss=5.7958, Acc=0.250, PPL=328.92
2025-09-24 23:46:51,916 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.6473, Acc=0.194, PPL=770.68
2025-09-24 23:46:59,259 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.3907, Acc=0.125, PPL=596.29
2025-09-24 23:47:06,364 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.3652, Acc=0.112, PPL=581.27
2025-09-24 23:47:13,522 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.0827, Acc=0.200, PPL=438.21
2025-09-24 23:47:20,700 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.2200, Acc=0.113, PPL=502.72
2025-09-24 23:47:27,879 - training.trainer - INFO - Epoch 1, Step 5582: Loss=5.6161, Acc=0.286, PPL=274.81
2025-09-24 23:47:35,145 - training.trainer - INFO - Epoch 1, Step 5682: Loss=5.7895, Acc=0.217, PPL=326.85
2025-09-24 23:47:42,354 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.7410, Acc=0.182, PPL=846.43
2025-09-24 23:47:49,539 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.3828, Acc=0.208, PPL=591.55
2025-09-24 23:47:56,764 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.2976, Acc=0.250, PPL=543.26
2025-09-24 23:48:04,051 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.2390, Acc=0.212, PPL=512.33
2025-09-24 23:48:11,225 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.3396, Acc=0.114, PPL=566.58
2025-09-24 23:48:18,454 - training.trainer - INFO - Epoch 1, Step 6282: Loss=5.9205, Acc=0.167, PPL=372.58
2025-09-24 23:48:25,811 - training.trainer - INFO - Epoch 1, Step 6382: Loss=5.9361, Acc=0.190, PPL=378.47
2025-09-24 23:48:33,036 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.5892, Acc=0.103, PPL=727.22
2025-09-24 23:48:40,369 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.3080, Acc=0.211, PPL=548.96
2025-09-24 23:48:47,743 - training.trainer - INFO - Epoch 1, Step 6682: Loss=5.9939, Acc=0.174, PPL=400.97
2025-09-24 23:49:06,225 - training.trainer - INFO - Epoch 2/100 completed in 258.09s - Train Loss: 6.3209, Train Acc: 0.167, Val Loss: 6.2061, Val Acc: 0.174
2025-09-24 23:49:06,856 - training.trainer - INFO - New best model saved with validation loss: 6.2061
2025-09-24 23:49:06,856 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-24 23:49:14,005 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.4280, Acc=0.174, PPL=618.94
2025-09-24 23:49:20,390 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.3150, Acc=0.205, PPL=552.78
2025-09-24 23:49:27,462 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.8182, Acc=0.125, PPL=914.30
2025-09-24 23:49:35,085 - training.trainer - INFO - Epoch 2, Step 7165: Loss=5.7428, Acc=0.167, PPL=311.94
2025-09-24 23:49:42,634 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.1768, Acc=0.172, PPL=481.46
2025-09-24 23:49:50,101 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.1769, Acc=0.237, PPL=481.49
2025-09-24 23:49:57,554 - training.trainer - INFO - Epoch 2, Step 7465: Loss=6.5659, Acc=0.145, PPL=710.47
2025-09-24 23:50:04,814 - training.trainer - INFO - Epoch 2, Step 7565: Loss=5.8089, Acc=0.208, PPL=333.27
2025-09-24 23:50:12,215 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.3570, Acc=0.208, PPL=576.53
2025-09-24 23:50:19,902 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.4798, Acc=0.160, PPL=651.84
2025-09-24 23:50:27,292 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.1387, Acc=0.156, PPL=463.46
2025-09-24 23:50:34,594 - training.trainer - INFO - Epoch 2, Step 7965: Loss=6.6449, Acc=0.113, PPL=768.84
2025-09-24 23:50:41,961 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.6715, Acc=0.104, PPL=789.58
2025-09-24 23:50:49,430 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.9037, Acc=0.231, PPL=995.98
2025-09-24 23:50:56,798 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.1140, Acc=0.122, PPL=452.12
2025-09-24 23:51:04,160 - training.trainer - INFO - Epoch 2, Step 8365: Loss=5.8398, Acc=0.200, PPL=343.71
2025-09-24 23:51:11,547 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.4517, Acc=0.147, PPL=633.75
2025-09-24 23:51:18,953 - training.trainer - INFO - Epoch 2, Step 8565: Loss=6.4911, Acc=0.184, PPL=659.24
2025-09-24 23:51:26,260 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.6992, Acc=0.216, PPL=811.75
2025-09-24 23:51:33,619 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.2108, Acc=0.130, PPL=498.10
2025-09-24 23:51:40,975 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.5712, Acc=0.200, PPL=714.23
2025-09-24 23:51:48,369 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.6620, Acc=0.129, PPL=782.13
2025-09-24 23:51:55,804 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.5885, Acc=0.136, PPL=726.66
2025-09-24 23:52:03,193 - training.trainer - INFO - Epoch 2, Step 9165: Loss=7.1879, Acc=0.136, PPL=1323.38
2025-09-24 23:52:10,559 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.3852, Acc=0.212, PPL=592.99
2025-09-24 23:52:17,939 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.0558, Acc=0.231, PPL=426.60
2025-09-24 23:52:25,366 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.0535, Acc=0.207, PPL=425.60
2025-09-24 23:52:32,714 - training.trainer - INFO - Epoch 2, Step 9565: Loss=5.7159, Acc=0.333, PPL=303.66
2025-09-24 23:52:40,023 - training.trainer - INFO - Epoch 2, Step 9665: Loss=6.4625, Acc=0.156, PPL=640.67
2025-09-24 23:52:47,345 - training.trainer - INFO - Epoch 2, Step 9765: Loss=5.7834, Acc=0.276, PPL=324.87
2025-09-24 23:52:54,785 - training.trainer - INFO - Epoch 2, Step 9865: Loss=5.8100, Acc=0.161, PPL=333.63
2025-09-24 23:53:02,219 - training.trainer - INFO - Epoch 2, Step 9965: Loss=7.1150, Acc=0.222, PPL=1230.34
2025-09-24 23:53:09,928 - training.trainer - INFO - Epoch 2, Step 10065: Loss=6.6519, Acc=0.176, PPL=774.24
2025-09-24 23:53:28,339 - training.trainer - INFO - Epoch 3/100 completed in 261.48s - Train Loss: 6.2023, Train Acc: 0.177, Val Loss: 6.1175, Val Acc: 0.179
2025-09-24 23:53:29,016 - training.trainer - INFO - New best model saved with validation loss: 6.1175
2025-09-24 23:53:29,016 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-24 23:53:35,621 - training.trainer - INFO - Epoch 3, Step 10248: Loss=6.0914, Acc=0.138, PPL=442.02
2025-09-24 23:53:41,920 - training.trainer - INFO - Epoch 3, Step 10348: Loss=5.9230, Acc=0.237, PPL=373.52
2025-09-24 23:53:48,154 - training.trainer - INFO - Epoch 3, Step 10448: Loss=5.7793, Acc=0.261, PPL=323.53
2025-09-24 23:53:54,469 - training.trainer - INFO - Epoch 3, Step 10548: Loss=6.2165, Acc=0.131, PPL=500.96
2025-09-24 23:54:00,764 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.7176, Acc=0.182, PPL=826.84
2025-09-24 23:54:07,210 - training.trainer - INFO - Epoch 3, Step 10748: Loss=5.6507, Acc=0.211, PPL=284.49
2025-09-24 23:54:13,468 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.5854, Acc=0.226, PPL=724.41
2025-09-24 23:54:19,747 - training.trainer - INFO - Epoch 3, Step 10948: Loss=4.5428, Acc=0.261, PPL=93.95
2025-09-24 23:54:26,008 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.0887, Acc=0.145, PPL=440.86
2025-09-24 23:54:32,219 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.6263, Acc=0.116, PPL=754.70
2025-09-24 23:54:38,527 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.7024, Acc=0.176, PPL=814.37
2025-09-24 23:54:44,763 - training.trainer - INFO - Epoch 3, Step 11348: Loss=6.1445, Acc=0.143, PPL=466.13
2025-09-24 23:54:51,003 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.2735, Acc=0.119, PPL=530.32
2025-09-24 23:54:57,545 - training.trainer - INFO - Epoch 3, Step 11548: Loss=5.3215, Acc=0.357, PPL=204.70
2025-09-24 23:55:04,154 - training.trainer - INFO - Epoch 3, Step 11648: Loss=5.8381, Acc=0.240, PPL=343.12
2025-09-24 23:55:10,474 - training.trainer - INFO - Epoch 3, Step 11748: Loss=6.2595, Acc=0.075, PPL=522.98
2025-09-24 23:55:16,704 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.9690, Acc=0.227, PPL=391.12
2025-09-24 23:55:23,026 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.2461, Acc=0.184, PPL=516.00
2025-09-24 23:55:29,358 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.2582, Acc=0.263, PPL=522.28
2025-09-24 23:55:35,887 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.0489, Acc=0.182, PPL=423.65
2025-09-24 23:55:42,190 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.1515, Acc=0.128, PPL=469.43
2025-09-24 23:55:48,371 - training.trainer - INFO - Epoch 3, Step 12348: Loss=5.8189, Acc=0.175, PPL=336.61
2025-09-24 23:55:54,930 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.3528, Acc=0.128, PPL=574.07
2025-09-24 23:56:01,848 - training.trainer - INFO - Epoch 3, Step 12548: Loss=5.5325, Acc=0.227, PPL=252.79
2025-09-24 23:56:08,933 - training.trainer - INFO - Epoch 3, Step 12648: Loss=5.7236, Acc=0.231, PPL=306.00
2025-09-24 23:56:15,908 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.2493, Acc=0.200, PPL=517.63
2025-09-24 23:56:22,840 - training.trainer - INFO - Epoch 3, Step 12848: Loss=5.9858, Acc=0.238, PPL=397.72
2025-09-24 23:56:30,573 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.0725, Acc=0.159, PPL=433.75
2025-09-24 23:56:38,000 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.9118, Acc=0.135, PPL=1004.07
2025-09-24 23:56:45,611 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.9398, Acc=0.122, PPL=1032.60
2025-09-24 23:56:52,954 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.4809, Acc=0.123, PPL=652.54
2025-09-24 23:57:00,270 - training.trainer - INFO - Epoch 3, Step 13348: Loss=6.5549, Acc=0.108, PPL=702.70
2025-09-24 23:57:07,718 - training.trainer - INFO - Epoch 3, Step 13448: Loss=5.8340, Acc=0.227, PPL=341.72
2025-09-24 23:57:26,060 - training.trainer - INFO - Epoch 4/100 completed in 237.04s - Train Loss: 6.1344, Train Acc: 0.184, Val Loss: 6.0475, Val Acc: 0.195
2025-09-24 23:57:26,760 - training.trainer - INFO - New best model saved with validation loss: 6.0475
2025-09-24 23:57:26,761 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-24 23:57:34,763 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.3738, Acc=0.190, PPL=586.27
2025-09-24 23:57:42,075 - training.trainer - INFO - Epoch 4, Step 13731: Loss=5.9262, Acc=0.214, PPL=374.72
2025-09-24 23:57:49,384 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.7369, Acc=0.143, PPL=842.93
2025-09-24 23:57:56,939 - training.trainer - INFO - Epoch 4, Step 13931: Loss=6.6335, Acc=0.235, PPL=760.11
2025-09-24 23:58:04,254 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.8044, Acc=0.227, PPL=331.77
2025-09-24 23:58:11,620 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.3545, Acc=0.125, PPL=575.10
2025-09-24 23:58:18,913 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.3500, Acc=0.148, PPL=572.47
2025-09-24 23:58:26,343 - training.trainer - INFO - Epoch 4, Step 14331: Loss=6.5381, Acc=0.140, PPL=690.99
2025-09-24 23:58:33,617 - training.trainer - INFO - Epoch 4, Step 14431: Loss=5.8250, Acc=0.200, PPL=338.66
2025-09-24 23:58:40,871 - training.trainer - INFO - Epoch 4, Step 14531: Loss=6.0637, Acc=0.148, PPL=429.97
2025-09-24 23:58:48,151 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.0909, Acc=0.128, PPL=441.82
2025-09-24 23:58:55,517 - training.trainer - INFO - Epoch 4, Step 14731: Loss=6.0084, Acc=0.182, PPL=406.84
2025-09-24 23:59:02,903 - training.trainer - INFO - Epoch 4, Step 14831: Loss=6.1028, Acc=0.138, PPL=447.10
2025-09-24 23:59:10,184 - training.trainer - INFO - Epoch 4, Step 14931: Loss=6.3019, Acc=0.207, PPL=545.60
2025-09-24 23:59:17,437 - training.trainer - INFO - Epoch 4, Step 15031: Loss=5.7067, Acc=0.389, PPL=300.88
2025-09-24 23:59:24,701 - training.trainer - INFO - Epoch 4, Step 15131: Loss=6.6797, Acc=0.108, PPL=796.10
2025-09-24 23:59:32,022 - training.trainer - INFO - Epoch 4, Step 15231: Loss=6.6567, Acc=0.141, PPL=778.01
2025-09-24 23:59:39,244 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.2331, Acc=0.191, PPL=509.35
2025-09-24 23:59:46,481 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.3030, Acc=0.172, PPL=546.22
2025-09-24 23:59:53,750 - training.trainer - INFO - Epoch 4, Step 15531: Loss=5.9456, Acc=0.162, PPL=382.07
2025-09-25 00:00:00,971 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.8280, Acc=0.146, PPL=923.34
2025-09-25 00:00:08,256 - training.trainer - INFO - Epoch 4, Step 15731: Loss=5.8994, Acc=0.222, PPL=364.80
2025-09-25 00:00:15,659 - training.trainer - INFO - Epoch 4, Step 15831: Loss=6.0094, Acc=0.174, PPL=407.23
2025-09-25 00:00:22,892 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.3111, Acc=0.189, PPL=550.65
2025-09-25 00:00:30,216 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.3092, Acc=0.227, PPL=549.62
2025-09-25 00:00:37,567 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.3273, Acc=0.207, PPL=559.64
2025-09-25 00:00:44,845 - training.trainer - INFO - Epoch 4, Step 16231: Loss=5.9746, Acc=0.192, PPL=393.32
2025-09-25 00:00:52,082 - training.trainer - INFO - Epoch 4, Step 16331: Loss=5.2237, Acc=0.136, PPL=185.62
2025-09-25 00:00:59,288 - training.trainer - INFO - Epoch 4, Step 16431: Loss=5.4151, Acc=0.235, PPL=224.77
2025-09-25 00:01:06,476 - training.trainer - INFO - Epoch 4, Step 16531: Loss=5.7989, Acc=0.250, PPL=329.95
2025-09-25 00:01:13,720 - training.trainer - INFO - Epoch 4, Step 16631: Loss=6.2618, Acc=0.143, PPL=524.15
2025-09-25 00:01:21,005 - training.trainer - INFO - Epoch 4, Step 16731: Loss=5.8862, Acc=0.162, PPL=360.02
2025-09-25 00:01:28,305 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.3256, Acc=0.261, PPL=558.69
2025-09-25 00:01:47,578 - training.trainer - INFO - Epoch 5/100 completed in 260.82s - Train Loss: 6.0775, Train Acc: 0.193, Val Loss: 6.0068, Val Acc: 0.199
2025-09-25 00:01:47,967 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-25 00:01:48,779 - training.trainer - INFO - New best model saved with validation loss: 6.0068
2025-09-25 00:01:48,780 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-25 00:01:56,510 - training.trainer - INFO - Epoch 5, Step 17014: Loss=5.9409, Acc=0.211, PPL=380.29
2025-09-25 00:02:03,873 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.2527, Acc=0.140, PPL=519.40
2025-09-25 00:02:11,083 - training.trainer - INFO - Epoch 5, Step 17214: Loss=6.0397, Acc=0.233, PPL=419.78
2025-09-25 00:02:18,434 - training.trainer - INFO - Epoch 5, Step 17314: Loss=5.5539, Acc=0.280, PPL=258.25
2025-09-25 00:02:25,820 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.1588, Acc=0.179, PPL=472.85
2025-09-25 00:02:33,171 - training.trainer - INFO - Epoch 5, Step 17514: Loss=5.1031, Acc=0.174, PPL=164.54
2025-09-25 00:02:40,507 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.1976, Acc=0.196, PPL=491.55
2025-09-25 00:02:47,985 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.0898, Acc=0.220, PPL=441.33
2025-09-25 00:02:55,272 - training.trainer - INFO - Epoch 5, Step 17814: Loss=6.3456, Acc=0.132, PPL=569.99
2025-09-25 00:03:02,571 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.9463, Acc=0.170, PPL=1039.34
2025-09-25 00:03:09,905 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.2679, Acc=0.160, PPL=527.39
2025-09-25 00:03:17,183 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.0659, Acc=0.154, PPL=430.92
2025-09-25 00:03:24,632 - training.trainer - INFO - Epoch 5, Step 18214: Loss=6.7344, Acc=0.088, PPL=840.84
2025-09-25 00:03:32,253 - training.trainer - INFO - Epoch 5, Step 18314: Loss=5.1726, Acc=0.400, PPL=176.38
2025-09-25 00:03:39,670 - training.trainer - INFO - Epoch 5, Step 18414: Loss=6.0324, Acc=0.156, PPL=416.73
2025-09-25 00:03:47,161 - training.trainer - INFO - Epoch 5, Step 18514: Loss=5.5918, Acc=0.139, PPL=268.21
2025-09-25 00:03:54,749 - training.trainer - INFO - Epoch 5, Step 18614: Loss=6.2087, Acc=0.317, PPL=497.06
2025-09-25 00:04:02,478 - training.trainer - INFO - Epoch 5, Step 18714: Loss=5.6850, Acc=0.200, PPL=294.42
2025-09-25 00:04:09,946 - training.trainer - INFO - Epoch 5, Step 18814: Loss=6.2138, Acc=0.273, PPL=499.57
2025-09-25 00:04:17,433 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.7239, Acc=0.095, PPL=832.02
2025-09-25 00:04:25,012 - training.trainer - INFO - Epoch 5, Step 19014: Loss=5.3990, Acc=0.333, PPL=221.18
2025-09-25 00:04:32,524 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.3207, Acc=0.211, PPL=555.95
2025-09-25 00:04:39,961 - training.trainer - INFO - Epoch 5, Step 19214: Loss=5.4914, Acc=0.238, PPL=242.61
2025-09-25 00:04:47,332 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.3420, Acc=0.200, PPL=567.95
2025-09-25 00:04:54,841 - training.trainer - INFO - Epoch 5, Step 19414: Loss=6.1078, Acc=0.122, PPL=449.33
2025-09-25 00:05:02,218 - training.trainer - INFO - Epoch 5, Step 19514: Loss=5.7295, Acc=0.261, PPL=307.81
2025-09-25 00:05:09,583 - training.trainer - INFO - Epoch 5, Step 19614: Loss=5.3472, Acc=0.312, PPL=210.02
2025-09-25 00:05:16,859 - training.trainer - INFO - Epoch 5, Step 19714: Loss=5.8071, Acc=0.250, PPL=332.64
2025-09-25 00:05:24,276 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.0828, Acc=0.281, PPL=438.27
2025-09-25 00:05:31,748 - training.trainer - INFO - Epoch 5, Step 19914: Loss=6.1646, Acc=0.171, PPL=475.63
2025-09-25 00:05:39,149 - training.trainer - INFO - Epoch 5, Step 20014: Loss=4.4194, Acc=0.412, PPL=83.04
2025-09-25 00:05:46,631 - training.trainer - INFO - Epoch 5, Step 20114: Loss=6.6751, Acc=0.261, PPL=792.45
2025-09-25 00:05:54,071 - training.trainer - INFO - Epoch 5, Step 20214: Loss=4.6391, Acc=0.294, PPL=103.45
2025-09-25 00:06:12,735 - training.trainer - INFO - Epoch 6/100 completed in 263.95s - Train Loss: 6.0271, Train Acc: 0.200, Val Loss: 5.9692, Val Acc: 0.208
2025-09-25 00:06:13,474 - training.trainer - INFO - New best model saved with validation loss: 5.9692
2025-09-25 00:06:13,474 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-25 00:06:21,486 - training.trainer - INFO - Epoch 6, Step 20397: Loss=5.7616, Acc=0.117, PPL=317.85
2025-09-25 00:06:28,889 - training.trainer - INFO - Epoch 6, Step 20497: Loss=6.2023, Acc=0.204, PPL=493.91
2025-09-25 00:06:36,347 - training.trainer - INFO - Epoch 6, Step 20597: Loss=5.6440, Acc=0.256, PPL=282.60
2025-09-25 00:06:43,958 - training.trainer - INFO - Epoch 6, Step 20697: Loss=6.2538, Acc=0.200, PPL=519.97
2025-09-25 00:06:51,794 - training.trainer - INFO - Epoch 6, Step 20797: Loss=6.3096, Acc=0.130, PPL=549.82
2025-09-25 00:06:59,384 - training.trainer - INFO - Epoch 6, Step 20897: Loss=5.5178, Acc=0.250, PPL=249.10
2025-09-25 00:07:06,961 - training.trainer - INFO - Epoch 6, Step 20997: Loss=6.7870, Acc=0.130, PPL=886.24
2025-09-25 00:07:14,568 - training.trainer - INFO - Epoch 6, Step 21097: Loss=5.7238, Acc=0.255, PPL=306.07
2025-09-25 00:07:22,043 - training.trainer - INFO - Epoch 6, Step 21197: Loss=5.4386, Acc=0.212, PPL=230.11
2025-09-25 00:07:29,577 - training.trainer - INFO - Epoch 6, Step 21297: Loss=6.6511, Acc=0.093, PPL=773.60
2025-09-25 00:07:37,152 - training.trainer - INFO - Epoch 6, Step 21397: Loss=5.6235, Acc=0.111, PPL=276.85
2025-09-25 00:07:44,984 - training.trainer - INFO - Epoch 6, Step 21497: Loss=5.9910, Acc=0.176, PPL=399.83
2025-09-25 00:07:52,715 - training.trainer - INFO - Epoch 6, Step 21597: Loss=6.1801, Acc=0.255, PPL=483.06
2025-09-25 00:08:00,534 - training.trainer - INFO - Epoch 6, Step 21697: Loss=4.9662, Acc=0.393, PPL=143.47
2025-09-25 00:08:08,250 - training.trainer - INFO - Epoch 6, Step 21797: Loss=5.4389, Acc=0.208, PPL=230.18
2025-09-25 00:08:15,834 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.3989, Acc=0.125, PPL=601.18
2025-09-25 00:08:23,432 - training.trainer - INFO - Epoch 6, Step 21997: Loss=5.7708, Acc=0.182, PPL=320.80
2025-09-25 00:08:30,864 - training.trainer - INFO - Epoch 6, Step 22097: Loss=5.7569, Acc=0.174, PPL=316.37
2025-09-25 00:08:38,278 - training.trainer - INFO - Epoch 6, Step 22197: Loss=5.3086, Acc=0.206, PPL=202.07
2025-09-25 00:08:45,689 - training.trainer - INFO - Epoch 6, Step 22297: Loss=5.9255, Acc=0.222, PPL=374.45
2025-09-25 00:08:53,088 - training.trainer - INFO - Epoch 6, Step 22397: Loss=5.3915, Acc=0.267, PPL=219.54
2025-09-25 00:09:00,482 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.2273, Acc=0.154, PPL=506.39
2025-09-25 00:09:07,851 - training.trainer - INFO - Epoch 6, Step 22597: Loss=6.1329, Acc=0.188, PPL=460.75
2025-09-25 00:09:15,319 - training.trainer - INFO - Epoch 6, Step 22697: Loss=5.6954, Acc=0.357, PPL=297.51
2025-09-25 00:09:22,827 - training.trainer - INFO - Epoch 6, Step 22797: Loss=5.7488, Acc=0.235, PPL=313.82
2025-09-25 00:09:30,377 - training.trainer - INFO - Epoch 6, Step 22897: Loss=5.6508, Acc=0.241, PPL=284.52
2025-09-25 00:09:37,818 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.2854, Acc=0.206, PPL=536.67
2025-09-25 00:09:45,270 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.0237, Acc=0.150, PPL=413.09
2025-09-25 00:09:52,752 - training.trainer - INFO - Epoch 6, Step 23197: Loss=5.7623, Acc=0.316, PPL=318.08
2025-09-25 00:10:00,268 - training.trainer - INFO - Epoch 6, Step 23297: Loss=6.5744, Acc=0.118, PPL=716.52
2025-09-25 00:10:07,755 - training.trainer - INFO - Epoch 6, Step 23397: Loss=5.4338, Acc=0.267, PPL=229.02
2025-09-25 00:10:15,123 - training.trainer - INFO - Epoch 6, Step 23497: Loss=6.4553, Acc=0.143, PPL=636.09
2025-09-25 00:10:22,625 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.5703, Acc=0.143, PPL=713.57
2025-09-25 00:10:41,734 - training.trainer - INFO - Epoch 7/100 completed in 268.26s - Train Loss: 5.9929, Train Acc: 0.206, Val Loss: 5.9162, Val Acc: 0.217
2025-09-25 00:10:42,232 - training.trainer - INFO - New best model saved with validation loss: 5.9162
2025-09-25 00:10:42,232 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-25 00:10:49,067 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.1096, Acc=0.185, PPL=450.16
2025-09-25 00:10:55,433 - training.trainer - INFO - Epoch 7, Step 23880: Loss=6.1595, Acc=0.231, PPL=473.17
2025-09-25 00:11:01,856 - training.trainer - INFO - Epoch 7, Step 23980: Loss=6.2631, Acc=0.154, PPL=524.83
2025-09-25 00:11:09,069 - training.trainer - INFO - Epoch 7, Step 24080: Loss=6.0302, Acc=0.212, PPL=415.81
2025-09-25 00:11:16,663 - training.trainer - INFO - Epoch 7, Step 24180: Loss=6.4217, Acc=0.146, PPL=615.07
2025-09-25 00:11:24,242 - training.trainer - INFO - Epoch 7, Step 24280: Loss=5.3953, Acc=0.250, PPL=220.37
2025-09-25 00:11:31,906 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.4998, Acc=0.130, PPL=665.00
2025-09-25 00:11:39,405 - training.trainer - INFO - Epoch 7, Step 24480: Loss=6.4281, Acc=0.400, PPL=618.99
2025-09-25 00:11:46,946 - training.trainer - INFO - Epoch 7, Step 24580: Loss=5.9329, Acc=0.296, PPL=377.24
2025-09-25 00:11:54,331 - training.trainer - INFO - Epoch 7, Step 24680: Loss=6.9505, Acc=0.123, PPL=1043.71
2025-09-25 00:12:01,702 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.1813, Acc=0.231, PPL=483.62
2025-09-25 00:12:09,050 - training.trainer - INFO - Epoch 7, Step 24880: Loss=6.3119, Acc=0.200, PPL=551.11
2025-09-25 00:12:16,556 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.6604, Acc=0.171, PPL=287.25
2025-09-25 00:12:23,880 - training.trainer - INFO - Epoch 7, Step 25080: Loss=6.5254, Acc=0.163, PPL=682.22
2025-09-25 00:12:31,470 - training.trainer - INFO - Epoch 7, Step 25180: Loss=6.4134, Acc=0.128, PPL=609.97
2025-09-25 00:12:38,984 - training.trainer - INFO - Epoch 7, Step 25280: Loss=5.9250, Acc=0.143, PPL=374.27
2025-09-25 00:12:46,414 - training.trainer - INFO - Epoch 7, Step 25380: Loss=6.2083, Acc=0.226, PPL=496.86
2025-09-25 00:12:53,917 - training.trainer - INFO - Epoch 7, Step 25480: Loss=6.7692, Acc=0.116, PPL=870.60
2025-09-25 00:13:01,352 - training.trainer - INFO - Epoch 7, Step 25580: Loss=5.9109, Acc=0.137, PPL=369.06
2025-09-25 00:13:08,877 - training.trainer - INFO - Epoch 7, Step 25680: Loss=6.5568, Acc=0.195, PPL=704.01
2025-09-25 00:13:16,227 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.0824, Acc=0.229, PPL=438.09
2025-09-25 00:13:23,606 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.0375, Acc=0.185, PPL=418.84
2025-09-25 00:13:30,937 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.2576, Acc=0.167, PPL=521.97
2025-09-25 00:13:38,526 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.0204, Acc=0.231, PPL=411.76
2025-09-25 00:13:45,899 - training.trainer - INFO - Epoch 7, Step 26180: Loss=6.2991, Acc=0.113, PPL=544.06
2025-09-25 00:13:53,372 - training.trainer - INFO - Epoch 7, Step 26280: Loss=6.6236, Acc=0.167, PPL=752.61
2025-09-25 00:14:00,909 - training.trainer - INFO - Epoch 7, Step 26380: Loss=4.1695, Acc=0.389, PPL=64.68
2025-09-25 00:14:08,491 - training.trainer - INFO - Epoch 7, Step 26480: Loss=5.8579, Acc=0.226, PPL=349.98
2025-09-25 00:14:15,863 - training.trainer - INFO - Epoch 7, Step 26580: Loss=6.0761, Acc=0.242, PPL=435.31
2025-09-25 00:14:23,370 - training.trainer - INFO - Epoch 7, Step 26680: Loss=6.0138, Acc=0.316, PPL=409.05
2025-09-25 00:14:30,892 - training.trainer - INFO - Epoch 7, Step 26780: Loss=5.8829, Acc=0.210, PPL=358.86
2025-09-25 00:14:38,785 - training.trainer - INFO - Epoch 7, Step 26880: Loss=5.5795, Acc=0.273, PPL=264.94
2025-09-25 00:14:46,228 - training.trainer - INFO - Epoch 7, Step 26980: Loss=6.1875, Acc=0.216, PPL=486.65
2025-09-25 00:15:05,594 - training.trainer - INFO - Epoch 8/100 completed in 263.36s - Train Loss: 5.9486, Train Acc: 0.213, Val Loss: 5.8831, Val Acc: 0.221
2025-09-25 00:15:06,218 - training.trainer - INFO - New best model saved with validation loss: 5.8831
2025-09-25 00:15:06,218 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-09-25 00:15:13,421 - training.trainer - INFO - Epoch 8, Step 27163: Loss=4.5523, Acc=0.364, PPL=94.85
2025-09-25 00:15:20,278 - training.trainer - INFO - Epoch 8, Step 27263: Loss=6.3283, Acc=0.158, PPL=560.23
2025-09-25 00:15:26,645 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.3852, Acc=0.222, PPL=218.15
2025-09-25 00:15:32,926 - training.trainer - INFO - Epoch 8, Step 27463: Loss=6.1196, Acc=0.194, PPL=454.70
2025-09-25 00:15:39,529 - training.trainer - INFO - Epoch 8, Step 27563: Loss=6.0666, Acc=0.232, PPL=431.22
2025-09-25 00:15:46,900 - training.trainer - INFO - Epoch 8, Step 27663: Loss=5.3098, Acc=0.242, PPL=202.31
2025-09-25 00:15:54,413 - training.trainer - INFO - Epoch 8, Step 27763: Loss=5.3725, Acc=0.279, PPL=215.40
2025-09-25 00:16:01,745 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.5063, Acc=0.196, PPL=669.34
2025-09-25 00:16:09,079 - training.trainer - INFO - Epoch 8, Step 27963: Loss=6.4499, Acc=0.130, PPL=632.62
2025-09-25 00:16:16,356 - training.trainer - INFO - Epoch 8, Step 28063: Loss=5.5139, Acc=0.270, PPL=248.12
2025-09-25 00:16:23,723 - training.trainer - INFO - Epoch 8, Step 28163: Loss=6.0689, Acc=0.208, PPL=432.20
2025-09-25 00:16:31,058 - training.trainer - INFO - Epoch 8, Step 28263: Loss=6.1497, Acc=0.179, PPL=468.57
2025-09-25 00:16:38,583 - training.trainer - INFO - Epoch 8, Step 28363: Loss=5.5869, Acc=0.240, PPL=266.91
2025-09-25 00:16:45,791 - training.trainer - INFO - Epoch 8, Step 28463: Loss=5.5001, Acc=0.116, PPL=244.70
2025-09-25 00:16:53,288 - training.trainer - INFO - Epoch 8, Step 28563: Loss=5.6605, Acc=0.148, PPL=287.28
2025-09-25 00:17:00,625 - training.trainer - INFO - Epoch 8, Step 28663: Loss=6.0555, Acc=0.162, PPL=426.44
2025-09-25 00:17:07,874 - training.trainer - INFO - Epoch 8, Step 28763: Loss=5.9485, Acc=0.286, PPL=383.16
2025-09-25 00:17:15,078 - training.trainer - INFO - Epoch 8, Step 28863: Loss=6.8717, Acc=0.100, PPL=964.55
2025-09-25 00:17:22,540 - training.trainer - INFO - Epoch 8, Step 28963: Loss=5.6524, Acc=0.216, PPL=284.99
2025-09-25 00:17:29,749 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.3092, Acc=0.154, PPL=549.63
2025-09-25 00:17:37,007 - training.trainer - INFO - Epoch 8, Step 29163: Loss=6.8876, Acc=0.106, PPL=980.02
2025-09-25 00:17:44,247 - training.trainer - INFO - Epoch 8, Step 29263: Loss=5.9132, Acc=0.250, PPL=369.88
2025-09-25 00:17:51,412 - training.trainer - INFO - Epoch 8, Step 29363: Loss=5.7237, Acc=0.255, PPL=306.03
2025-09-25 00:17:58,775 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.2495, Acc=0.188, PPL=517.77
2025-09-25 00:18:06,254 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.8526, Acc=0.161, PPL=348.15
2025-09-25 00:18:13,594 - training.trainer - INFO - Epoch 8, Step 29663: Loss=5.7452, Acc=0.263, PPL=312.68
2025-09-25 00:18:20,899 - training.trainer - INFO - Epoch 8, Step 29763: Loss=5.8962, Acc=0.333, PPL=363.66
2025-09-25 00:18:28,119 - training.trainer - INFO - Epoch 8, Step 29863: Loss=5.9251, Acc=0.292, PPL=374.33
2025-09-25 00:18:35,304 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.3472, Acc=0.130, PPL=570.91
2025-09-25 00:18:42,552 - training.trainer - INFO - Epoch 8, Step 30063: Loss=6.3721, Acc=0.151, PPL=585.26
2025-09-25 00:18:49,786 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.4165, Acc=0.275, PPL=225.09
2025-09-25 00:18:56,966 - training.trainer - INFO - Epoch 8, Step 30263: Loss=6.8534, Acc=0.179, PPL=947.13
2025-09-25 00:19:04,087 - training.trainer - INFO - Epoch 8, Step 30363: Loss=5.9032, Acc=0.226, PPL=366.22
2025-09-25 00:19:22,894 - training.trainer - INFO - Epoch 9/100 completed in 256.68s - Train Loss: 5.9136, Train Acc: 0.219, Val Loss: 5.8471, Val Acc: 0.226
2025-09-25 00:19:23,668 - training.trainer - INFO - New best model saved with validation loss: 5.8471
2025-09-25 00:19:23,668 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-25 00:19:30,408 - training.trainer - INFO - Epoch 9, Step 30546: Loss=4.9431, Acc=0.318, PPL=140.20
2025-09-25 00:19:36,496 - training.trainer - INFO - Epoch 9, Step 30646: Loss=6.3604, Acc=0.192, PPL=578.48
2025-09-25 00:19:42,909 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.5932, Acc=0.146, PPL=730.09
2025-09-25 00:19:49,101 - training.trainer - INFO - Epoch 9, Step 30846: Loss=5.5338, Acc=0.241, PPL=253.11
2025-09-25 00:19:56,598 - training.trainer - INFO - Epoch 9, Step 30946: Loss=6.0653, Acc=0.250, PPL=430.65
2025-09-25 00:20:03,839 - training.trainer - INFO - Epoch 9, Step 31046: Loss=6.4500, Acc=0.174, PPL=632.69
2025-09-25 00:20:11,026 - training.trainer - INFO - Epoch 9, Step 31146: Loss=5.5133, Acc=0.207, PPL=247.98
2025-09-25 00:20:18,614 - training.trainer - INFO - Epoch 9, Step 31246: Loss=5.5067, Acc=0.364, PPL=246.34
2025-09-25 00:20:25,953 - training.trainer - INFO - Epoch 9, Step 31346: Loss=5.7507, Acc=0.261, PPL=314.40
2025-09-25 00:20:33,089 - training.trainer - INFO - Epoch 9, Step 31446: Loss=5.8804, Acc=0.105, PPL=357.94
2025-09-25 00:20:40,246 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.9916, Acc=0.261, PPL=400.04
2025-09-25 00:20:47,495 - training.trainer - INFO - Epoch 9, Step 31646: Loss=6.3750, Acc=0.115, PPL=587.01
2025-09-25 00:20:54,651 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.4076, Acc=0.312, PPL=223.10
2025-09-25 00:21:01,837 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.1015, Acc=0.200, PPL=446.53
2025-09-25 00:21:09,043 - training.trainer - INFO - Epoch 9, Step 31946: Loss=5.9567, Acc=0.214, PPL=386.33
2025-09-25 00:21:16,566 - training.trainer - INFO - Epoch 9, Step 32046: Loss=4.9529, Acc=0.333, PPL=141.59
2025-09-25 00:21:24,231 - training.trainer - INFO - Epoch 9, Step 32146: Loss=5.9551, Acc=0.143, PPL=385.72
2025-09-25 00:21:31,723 - training.trainer - INFO - Epoch 9, Step 32246: Loss=6.4129, Acc=0.216, PPL=609.64
2025-09-25 00:21:39,137 - training.trainer - INFO - Epoch 9, Step 32346: Loss=6.5123, Acc=0.196, PPL=673.39
2025-09-25 00:21:46,402 - training.trainer - INFO - Epoch 9, Step 32446: Loss=6.2187, Acc=0.180, PPL=502.03
2025-09-25 00:21:53,991 - training.trainer - INFO - Epoch 9, Step 32546: Loss=4.7788, Acc=0.333, PPL=118.97
2025-09-25 00:22:01,406 - training.trainer - INFO - Epoch 9, Step 32646: Loss=6.0276, Acc=0.200, PPL=414.72
2025-09-25 00:22:08,865 - training.trainer - INFO - Epoch 9, Step 32746: Loss=6.1956, Acc=0.263, PPL=490.58
2025-09-25 00:22:16,488 - training.trainer - INFO - Epoch 9, Step 32846: Loss=6.2598, Acc=0.143, PPL=523.13
2025-09-25 00:22:24,020 - training.trainer - INFO - Epoch 9, Step 32946: Loss=5.3064, Acc=0.212, PPL=201.62
2025-09-25 00:22:31,534 - training.trainer - INFO - Epoch 9, Step 33046: Loss=5.7362, Acc=0.211, PPL=309.88
2025-09-25 00:22:38,857 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.3767, Acc=0.222, PPL=587.96
2025-09-25 00:22:46,291 - training.trainer - INFO - Epoch 9, Step 33246: Loss=6.0596, Acc=0.250, PPL=428.21
2025-09-25 00:22:53,840 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.2674, Acc=0.172, PPL=527.11
2025-09-25 00:23:01,418 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.0756, Acc=0.186, PPL=435.09
2025-09-25 00:23:08,789 - training.trainer - INFO - Epoch 9, Step 33546: Loss=6.4582, Acc=0.158, PPL=637.93
2025-09-25 00:23:16,080 - training.trainer - INFO - Epoch 9, Step 33646: Loss=5.8196, Acc=0.227, PPL=336.83
2025-09-25 00:23:23,405 - training.trainer - INFO - Epoch 9, Step 33746: Loss=6.5709, Acc=0.161, PPL=714.00
2025-09-25 00:23:41,954 - training.trainer - INFO - Epoch 10/100 completed in 258.29s - Train Loss: 5.8788, Train Acc: 0.222, Val Loss: 5.8297, Val Acc: 0.230
2025-09-25 00:23:42,393 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-25 00:23:43,236 - training.trainer - INFO - New best model saved with validation loss: 5.8297
2025-09-25 00:23:43,237 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-25 00:23:51,111 - training.trainer - INFO - Epoch 10, Step 33929: Loss=6.2372, Acc=0.222, PPL=511.42
2025-09-25 00:23:58,319 - training.trainer - INFO - Epoch 10, Step 34029: Loss=5.9865, Acc=0.234, PPL=398.00
2025-09-25 00:24:05,592 - training.trainer - INFO - Epoch 10, Step 34129: Loss=5.9357, Acc=0.194, PPL=378.30
2025-09-25 00:24:13,184 - training.trainer - INFO - Epoch 10, Step 34229: Loss=5.8111, Acc=0.262, PPL=333.97
2025-09-25 00:24:20,702 - training.trainer - INFO - Epoch 10, Step 34329: Loss=5.8746, Acc=0.158, PPL=355.89
2025-09-25 00:24:28,280 - training.trainer - INFO - Epoch 10, Step 34429: Loss=6.4129, Acc=0.177, PPL=609.64
2025-09-25 00:24:35,677 - training.trainer - INFO - Epoch 10, Step 34529: Loss=4.4222, Acc=0.556, PPL=83.28
2025-09-25 00:24:43,267 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.6746, Acc=0.267, PPL=291.38
2025-09-25 00:24:50,677 - training.trainer - INFO - Epoch 10, Step 34729: Loss=6.3457, Acc=0.278, PPL=570.04
2025-09-25 00:24:58,149 - training.trainer - INFO - Epoch 10, Step 34829: Loss=6.2723, Acc=0.182, PPL=529.70
2025-09-25 00:25:05,631 - training.trainer - INFO - Epoch 10, Step 34929: Loss=6.3779, Acc=0.190, PPL=588.69
2025-09-25 00:25:13,304 - training.trainer - INFO - Epoch 10, Step 35029: Loss=5.4332, Acc=0.286, PPL=228.88
2025-09-25 00:25:20,713 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.3508, Acc=0.167, PPL=572.94
2025-09-25 00:25:28,092 - training.trainer - INFO - Epoch 10, Step 35229: Loss=5.5207, Acc=0.219, PPL=249.80
2025-09-25 00:25:35,435 - training.trainer - INFO - Epoch 10, Step 35329: Loss=6.4711, Acc=0.140, PPL=646.22
2025-09-25 00:25:42,863 - training.trainer - INFO - Epoch 10, Step 35429: Loss=6.2162, Acc=0.207, PPL=500.80
2025-09-25 00:25:50,274 - training.trainer - INFO - Epoch 10, Step 35529: Loss=6.1073, Acc=0.250, PPL=449.12
2025-09-25 00:25:57,563 - training.trainer - INFO - Epoch 10, Step 35629: Loss=6.0099, Acc=0.231, PPL=407.45
2025-09-25 00:26:04,792 - training.trainer - INFO - Epoch 10, Step 35729: Loss=6.1327, Acc=0.169, PPL=460.69
2025-09-25 00:26:12,135 - training.trainer - INFO - Epoch 10, Step 35829: Loss=5.7704, Acc=0.233, PPL=320.67
2025-09-25 00:26:19,516 - training.trainer - INFO - Epoch 10, Step 35929: Loss=6.2693, Acc=0.118, PPL=528.12
2025-09-25 00:26:27,251 - training.trainer - INFO - Epoch 10, Step 36029: Loss=6.1520, Acc=0.231, PPL=469.68
2025-09-25 00:26:34,726 - training.trainer - INFO - Epoch 10, Step 36129: Loss=6.8194, Acc=0.152, PPL=915.40
2025-09-25 00:26:42,050 - training.trainer - INFO - Epoch 10, Step 36229: Loss=6.2661, Acc=0.172, PPL=526.41
2025-09-25 00:26:49,495 - training.trainer - INFO - Epoch 10, Step 36329: Loss=5.7468, Acc=0.241, PPL=313.18
2025-09-25 00:26:57,075 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.4748, Acc=0.192, PPL=648.58
2025-09-25 00:27:04,512 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.5488, Acc=0.250, PPL=256.93
2025-09-25 00:27:11,867 - training.trainer - INFO - Epoch 10, Step 36629: Loss=5.8651, Acc=0.185, PPL=352.52
2025-09-25 00:27:19,356 - training.trainer - INFO - Epoch 10, Step 36729: Loss=5.0791, Acc=0.286, PPL=160.63
2025-09-25 00:27:26,817 - training.trainer - INFO - Epoch 10, Step 36829: Loss=7.0021, Acc=0.163, PPL=1098.98
2025-09-25 00:27:34,709 - training.trainer - INFO - Epoch 10, Step 36929: Loss=5.2856, Acc=0.233, PPL=197.48
2025-09-25 00:27:42,187 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.6844, Acc=0.318, PPL=294.23
2025-09-25 00:27:49,697 - training.trainer - INFO - Epoch 10, Step 37129: Loss=6.0894, Acc=0.226, PPL=441.16
2025-09-25 00:28:09,218 - training.trainer - INFO - Epoch 11/100 completed in 265.98s - Train Loss: 5.8519, Train Acc: 0.227, Val Loss: 5.8060, Val Acc: 0.231
2025-09-25 00:28:09,901 - training.trainer - INFO - New best model saved with validation loss: 5.8060
2025-09-25 00:28:09,901 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-25 00:28:17,700 - training.trainer - INFO - Epoch 11, Step 37312: Loss=4.8823, Acc=0.320, PPL=131.93
2025-09-25 00:28:25,425 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.3326, Acc=0.167, PPL=562.64
2025-09-25 00:28:32,913 - training.trainer - INFO - Epoch 11, Step 37512: Loss=5.8939, Acc=0.208, PPL=362.83
2025-09-25 00:28:40,431 - training.trainer - INFO - Epoch 11, Step 37612: Loss=5.5692, Acc=0.286, PPL=262.22
2025-09-25 00:28:47,880 - training.trainer - INFO - Epoch 11, Step 37712: Loss=5.4282, Acc=0.296, PPL=227.73
2025-09-25 00:28:55,182 - training.trainer - INFO - Epoch 11, Step 37812: Loss=6.5907, Acc=0.148, PPL=728.30
2025-09-25 00:29:02,601 - training.trainer - INFO - Epoch 11, Step 37912: Loss=4.4493, Acc=0.211, PPL=85.57
2025-09-25 00:29:10,037 - training.trainer - INFO - Epoch 11, Step 38012: Loss=6.4284, Acc=0.152, PPL=619.17
2025-09-25 00:29:17,417 - training.trainer - INFO - Epoch 11, Step 38112: Loss=4.8594, Acc=0.407, PPL=128.95
2025-09-25 00:29:24,711 - training.trainer - INFO - Epoch 11, Step 38212: Loss=6.0282, Acc=0.250, PPL=414.98
2025-09-25 00:29:32,504 - training.trainer - INFO - Epoch 11, Step 38312: Loss=5.3657, Acc=0.280, PPL=213.95
2025-09-25 00:29:39,836 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.6382, Acc=0.135, PPL=280.96
2025-09-25 00:29:47,170 - training.trainer - INFO - Epoch 11, Step 38512: Loss=5.0035, Acc=0.419, PPL=148.93
2025-09-25 00:29:54,489 - training.trainer - INFO - Epoch 11, Step 38612: Loss=6.2735, Acc=0.128, PPL=530.36
2025-09-25 00:30:01,830 - training.trainer - INFO - Epoch 11, Step 38712: Loss=5.5719, Acc=0.256, PPL=262.93
2025-09-25 00:30:09,239 - training.trainer - INFO - Epoch 11, Step 38812: Loss=6.6293, Acc=0.154, PPL=756.95
2025-09-25 00:30:16,561 - training.trainer - INFO - Epoch 11, Step 38912: Loss=6.4676, Acc=0.118, PPL=643.92
2025-09-25 00:30:23,884 - training.trainer - INFO - Epoch 11, Step 39012: Loss=6.2576, Acc=0.156, PPL=521.96
2025-09-25 00:30:31,358 - training.trainer - INFO - Epoch 11, Step 39112: Loss=5.5216, Acc=0.200, PPL=250.05
2025-09-25 00:30:38,982 - training.trainer - INFO - Epoch 11, Step 39212: Loss=6.3518, Acc=0.217, PPL=573.50
2025-09-25 00:30:46,435 - training.trainer - INFO - Epoch 11, Step 39312: Loss=5.3648, Acc=0.232, PPL=213.74
2025-09-25 00:30:53,800 - training.trainer - INFO - Epoch 11, Step 39412: Loss=5.6352, Acc=0.194, PPL=280.12
2025-09-25 00:31:01,219 - training.trainer - INFO - Epoch 11, Step 39512: Loss=5.9668, Acc=0.204, PPL=390.24
2025-09-25 00:31:08,526 - training.trainer - INFO - Epoch 11, Step 39612: Loss=5.5359, Acc=0.156, PPL=253.64
2025-09-25 00:31:15,909 - training.trainer - INFO - Epoch 11, Step 39712: Loss=6.8648, Acc=0.194, PPL=957.92
2025-09-25 00:31:23,350 - training.trainer - INFO - Epoch 11, Step 39812: Loss=6.9234, Acc=0.081, PPL=1015.73
2025-09-25 00:31:31,245 - training.trainer - INFO - Epoch 11, Step 39912: Loss=5.9716, Acc=0.186, PPL=392.15
2025-09-25 00:31:38,566 - training.trainer - INFO - Epoch 11, Step 40012: Loss=5.5135, Acc=0.231, PPL=248.02
2025-09-25 00:31:45,949 - training.trainer - INFO - Epoch 11, Step 40112: Loss=5.6791, Acc=0.256, PPL=292.70
2025-09-25 00:31:53,249 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.0552, Acc=0.333, PPL=156.83
2025-09-25 00:32:00,674 - training.trainer - INFO - Epoch 11, Step 40312: Loss=5.9113, Acc=0.216, PPL=369.20
2025-09-25 00:32:08,174 - training.trainer - INFO - Epoch 11, Step 40412: Loss=5.9840, Acc=0.200, PPL=397.03
2025-09-25 00:32:15,639 - training.trainer - INFO - Epoch 11, Step 40512: Loss=5.7655, Acc=0.229, PPL=319.09
2025-09-25 00:32:33,729 - training.trainer - INFO - Epoch 12/100 completed in 263.83s - Train Loss: 5.8239, Train Acc: 0.232, Val Loss: 5.7849, Val Acc: 0.234
2025-09-25 00:32:34,427 - training.trainer - INFO - New best model saved with validation loss: 5.7849
2025-09-25 00:32:34,428 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-09-25 00:32:42,351 - training.trainer - INFO - Epoch 12, Step 40695: Loss=6.5033, Acc=0.137, PPL=667.32
2025-09-25 00:32:49,780 - training.trainer - INFO - Epoch 12, Step 40795: Loss=6.0015, Acc=0.179, PPL=404.05
2025-09-25 00:32:57,528 - training.trainer - INFO - Epoch 12, Step 40895: Loss=5.8692, Acc=0.175, PPL=353.95
2025-09-25 00:33:05,038 - training.trainer - INFO - Epoch 12, Step 40995: Loss=4.7025, Acc=0.343, PPL=110.22
2025-09-25 00:33:12,722 - training.trainer - INFO - Epoch 12, Step 41095: Loss=6.6260, Acc=0.125, PPL=754.47
2025-09-25 00:33:20,304 - training.trainer - INFO - Epoch 12, Step 41195: Loss=6.3330, Acc=0.196, PPL=562.87
2025-09-25 00:33:27,838 - training.trainer - INFO - Epoch 12, Step 41295: Loss=5.7370, Acc=0.140, PPL=310.14
2025-09-25 00:33:35,357 - training.trainer - INFO - Epoch 12, Step 41395: Loss=6.1098, Acc=0.143, PPL=450.23
2025-09-25 00:33:42,770 - training.trainer - INFO - Epoch 12, Step 41495: Loss=5.6221, Acc=0.194, PPL=276.46
2025-09-25 00:33:50,120 - training.trainer - INFO - Epoch 12, Step 41595: Loss=6.5439, Acc=0.091, PPL=695.02
2025-09-25 00:33:57,540 - training.trainer - INFO - Epoch 12, Step 41695: Loss=6.3074, Acc=0.182, PPL=548.61
2025-09-25 00:34:05,062 - training.trainer - INFO - Epoch 12, Step 41795: Loss=5.2355, Acc=0.368, PPL=187.83
2025-09-25 00:34:12,520 - training.trainer - INFO - Epoch 12, Step 41895: Loss=4.7406, Acc=0.312, PPL=114.50
2025-09-25 00:34:20,013 - training.trainer - INFO - Epoch 12, Step 41995: Loss=5.8980, Acc=0.264, PPL=364.30
2025-09-25 00:34:27,748 - training.trainer - INFO - Epoch 12, Step 42095: Loss=5.9863, Acc=0.154, PPL=397.93
2025-09-25 00:34:35,444 - training.trainer - INFO - Epoch 12, Step 42195: Loss=5.6887, Acc=0.250, PPL=295.51
2025-09-25 00:34:43,000 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.9170, Acc=0.240, PPL=371.30
2025-09-25 00:34:50,559 - training.trainer - INFO - Epoch 12, Step 42395: Loss=7.1162, Acc=0.172, PPL=1231.72
2025-09-25 00:34:58,136 - training.trainer - INFO - Epoch 12, Step 42495: Loss=6.1447, Acc=0.244, PPL=466.25
2025-09-25 00:35:05,507 - training.trainer - INFO - Epoch 12, Step 42595: Loss=5.8988, Acc=0.222, PPL=364.59
2025-09-25 00:35:12,999 - training.trainer - INFO - Epoch 12, Step 42695: Loss=5.7599, Acc=0.224, PPL=317.30
2025-09-25 00:35:20,320 - training.trainer - INFO - Epoch 12, Step 42795: Loss=6.1208, Acc=0.163, PPL=455.22
2025-09-25 00:35:27,712 - training.trainer - INFO - Epoch 12, Step 42895: Loss=6.1591, Acc=0.241, PPL=473.01
2025-09-25 00:35:35,310 - training.trainer - INFO - Epoch 12, Step 42995: Loss=5.7200, Acc=0.216, PPL=304.92
2025-09-25 00:35:42,754 - training.trainer - INFO - Epoch 12, Step 43095: Loss=5.7306, Acc=0.208, PPL=308.15
2025-09-25 00:35:50,133 - training.trainer - INFO - Epoch 12, Step 43195: Loss=4.9608, Acc=0.269, PPL=142.71
2025-09-25 00:35:57,388 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.0639, Acc=0.179, PPL=430.03
2025-09-25 00:36:05,000 - training.trainer - INFO - Epoch 12, Step 43395: Loss=5.8654, Acc=0.205, PPL=352.62
2025-09-25 00:36:12,745 - training.trainer - INFO - Epoch 12, Step 43495: Loss=5.5037, Acc=0.283, PPL=245.59
2025-09-25 00:36:20,302 - training.trainer - INFO - Epoch 12, Step 43595: Loss=5.9373, Acc=0.262, PPL=378.92
2025-09-25 00:36:27,746 - training.trainer - INFO - Epoch 12, Step 43695: Loss=5.1692, Acc=0.333, PPL=175.77
2025-09-25 00:36:35,118 - training.trainer - INFO - Epoch 12, Step 43795: Loss=6.1391, Acc=0.261, PPL=463.66
2025-09-25 00:36:42,800 - training.trainer - INFO - Epoch 12, Step 43895: Loss=5.7186, Acc=0.275, PPL=304.49
2025-09-25 00:37:02,356 - training.trainer - INFO - Epoch 13/100 completed in 267.93s - Train Loss: 5.7911, Train Acc: 0.236, Val Loss: 5.7667, Val Acc: 0.239
2025-09-25 00:37:02,965 - training.trainer - INFO - New best model saved with validation loss: 5.7667
2025-09-25 00:37:02,965 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-25 00:37:11,341 - training.trainer - INFO - Epoch 13, Step 44078: Loss=5.9826, Acc=0.194, PPL=396.48
2025-09-25 00:37:18,861 - training.trainer - INFO - Epoch 13, Step 44178: Loss=6.2092, Acc=0.147, PPL=497.31
2025-09-25 00:37:26,282 - training.trainer - INFO - Epoch 13, Step 44278: Loss=6.1809, Acc=0.213, PPL=483.43
2025-09-25 00:37:33,116 - training.trainer - INFO - Epoch 13, Step 44378: Loss=5.8810, Acc=0.140, PPL=358.17
2025-09-25 00:37:39,425 - training.trainer - INFO - Epoch 13, Step 44478: Loss=6.1476, Acc=0.231, PPL=467.60
2025-09-25 00:37:46,478 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.2710, Acc=0.429, PPL=194.61
2025-09-25 00:37:53,860 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.0237, Acc=0.182, PPL=151.98
2025-09-25 00:38:01,088 - training.trainer - INFO - Epoch 13, Step 44778: Loss=5.8418, Acc=0.265, PPL=344.40
2025-09-25 00:38:08,356 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.3641, Acc=0.333, PPL=213.61
2025-09-25 00:38:15,736 - training.trainer - INFO - Epoch 13, Step 44978: Loss=6.1068, Acc=0.209, PPL=448.91
2025-09-25 00:38:22,986 - training.trainer - INFO - Epoch 13, Step 45078: Loss=5.8833, Acc=0.216, PPL=358.98
2025-09-25 00:38:30,279 - training.trainer - INFO - Epoch 13, Step 45178: Loss=5.9922, Acc=0.345, PPL=400.30
2025-09-25 00:38:37,927 - training.trainer - INFO - Epoch 13, Step 45278: Loss=6.7487, Acc=0.167, PPL=852.93
2025-09-25 00:38:45,232 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.1215, Acc=0.233, PPL=455.53
2025-09-25 00:38:52,542 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.7614, Acc=0.260, PPL=317.80
2025-09-25 00:38:59,886 - training.trainer - INFO - Epoch 13, Step 45578: Loss=4.8563, Acc=0.333, PPL=128.54
2025-09-25 00:39:07,137 - training.trainer - INFO - Epoch 13, Step 45678: Loss=5.2620, Acc=0.217, PPL=192.87
2025-09-25 00:39:14,386 - training.trainer - INFO - Epoch 13, Step 45778: Loss=5.3755, Acc=0.179, PPL=216.06
2025-09-25 00:39:21,977 - training.trainer - INFO - Epoch 13, Step 45878: Loss=6.2250, Acc=0.154, PPL=505.21
2025-09-25 00:39:29,212 - training.trainer - INFO - Epoch 13, Step 45978: Loss=6.1440, Acc=0.214, PPL=465.93
2025-09-25 00:39:36,449 - training.trainer - INFO - Epoch 13, Step 46078: Loss=6.7360, Acc=0.133, PPL=842.20
2025-09-25 00:39:43,684 - training.trainer - INFO - Epoch 13, Step 46178: Loss=5.7343, Acc=0.143, PPL=309.29
2025-09-25 00:39:50,914 - training.trainer - INFO - Epoch 13, Step 46278: Loss=5.5562, Acc=0.238, PPL=258.85
2025-09-25 00:39:58,509 - training.trainer - INFO - Epoch 13, Step 46378: Loss=6.3447, Acc=0.179, PPL=569.46
2025-09-25 00:40:05,838 - training.trainer - INFO - Epoch 13, Step 46478: Loss=5.5745, Acc=0.184, PPL=263.62
2025-09-25 00:40:13,086 - training.trainer - INFO - Epoch 13, Step 46578: Loss=6.0483, Acc=0.276, PPL=423.38
2025-09-25 00:40:20,279 - training.trainer - INFO - Epoch 13, Step 46678: Loss=4.8247, Acc=0.289, PPL=124.55
2025-09-25 00:40:27,564 - training.trainer - INFO - Epoch 13, Step 46778: Loss=4.4607, Acc=0.333, PPL=86.55
2025-09-25 00:40:34,776 - training.trainer - INFO - Epoch 13, Step 46878: Loss=5.7405, Acc=0.196, PPL=311.23
2025-09-25 00:40:41,963 - training.trainer - INFO - Epoch 13, Step 46978: Loss=6.0298, Acc=0.200, PPL=415.65
2025-09-25 00:40:49,568 - training.trainer - INFO - Epoch 13, Step 47078: Loss=3.6317, Acc=0.706, PPL=37.78
2025-09-25 00:40:56,795 - training.trainer - INFO - Epoch 13, Step 47178: Loss=6.1827, Acc=0.170, PPL=484.29
2025-09-25 00:41:04,178 - training.trainer - INFO - Epoch 13, Step 47278: Loss=5.7168, Acc=0.189, PPL=303.93
2025-09-25 00:41:23,119 - training.trainer - INFO - Epoch 14/100 completed in 260.15s - Train Loss: 5.7727, Train Acc: 0.238, Val Loss: 5.7487, Val Acc: 0.239
2025-09-25 00:41:23,721 - training.trainer - INFO - New best model saved with validation loss: 5.7487
2025-09-25 00:41:23,721 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-25 00:41:31,382 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.2835, Acc=0.217, PPL=197.06
2025-09-25 00:41:37,849 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.6360, Acc=0.273, PPL=280.33
2025-09-25 00:41:43,987 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.6567, Acc=0.333, PPL=286.19
2025-09-25 00:41:50,151 - training.trainer - INFO - Epoch 14, Step 47761: Loss=5.9476, Acc=0.263, PPL=382.82
2025-09-25 00:41:56,379 - training.trainer - INFO - Epoch 14, Step 47861: Loss=6.6793, Acc=0.176, PPL=795.73
2025-09-25 00:42:03,441 - training.trainer - INFO - Epoch 14, Step 47961: Loss=5.5708, Acc=0.194, PPL=262.64
2025-09-25 00:42:11,027 - training.trainer - INFO - Epoch 14, Step 48061: Loss=6.6564, Acc=0.244, PPL=777.72
2025-09-25 00:42:18,251 - training.trainer - INFO - Epoch 14, Step 48161: Loss=6.1725, Acc=0.211, PPL=479.37
2025-09-25 00:42:25,339 - training.trainer - INFO - Epoch 14, Step 48261: Loss=5.6866, Acc=0.282, PPL=294.89
2025-09-25 00:42:32,358 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.9678, Acc=0.242, PPL=390.63
2025-09-25 00:42:39,527 - training.trainer - INFO - Epoch 14, Step 48461: Loss=6.0180, Acc=0.202, PPL=410.75
2025-09-25 00:42:46,676 - training.trainer - INFO - Epoch 14, Step 48561: Loss=5.6668, Acc=0.255, PPL=289.10
2025-09-25 00:42:54,086 - training.trainer - INFO - Epoch 14, Step 48661: Loss=6.0904, Acc=0.239, PPL=441.59
2025-09-25 00:43:01,466 - training.trainer - INFO - Epoch 14, Step 48761: Loss=6.0652, Acc=0.238, PPL=430.63
2025-09-25 00:43:09,211 - training.trainer - INFO - Epoch 14, Step 48861: Loss=5.9933, Acc=0.174, PPL=400.73
2025-09-25 00:43:16,778 - training.trainer - INFO - Epoch 14, Step 48961: Loss=5.5147, Acc=0.250, PPL=248.32
2025-09-25 00:43:24,106 - training.trainer - INFO - Epoch 14, Step 49061: Loss=5.7117, Acc=0.246, PPL=302.39
2025-09-25 00:43:31,515 - training.trainer - INFO - Epoch 14, Step 49161: Loss=5.6349, Acc=0.225, PPL=280.03
2025-09-25 00:43:39,162 - training.trainer - INFO - Epoch 14, Step 49261: Loss=6.5395, Acc=0.119, PPL=691.96
2025-09-25 00:43:46,905 - training.trainer - INFO - Epoch 14, Step 49361: Loss=5.4293, Acc=0.276, PPL=227.99
2025-09-25 00:43:54,337 - training.trainer - INFO - Epoch 14, Step 49461: Loss=6.4431, Acc=0.170, PPL=628.36
2025-09-25 00:44:01,736 - training.trainer - INFO - Epoch 14, Step 49561: Loss=5.7095, Acc=0.231, PPL=301.72
2025-09-25 00:44:09,333 - training.trainer - INFO - Epoch 14, Step 49661: Loss=5.9221, Acc=0.222, PPL=373.19
2025-09-25 00:44:16,901 - training.trainer - INFO - Epoch 14, Step 49761: Loss=5.8738, Acc=0.143, PPL=355.59
2025-09-25 00:44:24,363 - training.trainer - INFO - Epoch 14, Step 49861: Loss=5.9138, Acc=0.217, PPL=370.12
2025-09-25 00:44:31,855 - training.trainer - INFO - Epoch 14, Step 49961: Loss=5.5704, Acc=0.270, PPL=262.53
2025-09-25 00:44:39,342 - training.trainer - INFO - Epoch 14, Step 50061: Loss=3.6446, Acc=0.484, PPL=38.27
2025-09-25 00:44:46,839 - training.trainer - INFO - Epoch 14, Step 50161: Loss=4.0474, Acc=0.467, PPL=57.25
2025-09-25 00:44:54,312 - training.trainer - INFO - Epoch 14, Step 50261: Loss=5.3830, Acc=0.316, PPL=217.68
2025-09-25 00:45:01,690 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.4213, Acc=0.308, PPL=226.17
2025-09-25 00:45:09,087 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.1123, Acc=0.300, PPL=166.05
2025-09-25 00:45:16,419 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.1572, Acc=0.357, PPL=173.69
2025-09-25 00:45:23,799 - training.trainer - INFO - Epoch 14, Step 50661: Loss=5.7720, Acc=0.282, PPL=321.19
2025-09-25 00:45:42,640 - training.trainer - INFO - Epoch 15/100 completed in 258.92s - Train Loss: 5.7463, Train Acc: 0.241, Val Loss: 5.7435, Val Acc: 0.238
2025-09-25 00:45:42,974 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-25 00:45:43,660 - training.trainer - INFO - New best model saved with validation loss: 5.7435
2025-09-25 00:45:43,660 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-25 00:45:51,781 - training.trainer - INFO - Epoch 15, Step 50844: Loss=4.8184, Acc=0.348, PPL=123.76
2025-09-25 00:45:59,330 - training.trainer - INFO - Epoch 15, Step 50944: Loss=4.2629, Acc=0.349, PPL=71.02
2025-09-25 00:46:06,861 - training.trainer - INFO - Epoch 15, Step 51044: Loss=6.3269, Acc=0.119, PPL=559.40
2025-09-25 00:46:14,470 - training.trainer - INFO - Epoch 15, Step 51144: Loss=6.5150, Acc=0.142, PPL=675.17
2025-09-25 00:46:21,950 - training.trainer - INFO - Epoch 15, Step 51244: Loss=6.2738, Acc=0.175, PPL=530.47
2025-09-25 00:46:29,506 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.8484, Acc=0.258, PPL=346.66
2025-09-25 00:46:37,081 - training.trainer - INFO - Epoch 15, Step 51444: Loss=6.0186, Acc=0.200, PPL=411.00
2025-09-25 00:46:44,681 - training.trainer - INFO - Epoch 15, Step 51544: Loss=5.7879, Acc=0.228, PPL=326.34
2025-09-25 00:46:52,186 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.4640, Acc=0.214, PPL=236.05
2025-09-25 00:46:59,740 - training.trainer - INFO - Epoch 15, Step 51744: Loss=6.4263, Acc=0.118, PPL=617.86
2025-09-25 00:47:07,133 - training.trainer - INFO - Epoch 15, Step 51844: Loss=6.3097, Acc=0.179, PPL=549.88
2025-09-25 00:47:14,597 - training.trainer - INFO - Epoch 15, Step 51944: Loss=5.7777, Acc=0.224, PPL=323.02
2025-09-25 00:47:22,188 - training.trainer - INFO - Epoch 15, Step 52044: Loss=6.2323, Acc=0.190, PPL=508.94
2025-09-25 00:47:29,533 - training.trainer - INFO - Epoch 15, Step 52144: Loss=6.0230, Acc=0.250, PPL=412.83
2025-09-25 00:47:37,094 - training.trainer - INFO - Epoch 15, Step 52244: Loss=4.2271, Acc=0.343, PPL=68.52
2025-09-25 00:47:44,475 - training.trainer - INFO - Epoch 15, Step 52344: Loss=6.5798, Acc=0.208, PPL=720.38
2025-09-25 00:47:52,072 - training.trainer - INFO - Epoch 15, Step 52444: Loss=4.3566, Acc=0.484, PPL=77.99
2025-09-25 00:47:59,942 - training.trainer - INFO - Epoch 15, Step 52544: Loss=5.7262, Acc=0.245, PPL=306.81
2025-09-25 00:48:07,469 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.6231, Acc=0.235, PPL=276.74
2025-09-25 00:48:14,997 - training.trainer - INFO - Epoch 15, Step 52744: Loss=6.0403, Acc=0.229, PPL=420.01
2025-09-25 00:48:22,452 - training.trainer - INFO - Epoch 15, Step 52844: Loss=6.1784, Acc=0.121, PPL=482.21
2025-09-25 00:48:30,049 - training.trainer - INFO - Epoch 15, Step 52944: Loss=5.8680, Acc=0.298, PPL=353.55
2025-09-25 00:48:37,407 - training.trainer - INFO - Epoch 15, Step 53044: Loss=5.4470, Acc=0.280, PPL=232.07
2025-09-25 00:48:44,819 - training.trainer - INFO - Epoch 15, Step 53144: Loss=6.3045, Acc=0.127, PPL=547.02
2025-09-25 00:48:52,166 - training.trainer - INFO - Epoch 15, Step 53244: Loss=6.0636, Acc=0.276, PPL=429.93
2025-09-25 00:48:59,727 - training.trainer - INFO - Epoch 15, Step 53344: Loss=6.0574, Acc=0.143, PPL=427.28
2025-09-25 00:49:07,038 - training.trainer - INFO - Epoch 15, Step 53444: Loss=6.5084, Acc=0.194, PPL=670.78
2025-09-25 00:49:14,500 - training.trainer - INFO - Epoch 15, Step 53544: Loss=4.4949, Acc=0.412, PPL=89.56
2025-09-25 00:49:21,778 - training.trainer - INFO - Epoch 15, Step 53644: Loss=5.4520, Acc=0.304, PPL=233.22
2025-09-25 00:49:29,035 - training.trainer - INFO - Epoch 15, Step 53744: Loss=5.7060, Acc=0.222, PPL=300.65
2025-09-25 00:49:36,650 - training.trainer - INFO - Epoch 15, Step 53844: Loss=6.3905, Acc=0.226, PPL=596.15
2025-09-25 00:49:44,091 - training.trainer - INFO - Epoch 15, Step 53944: Loss=5.9538, Acc=0.196, PPL=385.23
2025-09-25 00:49:51,502 - training.trainer - INFO - Epoch 15, Step 54044: Loss=5.8272, Acc=0.135, PPL=339.40
2025-09-25 00:50:09,958 - training.trainer - INFO - Epoch 16/100 completed in 266.30s - Train Loss: 5.7302, Train Acc: 0.243, Val Loss: 5.7337, Val Acc: 0.242
2025-09-25 00:50:10,682 - training.trainer - INFO - New best model saved with validation loss: 5.7337
2025-09-25 00:50:10,683 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-25 00:50:17,936 - training.trainer - INFO - Epoch 16, Step 54227: Loss=3.8755, Acc=0.522, PPL=48.21
2025-09-25 00:50:24,897 - training.trainer - INFO - Epoch 16, Step 54327: Loss=5.0499, Acc=0.265, PPL=156.01
2025-09-25 00:50:32,279 - training.trainer - INFO - Epoch 16, Step 54427: Loss=5.1980, Acc=0.242, PPL=180.91
2025-09-25 00:50:39,560 - training.trainer - INFO - Epoch 16, Step 54527: Loss=5.7156, Acc=0.273, PPL=303.57
2025-09-25 00:50:46,746 - training.trainer - INFO - Epoch 16, Step 54627: Loss=4.8075, Acc=0.440, PPL=122.43
2025-09-25 00:50:54,141 - training.trainer - INFO - Epoch 16, Step 54727: Loss=5.2863, Acc=0.286, PPL=197.62
2025-09-25 00:51:01,360 - training.trainer - INFO - Epoch 16, Step 54827: Loss=6.3210, Acc=0.174, PPL=556.14
2025-09-25 00:51:08,832 - training.trainer - INFO - Epoch 16, Step 54927: Loss=5.7723, Acc=0.185, PPL=321.26
2025-09-25 00:51:16,090 - training.trainer - INFO - Epoch 16, Step 55027: Loss=5.9695, Acc=0.250, PPL=391.30
2025-09-25 00:51:23,410 - training.trainer - INFO - Epoch 16, Step 55127: Loss=6.0361, Acc=0.278, PPL=418.26
2025-09-25 00:51:30,648 - training.trainer - INFO - Epoch 16, Step 55227: Loss=4.9283, Acc=0.385, PPL=138.14
2025-09-25 00:51:37,936 - training.trainer - INFO - Epoch 16, Step 55327: Loss=5.3790, Acc=0.279, PPL=216.81
2025-09-25 00:51:45,165 - training.trainer - INFO - Epoch 16, Step 55427: Loss=6.1458, Acc=0.267, PPL=466.74
2025-09-25 00:51:52,413 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.7724, Acc=0.263, PPL=321.31
2025-09-25 00:51:59,934 - training.trainer - INFO - Epoch 16, Step 55627: Loss=5.8398, Acc=0.289, PPL=343.70
2025-09-25 00:52:07,363 - training.trainer - INFO - Epoch 16, Step 55727: Loss=5.1381, Acc=0.300, PPL=170.39
2025-09-25 00:52:14,757 - training.trainer - INFO - Epoch 16, Step 55827: Loss=6.4196, Acc=0.190, PPL=613.75
2025-09-25 00:52:22,212 - training.trainer - INFO - Epoch 16, Step 55927: Loss=6.3683, Acc=0.189, PPL=583.09
2025-09-25 00:52:29,629 - training.trainer - INFO - Epoch 16, Step 56027: Loss=6.6119, Acc=0.273, PPL=743.92
2025-09-25 00:52:37,058 - training.trainer - INFO - Epoch 16, Step 56127: Loss=4.7139, Acc=0.288, PPL=111.49
2025-09-25 00:52:44,577 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.9380, Acc=0.191, PPL=379.18
2025-09-25 00:52:52,105 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.6950, Acc=0.296, PPL=297.39
2025-09-25 00:52:59,600 - training.trainer - INFO - Epoch 16, Step 56427: Loss=5.5827, Acc=0.255, PPL=265.78
2025-09-25 00:53:07,263 - training.trainer - INFO - Epoch 16, Step 56527: Loss=5.3541, Acc=0.350, PPL=211.48
2025-09-25 00:53:14,732 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.6825, Acc=0.245, PPL=293.68
2025-09-25 00:53:22,099 - training.trainer - INFO - Epoch 16, Step 56727: Loss=5.9895, Acc=0.250, PPL=399.21
2025-09-25 00:53:30,309 - training.trainer - INFO - Epoch 16, Step 56827: Loss=6.1456, Acc=0.167, PPL=466.68
2025-09-25 00:53:37,808 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.1057, Acc=0.356, PPL=164.96
2025-09-25 00:53:45,413 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.7000, Acc=0.190, PPL=298.88
2025-09-25 00:53:52,809 - training.trainer - INFO - Epoch 16, Step 57127: Loss=5.7139, Acc=0.282, PPL=303.04
2025-09-25 00:54:00,281 - training.trainer - INFO - Epoch 16, Step 57227: Loss=5.9545, Acc=0.160, PPL=385.49
2025-09-25 00:54:07,899 - training.trainer - INFO - Epoch 16, Step 57327: Loss=6.0407, Acc=0.304, PPL=420.20
2025-09-25 00:54:15,370 - training.trainer - INFO - Epoch 16, Step 57427: Loss=6.2439, Acc=0.212, PPL=514.84
2025-09-25 00:54:34,815 - training.trainer - INFO - Epoch 17/100 completed in 264.13s - Train Loss: 5.7090, Train Acc: 0.248, Val Loss: 5.7326, Val Acc: 0.245
2025-09-25 00:54:35,514 - training.trainer - INFO - New best model saved with validation loss: 5.7326
2025-09-25 00:54:35,514 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-25 00:54:44,112 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.8448, Acc=0.233, PPL=345.44
2025-09-25 00:54:51,777 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.2050, Acc=0.381, PPL=182.18
2025-09-25 00:54:59,238 - training.trainer - INFO - Epoch 17, Step 57810: Loss=5.1900, Acc=0.194, PPL=179.47
2025-09-25 00:55:07,111 - training.trainer - INFO - Epoch 17, Step 57910: Loss=5.8021, Acc=0.200, PPL=330.99
2025-09-25 00:55:14,465 - training.trainer - INFO - Epoch 17, Step 58010: Loss=5.3014, Acc=0.200, PPL=200.63
2025-09-25 00:55:21,771 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.4138, Acc=0.308, PPL=224.49
2025-09-25 00:55:29,070 - training.trainer - INFO - Epoch 17, Step 58210: Loss=5.1981, Acc=0.421, PPL=180.93
2025-09-25 00:55:36,301 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.5343, Acc=0.254, PPL=253.24
2025-09-25 00:55:43,589 - training.trainer - INFO - Epoch 17, Step 58410: Loss=6.4787, Acc=0.178, PPL=651.15
2025-09-25 00:55:50,862 - training.trainer - INFO - Epoch 17, Step 58510: Loss=5.3375, Acc=0.286, PPL=208.00
2025-09-25 00:55:58,157 - training.trainer - INFO - Epoch 17, Step 58610: Loss=6.1384, Acc=0.200, PPL=463.33
2025-09-25 00:56:05,388 - training.trainer - INFO - Epoch 17, Step 58710: Loss=5.4304, Acc=0.238, PPL=228.24
2025-09-25 00:56:12,555 - training.trainer - INFO - Epoch 17, Step 58810: Loss=5.7841, Acc=0.300, PPL=325.10
2025-09-25 00:56:19,847 - training.trainer - INFO - Epoch 17, Step 58910: Loss=5.1028, Acc=0.217, PPL=164.48
2025-09-25 00:56:27,077 - training.trainer - INFO - Epoch 17, Step 59010: Loss=6.1968, Acc=0.119, PPL=491.17
2025-09-25 00:56:34,488 - training.trainer - INFO - Epoch 17, Step 59110: Loss=6.3502, Acc=0.222, PPL=572.62
2025-09-25 00:56:41,994 - training.trainer - INFO - Epoch 17, Step 59210: Loss=5.4316, Acc=0.269, PPL=228.52
2025-09-25 00:56:49,539 - training.trainer - INFO - Epoch 17, Step 59310: Loss=6.2969, Acc=0.183, PPL=542.90
2025-09-25 00:56:56,921 - training.trainer - INFO - Epoch 17, Step 59410: Loss=6.5647, Acc=0.143, PPL=709.63
2025-09-25 00:57:04,118 - training.trainer - INFO - Epoch 17, Step 59510: Loss=5.9636, Acc=0.303, PPL=389.02
2025-09-25 00:57:11,385 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.8777, Acc=0.255, PPL=356.97
2025-09-25 00:57:18,678 - training.trainer - INFO - Epoch 17, Step 59710: Loss=6.0269, Acc=0.311, PPL=414.44
2025-09-25 00:57:26,109 - training.trainer - INFO - Epoch 17, Step 59810: Loss=5.8568, Acc=0.222, PPL=349.61
2025-09-25 00:57:33,407 - training.trainer - INFO - Epoch 17, Step 59910: Loss=6.2404, Acc=0.222, PPL=513.08
2025-09-25 00:57:40,788 - training.trainer - INFO - Epoch 17, Step 60010: Loss=5.8180, Acc=0.240, PPL=336.30
2025-09-25 00:57:48,061 - training.trainer - INFO - Epoch 17, Step 60110: Loss=6.5334, Acc=0.132, PPL=687.74
2025-09-25 00:57:55,443 - training.trainer - INFO - Epoch 17, Step 60210: Loss=6.1110, Acc=0.164, PPL=450.78
2025-09-25 00:58:03,088 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.4028, Acc=0.348, PPL=222.03
2025-09-25 00:58:10,880 - training.trainer - INFO - Epoch 17, Step 60410: Loss=5.0063, Acc=0.281, PPL=149.35
2025-09-25 00:58:18,531 - training.trainer - INFO - Epoch 17, Step 60510: Loss=6.5036, Acc=0.149, PPL=667.55
2025-09-25 00:58:26,228 - training.trainer - INFO - Epoch 17, Step 60610: Loss=5.0542, Acc=0.276, PPL=156.68
2025-09-25 00:58:34,289 - training.trainer - INFO - Epoch 17, Step 60710: Loss=6.2563, Acc=0.205, PPL=521.28
2025-09-25 00:58:41,695 - training.trainer - INFO - Epoch 17, Step 60810: Loss=4.7220, Acc=0.375, PPL=112.39
2025-09-25 00:59:01,287 - training.trainer - INFO - Epoch 18/100 completed in 265.77s - Train Loss: 5.6857, Train Acc: 0.252, Val Loss: 5.7052, Val Acc: 0.246
2025-09-25 00:59:02,096 - training.trainer - INFO - New best model saved with validation loss: 5.7052
2025-09-25 00:59:02,096 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-25 00:59:09,906 - training.trainer - INFO - Epoch 18, Step 60993: Loss=5.4425, Acc=0.400, PPL=231.03
2025-09-25 00:59:17,808 - training.trainer - INFO - Epoch 18, Step 61093: Loss=6.5506, Acc=0.188, PPL=699.67
2025-09-25 00:59:25,124 - training.trainer - INFO - Epoch 18, Step 61193: Loss=6.5863, Acc=0.145, PPL=725.10
2025-09-25 00:59:32,441 - training.trainer - INFO - Epoch 18, Step 61293: Loss=6.3504, Acc=0.200, PPL=572.72
2025-09-25 00:59:39,791 - training.trainer - INFO - Epoch 18, Step 61393: Loss=6.2600, Acc=0.250, PPL=523.23
2025-09-25 00:59:47,065 - training.trainer - INFO - Epoch 18, Step 61493: Loss=4.9519, Acc=0.265, PPL=141.44
2025-09-25 00:59:54,341 - training.trainer - INFO - Epoch 18, Step 61593: Loss=5.7679, Acc=0.244, PPL=319.87
2025-09-25 01:00:01,851 - training.trainer - INFO - Epoch 18, Step 61693: Loss=5.2755, Acc=0.275, PPL=195.48
2025-09-25 01:00:09,235 - training.trainer - INFO - Epoch 18, Step 61793: Loss=5.8044, Acc=0.167, PPL=331.76
2025-09-25 01:00:16,887 - training.trainer - INFO - Epoch 18, Step 61893: Loss=5.5727, Acc=0.262, PPL=263.15
2025-09-25 01:00:24,294 - training.trainer - INFO - Epoch 18, Step 61993: Loss=5.5632, Acc=0.238, PPL=260.65
2025-09-25 01:00:31,758 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.6214, Acc=0.194, PPL=276.27
2025-09-25 01:00:39,206 - training.trainer - INFO - Epoch 18, Step 62193: Loss=5.3780, Acc=0.282, PPL=216.59
2025-09-25 01:00:46,745 - training.trainer - INFO - Epoch 18, Step 62293: Loss=5.3017, Acc=0.265, PPL=200.69
2025-09-25 01:00:54,135 - training.trainer - INFO - Epoch 18, Step 62393: Loss=5.2821, Acc=0.231, PPL=196.78
2025-09-25 01:01:01,525 - training.trainer - INFO - Epoch 18, Step 62493: Loss=6.1752, Acc=0.162, PPL=480.69
2025-09-25 01:01:09,116 - training.trainer - INFO - Epoch 18, Step 62593: Loss=5.9326, Acc=0.295, PPL=377.13
2025-09-25 01:01:16,586 - training.trainer - INFO - Epoch 18, Step 62693: Loss=5.2741, Acc=0.418, PPL=195.21
2025-09-25 01:01:24,103 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.7259, Acc=0.217, PPL=306.72
2025-09-25 01:01:31,702 - training.trainer - INFO - Epoch 18, Step 62893: Loss=5.9466, Acc=0.228, PPL=382.46
2025-09-25 01:01:39,163 - training.trainer - INFO - Epoch 18, Step 62993: Loss=6.1181, Acc=0.182, PPL=453.99
2025-09-25 01:01:46,714 - training.trainer - INFO - Epoch 18, Step 63093: Loss=5.4090, Acc=0.163, PPL=223.41
2025-09-25 01:01:54,212 - training.trainer - INFO - Epoch 18, Step 63193: Loss=4.1617, Acc=0.500, PPL=64.18
2025-09-25 01:02:01,674 - training.trainer - INFO - Epoch 18, Step 63293: Loss=5.3884, Acc=0.333, PPL=218.84
2025-09-25 01:02:09,165 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.8816, Acc=0.195, PPL=358.39
2025-09-25 01:02:16,583 - training.trainer - INFO - Epoch 18, Step 63493: Loss=5.9877, Acc=0.238, PPL=398.52
2025-09-25 01:02:24,071 - training.trainer - INFO - Epoch 18, Step 63593: Loss=5.7579, Acc=0.274, PPL=316.67
2025-09-25 01:02:31,438 - training.trainer - INFO - Epoch 18, Step 63693: Loss=5.0975, Acc=0.194, PPL=163.61
2025-09-25 01:02:39,199 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.8407, Acc=0.312, PPL=344.01
2025-09-25 01:02:46,904 - training.trainer - INFO - Epoch 18, Step 63893: Loss=6.7183, Acc=0.179, PPL=827.39
2025-09-25 01:02:54,489 - training.trainer - INFO - Epoch 18, Step 63993: Loss=6.1143, Acc=0.152, PPL=452.29
2025-09-25 01:03:02,247 - training.trainer - INFO - Epoch 18, Step 64093: Loss=6.6610, Acc=0.132, PPL=781.30
2025-09-25 01:03:10,055 - training.trainer - INFO - Epoch 18, Step 64193: Loss=5.9778, Acc=0.204, PPL=394.55
2025-09-25 01:03:29,428 - training.trainer - INFO - Epoch 19/100 completed in 267.33s - Train Loss: 5.6582, Train Acc: 0.255, Val Loss: 5.6981, Val Acc: 0.247
2025-09-25 01:03:30,135 - training.trainer - INFO - New best model saved with validation loss: 5.6981
2025-09-25 01:03:30,135 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-25 01:03:37,835 - training.trainer - INFO - Epoch 19, Step 64376: Loss=5.4918, Acc=0.219, PPL=242.70
2025-09-25 01:03:45,245 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.9280, Acc=0.296, PPL=375.39
2025-09-25 01:03:52,592 - training.trainer - INFO - Epoch 19, Step 64576: Loss=5.5757, Acc=0.311, PPL=263.94
2025-09-25 01:04:00,359 - training.trainer - INFO - Epoch 19, Step 64676: Loss=6.1854, Acc=0.167, PPL=485.59
2025-09-25 01:04:07,832 - training.trainer - INFO - Epoch 19, Step 64776: Loss=6.3635, Acc=0.259, PPL=580.30
2025-09-25 01:04:15,390 - training.trainer - INFO - Epoch 19, Step 64876: Loss=5.8879, Acc=0.222, PPL=360.63
2025-09-25 01:04:22,884 - training.trainer - INFO - Epoch 19, Step 64976: Loss=6.2044, Acc=0.150, PPL=494.92
2025-09-25 01:04:30,528 - training.trainer - INFO - Epoch 19, Step 65076: Loss=6.0031, Acc=0.205, PPL=404.70
2025-09-25 01:04:38,041 - training.trainer - INFO - Epoch 19, Step 65176: Loss=5.6480, Acc=0.320, PPL=283.72
2025-09-25 01:04:45,451 - training.trainer - INFO - Epoch 19, Step 65276: Loss=5.5531, Acc=0.154, PPL=258.04
2025-09-25 01:04:52,946 - training.trainer - INFO - Epoch 19, Step 65376: Loss=5.7520, Acc=0.226, PPL=314.81
2025-09-25 01:05:00,406 - training.trainer - INFO - Epoch 19, Step 65476: Loss=5.3056, Acc=0.273, PPL=201.46
2025-09-25 01:05:07,836 - training.trainer - INFO - Epoch 19, Step 65576: Loss=5.8077, Acc=0.217, PPL=332.86
2025-09-25 01:05:15,189 - training.trainer - INFO - Epoch 19, Step 65676: Loss=5.6018, Acc=0.250, PPL=270.93
2025-09-25 01:05:22,964 - training.trainer - INFO - Epoch 19, Step 65776: Loss=5.3665, Acc=0.257, PPL=214.11
2025-09-25 01:05:30,298 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.6875, Acc=0.222, PPL=295.16
2025-09-25 01:05:38,038 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.6252, Acc=0.158, PPL=277.33
2025-09-25 01:05:45,390 - training.trainer - INFO - Epoch 19, Step 66076: Loss=6.7692, Acc=0.250, PPL=870.58
2025-09-25 01:05:52,784 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.8849, Acc=0.196, PPL=359.56
2025-09-25 01:06:00,085 - training.trainer - INFO - Epoch 19, Step 66276: Loss=6.4256, Acc=0.147, PPL=617.46
2025-09-25 01:06:07,570 - training.trainer - INFO - Epoch 19, Step 66376: Loss=5.5606, Acc=0.267, PPL=259.99
2025-09-25 01:06:14,985 - training.trainer - INFO - Epoch 19, Step 66476: Loss=5.8365, Acc=0.300, PPL=342.56
2025-09-25 01:06:22,819 - training.trainer - INFO - Epoch 19, Step 66576: Loss=6.1645, Acc=0.192, PPL=475.58
2025-09-25 01:06:30,376 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.5173, Acc=0.209, PPL=248.97
2025-09-25 01:06:37,589 - training.trainer - INFO - Epoch 19, Step 66776: Loss=5.1225, Acc=0.355, PPL=167.75
2025-09-25 01:06:45,160 - training.trainer - INFO - Epoch 19, Step 66876: Loss=5.3633, Acc=0.234, PPL=213.44
2025-09-25 01:06:52,462 - training.trainer - INFO - Epoch 19, Step 66976: Loss=4.8817, Acc=0.241, PPL=131.86
2025-09-25 01:06:59,693 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.4717, Acc=0.316, PPL=237.86
2025-09-25 01:07:06,949 - training.trainer - INFO - Epoch 19, Step 67176: Loss=5.7261, Acc=0.233, PPL=306.78
2025-09-25 01:07:14,362 - training.trainer - INFO - Epoch 19, Step 67276: Loss=5.2910, Acc=0.294, PPL=198.53
2025-09-25 01:07:21,637 - training.trainer - INFO - Epoch 19, Step 67376: Loss=4.6135, Acc=0.346, PPL=100.84
2025-09-25 01:07:29,201 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.7316, Acc=0.217, PPL=308.46
2025-09-25 01:07:36,701 - training.trainer - INFO - Epoch 19, Step 67576: Loss=5.9252, Acc=0.208, PPL=374.36
2025-09-25 01:07:55,876 - training.trainer - INFO - Epoch 20/100 completed in 265.74s - Train Loss: 5.6459, Train Acc: 0.257, Val Loss: 5.6897, Val Acc: 0.248
2025-09-25 01:07:56,281 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-25 01:07:57,126 - training.trainer - INFO - New best model saved with validation loss: 5.6897
2025-09-25 01:07:57,126 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-25 01:08:05,063 - training.trainer - INFO - Epoch 20, Step 67759: Loss=6.3509, Acc=0.218, PPL=573.02
2025-09-25 01:08:12,403 - training.trainer - INFO - Epoch 20, Step 67859: Loss=5.6154, Acc=0.275, PPL=274.61
2025-09-25 01:08:20,119 - training.trainer - INFO - Epoch 20, Step 67959: Loss=4.8922, Acc=0.333, PPL=133.24
2025-09-25 01:08:27,435 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.9989, Acc=0.238, PPL=402.97
2025-09-25 01:08:34,755 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.9175, Acc=0.267, PPL=371.49
2025-09-25 01:08:42,085 - training.trainer - INFO - Epoch 20, Step 68259: Loss=5.1459, Acc=0.333, PPL=171.73
2025-09-25 01:08:49,811 - training.trainer - INFO - Epoch 20, Step 68359: Loss=5.2072, Acc=0.348, PPL=182.59
2025-09-25 01:08:57,302 - training.trainer - INFO - Epoch 20, Step 68459: Loss=5.5956, Acc=0.310, PPL=269.23
2025-09-25 01:09:04,733 - training.trainer - INFO - Epoch 20, Step 68559: Loss=6.2338, Acc=0.257, PPL=509.69
2025-09-25 01:09:11,978 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.8295, Acc=0.136, PPL=340.19
2025-09-25 01:09:19,355 - training.trainer - INFO - Epoch 20, Step 68759: Loss=6.0314, Acc=0.171, PPL=416.31
2025-09-25 01:09:26,791 - training.trainer - INFO - Epoch 20, Step 68859: Loss=4.3820, Acc=0.422, PPL=80.00
2025-09-25 01:09:33,926 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.9572, Acc=0.156, PPL=386.54
2025-09-25 01:09:41,223 - training.trainer - INFO - Epoch 20, Step 69059: Loss=4.4521, Acc=0.390, PPL=85.80
2025-09-25 01:09:48,433 - training.trainer - INFO - Epoch 20, Step 69159: Loss=4.4057, Acc=0.421, PPL=81.91
2025-09-25 01:09:55,642 - training.trainer - INFO - Epoch 20, Step 69259: Loss=5.4962, Acc=0.235, PPL=243.77
2025-09-25 01:10:03,006 - training.trainer - INFO - Epoch 20, Step 69359: Loss=5.5875, Acc=0.281, PPL=267.08
2025-09-25 01:10:10,378 - training.trainer - INFO - Epoch 20, Step 69459: Loss=6.1282, Acc=0.180, PPL=458.59
2025-09-25 01:10:17,603 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.6418, Acc=0.253, PPL=281.96
2025-09-25 01:10:24,794 - training.trainer - INFO - Epoch 20, Step 69659: Loss=5.8835, Acc=0.266, PPL=359.05
2025-09-25 01:10:32,118 - training.trainer - INFO - Epoch 20, Step 69759: Loss=5.3421, Acc=0.197, PPL=208.95
2025-09-25 01:10:39,420 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.8271, Acc=0.205, PPL=339.36
2025-09-25 01:10:46,606 - training.trainer - INFO - Epoch 20, Step 69959: Loss=5.7974, Acc=0.244, PPL=329.43
2025-09-25 01:10:53,846 - training.trainer - INFO - Epoch 20, Step 70059: Loss=6.4444, Acc=0.293, PPL=629.15
2025-09-25 01:11:01,288 - training.trainer - INFO - Epoch 20, Step 70159: Loss=5.3618, Acc=0.241, PPL=213.12
2025-09-25 01:11:08,600 - training.trainer - INFO - Epoch 20, Step 70259: Loss=6.2300, Acc=0.200, PPL=507.76
2025-09-25 01:11:15,810 - training.trainer - INFO - Epoch 20, Step 70359: Loss=5.5948, Acc=0.240, PPL=269.03
2025-09-25 01:11:23,189 - training.trainer - INFO - Epoch 20, Step 70459: Loss=6.1065, Acc=0.176, PPL=448.76
2025-09-25 01:11:30,470 - training.trainer - INFO - Epoch 20, Step 70559: Loss=4.4140, Acc=0.393, PPL=82.60
2025-09-25 01:11:37,893 - training.trainer - INFO - Epoch 20, Step 70659: Loss=6.1668, Acc=0.241, PPL=476.65
2025-09-25 01:11:45,197 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.8760, Acc=0.228, PPL=356.38
2025-09-25 01:11:52,557 - training.trainer - INFO - Epoch 20, Step 70859: Loss=4.6699, Acc=0.407, PPL=106.69
2025-09-25 01:11:59,945 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.7237, Acc=0.179, PPL=306.04
2025-09-25 01:12:18,961 - training.trainer - INFO - Epoch 21/100 completed in 261.83s - Train Loss: 5.6287, Train Acc: 0.261, Val Loss: 5.6847, Val Acc: 0.250
2025-09-25 01:12:19,557 - training.trainer - INFO - New best model saved with validation loss: 5.6847
2025-09-25 01:12:19,558 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-09-25 01:12:26,469 - training.trainer - INFO - Epoch 21, Step 71142: Loss=6.2790, Acc=0.182, PPL=533.25
2025-09-25 01:12:32,657 - training.trainer - INFO - Epoch 21, Step 71242: Loss=6.0117, Acc=0.286, PPL=408.18
2025-09-25 01:12:39,365 - training.trainer - INFO - Epoch 21, Step 71342: Loss=3.6545, Acc=0.500, PPL=38.65
2025-09-25 01:12:45,683 - training.trainer - INFO - Epoch 21, Step 71442: Loss=5.1147, Acc=0.360, PPL=166.46
2025-09-25 01:12:52,290 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.9539, Acc=0.270, PPL=385.26
2025-09-25 01:12:59,391 - training.trainer - INFO - Epoch 21, Step 71642: Loss=4.8833, Acc=0.278, PPL=132.06
2025-09-25 01:13:07,316 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.9425, Acc=0.194, PPL=380.88
2025-09-25 01:13:14,865 - training.trainer - INFO - Epoch 21, Step 71842: Loss=4.7980, Acc=0.282, PPL=121.27
2025-09-25 01:13:22,301 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.5255, Acc=0.286, PPL=251.01
2025-09-25 01:13:29,625 - training.trainer - INFO - Epoch 21, Step 72042: Loss=6.4777, Acc=0.138, PPL=650.47
2025-09-25 01:13:36,885 - training.trainer - INFO - Epoch 21, Step 72142: Loss=5.2338, Acc=0.250, PPL=187.50
2025-09-25 01:13:44,232 - training.trainer - INFO - Epoch 21, Step 72242: Loss=5.2877, Acc=0.306, PPL=197.89
2025-09-25 01:13:51,521 - training.trainer - INFO - Epoch 21, Step 72342: Loss=4.9096, Acc=0.409, PPL=135.58
2025-09-25 01:13:58,777 - training.trainer - INFO - Epoch 21, Step 72442: Loss=4.9454, Acc=0.304, PPL=140.53
2025-09-25 01:14:06,113 - training.trainer - INFO - Epoch 21, Step 72542: Loss=5.7243, Acc=0.188, PPL=306.22
2025-09-25 01:14:13,606 - training.trainer - INFO - Epoch 21, Step 72642: Loss=6.0400, Acc=0.214, PPL=419.90
2025-09-25 01:14:21,169 - training.trainer - INFO - Epoch 21, Step 72742: Loss=5.9471, Acc=0.178, PPL=382.64
2025-09-25 01:14:28,429 - training.trainer - INFO - Epoch 21, Step 72842: Loss=5.9566, Acc=0.270, PPL=386.30
2025-09-25 01:14:35,691 - training.trainer - INFO - Epoch 21, Step 72942: Loss=6.2379, Acc=0.148, PPL=511.78
2025-09-25 01:14:43,036 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.1244, Acc=0.333, PPL=168.07
2025-09-25 01:14:50,011 - training.trainer - INFO - Epoch 21, Step 73142: Loss=4.4121, Acc=0.462, PPL=82.44
2025-09-25 01:14:57,398 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.7157, Acc=0.300, PPL=303.59
2025-09-25 01:15:04,911 - training.trainer - INFO - Epoch 21, Step 73342: Loss=6.4232, Acc=0.093, PPL=615.98
2025-09-25 01:15:12,389 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.4433, Acc=0.230, PPL=231.20
2025-09-25 01:15:19,958 - training.trainer - INFO - Epoch 21, Step 73542: Loss=6.2428, Acc=0.184, PPL=514.30
2025-09-25 01:15:27,572 - training.trainer - INFO - Epoch 21, Step 73642: Loss=5.7859, Acc=0.182, PPL=325.68
2025-09-25 01:15:35,034 - training.trainer - INFO - Epoch 21, Step 73742: Loss=5.9752, Acc=0.190, PPL=393.56
2025-09-25 01:15:42,747 - training.trainer - INFO - Epoch 21, Step 73842: Loss=5.6532, Acc=0.188, PPL=285.19
2025-09-25 01:15:50,267 - training.trainer - INFO - Epoch 21, Step 73942: Loss=5.1169, Acc=0.261, PPL=166.82
2025-09-25 01:15:57,905 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.4773, Acc=0.320, PPL=239.21
2025-09-25 01:16:05,512 - training.trainer - INFO - Epoch 21, Step 74142: Loss=5.9269, Acc=0.231, PPL=375.00
2025-09-25 01:16:13,047 - training.trainer - INFO - Epoch 21, Step 74242: Loss=5.0595, Acc=0.241, PPL=157.51
2025-09-25 01:16:20,419 - training.trainer - INFO - Epoch 21, Step 74342: Loss=5.7372, Acc=0.200, PPL=310.19
2025-09-25 01:16:39,559 - training.trainer - INFO - Epoch 22/100 completed in 260.00s - Train Loss: 5.6079, Train Acc: 0.262, Val Loss: 5.6758, Val Acc: 0.251
2025-09-25 01:16:40,407 - training.trainer - INFO - New best model saved with validation loss: 5.6758
2025-09-25 01:16:40,407 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-09-25 01:16:48,566 - training.trainer - INFO - Epoch 22, Step 74525: Loss=6.1381, Acc=0.200, PPL=463.18
2025-09-25 01:16:56,026 - training.trainer - INFO - Epoch 22, Step 74625: Loss=6.1115, Acc=0.189, PPL=451.01
2025-09-25 01:17:03,528 - training.trainer - INFO - Epoch 22, Step 74725: Loss=4.5301, Acc=0.389, PPL=92.77
2025-09-25 01:17:11,028 - training.trainer - INFO - Epoch 22, Step 74825: Loss=5.3729, Acc=0.185, PPL=215.49
2025-09-25 01:17:18,435 - training.trainer - INFO - Epoch 22, Step 74925: Loss=5.4335, Acc=0.368, PPL=228.94
2025-09-25 01:17:25,979 - training.trainer - INFO - Epoch 22, Step 75025: Loss=4.8323, Acc=0.375, PPL=125.50
2025-09-25 01:17:33,406 - training.trainer - INFO - Epoch 22, Step 75125: Loss=5.6899, Acc=0.150, PPL=295.87
2025-09-25 01:17:40,925 - training.trainer - INFO - Epoch 22, Step 75225: Loss=4.7871, Acc=0.308, PPL=119.95
2025-09-25 01:17:48,468 - training.trainer - INFO - Epoch 22, Step 75325: Loss=6.5910, Acc=0.194, PPL=728.49
2025-09-25 01:17:55,768 - training.trainer - INFO - Epoch 22, Step 75425: Loss=7.0133, Acc=0.192, PPL=1111.29
2025-09-25 01:18:03,239 - training.trainer - INFO - Epoch 22, Step 75525: Loss=5.8879, Acc=0.250, PPL=360.63
2025-09-25 01:18:11,129 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.8090, Acc=0.212, PPL=333.27
2025-09-25 01:18:18,801 - training.trainer - INFO - Epoch 22, Step 75725: Loss=6.0670, Acc=0.182, PPL=431.38
2025-09-25 01:18:26,233 - training.trainer - INFO - Epoch 22, Step 75825: Loss=4.4571, Acc=0.382, PPL=86.24
2025-09-25 01:18:33,689 - training.trainer - INFO - Epoch 22, Step 75925: Loss=5.0630, Acc=0.348, PPL=158.06
2025-09-25 01:18:40,998 - training.trainer - INFO - Epoch 22, Step 76025: Loss=5.4510, Acc=0.179, PPL=233.00
2025-09-25 01:18:48,261 - training.trainer - INFO - Epoch 22, Step 76125: Loss=5.7627, Acc=0.247, PPL=318.22
2025-09-25 01:18:55,568 - training.trainer - INFO - Epoch 22, Step 76225: Loss=5.8564, Acc=0.257, PPL=349.47
2025-09-25 01:19:02,961 - training.trainer - INFO - Epoch 22, Step 76325: Loss=5.9001, Acc=0.238, PPL=365.09
2025-09-25 01:19:10,521 - training.trainer - INFO - Epoch 22, Step 76425: Loss=6.1219, Acc=0.197, PPL=455.75
2025-09-25 01:19:18,017 - training.trainer - INFO - Epoch 22, Step 76525: Loss=5.3067, Acc=0.200, PPL=201.69
2025-09-25 01:19:25,241 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.5867, Acc=0.273, PPL=266.85
2025-09-25 01:19:32,421 - training.trainer - INFO - Epoch 22, Step 76725: Loss=5.8108, Acc=0.231, PPL=333.90
2025-09-25 01:19:39,644 - training.trainer - INFO - Epoch 22, Step 76825: Loss=5.8143, Acc=0.240, PPL=335.06
2025-09-25 01:19:47,102 - training.trainer - INFO - Epoch 22, Step 76925: Loss=6.6225, Acc=0.125, PPL=751.83
2025-09-25 01:19:54,361 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.1133, Acc=0.286, PPL=166.22
2025-09-25 01:20:01,547 - training.trainer - INFO - Epoch 22, Step 77125: Loss=6.2385, Acc=0.179, PPL=512.10
2025-09-25 01:20:08,739 - training.trainer - INFO - Epoch 22, Step 77225: Loss=4.5732, Acc=0.360, PPL=96.85
2025-09-25 01:20:16,018 - training.trainer - INFO - Epoch 22, Step 77325: Loss=4.2690, Acc=0.571, PPL=71.45
2025-09-25 01:20:23,353 - training.trainer - INFO - Epoch 22, Step 77425: Loss=6.1469, Acc=0.130, PPL=467.29
2025-09-25 01:20:30,635 - training.trainer - INFO - Epoch 22, Step 77525: Loss=5.0649, Acc=0.312, PPL=158.37
2025-09-25 01:20:37,814 - training.trainer - INFO - Epoch 22, Step 77625: Loss=5.9886, Acc=0.237, PPL=398.85
2025-09-25 01:20:45,475 - training.trainer - INFO - Epoch 22, Step 77725: Loss=5.8163, Acc=0.186, PPL=335.74
2025-09-25 01:21:04,433 - training.trainer - INFO - Epoch 23/100 completed in 264.03s - Train Loss: 5.5877, Train Acc: 0.265, Val Loss: 5.6794, Val Acc: 0.252
2025-09-25 01:21:12,783 - training.trainer - INFO - Epoch 23, Step 77908: Loss=4.8681, Acc=0.312, PPL=130.07
2025-09-25 01:21:19,955 - training.trainer - INFO - Epoch 23, Step 78008: Loss=5.9396, Acc=0.205, PPL=379.77
2025-09-25 01:21:27,291 - training.trainer - INFO - Epoch 23, Step 78108: Loss=5.8577, Acc=0.183, PPL=349.93
2025-09-25 01:21:34,617 - training.trainer - INFO - Epoch 23, Step 78208: Loss=5.8218, Acc=0.169, PPL=337.58
2025-09-25 01:21:41,843 - training.trainer - INFO - Epoch 23, Step 78308: Loss=5.1669, Acc=0.375, PPL=175.38
2025-09-25 01:21:49,067 - training.trainer - INFO - Epoch 23, Step 78408: Loss=6.0587, Acc=0.256, PPL=427.83
2025-09-25 01:21:56,218 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.4443, Acc=0.350, PPL=231.43
2025-09-25 01:22:04,054 - training.trainer - INFO - Epoch 23, Step 78608: Loss=6.2092, Acc=0.192, PPL=497.33
2025-09-25 01:22:11,580 - training.trainer - INFO - Epoch 23, Step 78708: Loss=6.2081, Acc=0.156, PPL=496.77
2025-09-25 01:22:19,157 - training.trainer - INFO - Epoch 23, Step 78808: Loss=6.2265, Acc=0.214, PPL=505.99
2025-09-25 01:22:26,377 - training.trainer - INFO - Epoch 23, Step 78908: Loss=5.9561, Acc=0.231, PPL=386.11
2025-09-25 01:22:33,764 - training.trainer - INFO - Epoch 23, Step 79008: Loss=6.0520, Acc=0.171, PPL=424.97
2025-09-25 01:22:41,194 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.9692, Acc=0.195, PPL=391.18
2025-09-25 01:22:48,698 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.2497, Acc=0.424, PPL=190.51
2025-09-25 01:22:55,443 - training.trainer - INFO - Epoch 23, Step 79308: Loss=6.2544, Acc=0.303, PPL=520.31
2025-09-25 01:23:01,614 - training.trainer - INFO - Epoch 23, Step 79408: Loss=5.3027, Acc=0.297, PPL=200.88
2025-09-25 01:23:08,527 - training.trainer - INFO - Epoch 23, Step 79508: Loss=5.7746, Acc=0.283, PPL=322.01
2025-09-25 01:23:15,430 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.2071, Acc=0.244, PPL=182.57
2025-09-25 01:23:22,769 - training.trainer - INFO - Epoch 23, Step 79708: Loss=5.3013, Acc=0.267, PPL=200.60
2025-09-25 01:23:30,263 - training.trainer - INFO - Epoch 23, Step 79808: Loss=6.2019, Acc=0.190, PPL=493.70
2025-09-25 01:23:37,779 - training.trainer - INFO - Epoch 23, Step 79908: Loss=4.4971, Acc=0.350, PPL=89.76
2025-09-25 01:23:45,165 - training.trainer - INFO - Epoch 23, Step 80008: Loss=4.9420, Acc=0.341, PPL=140.06
2025-09-25 01:23:52,463 - training.trainer - INFO - Epoch 23, Step 80108: Loss=5.5613, Acc=0.250, PPL=260.15
2025-09-25 01:23:59,828 - training.trainer - INFO - Epoch 23, Step 80208: Loss=4.6454, Acc=0.409, PPL=104.10
2025-09-25 01:24:07,062 - training.trainer - INFO - Epoch 23, Step 80308: Loss=5.8988, Acc=0.200, PPL=364.58
2025-09-25 01:24:14,325 - training.trainer - INFO - Epoch 23, Step 80408: Loss=4.4748, Acc=0.387, PPL=87.78
2025-09-25 01:24:21,483 - training.trainer - INFO - Epoch 23, Step 80508: Loss=5.0340, Acc=0.391, PPL=153.55
2025-09-25 01:24:28,723 - training.trainer - INFO - Epoch 23, Step 80608: Loss=5.9634, Acc=0.218, PPL=388.95
2025-09-25 01:24:36,036 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.3261, Acc=0.267, PPL=205.64
2025-09-25 01:24:43,481 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.2940, Acc=0.290, PPL=199.14
2025-09-25 01:24:50,768 - training.trainer - INFO - Epoch 23, Step 80908: Loss=5.7969, Acc=0.273, PPL=329.29
2025-09-25 01:24:58,202 - training.trainer - INFO - Epoch 23, Step 81008: Loss=6.6029, Acc=0.192, PPL=737.23
2025-09-25 01:25:05,794 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.8467, Acc=0.200, PPL=346.09
2025-09-25 01:25:24,575 - training.trainer - INFO - Epoch 24/100 completed in 260.14s - Train Loss: 5.5635, Train Acc: 0.270, Val Loss: 5.6699, Val Acc: 0.253
2025-09-25 01:25:25,320 - training.trainer - INFO - New best model saved with validation loss: 5.6699
2025-09-25 01:25:25,320 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-09-25 01:25:33,090 - training.trainer - INFO - Epoch 24, Step 81291: Loss=5.2892, Acc=0.214, PPL=198.19
2025-09-25 01:25:40,477 - training.trainer - INFO - Epoch 24, Step 81391: Loss=5.1742, Acc=0.345, PPL=176.65
2025-09-25 01:25:47,887 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.8598, Acc=0.220, PPL=350.67
2025-09-25 01:25:55,304 - training.trainer - INFO - Epoch 24, Step 81591: Loss=5.9479, Acc=0.194, PPL=382.94
2025-09-25 01:26:02,680 - training.trainer - INFO - Epoch 24, Step 81691: Loss=2.5106, Acc=0.778, PPL=12.31
2025-09-25 01:26:10,046 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.4746, Acc=0.344, PPL=238.56
2025-09-25 01:26:17,518 - training.trainer - INFO - Epoch 24, Step 81891: Loss=5.9716, Acc=0.212, PPL=392.13
2025-09-25 01:26:25,226 - training.trainer - INFO - Epoch 24, Step 81991: Loss=5.3838, Acc=0.289, PPL=217.85
2025-09-25 01:26:32,577 - training.trainer - INFO - Epoch 24, Step 82091: Loss=5.6107, Acc=0.280, PPL=273.33
2025-09-25 01:26:39,966 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.9778, Acc=0.229, PPL=394.57
2025-09-25 01:26:47,210 - training.trainer - INFO - Epoch 24, Step 82291: Loss=5.0209, Acc=0.286, PPL=151.55
2025-09-25 01:26:54,848 - training.trainer - INFO - Epoch 24, Step 82391: Loss=6.3260, Acc=0.167, PPL=558.92
2025-09-25 01:27:02,272 - training.trainer - INFO - Epoch 24, Step 82491: Loss=5.4041, Acc=0.311, PPL=222.31
2025-09-25 01:27:09,695 - training.trainer - INFO - Epoch 24, Step 82591: Loss=6.0194, Acc=0.286, PPL=411.34
2025-09-25 01:27:17,061 - training.trainer - INFO - Epoch 24, Step 82691: Loss=4.9728, Acc=0.300, PPL=144.42
2025-09-25 01:27:24,383 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.4865, Acc=0.318, PPL=241.42
2025-09-25 01:27:31,883 - training.trainer - INFO - Epoch 24, Step 82891: Loss=5.4198, Acc=0.275, PPL=225.83
2025-09-25 01:27:39,662 - training.trainer - INFO - Epoch 24, Step 82991: Loss=6.4305, Acc=0.173, PPL=620.47
2025-09-25 01:27:47,279 - training.trainer - INFO - Epoch 24, Step 83091: Loss=5.3098, Acc=0.283, PPL=202.31
2025-09-25 01:27:54,829 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.3827, Acc=0.321, PPL=217.61
2025-09-25 01:28:02,354 - training.trainer - INFO - Epoch 24, Step 83291: Loss=4.6481, Acc=0.350, PPL=104.39
2025-09-25 01:28:09,819 - training.trainer - INFO - Epoch 24, Step 83391: Loss=4.8465, Acc=0.281, PPL=127.29
2025-09-25 01:28:17,365 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.3591, Acc=0.231, PPL=212.53
2025-09-25 01:28:25,048 - training.trainer - INFO - Epoch 24, Step 83591: Loss=5.9177, Acc=0.278, PPL=371.56
2025-09-25 01:28:32,645 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.1381, Acc=0.176, PPL=170.38
2025-09-25 01:28:40,460 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.9420, Acc=0.278, PPL=380.69
2025-09-25 01:28:47,878 - training.trainer - INFO - Epoch 24, Step 83891: Loss=3.7770, Acc=0.483, PPL=43.69
2025-09-25 01:28:55,590 - training.trainer - INFO - Epoch 24, Step 83991: Loss=4.2758, Acc=0.458, PPL=71.94
2025-09-25 01:29:03,050 - training.trainer - INFO - Epoch 24, Step 84091: Loss=5.7384, Acc=0.174, PPL=310.56
2025-09-25 01:29:10,404 - training.trainer - INFO - Epoch 24, Step 84191: Loss=4.7282, Acc=0.333, PPL=113.09
2025-09-25 01:29:17,997 - training.trainer - INFO - Epoch 24, Step 84291: Loss=6.3341, Acc=0.148, PPL=563.47
2025-09-25 01:29:25,642 - training.trainer - INFO - Epoch 24, Step 84391: Loss=6.1007, Acc=0.255, PPL=446.15
2025-09-25 01:29:33,083 - training.trainer - INFO - Epoch 24, Step 84491: Loss=5.7514, Acc=0.333, PPL=314.64
2025-09-25 01:29:52,617 - training.trainer - INFO - Epoch 25/100 completed in 267.30s - Train Loss: 5.5471, Train Acc: 0.272, Val Loss: 5.6493, Val Acc: 0.257
2025-09-25 01:29:52,973 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-25 01:29:53,650 - training.trainer - INFO - New best model saved with validation loss: 5.6493
2025-09-25 01:29:53,651 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-25 01:30:01,603 - training.trainer - INFO - Epoch 25, Step 84674: Loss=5.9273, Acc=0.207, PPL=375.15
2025-09-25 01:30:09,151 - training.trainer - INFO - Epoch 25, Step 84774: Loss=6.1477, Acc=0.167, PPL=467.65
2025-09-25 01:30:16,664 - training.trainer - INFO - Epoch 25, Step 84874: Loss=4.2175, Acc=0.379, PPL=67.86
2025-09-25 01:30:24,078 - training.trainer - INFO - Epoch 25, Step 84974: Loss=5.3164, Acc=0.370, PPL=203.66
2025-09-25 01:30:31,389 - training.trainer - INFO - Epoch 25, Step 85074: Loss=5.3885, Acc=0.294, PPL=218.88
2025-09-25 01:30:38,758 - training.trainer - INFO - Epoch 25, Step 85174: Loss=5.7478, Acc=0.316, PPL=313.49
2025-09-25 01:30:46,449 - training.trainer - INFO - Epoch 25, Step 85274: Loss=4.5545, Acc=0.407, PPL=95.06
2025-09-25 01:30:53,975 - training.trainer - INFO - Epoch 25, Step 85374: Loss=5.4915, Acc=0.205, PPL=242.63
2025-09-25 01:31:01,586 - training.trainer - INFO - Epoch 25, Step 85474: Loss=5.2029, Acc=0.250, PPL=181.79
2025-09-25 01:31:09,204 - training.trainer - INFO - Epoch 25, Step 85574: Loss=6.0483, Acc=0.204, PPL=423.41
2025-09-25 01:31:16,788 - training.trainer - INFO - Epoch 25, Step 85674: Loss=4.8613, Acc=0.314, PPL=129.19
2025-09-25 01:31:24,344 - training.trainer - INFO - Epoch 25, Step 85774: Loss=6.4565, Acc=0.247, PPL=636.85
2025-09-25 01:31:31,942 - training.trainer - INFO - Epoch 25, Step 85874: Loss=5.5160, Acc=0.265, PPL=248.65
2025-09-25 01:31:39,616 - training.trainer - INFO - Epoch 25, Step 85974: Loss=5.1280, Acc=0.375, PPL=168.67
2025-09-25 01:31:46,989 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.6497, Acc=0.257, PPL=284.21
2025-09-25 01:31:54,282 - training.trainer - INFO - Epoch 25, Step 86174: Loss=3.5031, Acc=0.652, PPL=33.22
2025-09-25 01:32:01,566 - training.trainer - INFO - Epoch 25, Step 86274: Loss=5.6644, Acc=0.351, PPL=288.40
2025-09-25 01:32:08,918 - training.trainer - INFO - Epoch 25, Step 86374: Loss=6.8007, Acc=0.170, PPL=898.50
2025-09-25 01:32:16,400 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.5124, Acc=0.222, PPL=247.74
2025-09-25 01:32:23,901 - training.trainer - INFO - Epoch 25, Step 86574: Loss=4.9262, Acc=0.316, PPL=137.86
2025-09-25 01:32:31,355 - training.trainer - INFO - Epoch 25, Step 86674: Loss=4.5690, Acc=0.444, PPL=96.45
2025-09-25 01:32:38,824 - training.trainer - INFO - Epoch 25, Step 86774: Loss=5.9323, Acc=0.207, PPL=377.02
2025-09-25 01:32:46,471 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.4548, Acc=0.194, PPL=635.76
2025-09-25 01:32:54,129 - training.trainer - INFO - Epoch 25, Step 86974: Loss=5.0711, Acc=0.364, PPL=159.35
2025-09-25 01:33:01,570 - training.trainer - INFO - Epoch 25, Step 87074: Loss=6.1209, Acc=0.217, PPL=455.27
2025-09-25 01:33:08,995 - training.trainer - INFO - Epoch 25, Step 87174: Loss=5.1430, Acc=0.348, PPL=171.23
2025-09-25 01:33:16,741 - training.trainer - INFO - Epoch 25, Step 87274: Loss=5.7930, Acc=0.273, PPL=327.98
2025-09-25 01:33:24,260 - training.trainer - INFO - Epoch 25, Step 87374: Loss=5.3977, Acc=0.303, PPL=220.91
2025-09-25 01:33:31,718 - training.trainer - INFO - Epoch 25, Step 87474: Loss=5.5999, Acc=0.286, PPL=270.39
2025-09-25 01:33:39,154 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.7932, Acc=0.289, PPL=328.07
2025-09-25 01:33:46,668 - training.trainer - INFO - Epoch 25, Step 87674: Loss=5.4310, Acc=0.207, PPL=228.38
2025-09-25 01:33:54,624 - training.trainer - INFO - Epoch 25, Step 87774: Loss=3.6724, Acc=0.478, PPL=39.35
2025-09-25 01:34:02,196 - training.trainer - INFO - Epoch 25, Step 87874: Loss=4.8697, Acc=0.317, PPL=130.29
2025-09-25 01:34:21,613 - training.trainer - INFO - Epoch 26/100 completed in 267.96s - Train Loss: 5.5237, Train Acc: 0.275, Val Loss: 5.6436, Val Acc: 0.256
2025-09-25 01:34:22,366 - training.trainer - INFO - New best model saved with validation loss: 5.6436
2025-09-25 01:34:22,367 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_26.pt
2025-09-25 01:34:30,196 - training.trainer - INFO - Epoch 26, Step 88057: Loss=6.4062, Acc=0.254, PPL=605.61
2025-09-25 01:34:37,659 - training.trainer - INFO - Epoch 26, Step 88157: Loss=5.2765, Acc=0.268, PPL=195.68
2025-09-25 01:34:45,737 - training.trainer - INFO - Epoch 26, Step 88257: Loss=5.2847, Acc=0.351, PPL=197.30
2025-09-25 01:34:53,109 - training.trainer - INFO - Epoch 26, Step 88357: Loss=5.8042, Acc=0.196, PPL=331.68
2025-09-25 01:35:00,457 - training.trainer - INFO - Epoch 26, Step 88457: Loss=5.8931, Acc=0.183, PPL=362.53
2025-09-25 01:35:08,087 - training.trainer - INFO - Epoch 26, Step 88557: Loss=4.6132, Acc=0.278, PPL=100.80
2025-09-25 01:35:15,477 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.3145, Acc=0.250, PPL=203.26
2025-09-25 01:35:22,940 - training.trainer - INFO - Epoch 26, Step 88757: Loss=5.0135, Acc=0.356, PPL=150.43
2025-09-25 01:35:30,379 - training.trainer - INFO - Epoch 26, Step 88857: Loss=5.5215, Acc=0.229, PPL=250.00
2025-09-25 01:35:37,777 - training.trainer - INFO - Epoch 26, Step 88957: Loss=5.8981, Acc=0.321, PPL=364.34
2025-09-25 01:35:45,135 - training.trainer - INFO - Epoch 26, Step 89057: Loss=6.0934, Acc=0.267, PPL=442.92
2025-09-25 01:35:52,528 - training.trainer - INFO - Epoch 26, Step 89157: Loss=4.8265, Acc=0.308, PPL=124.77
2025-09-25 01:36:00,613 - training.trainer - INFO - Epoch 26, Step 89257: Loss=5.4119, Acc=0.288, PPL=224.06
2025-09-25 01:36:08,182 - training.trainer - INFO - Epoch 26, Step 89357: Loss=3.8824, Acc=0.625, PPL=48.54
2025-09-25 01:36:15,604 - training.trainer - INFO - Epoch 26, Step 89457: Loss=6.0144, Acc=0.263, PPL=409.27
2025-09-25 01:36:22,942 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.9881, Acc=0.234, PPL=398.66
2025-09-25 01:36:30,293 - training.trainer - INFO - Epoch 26, Step 89657: Loss=5.5677, Acc=0.196, PPL=261.83
2025-09-25 01:36:37,672 - training.trainer - INFO - Epoch 26, Step 89757: Loss=5.8098, Acc=0.262, PPL=333.56
2025-09-25 01:36:45,153 - training.trainer - INFO - Epoch 26, Step 89857: Loss=6.2083, Acc=0.180, PPL=496.87
2025-09-25 01:36:52,795 - training.trainer - INFO - Epoch 26, Step 89957: Loss=5.6007, Acc=0.292, PPL=270.62
2025-09-25 01:37:00,305 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.0489, Acc=0.371, PPL=155.84
2025-09-25 01:37:07,883 - training.trainer - INFO - Epoch 26, Step 90157: Loss=5.6328, Acc=0.342, PPL=279.43
2025-09-25 01:37:15,516 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.5441, Acc=0.357, PPL=255.71
2025-09-25 01:37:22,876 - training.trainer - INFO - Epoch 26, Step 90357: Loss=4.6710, Acc=0.188, PPL=106.81
2025-09-25 01:37:30,242 - training.trainer - INFO - Epoch 26, Step 90457: Loss=5.4238, Acc=0.235, PPL=226.73
2025-09-25 01:37:37,637 - training.trainer - INFO - Epoch 26, Step 90557: Loss=5.6776, Acc=0.320, PPL=292.26
2025-09-25 01:37:45,109 - training.trainer - INFO - Epoch 26, Step 90657: Loss=6.0353, Acc=0.333, PPL=417.91
2025-09-25 01:37:52,697 - training.trainer - INFO - Epoch 26, Step 90757: Loss=6.6648, Acc=0.186, PPL=784.31
2025-09-25 01:38:00,016 - training.trainer - INFO - Epoch 26, Step 90857: Loss=5.4307, Acc=0.290, PPL=228.30
2025-09-25 01:38:07,298 - training.trainer - INFO - Epoch 26, Step 90957: Loss=5.9236, Acc=0.167, PPL=373.76
2025-09-25 01:38:14,670 - training.trainer - INFO - Epoch 26, Step 91057: Loss=3.3535, Acc=0.700, PPL=28.60
2025-09-25 01:38:22,068 - training.trainer - INFO - Epoch 26, Step 91157: Loss=4.7508, Acc=0.429, PPL=115.68
2025-09-25 01:38:29,491 - training.trainer - INFO - Epoch 26, Step 91257: Loss=5.3866, Acc=0.292, PPL=218.45
2025-09-25 01:38:48,798 - training.trainer - INFO - Epoch 27/100 completed in 266.43s - Train Loss: 5.5145, Train Acc: 0.276, Val Loss: 5.6484, Val Acc: 0.257
2025-09-25 01:38:56,826 - training.trainer - INFO - Epoch 27, Step 91440: Loss=5.2328, Acc=0.400, PPL=187.32
2025-09-25 01:39:04,661 - training.trainer - INFO - Epoch 27, Step 91540: Loss=3.7795, Acc=0.455, PPL=43.79
2025-09-25 01:39:12,310 - training.trainer - INFO - Epoch 27, Step 91640: Loss=6.0484, Acc=0.222, PPL=423.45
2025-09-25 01:39:19,689 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.8000, Acc=0.215, PPL=330.31
2025-09-25 01:39:27,629 - training.trainer - INFO - Epoch 27, Step 91840: Loss=5.3588, Acc=0.238, PPL=212.46
2025-09-25 01:39:34,957 - training.trainer - INFO - Epoch 27, Step 91940: Loss=4.9942, Acc=0.375, PPL=147.55
2025-09-25 01:39:42,332 - training.trainer - INFO - Epoch 27, Step 92040: Loss=4.8119, Acc=0.400, PPL=122.96
2025-09-25 01:39:49,845 - training.trainer - INFO - Epoch 27, Step 92140: Loss=6.1901, Acc=0.210, PPL=487.88
2025-09-25 01:39:57,203 - training.trainer - INFO - Epoch 27, Step 92240: Loss=6.1001, Acc=0.250, PPL=445.92
2025-09-25 01:40:04,723 - training.trainer - INFO - Epoch 27, Step 92340: Loss=5.3067, Acc=0.237, PPL=201.69
2025-09-25 01:40:12,165 - training.trainer - INFO - Epoch 27, Step 92440: Loss=6.2365, Acc=0.180, PPL=511.08
2025-09-25 01:40:19,599 - training.trainer - INFO - Epoch 27, Step 92540: Loss=5.5718, Acc=0.277, PPL=262.90
2025-09-25 01:40:26,949 - training.trainer - INFO - Epoch 27, Step 92640: Loss=5.0406, Acc=0.312, PPL=154.56
2025-09-25 01:40:34,388 - training.trainer - INFO - Epoch 27, Step 92740: Loss=5.9977, Acc=0.196, PPL=402.49
2025-09-25 01:40:41,732 - training.trainer - INFO - Epoch 27, Step 92840: Loss=5.4917, Acc=0.250, PPL=242.66
2025-09-25 01:40:49,069 - training.trainer - INFO - Epoch 27, Step 92940: Loss=5.5019, Acc=0.441, PPL=245.15
2025-09-25 01:40:56,569 - training.trainer - INFO - Epoch 27, Step 93040: Loss=5.7274, Acc=0.318, PPL=307.18
2025-09-25 01:41:04,004 - training.trainer - INFO - Epoch 27, Step 93140: Loss=6.0307, Acc=0.243, PPL=415.99
2025-09-25 01:41:11,343 - training.trainer - INFO - Epoch 27, Step 93240: Loss=6.1114, Acc=0.172, PPL=450.95
2025-09-25 01:41:18,683 - training.trainer - INFO - Epoch 27, Step 93340: Loss=5.4058, Acc=0.306, PPL=222.70
2025-09-25 01:41:26,208 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.2684, Acc=0.259, PPL=194.11
2025-09-25 01:41:33,559 - training.trainer - INFO - Epoch 27, Step 93540: Loss=4.1195, Acc=0.500, PPL=61.53
2025-09-25 01:41:40,952 - training.trainer - INFO - Epoch 27, Step 93640: Loss=6.0191, Acc=0.139, PPL=411.20
2025-09-25 01:41:48,355 - training.trainer - INFO - Epoch 27, Step 93740: Loss=6.6026, Acc=0.160, PPL=736.98
2025-09-25 01:41:55,693 - training.trainer - INFO - Epoch 27, Step 93840: Loss=6.0643, Acc=0.200, PPL=430.22
2025-09-25 01:42:03,458 - training.trainer - INFO - Epoch 27, Step 93940: Loss=4.0777, Acc=0.353, PPL=59.01
2025-09-25 01:42:11,192 - training.trainer - INFO - Epoch 27, Step 94040: Loss=4.8917, Acc=0.407, PPL=133.18
2025-09-25 01:42:18,764 - training.trainer - INFO - Epoch 27, Step 94140: Loss=5.9853, Acc=0.340, PPL=397.52
2025-09-25 01:42:26,230 - training.trainer - INFO - Epoch 27, Step 94240: Loss=6.2547, Acc=0.205, PPL=520.47
2025-09-25 01:42:33,881 - training.trainer - INFO - Epoch 27, Step 94340: Loss=5.5985, Acc=0.300, PPL=270.02
2025-09-25 01:42:41,374 - training.trainer - INFO - Epoch 27, Step 94440: Loss=6.3955, Acc=0.229, PPL=599.12
2025-09-25 01:42:48,810 - training.trainer - INFO - Epoch 27, Step 94540: Loss=5.5050, Acc=0.212, PPL=245.91
2025-09-25 01:42:56,396 - training.trainer - INFO - Epoch 27, Step 94640: Loss=5.7738, Acc=0.265, PPL=321.76
2025-09-25 01:43:15,024 - training.trainer - INFO - Epoch 28/100 completed in 266.23s - Train Loss: 5.4928, Train Acc: 0.279, Val Loss: 5.6376, Val Acc: 0.258
2025-09-25 01:43:15,775 - training.trainer - INFO - New best model saved with validation loss: 5.6376
2025-09-25 01:43:15,775 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_28.pt
2025-09-25 01:43:23,505 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.3590, Acc=0.310, PPL=212.52
2025-09-25 01:43:31,394 - training.trainer - INFO - Epoch 28, Step 94923: Loss=4.8125, Acc=0.419, PPL=123.03
2025-09-25 01:43:39,609 - training.trainer - INFO - Epoch 28, Step 95023: Loss=6.0235, Acc=0.269, PPL=413.03
2025-09-25 01:43:47,035 - training.trainer - INFO - Epoch 28, Step 95123: Loss=6.0807, Acc=0.280, PPL=437.32
2025-09-25 01:43:54,386 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.9801, Acc=0.290, PPL=395.50
2025-09-25 01:44:01,851 - training.trainer - INFO - Epoch 28, Step 95323: Loss=4.4056, Acc=0.375, PPL=81.91
2025-09-25 01:44:09,216 - training.trainer - INFO - Epoch 28, Step 95423: Loss=5.5467, Acc=0.256, PPL=256.38
2025-09-25 01:44:16,687 - training.trainer - INFO - Epoch 28, Step 95523: Loss=6.3001, Acc=0.158, PPL=544.65
2025-09-25 01:44:23,788 - training.trainer - INFO - Epoch 28, Step 95623: Loss=3.8266, Acc=0.486, PPL=45.91
2025-09-25 01:44:30,959 - training.trainer - INFO - Epoch 28, Step 95723: Loss=6.2525, Acc=0.197, PPL=519.30
2025-09-25 01:44:38,404 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.0106, Acc=0.375, PPL=150.00
2025-09-25 01:44:45,844 - training.trainer - INFO - Epoch 28, Step 95923: Loss=5.3837, Acc=0.310, PPL=217.83
2025-09-25 01:44:53,333 - training.trainer - INFO - Epoch 28, Step 96023: Loss=5.3500, Acc=0.385, PPL=210.61
2025-09-25 01:45:00,865 - training.trainer - INFO - Epoch 28, Step 96123: Loss=5.5706, Acc=0.175, PPL=262.60
2025-09-25 01:45:08,356 - training.trainer - INFO - Epoch 28, Step 96223: Loss=5.0857, Acc=0.292, PPL=161.70
2025-09-25 01:45:15,880 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.1978, Acc=0.318, PPL=180.88
2025-09-25 01:45:23,374 - training.trainer - INFO - Epoch 28, Step 96423: Loss=5.1903, Acc=0.367, PPL=179.52
2025-09-25 01:45:30,970 - training.trainer - INFO - Epoch 28, Step 96523: Loss=4.8651, Acc=0.364, PPL=129.68
2025-09-25 01:45:38,802 - training.trainer - INFO - Epoch 28, Step 96623: Loss=5.3961, Acc=0.357, PPL=220.55
2025-09-25 01:45:46,421 - training.trainer - INFO - Epoch 28, Step 96723: Loss=4.6718, Acc=0.395, PPL=106.89
2025-09-25 01:45:54,019 - training.trainer - INFO - Epoch 28, Step 96823: Loss=4.9419, Acc=0.250, PPL=140.03
2025-09-25 01:46:01,581 - training.trainer - INFO - Epoch 28, Step 96923: Loss=5.4269, Acc=0.333, PPL=227.45
2025-09-25 01:46:09,038 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.4775, Acc=0.261, PPL=239.25
2025-09-25 01:46:16,524 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.0021, Acc=0.194, PPL=148.73
2025-09-25 01:46:23,925 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.4949, Acc=0.237, PPL=243.44
2025-09-25 01:46:31,578 - training.trainer - INFO - Epoch 28, Step 97323: Loss=6.0141, Acc=0.224, PPL=409.16
2025-09-25 01:46:39,085 - training.trainer - INFO - Epoch 28, Step 97423: Loss=6.0080, Acc=0.244, PPL=406.68
2025-09-25 01:46:46,652 - training.trainer - INFO - Epoch 28, Step 97523: Loss=5.5722, Acc=0.215, PPL=263.02
2025-09-25 01:46:54,234 - training.trainer - INFO - Epoch 28, Step 97623: Loss=6.4386, Acc=0.161, PPL=625.55
2025-09-25 01:47:01,757 - training.trainer - INFO - Epoch 28, Step 97723: Loss=5.7093, Acc=0.226, PPL=301.67
2025-09-25 01:47:09,354 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.8391, Acc=0.286, PPL=343.48
2025-09-25 01:47:16,844 - training.trainer - INFO - Epoch 28, Step 97923: Loss=6.0972, Acc=0.225, PPL=444.62
2025-09-25 01:47:24,265 - training.trainer - INFO - Epoch 28, Step 98023: Loss=6.2516, Acc=0.233, PPL=518.85
2025-09-25 01:47:43,421 - training.trainer - INFO - Epoch 29/100 completed in 267.65s - Train Loss: 5.4716, Train Acc: 0.283, Val Loss: 5.6411, Val Acc: 0.255
2025-09-25 01:47:51,297 - training.trainer - INFO - Epoch 29, Step 98206: Loss=5.3217, Acc=0.342, PPL=204.73
2025-09-25 01:47:58,813 - training.trainer - INFO - Epoch 29, Step 98306: Loss=5.3118, Acc=0.333, PPL=202.71
2025-09-25 01:48:06,227 - training.trainer - INFO - Epoch 29, Step 98406: Loss=4.5031, Acc=0.474, PPL=90.30
2025-09-25 01:48:13,682 - training.trainer - INFO - Epoch 29, Step 98506: Loss=5.3298, Acc=0.267, PPL=206.39
2025-09-25 01:48:20,990 - training.trainer - INFO - Epoch 29, Step 98606: Loss=5.6487, Acc=0.254, PPL=283.93
2025-09-25 01:48:28,400 - training.trainer - INFO - Epoch 29, Step 98706: Loss=6.6462, Acc=0.098, PPL=769.84
2025-09-25 01:48:35,924 - training.trainer - INFO - Epoch 29, Step 98806: Loss=6.0605, Acc=0.107, PPL=428.59
2025-09-25 01:48:43,399 - training.trainer - INFO - Epoch 29, Step 98906: Loss=5.5518, Acc=0.308, PPL=257.69
2025-09-25 01:48:50,785 - training.trainer - INFO - Epoch 29, Step 99006: Loss=5.7248, Acc=0.231, PPL=306.36
2025-09-25 01:48:58,452 - training.trainer - INFO - Epoch 29, Step 99106: Loss=4.6760, Acc=0.500, PPL=107.34
2025-09-25 01:49:05,938 - training.trainer - INFO - Epoch 29, Step 99206: Loss=5.6094, Acc=0.198, PPL=272.98
2025-09-25 01:49:13,301 - training.trainer - INFO - Epoch 29, Step 99306: Loss=4.6629, Acc=0.348, PPL=105.94
2025-09-25 01:49:20,742 - training.trainer - INFO - Epoch 29, Step 99406: Loss=5.8016, Acc=0.214, PPL=330.84
2025-09-25 01:49:28,139 - training.trainer - INFO - Epoch 29, Step 99506: Loss=5.5155, Acc=0.258, PPL=248.51
2025-09-25 01:49:35,627 - training.trainer - INFO - Epoch 29, Step 99606: Loss=5.1349, Acc=0.263, PPL=169.84
2025-09-25 01:49:43,164 - training.trainer - INFO - Epoch 29, Step 99706: Loss=6.6185, Acc=0.222, PPL=748.86
2025-09-25 01:49:50,587 - training.trainer - INFO - Epoch 29, Step 99806: Loss=5.8320, Acc=0.211, PPL=341.04
2025-09-25 01:49:57,980 - training.trainer - INFO - Epoch 29, Step 99906: Loss=5.7911, Acc=0.225, PPL=327.38
2025-09-25 01:50:05,405 - training.trainer - INFO - Epoch 29, Step 100006: Loss=5.9943, Acc=0.193, PPL=401.13
2025-09-25 01:50:13,134 - training.trainer - INFO - Epoch 29, Step 100106: Loss=5.9149, Acc=0.195, PPL=370.51
2025-09-25 01:50:20,553 - training.trainer - INFO - Epoch 29, Step 100206: Loss=4.6789, Acc=0.417, PPL=107.65
2025-09-25 01:50:28,299 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.8630, Acc=0.216, PPL=351.79
2025-09-25 01:50:36,073 - training.trainer - INFO - Epoch 29, Step 100406: Loss=4.9766, Acc=0.355, PPL=144.98
2025-09-25 01:50:43,663 - training.trainer - INFO - Epoch 29, Step 100506: Loss=5.4747, Acc=0.304, PPL=238.58
2025-09-25 01:50:51,229 - training.trainer - INFO - Epoch 29, Step 100606: Loss=6.1370, Acc=0.228, PPL=462.66
2025-09-25 01:50:58,763 - training.trainer - INFO - Epoch 29, Step 100706: Loss=6.2735, Acc=0.250, PPL=530.34
2025-09-25 01:51:06,266 - training.trainer - INFO - Epoch 29, Step 100806: Loss=5.3195, Acc=0.300, PPL=204.28
2025-09-25 01:51:13,648 - training.trainer - INFO - Epoch 29, Step 100906: Loss=5.7519, Acc=0.222, PPL=314.79
2025-09-25 01:51:21,015 - training.trainer - INFO - Epoch 29, Step 101006: Loss=6.2002, Acc=0.176, PPL=492.85
2025-09-25 01:51:28,455 - training.trainer - INFO - Epoch 29, Step 101106: Loss=5.6119, Acc=0.255, PPL=273.66
2025-09-25 01:51:35,977 - training.trainer - INFO - Epoch 29, Step 101206: Loss=5.0140, Acc=0.322, PPL=150.50
2025-09-25 01:51:43,465 - training.trainer - INFO - Epoch 29, Step 101306: Loss=5.4768, Acc=0.250, PPL=239.07
2025-09-25 01:51:51,078 - training.trainer - INFO - Epoch 29, Step 101406: Loss=5.6888, Acc=0.219, PPL=295.54
2025-09-25 01:52:10,454 - training.trainer - INFO - Epoch 30/100 completed in 267.03s - Train Loss: 5.4537, Train Acc: 0.284, Val Loss: 5.6393, Val Acc: 0.259
2025-09-25 01:52:10,836 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-25 01:52:18,658 - training.trainer - INFO - Epoch 30, Step 101589: Loss=5.7818, Acc=0.250, PPL=324.34
2025-09-25 01:52:26,025 - training.trainer - INFO - Epoch 30, Step 101689: Loss=5.6873, Acc=0.263, PPL=295.11
2025-09-25 01:52:33,498 - training.trainer - INFO - Epoch 30, Step 101789: Loss=5.0183, Acc=0.227, PPL=151.15
2025-09-25 01:52:40,880 - training.trainer - INFO - Epoch 30, Step 101889: Loss=4.9914, Acc=0.250, PPL=147.14
2025-09-25 01:52:48,239 - training.trainer - INFO - Epoch 30, Step 101989: Loss=5.0339, Acc=0.250, PPL=153.52
2025-09-25 01:52:55,725 - training.trainer - INFO - Epoch 30, Step 102089: Loss=6.0468, Acc=0.231, PPL=422.74
2025-09-25 01:53:03,133 - training.trainer - INFO - Epoch 30, Step 102189: Loss=6.0011, Acc=0.141, PPL=403.87
2025-09-25 01:53:10,723 - training.trainer - INFO - Epoch 30, Step 102289: Loss=5.4080, Acc=0.200, PPL=223.17
2025-09-25 01:53:18,317 - training.trainer - INFO - Epoch 30, Step 102389: Loss=6.3284, Acc=0.148, PPL=560.29
2025-09-25 01:53:25,775 - training.trainer - INFO - Epoch 30, Step 102489: Loss=5.5972, Acc=0.306, PPL=269.67
2025-09-25 01:53:33,525 - training.trainer - INFO - Epoch 30, Step 102589: Loss=4.6607, Acc=0.359, PPL=105.71
2025-09-25 01:53:40,912 - training.trainer - INFO - Epoch 30, Step 102689: Loss=4.6710, Acc=0.381, PPL=106.81
2025-09-25 01:53:48,177 - training.trainer - INFO - Epoch 30, Step 102789: Loss=4.5997, Acc=0.343, PPL=99.45
2025-09-25 01:53:55,644 - training.trainer - INFO - Epoch 30, Step 102889: Loss=5.7581, Acc=0.233, PPL=316.74
2025-09-25 01:54:02,943 - training.trainer - INFO - Epoch 30, Step 102989: Loss=4.8693, Acc=0.346, PPL=130.23
2025-09-25 01:54:10,164 - training.trainer - INFO - Epoch 30, Step 103089: Loss=4.1350, Acc=0.471, PPL=62.49
2025-09-25 01:54:17,556 - training.trainer - INFO - Epoch 30, Step 103189: Loss=5.8346, Acc=0.182, PPL=341.92
2025-09-25 01:54:25,035 - training.trainer - INFO - Epoch 30, Step 103289: Loss=4.7657, Acc=0.306, PPL=117.41
2025-09-25 01:54:32,418 - training.trainer - INFO - Epoch 30, Step 103389: Loss=5.6440, Acc=0.372, PPL=282.60
2025-09-25 01:54:39,658 - training.trainer - INFO - Epoch 30, Step 103489: Loss=4.8017, Acc=0.269, PPL=121.72
2025-09-25 01:54:46,990 - training.trainer - INFO - Epoch 30, Step 103589: Loss=4.4333, Acc=0.448, PPL=84.21
2025-09-25 01:54:54,246 - training.trainer - INFO - Epoch 30, Step 103689: Loss=4.8735, Acc=0.355, PPL=130.78
2025-09-25 01:55:01,851 - training.trainer - INFO - Epoch 30, Step 103789: Loss=5.4702, Acc=0.250, PPL=237.51
2025-09-25 01:55:09,371 - training.trainer - INFO - Epoch 30, Step 103889: Loss=5.8824, Acc=0.214, PPL=358.65
2025-09-25 01:55:17,073 - training.trainer - INFO - Epoch 30, Step 103989: Loss=4.8199, Acc=0.324, PPL=123.96
2025-09-25 01:55:24,327 - training.trainer - INFO - Epoch 30, Step 104089: Loss=6.1185, Acc=0.143, PPL=454.20
2025-09-25 01:55:31,608 - training.trainer - INFO - Epoch 30, Step 104189: Loss=5.0329, Acc=0.364, PPL=153.38
2025-09-25 01:55:39,145 - training.trainer - INFO - Epoch 30, Step 104289: Loss=2.7557, Acc=0.735, PPL=15.73
2025-09-25 01:55:46,783 - training.trainer - INFO - Epoch 30, Step 104389: Loss=5.0868, Acc=0.319, PPL=161.88
2025-09-25 01:55:54,421 - training.trainer - INFO - Epoch 30, Step 104489: Loss=5.0318, Acc=0.400, PPL=153.21
2025-09-25 01:56:01,795 - training.trainer - INFO - Epoch 30, Step 104589: Loss=5.2609, Acc=0.263, PPL=192.66
2025-09-25 01:56:09,851 - training.trainer - INFO - Epoch 30, Step 104689: Loss=4.9857, Acc=0.333, PPL=146.31
2025-09-25 01:56:17,094 - training.trainer - INFO - Epoch 30, Step 104789: Loss=5.7644, Acc=0.250, PPL=318.73
2025-09-25 01:56:36,322 - training.trainer - INFO - Epoch 31/100 completed in 265.49s - Train Loss: 5.4300, Train Acc: 0.289, Val Loss: 5.6440, Val Acc: 0.260
2025-09-25 01:56:44,222 - training.trainer - INFO - Epoch 31, Step 104972: Loss=5.7366, Acc=0.222, PPL=310.01
2025-09-25 01:56:51,552 - training.trainer - INFO - Epoch 31, Step 105072: Loss=5.9806, Acc=0.171, PPL=395.66
2025-09-25 01:56:59,020 - training.trainer - INFO - Epoch 31, Step 105172: Loss=5.4822, Acc=0.342, PPL=240.37
2025-09-25 01:57:06,282 - training.trainer - INFO - Epoch 31, Step 105272: Loss=5.3326, Acc=0.327, PPL=206.97
2025-09-25 01:57:13,542 - training.trainer - INFO - Epoch 31, Step 105372: Loss=6.2905, Acc=0.169, PPL=539.42
2025-09-25 01:57:20,899 - training.trainer - INFO - Epoch 31, Step 105472: Loss=5.3282, Acc=0.273, PPL=206.07
2025-09-25 01:57:28,198 - training.trainer - INFO - Epoch 31, Step 105572: Loss=5.9938, Acc=0.312, PPL=400.92
2025-09-25 01:57:35,484 - training.trainer - INFO - Epoch 31, Step 105672: Loss=5.6292, Acc=0.344, PPL=278.44
2025-09-25 01:57:42,818 - training.trainer - INFO - Epoch 31, Step 105772: Loss=4.6653, Acc=0.483, PPL=106.20
2025-09-25 01:57:50,168 - training.trainer - INFO - Epoch 31, Step 105872: Loss=4.9692, Acc=0.276, PPL=143.91
2025-09-25 01:57:57,428 - training.trainer - INFO - Epoch 31, Step 105972: Loss=6.0630, Acc=0.213, PPL=429.65
2025-09-25 01:58:04,839 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.5451, Acc=0.265, PPL=255.98
2025-09-25 01:58:12,468 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.8232, Acc=0.231, PPL=338.04
2025-09-25 01:58:19,773 - training.trainer - INFO - Epoch 31, Step 106272: Loss=5.0569, Acc=0.318, PPL=157.10
2025-09-25 01:58:27,223 - training.trainer - INFO - Epoch 31, Step 106372: Loss=5.2128, Acc=0.229, PPL=183.61
2025-09-25 01:58:34,736 - training.trainer - INFO - Epoch 31, Step 106472: Loss=5.0030, Acc=0.250, PPL=148.86
2025-09-25 01:58:42,184 - training.trainer - INFO - Epoch 31, Step 106572: Loss=6.3994, Acc=0.218, PPL=601.49
2025-09-25 01:58:49,713 - training.trainer - INFO - Epoch 31, Step 106672: Loss=5.3933, Acc=0.333, PPL=219.92
2025-09-25 01:58:57,303 - training.trainer - INFO - Epoch 31, Step 106772: Loss=5.8324, Acc=0.286, PPL=341.17
2025-09-25 01:59:04,756 - training.trainer - INFO - Epoch 31, Step 106872: Loss=5.8707, Acc=0.281, PPL=354.49
2025-09-25 01:59:12,126 - training.trainer - INFO - Epoch 31, Step 106972: Loss=5.6910, Acc=0.233, PPL=296.20
2025-09-25 01:59:19,400 - training.trainer - INFO - Epoch 31, Step 107072: Loss=6.5762, Acc=0.216, PPL=717.82
2025-09-25 01:59:26,809 - training.trainer - INFO - Epoch 31, Step 107172: Loss=4.5751, Acc=0.333, PPL=97.04
2025-09-25 01:59:34,211 - training.trainer - INFO - Epoch 31, Step 107272: Loss=5.6878, Acc=0.262, PPL=295.24
2025-09-25 01:59:41,969 - training.trainer - INFO - Epoch 31, Step 107372: Loss=5.7058, Acc=0.250, PPL=300.61
2025-09-25 01:59:49,224 - training.trainer - INFO - Epoch 31, Step 107472: Loss=5.9413, Acc=0.224, PPL=380.41
2025-09-25 01:59:56,614 - training.trainer - INFO - Epoch 31, Step 107572: Loss=5.8762, Acc=0.159, PPL=356.47
2025-09-25 02:00:04,050 - training.trainer - INFO - Epoch 31, Step 107672: Loss=6.1311, Acc=0.163, PPL=459.94
2025-09-25 02:00:11,930 - training.trainer - INFO - Epoch 31, Step 107772: Loss=5.3653, Acc=0.393, PPL=213.85
2025-09-25 02:00:19,610 - training.trainer - INFO - Epoch 31, Step 107872: Loss=3.9294, Acc=0.452, PPL=50.88
2025-09-25 02:00:27,395 - training.trainer - INFO - Epoch 31, Step 107972: Loss=5.6154, Acc=0.279, PPL=274.61
2025-09-25 02:00:34,809 - training.trainer - INFO - Epoch 31, Step 108072: Loss=5.6557, Acc=0.368, PPL=285.93
2025-09-25 02:00:42,228 - training.trainer - INFO - Epoch 31, Step 108172: Loss=5.2889, Acc=0.292, PPL=198.13
2025-09-25 02:01:01,416 - training.trainer - INFO - Epoch 32/100 completed in 265.09s - Train Loss: 5.4273, Train Acc: 0.290, Val Loss: 5.6330, Val Acc: 0.258
2025-09-25 02:01:02,144 - training.trainer - INFO - New best model saved with validation loss: 5.6330
2025-09-25 02:01:02,145 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_32.pt
2025-09-25 02:01:10,188 - training.trainer - INFO - Epoch 32, Step 108355: Loss=5.5223, Acc=0.265, PPL=250.21
2025-09-25 02:01:17,778 - training.trainer - INFO - Epoch 32, Step 108455: Loss=6.5469, Acc=0.188, PPL=697.06
2025-09-25 02:01:25,185 - training.trainer - INFO - Epoch 32, Step 108555: Loss=5.5251, Acc=0.292, PPL=250.91
2025-09-25 02:01:32,606 - training.trainer - INFO - Epoch 32, Step 108655: Loss=5.9817, Acc=0.260, PPL=396.12
2025-09-25 02:01:40,030 - training.trainer - INFO - Epoch 32, Step 108755: Loss=5.2394, Acc=0.289, PPL=188.56
2025-09-25 02:01:47,417 - training.trainer - INFO - Epoch 32, Step 108855: Loss=5.4004, Acc=0.333, PPL=221.49
2025-09-25 02:01:54,943 - training.trainer - INFO - Epoch 32, Step 108955: Loss=5.7006, Acc=0.212, PPL=299.03
2025-09-25 02:02:02,305 - training.trainer - INFO - Epoch 32, Step 109055: Loss=4.6256, Acc=0.333, PPL=102.07
2025-09-25 02:02:10,348 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.8830, Acc=0.210, PPL=358.88
2025-09-25 02:02:17,817 - training.trainer - INFO - Epoch 32, Step 109255: Loss=5.2094, Acc=0.289, PPL=182.98
2025-09-25 02:02:25,217 - training.trainer - INFO - Epoch 32, Step 109355: Loss=4.7146, Acc=0.286, PPL=111.57
2025-09-25 02:02:32,579 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.5200, Acc=0.340, PPL=249.63
2025-09-25 02:02:39,861 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.6786, Acc=0.278, PPL=292.55
2025-09-25 02:02:47,349 - training.trainer - INFO - Epoch 32, Step 109655: Loss=5.4399, Acc=0.292, PPL=230.42
2025-09-25 02:02:54,830 - training.trainer - INFO - Epoch 32, Step 109755: Loss=6.3976, Acc=0.125, PPL=600.40
2025-09-25 02:03:02,244 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.6338, Acc=0.277, PPL=279.73
2025-09-25 02:03:09,733 - training.trainer - INFO - Epoch 32, Step 109955: Loss=5.3368, Acc=0.210, PPL=207.84
2025-09-25 02:03:17,263 - training.trainer - INFO - Epoch 32, Step 110055: Loss=6.1292, Acc=0.245, PPL=459.08
2025-09-25 02:03:24,809 - training.trainer - INFO - Epoch 32, Step 110155: Loss=5.6523, Acc=0.188, PPL=284.96
2025-09-25 02:03:32,379 - training.trainer - INFO - Epoch 32, Step 110255: Loss=5.4452, Acc=0.243, PPL=231.64
2025-09-25 02:03:39,859 - training.trainer - INFO - Epoch 32, Step 110355: Loss=5.1059, Acc=0.217, PPL=164.99
2025-09-25 02:03:47,529 - training.trainer - INFO - Epoch 32, Step 110455: Loss=6.1664, Acc=0.113, PPL=476.47
2025-09-25 02:03:55,509 - training.trainer - INFO - Epoch 32, Step 110555: Loss=6.0790, Acc=0.269, PPL=436.57
2025-09-25 02:04:03,176 - training.trainer - INFO - Epoch 32, Step 110655: Loss=5.0912, Acc=0.400, PPL=162.59
2025-09-25 02:04:10,562 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.7314, Acc=0.320, PPL=308.40
2025-09-25 02:04:17,868 - training.trainer - INFO - Epoch 32, Step 110855: Loss=5.4531, Acc=0.234, PPL=233.49
2025-09-25 02:04:25,208 - training.trainer - INFO - Epoch 32, Step 110955: Loss=5.9817, Acc=0.292, PPL=396.13
2025-09-25 02:04:32,447 - training.trainer - INFO - Epoch 32, Step 111055: Loss=5.8315, Acc=0.216, PPL=340.87
2025-09-25 02:04:39,744 - training.trainer - INFO - Epoch 32, Step 111155: Loss=4.8157, Acc=0.441, PPL=123.43
2025-09-25 02:04:47,012 - training.trainer - INFO - Epoch 32, Step 111255: Loss=5.3535, Acc=0.241, PPL=211.35
2025-09-25 02:04:54,398 - training.trainer - INFO - Epoch 32, Step 111355: Loss=5.3379, Acc=0.364, PPL=208.07
2025-09-25 02:05:01,859 - training.trainer - INFO - Epoch 32, Step 111455: Loss=5.5607, Acc=0.256, PPL=260.01
2025-09-25 02:05:09,182 - training.trainer - INFO - Epoch 32, Step 111555: Loss=4.3024, Acc=0.400, PPL=73.88
2025-09-25 02:05:27,953 - training.trainer - INFO - Epoch 33/100 completed in 265.81s - Train Loss: 5.4057, Train Acc: 0.293, Val Loss: 5.6304, Val Acc: 0.260
2025-09-25 02:05:28,659 - training.trainer - INFO - New best model saved with validation loss: 5.6304
2025-09-25 02:05:28,659 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_33.pt
2025-09-25 02:05:36,151 - training.trainer - INFO - Epoch 33, Step 111738: Loss=5.3422, Acc=0.333, PPL=208.97
2025-09-25 02:05:43,654 - training.trainer - INFO - Epoch 33, Step 111838: Loss=4.7146, Acc=0.440, PPL=111.56
2025-09-25 02:05:51,132 - training.trainer - INFO - Epoch 33, Step 111938: Loss=6.0580, Acc=0.241, PPL=427.51
2025-09-25 02:05:58,531 - training.trainer - INFO - Epoch 33, Step 112038: Loss=4.9860, Acc=0.342, PPL=146.34
2025-09-25 02:06:06,010 - training.trainer - INFO - Epoch 33, Step 112138: Loss=4.9909, Acc=0.280, PPL=147.07
2025-09-25 02:06:13,618 - training.trainer - INFO - Epoch 33, Step 112238: Loss=5.1941, Acc=0.385, PPL=180.20
2025-09-25 02:06:21,132 - training.trainer - INFO - Epoch 33, Step 112338: Loss=4.3993, Acc=0.474, PPL=81.40
2025-09-25 02:06:28,688 - training.trainer - INFO - Epoch 33, Step 112438: Loss=5.4308, Acc=0.188, PPL=228.34
2025-09-25 02:06:35,334 - training.trainer - INFO - Epoch 33, Step 112538: Loss=4.5809, Acc=0.385, PPL=97.60
2025-09-25 02:06:41,647 - training.trainer - INFO - Epoch 33, Step 112638: Loss=5.7782, Acc=0.200, PPL=323.18
2025-09-25 02:06:48,508 - training.trainer - INFO - Epoch 33, Step 112738: Loss=5.1192, Acc=0.300, PPL=167.20
2025-09-25 02:06:55,969 - training.trainer - INFO - Epoch 33, Step 112838: Loss=4.6613, Acc=0.412, PPL=105.77
2025-09-25 02:07:03,413 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.6640, Acc=0.171, PPL=288.30
2025-09-25 02:07:10,957 - training.trainer - INFO - Epoch 33, Step 113038: Loss=4.0509, Acc=0.429, PPL=57.45
2025-09-25 02:07:18,733 - training.trainer - INFO - Epoch 33, Step 113138: Loss=6.1655, Acc=0.250, PPL=476.04
2025-09-25 02:07:26,263 - training.trainer - INFO - Epoch 33, Step 113238: Loss=4.7249, Acc=0.360, PPL=112.71
2025-09-25 02:07:34,451 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.3191, Acc=0.267, PPL=204.20
2025-09-25 02:07:41,901 - training.trainer - INFO - Epoch 33, Step 113438: Loss=4.5626, Acc=0.346, PPL=95.83
2025-09-25 02:07:49,291 - training.trainer - INFO - Epoch 33, Step 113538: Loss=4.2128, Acc=0.407, PPL=67.55
2025-09-25 02:07:56,740 - training.trainer - INFO - Epoch 33, Step 113638: Loss=6.0221, Acc=0.265, PPL=412.45
2025-09-25 02:08:04,550 - training.trainer - INFO - Epoch 33, Step 113738: Loss=6.1589, Acc=0.241, PPL=472.91
2025-09-25 02:08:12,004 - training.trainer - INFO - Epoch 33, Step 113838: Loss=4.6276, Acc=0.391, PPL=102.27
2025-09-25 02:08:19,378 - training.trainer - INFO - Epoch 33, Step 113938: Loss=5.4936, Acc=0.318, PPL=243.13
2025-09-25 02:08:26,823 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.0838, Acc=0.282, PPL=161.39
2025-09-25 02:08:34,184 - training.trainer - INFO - Epoch 33, Step 114138: Loss=4.7844, Acc=0.500, PPL=119.63
2025-09-25 02:08:41,598 - training.trainer - INFO - Epoch 33, Step 114238: Loss=5.0273, Acc=0.222, PPL=152.52
2025-09-25 02:08:49,412 - training.trainer - INFO - Epoch 33, Step 114338: Loss=6.0684, Acc=0.207, PPL=431.97
2025-09-25 02:08:56,787 - training.trainer - INFO - Epoch 33, Step 114438: Loss=6.3177, Acc=0.182, PPL=554.27
2025-09-25 02:09:04,121 - training.trainer - INFO - Epoch 33, Step 114538: Loss=5.9951, Acc=0.296, PPL=401.45
2025-09-25 02:09:11,405 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.6620, Acc=0.318, PPL=287.72
2025-09-25 02:09:18,828 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.7600, Acc=0.262, PPL=317.35
2025-09-25 02:09:26,089 - training.trainer - INFO - Epoch 33, Step 114838: Loss=5.1161, Acc=0.258, PPL=166.68
2025-09-25 02:09:33,422 - training.trainer - INFO - Epoch 33, Step 114938: Loss=6.5451, Acc=0.304, PPL=695.85
2025-09-25 02:09:52,245 - training.trainer - INFO - Epoch 34/100 completed in 263.59s - Train Loss: 5.3926, Train Acc: 0.296, Val Loss: 5.6316, Val Acc: 0.258
2025-09-25 02:09:58,748 - training.trainer - INFO - Epoch 34, Step 115121: Loss=4.3311, Acc=0.343, PPL=76.03
2025-09-25 02:10:05,195 - training.trainer - INFO - Epoch 34, Step 115221: Loss=3.8468, Acc=0.519, PPL=46.84
2025-09-25 02:10:11,328 - training.trainer - INFO - Epoch 34, Step 115321: Loss=5.9248, Acc=0.197, PPL=374.22
2025-09-25 02:10:17,528 - training.trainer - INFO - Epoch 34, Step 115421: Loss=5.5951, Acc=0.250, PPL=269.10
2025-09-25 02:10:23,883 - training.trainer - INFO - Epoch 34, Step 115521: Loss=5.3824, Acc=0.190, PPL=217.54
2025-09-25 02:10:30,074 - training.trainer - INFO - Epoch 34, Step 115621: Loss=6.2426, Acc=0.138, PPL=514.20
2025-09-25 02:10:36,279 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.7043, Acc=0.240, PPL=300.15
2025-09-25 02:10:42,360 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.7712, Acc=0.278, PPL=320.91
2025-09-25 02:10:48,621 - training.trainer - INFO - Epoch 34, Step 115921: Loss=5.2166, Acc=0.295, PPL=184.31
2025-09-25 02:10:54,862 - training.trainer - INFO - Epoch 34, Step 116021: Loss=5.3537, Acc=0.239, PPL=211.39
2025-09-25 02:11:00,949 - training.trainer - INFO - Epoch 34, Step 116121: Loss=4.8918, Acc=0.244, PPL=133.19
2025-09-25 02:11:07,696 - training.trainer - INFO - Epoch 34, Step 116221: Loss=5.5889, Acc=0.324, PPL=267.44
2025-09-25 02:11:14,872 - training.trainer - INFO - Epoch 34, Step 116321: Loss=4.4051, Acc=0.267, PPL=81.86
2025-09-25 02:11:22,058 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.2125, Acc=0.311, PPL=183.55
2025-09-25 02:11:29,791 - training.trainer - INFO - Epoch 34, Step 116521: Loss=5.9505, Acc=0.194, PPL=383.96
2025-09-25 02:11:37,050 - training.trainer - INFO - Epoch 34, Step 116621: Loss=5.2744, Acc=0.154, PPL=195.28
2025-09-25 02:11:44,428 - training.trainer - INFO - Epoch 34, Step 116721: Loss=6.4255, Acc=0.148, PPL=617.37
2025-09-25 02:11:51,663 - training.trainer - INFO - Epoch 34, Step 116821: Loss=4.9686, Acc=0.390, PPL=143.82
2025-09-25 02:11:58,863 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.4846, Acc=0.217, PPL=240.94
2025-09-25 02:12:06,131 - training.trainer - INFO - Epoch 34, Step 117021: Loss=6.3503, Acc=0.182, PPL=572.65
2025-09-25 02:12:13,472 - training.trainer - INFO - Epoch 34, Step 117121: Loss=5.0285, Acc=0.286, PPL=152.71
2025-09-25 02:12:20,943 - training.trainer - INFO - Epoch 34, Step 117221: Loss=6.7021, Acc=0.118, PPL=814.08
2025-09-25 02:12:28,284 - training.trainer - INFO - Epoch 34, Step 117321: Loss=6.3183, Acc=0.118, PPL=554.64
2025-09-25 02:12:35,673 - training.trainer - INFO - Epoch 34, Step 117421: Loss=6.2649, Acc=0.241, PPL=525.80
2025-09-25 02:12:42,904 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.9361, Acc=0.254, PPL=378.46
2025-09-25 02:12:50,292 - training.trainer - INFO - Epoch 34, Step 117621: Loss=4.9017, Acc=0.333, PPL=134.52
2025-09-25 02:12:58,042 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.0539, Acc=0.467, PPL=156.64
2025-09-25 02:13:05,851 - training.trainer - INFO - Epoch 34, Step 117821: Loss=5.3480, Acc=0.316, PPL=210.19
2025-09-25 02:13:13,438 - training.trainer - INFO - Epoch 34, Step 117921: Loss=5.3263, Acc=0.273, PPL=205.67
2025-09-25 02:13:21,141 - training.trainer - INFO - Epoch 34, Step 118021: Loss=5.2779, Acc=0.344, PPL=195.96
2025-09-25 02:13:28,668 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.6412, Acc=0.279, PPL=281.80
2025-09-25 02:13:36,046 - training.trainer - INFO - Epoch 34, Step 118221: Loss=4.8449, Acc=0.350, PPL=127.09
2025-09-25 02:13:43,351 - training.trainer - INFO - Epoch 34, Step 118321: Loss=5.7082, Acc=0.268, PPL=301.31
2025-09-25 02:14:02,419 - training.trainer - INFO - Epoch 35/100 completed in 250.17s - Train Loss: 5.3751, Train Acc: 0.299, Val Loss: 5.6265, Val Acc: 0.261
2025-09-25 02:14:02,861 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-25 02:14:03,761 - training.trainer - INFO - New best model saved with validation loss: 5.6265
2025-09-25 02:14:03,762 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-25 02:14:11,730 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.8680, Acc=0.286, PPL=353.54
2025-09-25 02:14:19,139 - training.trainer - INFO - Epoch 35, Step 118604: Loss=6.1102, Acc=0.214, PPL=450.45
2025-09-25 02:14:26,601 - training.trainer - INFO - Epoch 35, Step 118704: Loss=4.9862, Acc=0.367, PPL=146.38
2025-09-25 02:14:34,055 - training.trainer - INFO - Epoch 35, Step 118804: Loss=6.0016, Acc=0.333, PPL=404.08
2025-09-25 02:14:41,276 - training.trainer - INFO - Epoch 35, Step 118904: Loss=5.4882, Acc=0.300, PPL=241.82
2025-09-25 02:14:48,624 - training.trainer - INFO - Epoch 35, Step 119004: Loss=6.0268, Acc=0.192, PPL=414.39
2025-09-25 02:14:56,134 - training.trainer - INFO - Epoch 35, Step 119104: Loss=3.8932, Acc=0.524, PPL=49.07
2025-09-25 02:15:03,403 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.1074, Acc=0.359, PPL=165.25
2025-09-25 02:15:10,641 - training.trainer - INFO - Epoch 35, Step 119304: Loss=5.0228, Acc=0.353, PPL=151.84
2025-09-25 02:15:17,918 - training.trainer - INFO - Epoch 35, Step 119404: Loss=4.5097, Acc=0.500, PPL=90.89
2025-09-25 02:15:25,119 - training.trainer - INFO - Epoch 35, Step 119504: Loss=3.2996, Acc=0.611, PPL=27.10
2025-09-25 02:15:32,440 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.6550, Acc=0.241, PPL=285.72
2025-09-25 02:15:39,648 - training.trainer - INFO - Epoch 35, Step 119704: Loss=6.4597, Acc=0.177, PPL=638.86
2025-09-25 02:15:47,365 - training.trainer - INFO - Epoch 35, Step 119804: Loss=5.4424, Acc=0.296, PPL=230.99
2025-09-25 02:15:54,565 - training.trainer - INFO - Epoch 35, Step 119904: Loss=5.7881, Acc=0.276, PPL=326.39
2025-09-25 02:16:01,895 - training.trainer - INFO - Epoch 35, Step 120004: Loss=5.6150, Acc=0.258, PPL=274.51
2025-09-25 02:16:09,171 - training.trainer - INFO - Epoch 35, Step 120104: Loss=2.8160, Acc=0.622, PPL=16.71
2025-09-25 02:16:16,412 - training.trainer - INFO - Epoch 35, Step 120204: Loss=4.7220, Acc=0.455, PPL=112.40
2025-09-25 02:16:23,720 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.8836, Acc=0.241, PPL=359.11
2025-09-25 02:16:30,937 - training.trainer - INFO - Epoch 35, Step 120404: Loss=5.9939, Acc=0.212, PPL=400.97
2025-09-25 02:16:38,283 - training.trainer - INFO - Epoch 35, Step 120504: Loss=5.1140, Acc=0.317, PPL=166.33
2025-09-25 02:16:46,056 - training.trainer - INFO - Epoch 35, Step 120604: Loss=5.4049, Acc=0.111, PPL=222.50
2025-09-25 02:16:53,268 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.6879, Acc=0.182, PPL=295.28
2025-09-25 02:17:00,580 - training.trainer - INFO - Epoch 35, Step 120804: Loss=5.0411, Acc=0.353, PPL=154.65
2025-09-25 02:17:08,008 - training.trainer - INFO - Epoch 35, Step 120904: Loss=5.9280, Acc=0.211, PPL=375.42
2025-09-25 02:17:15,243 - training.trainer - INFO - Epoch 35, Step 121004: Loss=4.9736, Acc=0.400, PPL=144.54
2025-09-25 02:17:22,519 - training.trainer - INFO - Epoch 35, Step 121104: Loss=3.5274, Acc=0.513, PPL=34.04
2025-09-25 02:17:29,867 - training.trainer - INFO - Epoch 35, Step 121204: Loss=5.4594, Acc=0.302, PPL=234.96
2025-09-25 02:17:37,145 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.8610, Acc=0.224, PPL=351.09
2025-09-25 02:17:44,568 - training.trainer - INFO - Epoch 35, Step 121404: Loss=4.4549, Acc=0.455, PPL=86.05
2025-09-25 02:17:51,793 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.6934, Acc=0.273, PPL=296.91
2025-09-25 02:17:59,000 - training.trainer - INFO - Epoch 35, Step 121604: Loss=5.7359, Acc=0.222, PPL=309.78
2025-09-25 02:18:06,315 - training.trainer - INFO - Epoch 35, Step 121704: Loss=5.5468, Acc=0.289, PPL=256.41
2025-09-25 02:18:25,762 - training.trainer - INFO - Epoch 36/100 completed in 262.00s - Train Loss: 5.3587, Train Acc: 0.300, Val Loss: 5.6319, Val Acc: 0.261
2025-09-25 02:18:32,259 - training.trainer - INFO - Epoch 36, Step 121887: Loss=5.6826, Acc=0.245, PPL=293.70
2025-09-25 02:18:38,435 - training.trainer - INFO - Epoch 36, Step 121987: Loss=4.8406, Acc=0.317, PPL=126.54
2025-09-25 02:18:44,700 - training.trainer - INFO - Epoch 36, Step 122087: Loss=4.7867, Acc=0.400, PPL=119.90
2025-09-25 02:18:51,102 - training.trainer - INFO - Epoch 36, Step 122187: Loss=6.0446, Acc=0.241, PPL=421.84
2025-09-25 02:18:58,362 - training.trainer - INFO - Epoch 36, Step 122287: Loss=5.3557, Acc=0.312, PPL=211.81
2025-09-25 02:19:05,644 - training.trainer - INFO - Epoch 36, Step 122387: Loss=5.8315, Acc=0.278, PPL=340.87
2025-09-25 02:19:12,970 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.6926, Acc=0.185, PPL=296.68
2025-09-25 02:19:20,390 - training.trainer - INFO - Epoch 36, Step 122587: Loss=4.9963, Acc=0.382, PPL=147.86
2025-09-25 02:19:27,664 - training.trainer - INFO - Epoch 36, Step 122687: Loss=6.5543, Acc=0.134, PPL=702.25
2025-09-25 02:19:34,891 - training.trainer - INFO - Epoch 36, Step 122787: Loss=6.2661, Acc=0.164, PPL=526.42
2025-09-25 02:19:42,131 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.2118, Acc=0.393, PPL=183.43
2025-09-25 02:19:50,086 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.4161, Acc=0.247, PPL=225.00
2025-09-25 02:19:57,617 - training.trainer - INFO - Epoch 36, Step 123087: Loss=5.9790, Acc=0.187, PPL=395.05
2025-09-25 02:20:04,878 - training.trainer - INFO - Epoch 36, Step 123187: Loss=5.7345, Acc=0.229, PPL=309.36
2025-09-25 02:20:12,436 - training.trainer - INFO - Epoch 36, Step 123287: Loss=5.1959, Acc=0.314, PPL=180.53
2025-09-25 02:20:19,578 - training.trainer - INFO - Epoch 36, Step 123387: Loss=6.4907, Acc=0.255, PPL=658.99
2025-09-25 02:20:26,850 - training.trainer - INFO - Epoch 36, Step 123487: Loss=5.7665, Acc=0.284, PPL=319.43
2025-09-25 02:20:34,069 - training.trainer - INFO - Epoch 36, Step 123587: Loss=5.4321, Acc=0.185, PPL=228.63
2025-09-25 02:20:41,283 - training.trainer - INFO - Epoch 36, Step 123687: Loss=5.3898, Acc=0.333, PPL=219.16
2025-09-25 02:20:48,635 - training.trainer - INFO - Epoch 36, Step 123787: Loss=4.3053, Acc=0.364, PPL=74.09
2025-09-25 02:20:55,993 - training.trainer - INFO - Epoch 36, Step 123887: Loss=4.9485, Acc=0.296, PPL=140.97
2025-09-25 02:21:03,177 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.2559, Acc=0.371, PPL=191.69
2025-09-25 02:21:10,400 - training.trainer - INFO - Epoch 36, Step 124087: Loss=6.2860, Acc=0.250, PPL=536.99
2025-09-25 02:21:17,723 - training.trainer - INFO - Epoch 36, Step 124187: Loss=5.3059, Acc=0.194, PPL=201.53
2025-09-25 02:21:25,083 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.0538, Acc=0.250, PPL=156.61
2025-09-25 02:21:32,411 - training.trainer - INFO - Epoch 36, Step 124387: Loss=5.4540, Acc=0.222, PPL=233.69
2025-09-25 02:21:39,689 - training.trainer - INFO - Epoch 36, Step 124487: Loss=5.7660, Acc=0.455, PPL=319.27
2025-09-25 02:21:47,815 - training.trainer - INFO - Epoch 36, Step 124587: Loss=5.7996, Acc=0.225, PPL=330.17
2025-09-25 02:21:55,263 - training.trainer - INFO - Epoch 36, Step 124687: Loss=5.6888, Acc=0.279, PPL=295.55
2025-09-25 02:22:02,684 - training.trainer - INFO - Epoch 36, Step 124787: Loss=3.7864, Acc=0.435, PPL=44.10
2025-09-25 02:22:10,058 - training.trainer - INFO - Epoch 36, Step 124887: Loss=5.1397, Acc=0.318, PPL=170.67
2025-09-25 02:22:17,390 - training.trainer - INFO - Epoch 36, Step 124987: Loss=4.1243, Acc=0.429, PPL=61.82
2025-09-25 02:22:24,782 - training.trainer - INFO - Epoch 36, Step 125087: Loss=5.8105, Acc=0.250, PPL=333.79
2025-09-25 02:22:43,864 - training.trainer - INFO - Epoch 37/100 completed in 258.10s - Train Loss: 5.3470, Train Acc: 0.303, Val Loss: 5.6248, Val Acc: 0.260
2025-09-25 02:22:44,493 - training.trainer - INFO - New best model saved with validation loss: 5.6248
2025-09-25 02:22:44,494 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_37.pt
2025-09-25 02:22:52,180 - training.trainer - INFO - Epoch 37, Step 125270: Loss=5.2551, Acc=0.296, PPL=191.54
2025-09-25 02:22:59,479 - training.trainer - INFO - Epoch 37, Step 125370: Loss=6.1223, Acc=0.206, PPL=455.93
2025-09-25 02:23:06,743 - training.trainer - INFO - Epoch 37, Step 125470: Loss=5.7357, Acc=0.333, PPL=309.72
2025-09-25 02:23:14,233 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.7074, Acc=0.312, PPL=301.07
2025-09-25 02:23:21,502 - training.trainer - INFO - Epoch 37, Step 125670: Loss=5.1959, Acc=0.345, PPL=180.53
2025-09-25 02:23:28,713 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.6056, Acc=0.254, PPL=271.96
2025-09-25 02:23:35,912 - training.trainer - INFO - Epoch 37, Step 125870: Loss=4.8195, Acc=0.302, PPL=123.90
2025-09-25 02:23:43,170 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.9345, Acc=0.242, PPL=377.86
2025-09-25 02:23:50,540 - training.trainer - INFO - Epoch 37, Step 126070: Loss=4.6949, Acc=0.292, PPL=109.39
2025-09-25 02:23:57,708 - training.trainer - INFO - Epoch 37, Step 126170: Loss=6.0286, Acc=0.235, PPL=415.11
2025-09-25 02:24:05,197 - training.trainer - INFO - Epoch 37, Step 126270: Loss=4.2051, Acc=0.353, PPL=67.03
2025-09-25 02:24:12,426 - training.trainer - INFO - Epoch 37, Step 126370: Loss=5.2645, Acc=0.308, PPL=193.35
2025-09-25 02:24:19,780 - training.trainer - INFO - Epoch 37, Step 126470: Loss=4.9387, Acc=0.333, PPL=139.59
2025-09-25 02:24:27,145 - training.trainer - INFO - Epoch 37, Step 126570: Loss=6.0683, Acc=0.250, PPL=431.95
2025-09-25 02:24:34,730 - training.trainer - INFO - Epoch 37, Step 126670: Loss=5.5841, Acc=0.294, PPL=266.15
2025-09-25 02:24:42,387 - training.trainer - INFO - Epoch 37, Step 126770: Loss=5.9405, Acc=0.298, PPL=380.14
2025-09-25 02:24:49,692 - training.trainer - INFO - Epoch 37, Step 126870: Loss=5.3807, Acc=0.200, PPL=217.17
2025-09-25 02:24:56,901 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.9498, Acc=0.190, PPL=383.66
2025-09-25 02:25:04,152 - training.trainer - INFO - Epoch 37, Step 127070: Loss=4.1142, Acc=0.286, PPL=61.20
2025-09-25 02:25:11,443 - training.trainer - INFO - Epoch 37, Step 127170: Loss=5.4818, Acc=0.370, PPL=240.28
2025-09-25 02:25:18,803 - training.trainer - INFO - Epoch 37, Step 127270: Loss=6.1227, Acc=0.235, PPL=456.07
2025-09-25 02:25:26,253 - training.trainer - INFO - Epoch 37, Step 127370: Loss=4.9928, Acc=0.293, PPL=147.35
2025-09-25 02:25:33,543 - training.trainer - INFO - Epoch 37, Step 127470: Loss=5.9150, Acc=0.271, PPL=370.55
2025-09-25 02:25:40,865 - training.trainer - INFO - Epoch 37, Step 127570: Loss=5.0542, Acc=0.250, PPL=156.68
2025-09-25 02:25:48,328 - training.trainer - INFO - Epoch 37, Step 127670: Loss=4.7984, Acc=0.348, PPL=121.31
2025-09-25 02:25:56,159 - training.trainer - INFO - Epoch 37, Step 127770: Loss=4.7616, Acc=0.458, PPL=116.94
2025-09-25 02:26:03,411 - training.trainer - INFO - Epoch 37, Step 127870: Loss=2.3308, Acc=0.700, PPL=10.29
2025-09-25 02:26:10,655 - training.trainer - INFO - Epoch 37, Step 127970: Loss=4.9096, Acc=0.300, PPL=135.58
2025-09-25 02:26:17,919 - training.trainer - INFO - Epoch 37, Step 128070: Loss=6.3414, Acc=0.205, PPL=567.59
2025-09-25 02:26:25,282 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.6201, Acc=0.298, PPL=275.91
2025-09-25 02:26:32,665 - training.trainer - INFO - Epoch 37, Step 128270: Loss=6.2801, Acc=0.200, PPL=533.85
2025-09-25 02:26:40,176 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.4461, Acc=0.242, PPL=231.85
2025-09-25 02:26:47,826 - training.trainer - INFO - Epoch 37, Step 128470: Loss=5.6535, Acc=0.267, PPL=285.30
2025-09-25 02:27:07,191 - training.trainer - INFO - Epoch 38/100 completed in 262.70s - Train Loss: 5.3225, Train Acc: 0.307, Val Loss: 5.6260, Val Acc: 0.264
2025-09-25 02:27:15,316 - training.trainer - INFO - Epoch 38, Step 128653: Loss=5.2714, Acc=0.233, PPL=194.70
2025-09-25 02:27:22,841 - training.trainer - INFO - Epoch 38, Step 128753: Loss=5.7150, Acc=0.212, PPL=303.39
2025-09-25 02:27:30,616 - training.trainer - INFO - Epoch 38, Step 128853: Loss=5.3120, Acc=0.312, PPL=202.75
2025-09-25 02:27:37,963 - training.trainer - INFO - Epoch 38, Step 128953: Loss=5.0323, Acc=0.361, PPL=153.28
2025-09-25 02:27:45,388 - training.trainer - INFO - Epoch 38, Step 129053: Loss=5.1854, Acc=0.290, PPL=178.64
2025-09-25 02:27:52,883 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.3401, Acc=0.310, PPL=208.54
2025-09-25 02:28:00,721 - training.trainer - INFO - Epoch 38, Step 129253: Loss=5.9802, Acc=0.190, PPL=395.52
2025-09-25 02:28:08,338 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.3059, Acc=0.310, PPL=201.52
2025-09-25 02:28:15,919 - training.trainer - INFO - Epoch 38, Step 129453: Loss=5.1272, Acc=0.406, PPL=168.54
2025-09-25 02:28:23,512 - training.trainer - INFO - Epoch 38, Step 129553: Loss=6.0806, Acc=0.225, PPL=437.31
2025-09-25 02:28:30,983 - training.trainer - INFO - Epoch 38, Step 129653: Loss=6.1331, Acc=0.245, PPL=460.86
2025-09-25 02:28:38,519 - training.trainer - INFO - Epoch 38, Step 129753: Loss=5.0124, Acc=0.333, PPL=150.26
2025-09-25 02:28:45,988 - training.trainer - INFO - Epoch 38, Step 129853: Loss=4.1116, Acc=0.438, PPL=61.05
2025-09-25 02:28:53,336 - training.trainer - INFO - Epoch 38, Step 129953: Loss=5.8664, Acc=0.348, PPL=352.99
2025-09-25 02:29:00,803 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.5203, Acc=0.304, PPL=249.71
2025-09-25 02:29:08,321 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.5880, Acc=0.275, PPL=267.19
2025-09-25 02:29:15,919 - training.trainer - INFO - Epoch 38, Step 130253: Loss=6.4442, Acc=0.183, PPL=629.03
2025-09-25 02:29:23,303 - training.trainer - INFO - Epoch 38, Step 130353: Loss=3.6256, Acc=0.500, PPL=37.55
2025-09-25 02:29:30,921 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.4402, Acc=0.177, PPL=230.49
2025-09-25 02:29:38,477 - training.trainer - INFO - Epoch 38, Step 130553: Loss=4.6886, Acc=0.310, PPL=108.70
2025-09-25 02:29:45,943 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.7480, Acc=0.200, PPL=313.55
2025-09-25 02:29:53,365 - training.trainer - INFO - Epoch 38, Step 130753: Loss=5.6504, Acc=0.414, PPL=284.42
2025-09-25 02:30:00,875 - training.trainer - INFO - Epoch 38, Step 130853: Loss=5.1106, Acc=0.296, PPL=165.76
2025-09-25 02:30:08,252 - training.trainer - INFO - Epoch 38, Step 130953: Loss=5.6496, Acc=0.327, PPL=284.19
2025-09-25 02:30:15,760 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.6241, Acc=0.316, PPL=277.01
2025-09-25 02:30:23,312 - training.trainer - INFO - Epoch 38, Step 131153: Loss=3.9583, Acc=0.500, PPL=52.37
2025-09-25 02:30:30,884 - training.trainer - INFO - Epoch 38, Step 131253: Loss=6.4409, Acc=0.212, PPL=626.98
2025-09-25 02:30:38,483 - training.trainer - INFO - Epoch 38, Step 131353: Loss=5.9519, Acc=0.295, PPL=384.48
2025-09-25 02:30:45,993 - training.trainer - INFO - Epoch 38, Step 131453: Loss=6.0153, Acc=0.246, PPL=409.65
2025-09-25 02:30:53,322 - training.trainer - INFO - Epoch 38, Step 131553: Loss=5.5778, Acc=0.121, PPL=264.50
2025-09-25 02:31:00,661 - training.trainer - INFO - Epoch 38, Step 131653: Loss=5.6370, Acc=0.280, PPL=280.61
2025-09-25 02:31:08,115 - training.trainer - INFO - Epoch 38, Step 131753: Loss=5.6527, Acc=0.218, PPL=285.07
2025-09-25 02:31:15,626 - training.trainer - INFO - Epoch 38, Step 131853: Loss=6.4844, Acc=0.208, PPL=654.88
2025-09-25 02:31:34,428 - training.trainer - INFO - Epoch 39/100 completed in 267.24s - Train Loss: 5.3113, Train Acc: 0.306, Val Loss: 5.6412, Val Acc: 0.262
2025-09-25 02:31:42,348 - training.trainer - INFO - Epoch 39, Step 132036: Loss=6.2585, Acc=0.225, PPL=522.42
2025-09-25 02:31:49,707 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.5797, Acc=0.273, PPL=264.98
2025-09-25 02:31:57,167 - training.trainer - INFO - Epoch 39, Step 132236: Loss=5.0462, Acc=0.538, PPL=155.44
2025-09-25 02:32:04,516 - training.trainer - INFO - Epoch 39, Step 132336: Loss=5.2793, Acc=0.226, PPL=196.23
2025-09-25 02:32:11,989 - training.trainer - INFO - Epoch 39, Step 132436: Loss=6.2094, Acc=0.255, PPL=497.39
2025-09-25 02:32:19,317 - training.trainer - INFO - Epoch 39, Step 132536: Loss=4.4578, Acc=0.425, PPL=86.30
2025-09-25 02:32:26,689 - training.trainer - INFO - Epoch 39, Step 132636: Loss=5.4114, Acc=0.242, PPL=223.95
2025-09-25 02:32:34,005 - training.trainer - INFO - Epoch 39, Step 132736: Loss=5.9045, Acc=0.250, PPL=366.69
2025-09-25 02:32:41,550 - training.trainer - INFO - Epoch 39, Step 132836: Loss=5.7378, Acc=0.210, PPL=310.40
2025-09-25 02:32:49,058 - training.trainer - INFO - Epoch 39, Step 132936: Loss=6.1063, Acc=0.275, PPL=448.66
2025-09-25 02:32:56,473 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.4663, Acc=0.254, PPL=236.59
2025-09-25 02:33:04,010 - training.trainer - INFO - Epoch 39, Step 133136: Loss=5.0199, Acc=0.378, PPL=151.40
2025-09-25 02:33:11,373 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.2292, Acc=0.320, PPL=186.64
2025-09-25 02:33:18,997 - training.trainer - INFO - Epoch 39, Step 133336: Loss=5.7624, Acc=0.300, PPL=318.11
2025-09-25 02:33:26,481 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.1377, Acc=0.298, PPL=170.32
2025-09-25 02:33:34,398 - training.trainer - INFO - Epoch 39, Step 133536: Loss=3.8017, Acc=0.562, PPL=44.78
2025-09-25 02:33:41,829 - training.trainer - INFO - Epoch 39, Step 133636: Loss=5.2187, Acc=0.357, PPL=184.70
2025-09-25 02:33:49,282 - training.trainer - INFO - Epoch 39, Step 133736: Loss=6.5786, Acc=0.163, PPL=719.53
2025-09-25 02:33:56,816 - training.trainer - INFO - Epoch 39, Step 133836: Loss=6.5623, Acc=0.257, PPL=707.93
2025-09-25 02:34:04,468 - training.trainer - INFO - Epoch 39, Step 133936: Loss=5.4899, Acc=0.255, PPL=242.24
2025-09-25 02:34:12,218 - training.trainer - INFO - Epoch 39, Step 134036: Loss=5.0031, Acc=0.231, PPL=148.87
2025-09-25 02:34:19,543 - training.trainer - INFO - Epoch 39, Step 134136: Loss=6.2854, Acc=0.190, PPL=536.69
2025-09-25 02:34:26,940 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.1992, Acc=0.247, PPL=181.13
2025-09-25 02:34:34,258 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.6736, Acc=0.250, PPL=291.08
2025-09-25 02:34:41,673 - training.trainer - INFO - Epoch 39, Step 134436: Loss=4.7496, Acc=0.306, PPL=115.53
2025-09-25 02:34:48,995 - training.trainer - INFO - Epoch 39, Step 134536: Loss=4.9402, Acc=0.318, PPL=139.80
2025-09-25 02:34:56,396 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.4338, Acc=0.327, PPL=229.03
2025-09-25 02:35:03,696 - training.trainer - INFO - Epoch 39, Step 134736: Loss=6.0713, Acc=0.253, PPL=433.24
2025-09-25 02:35:11,060 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.5609, Acc=0.200, PPL=260.05
2025-09-25 02:35:18,340 - training.trainer - INFO - Epoch 39, Step 134936: Loss=6.2578, Acc=0.217, PPL=522.08
2025-09-25 02:35:25,818 - training.trainer - INFO - Epoch 39, Step 135036: Loss=5.7923, Acc=0.157, PPL=327.78
2025-09-25 02:35:33,408 - training.trainer - INFO - Epoch 39, Step 135136: Loss=5.6292, Acc=0.333, PPL=278.44
2025-09-25 02:35:40,874 - training.trainer - INFO - Epoch 39, Step 135236: Loss=4.9850, Acc=0.364, PPL=146.21
2025-09-25 02:35:59,630 - training.trainer - INFO - Epoch 40/100 completed in 265.20s - Train Loss: 5.2987, Train Acc: 0.311, Val Loss: 5.6449, Val Acc: 0.263
2025-09-25 02:36:00,004 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-25 02:36:07,880 - training.trainer - INFO - Epoch 40, Step 135419: Loss=5.9381, Acc=0.295, PPL=379.22
2025-09-25 02:36:15,747 - training.trainer - INFO - Epoch 40, Step 135519: Loss=4.3127, Acc=0.421, PPL=74.64
2025-09-25 02:36:23,187 - training.trainer - INFO - Epoch 40, Step 135619: Loss=6.0517, Acc=0.203, PPL=424.85
2025-09-25 02:36:30,610 - training.trainer - INFO - Epoch 40, Step 135719: Loss=5.2252, Acc=0.261, PPL=185.89
2025-09-25 02:36:38,356 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.5062, Acc=0.294, PPL=246.22
2025-09-25 02:36:45,755 - training.trainer - INFO - Epoch 40, Step 135919: Loss=4.9872, Acc=0.429, PPL=146.53
2025-09-25 02:36:53,257 - training.trainer - INFO - Epoch 40, Step 136019: Loss=5.5043, Acc=0.317, PPL=245.76
2025-09-25 02:37:00,761 - training.trainer - INFO - Epoch 40, Step 136119: Loss=5.8415, Acc=0.186, PPL=344.29
2025-09-25 02:37:08,367 - training.trainer - INFO - Epoch 40, Step 136219: Loss=4.8837, Acc=0.300, PPL=132.12
2025-09-25 02:37:15,864 - training.trainer - INFO - Epoch 40, Step 136319: Loss=5.2254, Acc=0.308, PPL=185.94
2025-09-25 02:37:23,259 - training.trainer - INFO - Epoch 40, Step 136419: Loss=5.4598, Acc=0.263, PPL=235.05
2025-09-25 02:37:31,000 - training.trainer - INFO - Epoch 40, Step 136519: Loss=5.7887, Acc=0.238, PPL=326.59
2025-09-25 02:37:38,330 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.7565, Acc=0.161, PPL=316.25
2025-09-25 02:37:45,588 - training.trainer - INFO - Epoch 40, Step 136719: Loss=5.3182, Acc=0.278, PPL=204.01
2025-09-25 02:37:53,526 - training.trainer - INFO - Epoch 40, Step 136819: Loss=5.3856, Acc=0.345, PPL=218.25
2025-09-25 02:38:00,960 - training.trainer - INFO - Epoch 40, Step 136919: Loss=4.8726, Acc=0.279, PPL=130.66
2025-09-25 02:38:08,290 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.5996, Acc=0.268, PPL=270.32
2025-09-25 02:38:16,308 - training.trainer - INFO - Epoch 40, Step 137119: Loss=5.0855, Acc=0.314, PPL=161.66
2025-09-25 02:38:23,611 - training.trainer - INFO - Epoch 40, Step 137219: Loss=7.1731, Acc=0.132, PPL=1303.86
2025-09-25 02:38:30,927 - training.trainer - INFO - Epoch 40, Step 137319: Loss=4.8671, Acc=0.286, PPL=129.94
2025-09-25 02:38:38,235 - training.trainer - INFO - Epoch 40, Step 137419: Loss=5.9613, Acc=0.310, PPL=388.13
2025-09-25 02:38:45,481 - training.trainer - INFO - Epoch 40, Step 137519: Loss=5.5067, Acc=0.271, PPL=246.34
2025-09-25 02:38:52,780 - training.trainer - INFO - Epoch 40, Step 137619: Loss=6.1735, Acc=0.192, PPL=479.87
2025-09-25 02:39:00,067 - training.trainer - INFO - Epoch 40, Step 137719: Loss=4.8614, Acc=0.524, PPL=129.21
2025-09-25 02:39:07,292 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.3158, Acc=0.286, PPL=203.54
2025-09-25 02:39:14,514 - training.trainer - INFO - Epoch 40, Step 137919: Loss=5.4970, Acc=0.438, PPL=243.96
2025-09-25 02:39:21,788 - training.trainer - INFO - Epoch 40, Step 138019: Loss=3.5141, Acc=0.550, PPL=33.59
2025-09-25 02:39:29,092 - training.trainer - INFO - Epoch 40, Step 138119: Loss=5.2519, Acc=0.220, PPL=190.92
2025-09-25 02:39:36,462 - training.trainer - INFO - Epoch 40, Step 138219: Loss=4.7136, Acc=0.344, PPL=111.46
2025-09-25 02:39:43,676 - training.trainer - INFO - Epoch 40, Step 138319: Loss=5.1364, Acc=0.324, PPL=170.10
2025-09-25 02:39:50,979 - training.trainer - INFO - Epoch 40, Step 138419: Loss=5.9952, Acc=0.212, PPL=401.50
2025-09-25 02:39:58,270 - training.trainer - INFO - Epoch 40, Step 138519: Loss=5.3400, Acc=0.333, PPL=208.51
2025-09-25 02:40:05,632 - training.trainer - INFO - Epoch 40, Step 138619: Loss=5.9187, Acc=0.264, PPL=371.94
2025-09-25 02:40:25,498 - training.trainer - INFO - Epoch 41/100 completed in 265.49s - Train Loss: 5.2871, Train Acc: 0.313, Val Loss: 5.6492, Val Acc: 0.263
2025-09-25 02:40:31,970 - training.trainer - INFO - Epoch 41, Step 138802: Loss=5.5358, Acc=0.279, PPL=253.62
2025-09-25 02:40:38,243 - training.trainer - INFO - Epoch 41, Step 138902: Loss=5.5021, Acc=0.367, PPL=245.20
2025-09-25 02:40:44,661 - training.trainer - INFO - Epoch 41, Step 139002: Loss=5.6040, Acc=0.283, PPL=271.50
2025-09-25 02:40:50,829 - training.trainer - INFO - Epoch 41, Step 139102: Loss=6.0072, Acc=0.276, PPL=406.34
2025-09-25 02:40:57,983 - training.trainer - INFO - Epoch 41, Step 139202: Loss=5.5202, Acc=0.367, PPL=249.68
2025-09-25 02:41:05,279 - training.trainer - INFO - Epoch 41, Step 139302: Loss=3.7056, Acc=0.536, PPL=40.68
2025-09-25 02:41:12,923 - training.trainer - INFO - Epoch 41, Step 139402: Loss=5.2692, Acc=0.243, PPL=194.26
2025-09-25 02:41:20,721 - training.trainer - INFO - Epoch 41, Step 139502: Loss=5.5776, Acc=0.289, PPL=264.43
2025-09-25 02:41:28,171 - training.trainer - INFO - Epoch 41, Step 139602: Loss=6.1138, Acc=0.242, PPL=452.07
2025-09-25 02:41:35,699 - training.trainer - INFO - Epoch 41, Step 139702: Loss=4.2225, Acc=0.421, PPL=68.21
2025-09-25 02:41:43,250 - training.trainer - INFO - Epoch 41, Step 139802: Loss=5.4535, Acc=0.300, PPL=233.58
2025-09-25 02:41:50,683 - training.trainer - INFO - Epoch 41, Step 139902: Loss=5.3043, Acc=0.324, PPL=201.19
2025-09-25 02:41:58,187 - training.trainer - INFO - Epoch 41, Step 140002: Loss=3.7796, Acc=0.500, PPL=43.80
2025-09-25 02:42:05,969 - training.trainer - INFO - Epoch 41, Step 140102: Loss=5.2177, Acc=0.225, PPL=184.51
2025-09-25 02:42:13,420 - training.trainer - INFO - Epoch 41, Step 140202: Loss=5.1415, Acc=0.356, PPL=170.97
2025-09-25 02:42:20,986 - training.trainer - INFO - Epoch 41, Step 140302: Loss=6.0635, Acc=0.267, PPL=429.89
2025-09-25 02:42:28,542 - training.trainer - INFO - Epoch 41, Step 140402: Loss=5.0112, Acc=0.306, PPL=150.08
2025-09-25 02:42:36,225 - training.trainer - INFO - Epoch 41, Step 140502: Loss=5.1371, Acc=0.429, PPL=170.22
2025-09-25 02:42:43,642 - training.trainer - INFO - Epoch 41, Step 140602: Loss=4.9799, Acc=0.394, PPL=145.46
2025-09-25 02:42:51,276 - training.trainer - INFO - Epoch 41, Step 140702: Loss=4.8366, Acc=0.387, PPL=126.04
2025-09-25 02:42:58,647 - training.trainer - INFO - Epoch 41, Step 140802: Loss=5.2725, Acc=0.240, PPL=194.90
2025-09-25 02:43:06,162 - training.trainer - INFO - Epoch 41, Step 140902: Loss=5.6391, Acc=0.235, PPL=281.20
2025-09-25 02:43:13,709 - training.trainer - INFO - Epoch 41, Step 141002: Loss=5.8062, Acc=0.211, PPL=332.34
2025-09-25 02:43:21,227 - training.trainer - INFO - Epoch 41, Step 141102: Loss=5.9646, Acc=0.245, PPL=389.41
2025-09-25 02:43:28,630 - training.trainer - INFO - Epoch 41, Step 141202: Loss=6.3858, Acc=0.304, PPL=593.34
2025-09-25 02:43:36,102 - training.trainer - INFO - Epoch 41, Step 141302: Loss=6.2106, Acc=0.186, PPL=498.02
2025-09-25 02:43:43,566 - training.trainer - INFO - Epoch 41, Step 141402: Loss=4.7302, Acc=0.300, PPL=113.31
2025-09-25 02:43:51,015 - training.trainer - INFO - Epoch 41, Step 141502: Loss=3.2238, Acc=0.649, PPL=25.12
2025-09-25 02:43:58,568 - training.trainer - INFO - Epoch 41, Step 141602: Loss=6.1327, Acc=0.250, PPL=460.69
2025-09-25 02:44:05,909 - training.trainer - INFO - Epoch 41, Step 141702: Loss=4.6970, Acc=0.320, PPL=109.61
2025-09-25 02:44:13,447 - training.trainer - INFO - Epoch 41, Step 141802: Loss=5.4751, Acc=0.324, PPL=238.66
2025-09-25 02:44:21,177 - training.trainer - INFO - Epoch 41, Step 141902: Loss=4.6706, Acc=0.345, PPL=106.76
2025-09-25 02:44:28,789 - training.trainer - INFO - Epoch 41, Step 142002: Loss=5.2606, Acc=0.293, PPL=192.59
2025-09-25 02:44:47,633 - training.trainer - INFO - Epoch 42/100 completed in 262.13s - Train Loss: 5.2738, Train Acc: 0.316, Val Loss: 5.6406, Val Acc: 0.264
2025-09-25 02:44:55,359 - training.trainer - INFO - Epoch 42, Step 142185: Loss=4.4548, Acc=0.308, PPL=86.04
2025-09-25 02:45:03,030 - training.trainer - INFO - Epoch 42, Step 142285: Loss=6.3843, Acc=0.125, PPL=592.48
2025-09-25 02:45:10,614 - training.trainer - INFO - Epoch 42, Step 142385: Loss=3.8973, Acc=0.543, PPL=49.27
2025-09-25 02:45:18,346 - training.trainer - INFO - Epoch 42, Step 142485: Loss=5.5312, Acc=0.412, PPL=252.44
2025-09-25 02:45:25,743 - training.trainer - INFO - Epoch 42, Step 142585: Loss=5.7233, Acc=0.296, PPL=305.92
2025-09-25 02:45:33,162 - training.trainer - INFO - Epoch 42, Step 142685: Loss=5.1421, Acc=0.220, PPL=171.08
2025-09-25 02:45:40,542 - training.trainer - INFO - Epoch 42, Step 142785: Loss=6.0020, Acc=0.244, PPL=404.26
2025-09-25 02:45:47,875 - training.trainer - INFO - Epoch 42, Step 142885: Loss=5.8294, Acc=0.385, PPL=340.16
2025-09-25 02:45:55,396 - training.trainer - INFO - Epoch 42, Step 142985: Loss=5.9948, Acc=0.214, PPL=401.33
2025-09-25 02:46:02,850 - training.trainer - INFO - Epoch 42, Step 143085: Loss=4.9282, Acc=0.400, PPL=138.14
2025-09-25 02:46:10,308 - training.trainer - INFO - Epoch 42, Step 143185: Loss=5.8283, Acc=0.231, PPL=339.79
2025-09-25 02:46:17,767 - training.trainer - INFO - Epoch 42, Step 143285: Loss=5.2748, Acc=0.314, PPL=195.35
2025-09-25 02:46:25,221 - training.trainer - INFO - Epoch 42, Step 143385: Loss=6.3812, Acc=0.121, PPL=590.62
2025-09-25 02:46:32,649 - training.trainer - INFO - Epoch 42, Step 143485: Loss=4.8887, Acc=0.387, PPL=132.79
2025-09-25 02:46:40,084 - training.trainer - INFO - Epoch 42, Step 143585: Loss=3.7273, Acc=0.647, PPL=41.57
2025-09-25 02:46:47,575 - training.trainer - INFO - Epoch 42, Step 143685: Loss=6.4435, Acc=0.100, PPL=628.62
2025-09-25 02:46:55,045 - training.trainer - INFO - Epoch 42, Step 143785: Loss=3.4929, Acc=0.560, PPL=32.88
2025-09-25 02:47:02,609 - training.trainer - INFO - Epoch 42, Step 143885: Loss=5.2611, Acc=0.317, PPL=192.70
2025-09-25 02:47:10,615 - training.trainer - INFO - Epoch 42, Step 143985: Loss=3.2898, Acc=0.655, PPL=26.84
2025-09-25 02:47:18,038 - training.trainer - INFO - Epoch 42, Step 144085: Loss=5.6948, Acc=0.250, PPL=297.32
2025-09-25 02:47:25,514 - training.trainer - INFO - Epoch 42, Step 144185: Loss=5.2074, Acc=0.294, PPL=182.63
2025-09-25 02:47:33,030 - training.trainer - INFO - Epoch 42, Step 144285: Loss=4.2700, Acc=0.471, PPL=71.52
2025-09-25 02:47:40,436 - training.trainer - INFO - Epoch 42, Step 144385: Loss=5.0894, Acc=0.412, PPL=162.29
2025-09-25 02:47:47,987 - training.trainer - INFO - Epoch 42, Step 144485: Loss=6.3909, Acc=0.243, PPL=596.39
2025-09-25 02:47:55,361 - training.trainer - INFO - Epoch 42, Step 144585: Loss=6.0050, Acc=0.276, PPL=405.47
2025-09-25 02:48:02,810 - training.trainer - INFO - Epoch 42, Step 144685: Loss=5.0525, Acc=0.394, PPL=156.41
2025-09-25 02:48:10,237 - training.trainer - INFO - Epoch 42, Step 144785: Loss=5.9857, Acc=0.207, PPL=397.69
2025-09-25 02:48:17,702 - training.trainer - INFO - Epoch 42, Step 144885: Loss=5.5354, Acc=0.289, PPL=253.52
2025-09-25 02:48:25,426 - training.trainer - INFO - Epoch 42, Step 144985: Loss=5.8035, Acc=0.203, PPL=331.47
2025-09-25 02:48:32,896 - training.trainer - INFO - Epoch 42, Step 145085: Loss=5.9368, Acc=0.242, PPL=378.73
2025-09-25 02:48:40,348 - training.trainer - INFO - Epoch 42, Step 145185: Loss=5.2824, Acc=0.208, PPL=196.83
2025-09-25 02:48:47,840 - training.trainer - INFO - Epoch 42, Step 145285: Loss=5.4198, Acc=0.278, PPL=225.82
2025-09-25 02:48:55,258 - training.trainer - INFO - Epoch 42, Step 145385: Loss=5.3638, Acc=0.283, PPL=213.53
2025-09-25 02:49:14,047 - training.trainer - INFO - Epoch 43/100 completed in 266.41s - Train Loss: 5.2579, Train Acc: 0.317, Val Loss: 5.6451, Val Acc: 0.263
2025-09-25 02:49:20,875 - training.trainer - INFO - Epoch 43, Step 145568: Loss=5.0206, Acc=0.319, PPL=151.51
2025-09-25 02:49:27,165 - training.trainer - INFO - Epoch 43, Step 145668: Loss=5.4532, Acc=0.219, PPL=233.51
2025-09-25 02:49:33,404 - training.trainer - INFO - Epoch 43, Step 145768: Loss=5.4727, Acc=0.243, PPL=238.10
2025-09-25 02:49:39,610 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.4330, Acc=0.316, PPL=228.84
2025-09-25 02:49:46,260 - training.trainer - INFO - Epoch 43, Step 145968: Loss=5.4963, Acc=0.303, PPL=243.80
2025-09-25 02:49:52,464 - training.trainer - INFO - Epoch 43, Step 146068: Loss=5.3301, Acc=0.333, PPL=206.47
2025-09-25 02:49:58,773 - training.trainer - INFO - Epoch 43, Step 146168: Loss=5.2932, Acc=0.250, PPL=198.99
2025-09-25 02:50:05,277 - training.trainer - INFO - Epoch 43, Step 146268: Loss=5.8037, Acc=0.228, PPL=331.52
2025-09-25 02:50:11,556 - training.trainer - INFO - Epoch 43, Step 146368: Loss=4.2384, Acc=0.426, PPL=69.30
2025-09-25 02:50:18,289 - training.trainer - INFO - Epoch 43, Step 146468: Loss=5.6624, Acc=0.269, PPL=287.85
2025-09-25 02:50:24,827 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.2980, Acc=0.266, PPL=199.94
2025-09-25 02:50:31,333 - training.trainer - INFO - Epoch 43, Step 146668: Loss=4.9364, Acc=0.348, PPL=139.26
2025-09-25 02:50:37,657 - training.trainer - INFO - Epoch 43, Step 146768: Loss=5.8188, Acc=0.259, PPL=336.57
2025-09-25 02:50:43,977 - training.trainer - INFO - Epoch 43, Step 146868: Loss=5.6377, Acc=0.310, PPL=280.81
2025-09-25 02:50:50,407 - training.trainer - INFO - Epoch 43, Step 146968: Loss=4.6458, Acc=0.359, PPL=104.15
2025-09-25 02:50:56,759 - training.trainer - INFO - Epoch 43, Step 147068: Loss=5.8307, Acc=0.211, PPL=340.60
2025-09-25 02:51:03,354 - training.trainer - INFO - Epoch 43, Step 147168: Loss=5.7335, Acc=0.235, PPL=309.04
2025-09-25 02:51:10,114 - training.trainer - INFO - Epoch 43, Step 147268: Loss=6.1232, Acc=0.226, PPL=456.31
2025-09-25 02:51:16,422 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.9422, Acc=0.271, PPL=380.76
2025-09-25 02:51:22,672 - training.trainer - INFO - Epoch 43, Step 147468: Loss=5.1049, Acc=0.318, PPL=164.83
2025-09-25 02:51:29,048 - training.trainer - INFO - Epoch 43, Step 147568: Loss=5.5564, Acc=0.293, PPL=258.88
2025-09-25 02:51:35,557 - training.trainer - INFO - Epoch 43, Step 147668: Loss=4.8406, Acc=0.360, PPL=126.54
2025-09-25 02:51:41,832 - training.trainer - INFO - Epoch 43, Step 147768: Loss=5.6647, Acc=0.302, PPL=288.50
2025-09-25 02:51:48,288 - training.trainer - INFO - Epoch 43, Step 147868: Loss=5.5171, Acc=0.282, PPL=248.91
2025-09-25 02:51:55,687 - training.trainer - INFO - Epoch 43, Step 147968: Loss=5.0772, Acc=0.333, PPL=160.33
2025-09-25 02:52:03,054 - training.trainer - INFO - Epoch 43, Step 148068: Loss=5.7979, Acc=0.260, PPL=329.60
2025-09-25 02:52:10,737 - training.trainer - INFO - Epoch 43, Step 148168: Loss=3.6452, Acc=0.484, PPL=38.29
2025-09-25 02:52:18,178 - training.trainer - INFO - Epoch 43, Step 148268: Loss=5.3467, Acc=0.324, PPL=209.92
2025-09-25 02:52:25,982 - training.trainer - INFO - Epoch 43, Step 148368: Loss=5.9923, Acc=0.314, PPL=400.33
2025-09-25 02:52:33,420 - training.trainer - INFO - Epoch 43, Step 148468: Loss=5.5875, Acc=0.316, PPL=267.07
2025-09-25 02:52:40,853 - training.trainer - INFO - Epoch 43, Step 148568: Loss=4.4816, Acc=0.400, PPL=88.38
2025-09-25 02:52:48,272 - training.trainer - INFO - Epoch 43, Step 148668: Loss=5.3568, Acc=0.346, PPL=212.05
2025-09-25 02:52:55,727 - training.trainer - INFO - Epoch 43, Step 148768: Loss=4.9566, Acc=0.375, PPL=142.12
2025-09-25 02:53:14,677 - training.trainer - INFO - Epoch 44/100 completed in 240.63s - Train Loss: 5.2358, Train Acc: 0.321, Val Loss: 5.6618, Val Acc: 0.265
2025-09-25 02:53:21,678 - training.trainer - INFO - Epoch 44, Step 148951: Loss=4.7321, Acc=0.375, PPL=113.53
2025-09-25 02:53:27,906 - training.trainer - INFO - Epoch 44, Step 149051: Loss=5.7743, Acc=0.159, PPL=321.94
2025-09-25 02:53:34,247 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.2071, Acc=0.368, PPL=182.56
2025-09-25 02:53:40,766 - training.trainer - INFO - Epoch 44, Step 149251: Loss=5.4839, Acc=0.189, PPL=240.79
2025-09-25 02:53:47,100 - training.trainer - INFO - Epoch 44, Step 149351: Loss=4.6864, Acc=0.462, PPL=108.46
2025-09-25 02:53:53,943 - training.trainer - INFO - Epoch 44, Step 149451: Loss=3.9140, Acc=0.500, PPL=50.10
2025-09-25 02:54:01,344 - training.trainer - INFO - Epoch 44, Step 149551: Loss=4.1061, Acc=0.412, PPL=60.71
2025-09-25 02:54:08,823 - training.trainer - INFO - Epoch 44, Step 149651: Loss=5.4332, Acc=0.250, PPL=228.88
2025-09-25 02:54:16,367 - training.trainer - INFO - Epoch 44, Step 149751: Loss=5.3006, Acc=0.444, PPL=200.45
2025-09-25 02:54:23,957 - training.trainer - INFO - Epoch 44, Step 149851: Loss=3.0056, Acc=0.696, PPL=20.20
2025-09-25 02:54:31,468 - training.trainer - INFO - Epoch 44, Step 149951: Loss=4.8198, Acc=0.459, PPL=123.94
2025-09-25 02:54:39,023 - training.trainer - INFO - Epoch 44, Step 150051: Loss=4.8466, Acc=0.324, PPL=127.31
2025-09-25 02:54:46,380 - training.trainer - INFO - Epoch 44, Step 150151: Loss=5.0496, Acc=0.352, PPL=155.96
2025-09-25 02:54:53,903 - training.trainer - INFO - Epoch 44, Step 150251: Loss=5.1721, Acc=0.311, PPL=176.29
2025-09-25 02:55:01,334 - training.trainer - INFO - Epoch 44, Step 150351: Loss=5.9930, Acc=0.267, PPL=400.62
2025-09-25 02:55:08,768 - training.trainer - INFO - Epoch 44, Step 150451: Loss=5.0030, Acc=0.250, PPL=148.86
2025-09-25 02:55:16,174 - training.trainer - INFO - Epoch 44, Step 150551: Loss=4.8744, Acc=0.345, PPL=130.90
2025-09-25 02:55:23,873 - training.trainer - INFO - Epoch 44, Step 150651: Loss=5.3381, Acc=0.443, PPL=208.11
2025-09-25 02:55:31,323 - training.trainer - INFO - Epoch 44, Step 150751: Loss=5.2580, Acc=0.270, PPL=192.10
2025-09-25 02:55:39,149 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.6271, Acc=0.321, PPL=277.84
2025-09-25 02:55:46,698 - training.trainer - INFO - Epoch 44, Step 150951: Loss=6.6244, Acc=0.186, PPL=753.27
2025-09-25 02:55:54,339 - training.trainer - INFO - Epoch 44, Step 151051: Loss=5.2877, Acc=0.259, PPL=197.90
2025-09-25 02:56:02,148 - training.trainer - INFO - Epoch 44, Step 151151: Loss=3.9256, Acc=0.500, PPL=50.69
2025-09-25 02:56:09,526 - training.trainer - INFO - Epoch 44, Step 151251: Loss=5.4220, Acc=0.302, PPL=226.34
2025-09-25 02:56:17,022 - training.trainer - INFO - Epoch 44, Step 151351: Loss=5.7503, Acc=0.150, PPL=314.29
2025-09-25 02:56:24,595 - training.trainer - INFO - Epoch 44, Step 151451: Loss=6.1600, Acc=0.224, PPL=473.43
2025-09-25 02:56:32,178 - training.trainer - INFO - Epoch 44, Step 151551: Loss=5.5205, Acc=0.280, PPL=249.76
2025-09-25 02:56:39,589 - training.trainer - INFO - Epoch 44, Step 151651: Loss=5.2798, Acc=0.312, PPL=196.32
2025-09-25 02:56:47,021 - training.trainer - INFO - Epoch 44, Step 151751: Loss=4.9595, Acc=0.375, PPL=142.53
2025-09-25 02:56:55,109 - training.trainer - INFO - Epoch 44, Step 151851: Loss=6.0056, Acc=0.164, PPL=405.71
2025-09-25 02:57:02,566 - training.trainer - INFO - Epoch 44, Step 151951: Loss=5.8201, Acc=0.242, PPL=337.00
2025-09-25 02:57:10,138 - training.trainer - INFO - Epoch 44, Step 152051: Loss=4.7840, Acc=0.280, PPL=119.58
2025-09-25 02:57:17,517 - training.trainer - INFO - Epoch 44, Step 152151: Loss=2.8934, Acc=0.667, PPL=18.06
2025-09-25 02:57:36,171 - training.trainer - INFO - Epoch 45/100 completed in 261.49s - Train Loss: 5.2263, Train Acc: 0.323, Val Loss: 5.6587, Val Acc: 0.263
2025-09-25 02:57:36,501 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-25 02:57:43,174 - training.trainer - INFO - Epoch 45, Step 152334: Loss=5.3347, Acc=0.205, PPL=207.41
2025-09-25 02:57:50,000 - training.trainer - INFO - Epoch 45, Step 152434: Loss=5.7273, Acc=0.265, PPL=307.14
2025-09-25 02:57:57,221 - training.trainer - INFO - Epoch 45, Step 152534: Loss=6.0125, Acc=0.255, PPL=408.49
2025-09-25 02:58:04,532 - training.trainer - INFO - Epoch 45, Step 152634: Loss=4.7024, Acc=0.439, PPL=110.21
2025-09-25 02:58:12,146 - training.trainer - INFO - Epoch 45, Step 152734: Loss=3.8047, Acc=0.432, PPL=44.91
2025-09-25 02:58:19,673 - training.trainer - INFO - Epoch 45, Step 152834: Loss=4.5588, Acc=0.346, PPL=95.47
2025-09-25 02:58:27,211 - training.trainer - INFO - Epoch 45, Step 152934: Loss=5.6127, Acc=0.273, PPL=273.89
2025-09-25 02:58:34,743 - training.trainer - INFO - Epoch 45, Step 153034: Loss=4.5357, Acc=0.364, PPL=93.29
2025-09-25 02:58:42,311 - training.trainer - INFO - Epoch 45, Step 153134: Loss=5.0693, Acc=0.436, PPL=159.06
2025-09-25 02:58:49,697 - training.trainer - INFO - Epoch 45, Step 153234: Loss=4.9653, Acc=0.265, PPL=143.35
2025-09-25 02:58:57,082 - training.trainer - INFO - Epoch 45, Step 153334: Loss=6.1608, Acc=0.235, PPL=473.82
2025-09-25 02:59:04,461 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.8328, Acc=0.187, PPL=341.30
2025-09-25 02:59:11,907 - training.trainer - INFO - Epoch 45, Step 153534: Loss=4.9869, Acc=0.286, PPL=146.48
2025-09-25 02:59:19,219 - training.trainer - INFO - Epoch 45, Step 153634: Loss=4.0934, Acc=0.385, PPL=59.94
2025-09-25 02:59:26,913 - training.trainer - INFO - Epoch 45, Step 153734: Loss=2.9662, Acc=0.684, PPL=19.42
2025-09-25 02:59:34,317 - training.trainer - INFO - Epoch 45, Step 153834: Loss=6.0894, Acc=0.273, PPL=441.18
2025-09-25 02:59:41,712 - training.trainer - INFO - Epoch 45, Step 153934: Loss=5.2682, Acc=0.321, PPL=194.06
2025-09-25 02:59:49,172 - training.trainer - INFO - Epoch 45, Step 154034: Loss=5.6722, Acc=0.281, PPL=290.68
2025-09-25 02:59:56,536 - training.trainer - INFO - Epoch 45, Step 154134: Loss=5.3818, Acc=0.290, PPL=217.41
2025-09-25 03:00:03,998 - training.trainer - INFO - Epoch 45, Step 154234: Loss=5.7849, Acc=0.250, PPL=325.34
2025-09-25 03:00:11,513 - training.trainer - INFO - Epoch 45, Step 154334: Loss=4.7317, Acc=0.333, PPL=113.49
2025-09-25 03:00:19,019 - training.trainer - INFO - Epoch 45, Step 154434: Loss=4.7634, Acc=0.312, PPL=117.15
2025-09-25 03:00:26,373 - training.trainer - INFO - Epoch 45, Step 154534: Loss=5.2545, Acc=0.417, PPL=191.43
2025-09-25 03:00:33,755 - training.trainer - INFO - Epoch 45, Step 154634: Loss=5.2624, Acc=0.362, PPL=192.94
2025-09-25 03:00:41,351 - training.trainer - INFO - Epoch 45, Step 154734: Loss=5.8321, Acc=0.273, PPL=341.08
2025-09-25 03:00:48,911 - training.trainer - INFO - Epoch 45, Step 154834: Loss=5.1996, Acc=0.344, PPL=181.19
2025-09-25 03:00:56,432 - training.trainer - INFO - Epoch 45, Step 154934: Loss=5.9317, Acc=0.275, PPL=376.78
2025-09-25 03:01:03,815 - training.trainer - INFO - Epoch 45, Step 155034: Loss=5.2857, Acc=0.296, PPL=197.48
2025-09-25 03:01:11,436 - training.trainer - INFO - Epoch 45, Step 155134: Loss=5.7083, Acc=0.293, PPL=301.37
2025-09-25 03:01:18,770 - training.trainer - INFO - Epoch 45, Step 155234: Loss=5.5949, Acc=0.375, PPL=269.04
2025-09-25 03:01:26,328 - training.trainer - INFO - Epoch 45, Step 155334: Loss=4.6688, Acc=0.412, PPL=106.57
2025-09-25 03:01:33,723 - training.trainer - INFO - Epoch 45, Step 155434: Loss=4.5917, Acc=0.429, PPL=98.66
2025-09-25 03:01:41,033 - training.trainer - INFO - Epoch 45, Step 155534: Loss=3.2535, Acc=0.625, PPL=25.88
2025-09-25 03:02:00,275 - training.trainer - INFO - Epoch 46/100 completed in 263.77s - Train Loss: 5.2119, Train Acc: 0.326, Val Loss: 5.6532, Val Acc: 0.265
2025-09-25 03:02:06,860 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.1311, Acc=0.286, PPL=169.20
2025-09-25 03:02:13,348 - training.trainer - INFO - Epoch 46, Step 155817: Loss=5.6764, Acc=0.263, PPL=291.90
2025-09-25 03:02:20,755 - training.trainer - INFO - Epoch 46, Step 155917: Loss=4.7467, Acc=0.429, PPL=115.21
2025-09-25 03:02:28,102 - training.trainer - INFO - Epoch 46, Step 156017: Loss=4.5403, Acc=0.258, PPL=93.72
2025-09-25 03:02:35,504 - training.trainer - INFO - Epoch 46, Step 156117: Loss=5.4623, Acc=0.286, PPL=235.63
2025-09-25 03:02:42,817 - training.trainer - INFO - Epoch 46, Step 156217: Loss=5.3641, Acc=0.429, PPL=213.60
2025-09-25 03:02:50,410 - training.trainer - INFO - Epoch 46, Step 156317: Loss=5.2373, Acc=0.333, PPL=188.15
2025-09-25 03:02:58,117 - training.trainer - INFO - Epoch 46, Step 156417: Loss=4.1742, Acc=0.632, PPL=64.99
2025-09-25 03:03:05,789 - training.trainer - INFO - Epoch 46, Step 156517: Loss=5.3800, Acc=0.286, PPL=217.03
2025-09-25 03:03:13,434 - training.trainer - INFO - Epoch 46, Step 156617: Loss=4.4703, Acc=0.438, PPL=87.38
2025-09-25 03:03:21,066 - training.trainer - INFO - Epoch 46, Step 156717: Loss=5.9080, Acc=0.217, PPL=367.96
2025-09-25 03:03:28,514 - training.trainer - INFO - Epoch 46, Step 156817: Loss=5.2564, Acc=0.371, PPL=191.80
2025-09-25 03:03:35,943 - training.trainer - INFO - Epoch 46, Step 156917: Loss=5.4459, Acc=0.214, PPL=231.81
2025-09-25 03:03:43,308 - training.trainer - INFO - Epoch 46, Step 157017: Loss=5.2020, Acc=0.281, PPL=181.63
2025-09-25 03:03:50,871 - training.trainer - INFO - Epoch 46, Step 157117: Loss=5.8357, Acc=0.246, PPL=342.30
2025-09-25 03:03:58,320 - training.trainer - INFO - Epoch 46, Step 157217: Loss=4.9059, Acc=0.333, PPL=135.09
2025-09-25 03:04:05,822 - training.trainer - INFO - Epoch 46, Step 157317: Loss=6.0243, Acc=0.225, PPL=413.34
2025-09-25 03:04:13,384 - training.trainer - INFO - Epoch 46, Step 157417: Loss=4.3443, Acc=0.375, PPL=77.04
2025-09-25 03:04:20,918 - training.trainer - INFO - Epoch 46, Step 157517: Loss=5.1466, Acc=0.200, PPL=171.85
2025-09-25 03:04:28,833 - training.trainer - INFO - Epoch 46, Step 157617: Loss=5.5852, Acc=0.240, PPL=266.46
2025-09-25 03:04:36,282 - training.trainer - INFO - Epoch 46, Step 157717: Loss=6.2400, Acc=0.207, PPL=512.85
2025-09-25 03:04:43,807 - training.trainer - INFO - Epoch 46, Step 157817: Loss=5.1533, Acc=0.226, PPL=173.00
2025-09-25 03:04:51,164 - training.trainer - INFO - Epoch 46, Step 157917: Loss=5.9935, Acc=0.224, PPL=400.80
2025-09-25 03:04:58,542 - training.trainer - INFO - Epoch 46, Step 158017: Loss=5.1949, Acc=0.375, PPL=180.36
2025-09-25 03:05:05,883 - training.trainer - INFO - Epoch 46, Step 158117: Loss=4.7852, Acc=0.371, PPL=119.73
2025-09-25 03:05:13,416 - training.trainer - INFO - Epoch 46, Step 158217: Loss=4.7191, Acc=0.348, PPL=112.07
2025-09-25 03:05:20,953 - training.trainer - INFO - Epoch 46, Step 158317: Loss=5.7422, Acc=0.340, PPL=311.75
2025-09-25 03:05:28,471 - training.trainer - INFO - Epoch 46, Step 158417: Loss=3.8935, Acc=0.536, PPL=49.08
2025-09-25 03:05:35,931 - training.trainer - INFO - Epoch 46, Step 158517: Loss=5.7766, Acc=0.233, PPL=322.67
2025-09-25 03:05:43,245 - training.trainer - INFO - Epoch 46, Step 158617: Loss=4.8647, Acc=0.279, PPL=129.63
2025-09-25 03:05:50,914 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.7445, Acc=0.312, PPL=312.46
2025-09-25 03:05:58,309 - training.trainer - INFO - Epoch 46, Step 158817: Loss=4.4985, Acc=0.500, PPL=89.88
2025-09-25 03:06:05,788 - training.trainer - INFO - Epoch 46, Step 158917: Loss=4.6003, Acc=0.372, PPL=99.52
2025-09-25 03:06:24,723 - training.trainer - INFO - Epoch 47/100 completed in 264.45s - Train Loss: 5.2042, Train Acc: 0.328, Val Loss: 5.6625, Val Acc: 0.265
2025-09-25 03:06:31,322 - training.trainer - INFO - Epoch 47, Step 159100: Loss=5.7928, Acc=0.255, PPL=327.92
2025-09-25 03:06:37,689 - training.trainer - INFO - Epoch 47, Step 159200: Loss=5.2369, Acc=0.326, PPL=188.08
2025-09-25 03:06:44,685 - training.trainer - INFO - Epoch 47, Step 159300: Loss=3.7706, Acc=0.471, PPL=43.40
2025-09-25 03:06:51,300 - training.trainer - INFO - Epoch 47, Step 159400: Loss=4.7186, Acc=0.476, PPL=112.01
2025-09-25 03:06:58,094 - training.trainer - INFO - Epoch 47, Step 159500: Loss=5.2243, Acc=0.286, PPL=185.73
2025-09-25 03:07:04,380 - training.trainer - INFO - Epoch 47, Step 159600: Loss=5.1083, Acc=0.362, PPL=165.39
2025-09-25 03:07:10,707 - training.trainer - INFO - Epoch 47, Step 159700: Loss=5.3294, Acc=0.324, PPL=206.31
2025-09-25 03:07:16,942 - training.trainer - INFO - Epoch 47, Step 159800: Loss=5.5852, Acc=0.194, PPL=266.44
2025-09-25 03:07:23,700 - training.trainer - INFO - Epoch 47, Step 159900: Loss=5.2776, Acc=0.250, PPL=195.90
2025-09-25 03:07:30,644 - training.trainer - INFO - Epoch 47, Step 160000: Loss=5.9168, Acc=0.195, PPL=371.24
2025-09-25 03:07:37,936 - training.trainer - INFO - Epoch 47, Step 160100: Loss=5.9858, Acc=0.360, PPL=397.75
2025-09-25 03:07:45,763 - training.trainer - INFO - Epoch 47, Step 160200: Loss=6.2636, Acc=0.141, PPL=525.13
2025-09-25 03:07:53,384 - training.trainer - INFO - Epoch 47, Step 160300: Loss=5.2416, Acc=0.235, PPL=188.98
2025-09-25 03:08:00,950 - training.trainer - INFO - Epoch 47, Step 160400: Loss=5.6268, Acc=0.300, PPL=277.76
2025-09-25 03:08:08,453 - training.trainer - INFO - Epoch 47, Step 160500: Loss=6.0525, Acc=0.276, PPL=425.18
2025-09-25 03:08:15,990 - training.trainer - INFO - Epoch 47, Step 160600: Loss=4.9327, Acc=0.207, PPL=138.76
2025-09-25 03:08:23,519 - training.trainer - INFO - Epoch 47, Step 160700: Loss=4.5296, Acc=0.400, PPL=92.72
2025-09-25 03:08:31,235 - training.trainer - INFO - Epoch 47, Step 160800: Loss=5.0094, Acc=0.462, PPL=149.81
2025-09-25 03:08:38,728 - training.trainer - INFO - Epoch 47, Step 160900: Loss=4.6696, Acc=0.478, PPL=106.66
2025-09-25 03:08:46,251 - training.trainer - INFO - Epoch 47, Step 161000: Loss=4.5122, Acc=0.440, PPL=91.12
2025-09-25 03:08:53,737 - training.trainer - INFO - Epoch 47, Step 161100: Loss=5.9988, Acc=0.296, PPL=402.93
2025-09-25 03:09:01,178 - training.trainer - INFO - Epoch 47, Step 161200: Loss=4.6442, Acc=0.352, PPL=103.98
2025-09-25 03:09:08,775 - training.trainer - INFO - Epoch 47, Step 161300: Loss=5.8739, Acc=0.250, PPL=355.62
2025-09-25 03:09:16,086 - training.trainer - INFO - Epoch 47, Step 161400: Loss=5.1898, Acc=0.350, PPL=179.43
2025-09-25 03:09:23,475 - training.trainer - INFO - Epoch 47, Step 161500: Loss=5.8400, Acc=0.207, PPL=343.79
2025-09-25 03:09:31,009 - training.trainer - INFO - Epoch 47, Step 161600: Loss=5.8561, Acc=0.250, PPL=349.36
2025-09-25 03:09:38,669 - training.trainer - INFO - Epoch 47, Step 161700: Loss=5.9597, Acc=0.204, PPL=387.49
2025-09-25 03:09:46,167 - training.trainer - INFO - Epoch 47, Step 161800: Loss=4.3216, Acc=0.450, PPL=75.31
2025-09-25 03:09:53,606 - training.trainer - INFO - Epoch 47, Step 161900: Loss=5.2683, Acc=0.209, PPL=194.09
2025-09-25 03:10:01,310 - training.trainer - INFO - Epoch 47, Step 162000: Loss=5.5515, Acc=0.273, PPL=257.62
2025-09-25 03:10:08,687 - training.trainer - INFO - Epoch 47, Step 162100: Loss=5.4708, Acc=0.163, PPL=237.65
2025-09-25 03:10:16,218 - training.trainer - INFO - Epoch 47, Step 162200: Loss=5.3051, Acc=0.318, PPL=201.36
2025-09-25 03:10:23,697 - training.trainer - INFO - Epoch 47, Step 162300: Loss=5.8720, Acc=0.286, PPL=354.96
2025-09-25 03:10:42,863 - training.trainer - INFO - Epoch 48/100 completed in 258.14s - Train Loss: 5.1874, Train Acc: 0.330, Val Loss: 5.6594, Val Acc: 0.266
2025-09-25 03:10:50,542 - training.trainer - INFO - Epoch 48, Step 162483: Loss=5.3921, Acc=0.308, PPL=219.66
2025-09-25 03:10:58,034 - training.trainer - INFO - Epoch 48, Step 162583: Loss=4.4590, Acc=0.464, PPL=86.40
2025-09-25 03:11:05,568 - training.trainer - INFO - Epoch 48, Step 162683: Loss=6.2383, Acc=0.231, PPL=511.99
2025-09-25 03:11:13,022 - training.trainer - INFO - Epoch 48, Step 162783: Loss=5.3151, Acc=0.250, PPL=203.39
2025-09-25 03:11:19,921 - training.trainer - INFO - Epoch 48, Step 162883: Loss=4.8250, Acc=0.444, PPL=124.59
2025-09-25 03:11:27,189 - training.trainer - INFO - Epoch 48, Step 162983: Loss=5.4719, Acc=0.293, PPL=237.91
2025-09-25 03:11:34,812 - training.trainer - INFO - Epoch 48, Step 163083: Loss=6.1944, Acc=0.228, PPL=489.98
2025-09-25 03:11:42,397 - training.trainer - INFO - Epoch 48, Step 163183: Loss=4.8071, Acc=0.392, PPL=122.38
2025-09-25 03:11:49,964 - training.trainer - INFO - Epoch 48, Step 163283: Loss=4.7030, Acc=0.406, PPL=110.28
2025-09-25 03:11:57,460 - training.trainer - INFO - Epoch 48, Step 163383: Loss=3.3667, Acc=0.600, PPL=28.98
2025-09-25 03:12:04,868 - training.trainer - INFO - Epoch 48, Step 163483: Loss=2.4498, Acc=0.812, PPL=11.59
2025-09-25 03:12:12,213 - training.trainer - INFO - Epoch 48, Step 163583: Loss=5.5142, Acc=0.324, PPL=248.18
2025-09-25 03:12:19,496 - training.trainer - INFO - Epoch 48, Step 163683: Loss=5.3334, Acc=0.250, PPL=207.13
2025-09-25 03:12:26,699 - training.trainer - INFO - Epoch 48, Step 163783: Loss=5.8296, Acc=0.269, PPL=340.21
2025-09-25 03:12:33,973 - training.trainer - INFO - Epoch 48, Step 163883: Loss=4.8285, Acc=0.393, PPL=125.02
2025-09-25 03:12:41,537 - training.trainer - INFO - Epoch 48, Step 163983: Loss=5.4335, Acc=0.245, PPL=228.96
2025-09-25 03:12:48,820 - training.trainer - INFO - Epoch 48, Step 164083: Loss=5.3631, Acc=0.478, PPL=213.39
2025-09-25 03:12:56,303 - training.trainer - INFO - Epoch 48, Step 164183: Loss=5.5810, Acc=0.267, PPL=265.35
2025-09-25 03:13:03,543 - training.trainer - INFO - Epoch 48, Step 164283: Loss=4.8893, Acc=0.294, PPL=132.86
2025-09-25 03:13:11,472 - training.trainer - INFO - Epoch 48, Step 164383: Loss=5.5272, Acc=0.255, PPL=251.45
2025-09-25 03:13:18,799 - training.trainer - INFO - Epoch 48, Step 164483: Loss=6.4202, Acc=0.194, PPL=614.13
2025-09-25 03:13:26,163 - training.trainer - INFO - Epoch 48, Step 164583: Loss=5.2404, Acc=0.297, PPL=188.75
2025-09-25 03:13:33,401 - training.trainer - INFO - Epoch 48, Step 164683: Loss=3.6771, Acc=0.556, PPL=39.53
2025-09-25 03:13:40,605 - training.trainer - INFO - Epoch 48, Step 164783: Loss=4.0254, Acc=0.476, PPL=56.00
2025-09-25 03:13:47,869 - training.trainer - INFO - Epoch 48, Step 164883: Loss=5.8623, Acc=0.250, PPL=351.51
2025-09-25 03:13:55,160 - training.trainer - INFO - Epoch 48, Step 164983: Loss=5.6547, Acc=0.271, PPL=285.62
2025-09-25 03:14:02,512 - training.trainer - INFO - Epoch 48, Step 165083: Loss=5.2702, Acc=0.286, PPL=194.45
2025-09-25 03:14:09,808 - training.trainer - INFO - Epoch 48, Step 165183: Loss=5.7299, Acc=0.216, PPL=307.93
2025-09-25 03:14:17,109 - training.trainer - INFO - Epoch 48, Step 165283: Loss=5.5408, Acc=0.254, PPL=254.89
2025-09-25 03:14:24,356 - training.trainer - INFO - Epoch 48, Step 165383: Loss=5.6801, Acc=0.229, PPL=292.99
2025-09-25 03:14:31,894 - training.trainer - INFO - Epoch 48, Step 165483: Loss=5.9500, Acc=0.248, PPL=383.75
2025-09-25 03:14:39,196 - training.trainer - INFO - Epoch 48, Step 165583: Loss=4.6525, Acc=0.400, PPL=104.84
2025-09-25 03:14:46,418 - training.trainer - INFO - Epoch 48, Step 165683: Loss=4.2023, Acc=0.500, PPL=66.84
2025-09-25 03:15:05,524 - training.trainer - INFO - Epoch 49/100 completed in 262.66s - Train Loss: 5.1684, Train Acc: 0.334, Val Loss: 5.6661, Val Acc: 0.266
2025-09-25 03:15:13,604 - training.trainer - INFO - Epoch 49, Step 165866: Loss=5.4480, Acc=0.328, PPL=232.29
2025-09-25 03:15:20,881 - training.trainer - INFO - Epoch 49, Step 165966: Loss=4.7429, Acc=0.451, PPL=114.76
2025-09-25 03:15:28,088 - training.trainer - INFO - Epoch 49, Step 166066: Loss=4.4868, Acc=0.478, PPL=88.84
2025-09-25 03:15:35,470 - training.trainer - INFO - Epoch 49, Step 166166: Loss=3.9846, Acc=0.532, PPL=53.76
2025-09-25 03:15:42,806 - training.trainer - INFO - Epoch 49, Step 166266: Loss=2.9091, Acc=0.565, PPL=18.34
2025-09-25 03:15:50,133 - training.trainer - INFO - Epoch 49, Step 166366: Loss=5.4965, Acc=0.250, PPL=243.83
2025-09-25 03:15:57,366 - training.trainer - INFO - Epoch 49, Step 166466: Loss=5.6560, Acc=0.324, PPL=286.01
2025-09-25 03:16:04,600 - training.trainer - INFO - Epoch 49, Step 166566: Loss=5.6995, Acc=0.273, PPL=298.73
2025-09-25 03:16:11,898 - training.trainer - INFO - Epoch 49, Step 166666: Loss=5.0976, Acc=0.341, PPL=163.62
2025-09-25 03:16:19,129 - training.trainer - INFO - Epoch 49, Step 166766: Loss=5.1910, Acc=0.319, PPL=179.66
2025-09-25 03:16:26,478 - training.trainer - INFO - Epoch 49, Step 166866: Loss=5.2917, Acc=0.340, PPL=198.67
2025-09-25 03:16:33,908 - training.trainer - INFO - Epoch 49, Step 166966: Loss=4.3804, Acc=0.460, PPL=79.87
2025-09-25 03:16:41,221 - training.trainer - INFO - Epoch 49, Step 167066: Loss=5.1624, Acc=0.455, PPL=174.58
2025-09-25 03:16:48,438 - training.trainer - INFO - Epoch 49, Step 167166: Loss=5.1004, Acc=0.421, PPL=164.08
2025-09-25 03:16:56,229 - training.trainer - INFO - Epoch 49, Step 167266: Loss=5.9541, Acc=0.375, PPL=385.32
2025-09-25 03:17:03,546 - training.trainer - INFO - Epoch 49, Step 167366: Loss=5.0521, Acc=0.406, PPL=156.36
2025-09-25 03:17:10,881 - training.trainer - INFO - Epoch 49, Step 167466: Loss=4.5499, Acc=0.500, PPL=94.62
2025-09-25 03:17:18,543 - training.trainer - INFO - Epoch 49, Step 167566: Loss=2.5374, Acc=0.739, PPL=12.65
2025-09-25 03:17:25,780 - training.trainer - INFO - Epoch 49, Step 167666: Loss=6.0394, Acc=0.208, PPL=419.64
2025-09-25 03:17:33,093 - training.trainer - INFO - Epoch 49, Step 167766: Loss=5.3180, Acc=0.316, PPL=203.97
2025-09-25 03:17:40,319 - training.trainer - INFO - Epoch 49, Step 167866: Loss=5.6585, Acc=0.313, PPL=286.72
2025-09-25 03:17:47,644 - training.trainer - INFO - Epoch 49, Step 167966: Loss=4.4892, Acc=0.353, PPL=89.05
2025-09-25 03:17:54,977 - training.trainer - INFO - Epoch 49, Step 168066: Loss=4.9780, Acc=0.325, PPL=145.18
2025-09-25 03:18:02,283 - training.trainer - INFO - Epoch 49, Step 168166: Loss=5.8068, Acc=0.283, PPL=332.56
2025-09-25 03:18:09,572 - training.trainer - INFO - Epoch 49, Step 168266: Loss=5.2278, Acc=0.273, PPL=186.38
2025-09-25 03:18:16,818 - training.trainer - INFO - Epoch 49, Step 168366: Loss=5.6155, Acc=0.174, PPL=274.65
2025-09-25 03:18:24,213 - training.trainer - INFO - Epoch 49, Step 168466: Loss=5.1269, Acc=0.317, PPL=168.49
2025-09-25 03:18:32,022 - training.trainer - INFO - Epoch 49, Step 168566: Loss=5.5792, Acc=0.254, PPL=264.85
2025-09-25 03:18:39,238 - training.trainer - INFO - Epoch 49, Step 168666: Loss=6.1027, Acc=0.222, PPL=447.07
2025-09-25 03:18:46,392 - training.trainer - INFO - Epoch 49, Step 168766: Loss=4.7449, Acc=0.444, PPL=114.99
2025-09-25 03:18:53,653 - training.trainer - INFO - Epoch 49, Step 168866: Loss=4.3325, Acc=0.533, PPL=76.14
2025-09-25 03:19:00,977 - training.trainer - INFO - Epoch 49, Step 168966: Loss=5.6711, Acc=0.250, PPL=290.35
2025-09-25 03:19:08,358 - training.trainer - INFO - Epoch 49, Step 169066: Loss=5.6926, Acc=0.327, PPL=296.67
2025-09-25 03:19:27,281 - training.trainer - INFO - Epoch 50/100 completed in 261.76s - Train Loss: 5.1601, Train Acc: 0.335, Val Loss: 5.6625, Val Acc: 0.266
2025-09-25 03:19:27,585 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-25 03:19:34,638 - training.trainer - INFO - Epoch 50, Step 169249: Loss=5.7541, Acc=0.243, PPL=315.48
2025-09-25 03:19:41,704 - training.trainer - INFO - Epoch 50, Step 169349: Loss=5.4117, Acc=0.267, PPL=224.02
2025-09-25 03:19:49,222 - training.trainer - INFO - Epoch 50, Step 169449: Loss=5.8825, Acc=0.310, PPL=358.71
2025-09-25 03:19:56,803 - training.trainer - INFO - Epoch 50, Step 169549: Loss=5.0634, Acc=0.250, PPL=158.12
2025-09-25 03:20:04,275 - training.trainer - INFO - Epoch 50, Step 169649: Loss=5.4697, Acc=0.311, PPL=237.38
2025-09-25 03:20:11,692 - training.trainer - INFO - Epoch 50, Step 169749: Loss=5.5462, Acc=0.289, PPL=256.26
2025-09-25 03:20:19,171 - training.trainer - INFO - Epoch 50, Step 169849: Loss=5.3802, Acc=0.345, PPL=217.06
2025-09-25 03:20:26,662 - training.trainer - INFO - Epoch 50, Step 169949: Loss=5.9006, Acc=0.300, PPL=365.24
2025-09-25 03:20:34,115 - training.trainer - INFO - Epoch 50, Step 170049: Loss=4.8564, Acc=0.286, PPL=128.56
2025-09-25 03:20:41,671 - training.trainer - INFO - Epoch 50, Step 170149: Loss=5.9800, Acc=0.269, PPL=395.46
2025-09-25 03:20:49,127 - training.trainer - INFO - Epoch 50, Step 170249: Loss=5.6348, Acc=0.267, PPL=280.00
2025-09-25 03:20:56,571 - training.trainer - INFO - Epoch 50, Step 170349: Loss=5.8239, Acc=0.259, PPL=338.29
2025-09-25 03:21:04,044 - training.trainer - INFO - Epoch 50, Step 170449: Loss=5.7173, Acc=0.268, PPL=304.07
2025-09-25 03:21:11,415 - training.trainer - INFO - Epoch 50, Step 170549: Loss=4.6685, Acc=0.391, PPL=106.54
2025-09-25 03:21:18,933 - training.trainer - INFO - Epoch 50, Step 170649: Loss=5.4617, Acc=0.417, PPL=235.50
2025-09-25 03:21:26,432 - training.trainer - INFO - Epoch 50, Step 170749: Loss=5.6548, Acc=0.250, PPL=285.67
2025-09-25 03:21:33,799 - training.trainer - INFO - Epoch 50, Step 170849: Loss=4.7898, Acc=0.444, PPL=120.28
2025-09-25 03:21:41,242 - training.trainer - INFO - Epoch 50, Step 170949: Loss=4.5378, Acc=0.435, PPL=93.48
2025-09-25 03:21:48,653 - training.trainer - INFO - Epoch 50, Step 171049: Loss=5.8785, Acc=0.357, PPL=357.26
2025-09-25 03:21:56,204 - training.trainer - INFO - Epoch 50, Step 171149: Loss=3.9007, Acc=0.524, PPL=49.44
2025-09-25 03:22:04,085 - training.trainer - INFO - Epoch 50, Step 171249: Loss=4.6471, Acc=0.394, PPL=104.29
2025-09-25 03:22:11,744 - training.trainer - INFO - Epoch 50, Step 171349: Loss=5.0056, Acc=0.298, PPL=149.24
2025-09-25 03:22:19,279 - training.trainer - INFO - Epoch 50, Step 171449: Loss=4.7745, Acc=0.364, PPL=118.45
2025-09-25 03:22:26,883 - training.trainer - INFO - Epoch 50, Step 171549: Loss=4.0194, Acc=0.500, PPL=55.67
2025-09-25 03:22:34,220 - training.trainer - INFO - Epoch 50, Step 171649: Loss=6.1057, Acc=0.270, PPL=448.42
2025-09-25 03:22:41,587 - training.trainer - INFO - Epoch 50, Step 171749: Loss=3.6804, Acc=0.565, PPL=39.66
2025-09-25 03:22:48,874 - training.trainer - INFO - Epoch 50, Step 171849: Loss=4.6170, Acc=0.389, PPL=101.19
2025-09-25 03:22:56,230 - training.trainer - INFO - Epoch 50, Step 171949: Loss=5.6394, Acc=0.271, PPL=281.30
2025-09-25 03:23:03,679 - training.trainer - INFO - Epoch 50, Step 172049: Loss=5.0161, Acc=0.367, PPL=150.82
2025-09-25 03:23:11,026 - training.trainer - INFO - Epoch 50, Step 172149: Loss=5.5961, Acc=0.421, PPL=269.36
2025-09-25 03:23:18,592 - training.trainer - INFO - Epoch 50, Step 172249: Loss=5.1224, Acc=0.355, PPL=167.74
2025-09-25 03:23:26,291 - training.trainer - INFO - Epoch 50, Step 172349: Loss=4.4145, Acc=0.432, PPL=82.64
2025-09-25 03:23:33,801 - training.trainer - INFO - Epoch 50, Step 172449: Loss=6.0072, Acc=0.214, PPL=406.36
2025-09-25 03:23:52,882 - training.trainer - INFO - Epoch 51/100 completed in 265.30s - Train Loss: 5.1477, Train Acc: 0.338, Val Loss: 5.6748, Val Acc: 0.264
2025-09-25 03:23:59,440 - training.trainer - INFO - Epoch 51, Step 172632: Loss=4.5205, Acc=0.423, PPL=91.88
2025-09-25 03:24:05,715 - training.trainer - INFO - Epoch 51, Step 172732: Loss=5.1474, Acc=0.244, PPL=171.99
2025-09-25 03:24:11,988 - training.trainer - INFO - Epoch 51, Step 172832: Loss=5.5125, Acc=0.273, PPL=247.77
2025-09-25 03:24:19,123 - training.trainer - INFO - Epoch 51, Step 172932: Loss=5.0200, Acc=0.297, PPL=151.41
2025-09-25 03:24:26,668 - training.trainer - INFO - Epoch 51, Step 173032: Loss=4.9722, Acc=0.400, PPL=144.34
2025-09-25 03:24:34,168 - training.trainer - INFO - Epoch 51, Step 173132: Loss=5.1836, Acc=0.271, PPL=178.32
2025-09-25 03:24:41,913 - training.trainer - INFO - Epoch 51, Step 173232: Loss=5.1934, Acc=0.310, PPL=180.07
2025-09-25 03:24:49,425 - training.trainer - INFO - Epoch 51, Step 173332: Loss=4.8065, Acc=0.391, PPL=122.30
2025-09-25 03:24:56,789 - training.trainer - INFO - Epoch 51, Step 173432: Loss=5.2249, Acc=0.300, PPL=185.84
2025-09-25 03:25:04,155 - training.trainer - INFO - Epoch 51, Step 173532: Loss=4.6876, Acc=0.333, PPL=108.59
2025-09-25 03:25:11,957 - training.trainer - INFO - Epoch 51, Step 173632: Loss=4.0339, Acc=0.560, PPL=56.48
2025-09-25 03:25:19,845 - training.trainer - INFO - Epoch 51, Step 173732: Loss=5.4247, Acc=0.278, PPL=226.95
2025-09-25 03:25:27,383 - training.trainer - INFO - Epoch 51, Step 173832: Loss=5.5519, Acc=0.250, PPL=257.72
2025-09-25 03:25:34,877 - training.trainer - INFO - Epoch 51, Step 173932: Loss=4.6616, Acc=0.415, PPL=105.81
2025-09-25 03:25:42,498 - training.trainer - INFO - Epoch 51, Step 174032: Loss=5.7573, Acc=0.268, PPL=316.49
2025-09-25 03:25:50,136 - training.trainer - INFO - Epoch 51, Step 174132: Loss=5.4451, Acc=0.250, PPL=231.61
2025-09-25 03:25:58,090 - training.trainer - INFO - Epoch 51, Step 174232: Loss=4.7175, Acc=0.359, PPL=111.89
2025-09-25 03:26:05,795 - training.trainer - INFO - Epoch 51, Step 174332: Loss=5.5945, Acc=0.385, PPL=268.95
2025-09-25 03:26:13,550 - training.trainer - INFO - Epoch 51, Step 174432: Loss=4.6865, Acc=0.333, PPL=108.48
2025-09-25 03:26:21,066 - training.trainer - INFO - Epoch 51, Step 174532: Loss=4.7740, Acc=0.345, PPL=118.39
2025-09-25 03:26:28,574 - training.trainer - INFO - Epoch 51, Step 174632: Loss=5.7593, Acc=0.295, PPL=317.11
2025-09-25 03:26:35,948 - training.trainer - INFO - Epoch 51, Step 174732: Loss=5.2183, Acc=0.250, PPL=184.63
2025-09-25 03:26:43,199 - training.trainer - INFO - Epoch 51, Step 174832: Loss=5.8357, Acc=0.281, PPL=342.32
2025-09-25 03:26:50,679 - training.trainer - INFO - Epoch 51, Step 174932: Loss=5.6746, Acc=0.235, PPL=291.36
2025-09-25 03:26:58,091 - training.trainer - INFO - Epoch 51, Step 175032: Loss=5.7504, Acc=0.214, PPL=314.33
2025-09-25 03:27:05,457 - training.trainer - INFO - Epoch 51, Step 175132: Loss=3.4048, Acc=0.444, PPL=30.11
2025-09-25 03:27:12,929 - training.trainer - INFO - Epoch 51, Step 175232: Loss=5.8999, Acc=0.261, PPL=365.01
2025-09-25 03:27:20,170 - training.trainer - INFO - Epoch 51, Step 175332: Loss=3.8131, Acc=0.522, PPL=45.29
2025-09-25 03:27:27,470 - training.trainer - INFO - Epoch 51, Step 175432: Loss=5.4815, Acc=0.298, PPL=240.20
2025-09-25 03:27:34,724 - training.trainer - INFO - Epoch 51, Step 175532: Loss=5.2695, Acc=0.394, PPL=194.32
2025-09-25 03:27:42,092 - training.trainer - INFO - Epoch 51, Step 175632: Loss=5.6835, Acc=0.234, PPL=293.98
2025-09-25 03:27:49,295 - training.trainer - INFO - Epoch 51, Step 175732: Loss=6.3764, Acc=0.203, PPL=587.81
2025-09-25 03:27:56,618 - training.trainer - INFO - Epoch 51, Step 175832: Loss=5.9953, Acc=0.333, PPL=401.53
2025-09-25 03:28:15,872 - training.trainer - INFO - Epoch 52/100 completed in 262.99s - Train Loss: 5.1412, Train Acc: 0.339, Val Loss: 5.6880, Val Acc: 0.265
2025-09-25 03:28:15,873 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-09-25 03:28:15,873 - training.trainer - INFO - Training completed!
2025-09-25 03:28:15,879 - __main__ - INFO - Training completed successfully!
2025-09-25 03:28:15,987 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-25 03:28:16,198 - __main__ - INFO - Process completed!
2025-09-25 20:49:07,101 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-25 20:49:07,103 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-25 20:49:07,103 - __main__ - INFO - Starting model evaluation
2025-09-25 20:49:08,092 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-25 20:55:48,299 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-25 20:55:48,314 - __main__ - INFO - Process completed!
2025-09-25 20:57:42,086 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-25 20:57:42,086 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-25 20:57:42,087 - __main__ - ERROR - Input file required for inference mode
2025-09-25 21:17:05,991 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-25 21:17:05,991 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-25 21:17:05,991 - __main__ - INFO - Starting training pipeline
2025-09-25 21:17:06,101 - __main__ - INFO - üîç Initial GPU check: CUDA available = True
2025-09-25 21:17:06,126 - __main__ - INFO - üöÄ GPU: NVIDIA A30
2025-09-25 21:17:06,127 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-25 21:17:06,127 - __main__ - INFO - Loading training data...
2025-09-25 21:17:13,976 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-25 21:17:13,977 - __main__ - INFO - Processing train split...
2025-09-25 21:17:14,063 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-25 21:17:14,063 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-25 21:17:59,084 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-25 21:18:43,662 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-25 21:19:28,669 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-25 21:20:12,153 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-25 21:20:55,469 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-25 21:21:37,725 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-25 21:22:10,595 - __main__ - INFO - Processing val split...
2025-09-25 21:22:10,830 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-25 21:22:10,831 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-25 21:22:46,261 - __main__ - INFO - Processing test split...
2025-09-25 21:22:46,476 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-25 21:22:46,476 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-25 21:23:18,394 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-25 21:23:18,394 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-25 21:23:18,410 - __main__ - INFO - ‚úÖ Vocabulary created successfully with 13664 words
2025-09-25 21:23:18,410 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-25 21:23:18,410 - __main__ - INFO - Creating model architecture...
2025-09-25 21:23:18,869 - __main__ - INFO - ‚úÖ Model created successfully
2025-09-25 21:23:18,869 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-25 21:23:18,870 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-25 21:23:18,870 - __main__ - INFO - üñ•Ô∏è  Using device: cuda
2025-09-25 21:23:18,870 - __main__ - INFO - Creating trainer...
2025-09-25 21:23:18,870 - __main__ - INFO - üîÑ Moving model to cuda...
2025-09-25 21:23:19,180 - __main__ - INFO - ‚úÖ Model moved to cuda
2025-09-25 21:23:19,181 - __main__ - INFO - üìç Model parameters are on: cuda:0
2025-09-25 21:23:21,009 - __main__ - INFO - ‚úÖ Trainer created successfully
2025-09-25 21:23:21,009 - __main__ - INFO - üìç Trainer model parameters are on: cuda:0
2025-09-25 21:23:21,009 - __main__ - INFO - üöÄ Starting training...
2025-09-25 21:23:21,009 - __main__ - INFO - Training configuration:
2025-09-25 21:23:21,009 - __main__ - INFO -   - Epochs: 100
2025-09-25 21:23:21,009 - __main__ - INFO -   - Batch size: 2
2025-09-25 21:23:21,009 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-25 21:23:21,009 - __main__ - INFO -   - Training samples: 6765
2025-09-25 21:23:21,009 - __main__ - INFO -   - Validation samples: 845
2025-09-25 21:23:21,010 - training.trainer - INFO - Starting training for 100 epochs
2025-09-25 21:23:21,010 - training.trainer - INFO - Model parameters: 16,680,032
2025-09-25 21:23:21,010 - training.trainer - INFO - Training on device: cuda
2025-09-25 21:23:31,294 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.8440, Acc=0.043, PPL=6932.51
2025-09-25 21:23:39,817 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.1966, Acc=0.077, PPL=3628.62
2025-09-25 21:23:48,123 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.4806, Acc=0.061, PPL=1773.29
2025-09-25 21:23:56,153 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.4136, Acc=0.100, PPL=1658.44
2025-09-25 21:24:04,081 - training.trainer - INFO - Epoch 0, Step 499: Loss=7.3648, Acc=0.107, PPL=1579.34
2025-09-25 21:24:12,087 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.2847, Acc=0.042, PPL=1457.84
2025-09-25 21:24:19,801 - training.trainer - INFO - Epoch 0, Step 699: Loss=7.2187, Acc=0.053, PPL=1364.75
2025-09-25 21:24:27,466 - training.trainer - INFO - Epoch 0, Step 799: Loss=7.4189, Acc=0.111, PPL=1667.21
2025-09-25 21:24:35,436 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.7380, Acc=0.074, PPL=843.86
2025-09-25 21:24:43,426 - training.trainer - INFO - Epoch 0, Step 999: Loss=7.1803, Acc=0.118, PPL=1313.33
2025-09-25 21:24:51,117 - training.trainer - INFO - Epoch 0, Step 1099: Loss=7.0941, Acc=0.130, PPL=1204.87
2025-09-25 21:24:58,805 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.4010, Acc=0.222, PPL=602.44
2025-09-25 21:25:06,280 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.6244, Acc=0.105, PPL=753.26
2025-09-25 21:25:13,875 - training.trainer - INFO - Epoch 0, Step 1399: Loss=5.8368, Acc=0.222, PPL=342.69
2025-09-25 21:25:21,371 - training.trainer - INFO - Epoch 0, Step 1499: Loss=5.9037, Acc=0.136, PPL=366.39
2025-09-25 21:25:28,838 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.3139, Acc=0.143, PPL=552.20
2025-09-25 21:25:36,311 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.7419, Acc=0.130, PPL=847.14
2025-09-25 21:25:43,735 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.6805, Acc=0.071, PPL=796.69
2025-09-25 21:25:51,280 - training.trainer - INFO - Epoch 0, Step 1899: Loss=7.0701, Acc=0.075, PPL=1176.27
2025-09-25 21:25:58,951 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.2447, Acc=0.119, PPL=515.28
2025-09-25 21:26:06,459 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.8011, Acc=0.125, PPL=898.84
2025-09-25 21:26:14,017 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.5707, Acc=0.150, PPL=713.89
2025-09-25 21:26:21,483 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.5593, Acc=0.135, PPL=705.78
2025-09-25 21:26:28,870 - training.trainer - INFO - Epoch 0, Step 2399: Loss=7.4084, Acc=0.148, PPL=1649.85
2025-09-25 21:26:36,368 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.8019, Acc=0.107, PPL=899.53
2025-09-25 21:26:43,652 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.5217, Acc=0.132, PPL=679.72
2025-09-25 21:26:51,315 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.3567, Acc=0.107, PPL=576.34
2025-09-25 21:26:59,068 - training.trainer - INFO - Epoch 0, Step 2799: Loss=5.9199, Acc=0.154, PPL=372.37
2025-09-25 21:27:06,490 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.6738, Acc=0.135, PPL=791.39
2025-09-25 21:27:14,144 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.5029, Acc=0.151, PPL=667.06
2025-09-25 21:27:21,662 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.5711, Acc=0.115, PPL=714.18
2025-09-25 21:27:29,157 - training.trainer - INFO - Epoch 0, Step 3199: Loss=6.9666, Acc=0.125, PPL=1060.63
2025-09-25 21:27:36,529 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.3356, Acc=0.179, PPL=564.31
2025-09-25 21:27:54,818 - training.trainer - INFO - Epoch 1/100 completed in 273.81s - Train Loss: 6.8275, Train Acc: 0.127, Val Loss: 6.3685, Val Acc: 0.165
2025-09-25 21:27:55,665 - training.trainer - INFO - New best model saved with validation loss: 6.3685
2025-09-25 21:27:55,665 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-25 21:28:02,513 - training.trainer - INFO - Epoch 1, Step 3482: Loss=6.0906, Acc=0.200, PPL=441.70
2025-09-25 21:28:09,419 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.4800, Acc=0.146, PPL=651.95
2025-09-25 21:28:16,361 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.7478, Acc=0.190, PPL=852.17
2025-09-25 21:28:23,601 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.2652, Acc=0.109, PPL=525.95
2025-09-25 21:28:31,216 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.6560, Acc=0.101, PPL=777.43
2025-09-25 21:28:38,600 - training.trainer - INFO - Epoch 1, Step 3982: Loss=7.1954, Acc=0.167, PPL=1333.31
2025-09-25 21:28:46,010 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.4622, Acc=0.167, PPL=640.46
2025-09-25 21:28:53,319 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.4385, Acc=0.138, PPL=625.50
2025-09-25 21:29:00,724 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.0638, Acc=0.178, PPL=429.99
2025-09-25 21:29:08,119 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.3092, Acc=0.140, PPL=549.59
2025-09-25 21:29:15,360 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.4861, Acc=0.156, PPL=655.94
2025-09-25 21:29:22,635 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.7090, Acc=0.222, PPL=819.77
2025-09-25 21:29:29,895 - training.trainer - INFO - Epoch 1, Step 4682: Loss=6.9717, Acc=0.158, PPL=1065.99
2025-09-25 21:29:37,253 - training.trainer - INFO - Epoch 1, Step 4782: Loss=6.4500, Acc=0.091, PPL=632.71
2025-09-25 21:29:44,465 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.7345, Acc=0.167, PPL=840.88
2025-09-25 21:29:51,793 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.7888, Acc=0.147, PPL=887.89
2025-09-25 21:29:59,064 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.8686, Acc=0.092, PPL=961.65
2025-09-25 21:30:06,341 - training.trainer - INFO - Epoch 1, Step 5182: Loss=5.5764, Acc=0.217, PPL=264.12
2025-09-25 21:30:13,911 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.1393, Acc=0.189, PPL=463.74
2025-09-25 21:30:21,152 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.5102, Acc=0.194, PPL=671.96
2025-09-25 21:30:28,616 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.1724, Acc=0.171, PPL=479.32
2025-09-25 21:30:35,879 - training.trainer - INFO - Epoch 1, Step 5582: Loss=6.4918, Acc=0.150, PPL=659.70
2025-09-25 21:30:43,256 - training.trainer - INFO - Epoch 1, Step 5682: Loss=5.4506, Acc=0.208, PPL=232.90
2025-09-25 21:30:50,502 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.2943, Acc=0.148, PPL=541.48
2025-09-25 21:30:57,726 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.5783, Acc=0.128, PPL=719.35
2025-09-25 21:31:05,093 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.9687, Acc=0.152, PPL=1062.87
2025-09-25 21:31:12,364 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.5824, Acc=0.143, PPL=722.27
2025-09-25 21:31:19,721 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.4065, Acc=0.140, PPL=605.79
2025-09-25 21:31:26,969 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.3400, Acc=0.103, PPL=566.79
2025-09-25 21:31:34,209 - training.trainer - INFO - Epoch 1, Step 6382: Loss=5.6806, Acc=0.308, PPL=293.13
2025-09-25 21:31:41,479 - training.trainer - INFO - Epoch 1, Step 6482: Loss=7.2250, Acc=0.136, PPL=1373.30
2025-09-25 21:31:48,850 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.7463, Acc=0.095, PPL=850.91
2025-09-25 21:31:56,262 - training.trainer - INFO - Epoch 1, Step 6682: Loss=5.5414, Acc=0.229, PPL=255.04
2025-09-25 21:32:15,015 - training.trainer - INFO - Epoch 2/100 completed in 259.35s - Train Loss: 6.3254, Train Acc: 0.165, Val Loss: 6.2141, Val Acc: 0.173
2025-09-25 21:32:15,740 - training.trainer - INFO - New best model saved with validation loss: 6.2141
2025-09-25 21:32:15,740 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-25 21:32:23,512 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.2285, Acc=0.138, PPL=507.00
2025-09-25 21:32:30,772 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.7623, Acc=0.150, PPL=864.61
2025-09-25 21:32:37,979 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.4635, Acc=0.113, PPL=641.32
2025-09-25 21:32:45,271 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.1934, Acc=0.147, PPL=489.49
2025-09-25 21:32:52,581 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.5496, Acc=0.143, PPL=698.95
2025-09-25 21:32:59,794 - training.trainer - INFO - Epoch 2, Step 7365: Loss=5.7810, Acc=0.263, PPL=324.07
2025-09-25 21:33:06,958 - training.trainer - INFO - Epoch 2, Step 7465: Loss=5.6329, Acc=0.154, PPL=279.48
2025-09-25 21:33:14,195 - training.trainer - INFO - Epoch 2, Step 7565: Loss=6.2363, Acc=0.150, PPL=510.98
2025-09-25 21:33:21,523 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.0245, Acc=0.231, PPL=413.42
2025-09-25 21:33:28,939 - training.trainer - INFO - Epoch 2, Step 7765: Loss=4.8983, Acc=0.273, PPL=134.06
2025-09-25 21:33:36,241 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.0406, Acc=0.207, PPL=420.16
2025-09-25 21:33:43,508 - training.trainer - INFO - Epoch 2, Step 7965: Loss=5.5883, Acc=0.259, PPL=267.28
2025-09-25 21:33:50,697 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.2857, Acc=0.143, PPL=536.84
2025-09-25 21:33:58,064 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.3630, Acc=0.136, PPL=579.96
2025-09-25 21:34:05,221 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.8345, Acc=0.084, PPL=929.40
2025-09-25 21:34:12,415 - training.trainer - INFO - Epoch 2, Step 8365: Loss=6.3734, Acc=0.208, PPL=586.05
2025-09-25 21:34:19,921 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.4659, Acc=0.132, PPL=642.84
2025-09-25 21:34:27,598 - training.trainer - INFO - Epoch 2, Step 8565: Loss=7.2201, Acc=0.100, PPL=1366.62
2025-09-25 21:34:35,183 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.6838, Acc=0.152, PPL=799.35
2025-09-25 21:34:42,874 - training.trainer - INFO - Epoch 2, Step 8765: Loss=5.7345, Acc=0.250, PPL=309.34
2025-09-25 21:34:50,404 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.7149, Acc=0.138, PPL=824.60
2025-09-25 21:34:57,872 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.4936, Acc=0.162, PPL=660.89
2025-09-25 21:35:05,363 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.4778, Acc=0.162, PPL=650.55
2025-09-25 21:35:12,670 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.6543, Acc=0.085, PPL=776.14
2025-09-25 21:35:20,129 - training.trainer - INFO - Epoch 2, Step 9265: Loss=5.9829, Acc=0.214, PPL=396.59
2025-09-25 21:35:27,416 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.4594, Acc=0.171, PPL=638.71
2025-09-25 21:35:34,737 - training.trainer - INFO - Epoch 2, Step 9465: Loss=5.6493, Acc=0.286, PPL=284.08
2025-09-25 21:35:42,096 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.7834, Acc=0.107, PPL=883.09
2025-09-25 21:35:49,436 - training.trainer - INFO - Epoch 2, Step 9665: Loss=5.9579, Acc=0.235, PPL=386.81
2025-09-25 21:35:56,744 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.1722, Acc=0.146, PPL=479.23
2025-09-25 21:36:04,020 - training.trainer - INFO - Epoch 2, Step 9865: Loss=5.6624, Acc=0.154, PPL=287.83
2025-09-25 21:36:11,423 - training.trainer - INFO - Epoch 2, Step 9965: Loss=6.3656, Acc=0.222, PPL=581.48
2025-09-25 21:36:18,717 - training.trainer - INFO - Epoch 2, Step 10065: Loss=5.9480, Acc=0.171, PPL=382.97
2025-09-25 21:36:37,923 - training.trainer - INFO - Epoch 3/100 completed in 262.18s - Train Loss: 6.2110, Train Acc: 0.176, Val Loss: 6.1263, Val Acc: 0.181
2025-09-25 21:36:38,648 - training.trainer - INFO - New best model saved with validation loss: 6.1263
2025-09-25 21:36:38,648 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-25 21:36:45,450 - training.trainer - INFO - Epoch 3, Step 10248: Loss=6.4334, Acc=0.189, PPL=622.28
2025-09-25 21:36:51,740 - training.trainer - INFO - Epoch 3, Step 10348: Loss=6.3771, Acc=0.219, PPL=588.25
2025-09-25 21:36:58,128 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.2798, Acc=0.136, PPL=533.70
2025-09-25 21:37:04,457 - training.trainer - INFO - Epoch 3, Step 10548: Loss=5.8315, Acc=0.179, PPL=340.88
2025-09-25 21:37:11,394 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.6631, Acc=0.161, PPL=782.94
2025-09-25 21:37:18,379 - training.trainer - INFO - Epoch 3, Step 10748: Loss=6.2228, Acc=0.143, PPL=504.10
2025-09-25 21:37:25,413 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.5893, Acc=0.196, PPL=727.26
2025-09-25 21:37:32,419 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.4010, Acc=0.127, PPL=602.45
2025-09-25 21:37:39,929 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.7696, Acc=0.108, PPL=870.99
2025-09-25 21:37:47,684 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.4156, Acc=0.154, PPL=611.29
2025-09-25 21:37:55,286 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.5719, Acc=0.165, PPL=714.74
2025-09-25 21:38:02,841 - training.trainer - INFO - Epoch 3, Step 11348: Loss=6.7273, Acc=0.143, PPL=834.89
2025-09-25 21:38:10,449 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.2249, Acc=0.176, PPL=505.16
2025-09-25 21:38:18,058 - training.trainer - INFO - Epoch 3, Step 11548: Loss=5.8972, Acc=0.233, PPL=364.03
2025-09-25 21:38:25,680 - training.trainer - INFO - Epoch 3, Step 11648: Loss=5.5292, Acc=0.250, PPL=251.93
2025-09-25 21:38:33,198 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.7880, Acc=0.259, PPL=326.36
2025-09-25 21:38:40,733 - training.trainer - INFO - Epoch 3, Step 11848: Loss=6.8514, Acc=0.130, PPL=945.16
2025-09-25 21:38:48,342 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.4611, Acc=0.154, PPL=639.78
2025-09-25 21:38:56,030 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.0134, Acc=0.250, PPL=408.87
2025-09-25 21:39:03,429 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.2774, Acc=0.184, PPL=532.38
2025-09-25 21:39:10,834 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.2819, Acc=0.139, PPL=534.80
2025-09-25 21:39:18,294 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.0370, Acc=0.148, PPL=418.63
2025-09-25 21:39:25,718 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.4701, Acc=0.156, PPL=645.54
2025-09-25 21:39:32,999 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.4703, Acc=0.116, PPL=645.67
2025-09-25 21:39:40,255 - training.trainer - INFO - Epoch 3, Step 12648: Loss=5.9829, Acc=0.333, PPL=396.58
2025-09-25 21:39:47,512 - training.trainer - INFO - Epoch 3, Step 12748: Loss=5.2387, Acc=0.250, PPL=188.42
2025-09-25 21:39:54,770 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.9990, Acc=0.125, PPL=1095.59
2025-09-25 21:40:02,133 - training.trainer - INFO - Epoch 3, Step 12948: Loss=5.7648, Acc=0.226, PPL=318.89
2025-09-25 21:40:09,592 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.2261, Acc=0.182, PPL=505.78
2025-09-25 21:40:16,801 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.2916, Acc=0.196, PPL=539.99
2025-09-25 21:40:24,008 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.5918, Acc=0.162, PPL=729.11
2025-09-25 21:40:31,334 - training.trainer - INFO - Epoch 3, Step 13348: Loss=4.6996, Acc=0.333, PPL=109.90
2025-09-25 21:40:38,573 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.6526, Acc=0.200, PPL=774.81
2025-09-25 21:40:57,972 - training.trainer - INFO - Epoch 4/100 completed in 259.32s - Train Loss: 6.1352, Train Acc: 0.185, Val Loss: 6.0610, Val Acc: 0.196
2025-09-25 21:40:58,739 - training.trainer - INFO - New best model saved with validation loss: 6.0610
2025-09-25 21:40:58,739 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-25 21:41:04,880 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-25 21:41:04,880 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-25 21:41:04,880 - __main__ - INFO - Starting model evaluation
2025-09-25 21:41:05,908 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-25 21:41:06,473 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.2307, Acc=0.250, PPL=508.13
2025-09-25 21:41:13,668 - training.trainer - INFO - Epoch 4, Step 13731: Loss=5.8157, Acc=0.138, PPL=335.53
2025-09-25 21:41:21,019 - training.trainer - INFO - Epoch 4, Step 13831: Loss=5.7222, Acc=0.231, PPL=305.59
2025-09-25 21:41:28,377 - training.trainer - INFO - Epoch 4, Step 13931: Loss=5.5872, Acc=0.273, PPL=266.99
2025-09-25 21:41:35,729 - training.trainer - INFO - Epoch 4, Step 14031: Loss=6.7469, Acc=0.156, PPL=851.37
2025-09-25 21:41:43,209 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.1942, Acc=0.188, PPL=489.90
2025-09-25 21:41:50,604 - training.trainer - INFO - Epoch 4, Step 14231: Loss=5.3629, Acc=0.233, PPL=213.33
2025-09-25 21:41:57,998 - training.trainer - INFO - Epoch 4, Step 14331: Loss=5.9970, Acc=0.169, PPL=402.24
2025-09-25 21:42:05,396 - training.trainer - INFO - Epoch 4, Step 14431: Loss=6.5302, Acc=0.179, PPL=685.51
2025-09-25 21:42:12,749 - training.trainer - INFO - Epoch 4, Step 14531: Loss=6.0846, Acc=0.273, PPL=439.02
2025-09-25 21:42:20,034 - training.trainer - INFO - Epoch 4, Step 14631: Loss=5.8779, Acc=0.195, PPL=357.05
2025-09-25 21:42:27,011 - training.trainer - INFO - Epoch 4, Step 14731: Loss=6.5206, Acc=0.138, PPL=679.00
2025-09-25 21:42:34,367 - training.trainer - INFO - Epoch 4, Step 14831: Loss=6.4760, Acc=0.214, PPL=649.36
2025-09-25 21:42:41,729 - training.trainer - INFO - Epoch 4, Step 14931: Loss=6.1431, Acc=0.125, PPL=465.51
2025-09-25 21:42:49,101 - training.trainer - INFO - Epoch 4, Step 15031: Loss=6.5065, Acc=0.125, PPL=669.46
2025-09-25 21:42:56,483 - training.trainer - INFO - Epoch 4, Step 15131: Loss=6.4212, Acc=0.217, PPL=614.73
2025-09-25 21:43:03,840 - training.trainer - INFO - Epoch 4, Step 15231: Loss=5.7433, Acc=0.158, PPL=312.08
2025-09-25 21:43:11,229 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.0919, Acc=0.128, PPL=442.27
2025-09-25 21:43:18,507 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.0439, Acc=0.226, PPL=421.54
2025-09-25 21:43:25,732 - training.trainer - INFO - Epoch 4, Step 15531: Loss=5.5630, Acc=0.250, PPL=260.60
2025-09-25 21:43:33,068 - training.trainer - INFO - Epoch 4, Step 15631: Loss=5.9944, Acc=0.280, PPL=401.18
2025-09-25 21:43:40,062 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.6188, Acc=0.143, PPL=749.06
2025-09-25 21:43:47,397 - training.trainer - INFO - Epoch 4, Step 15831: Loss=6.6432, Acc=0.192, PPL=767.53
2025-09-25 21:43:54,754 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.2926, Acc=0.133, PPL=540.54
2025-09-25 21:44:02,177 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.1768, Acc=0.259, PPL=481.46
2025-09-25 21:44:09,528 - training.trainer - INFO - Epoch 4, Step 16131: Loss=5.6563, Acc=0.278, PPL=286.09
2025-09-25 21:44:16,885 - training.trainer - INFO - Epoch 4, Step 16231: Loss=5.9276, Acc=0.150, PPL=375.25
2025-09-25 21:44:24,339 - training.trainer - INFO - Epoch 4, Step 16331: Loss=6.1944, Acc=0.152, PPL=490.01
2025-09-25 21:44:31,659 - training.trainer - INFO - Epoch 4, Step 16431: Loss=6.3155, Acc=0.186, PPL=553.10
2025-09-25 21:44:38,972 - training.trainer - INFO - Epoch 4, Step 16531: Loss=6.7412, Acc=0.136, PPL=846.57
2025-09-25 21:44:46,037 - training.trainer - INFO - Epoch 4, Step 16631: Loss=6.2051, Acc=0.140, PPL=495.27
2025-09-25 21:44:53,481 - training.trainer - INFO - Epoch 4, Step 16731: Loss=6.3148, Acc=0.269, PPL=552.72
2025-09-25 21:45:00,828 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.6726, Acc=0.100, PPL=790.44
2025-09-25 21:45:18,852 - training.trainer - INFO - Epoch 5/100 completed in 260.11s - Train Loss: 6.0861, Train Acc: 0.193, Val Loss: 6.0030, Val Acc: 0.200
2025-09-25 21:45:19,155 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-25 21:45:19,727 - training.trainer - INFO - New best model saved with validation loss: 6.0030
2025-09-25 21:45:19,727 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-25 21:45:27,547 - training.trainer - INFO - Epoch 5, Step 17014: Loss=5.6943, Acc=0.257, PPL=297.17
2025-09-25 21:45:34,894 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.2177, Acc=0.154, PPL=501.57
2025-09-25 21:45:42,228 - training.trainer - INFO - Epoch 5, Step 17214: Loss=6.5350, Acc=0.174, PPL=688.80
2025-09-25 21:45:49,545 - training.trainer - INFO - Epoch 5, Step 17314: Loss=6.6824, Acc=0.205, PPL=798.22
2025-09-25 21:45:57,074 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.5782, Acc=0.151, PPL=719.27
2025-09-25 21:46:04,452 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.3520, Acc=0.188, PPL=573.62
2025-09-25 21:46:11,684 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.2977, Acc=0.155, PPL=543.30
2025-09-25 21:46:19,070 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.1332, Acc=0.182, PPL=460.92
2025-09-25 21:46:26,384 - training.trainer - INFO - Epoch 5, Step 17814: Loss=6.4376, Acc=0.178, PPL=624.93
2025-09-25 21:46:33,802 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.2535, Acc=0.167, PPL=519.83
2025-09-25 21:46:41,091 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.9625, Acc=0.200, PPL=1056.22
2025-09-25 21:46:48,395 - training.trainer - INFO - Epoch 5, Step 18114: Loss=5.9738, Acc=0.163, PPL=393.02
2025-09-25 21:46:55,751 - training.trainer - INFO - Epoch 5, Step 18214: Loss=5.2692, Acc=0.250, PPL=194.26
2025-09-25 21:47:03,085 - training.trainer - INFO - Epoch 5, Step 18314: Loss=5.6250, Acc=0.143, PPL=277.27
2025-09-25 21:47:10,483 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.8817, Acc=0.125, PPL=358.43
2025-09-25 21:47:17,763 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.4852, Acc=0.082, PPL=655.34
2025-09-25 21:47:25,121 - training.trainer - INFO - Epoch 5, Step 18614: Loss=6.2948, Acc=0.220, PPL=541.73
2025-09-25 21:47:32,373 - training.trainer - INFO - Epoch 5, Step 18714: Loss=6.3797, Acc=0.194, PPL=589.78
2025-09-25 21:47:39,771 - training.trainer - INFO - Epoch 5, Step 18814: Loss=5.7630, Acc=0.231, PPL=318.30
2025-09-25 21:47:47,080 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.2253, Acc=0.118, PPL=505.37
2025-09-25 21:47:54,460 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.3250, Acc=0.111, PPL=558.35
2025-09-25 21:48:01,848 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.6876, Acc=0.100, PPL=802.36
2025-09-25 21:48:09,294 - training.trainer - INFO - Epoch 5, Step 19214: Loss=5.7286, Acc=0.292, PPL=307.54
2025-09-25 21:48:16,746 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.6603, Acc=0.140, PPL=780.75
2025-09-25 21:48:23,764 - training.trainer - INFO - Epoch 5, Step 19414: Loss=5.8786, Acc=0.119, PPL=357.32
2025-09-25 21:48:31,007 - training.trainer - INFO - Epoch 5, Step 19514: Loss=5.5006, Acc=0.227, PPL=244.83
2025-09-25 21:48:38,374 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.1505, Acc=0.178, PPL=468.96
2025-09-25 21:48:41,784 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-25 21:48:41,801 - __main__ - INFO - Process completed!
2025-09-25 21:48:45,789 - training.trainer - INFO - Epoch 5, Step 19714: Loss=6.5080, Acc=0.185, PPL=670.46
2025-09-25 21:48:53,374 - training.trainer - INFO - Epoch 5, Step 19814: Loss=5.6572, Acc=0.316, PPL=286.33
2025-09-25 21:49:01,018 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.9949, Acc=0.250, PPL=401.36
2025-09-25 21:49:08,602 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.5218, Acc=0.200, PPL=679.82
2025-09-25 21:49:16,127 - training.trainer - INFO - Epoch 5, Step 20114: Loss=6.8577, Acc=0.167, PPL=951.17
2025-09-25 21:49:23,640 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.5303, Acc=0.200, PPL=685.62
2025-09-25 21:49:42,205 - training.trainer - INFO - Epoch 6/100 completed in 262.48s - Train Loss: 6.0368, Train Acc: 0.200, Val Loss: 5.9709, Val Acc: 0.207
2025-09-25 21:49:42,901 - training.trainer - INFO - New best model saved with validation loss: 5.9709
2025-09-25 21:49:42,902 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-25 21:49:50,959 - training.trainer - INFO - Epoch 6, Step 20397: Loss=5.3809, Acc=0.241, PPL=217.22
2025-09-25 21:49:58,539 - training.trainer - INFO - Epoch 6, Step 20497: Loss=6.7022, Acc=0.155, PPL=814.23
2025-09-25 21:50:06,106 - training.trainer - INFO - Epoch 6, Step 20597: Loss=6.5626, Acc=0.137, PPL=708.12
2025-09-25 21:50:13,695 - training.trainer - INFO - Epoch 6, Step 20697: Loss=5.2378, Acc=0.152, PPL=188.25
2025-09-25 21:50:19,295 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-25 21:50:19,295 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-25 21:50:19,295 - __main__ - INFO - Starting model evaluation
2025-09-25 21:50:20,326 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-25 21:50:21,412 - training.trainer - INFO - Epoch 6, Step 20797: Loss=6.2328, Acc=0.190, PPL=509.20
2025-09-25 21:50:28,918 - training.trainer - INFO - Epoch 6, Step 20897: Loss=5.8150, Acc=0.190, PPL=335.29
2025-09-25 21:50:36,267 - training.trainer - INFO - Epoch 6, Step 20997: Loss=6.4546, Acc=0.316, PPL=635.65
2025-09-25 21:50:43,788 - training.trainer - INFO - Epoch 6, Step 21097: Loss=5.7550, Acc=0.222, PPL=315.75
2025-09-25 21:50:51,308 - training.trainer - INFO - Epoch 6, Step 21197: Loss=5.8619, Acc=0.214, PPL=351.40
2025-09-25 21:50:58,905 - training.trainer - INFO - Epoch 6, Step 21297: Loss=6.1961, Acc=0.205, PPL=490.82
2025-09-25 21:51:06,187 - training.trainer - INFO - Epoch 6, Step 21397: Loss=5.7768, Acc=0.175, PPL=322.71
2025-09-25 21:51:13,474 - training.trainer - INFO - Epoch 6, Step 21497: Loss=5.8905, Acc=0.179, PPL=361.57
2025-09-25 21:51:20,737 - training.trainer - INFO - Epoch 6, Step 21597: Loss=6.4412, Acc=0.093, PPL=627.18
2025-09-25 21:51:28,037 - training.trainer - INFO - Epoch 6, Step 21697: Loss=5.9981, Acc=0.224, PPL=402.67
2025-09-25 21:51:35,293 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.3644, Acc=0.163, PPL=580.77
2025-09-25 21:51:42,517 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.3941, Acc=0.152, PPL=598.31
2025-09-25 21:51:49,743 - training.trainer - INFO - Epoch 6, Step 21997: Loss=6.3906, Acc=0.207, PPL=596.22
2025-09-25 21:51:57,026 - training.trainer - INFO - Epoch 6, Step 22097: Loss=6.2922, Acc=0.143, PPL=540.35
2025-09-25 21:52:04,468 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.0659, Acc=0.169, PPL=430.90
2025-09-25 21:52:11,973 - training.trainer - INFO - Epoch 6, Step 22297: Loss=5.0719, Acc=0.375, PPL=159.48
2025-09-25 21:52:19,291 - training.trainer - INFO - Epoch 6, Step 22397: Loss=5.8358, Acc=0.160, PPL=342.32
2025-09-25 21:52:26,531 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.0414, Acc=0.211, PPL=420.50
2025-09-25 21:52:33,998 - training.trainer - INFO - Epoch 6, Step 22597: Loss=5.7104, Acc=0.308, PPL=302.00
2025-09-25 21:52:41,178 - training.trainer - INFO - Epoch 6, Step 22697: Loss=5.4863, Acc=0.276, PPL=241.37
2025-09-25 21:52:48,394 - training.trainer - INFO - Epoch 6, Step 22797: Loss=5.1781, Acc=0.353, PPL=177.35
2025-09-25 21:52:55,571 - training.trainer - INFO - Epoch 6, Step 22897: Loss=6.4659, Acc=0.138, PPL=642.86
2025-09-25 21:53:03,215 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.4582, Acc=0.156, PPL=637.92
2025-09-25 21:53:10,785 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.5769, Acc=0.121, PPL=718.30
2025-09-25 21:53:18,061 - training.trainer - INFO - Epoch 6, Step 23197: Loss=6.6448, Acc=0.140, PPL=768.75
2025-09-25 21:53:25,359 - training.trainer - INFO - Epoch 6, Step 23297: Loss=6.2766, Acc=0.154, PPL=531.96
2025-09-25 21:53:32,667 - training.trainer - INFO - Epoch 6, Step 23397: Loss=5.2205, Acc=0.312, PPL=185.03
2025-09-25 21:53:40,074 - training.trainer - INFO - Epoch 6, Step 23497: Loss=5.9639, Acc=0.375, PPL=389.13
2025-09-25 21:53:47,303 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.3588, Acc=0.129, PPL=577.58
2025-09-25 21:54:06,503 - training.trainer - INFO - Epoch 7/100 completed in 263.60s - Train Loss: 5.9908, Train Acc: 0.207, Val Loss: 5.9182, Val Acc: 0.213
2025-09-25 21:54:07,200 - training.trainer - INFO - New best model saved with validation loss: 5.9182
2025-09-25 21:54:07,200 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-25 21:54:15,084 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.0567, Acc=0.133, PPL=426.98
2025-09-25 21:54:22,443 - training.trainer - INFO - Epoch 7, Step 23880: Loss=5.9599, Acc=0.216, PPL=387.56
2025-09-25 21:54:29,712 - training.trainer - INFO - Epoch 7, Step 23980: Loss=6.2764, Acc=0.140, PPL=531.85
2025-09-25 21:54:37,086 - training.trainer - INFO - Epoch 7, Step 24080: Loss=5.6708, Acc=0.241, PPL=290.28
2025-09-25 21:54:44,564 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.4798, Acc=0.182, PPL=239.80
2025-09-25 21:54:51,949 - training.trainer - INFO - Epoch 7, Step 24280: Loss=5.2757, Acc=0.250, PPL=195.53
2025-09-25 21:54:59,363 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.7068, Acc=0.115, PPL=817.95
2025-09-25 21:55:06,764 - training.trainer - INFO - Epoch 7, Step 24480: Loss=5.9997, Acc=0.209, PPL=403.29
2025-09-25 21:55:13,987 - training.trainer - INFO - Epoch 7, Step 24580: Loss=5.8869, Acc=0.314, PPL=360.29
2025-09-25 21:55:21,354 - training.trainer - INFO - Epoch 7, Step 24680: Loss=5.4873, Acc=0.259, PPL=241.60
2025-09-25 21:55:28,688 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.7458, Acc=0.103, PPL=850.51
2025-09-25 21:55:36,021 - training.trainer - INFO - Epoch 7, Step 24880: Loss=4.5321, Acc=0.400, PPL=92.96
2025-09-25 21:55:43,560 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.7021, Acc=0.239, PPL=299.49
2025-09-25 21:55:51,195 - training.trainer - INFO - Epoch 7, Step 25080: Loss=6.2397, Acc=0.222, PPL=512.70
2025-09-25 21:55:58,680 - training.trainer - INFO - Epoch 7, Step 25180: Loss=6.0612, Acc=0.163, PPL=428.87
2025-09-25 21:56:06,236 - training.trainer - INFO - Epoch 7, Step 25280: Loss=6.6497, Acc=0.157, PPL=772.56
2025-09-25 21:56:13,781 - training.trainer - INFO - Epoch 7, Step 25380: Loss=5.3036, Acc=0.275, PPL=201.06
2025-09-25 21:56:21,243 - training.trainer - INFO - Epoch 7, Step 25480: Loss=6.3944, Acc=0.131, PPL=598.51
2025-09-25 21:56:28,901 - training.trainer - INFO - Epoch 7, Step 25580: Loss=5.9604, Acc=0.197, PPL=387.78
2025-09-25 21:56:36,527 - training.trainer - INFO - Epoch 7, Step 25680: Loss=5.9812, Acc=0.238, PPL=395.91
2025-09-25 21:56:44,044 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.3578, Acc=0.241, PPL=576.96
2025-09-25 21:56:51,539 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.3893, Acc=0.114, PPL=595.45
2025-09-25 21:56:59,087 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.4874, Acc=0.111, PPL=656.78
2025-09-25 21:57:06,735 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.3173, Acc=0.159, PPL=554.10
2025-09-25 21:57:14,186 - training.trainer - INFO - Epoch 7, Step 26180: Loss=5.2902, Acc=0.444, PPL=198.39
2025-09-25 21:57:21,608 - training.trainer - INFO - Epoch 7, Step 26280: Loss=6.2592, Acc=0.148, PPL=522.80
2025-09-25 21:57:29,131 - training.trainer - INFO - Epoch 7, Step 26380: Loss=7.0316, Acc=0.130, PPL=1131.89
2025-09-25 21:57:36,552 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.5424, Acc=0.231, PPL=693.95
2025-09-25 21:57:43,936 - training.trainer - INFO - Epoch 7, Step 26580: Loss=6.0081, Acc=0.192, PPL=406.71
2025-09-25 21:57:51,465 - training.trainer - INFO - Epoch 7, Step 26680: Loss=5.4969, Acc=0.320, PPL=243.95
2025-09-25 21:57:58,973 - training.trainer - INFO - Epoch 7, Step 26780: Loss=6.2909, Acc=0.333, PPL=539.63
2025-09-25 21:58:06,661 - training.trainer - INFO - Epoch 7, Step 26880: Loss=5.1611, Acc=0.292, PPL=174.36
2025-09-25 21:58:14,209 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.7272, Acc=0.208, PPL=307.12
2025-09-25 21:58:32,872 - training.trainer - INFO - Epoch 8/100 completed in 265.67s - Train Loss: 5.9471, Train Acc: 0.213, Val Loss: 5.8954, Val Acc: 0.219
2025-09-25 21:58:33,565 - training.trainer - INFO - New best model saved with validation loss: 5.8954
2025-09-25 21:58:33,565 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-09-25 21:58:41,561 - training.trainer - INFO - Epoch 8, Step 27163: Loss=5.7446, Acc=0.200, PPL=312.50
2025-09-25 21:58:48,950 - training.trainer - INFO - Epoch 8, Step 27263: Loss=5.6939, Acc=0.250, PPL=297.04
2025-09-25 21:58:56,395 - training.trainer - INFO - Epoch 8, Step 27363: Loss=6.4430, Acc=0.179, PPL=628.26
2025-09-25 21:59:03,967 - training.trainer - INFO - Epoch 8, Step 27463: Loss=5.6159, Acc=0.208, PPL=274.76
2025-09-25 21:59:11,496 - training.trainer - INFO - Epoch 8, Step 27563: Loss=4.1657, Acc=0.545, PPL=64.44
2025-09-25 21:59:18,858 - training.trainer - INFO - Epoch 8, Step 27663: Loss=6.0253, Acc=0.185, PPL=413.75
2025-09-25 21:59:26,361 - training.trainer - INFO - Epoch 8, Step 27763: Loss=6.3448, Acc=0.109, PPL=569.52
2025-09-25 21:59:33,931 - training.trainer - INFO - Epoch 8, Step 27863: Loss=5.6898, Acc=0.229, PPL=295.82
2025-09-25 21:59:41,537 - training.trainer - INFO - Epoch 8, Step 27963: Loss=4.4928, Acc=0.429, PPL=89.37
2025-09-25 21:59:49,004 - training.trainer - INFO - Epoch 8, Step 28063: Loss=5.8902, Acc=0.200, PPL=361.49
2025-09-25 21:59:56,564 - training.trainer - INFO - Epoch 8, Step 28163: Loss=5.8915, Acc=0.176, PPL=361.96
2025-09-25 22:00:04,224 - training.trainer - INFO - Epoch 8, Step 28263: Loss=5.5622, Acc=0.320, PPL=260.40
2025-09-25 22:00:11,546 - training.trainer - INFO - Epoch 8, Step 28363: Loss=6.5146, Acc=0.155, PPL=674.93
2025-09-25 22:00:18,930 - training.trainer - INFO - Epoch 8, Step 28463: Loss=6.5096, Acc=0.148, PPL=671.56
2025-09-25 22:00:26,253 - training.trainer - INFO - Epoch 8, Step 28563: Loss=6.9215, Acc=0.222, PPL=1013.83
2025-09-25 22:00:33,618 - training.trainer - INFO - Epoch 8, Step 28663: Loss=5.9835, Acc=0.130, PPL=396.83
2025-09-25 22:00:40,957 - training.trainer - INFO - Epoch 8, Step 28763: Loss=4.4033, Acc=0.433, PPL=81.72
2025-09-25 22:00:48,366 - training.trainer - INFO - Epoch 8, Step 28863: Loss=6.2582, Acc=0.164, PPL=522.29
2025-09-25 22:00:55,738 - training.trainer - INFO - Epoch 8, Step 28963: Loss=6.4696, Acc=0.153, PPL=645.26
2025-09-25 22:01:03,068 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.4128, Acc=0.189, PPL=609.60
2025-09-25 22:01:10,391 - training.trainer - INFO - Epoch 8, Step 29163: Loss=5.7138, Acc=0.211, PPL=303.02
2025-09-25 22:01:17,801 - training.trainer - INFO - Epoch 8, Step 29263: Loss=5.8722, Acc=0.212, PPL=355.02
2025-09-25 22:01:25,176 - training.trainer - INFO - Epoch 8, Step 29363: Loss=6.1595, Acc=0.206, PPL=473.19
2025-09-25 22:01:32,539 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.4404, Acc=0.200, PPL=626.68
2025-09-25 22:01:39,899 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.0696, Acc=0.225, PPL=159.12
2025-09-25 22:01:47,308 - training.trainer - INFO - Epoch 8, Step 29663: Loss=6.5054, Acc=0.176, PPL=668.73
2025-09-25 22:01:54,793 - training.trainer - INFO - Epoch 8, Step 29763: Loss=5.6839, Acc=0.250, PPL=294.09
2025-09-25 22:02:02,147 - training.trainer - INFO - Epoch 8, Step 29863: Loss=5.3615, Acc=0.323, PPL=213.04
2025-09-25 22:02:09,432 - training.trainer - INFO - Epoch 8, Step 29963: Loss=5.8222, Acc=0.250, PPL=337.70
2025-09-25 22:02:16,818 - training.trainer - INFO - Epoch 8, Step 30063: Loss=5.5902, Acc=0.219, PPL=267.79
2025-09-25 22:02:24,283 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.0611, Acc=0.214, PPL=157.76
2025-09-25 22:02:31,656 - training.trainer - INFO - Epoch 8, Step 30263: Loss=6.3849, Acc=0.209, PPL=592.81
2025-09-25 22:02:38,967 - training.trainer - INFO - Epoch 8, Step 30363: Loss=6.0791, Acc=0.263, PPL=436.64
2025-09-25 22:02:57,648 - training.trainer - INFO - Epoch 9/100 completed in 264.08s - Train Loss: 5.9177, Train Acc: 0.218, Val Loss: 5.8786, Val Acc: 0.221
2025-09-25 22:02:58,471 - training.trainer - INFO - New best model saved with validation loss: 5.8786
2025-09-25 22:02:58,471 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-25 22:03:06,301 - training.trainer - INFO - Epoch 9, Step 30546: Loss=6.5753, Acc=0.178, PPL=717.15
2025-09-25 22:03:13,317 - training.trainer - INFO - Epoch 9, Step 30646: Loss=4.7216, Acc=0.429, PPL=112.35
2025-09-25 22:03:20,318 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.4658, Acc=0.206, PPL=642.75
2025-09-25 22:03:27,665 - training.trainer - INFO - Epoch 9, Step 30846: Loss=6.1293, Acc=0.275, PPL=459.11
2025-09-25 22:03:35,331 - training.trainer - INFO - Epoch 9, Step 30946: Loss=6.0443, Acc=0.233, PPL=421.70
2025-09-25 22:03:42,941 - training.trainer - INFO - Epoch 9, Step 31046: Loss=6.1345, Acc=0.133, PPL=461.49
2025-09-25 22:03:50,396 - training.trainer - INFO - Epoch 9, Step 31146: Loss=5.8928, Acc=0.167, PPL=362.43
2025-09-25 22:03:57,938 - training.trainer - INFO - Epoch 9, Step 31246: Loss=5.5851, Acc=0.190, PPL=266.43
2025-09-25 22:04:05,495 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.1613, Acc=0.200, PPL=474.03
2025-09-25 22:04:13,112 - training.trainer - INFO - Epoch 9, Step 31446: Loss=5.8737, Acc=0.175, PPL=355.55
2025-09-25 22:04:20,654 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.4341, Acc=0.328, PPL=229.08
2025-09-25 22:04:28,146 - training.trainer - INFO - Epoch 9, Step 31646: Loss=6.0660, Acc=0.158, PPL=430.96
2025-09-25 22:04:35,656 - training.trainer - INFO - Epoch 9, Step 31746: Loss=4.9921, Acc=0.382, PPL=147.24
2025-09-25 22:04:43,004 - training.trainer - INFO - Epoch 9, Step 31846: Loss=4.7202, Acc=0.375, PPL=112.19
2025-09-25 22:04:50,455 - training.trainer - INFO - Epoch 9, Step 31946: Loss=6.3696, Acc=0.188, PPL=583.82
2025-09-25 22:04:57,881 - training.trainer - INFO - Epoch 9, Step 32046: Loss=5.8091, Acc=0.233, PPL=333.31
2025-09-25 22:05:05,359 - training.trainer - INFO - Epoch 9, Step 32146: Loss=6.4686, Acc=0.278, PPL=644.58
2025-09-25 22:05:12,922 - training.trainer - INFO - Epoch 9, Step 32246: Loss=6.3646, Acc=0.214, PPL=580.93
2025-09-25 22:05:20,359 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.7316, Acc=0.242, PPL=308.46
2025-09-25 22:05:27,791 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.9775, Acc=0.208, PPL=394.46
2025-09-25 22:05:35,301 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.7849, Acc=0.276, PPL=325.36
2025-09-25 22:05:42,998 - training.trainer - INFO - Epoch 9, Step 32646: Loss=4.3468, Acc=0.421, PPL=77.23
2025-09-25 22:05:50,517 - training.trainer - INFO - Epoch 9, Step 32746: Loss=6.1687, Acc=0.191, PPL=477.57
2025-09-25 22:05:57,878 - training.trainer - INFO - Epoch 9, Step 32846: Loss=5.8664, Acc=0.200, PPL=352.96
2025-09-25 22:06:05,268 - training.trainer - INFO - Epoch 9, Step 32946: Loss=5.5943, Acc=0.286, PPL=268.90
2025-09-25 22:06:12,797 - training.trainer - INFO - Epoch 9, Step 33046: Loss=6.2742, Acc=0.147, PPL=530.71
2025-09-25 22:06:20,145 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.4033, Acc=0.115, PPL=603.85
2025-09-25 22:06:27,493 - training.trainer - INFO - Epoch 9, Step 33246: Loss=5.8573, Acc=0.178, PPL=349.76
2025-09-25 22:06:34,816 - training.trainer - INFO - Epoch 9, Step 33346: Loss=5.8419, Acc=0.173, PPL=344.42
2025-09-25 22:06:42,153 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.4119, Acc=0.167, PPL=609.07
2025-09-25 22:06:49,704 - training.trainer - INFO - Epoch 9, Step 33546: Loss=5.5159, Acc=0.194, PPL=248.61
2025-09-25 22:06:57,110 - training.trainer - INFO - Epoch 9, Step 33646: Loss=5.9659, Acc=0.154, PPL=389.92
2025-09-25 22:07:04,497 - training.trainer - INFO - Epoch 9, Step 33746: Loss=5.7538, Acc=0.138, PPL=315.38
2025-09-25 22:07:22,998 - training.trainer - INFO - Epoch 10/100 completed in 264.53s - Train Loss: 5.8796, Train Acc: 0.223, Val Loss: 5.8291, Val Acc: 0.225
2025-09-25 22:07:23,374 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-25 22:07:24,074 - training.trainer - INFO - New best model saved with validation loss: 5.8291
2025-09-25 22:07:24,074 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-25 22:07:31,122 - training.trainer - INFO - Epoch 10, Step 33929: Loss=6.1111, Acc=0.190, PPL=450.83
2025-09-25 22:07:38,319 - training.trainer - INFO - Epoch 10, Step 34029: Loss=6.2371, Acc=0.129, PPL=511.35
2025-09-25 22:07:45,874 - training.trainer - INFO - Epoch 10, Step 34129: Loss=6.7495, Acc=0.185, PPL=853.59
2025-09-25 22:07:53,550 - training.trainer - INFO - Epoch 10, Step 34229: Loss=6.4169, Acc=0.148, PPL=612.13
2025-09-25 22:08:00,871 - training.trainer - INFO - Epoch 10, Step 34329: Loss=6.7841, Acc=0.078, PPL=883.64
2025-09-25 22:08:08,290 - training.trainer - INFO - Epoch 10, Step 34429: Loss=6.3671, Acc=0.179, PPL=582.36
2025-09-25 22:08:15,976 - training.trainer - INFO - Epoch 10, Step 34529: Loss=5.9889, Acc=0.180, PPL=398.99
2025-09-25 22:08:23,422 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.4462, Acc=0.286, PPL=231.88
2025-09-25 22:08:30,911 - training.trainer - INFO - Epoch 10, Step 34729: Loss=5.8521, Acc=0.211, PPL=347.98
2025-09-25 22:08:38,631 - training.trainer - INFO - Epoch 10, Step 34829: Loss=5.5918, Acc=0.250, PPL=268.22
2025-09-25 22:08:46,096 - training.trainer - INFO - Epoch 10, Step 34929: Loss=5.4270, Acc=0.286, PPL=227.47
2025-09-25 22:08:53,534 - training.trainer - INFO - Epoch 10, Step 35029: Loss=5.4203, Acc=0.225, PPL=225.94
2025-09-25 22:09:01,030 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.5254, Acc=0.195, PPL=682.28
2025-09-25 22:09:08,259 - training.trainer - INFO - Epoch 10, Step 35229: Loss=5.9147, Acc=0.183, PPL=370.46
2025-09-25 22:09:15,523 - training.trainer - INFO - Epoch 10, Step 35329: Loss=5.4994, Acc=0.300, PPL=244.54
2025-09-25 22:09:22,868 - training.trainer - INFO - Epoch 10, Step 35429: Loss=5.9116, Acc=0.154, PPL=369.31
2025-09-25 22:09:30,463 - training.trainer - INFO - Epoch 10, Step 35529: Loss=6.4205, Acc=0.216, PPL=614.32
2025-09-25 22:09:37,835 - training.trainer - INFO - Epoch 10, Step 35629: Loss=4.9972, Acc=0.259, PPL=148.00
2025-09-25 22:09:45,240 - training.trainer - INFO - Epoch 10, Step 35729: Loss=5.5268, Acc=0.250, PPL=251.34
2025-09-25 22:09:52,698 - training.trainer - INFO - Epoch 10, Step 35829: Loss=6.2775, Acc=0.203, PPL=532.46
2025-09-25 22:10:00,144 - training.trainer - INFO - Epoch 10, Step 35929: Loss=5.5352, Acc=0.278, PPL=253.46
2025-09-25 22:10:07,653 - training.trainer - INFO - Epoch 10, Step 36029: Loss=5.8139, Acc=0.209, PPL=334.94
2025-09-25 22:10:15,140 - training.trainer - INFO - Epoch 10, Step 36129: Loss=4.6567, Acc=0.333, PPL=105.29
2025-09-25 22:10:22,606 - training.trainer - INFO - Epoch 10, Step 36229: Loss=5.7415, Acc=0.288, PPL=311.52
2025-09-25 22:10:30,263 - training.trainer - INFO - Epoch 10, Step 36329: Loss=5.2248, Acc=0.190, PPL=185.82
2025-09-25 22:10:37,806 - training.trainer - INFO - Epoch 10, Step 36429: Loss=5.4308, Acc=0.250, PPL=228.33
2025-09-25 22:10:45,353 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.5439, Acc=0.265, PPL=255.68
2025-09-25 22:10:52,690 - training.trainer - INFO - Epoch 10, Step 36629: Loss=5.7534, Acc=0.219, PPL=315.25
2025-09-25 22:10:59,961 - training.trainer - INFO - Epoch 10, Step 36729: Loss=6.5516, Acc=0.158, PPL=700.39
2025-09-25 22:11:07,282 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.5344, Acc=0.286, PPL=253.25
2025-09-25 22:11:14,656 - training.trainer - INFO - Epoch 10, Step 36929: Loss=5.7726, Acc=0.189, PPL=321.37
2025-09-25 22:11:21,903 - training.trainer - INFO - Epoch 10, Step 37029: Loss=6.4853, Acc=0.237, PPL=655.46
2025-09-25 22:11:29,156 - training.trainer - INFO - Epoch 10, Step 37129: Loss=5.0826, Acc=0.350, PPL=161.20
2025-09-25 22:11:48,064 - training.trainer - INFO - Epoch 11/100 completed in 263.99s - Train Loss: 5.8433, Train Acc: 0.227, Val Loss: 5.8030, Val Acc: 0.233
2025-09-25 22:11:48,700 - training.trainer - INFO - New best model saved with validation loss: 5.8030
2025-09-25 22:11:48,701 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-25 22:11:55,492 - training.trainer - INFO - Epoch 11, Step 37312: Loss=5.2744, Acc=0.182, PPL=195.27
2025-09-25 22:12:02,693 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.6668, Acc=0.162, PPL=785.86
2025-09-25 22:12:10,211 - training.trainer - INFO - Epoch 11, Step 37512: Loss=6.4341, Acc=0.118, PPL=622.70
2025-09-25 22:12:17,670 - training.trainer - INFO - Epoch 11, Step 37612: Loss=6.4207, Acc=0.225, PPL=614.46
2025-09-25 22:12:24,932 - training.trainer - INFO - Epoch 11, Step 37712: Loss=6.2013, Acc=0.233, PPL=493.41
2025-09-25 22:12:32,430 - training.trainer - INFO - Epoch 11, Step 37812: Loss=5.7297, Acc=0.324, PPL=307.88
2025-09-25 22:12:39,878 - training.trainer - INFO - Epoch 11, Step 37912: Loss=4.2525, Acc=0.462, PPL=70.28
2025-09-25 22:12:47,261 - training.trainer - INFO - Epoch 11, Step 38012: Loss=6.3695, Acc=0.205, PPL=583.76
2025-09-25 22:12:54,546 - training.trainer - INFO - Epoch 11, Step 38112: Loss=5.4405, Acc=0.241, PPL=230.57
2025-09-25 22:13:01,944 - training.trainer - INFO - Epoch 11, Step 38212: Loss=5.8826, Acc=0.278, PPL=358.73
2025-09-25 22:13:09,208 - training.trainer - INFO - Epoch 11, Step 38312: Loss=5.7458, Acc=0.323, PPL=312.88
2025-09-25 22:13:16,432 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.6332, Acc=0.233, PPL=279.55
2025-09-25 22:13:23,802 - training.trainer - INFO - Epoch 11, Step 38512: Loss=6.4178, Acc=0.200, PPL=612.68
2025-09-25 22:13:31,413 - training.trainer - INFO - Epoch 11, Step 38612: Loss=6.5126, Acc=0.143, PPL=673.57
2025-09-25 22:13:38,988 - training.trainer - INFO - Epoch 11, Step 38712: Loss=6.4841, Acc=0.130, PPL=654.62
2025-09-25 22:13:46,425 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.8854, Acc=0.170, PPL=359.74
2025-09-25 22:13:53,870 - training.trainer - INFO - Epoch 11, Step 38912: Loss=4.8183, Acc=0.414, PPL=123.75
2025-09-25 22:14:01,243 - training.trainer - INFO - Epoch 11, Step 39012: Loss=6.5071, Acc=0.089, PPL=669.89
2025-09-25 22:14:08,531 - training.trainer - INFO - Epoch 11, Step 39112: Loss=6.1204, Acc=0.268, PPL=455.04
2025-09-25 22:14:15,847 - training.trainer - INFO - Epoch 11, Step 39212: Loss=5.2218, Acc=0.194, PPL=185.26
2025-09-25 22:14:23,161 - training.trainer - INFO - Epoch 11, Step 39312: Loss=5.5542, Acc=0.250, PPL=258.33
2025-09-25 22:14:30,631 - training.trainer - INFO - Epoch 11, Step 39412: Loss=6.4071, Acc=0.167, PPL=606.16
2025-09-25 22:14:38,230 - training.trainer - INFO - Epoch 11, Step 39512: Loss=6.1355, Acc=0.184, PPL=461.97
2025-09-25 22:14:45,673 - training.trainer - INFO - Epoch 11, Step 39612: Loss=6.7810, Acc=0.240, PPL=880.97
2025-09-25 22:14:53,080 - training.trainer - INFO - Epoch 11, Step 39712: Loss=5.4976, Acc=0.207, PPL=244.10
2025-09-25 22:15:00,607 - training.trainer - INFO - Epoch 11, Step 39812: Loss=6.1917, Acc=0.167, PPL=488.68
2025-09-25 22:15:08,026 - training.trainer - INFO - Epoch 11, Step 39912: Loss=5.6575, Acc=0.211, PPL=286.44
2025-09-25 22:15:15,546 - training.trainer - INFO - Epoch 11, Step 40012: Loss=5.9308, Acc=0.260, PPL=376.44
2025-09-25 22:15:22,921 - training.trainer - INFO - Epoch 11, Step 40112: Loss=6.1647, Acc=0.177, PPL=475.68
2025-09-25 22:15:30,593 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.2443, Acc=0.333, PPL=189.48
2025-09-25 22:15:38,061 - training.trainer - INFO - Epoch 11, Step 40312: Loss=6.2015, Acc=0.217, PPL=493.49
2025-09-25 22:15:45,471 - training.trainer - INFO - Epoch 11, Step 40412: Loss=6.0674, Acc=0.174, PPL=431.56
2025-09-25 22:15:52,948 - training.trainer - INFO - Epoch 11, Step 40512: Loss=6.2044, Acc=0.208, PPL=494.90
2025-09-25 22:16:11,749 - training.trainer - INFO - Epoch 12/100 completed in 263.05s - Train Loss: 5.8238, Train Acc: 0.231, Val Loss: 5.7984, Val Acc: 0.231
2025-09-25 22:16:12,460 - training.trainer - INFO - New best model saved with validation loss: 5.7984
2025-09-25 22:16:12,461 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-09-25 22:16:20,161 - training.trainer - INFO - Epoch 12, Step 40695: Loss=5.9977, Acc=0.244, PPL=402.48
2025-09-25 22:16:27,594 - training.trainer - INFO - Epoch 12, Step 40795: Loss=5.9376, Acc=0.217, PPL=379.03
2025-09-25 22:16:34,943 - training.trainer - INFO - Epoch 12, Step 40895: Loss=6.4112, Acc=0.263, PPL=608.63
2025-09-25 22:16:42,568 - training.trainer - INFO - Epoch 12, Step 40995: Loss=6.3644, Acc=0.143, PPL=580.82
2025-09-25 22:16:49,943 - training.trainer - INFO - Epoch 12, Step 41095: Loss=5.5795, Acc=0.184, PPL=264.95
2025-09-25 22:16:57,415 - training.trainer - INFO - Epoch 12, Step 41195: Loss=6.1975, Acc=0.172, PPL=491.51
2025-09-25 22:17:04,831 - training.trainer - INFO - Epoch 12, Step 41295: Loss=6.0563, Acc=0.151, PPL=426.80
2025-09-25 22:17:12,318 - training.trainer - INFO - Epoch 12, Step 41395: Loss=5.1995, Acc=0.375, PPL=181.18
2025-09-25 22:17:19,731 - training.trainer - INFO - Epoch 12, Step 41495: Loss=4.0704, Acc=0.389, PPL=58.58
2025-09-25 22:17:27,161 - training.trainer - INFO - Epoch 12, Step 41595: Loss=6.1168, Acc=0.308, PPL=453.42
2025-09-25 22:17:34,546 - training.trainer - INFO - Epoch 12, Step 41695: Loss=6.1443, Acc=0.105, PPL=466.04
2025-09-25 22:17:42,241 - training.trainer - INFO - Epoch 12, Step 41795: Loss=6.4396, Acc=0.138, PPL=626.16
2025-09-25 22:17:49,574 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.0623, Acc=0.173, PPL=429.37
2025-09-25 22:17:56,969 - training.trainer - INFO - Epoch 12, Step 41995: Loss=5.5597, Acc=0.258, PPL=259.74
2025-09-25 22:18:04,463 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.7638, Acc=0.139, PPL=865.89
2025-09-25 22:18:11,991 - training.trainer - INFO - Epoch 12, Step 42195: Loss=6.4693, Acc=0.197, PPL=645.04
2025-09-25 22:18:19,657 - training.trainer - INFO - Epoch 12, Step 42295: Loss=6.5888, Acc=0.167, PPL=726.88
2025-09-25 22:18:27,220 - training.trainer - INFO - Epoch 12, Step 42395: Loss=5.3724, Acc=0.256, PPL=215.37
2025-09-25 22:18:34,742 - training.trainer - INFO - Epoch 12, Step 42495: Loss=5.4737, Acc=0.167, PPL=238.35
2025-09-25 22:18:42,271 - training.trainer - INFO - Epoch 12, Step 42595: Loss=5.6259, Acc=0.256, PPL=277.51
2025-09-25 22:18:50,018 - training.trainer - INFO - Epoch 12, Step 42695: Loss=6.9719, Acc=0.182, PPL=1066.19
2025-09-25 22:18:57,618 - training.trainer - INFO - Epoch 12, Step 42795: Loss=6.4591, Acc=0.222, PPL=638.50
2025-09-25 22:19:05,191 - training.trainer - INFO - Epoch 12, Step 42895: Loss=5.1492, Acc=0.250, PPL=172.30
2025-09-25 22:19:12,570 - training.trainer - INFO - Epoch 12, Step 42995: Loss=6.0978, Acc=0.205, PPL=444.90
2025-09-25 22:19:20,180 - training.trainer - INFO - Epoch 12, Step 43095: Loss=5.2643, Acc=0.316, PPL=193.31
2025-09-25 22:19:27,889 - training.trainer - INFO - Epoch 12, Step 43195: Loss=5.9965, Acc=0.140, PPL=402.01
2025-09-25 22:19:35,292 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.0012, Acc=0.139, PPL=403.93
2025-09-25 22:19:42,556 - training.trainer - INFO - Epoch 12, Step 43395: Loss=5.7669, Acc=0.271, PPL=319.55
2025-09-25 22:19:50,111 - training.trainer - INFO - Epoch 12, Step 43495: Loss=5.8543, Acc=0.229, PPL=348.72
2025-09-25 22:19:57,661 - training.trainer - INFO - Epoch 12, Step 43595: Loss=6.3240, Acc=0.206, PPL=557.78
2025-09-25 22:20:05,284 - training.trainer - INFO - Epoch 12, Step 43695: Loss=6.6571, Acc=0.172, PPL=778.28
2025-09-25 22:20:12,903 - training.trainer - INFO - Epoch 12, Step 43795: Loss=5.8736, Acc=0.200, PPL=355.54
2025-09-25 22:20:20,456 - training.trainer - INFO - Epoch 12, Step 43895: Loss=5.1486, Acc=0.261, PPL=172.19
2025-09-25 22:20:39,668 - training.trainer - INFO - Epoch 13/100 completed in 267.21s - Train Loss: 5.7944, Train Acc: 0.236, Val Loss: 5.7783, Val Acc: 0.237
2025-09-25 22:20:40,378 - training.trainer - INFO - New best model saved with validation loss: 5.7783
2025-09-25 22:20:40,378 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-25 22:20:48,015 - training.trainer - INFO - Epoch 13, Step 44078: Loss=5.6081, Acc=0.206, PPL=272.62
2025-09-25 22:20:55,469 - training.trainer - INFO - Epoch 13, Step 44178: Loss=5.6175, Acc=0.246, PPL=275.19
2025-09-25 22:21:03,037 - training.trainer - INFO - Epoch 13, Step 44278: Loss=6.1602, Acc=0.186, PPL=473.53
2025-09-25 22:21:10,598 - training.trainer - INFO - Epoch 13, Step 44378: Loss=5.4915, Acc=0.200, PPL=242.63
2025-09-25 22:21:18,056 - training.trainer - INFO - Epoch 13, Step 44478: Loss=6.2686, Acc=0.177, PPL=527.72
2025-09-25 22:21:25,455 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.5934, Acc=0.237, PPL=268.64
2025-09-25 22:21:33,041 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.5581, Acc=0.240, PPL=259.33
2025-09-25 22:21:40,392 - training.trainer - INFO - Epoch 13, Step 44778: Loss=5.9486, Acc=0.286, PPL=383.23
2025-09-25 22:21:47,726 - training.trainer - INFO - Epoch 13, Step 44878: Loss=6.0989, Acc=0.189, PPL=445.38
2025-09-25 22:21:55,222 - training.trainer - INFO - Epoch 13, Step 44978: Loss=5.7200, Acc=0.256, PPL=304.92
2025-09-25 22:22:02,625 - training.trainer - INFO - Epoch 13, Step 45078: Loss=5.2617, Acc=0.222, PPL=192.81
2025-09-25 22:22:10,139 - training.trainer - INFO - Epoch 13, Step 45178: Loss=5.7164, Acc=0.170, PPL=303.80
2025-09-25 22:22:17,521 - training.trainer - INFO - Epoch 13, Step 45278: Loss=4.9879, Acc=0.304, PPL=146.62
2025-09-25 22:22:24,865 - training.trainer - INFO - Epoch 13, Step 45378: Loss=5.4627, Acc=0.267, PPL=235.74
2025-09-25 22:22:32,219 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.7661, Acc=0.231, PPL=319.28
2025-09-25 22:22:39,653 - training.trainer - INFO - Epoch 13, Step 45578: Loss=5.5069, Acc=0.263, PPL=246.37
2025-09-25 22:22:47,026 - training.trainer - INFO - Epoch 13, Step 45678: Loss=4.9909, Acc=0.308, PPL=147.06
2025-09-25 22:22:54,415 - training.trainer - INFO - Epoch 13, Step 45778: Loss=6.3289, Acc=0.180, PPL=560.56
2025-09-25 22:23:01,870 - training.trainer - INFO - Epoch 13, Step 45878: Loss=5.9635, Acc=0.154, PPL=388.96
2025-09-25 22:23:09,427 - training.trainer - INFO - Epoch 13, Step 45978: Loss=5.9847, Acc=0.200, PPL=397.31
2025-09-25 22:23:16,864 - training.trainer - INFO - Epoch 13, Step 46078: Loss=5.8946, Acc=0.200, PPL=363.09
2025-09-25 22:23:24,456 - training.trainer - INFO - Epoch 13, Step 46178: Loss=6.5774, Acc=0.155, PPL=718.65
2025-09-25 22:23:31,912 - training.trainer - INFO - Epoch 13, Step 46278: Loss=6.4178, Acc=0.160, PPL=612.65
2025-09-25 22:23:39,413 - training.trainer - INFO - Epoch 13, Step 46378: Loss=5.7846, Acc=0.164, PPL=325.25
2025-09-25 22:23:47,041 - training.trainer - INFO - Epoch 13, Step 46478: Loss=6.1550, Acc=0.273, PPL=471.09
2025-09-25 22:23:54,383 - training.trainer - INFO - Epoch 13, Step 46578: Loss=4.0174, Acc=0.421, PPL=55.55
2025-09-25 22:24:01,870 - training.trainer - INFO - Epoch 13, Step 46678: Loss=5.2725, Acc=0.357, PPL=194.89
2025-09-25 22:24:09,386 - training.trainer - INFO - Epoch 13, Step 46778: Loss=5.8812, Acc=0.167, PPL=358.25
2025-09-25 22:24:16,964 - training.trainer - INFO - Epoch 13, Step 46878: Loss=5.8174, Acc=0.212, PPL=336.09
2025-09-25 22:24:24,383 - training.trainer - INFO - Epoch 13, Step 46978: Loss=5.7867, Acc=0.283, PPL=325.93
2025-09-25 22:24:31,869 - training.trainer - INFO - Epoch 13, Step 47078: Loss=6.0454, Acc=0.139, PPL=422.17
2025-09-25 22:24:39,342 - training.trainer - INFO - Epoch 13, Step 47178: Loss=6.4487, Acc=0.178, PPL=631.86
2025-09-25 22:24:46,757 - training.trainer - INFO - Epoch 13, Step 47278: Loss=5.7080, Acc=0.260, PPL=301.26
2025-09-25 22:25:06,308 - training.trainer - INFO - Epoch 14/100 completed in 265.93s - Train Loss: 5.7675, Train Acc: 0.238, Val Loss: 5.7760, Val Acc: 0.239
2025-09-25 22:25:07,080 - training.trainer - INFO - New best model saved with validation loss: 5.7760
2025-09-25 22:25:07,081 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-25 22:25:15,038 - training.trainer - INFO - Epoch 14, Step 47461: Loss=6.2489, Acc=0.154, PPL=517.44
2025-09-25 22:25:22,758 - training.trainer - INFO - Epoch 14, Step 47561: Loss=4.5396, Acc=0.381, PPL=93.65
2025-09-25 22:25:30,459 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.7843, Acc=0.200, PPL=325.15
2025-09-25 22:25:37,868 - training.trainer - INFO - Epoch 14, Step 47761: Loss=6.3656, Acc=0.167, PPL=581.50
2025-09-25 22:25:45,461 - training.trainer - INFO - Epoch 14, Step 47861: Loss=4.4103, Acc=0.357, PPL=82.30
2025-09-25 22:25:53,003 - training.trainer - INFO - Epoch 14, Step 47961: Loss=5.6027, Acc=0.262, PPL=271.15
2025-09-25 22:26:00,591 - training.trainer - INFO - Epoch 14, Step 48061: Loss=5.2844, Acc=0.333, PPL=197.23
2025-09-25 22:26:08,077 - training.trainer - INFO - Epoch 14, Step 48161: Loss=6.2842, Acc=0.233, PPL=536.03
2025-09-25 22:26:15,353 - training.trainer - INFO - Epoch 14, Step 48261: Loss=6.2962, Acc=0.204, PPL=542.52
2025-09-25 22:26:22,687 - training.trainer - INFO - Epoch 14, Step 48361: Loss=6.1297, Acc=0.156, PPL=459.31
2025-09-25 22:26:29,981 - training.trainer - INFO - Epoch 14, Step 48461: Loss=5.0119, Acc=0.467, PPL=150.19
2025-09-25 22:26:37,181 - training.trainer - INFO - Epoch 14, Step 48561: Loss=4.3810, Acc=0.409, PPL=79.92
2025-09-25 22:26:44,448 - training.trainer - INFO - Epoch 14, Step 48661: Loss=6.6364, Acc=0.205, PPL=762.34
2025-09-25 22:26:51,707 - training.trainer - INFO - Epoch 14, Step 48761: Loss=5.4731, Acc=0.286, PPL=238.21
2025-09-25 22:26:58,991 - training.trainer - INFO - Epoch 14, Step 48861: Loss=6.5337, Acc=0.175, PPL=687.95
2025-09-25 22:27:06,269 - training.trainer - INFO - Epoch 14, Step 48961: Loss=5.1218, Acc=0.273, PPL=167.63
2025-09-25 22:27:13,489 - training.trainer - INFO - Epoch 14, Step 49061: Loss=5.2969, Acc=0.417, PPL=199.71
2025-09-25 22:27:20,909 - training.trainer - INFO - Epoch 14, Step 49161: Loss=5.1732, Acc=0.231, PPL=176.48
2025-09-25 22:27:28,303 - training.trainer - INFO - Epoch 14, Step 49261: Loss=6.0169, Acc=0.190, PPL=410.31
2025-09-25 22:27:35,844 - training.trainer - INFO - Epoch 14, Step 49361: Loss=5.3939, Acc=0.333, PPL=220.05
2025-09-25 22:27:43,176 - training.trainer - INFO - Epoch 14, Step 49461: Loss=6.1427, Acc=0.132, PPL=465.32
2025-09-25 22:27:50,531 - training.trainer - INFO - Epoch 14, Step 49561: Loss=5.6435, Acc=0.242, PPL=282.46
2025-09-25 22:27:57,992 - training.trainer - INFO - Epoch 14, Step 49661: Loss=6.2200, Acc=0.216, PPL=502.72
2025-09-25 22:28:05,585 - training.trainer - INFO - Epoch 14, Step 49761: Loss=5.7087, Acc=0.267, PPL=301.48
2025-09-25 22:28:13,015 - training.trainer - INFO - Epoch 14, Step 49861: Loss=4.6894, Acc=0.310, PPL=108.79
2025-09-25 22:28:20,435 - training.trainer - INFO - Epoch 14, Step 49961: Loss=5.9354, Acc=0.250, PPL=378.19
2025-09-25 22:28:27,951 - training.trainer - INFO - Epoch 14, Step 50061: Loss=5.9965, Acc=0.178, PPL=402.01
2025-09-25 22:28:35,506 - training.trainer - INFO - Epoch 14, Step 50161: Loss=6.0344, Acc=0.160, PPL=417.55
2025-09-25 22:28:43,067 - training.trainer - INFO - Epoch 14, Step 50261: Loss=5.2575, Acc=0.250, PPL=192.01
2025-09-25 22:28:50,528 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.2068, Acc=0.320, PPL=182.52
2025-09-25 22:28:57,926 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.6514, Acc=0.172, PPL=284.68
2025-09-25 22:29:05,369 - training.trainer - INFO - Epoch 14, Step 50561: Loss=6.2565, Acc=0.185, PPL=521.37
2025-09-25 22:29:12,962 - training.trainer - INFO - Epoch 14, Step 50661: Loss=4.9319, Acc=0.311, PPL=138.65
2025-09-25 22:29:31,908 - training.trainer - INFO - Epoch 15/100 completed in 264.83s - Train Loss: 5.7486, Train Acc: 0.242, Val Loss: 5.7539, Val Acc: 0.240
2025-09-25 22:29:32,267 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-25 22:29:33,077 - training.trainer - INFO - New best model saved with validation loss: 5.7539
2025-09-25 22:29:33,078 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-25 22:29:40,783 - training.trainer - INFO - Epoch 15, Step 50844: Loss=6.3909, Acc=0.190, PPL=596.36
2025-09-25 22:29:48,326 - training.trainer - INFO - Epoch 15, Step 50944: Loss=5.7548, Acc=0.135, PPL=315.70
2025-09-25 22:29:55,684 - training.trainer - INFO - Epoch 15, Step 51044: Loss=6.1984, Acc=0.214, PPL=491.97
2025-09-25 22:30:03,058 - training.trainer - INFO - Epoch 15, Step 51144: Loss=6.5411, Acc=0.113, PPL=693.08
2025-09-25 22:30:10,610 - training.trainer - INFO - Epoch 15, Step 51244: Loss=4.7304, Acc=0.357, PPL=113.34
2025-09-25 22:30:18,250 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.8779, Acc=0.160, PPL=357.06
2025-09-25 22:30:25,857 - training.trainer - INFO - Epoch 15, Step 51444: Loss=4.9601, Acc=0.333, PPL=142.61
2025-09-25 22:30:33,409 - training.trainer - INFO - Epoch 15, Step 51544: Loss=5.7935, Acc=0.241, PPL=328.17
2025-09-25 22:30:40,758 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.7121, Acc=0.221, PPL=302.52
2025-09-25 22:30:48,139 - training.trainer - INFO - Epoch 15, Step 51744: Loss=4.8166, Acc=0.310, PPL=123.54
2025-09-25 22:30:55,480 - training.trainer - INFO - Epoch 15, Step 51844: Loss=5.6214, Acc=0.257, PPL=276.27
2025-09-25 22:31:02,742 - training.trainer - INFO - Epoch 15, Step 51944: Loss=5.4768, Acc=0.259, PPL=239.09
2025-09-25 22:31:09,989 - training.trainer - INFO - Epoch 15, Step 52044: Loss=5.5988, Acc=0.308, PPL=270.09
2025-09-25 22:31:17,208 - training.trainer - INFO - Epoch 15, Step 52144: Loss=5.9187, Acc=0.209, PPL=371.92
2025-09-25 22:31:24,771 - training.trainer - INFO - Epoch 15, Step 52244: Loss=4.6176, Acc=0.316, PPL=101.25
2025-09-25 22:31:32,121 - training.trainer - INFO - Epoch 15, Step 52344: Loss=4.8827, Acc=0.208, PPL=131.99
2025-09-25 22:31:39,706 - training.trainer - INFO - Epoch 15, Step 52444: Loss=5.4297, Acc=0.367, PPL=228.09
2025-09-25 22:31:47,150 - training.trainer - INFO - Epoch 15, Step 52544: Loss=6.4740, Acc=0.213, PPL=648.10
2025-09-25 22:31:54,729 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.5337, Acc=0.192, PPL=253.09
2025-09-25 22:32:02,338 - training.trainer - INFO - Epoch 15, Step 52744: Loss=5.1518, Acc=0.318, PPL=172.74
2025-09-25 22:32:10,059 - training.trainer - INFO - Epoch 15, Step 52844: Loss=5.7762, Acc=0.216, PPL=322.52
2025-09-25 22:32:17,706 - training.trainer - INFO - Epoch 15, Step 52944: Loss=6.4980, Acc=0.161, PPL=663.81
2025-09-25 22:32:25,116 - training.trainer - INFO - Epoch 15, Step 53044: Loss=5.9322, Acc=0.224, PPL=377.00
2025-09-25 22:32:32,695 - training.trainer - INFO - Epoch 15, Step 53144: Loss=5.4352, Acc=0.273, PPL=229.35
2025-09-25 22:32:40,094 - training.trainer - INFO - Epoch 15, Step 53244: Loss=5.1361, Acc=0.250, PPL=170.04
2025-09-25 22:32:47,508 - training.trainer - INFO - Epoch 15, Step 53344: Loss=6.0516, Acc=0.268, PPL=424.80
2025-09-25 22:32:54,954 - training.trainer - INFO - Epoch 15, Step 53444: Loss=5.8660, Acc=0.292, PPL=352.85
2025-09-25 22:33:02,467 - training.trainer - INFO - Epoch 15, Step 53544: Loss=5.2061, Acc=0.316, PPL=182.38
2025-09-25 22:33:09,860 - training.trainer - INFO - Epoch 15, Step 53644: Loss=6.5628, Acc=0.167, PPL=708.23
2025-09-25 22:33:17,141 - training.trainer - INFO - Epoch 15, Step 53744: Loss=4.0847, Acc=0.435, PPL=59.42
2025-09-25 22:33:24,438 - training.trainer - INFO - Epoch 15, Step 53844: Loss=5.8184, Acc=0.225, PPL=336.44
2025-09-25 22:33:31,775 - training.trainer - INFO - Epoch 15, Step 53944: Loss=4.9668, Acc=0.283, PPL=143.57
2025-09-25 22:33:39,186 - training.trainer - INFO - Epoch 15, Step 54044: Loss=5.7250, Acc=0.148, PPL=306.42
2025-09-25 22:33:58,511 - training.trainer - INFO - Epoch 16/100 completed in 265.43s - Train Loss: 5.7280, Train Acc: 0.245, Val Loss: 5.7396, Val Acc: 0.242
2025-09-25 22:33:59,096 - training.trainer - INFO - New best model saved with validation loss: 5.7396
2025-09-25 22:33:59,096 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-25 22:34:05,956 - training.trainer - INFO - Epoch 16, Step 54227: Loss=6.3537, Acc=0.205, PPL=574.64
2025-09-25 22:34:12,483 - training.trainer - INFO - Epoch 16, Step 54327: Loss=5.9157, Acc=0.255, PPL=370.80
2025-09-25 22:34:18,874 - training.trainer - INFO - Epoch 16, Step 54427: Loss=5.7235, Acc=0.162, PPL=305.99
2025-09-25 22:34:25,589 - training.trainer - INFO - Epoch 16, Step 54527: Loss=4.8418, Acc=0.357, PPL=126.70
2025-09-25 22:34:32,949 - training.trainer - INFO - Epoch 16, Step 54627: Loss=5.5616, Acc=0.268, PPL=260.23
2025-09-25 22:34:40,374 - training.trainer - INFO - Epoch 16, Step 54727: Loss=5.5647, Acc=0.250, PPL=261.04
2025-09-25 22:34:47,656 - training.trainer - INFO - Epoch 16, Step 54827: Loss=6.0378, Acc=0.195, PPL=418.97
2025-09-25 22:34:54,974 - training.trainer - INFO - Epoch 16, Step 54927: Loss=5.9255, Acc=0.250, PPL=374.46
2025-09-25 22:35:02,441 - training.trainer - INFO - Epoch 16, Step 55027: Loss=6.5047, Acc=0.178, PPL=668.26
2025-09-25 22:35:09,866 - training.trainer - INFO - Epoch 16, Step 55127: Loss=5.7569, Acc=0.444, PPL=316.36
2025-09-25 22:35:17,201 - training.trainer - INFO - Epoch 16, Step 55227: Loss=6.5671, Acc=0.179, PPL=711.33
2025-09-25 22:35:24,875 - training.trainer - INFO - Epoch 16, Step 55327: Loss=3.5339, Acc=0.588, PPL=34.26
2025-09-25 22:35:32,305 - training.trainer - INFO - Epoch 16, Step 55427: Loss=5.6809, Acc=0.267, PPL=293.22
2025-09-25 22:35:39,767 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.7888, Acc=0.228, PPL=326.62
2025-09-25 22:35:47,396 - training.trainer - INFO - Epoch 16, Step 55627: Loss=5.4028, Acc=0.212, PPL=222.03
2025-09-25 22:35:55,106 - training.trainer - INFO - Epoch 16, Step 55727: Loss=5.8898, Acc=0.214, PPL=361.35
2025-09-25 22:36:02,650 - training.trainer - INFO - Epoch 16, Step 55827: Loss=6.1035, Acc=0.136, PPL=447.42
2025-09-25 22:36:10,040 - training.trainer - INFO - Epoch 16, Step 55927: Loss=4.8035, Acc=0.318, PPL=121.93
2025-09-25 22:36:17,594 - training.trainer - INFO - Epoch 16, Step 56027: Loss=5.3654, Acc=0.286, PPL=213.87
2025-09-25 22:36:24,989 - training.trainer - INFO - Epoch 16, Step 56127: Loss=5.4021, Acc=0.304, PPL=221.88
2025-09-25 22:36:32,468 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.0996, Acc=0.389, PPL=163.96
2025-09-25 22:36:39,809 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.5573, Acc=0.237, PPL=259.12
2025-09-25 22:36:47,290 - training.trainer - INFO - Epoch 16, Step 56427: Loss=6.4406, Acc=0.167, PPL=626.76
2025-09-25 22:36:54,747 - training.trainer - INFO - Epoch 16, Step 56527: Loss=4.8895, Acc=0.308, PPL=132.89
2025-09-25 22:37:02,059 - training.trainer - INFO - Epoch 16, Step 56627: Loss=6.5128, Acc=0.125, PPL=673.70
2025-09-25 22:37:09,336 - training.trainer - INFO - Epoch 16, Step 56727: Loss=6.5213, Acc=0.100, PPL=679.48
2025-09-25 22:37:16,843 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.5391, Acc=0.346, PPL=254.45
2025-09-25 22:37:24,336 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.7467, Acc=0.250, PPL=313.16
2025-09-25 22:37:31,731 - training.trainer - INFO - Epoch 16, Step 57027: Loss=6.1564, Acc=0.139, PPL=471.75
2025-09-25 22:37:39,083 - training.trainer - INFO - Epoch 16, Step 57127: Loss=6.0213, Acc=0.250, PPL=412.10
2025-09-25 22:37:46,586 - training.trainer - INFO - Epoch 16, Step 57227: Loss=6.5049, Acc=0.171, PPL=668.38
2025-09-25 22:37:54,097 - training.trainer - INFO - Epoch 16, Step 57327: Loss=6.2661, Acc=0.197, PPL=526.42
2025-09-25 22:38:01,496 - training.trainer - INFO - Epoch 16, Step 57427: Loss=6.1900, Acc=0.207, PPL=487.87
2025-09-25 22:38:20,022 - training.trainer - INFO - Epoch 17/100 completed in 260.93s - Train Loss: 5.7016, Train Acc: 0.248, Val Loss: 5.7314, Val Acc: 0.244
2025-09-25 22:38:20,870 - training.trainer - INFO - New best model saved with validation loss: 5.7314
2025-09-25 22:38:20,871 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-25 22:38:28,873 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.5680, Acc=0.239, PPL=261.91
2025-09-25 22:38:36,411 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.8503, Acc=0.102, PPL=347.35
2025-09-25 22:38:44,113 - training.trainer - INFO - Epoch 17, Step 57810: Loss=6.0395, Acc=0.222, PPL=419.70
2025-09-25 22:38:51,551 - training.trainer - INFO - Epoch 17, Step 57910: Loss=5.4163, Acc=0.176, PPL=225.04
2025-09-25 22:38:59,086 - training.trainer - INFO - Epoch 17, Step 58010: Loss=5.4868, Acc=0.280, PPL=241.48
2025-09-25 22:39:06,590 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.8849, Acc=0.268, PPL=359.58
2025-09-25 22:39:14,196 - training.trainer - INFO - Epoch 17, Step 58210: Loss=5.3889, Acc=0.282, PPL=218.96
2025-09-25 22:39:21,761 - training.trainer - INFO - Epoch 17, Step 58310: Loss=6.0988, Acc=0.214, PPL=445.33
2025-09-25 22:39:29,295 - training.trainer - INFO - Epoch 17, Step 58410: Loss=5.4999, Acc=0.233, PPL=244.66
2025-09-25 22:39:36,987 - training.trainer - INFO - Epoch 17, Step 58510: Loss=6.0977, Acc=0.175, PPL=444.83
2025-09-25 22:39:44,475 - training.trainer - INFO - Epoch 17, Step 58610: Loss=5.4590, Acc=0.250, PPL=234.87
2025-09-25 22:39:51,897 - training.trainer - INFO - Epoch 17, Step 58710: Loss=6.1838, Acc=0.150, PPL=484.85
2025-09-25 22:39:59,439 - training.trainer - INFO - Epoch 17, Step 58810: Loss=5.5467, Acc=0.333, PPL=256.39
2025-09-25 22:40:07,097 - training.trainer - INFO - Epoch 17, Step 58910: Loss=5.9223, Acc=0.312, PPL=373.26
2025-09-25 22:40:14,609 - training.trainer - INFO - Epoch 17, Step 59010: Loss=5.9385, Acc=0.200, PPL=379.37
2025-09-25 22:40:22,043 - training.trainer - INFO - Epoch 17, Step 59110: Loss=5.9443, Acc=0.178, PPL=381.56
2025-09-25 22:40:29,482 - training.trainer - INFO - Epoch 17, Step 59210: Loss=5.2775, Acc=0.269, PPL=195.89
2025-09-25 22:40:36,834 - training.trainer - INFO - Epoch 17, Step 59310: Loss=6.2508, Acc=0.163, PPL=518.45
2025-09-25 22:40:44,288 - training.trainer - INFO - Epoch 17, Step 59410: Loss=5.3630, Acc=0.302, PPL=213.36
2025-09-25 22:40:51,637 - training.trainer - INFO - Epoch 17, Step 59510: Loss=5.6477, Acc=0.219, PPL=283.65
2025-09-25 22:40:58,961 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.7254, Acc=0.216, PPL=306.54
2025-09-25 22:41:06,248 - training.trainer - INFO - Epoch 17, Step 59710: Loss=5.2835, Acc=0.324, PPL=197.06
2025-09-25 22:41:13,669 - training.trainer - INFO - Epoch 17, Step 59810: Loss=6.8945, Acc=0.138, PPL=986.82
2025-09-25 22:41:20,964 - training.trainer - INFO - Epoch 17, Step 59910: Loss=6.2087, Acc=0.190, PPL=497.06
2025-09-25 22:41:28,343 - training.trainer - INFO - Epoch 17, Step 60010: Loss=5.7138, Acc=0.250, PPL=303.01
2025-09-25 22:41:35,639 - training.trainer - INFO - Epoch 17, Step 60110: Loss=6.3328, Acc=0.222, PPL=562.72
2025-09-25 22:41:43,003 - training.trainer - INFO - Epoch 17, Step 60210: Loss=4.0847, Acc=0.435, PPL=59.42
2025-09-25 22:41:50,308 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.6136, Acc=0.300, PPL=274.13
2025-09-25 22:41:57,751 - training.trainer - INFO - Epoch 17, Step 60410: Loss=6.1293, Acc=0.217, PPL=459.13
2025-09-25 22:42:05,124 - training.trainer - INFO - Epoch 17, Step 60510: Loss=5.0058, Acc=0.250, PPL=149.28
2025-09-25 22:42:12,405 - training.trainer - INFO - Epoch 17, Step 60610: Loss=4.5621, Acc=0.333, PPL=95.78
2025-09-25 22:42:19,767 - training.trainer - INFO - Epoch 17, Step 60710: Loss=5.6429, Acc=0.254, PPL=282.28
2025-09-25 22:42:27,005 - training.trainer - INFO - Epoch 17, Step 60810: Loss=5.5733, Acc=0.303, PPL=263.29
2025-09-25 22:42:46,325 - training.trainer - INFO - Epoch 18/100 completed in 265.45s - Train Loss: 5.6837, Train Acc: 0.251, Val Loss: 5.7231, Val Acc: 0.246
2025-09-25 22:42:47,077 - training.trainer - INFO - New best model saved with validation loss: 5.7231
2025-09-25 22:42:47,078 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-25 22:42:54,235 - training.trainer - INFO - Epoch 18, Step 60993: Loss=6.2933, Acc=0.200, PPL=540.96
2025-09-25 22:43:00,981 - training.trainer - INFO - Epoch 18, Step 61093: Loss=5.0423, Acc=0.235, PPL=154.82
2025-09-25 22:43:08,427 - training.trainer - INFO - Epoch 18, Step 61193: Loss=6.3986, Acc=0.234, PPL=601.00
2025-09-25 22:43:15,797 - training.trainer - INFO - Epoch 18, Step 61293: Loss=6.1755, Acc=0.250, PPL=480.81
2025-09-25 22:43:23,199 - training.trainer - INFO - Epoch 18, Step 61393: Loss=6.2284, Acc=0.149, PPL=506.93
2025-09-25 22:43:30,556 - training.trainer - INFO - Epoch 18, Step 61493: Loss=5.1438, Acc=0.323, PPL=171.36
2025-09-25 22:43:37,893 - training.trainer - INFO - Epoch 18, Step 61593: Loss=2.9664, Acc=0.647, PPL=19.42
2025-09-25 22:43:45,184 - training.trainer - INFO - Epoch 18, Step 61693: Loss=4.6571, Acc=0.357, PPL=105.33
2025-09-25 22:43:52,574 - training.trainer - INFO - Epoch 18, Step 61793: Loss=6.0414, Acc=0.242, PPL=420.48
2025-09-25 22:43:59,922 - training.trainer - INFO - Epoch 18, Step 61893: Loss=5.9499, Acc=0.213, PPL=383.70
2025-09-25 22:44:07,184 - training.trainer - INFO - Epoch 18, Step 61993: Loss=6.1758, Acc=0.174, PPL=480.99
2025-09-25 22:44:14,489 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.5817, Acc=0.250, PPL=265.53
2025-09-25 22:44:21,863 - training.trainer - INFO - Epoch 18, Step 62193: Loss=6.2644, Acc=0.137, PPL=525.54
2025-09-25 22:44:29,327 - training.trainer - INFO - Epoch 18, Step 62293: Loss=6.6424, Acc=0.190, PPL=766.94
2025-09-25 22:44:36,657 - training.trainer - INFO - Epoch 18, Step 62393: Loss=5.6907, Acc=0.250, PPL=296.10
2025-09-25 22:44:43,996 - training.trainer - INFO - Epoch 18, Step 62493: Loss=5.3998, Acc=0.294, PPL=221.35
2025-09-25 22:44:51,364 - training.trainer - INFO - Epoch 18, Step 62593: Loss=6.0289, Acc=0.233, PPL=415.25
2025-09-25 22:44:58,704 - training.trainer - INFO - Epoch 18, Step 62693: Loss=6.0581, Acc=0.188, PPL=427.55
2025-09-25 22:45:06,352 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.4799, Acc=0.222, PPL=239.83
2025-09-25 22:45:13,675 - training.trainer - INFO - Epoch 18, Step 62893: Loss=6.0119, Acc=0.233, PPL=408.24
2025-09-25 22:45:20,970 - training.trainer - INFO - Epoch 18, Step 62993: Loss=5.5912, Acc=0.182, PPL=268.07
2025-09-25 22:45:28,324 - training.trainer - INFO - Epoch 18, Step 63093: Loss=5.7734, Acc=0.204, PPL=321.63
2025-09-25 22:45:35,959 - training.trainer - INFO - Epoch 18, Step 63193: Loss=5.6533, Acc=0.250, PPL=285.24
2025-09-25 22:45:43,342 - training.trainer - INFO - Epoch 18, Step 63293: Loss=5.7965, Acc=0.200, PPL=329.13
2025-09-25 22:45:50,779 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.0556, Acc=0.400, PPL=156.91
2025-09-25 22:45:58,133 - training.trainer - INFO - Epoch 18, Step 63493: Loss=5.7177, Acc=0.186, PPL=304.22
2025-09-25 22:46:05,570 - training.trainer - INFO - Epoch 18, Step 63593: Loss=5.1420, Acc=0.273, PPL=171.06
2025-09-25 22:46:12,829 - training.trainer - INFO - Epoch 18, Step 63693: Loss=6.1372, Acc=0.246, PPL=462.77
2025-09-25 22:46:20,276 - training.trainer - INFO - Epoch 18, Step 63793: Loss=6.3265, Acc=0.175, PPL=559.21
2025-09-25 22:46:27,611 - training.trainer - INFO - Epoch 18, Step 63893: Loss=5.9267, Acc=0.167, PPL=374.92
2025-09-25 22:46:34,951 - training.trainer - INFO - Epoch 18, Step 63993: Loss=4.4988, Acc=0.389, PPL=89.91
2025-09-25 22:46:42,459 - training.trainer - INFO - Epoch 18, Step 64093: Loss=5.6907, Acc=0.214, PPL=296.10
2025-09-25 22:46:49,920 - training.trainer - INFO - Epoch 18, Step 64193: Loss=5.8856, Acc=0.222, PPL=359.81
2025-09-25 22:47:08,698 - training.trainer - INFO - Epoch 19/100 completed in 261.62s - Train Loss: 5.6582, Train Acc: 0.254, Val Loss: 5.7001, Val Acc: 0.248
2025-09-25 22:47:09,447 - training.trainer - INFO - New best model saved with validation loss: 5.7001
2025-09-25 22:47:09,448 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-25 22:47:17,312 - training.trainer - INFO - Epoch 19, Step 64376: Loss=6.1829, Acc=0.200, PPL=484.41
2025-09-25 22:47:24,792 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.3309, Acc=0.314, PPL=206.61
2025-09-25 22:47:32,216 - training.trainer - INFO - Epoch 19, Step 64576: Loss=5.5197, Acc=0.135, PPL=249.56
2025-09-25 22:47:39,690 - training.trainer - INFO - Epoch 19, Step 64676: Loss=5.9581, Acc=0.271, PPL=386.87
2025-09-25 22:47:47,319 - training.trainer - INFO - Epoch 19, Step 64776: Loss=4.6370, Acc=0.467, PPL=103.24
2025-09-25 22:47:54,702 - training.trainer - INFO - Epoch 19, Step 64876: Loss=4.6102, Acc=0.351, PPL=100.51
2025-09-25 22:48:02,149 - training.trainer - INFO - Epoch 19, Step 64976: Loss=5.6263, Acc=0.250, PPL=277.64
2025-09-25 22:48:09,673 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.8037, Acc=0.175, PPL=331.51
2025-09-25 22:48:17,253 - training.trainer - INFO - Epoch 19, Step 65176: Loss=5.2112, Acc=0.308, PPL=183.32
2025-09-25 22:48:24,741 - training.trainer - INFO - Epoch 19, Step 65276: Loss=6.1461, Acc=0.150, PPL=466.90
2025-09-25 22:48:32,211 - training.trainer - INFO - Epoch 19, Step 65376: Loss=5.8292, Acc=0.179, PPL=340.08
2025-09-25 22:48:39,738 - training.trainer - INFO - Epoch 19, Step 65476: Loss=5.6324, Acc=0.296, PPL=279.33
2025-09-25 22:48:47,092 - training.trainer - INFO - Epoch 19, Step 65576: Loss=5.1162, Acc=0.538, PPL=166.70
2025-09-25 22:48:54,573 - training.trainer - INFO - Epoch 19, Step 65676: Loss=5.3982, Acc=0.204, PPL=221.01
2025-09-25 22:49:01,995 - training.trainer - INFO - Epoch 19, Step 65776: Loss=6.4435, Acc=0.188, PPL=628.59
2025-09-25 22:49:09,586 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.9032, Acc=0.240, PPL=366.21
2025-09-25 22:49:16,956 - training.trainer - INFO - Epoch 19, Step 65976: Loss=4.1631, Acc=0.500, PPL=64.27
2025-09-25 22:49:24,556 - training.trainer - INFO - Epoch 19, Step 66076: Loss=5.4423, Acc=0.267, PPL=230.98
2025-09-25 22:49:31,931 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.9978, Acc=0.232, PPL=402.54
2025-09-25 22:49:39,260 - training.trainer - INFO - Epoch 19, Step 66276: Loss=6.3550, Acc=0.244, PPL=575.34
2025-09-25 22:49:46,629 - training.trainer - INFO - Epoch 19, Step 66376: Loss=5.8039, Acc=0.228, PPL=331.61
2025-09-25 22:49:54,085 - training.trainer - INFO - Epoch 19, Step 66476: Loss=6.2540, Acc=0.176, PPL=520.09
2025-09-25 22:50:01,527 - training.trainer - INFO - Epoch 19, Step 66576: Loss=6.6124, Acc=0.196, PPL=744.25
2025-09-25 22:50:08,864 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.7829, Acc=0.231, PPL=324.70
2025-09-25 22:50:16,191 - training.trainer - INFO - Epoch 19, Step 66776: Loss=6.1418, Acc=0.200, PPL=464.87
2025-09-25 22:50:23,565 - training.trainer - INFO - Epoch 19, Step 66876: Loss=5.8522, Acc=0.244, PPL=348.01
2025-09-25 22:50:30,961 - training.trainer - INFO - Epoch 19, Step 66976: Loss=5.7180, Acc=0.194, PPL=304.31
2025-09-25 22:50:38,245 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.5424, Acc=0.184, PPL=255.30
2025-09-25 22:50:45,853 - training.trainer - INFO - Epoch 19, Step 67176: Loss=6.3481, Acc=0.162, PPL=571.42
2025-09-25 22:50:53,266 - training.trainer - INFO - Epoch 19, Step 67276: Loss=6.1950, Acc=0.186, PPL=490.31
2025-09-25 22:51:00,849 - training.trainer - INFO - Epoch 19, Step 67376: Loss=4.1339, Acc=0.385, PPL=62.42
2025-09-25 22:51:08,176 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.4763, Acc=0.323, PPL=238.97
2025-09-25 22:51:15,620 - training.trainer - INFO - Epoch 19, Step 67576: Loss=4.0186, Acc=0.421, PPL=55.62
2025-09-25 22:51:34,701 - training.trainer - INFO - Epoch 20/100 completed in 265.25s - Train Loss: 5.6395, Train Acc: 0.258, Val Loss: 5.6977, Val Acc: 0.251
2025-09-25 22:51:35,157 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-25 22:51:35,960 - training.trainer - INFO - New best model saved with validation loss: 5.6977
2025-09-25 22:51:35,961 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-25 22:51:43,881 - training.trainer - INFO - Epoch 20, Step 67759: Loss=4.8549, Acc=0.321, PPL=128.37
2025-09-25 22:51:51,245 - training.trainer - INFO - Epoch 20, Step 67859: Loss=5.5629, Acc=0.206, PPL=260.57
2025-09-25 22:51:58,956 - training.trainer - INFO - Epoch 20, Step 67959: Loss=6.0342, Acc=0.240, PPL=417.45
2025-09-25 22:52:06,543 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.8183, Acc=0.216, PPL=336.41
2025-09-25 22:52:14,058 - training.trainer - INFO - Epoch 20, Step 68159: Loss=3.9921, Acc=0.500, PPL=54.17
2025-09-25 22:52:21,650 - training.trainer - INFO - Epoch 20, Step 68259: Loss=6.0531, Acc=0.227, PPL=425.43
2025-09-25 22:52:29,253 - training.trainer - INFO - Epoch 20, Step 68359: Loss=5.3526, Acc=0.241, PPL=211.15
2025-09-25 22:52:36,875 - training.trainer - INFO - Epoch 20, Step 68459: Loss=6.4285, Acc=0.174, PPL=619.23
2025-09-25 22:52:44,491 - training.trainer - INFO - Epoch 20, Step 68559: Loss=5.7831, Acc=0.172, PPL=324.77
2025-09-25 22:52:52,232 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.7596, Acc=0.333, PPL=317.22
2025-09-25 22:52:59,773 - training.trainer - INFO - Epoch 20, Step 68759: Loss=5.5040, Acc=0.319, PPL=245.67
2025-09-25 22:53:07,334 - training.trainer - INFO - Epoch 20, Step 68859: Loss=6.0551, Acc=0.244, PPL=426.27
2025-09-25 22:53:14,909 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.4926, Acc=0.237, PPL=242.88
2025-09-25 22:53:22,293 - training.trainer - INFO - Epoch 20, Step 69059: Loss=6.5933, Acc=0.133, PPL=730.16
2025-09-25 22:53:29,770 - training.trainer - INFO - Epoch 20, Step 69159: Loss=6.0542, Acc=0.227, PPL=425.89
2025-09-25 22:53:37,377 - training.trainer - INFO - Epoch 20, Step 69259: Loss=5.7712, Acc=0.333, PPL=320.93
2025-09-25 22:53:44,896 - training.trainer - INFO - Epoch 20, Step 69359: Loss=5.9272, Acc=0.197, PPL=375.09
2025-09-25 22:53:52,435 - training.trainer - INFO - Epoch 20, Step 69459: Loss=6.1804, Acc=0.186, PPL=483.17
2025-09-25 22:54:00,015 - training.trainer - INFO - Epoch 20, Step 69559: Loss=6.0148, Acc=0.205, PPL=409.45
2025-09-25 22:54:07,347 - training.trainer - INFO - Epoch 20, Step 69659: Loss=4.8009, Acc=0.500, PPL=121.61
2025-09-25 22:54:14,602 - training.trainer - INFO - Epoch 20, Step 69759: Loss=5.3430, Acc=0.255, PPL=209.13
2025-09-25 22:54:21,943 - training.trainer - INFO - Epoch 20, Step 69859: Loss=4.8604, Acc=0.294, PPL=129.08
2025-09-25 22:54:29,160 - training.trainer - INFO - Epoch 20, Step 69959: Loss=5.3781, Acc=0.296, PPL=216.61
2025-09-25 22:54:36,577 - training.trainer - INFO - Epoch 20, Step 70059: Loss=4.8421, Acc=0.382, PPL=126.74
2025-09-25 22:54:44,217 - training.trainer - INFO - Epoch 20, Step 70159: Loss=6.5570, Acc=0.126, PPL=704.14
2025-09-25 22:54:51,785 - training.trainer - INFO - Epoch 20, Step 70259: Loss=5.8546, Acc=0.207, PPL=348.82
2025-09-25 22:54:59,296 - training.trainer - INFO - Epoch 20, Step 70359: Loss=4.0733, Acc=0.423, PPL=58.75
2025-09-25 22:55:06,834 - training.trainer - INFO - Epoch 20, Step 70459: Loss=6.4363, Acc=0.174, PPL=624.07
2025-09-25 22:55:14,348 - training.trainer - INFO - Epoch 20, Step 70559: Loss=5.4898, Acc=0.244, PPL=242.22
2025-09-25 22:55:21,870 - training.trainer - INFO - Epoch 20, Step 70659: Loss=6.0898, Acc=0.188, PPL=441.33
2025-09-25 22:55:29,437 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.9790, Acc=0.125, PPL=395.06
2025-09-25 22:55:36,937 - training.trainer - INFO - Epoch 20, Step 70859: Loss=5.7224, Acc=0.270, PPL=305.63
2025-09-25 22:55:44,472 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.9080, Acc=0.241, PPL=367.97
2025-09-25 22:56:03,266 - training.trainer - INFO - Epoch 21/100 completed in 267.30s - Train Loss: 5.6274, Train Acc: 0.261, Val Loss: 5.6941, Val Acc: 0.253
2025-09-25 22:56:03,990 - training.trainer - INFO - New best model saved with validation loss: 5.6941
2025-09-25 22:56:03,990 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-09-25 22:56:12,126 - training.trainer - INFO - Epoch 21, Step 71142: Loss=5.7848, Acc=0.226, PPL=325.32
2025-09-25 22:56:19,600 - training.trainer - INFO - Epoch 21, Step 71242: Loss=5.2516, Acc=0.224, PPL=190.87
2025-09-25 22:56:27,103 - training.trainer - INFO - Epoch 21, Step 71342: Loss=6.0171, Acc=0.229, PPL=410.40
2025-09-25 22:56:34,622 - training.trainer - INFO - Epoch 21, Step 71442: Loss=5.7541, Acc=0.277, PPL=315.48
2025-09-25 22:56:41,990 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.3292, Acc=0.250, PPL=206.28
2025-09-25 22:56:49,436 - training.trainer - INFO - Epoch 21, Step 71642: Loss=5.1931, Acc=0.314, PPL=180.02
2025-09-25 22:56:56,986 - training.trainer - INFO - Epoch 21, Step 71742: Loss=6.1827, Acc=0.222, PPL=484.32
2025-09-25 22:57:04,880 - training.trainer - INFO - Epoch 21, Step 71842: Loss=5.8220, Acc=0.269, PPL=337.64
2025-09-25 22:57:12,406 - training.trainer - INFO - Epoch 21, Step 71942: Loss=6.6143, Acc=0.237, PPL=745.70
2025-09-25 22:57:20,166 - training.trainer - INFO - Epoch 21, Step 72042: Loss=6.0818, Acc=0.200, PPL=437.81
2025-09-25 22:57:27,654 - training.trainer - INFO - Epoch 21, Step 72142: Loss=6.8705, Acc=0.143, PPL=963.48
2025-09-25 22:57:35,517 - training.trainer - INFO - Epoch 21, Step 72242: Loss=5.7082, Acc=0.206, PPL=301.32
2025-09-25 22:57:43,064 - training.trainer - INFO - Epoch 21, Step 72342: Loss=4.5458, Acc=0.438, PPL=94.24
2025-09-25 22:57:50,586 - training.trainer - INFO - Epoch 21, Step 72442: Loss=5.7869, Acc=0.277, PPL=326.01
2025-09-25 22:57:58,086 - training.trainer - INFO - Epoch 21, Step 72542: Loss=5.3628, Acc=0.298, PPL=213.32
2025-09-25 22:58:05,683 - training.trainer - INFO - Epoch 21, Step 72642: Loss=5.8584, Acc=0.154, PPL=350.15
2025-09-25 22:58:13,195 - training.trainer - INFO - Epoch 21, Step 72742: Loss=5.0655, Acc=0.238, PPL=158.46
2025-09-25 22:58:20,617 - training.trainer - INFO - Epoch 21, Step 72842: Loss=6.8026, Acc=0.183, PPL=900.19
2025-09-25 22:58:28,103 - training.trainer - INFO - Epoch 21, Step 72942: Loss=4.6170, Acc=0.324, PPL=101.19
2025-09-25 22:58:35,643 - training.trainer - INFO - Epoch 21, Step 73042: Loss=6.2519, Acc=0.189, PPL=518.99
2025-09-25 22:58:43,365 - training.trainer - INFO - Epoch 21, Step 73142: Loss=5.5199, Acc=0.200, PPL=249.61
2025-09-25 22:58:51,039 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.8683, Acc=0.233, PPL=353.65
2025-09-25 22:58:58,576 - training.trainer - INFO - Epoch 21, Step 73342: Loss=5.8513, Acc=0.154, PPL=347.68
2025-09-25 22:59:06,108 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.3450, Acc=0.321, PPL=209.57
2025-09-25 22:59:13,769 - training.trainer - INFO - Epoch 21, Step 73542: Loss=4.9752, Acc=0.321, PPL=144.78
2025-09-25 22:59:21,421 - training.trainer - INFO - Epoch 21, Step 73642: Loss=5.6409, Acc=0.212, PPL=281.70
2025-09-25 22:59:28,947 - training.trainer - INFO - Epoch 21, Step 73742: Loss=5.1721, Acc=0.304, PPL=176.28
2025-09-25 22:59:36,140 - training.trainer - INFO - Epoch 21, Step 73842: Loss=5.3010, Acc=0.257, PPL=200.53
2025-09-25 22:59:43,616 - training.trainer - INFO - Epoch 21, Step 73942: Loss=5.6595, Acc=0.167, PPL=287.02
2025-09-25 22:59:51,138 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.5285, Acc=0.200, PPL=251.76
2025-09-25 22:59:58,473 - training.trainer - INFO - Epoch 21, Step 74142: Loss=5.3591, Acc=0.250, PPL=212.54
2025-09-25 23:00:05,848 - training.trainer - INFO - Epoch 21, Step 74242: Loss=4.2853, Acc=0.368, PPL=72.63
2025-09-25 23:00:13,312 - training.trainer - INFO - Epoch 21, Step 74342: Loss=5.6933, Acc=0.214, PPL=296.87
2025-09-25 23:00:32,373 - training.trainer - INFO - Epoch 22/100 completed in 268.38s - Train Loss: 5.6041, Train Acc: 0.264, Val Loss: 5.7055, Val Acc: 0.249
2025-09-25 23:00:40,065 - training.trainer - INFO - Epoch 22, Step 74525: Loss=5.2366, Acc=0.300, PPL=188.02
2025-09-25 23:00:47,593 - training.trainer - INFO - Epoch 22, Step 74625: Loss=4.9820, Acc=0.385, PPL=145.76
2025-09-25 23:00:55,188 - training.trainer - INFO - Epoch 22, Step 74725: Loss=5.3924, Acc=0.286, PPL=219.73
2025-09-25 23:01:02,619 - training.trainer - INFO - Epoch 22, Step 74825: Loss=5.5628, Acc=0.222, PPL=260.56
2025-09-25 23:01:10,251 - training.trainer - INFO - Epoch 22, Step 74925: Loss=5.4335, Acc=0.232, PPL=228.96
2025-09-25 23:01:17,773 - training.trainer - INFO - Epoch 22, Step 75025: Loss=5.8315, Acc=0.240, PPL=340.88
2025-09-25 23:01:25,430 - training.trainer - INFO - Epoch 22, Step 75125: Loss=5.8887, Acc=0.311, PPL=360.95
2025-09-25 23:01:33,115 - training.trainer - INFO - Epoch 22, Step 75225: Loss=6.1522, Acc=0.205, PPL=469.74
2025-09-25 23:01:40,637 - training.trainer - INFO - Epoch 22, Step 75325: Loss=5.7642, Acc=0.256, PPL=318.69
2025-09-25 23:01:48,153 - training.trainer - INFO - Epoch 22, Step 75425: Loss=5.6508, Acc=0.154, PPL=284.53
2025-09-25 23:01:55,807 - training.trainer - INFO - Epoch 22, Step 75525: Loss=6.6436, Acc=0.211, PPL=767.83
2025-09-25 23:02:03,524 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.8654, Acc=0.162, PPL=352.61
2025-09-25 23:02:11,195 - training.trainer - INFO - Epoch 22, Step 75725: Loss=5.5633, Acc=0.275, PPL=260.68
2025-09-25 23:02:18,855 - training.trainer - INFO - Epoch 22, Step 75825: Loss=4.9279, Acc=0.250, PPL=138.08
2025-09-25 23:02:26,492 - training.trainer - INFO - Epoch 22, Step 75925: Loss=6.4898, Acc=0.140, PPL=658.36
2025-09-25 23:02:34,139 - training.trainer - INFO - Epoch 22, Step 76025: Loss=6.0833, Acc=0.315, PPL=438.50
2025-09-25 23:02:41,709 - training.trainer - INFO - Epoch 22, Step 76125: Loss=5.2553, Acc=0.265, PPL=191.58
2025-09-25 23:02:49,311 - training.trainer - INFO - Epoch 22, Step 76225: Loss=5.6095, Acc=0.214, PPL=273.01
2025-09-25 23:02:56,667 - training.trainer - INFO - Epoch 22, Step 76325: Loss=6.3440, Acc=0.250, PPL=569.06
2025-09-25 23:03:03,952 - training.trainer - INFO - Epoch 22, Step 76425: Loss=5.4900, Acc=0.243, PPL=242.25
2025-09-25 23:03:11,510 - training.trainer - INFO - Epoch 22, Step 76525: Loss=4.9835, Acc=0.403, PPL=145.98
2025-09-25 23:03:18,612 - training.trainer - INFO - Epoch 22, Step 76625: Loss=3.7484, Acc=0.429, PPL=42.45
2025-09-25 23:03:25,002 - training.trainer - INFO - Epoch 22, Step 76725: Loss=4.6661, Acc=0.211, PPL=106.29
2025-09-25 23:03:31,970 - training.trainer - INFO - Epoch 22, Step 76825: Loss=5.2864, Acc=0.364, PPL=197.63
2025-09-25 23:03:39,340 - training.trainer - INFO - Epoch 22, Step 76925: Loss=5.4763, Acc=0.216, PPL=238.95
2025-09-25 23:03:46,946 - training.trainer - INFO - Epoch 22, Step 77025: Loss=4.7128, Acc=0.423, PPL=111.36
2025-09-25 23:03:54,370 - training.trainer - INFO - Epoch 22, Step 77125: Loss=6.0149, Acc=0.167, PPL=409.49
2025-09-25 23:04:01,824 - training.trainer - INFO - Epoch 22, Step 77225: Loss=5.6358, Acc=0.273, PPL=280.29
2025-09-25 23:04:09,451 - training.trainer - INFO - Epoch 22, Step 77325: Loss=5.0524, Acc=0.294, PPL=156.40
2025-09-25 23:04:16,856 - training.trainer - INFO - Epoch 22, Step 77425: Loss=4.8536, Acc=0.367, PPL=128.20
2025-09-25 23:04:24,295 - training.trainer - INFO - Epoch 22, Step 77525: Loss=5.6500, Acc=0.300, PPL=284.29
2025-09-25 23:04:31,916 - training.trainer - INFO - Epoch 22, Step 77625: Loss=4.1004, Acc=0.375, PPL=60.37
2025-09-25 23:04:39,480 - training.trainer - INFO - Epoch 22, Step 77725: Loss=5.8651, Acc=0.231, PPL=352.51
2025-09-25 23:04:58,205 - training.trainer - INFO - Epoch 23/100 completed in 265.83s - Train Loss: 5.5890, Train Acc: 0.266, Val Loss: 5.6972, Val Acc: 0.251
2025-09-25 23:05:06,046 - training.trainer - INFO - Epoch 23, Step 77908: Loss=5.7436, Acc=0.289, PPL=312.19
2025-09-25 23:05:13,841 - training.trainer - INFO - Epoch 23, Step 78008: Loss=4.4974, Acc=0.238, PPL=89.78
2025-09-25 23:05:21,336 - training.trainer - INFO - Epoch 23, Step 78108: Loss=5.9697, Acc=0.190, PPL=391.37
2025-09-25 23:05:28,872 - training.trainer - INFO - Epoch 23, Step 78208: Loss=5.6312, Acc=0.304, PPL=279.00
2025-09-25 23:05:36,502 - training.trainer - INFO - Epoch 23, Step 78308: Loss=6.0953, Acc=0.148, PPL=443.77
2025-09-25 23:05:44,020 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.2074, Acc=0.273, PPL=182.62
2025-09-25 23:05:51,730 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.3433, Acc=0.346, PPL=209.20
2025-09-25 23:05:59,202 - training.trainer - INFO - Epoch 23, Step 78608: Loss=5.6976, Acc=0.250, PPL=298.15
2025-09-25 23:06:06,671 - training.trainer - INFO - Epoch 23, Step 78708: Loss=6.2018, Acc=0.182, PPL=493.61
2025-09-25 23:06:14,185 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.1046, Acc=0.333, PPL=164.77
2025-09-25 23:06:21,746 - training.trainer - INFO - Epoch 23, Step 78908: Loss=5.2135, Acc=0.417, PPL=183.74
2025-09-25 23:06:29,235 - training.trainer - INFO - Epoch 23, Step 79008: Loss=5.5621, Acc=0.238, PPL=260.36
2025-09-25 23:06:36,688 - training.trainer - INFO - Epoch 23, Step 79108: Loss=4.8900, Acc=0.333, PPL=132.95
2025-09-25 23:06:44,109 - training.trainer - INFO - Epoch 23, Step 79208: Loss=6.7488, Acc=0.183, PPL=853.07
2025-09-25 23:06:51,612 - training.trainer - INFO - Epoch 23, Step 79308: Loss=5.9242, Acc=0.170, PPL=373.99
2025-09-25 23:06:59,051 - training.trainer - INFO - Epoch 23, Step 79408: Loss=6.6340, Acc=0.182, PPL=760.49
2025-09-25 23:07:06,443 - training.trainer - INFO - Epoch 23, Step 79508: Loss=5.1943, Acc=0.244, PPL=180.25
2025-09-25 23:07:13,941 - training.trainer - INFO - Epoch 23, Step 79608: Loss=6.0404, Acc=0.318, PPL=420.07
2025-09-25 23:07:21,480 - training.trainer - INFO - Epoch 23, Step 79708: Loss=6.0691, Acc=0.294, PPL=432.30
2025-09-25 23:07:29,145 - training.trainer - INFO - Epoch 23, Step 79808: Loss=6.4055, Acc=0.158, PPL=605.18
2025-09-25 23:07:36,683 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.8315, Acc=0.267, PPL=340.87
2025-09-25 23:07:44,144 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.9115, Acc=0.250, PPL=369.24
2025-09-25 23:07:51,661 - training.trainer - INFO - Epoch 23, Step 80108: Loss=6.0938, Acc=0.154, PPL=443.11
2025-09-25 23:07:59,194 - training.trainer - INFO - Epoch 23, Step 80208: Loss=5.9699, Acc=0.214, PPL=391.45
2025-09-25 23:08:06,783 - training.trainer - INFO - Epoch 23, Step 80308: Loss=6.4222, Acc=0.227, PPL=615.34
2025-09-25 23:08:13,980 - training.trainer - INFO - Epoch 23, Step 80408: Loss=5.1293, Acc=0.250, PPL=168.89
2025-09-25 23:08:21,305 - training.trainer - INFO - Epoch 23, Step 80508: Loss=4.8126, Acc=0.250, PPL=123.06
2025-09-25 23:08:28,641 - training.trainer - INFO - Epoch 23, Step 80608: Loss=5.8529, Acc=0.186, PPL=348.24
2025-09-25 23:08:35,985 - training.trainer - INFO - Epoch 23, Step 80708: Loss=6.3966, Acc=0.235, PPL=599.79
2025-09-25 23:08:43,273 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.0776, Acc=0.273, PPL=160.39
2025-09-25 23:08:50,597 - training.trainer - INFO - Epoch 23, Step 80908: Loss=6.0532, Acc=0.171, PPL=425.49
2025-09-25 23:08:57,990 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.8012, Acc=0.219, PPL=330.71
2025-09-25 23:09:05,421 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.4257, Acc=0.258, PPL=227.17
2025-09-25 23:09:24,094 - training.trainer - INFO - Epoch 24/100 completed in 265.89s - Train Loss: 5.5657, Train Acc: 0.270, Val Loss: 5.6812, Val Acc: 0.255
2025-09-25 23:09:24,707 - training.trainer - INFO - New best model saved with validation loss: 5.6812
2025-09-25 23:09:24,707 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-09-25 23:09:31,482 - training.trainer - INFO - Epoch 24, Step 81291: Loss=5.6447, Acc=0.300, PPL=282.80
2025-09-25 23:09:38,504 - training.trainer - INFO - Epoch 24, Step 81391: Loss=7.1562, Acc=0.231, PPL=1282.08
2025-09-25 23:09:45,353 - training.trainer - INFO - Epoch 24, Step 81491: Loss=4.8898, Acc=0.306, PPL=132.93
2025-09-25 23:09:52,198 - training.trainer - INFO - Epoch 24, Step 81591: Loss=5.4571, Acc=0.268, PPL=234.41
2025-09-25 23:09:59,681 - training.trainer - INFO - Epoch 24, Step 81691: Loss=6.0018, Acc=0.216, PPL=404.16
2025-09-25 23:10:07,254 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.9758, Acc=0.200, PPL=393.78
2025-09-25 23:10:14,689 - training.trainer - INFO - Epoch 24, Step 81891: Loss=5.8996, Acc=0.172, PPL=364.90
2025-09-25 23:10:22,405 - training.trainer - INFO - Epoch 24, Step 81991: Loss=5.2661, Acc=0.250, PPL=193.66
2025-09-25 23:10:29,921 - training.trainer - INFO - Epoch 24, Step 82091: Loss=4.9428, Acc=0.240, PPL=140.16
2025-09-25 23:10:37,421 - training.trainer - INFO - Epoch 24, Step 82191: Loss=6.6080, Acc=0.143, PPL=740.99
2025-09-25 23:10:44,930 - training.trainer - INFO - Epoch 24, Step 82291: Loss=6.0251, Acc=0.230, PPL=413.67
2025-09-25 23:10:52,265 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.4548, Acc=0.273, PPL=233.88
2025-09-25 23:10:59,778 - training.trainer - INFO - Epoch 24, Step 82491: Loss=5.8614, Acc=0.317, PPL=351.22
2025-09-25 23:11:07,070 - training.trainer - INFO - Epoch 24, Step 82591: Loss=4.8998, Acc=0.385, PPL=134.26
2025-09-25 23:11:14,508 - training.trainer - INFO - Epoch 24, Step 82691: Loss=4.5929, Acc=0.583, PPL=98.78
2025-09-25 23:11:21,948 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.5000, Acc=0.316, PPL=244.70
2025-09-25 23:11:29,409 - training.trainer - INFO - Epoch 24, Step 82891: Loss=4.5558, Acc=0.381, PPL=95.19
2025-09-25 23:11:36,773 - training.trainer - INFO - Epoch 24, Step 82991: Loss=5.0407, Acc=0.341, PPL=154.58
2025-09-25 23:11:44,092 - training.trainer - INFO - Epoch 24, Step 83091: Loss=6.1972, Acc=0.160, PPL=491.39
2025-09-25 23:11:51,650 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.9987, Acc=0.240, PPL=402.92
2025-09-25 23:11:59,097 - training.trainer - INFO - Epoch 24, Step 83291: Loss=5.8085, Acc=0.250, PPL=333.13
2025-09-25 23:12:06,536 - training.trainer - INFO - Epoch 24, Step 83391: Loss=6.0809, Acc=0.226, PPL=437.43
2025-09-25 23:12:13,917 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.3312, Acc=0.348, PPL=206.69
2025-09-25 23:12:21,430 - training.trainer - INFO - Epoch 24, Step 83591: Loss=5.8152, Acc=0.217, PPL=335.37
2025-09-25 23:12:28,927 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.9382, Acc=0.229, PPL=379.26
2025-09-25 23:12:36,372 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.1084, Acc=0.278, PPL=165.40
2025-09-25 23:12:43,891 - training.trainer - INFO - Epoch 24, Step 83891: Loss=5.6769, Acc=0.207, PPL=292.05
2025-09-25 23:12:51,463 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.2446, Acc=0.231, PPL=189.54
2025-09-25 23:12:58,915 - training.trainer - INFO - Epoch 24, Step 84091: Loss=5.7429, Acc=0.258, PPL=311.98
2025-09-25 23:13:06,382 - training.trainer - INFO - Epoch 24, Step 84191: Loss=4.8104, Acc=0.325, PPL=122.78
2025-09-25 23:13:13,941 - training.trainer - INFO - Epoch 24, Step 84291: Loss=5.4119, Acc=0.297, PPL=224.06
2025-09-25 23:13:21,370 - training.trainer - INFO - Epoch 24, Step 84391: Loss=5.5174, Acc=0.208, PPL=248.98
2025-09-25 23:13:28,849 - training.trainer - INFO - Epoch 24, Step 84491: Loss=4.7026, Acc=0.348, PPL=110.24
2025-09-25 23:13:47,044 - training.trainer - INFO - Epoch 25/100 completed in 262.34s - Train Loss: 5.5496, Train Acc: 0.272, Val Loss: 5.6747, Val Acc: 0.255
2025-09-25 23:13:47,361 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-25 23:13:47,933 - training.trainer - INFO - New best model saved with validation loss: 5.6747
2025-09-25 23:13:47,933 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-25 23:13:55,765 - training.trainer - INFO - Epoch 25, Step 84674: Loss=5.8612, Acc=0.206, PPL=351.13
2025-09-25 23:14:03,497 - training.trainer - INFO - Epoch 25, Step 84774: Loss=5.9336, Acc=0.200, PPL=377.53
2025-09-25 23:14:11,065 - training.trainer - INFO - Epoch 25, Step 84874: Loss=6.0891, Acc=0.163, PPL=441.03
2025-09-25 23:14:18,517 - training.trainer - INFO - Epoch 25, Step 84974: Loss=6.1778, Acc=0.224, PPL=481.95
2025-09-25 23:14:26,102 - training.trainer - INFO - Epoch 25, Step 85074: Loss=5.2013, Acc=0.241, PPL=181.50
2025-09-25 23:14:33,591 - training.trainer - INFO - Epoch 25, Step 85174: Loss=6.0024, Acc=0.241, PPL=404.40
2025-09-25 23:14:41,073 - training.trainer - INFO - Epoch 25, Step 85274: Loss=4.2018, Acc=0.357, PPL=66.81
2025-09-25 23:14:48,420 - training.trainer - INFO - Epoch 25, Step 85374: Loss=6.1209, Acc=0.208, PPL=455.26
2025-09-25 23:14:55,846 - training.trainer - INFO - Epoch 25, Step 85474: Loss=5.8142, Acc=0.317, PPL=335.02
2025-09-25 23:15:03,199 - training.trainer - INFO - Epoch 25, Step 85574: Loss=5.4407, Acc=0.274, PPL=230.61
2025-09-25 23:15:10,542 - training.trainer - INFO - Epoch 25, Step 85674: Loss=5.2009, Acc=0.275, PPL=181.44
2025-09-25 23:15:17,836 - training.trainer - INFO - Epoch 25, Step 85774: Loss=6.0013, Acc=0.156, PPL=403.96
2025-09-25 23:15:25,141 - training.trainer - INFO - Epoch 25, Step 85874: Loss=5.4683, Acc=0.263, PPL=237.05
2025-09-25 23:15:32,477 - training.trainer - INFO - Epoch 25, Step 85974: Loss=5.8115, Acc=0.232, PPL=334.13
2025-09-25 23:15:39,895 - training.trainer - INFO - Epoch 25, Step 86074: Loss=6.8553, Acc=0.067, PPL=948.91
2025-09-25 23:15:47,390 - training.trainer - INFO - Epoch 25, Step 86174: Loss=5.8436, Acc=0.222, PPL=345.03
2025-09-25 23:15:54,865 - training.trainer - INFO - Epoch 25, Step 86274: Loss=6.0433, Acc=0.227, PPL=421.27
2025-09-25 23:16:02,193 - training.trainer - INFO - Epoch 25, Step 86374: Loss=5.5985, Acc=0.385, PPL=270.01
2025-09-25 23:16:09,624 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.7334, Acc=0.273, PPL=309.03
2025-09-25 23:16:16,956 - training.trainer - INFO - Epoch 25, Step 86574: Loss=6.1758, Acc=0.294, PPL=480.95
2025-09-25 23:16:24,225 - training.trainer - INFO - Epoch 25, Step 86674: Loss=5.9289, Acc=0.208, PPL=375.73
2025-09-25 23:16:31,560 - training.trainer - INFO - Epoch 25, Step 86774: Loss=6.5783, Acc=0.114, PPL=719.29
2025-09-25 23:16:39,068 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.6099, Acc=0.197, PPL=742.39
2025-09-25 23:16:46,585 - training.trainer - INFO - Epoch 25, Step 86974: Loss=5.2290, Acc=0.227, PPL=186.61
2025-09-25 23:16:54,019 - training.trainer - INFO - Epoch 25, Step 87074: Loss=5.5444, Acc=0.286, PPL=255.81
2025-09-25 23:17:01,369 - training.trainer - INFO - Epoch 25, Step 87174: Loss=5.1107, Acc=0.429, PPL=165.79
2025-09-25 23:17:08,839 - training.trainer - INFO - Epoch 25, Step 87274: Loss=6.2458, Acc=0.300, PPL=515.83
2025-09-25 23:17:16,355 - training.trainer - INFO - Epoch 25, Step 87374: Loss=6.4786, Acc=0.235, PPL=651.06
2025-09-25 23:17:24,062 - training.trainer - INFO - Epoch 25, Step 87474: Loss=4.6453, Acc=0.385, PPL=104.09
2025-09-25 23:17:31,376 - training.trainer - INFO - Epoch 25, Step 87574: Loss=4.2473, Acc=0.500, PPL=69.91
2025-09-25 23:17:38,748 - training.trainer - INFO - Epoch 25, Step 87674: Loss=5.0005, Acc=0.345, PPL=148.49
2025-09-25 23:17:46,209 - training.trainer - INFO - Epoch 25, Step 87774: Loss=5.9341, Acc=0.259, PPL=377.72
2025-09-25 23:17:53,499 - training.trainer - INFO - Epoch 25, Step 87874: Loss=5.5490, Acc=0.294, PPL=256.99
2025-09-25 23:18:12,189 - training.trainer - INFO - Epoch 26/100 completed in 264.26s - Train Loss: 5.5219, Train Acc: 0.276, Val Loss: 5.6713, Val Acc: 0.255
2025-09-25 23:18:12,876 - training.trainer - INFO - New best model saved with validation loss: 5.6713
2025-09-25 23:18:12,876 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_26.pt
2025-09-25 23:18:19,807 - training.trainer - INFO - Epoch 26, Step 88057: Loss=5.9091, Acc=0.275, PPL=368.38
2025-09-25 23:18:26,129 - training.trainer - INFO - Epoch 26, Step 88157: Loss=6.2236, Acc=0.140, PPL=504.53
2025-09-25 23:18:33,107 - training.trainer - INFO - Epoch 26, Step 88257: Loss=6.2205, Acc=0.265, PPL=502.95
2025-09-25 23:18:40,458 - training.trainer - INFO - Epoch 26, Step 88357: Loss=4.6526, Acc=0.391, PPL=104.85
2025-09-25 23:18:47,886 - training.trainer - INFO - Epoch 26, Step 88457: Loss=5.3653, Acc=0.317, PPL=213.86
2025-09-25 23:18:55,559 - training.trainer - INFO - Epoch 26, Step 88557: Loss=5.8002, Acc=0.219, PPL=330.36
2025-09-25 23:19:03,019 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.1497, Acc=0.379, PPL=172.38
2025-09-25 23:19:10,534 - training.trainer - INFO - Epoch 26, Step 88757: Loss=5.9203, Acc=0.191, PPL=372.54
2025-09-25 23:19:18,117 - training.trainer - INFO - Epoch 26, Step 88857: Loss=6.2723, Acc=0.190, PPL=529.71
2025-09-25 23:19:25,665 - training.trainer - INFO - Epoch 26, Step 88957: Loss=5.1604, Acc=0.424, PPL=174.23
2025-09-25 23:19:33,503 - training.trainer - INFO - Epoch 26, Step 89057: Loss=5.0610, Acc=0.258, PPL=157.74
2025-09-25 23:19:40,965 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.6347, Acc=0.263, PPL=279.96
2025-09-25 23:19:48,349 - training.trainer - INFO - Epoch 26, Step 89257: Loss=3.5901, Acc=0.433, PPL=36.24
2025-09-25 23:19:55,655 - training.trainer - INFO - Epoch 26, Step 89357: Loss=5.6591, Acc=0.357, PPL=286.88
2025-09-25 23:20:03,034 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.2933, Acc=0.277, PPL=199.00
2025-09-25 23:20:10,447 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.6717, Acc=0.133, PPL=290.52
2025-09-25 23:20:17,738 - training.trainer - INFO - Epoch 26, Step 89657: Loss=5.4720, Acc=0.308, PPL=237.94
2025-09-25 23:20:25,194 - training.trainer - INFO - Epoch 26, Step 89757: Loss=5.8696, Acc=0.278, PPL=354.11
2025-09-25 23:20:32,663 - training.trainer - INFO - Epoch 26, Step 89857: Loss=5.3601, Acc=0.222, PPL=212.74
2025-09-25 23:20:40,358 - training.trainer - INFO - Epoch 26, Step 89957: Loss=5.5503, Acc=0.312, PPL=257.31
2025-09-25 23:20:47,686 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.8954, Acc=0.200, PPL=363.35
2025-09-25 23:20:55,047 - training.trainer - INFO - Epoch 26, Step 90157: Loss=5.8459, Acc=0.169, PPL=345.80
2025-09-25 23:21:02,475 - training.trainer - INFO - Epoch 26, Step 90257: Loss=6.0590, Acc=0.205, PPL=427.96
2025-09-25 23:21:09,765 - training.trainer - INFO - Epoch 26, Step 90357: Loss=5.8273, Acc=0.108, PPL=339.45
2025-09-25 23:21:17,055 - training.trainer - INFO - Epoch 26, Step 90457: Loss=4.3628, Acc=0.389, PPL=78.47
2025-09-25 23:21:24,397 - training.trainer - INFO - Epoch 26, Step 90557: Loss=5.6025, Acc=0.241, PPL=271.10
2025-09-25 23:21:31,680 - training.trainer - INFO - Epoch 26, Step 90657: Loss=5.7903, Acc=0.267, PPL=327.12
2025-09-25 23:21:39,037 - training.trainer - INFO - Epoch 26, Step 90757: Loss=5.6978, Acc=0.212, PPL=298.21
2025-09-25 23:21:46,397 - training.trainer - INFO - Epoch 26, Step 90857: Loss=5.6422, Acc=0.308, PPL=282.07
2025-09-25 23:21:53,716 - training.trainer - INFO - Epoch 26, Step 90957: Loss=6.0120, Acc=0.286, PPL=408.31
2025-09-25 23:22:01,099 - training.trainer - INFO - Epoch 26, Step 91057: Loss=4.5870, Acc=0.308, PPL=98.19
2025-09-25 23:22:08,536 - training.trainer - INFO - Epoch 26, Step 91157: Loss=5.8301, Acc=0.286, PPL=340.40
2025-09-25 23:22:15,868 - training.trainer - INFO - Epoch 26, Step 91257: Loss=5.3601, Acc=0.306, PPL=212.74
2025-09-25 23:22:34,284 - training.trainer - INFO - Epoch 27/100 completed in 261.41s - Train Loss: 5.5087, Train Acc: 0.278, Val Loss: 5.6674, Val Acc: 0.256
2025-09-25 23:22:34,880 - training.trainer - INFO - New best model saved with validation loss: 5.6674
2025-09-25 23:22:34,880 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_27.pt
2025-09-25 23:22:41,855 - training.trainer - INFO - Epoch 27, Step 91440: Loss=5.1698, Acc=0.440, PPL=175.87
2025-09-25 23:22:48,542 - training.trainer - INFO - Epoch 27, Step 91540: Loss=5.5014, Acc=0.241, PPL=245.03
2025-09-25 23:22:55,818 - training.trainer - INFO - Epoch 27, Step 91640: Loss=5.4264, Acc=0.294, PPL=227.32
2025-09-25 23:23:03,385 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.9063, Acc=0.184, PPL=367.33
2025-09-25 23:23:11,097 - training.trainer - INFO - Epoch 27, Step 91840: Loss=5.5587, Acc=0.308, PPL=259.49
2025-09-25 23:23:18,640 - training.trainer - INFO - Epoch 27, Step 91940: Loss=5.7510, Acc=0.207, PPL=314.51
2025-09-25 23:23:25,901 - training.trainer - INFO - Epoch 27, Step 92040: Loss=5.4435, Acc=0.190, PPL=231.24
2025-09-25 23:23:33,157 - training.trainer - INFO - Epoch 27, Step 92140: Loss=5.0628, Acc=0.391, PPL=158.04
2025-09-25 23:23:40,496 - training.trainer - INFO - Epoch 27, Step 92240: Loss=6.1589, Acc=0.214, PPL=472.93
2025-09-25 23:23:47,985 - training.trainer - INFO - Epoch 27, Step 92340: Loss=3.6175, Acc=0.543, PPL=37.24
2025-09-25 23:23:55,321 - training.trainer - INFO - Epoch 27, Step 92440: Loss=5.4586, Acc=0.180, PPL=234.77
2025-09-25 23:24:02,838 - training.trainer - INFO - Epoch 27, Step 92540: Loss=6.4060, Acc=0.167, PPL=605.46
2025-09-25 23:24:10,174 - training.trainer - INFO - Epoch 27, Step 92640: Loss=5.3023, Acc=0.289, PPL=200.80
2025-09-25 23:24:17,544 - training.trainer - INFO - Epoch 27, Step 92740: Loss=6.3377, Acc=0.256, PPL=565.49
2025-09-25 23:24:24,903 - training.trainer - INFO - Epoch 27, Step 92840: Loss=6.3907, Acc=0.218, PPL=596.25
2025-09-25 23:24:32,151 - training.trainer - INFO - Epoch 27, Step 92940: Loss=6.3577, Acc=0.200, PPL=576.89
2025-09-25 23:24:39,448 - training.trainer - INFO - Epoch 27, Step 93040: Loss=6.0006, Acc=0.185, PPL=403.68
2025-09-25 23:24:46,665 - training.trainer - INFO - Epoch 27, Step 93140: Loss=5.6187, Acc=0.200, PPL=275.52
2025-09-25 23:24:53,989 - training.trainer - INFO - Epoch 27, Step 93240: Loss=5.8996, Acc=0.200, PPL=364.88
2025-09-25 23:25:01,232 - training.trainer - INFO - Epoch 27, Step 93340: Loss=4.9269, Acc=0.308, PPL=137.95
2025-09-25 23:25:08,495 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.4661, Acc=0.279, PPL=236.53
2025-09-25 23:25:16,109 - training.trainer - INFO - Epoch 27, Step 93540: Loss=5.8113, Acc=0.187, PPL=334.05
2025-09-25 23:25:23,300 - training.trainer - INFO - Epoch 27, Step 93640: Loss=4.9397, Acc=0.375, PPL=139.72
2025-09-25 23:25:30,615 - training.trainer - INFO - Epoch 27, Step 93740: Loss=5.2501, Acc=0.345, PPL=190.59
2025-09-25 23:25:37,789 - training.trainer - INFO - Epoch 27, Step 93840: Loss=5.8859, Acc=0.217, PPL=359.92
2025-09-25 23:25:44,995 - training.trainer - INFO - Epoch 27, Step 93940: Loss=5.3167, Acc=0.286, PPL=203.70
2025-09-25 23:25:52,221 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.1387, Acc=0.350, PPL=170.50
2025-09-25 23:25:59,522 - training.trainer - INFO - Epoch 27, Step 94140: Loss=6.1142, Acc=0.261, PPL=452.24
2025-09-25 23:26:06,913 - training.trainer - INFO - Epoch 27, Step 94240: Loss=5.7959, Acc=0.209, PPL=328.96
2025-09-25 23:26:14,727 - training.trainer - INFO - Epoch 27, Step 94340: Loss=5.9063, Acc=0.345, PPL=367.35
2025-09-25 23:26:22,105 - training.trainer - INFO - Epoch 27, Step 94440: Loss=5.7496, Acc=0.300, PPL=314.05
2025-09-25 23:26:29,330 - training.trainer - INFO - Epoch 27, Step 94540: Loss=5.7273, Acc=0.273, PPL=307.14
2025-09-25 23:26:36,702 - training.trainer - INFO - Epoch 27, Step 94640: Loss=5.8509, Acc=0.265, PPL=347.54
2025-09-25 23:26:55,335 - training.trainer - INFO - Epoch 28/100 completed in 260.45s - Train Loss: 5.4891, Train Acc: 0.280, Val Loss: 5.6697, Val Acc: 0.255
2025-09-25 23:27:03,455 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.5824, Acc=0.262, PPL=265.72
2025-09-25 23:27:10,918 - training.trainer - INFO - Epoch 28, Step 94923: Loss=5.3466, Acc=0.306, PPL=209.89
2025-09-25 23:27:18,413 - training.trainer - INFO - Epoch 28, Step 95023: Loss=5.5692, Acc=0.208, PPL=262.23
2025-09-25 23:27:25,908 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.6249, Acc=0.273, PPL=277.25
2025-09-25 23:27:33,330 - training.trainer - INFO - Epoch 28, Step 95223: Loss=6.3408, Acc=0.250, PPL=567.24
2025-09-25 23:27:40,819 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.4884, Acc=0.231, PPL=241.87
2025-09-25 23:27:48,104 - training.trainer - INFO - Epoch 28, Step 95423: Loss=5.7002, Acc=0.217, PPL=298.94
2025-09-25 23:27:56,355 - training.trainer - INFO - Epoch 28, Step 95523: Loss=5.5365, Acc=0.262, PPL=253.79
2025-09-25 23:28:03,893 - training.trainer - INFO - Epoch 28, Step 95623: Loss=5.3082, Acc=0.250, PPL=201.99
2025-09-25 23:28:11,439 - training.trainer - INFO - Epoch 28, Step 95723: Loss=5.3788, Acc=0.309, PPL=216.75
2025-09-25 23:28:18,959 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.1576, Acc=0.231, PPL=173.75
2025-09-25 23:28:26,365 - training.trainer - INFO - Epoch 28, Step 95923: Loss=6.3367, Acc=0.176, PPL=564.91
2025-09-25 23:28:33,695 - training.trainer - INFO - Epoch 28, Step 96023: Loss=5.0187, Acc=0.302, PPL=151.21
2025-09-25 23:28:41,118 - training.trainer - INFO - Epoch 28, Step 96123: Loss=5.5554, Acc=0.296, PPL=258.64
2025-09-25 23:28:48,475 - training.trainer - INFO - Epoch 28, Step 96223: Loss=5.5985, Acc=0.294, PPL=270.02
2025-09-25 23:28:55,820 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.1664, Acc=0.237, PPL=175.29
2025-09-25 23:29:03,164 - training.trainer - INFO - Epoch 28, Step 96423: Loss=5.2741, Acc=0.308, PPL=195.21
2025-09-25 23:29:10,504 - training.trainer - INFO - Epoch 28, Step 96523: Loss=4.7527, Acc=0.250, PPL=115.90
2025-09-25 23:29:17,979 - training.trainer - INFO - Epoch 28, Step 96623: Loss=5.5506, Acc=0.200, PPL=257.40
2025-09-25 23:29:25,319 - training.trainer - INFO - Epoch 28, Step 96723: Loss=5.7739, Acc=0.260, PPL=321.78
2025-09-25 23:29:32,630 - training.trainer - INFO - Epoch 28, Step 96823: Loss=5.3249, Acc=0.306, PPL=205.39
2025-09-25 23:29:40,069 - training.trainer - INFO - Epoch 28, Step 96923: Loss=4.7780, Acc=0.231, PPL=118.87
2025-09-25 23:29:47,523 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.5450, Acc=0.241, PPL=255.95
2025-09-25 23:29:54,921 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.7860, Acc=0.259, PPL=325.70
2025-09-25 23:30:02,208 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.5370, Acc=0.351, PPL=253.91
2025-09-25 23:30:09,497 - training.trainer - INFO - Epoch 28, Step 97323: Loss=5.9877, Acc=0.308, PPL=398.51
2025-09-25 23:30:16,777 - training.trainer - INFO - Epoch 28, Step 97423: Loss=2.4140, Acc=0.676, PPL=11.18
2025-09-25 23:30:24,154 - training.trainer - INFO - Epoch 28, Step 97523: Loss=4.7239, Acc=0.333, PPL=112.61
2025-09-25 23:30:31,428 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.9083, Acc=0.222, PPL=368.09
2025-09-25 23:30:38,753 - training.trainer - INFO - Epoch 28, Step 97723: Loss=4.7580, Acc=0.320, PPL=116.52
2025-09-25 23:30:46,075 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.2949, Acc=0.444, PPL=199.31
2025-09-25 23:30:53,525 - training.trainer - INFO - Epoch 28, Step 97923: Loss=5.9214, Acc=0.231, PPL=372.92
2025-09-25 23:31:00,960 - training.trainer - INFO - Epoch 28, Step 98023: Loss=5.5684, Acc=0.316, PPL=262.02
2025-09-25 23:31:19,778 - training.trainer - INFO - Epoch 29/100 completed in 264.44s - Train Loss: 5.4733, Train Acc: 0.282, Val Loss: 5.6658, Val Acc: 0.257
2025-09-25 23:31:20,370 - training.trainer - INFO - New best model saved with validation loss: 5.6658
2025-09-25 23:31:20,370 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_29.pt
2025-09-25 23:31:27,954 - training.trainer - INFO - Epoch 29, Step 98206: Loss=5.1959, Acc=0.372, PPL=180.53
2025-09-25 23:31:35,412 - training.trainer - INFO - Epoch 29, Step 98306: Loss=5.2095, Acc=0.286, PPL=183.00
2025-09-25 23:31:42,760 - training.trainer - INFO - Epoch 29, Step 98406: Loss=5.9920, Acc=0.217, PPL=400.21
2025-09-25 23:31:50,185 - training.trainer - INFO - Epoch 29, Step 98506: Loss=6.2620, Acc=0.270, PPL=524.27
2025-09-25 23:31:57,597 - training.trainer - INFO - Epoch 29, Step 98606: Loss=5.1828, Acc=0.277, PPL=178.18
2025-09-25 23:32:04,913 - training.trainer - INFO - Epoch 29, Step 98706: Loss=5.5573, Acc=0.219, PPL=259.13
2025-09-25 23:32:12,222 - training.trainer - INFO - Epoch 29, Step 98806: Loss=6.0394, Acc=0.211, PPL=419.63
2025-09-25 23:32:19,529 - training.trainer - INFO - Epoch 29, Step 98906: Loss=5.5972, Acc=0.218, PPL=269.66
2025-09-25 23:32:26,886 - training.trainer - INFO - Epoch 29, Step 99006: Loss=5.6832, Acc=0.289, PPL=293.88
2025-09-25 23:32:34,340 - training.trainer - INFO - Epoch 29, Step 99106: Loss=5.4983, Acc=0.286, PPL=244.28
2025-09-25 23:32:42,068 - training.trainer - INFO - Epoch 29, Step 99206: Loss=5.8682, Acc=0.170, PPL=353.60
2025-09-25 23:32:49,441 - training.trainer - INFO - Epoch 29, Step 99306: Loss=6.1404, Acc=0.200, PPL=464.24
2025-09-25 23:32:56,949 - training.trainer - INFO - Epoch 29, Step 99406: Loss=6.2502, Acc=0.209, PPL=518.13
2025-09-25 23:33:04,561 - training.trainer - INFO - Epoch 29, Step 99506: Loss=5.5451, Acc=0.353, PPL=255.99
2025-09-25 23:33:12,130 - training.trainer - INFO - Epoch 29, Step 99606: Loss=5.7568, Acc=0.176, PPL=316.35
2025-09-25 23:33:19,727 - training.trainer - INFO - Epoch 29, Step 99706: Loss=5.6551, Acc=0.283, PPL=285.73
2025-09-25 23:33:27,413 - training.trainer - INFO - Epoch 29, Step 99806: Loss=4.8141, Acc=0.417, PPL=123.23
2025-09-25 23:33:34,874 - training.trainer - INFO - Epoch 29, Step 99906: Loss=6.1060, Acc=0.224, PPL=448.55
2025-09-25 23:33:42,370 - training.trainer - INFO - Epoch 29, Step 100006: Loss=5.2648, Acc=0.286, PPL=193.41
2025-09-25 23:33:50,003 - training.trainer - INFO - Epoch 29, Step 100106: Loss=5.3136, Acc=0.304, PPL=203.09
2025-09-25 23:33:57,535 - training.trainer - INFO - Epoch 29, Step 100206: Loss=4.8923, Acc=0.375, PPL=133.25
2025-09-25 23:34:05,098 - training.trainer - INFO - Epoch 29, Step 100306: Loss=3.8535, Acc=0.529, PPL=47.16
2025-09-25 23:34:12,661 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.3817, Acc=0.333, PPL=217.39
2025-09-25 23:34:20,174 - training.trainer - INFO - Epoch 29, Step 100506: Loss=6.0815, Acc=0.200, PPL=437.69
2025-09-25 23:34:27,616 - training.trainer - INFO - Epoch 29, Step 100606: Loss=4.3085, Acc=0.440, PPL=74.33
2025-09-25 23:34:35,063 - training.trainer - INFO - Epoch 29, Step 100706: Loss=5.7337, Acc=0.235, PPL=309.11
2025-09-25 23:34:42,436 - training.trainer - INFO - Epoch 29, Step 100806: Loss=5.7147, Acc=0.313, PPL=303.29
2025-09-25 23:34:49,735 - training.trainer - INFO - Epoch 29, Step 100906: Loss=3.1601, Acc=0.583, PPL=23.57
2025-09-25 23:34:57,187 - training.trainer - INFO - Epoch 29, Step 101006: Loss=5.9915, Acc=0.146, PPL=400.03
2025-09-25 23:35:04,699 - training.trainer - INFO - Epoch 29, Step 101106: Loss=5.3702, Acc=0.250, PPL=214.92
2025-09-25 23:35:12,114 - training.trainer - INFO - Epoch 29, Step 101206: Loss=5.2420, Acc=0.387, PPL=189.05
2025-09-25 23:35:19,545 - training.trainer - INFO - Epoch 29, Step 101306: Loss=5.9333, Acc=0.312, PPL=377.40
2025-09-25 23:35:26,824 - training.trainer - INFO - Epoch 29, Step 101406: Loss=5.5488, Acc=0.306, PPL=256.93
2025-09-25 23:35:45,742 - training.trainer - INFO - Epoch 30/100 completed in 265.37s - Train Loss: 5.4609, Train Acc: 0.285, Val Loss: 5.6585, Val Acc: 0.258
2025-09-25 23:35:46,043 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-25 23:35:46,653 - training.trainer - INFO - New best model saved with validation loss: 5.6585
2025-09-25 23:35:46,653 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-25 23:35:53,435 - training.trainer - INFO - Epoch 30, Step 101589: Loss=5.5261, Acc=0.219, PPL=251.17
2025-09-25 23:36:00,467 - training.trainer - INFO - Epoch 30, Step 101689: Loss=5.4331, Acc=0.261, PPL=228.86
2025-09-25 23:36:07,691 - training.trainer - INFO - Epoch 30, Step 101789: Loss=4.9141, Acc=0.379, PPL=136.19
2025-09-25 23:36:14,918 - training.trainer - INFO - Epoch 30, Step 101889: Loss=5.0715, Acc=0.344, PPL=159.42
2025-09-25 23:36:22,268 - training.trainer - INFO - Epoch 30, Step 101989: Loss=3.8558, Acc=0.450, PPL=47.27
2025-09-25 23:36:29,440 - training.trainer - INFO - Epoch 30, Step 102089: Loss=5.7739, Acc=0.205, PPL=321.79
2025-09-25 23:36:36,615 - training.trainer - INFO - Epoch 30, Step 102189: Loss=5.4781, Acc=0.256, PPL=239.40
2025-09-25 23:36:43,801 - training.trainer - INFO - Epoch 30, Step 102289: Loss=5.2164, Acc=0.338, PPL=184.28
2025-09-25 23:36:51,049 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.5879, Acc=0.204, PPL=267.18
2025-09-25 23:36:58,415 - training.trainer - INFO - Epoch 30, Step 102489: Loss=5.6781, Acc=0.333, PPL=292.40
2025-09-25 23:37:05,744 - training.trainer - INFO - Epoch 30, Step 102589: Loss=5.5680, Acc=0.306, PPL=261.90
2025-09-25 23:37:13,018 - training.trainer - INFO - Epoch 30, Step 102689: Loss=4.6568, Acc=0.410, PPL=105.30
2025-09-25 23:37:20,498 - training.trainer - INFO - Epoch 30, Step 102789: Loss=5.6830, Acc=0.288, PPL=293.82
2025-09-25 23:37:27,939 - training.trainer - INFO - Epoch 30, Step 102889: Loss=5.2006, Acc=0.163, PPL=181.38
2025-09-25 23:37:35,153 - training.trainer - INFO - Epoch 30, Step 102989: Loss=4.6003, Acc=0.333, PPL=99.51
2025-09-25 23:37:42,508 - training.trainer - INFO - Epoch 30, Step 103089: Loss=4.5752, Acc=0.382, PPL=97.05
2025-09-25 23:37:49,837 - training.trainer - INFO - Epoch 30, Step 103189: Loss=5.1941, Acc=0.200, PPL=180.20
2025-09-25 23:37:57,155 - training.trainer - INFO - Epoch 30, Step 103289: Loss=6.4816, Acc=0.255, PPL=653.02
2025-09-25 23:38:04,541 - training.trainer - INFO - Epoch 30, Step 103389: Loss=4.1895, Acc=0.412, PPL=65.99
2025-09-25 23:38:12,198 - training.trainer - INFO - Epoch 30, Step 103489: Loss=5.8050, Acc=0.262, PPL=331.95
2025-09-25 23:38:19,757 - training.trainer - INFO - Epoch 30, Step 103589: Loss=5.5227, Acc=0.306, PPL=250.32
2025-09-25 23:38:27,274 - training.trainer - INFO - Epoch 30, Step 103689: Loss=6.1441, Acc=0.138, PPL=465.96
2025-09-25 23:38:34,866 - training.trainer - INFO - Epoch 30, Step 103789: Loss=6.0925, Acc=0.182, PPL=442.52
2025-09-25 23:38:42,437 - training.trainer - INFO - Epoch 30, Step 103889: Loss=5.8610, Acc=0.222, PPL=351.09
2025-09-25 23:38:49,895 - training.trainer - INFO - Epoch 30, Step 103989: Loss=6.0764, Acc=0.145, PPL=435.48
2025-09-25 23:38:57,359 - training.trainer - INFO - Epoch 30, Step 104089: Loss=5.1064, Acc=0.304, PPL=165.08
2025-09-25 23:39:04,850 - training.trainer - INFO - Epoch 30, Step 104189: Loss=5.6272, Acc=0.264, PPL=277.89
2025-09-25 23:39:12,330 - training.trainer - INFO - Epoch 30, Step 104289: Loss=5.2452, Acc=0.294, PPL=189.66
2025-09-25 23:39:19,980 - training.trainer - INFO - Epoch 30, Step 104389: Loss=6.3597, Acc=0.158, PPL=578.09
2025-09-25 23:39:27,501 - training.trainer - INFO - Epoch 30, Step 104489: Loss=5.3294, Acc=0.227, PPL=206.31
2025-09-25 23:39:34,923 - training.trainer - INFO - Epoch 30, Step 104589: Loss=5.5577, Acc=0.267, PPL=259.22
2025-09-25 23:39:42,234 - training.trainer - INFO - Epoch 30, Step 104689: Loss=6.0263, Acc=0.242, PPL=414.18
2025-09-25 23:39:49,756 - training.trainer - INFO - Epoch 30, Step 104789: Loss=5.0749, Acc=0.263, PPL=159.96
2025-09-25 23:40:08,695 - training.trainer - INFO - Epoch 31/100 completed in 262.04s - Train Loss: 5.4345, Train Acc: 0.289, Val Loss: 5.6654, Val Acc: 0.258
2025-09-25 23:40:16,760 - training.trainer - INFO - Epoch 31, Step 104972: Loss=4.9226, Acc=0.310, PPL=137.36
2025-09-25 23:40:24,410 - training.trainer - INFO - Epoch 31, Step 105072: Loss=5.6470, Acc=0.300, PPL=283.44
2025-09-25 23:40:31,486 - training.trainer - INFO - Epoch 31, Step 105172: Loss=4.9928, Acc=0.296, PPL=147.34
2025-09-25 23:40:39,135 - training.trainer - INFO - Epoch 31, Step 105272: Loss=5.4265, Acc=0.226, PPL=227.36
2025-09-25 23:40:46,845 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.4976, Acc=0.233, PPL=244.10
2025-09-25 23:40:54,302 - training.trainer - INFO - Epoch 31, Step 105472: Loss=6.1722, Acc=0.259, PPL=479.23
2025-09-25 23:41:01,601 - training.trainer - INFO - Epoch 31, Step 105572: Loss=4.8036, Acc=0.312, PPL=121.94
2025-09-25 23:41:08,880 - training.trainer - INFO - Epoch 31, Step 105672: Loss=4.9177, Acc=0.364, PPL=136.68
2025-09-25 23:41:16,128 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.7059, Acc=0.283, PPL=300.64
2025-09-25 23:41:23,411 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.9440, Acc=0.323, PPL=381.44
2025-09-25 23:41:30,659 - training.trainer - INFO - Epoch 31, Step 105972: Loss=5.7169, Acc=0.304, PPL=303.97
2025-09-25 23:41:37,915 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.1993, Acc=0.250, PPL=181.15
2025-09-25 23:41:45,147 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.6166, Acc=0.298, PPL=274.95
2025-09-25 23:41:52,481 - training.trainer - INFO - Epoch 31, Step 106272: Loss=4.2839, Acc=0.480, PPL=72.52
2025-09-25 23:41:59,699 - training.trainer - INFO - Epoch 31, Step 106372: Loss=5.7481, Acc=0.283, PPL=313.58
2025-09-25 23:42:06,894 - training.trainer - INFO - Epoch 31, Step 106472: Loss=5.0866, Acc=0.346, PPL=161.84
2025-09-25 23:42:14,160 - training.trainer - INFO - Epoch 31, Step 106572: Loss=5.3952, Acc=0.286, PPL=220.34
2025-09-25 23:42:21,453 - training.trainer - INFO - Epoch 31, Step 106672: Loss=3.0390, Acc=0.565, PPL=20.88
2025-09-25 23:42:28,954 - training.trainer - INFO - Epoch 31, Step 106772: Loss=6.0042, Acc=0.244, PPL=405.13
2025-09-25 23:42:36,202 - training.trainer - INFO - Epoch 31, Step 106872: Loss=5.4617, Acc=0.257, PPL=235.49
2025-09-25 23:42:43,600 - training.trainer - INFO - Epoch 31, Step 106972: Loss=5.6046, Acc=0.276, PPL=271.67
2025-09-25 23:42:51,144 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.8464, Acc=0.250, PPL=346.00
2025-09-25 23:42:58,621 - training.trainer - INFO - Epoch 31, Step 107172: Loss=5.4370, Acc=0.279, PPL=229.74
2025-09-25 23:43:05,837 - training.trainer - INFO - Epoch 31, Step 107272: Loss=6.1333, Acc=0.170, PPL=460.95
2025-09-25 23:43:13,089 - training.trainer - INFO - Epoch 31, Step 107372: Loss=5.6508, Acc=0.242, PPL=284.53
2025-09-25 23:43:20,271 - training.trainer - INFO - Epoch 31, Step 107472: Loss=6.4054, Acc=0.185, PPL=605.13
2025-09-25 23:43:27,571 - training.trainer - INFO - Epoch 31, Step 107572: Loss=4.1595, Acc=0.412, PPL=64.04
2025-09-25 23:43:34,964 - training.trainer - INFO - Epoch 31, Step 107672: Loss=5.9988, Acc=0.185, PPL=402.96
2025-09-25 23:43:42,520 - training.trainer - INFO - Epoch 31, Step 107772: Loss=5.6711, Acc=0.231, PPL=290.36
2025-09-25 23:43:50,059 - training.trainer - INFO - Epoch 31, Step 107872: Loss=5.2620, Acc=0.273, PPL=192.87
2025-09-25 23:43:57,610 - training.trainer - INFO - Epoch 31, Step 107972: Loss=6.3365, Acc=0.250, PPL=564.81
2025-09-25 23:44:05,240 - training.trainer - INFO - Epoch 31, Step 108072: Loss=5.4798, Acc=0.321, PPL=239.80
2025-09-25 23:44:13,164 - training.trainer - INFO - Epoch 31, Step 108172: Loss=5.9015, Acc=0.189, PPL=365.58
2025-09-25 23:44:32,372 - training.trainer - INFO - Epoch 32/100 completed in 263.68s - Train Loss: 5.4250, Train Acc: 0.290, Val Loss: 5.6634, Val Acc: 0.259
2025-09-25 23:44:40,261 - training.trainer - INFO - Epoch 32, Step 108355: Loss=6.3363, Acc=0.300, PPL=564.69
2025-09-25 23:44:47,147 - training.trainer - INFO - Epoch 32, Step 108455: Loss=5.3801, Acc=0.240, PPL=217.05
2025-09-25 23:44:54,115 - training.trainer - INFO - Epoch 32, Step 108555: Loss=5.8860, Acc=0.265, PPL=359.98
2025-09-25 23:45:01,045 - training.trainer - INFO - Epoch 32, Step 108655: Loss=5.3733, Acc=0.333, PPL=215.58
2025-09-25 23:45:08,622 - training.trainer - INFO - Epoch 32, Step 108755: Loss=5.3377, Acc=0.297, PPL=208.04
2025-09-25 23:45:16,080 - training.trainer - INFO - Epoch 32, Step 108855: Loss=5.3617, Acc=0.349, PPL=213.08
2025-09-25 23:45:23,684 - training.trainer - INFO - Epoch 32, Step 108955: Loss=5.3421, Acc=0.212, PPL=208.94
2025-09-25 23:45:31,276 - training.trainer - INFO - Epoch 32, Step 109055: Loss=4.9426, Acc=0.440, PPL=140.13
2025-09-25 23:45:38,931 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.7533, Acc=0.235, PPL=315.23
2025-09-25 23:45:46,583 - training.trainer - INFO - Epoch 32, Step 109255: Loss=4.8067, Acc=0.356, PPL=122.33
2025-09-25 23:45:54,115 - training.trainer - INFO - Epoch 32, Step 109355: Loss=5.0290, Acc=0.378, PPL=152.77
2025-09-25 23:46:01,809 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.3406, Acc=0.267, PPL=208.63
2025-09-25 23:46:09,270 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.0171, Acc=0.333, PPL=150.98
2025-09-25 23:46:16,916 - training.trainer - INFO - Epoch 32, Step 109655: Loss=6.0632, Acc=0.271, PPL=429.75
2025-09-25 23:46:24,397 - training.trainer - INFO - Epoch 32, Step 109755: Loss=5.3638, Acc=0.192, PPL=213.53
2025-09-25 23:46:31,904 - training.trainer - INFO - Epoch 32, Step 109855: Loss=4.9779, Acc=0.241, PPL=145.17
2025-09-25 23:46:39,404 - training.trainer - INFO - Epoch 32, Step 109955: Loss=5.1696, Acc=0.300, PPL=175.85
2025-09-25 23:46:47,036 - training.trainer - INFO - Epoch 32, Step 110055: Loss=5.7962, Acc=0.237, PPL=329.05
2025-09-25 23:46:54,550 - training.trainer - INFO - Epoch 32, Step 110155: Loss=4.9384, Acc=0.309, PPL=139.55
2025-09-25 23:47:02,014 - training.trainer - INFO - Epoch 32, Step 110255: Loss=5.6328, Acc=0.255, PPL=279.44
2025-09-25 23:47:09,523 - training.trainer - INFO - Epoch 32, Step 110355: Loss=4.4931, Acc=0.391, PPL=89.40
2025-09-25 23:47:17,192 - training.trainer - INFO - Epoch 32, Step 110455: Loss=6.1178, Acc=0.273, PPL=453.85
2025-09-25 23:47:24,605 - training.trainer - INFO - Epoch 32, Step 110555: Loss=6.0387, Acc=0.234, PPL=419.33
2025-09-25 23:47:32,101 - training.trainer - INFO - Epoch 32, Step 110655: Loss=6.1026, Acc=0.241, PPL=447.02
2025-09-25 23:47:39,533 - training.trainer - INFO - Epoch 32, Step 110755: Loss=6.3425, Acc=0.241, PPL=568.23
2025-09-25 23:47:47,017 - training.trainer - INFO - Epoch 32, Step 110855: Loss=5.4257, Acc=0.353, PPL=227.17
2025-09-25 23:47:54,628 - training.trainer - INFO - Epoch 32, Step 110955: Loss=5.9305, Acc=0.321, PPL=376.35
2025-09-25 23:48:02,022 - training.trainer - INFO - Epoch 32, Step 111055: Loss=6.1326, Acc=0.244, PPL=460.61
2025-09-25 23:48:09,451 - training.trainer - INFO - Epoch 32, Step 111155: Loss=5.8124, Acc=0.217, PPL=334.42
2025-09-25 23:48:16,903 - training.trainer - INFO - Epoch 32, Step 111255: Loss=5.7002, Acc=0.286, PPL=298.93
2025-09-25 23:48:24,363 - training.trainer - INFO - Epoch 32, Step 111355: Loss=5.7472, Acc=0.310, PPL=313.31
2025-09-25 23:48:31,777 - training.trainer - INFO - Epoch 32, Step 111455: Loss=5.9205, Acc=0.240, PPL=372.61
2025-09-25 23:48:39,396 - training.trainer - INFO - Epoch 32, Step 111555: Loss=5.6258, Acc=0.185, PPL=277.48
2025-09-25 23:48:58,514 - training.trainer - INFO - Epoch 33/100 completed in 266.14s - Train Loss: 5.4104, Train Acc: 0.293, Val Loss: 5.6654, Val Acc: 0.258
2025-09-25 23:49:06,045 - training.trainer - INFO - Epoch 33, Step 111738: Loss=4.2037, Acc=0.458, PPL=66.94
2025-09-25 23:49:12,884 - training.trainer - INFO - Epoch 33, Step 111838: Loss=5.4899, Acc=0.229, PPL=242.23
2025-09-25 23:49:19,961 - training.trainer - INFO - Epoch 33, Step 111938: Loss=4.8368, Acc=0.250, PPL=126.06
2025-09-25 23:49:27,365 - training.trainer - INFO - Epoch 33, Step 112038: Loss=5.0051, Acc=0.325, PPL=149.18
2025-09-25 23:49:34,917 - training.trainer - INFO - Epoch 33, Step 112138: Loss=4.7177, Acc=0.350, PPL=111.91
2025-09-25 23:49:42,318 - training.trainer - INFO - Epoch 33, Step 112238: Loss=5.5208, Acc=0.240, PPL=249.83
2025-09-25 23:49:49,647 - training.trainer - INFO - Epoch 33, Step 112338: Loss=5.2754, Acc=0.382, PPL=195.47
2025-09-25 23:49:56,926 - training.trainer - INFO - Epoch 33, Step 112438: Loss=5.8382, Acc=0.171, PPL=343.17
2025-09-25 23:50:04,407 - training.trainer - INFO - Epoch 33, Step 112538: Loss=5.9235, Acc=0.273, PPL=373.71
2025-09-25 23:50:11,723 - training.trainer - INFO - Epoch 33, Step 112638: Loss=4.8530, Acc=0.393, PPL=128.13
2025-09-25 23:50:19,046 - training.trainer - INFO - Epoch 33, Step 112738: Loss=3.9629, Acc=0.520, PPL=52.61
2025-09-25 23:50:26,359 - training.trainer - INFO - Epoch 33, Step 112838: Loss=6.1138, Acc=0.158, PPL=452.06
2025-09-25 23:50:33,801 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.4750, Acc=0.280, PPL=238.65
2025-09-25 23:50:41,123 - training.trainer - INFO - Epoch 33, Step 113038: Loss=5.4684, Acc=0.286, PPL=237.07
2025-09-25 23:50:48,417 - training.trainer - INFO - Epoch 33, Step 113138: Loss=3.1336, Acc=0.625, PPL=22.96
2025-09-25 23:50:55,766 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.5810, Acc=0.259, PPL=265.34
2025-09-25 23:51:03,154 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.1406, Acc=0.200, PPL=170.82
2025-09-25 23:51:10,611 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.8275, Acc=0.222, PPL=339.52
2025-09-25 23:51:18,002 - training.trainer - INFO - Epoch 33, Step 113538: Loss=6.1323, Acc=0.188, PPL=460.49
2025-09-25 23:51:25,366 - training.trainer - INFO - Epoch 33, Step 113638: Loss=6.2226, Acc=0.136, PPL=504.01
2025-09-25 23:51:32,722 - training.trainer - INFO - Epoch 33, Step 113738: Loss=4.0375, Acc=0.438, PPL=56.69
2025-09-25 23:51:40,137 - training.trainer - INFO - Epoch 33, Step 113838: Loss=5.6833, Acc=0.219, PPL=293.91
2025-09-25 23:51:47,726 - training.trainer - INFO - Epoch 33, Step 113938: Loss=6.0970, Acc=0.208, PPL=444.54
2025-09-25 23:51:55,304 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.3021, Acc=0.267, PPL=200.75
2025-09-25 23:52:02,817 - training.trainer - INFO - Epoch 33, Step 114138: Loss=4.9925, Acc=0.224, PPL=147.31
2025-09-25 23:52:10,162 - training.trainer - INFO - Epoch 33, Step 114238: Loss=5.8778, Acc=0.236, PPL=357.04
2025-09-25 23:52:17,678 - training.trainer - INFO - Epoch 33, Step 114338: Loss=6.8073, Acc=0.235, PPL=904.44
2025-09-25 23:52:25,014 - training.trainer - INFO - Epoch 33, Step 114438: Loss=5.9361, Acc=0.206, PPL=378.47
2025-09-25 23:52:32,545 - training.trainer - INFO - Epoch 33, Step 114538: Loss=4.8893, Acc=0.391, PPL=132.86
2025-09-25 23:52:39,966 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.2389, Acc=0.298, PPL=188.47
2025-09-25 23:52:47,579 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.3330, Acc=0.238, PPL=207.05
2025-09-25 23:52:55,337 - training.trainer - INFO - Epoch 33, Step 114838: Loss=5.4586, Acc=0.283, PPL=234.77
2025-09-25 23:53:02,915 - training.trainer - INFO - Epoch 33, Step 114938: Loss=5.4155, Acc=0.308, PPL=224.86
2025-09-25 23:53:21,652 - training.trainer - INFO - Epoch 34/100 completed in 263.14s - Train Loss: 5.3925, Train Acc: 0.295, Val Loss: 5.6592, Val Acc: 0.258
2025-09-25 23:53:28,245 - training.trainer - INFO - Epoch 34, Step 115121: Loss=6.3551, Acc=0.140, PPL=575.42
2025-09-25 23:53:35,040 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.3129, Acc=0.300, PPL=202.93
2025-09-25 23:53:42,610 - training.trainer - INFO - Epoch 34, Step 115321: Loss=5.0996, Acc=0.304, PPL=163.96
2025-09-25 23:53:50,226 - training.trainer - INFO - Epoch 34, Step 115421: Loss=5.4171, Acc=0.323, PPL=225.23
2025-09-25 23:53:57,615 - training.trainer - INFO - Epoch 34, Step 115521: Loss=6.8023, Acc=0.133, PPL=899.89
2025-09-25 23:54:04,594 - training.trainer - INFO - Epoch 34, Step 115621: Loss=5.7279, Acc=0.256, PPL=307.33
2025-09-25 23:54:11,937 - training.trainer - INFO - Epoch 34, Step 115721: Loss=3.6675, Acc=0.636, PPL=39.15
2025-09-25 23:54:19,485 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.4858, Acc=0.280, PPL=241.25
2025-09-25 23:54:27,124 - training.trainer - INFO - Epoch 34, Step 115921: Loss=5.1644, Acc=0.368, PPL=174.93
2025-09-25 23:54:34,535 - training.trainer - INFO - Epoch 34, Step 116021: Loss=4.9008, Acc=0.360, PPL=134.39
2025-09-25 23:54:41,940 - training.trainer - INFO - Epoch 34, Step 116121: Loss=4.5470, Acc=0.333, PPL=94.35
2025-09-25 23:54:49,373 - training.trainer - INFO - Epoch 34, Step 116221: Loss=5.1702, Acc=0.333, PPL=175.94
2025-09-25 23:54:56,811 - training.trainer - INFO - Epoch 34, Step 116321: Loss=5.0332, Acc=0.319, PPL=153.42
2025-09-25 23:55:04,295 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.6688, Acc=0.214, PPL=289.70
2025-09-25 23:55:11,766 - training.trainer - INFO - Epoch 34, Step 116521: Loss=6.0199, Acc=0.209, PPL=411.52
2025-09-25 23:55:19,153 - training.trainer - INFO - Epoch 34, Step 116621: Loss=5.5911, Acc=0.266, PPL=268.03
2025-09-25 23:55:26,639 - training.trainer - INFO - Epoch 34, Step 116721: Loss=5.5223, Acc=0.262, PPL=250.21
2025-09-25 23:55:34,346 - training.trainer - INFO - Epoch 34, Step 116821: Loss=5.0666, Acc=0.250, PPL=158.63
2025-09-25 23:55:41,782 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.2659, Acc=0.394, PPL=193.62
2025-09-25 23:55:49,229 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.2318, Acc=0.368, PPL=187.13
2025-09-25 23:55:56,725 - training.trainer - INFO - Epoch 34, Step 117121: Loss=5.7594, Acc=0.211, PPL=317.17
2025-09-25 23:56:04,339 - training.trainer - INFO - Epoch 34, Step 117221: Loss=5.4547, Acc=0.375, PPL=233.87
2025-09-25 23:56:11,747 - training.trainer - INFO - Epoch 34, Step 117321: Loss=5.6276, Acc=0.225, PPL=277.98
2025-09-25 23:56:19,244 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.5834, Acc=0.263, PPL=265.98
2025-09-25 23:56:26,562 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.1457, Acc=0.310, PPL=171.70
2025-09-25 23:56:33,946 - training.trainer - INFO - Epoch 34, Step 117621: Loss=4.2518, Acc=0.333, PPL=70.23
2025-09-25 23:56:41,303 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.2888, Acc=0.260, PPL=198.10
2025-09-25 23:56:48,767 - training.trainer - INFO - Epoch 34, Step 117821: Loss=5.8117, Acc=0.255, PPL=334.17
2025-09-25 23:56:56,318 - training.trainer - INFO - Epoch 34, Step 117921: Loss=4.7870, Acc=0.391, PPL=119.94
2025-09-25 23:57:03,775 - training.trainer - INFO - Epoch 34, Step 118021: Loss=5.2597, Acc=0.242, PPL=192.43
2025-09-25 23:57:11,367 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.3170, Acc=0.192, PPL=203.78
2025-09-25 23:57:18,859 - training.trainer - INFO - Epoch 34, Step 118221: Loss=4.5233, Acc=0.429, PPL=92.14
2025-09-25 23:57:26,301 - training.trainer - INFO - Epoch 34, Step 118321: Loss=5.8024, Acc=0.207, PPL=331.08
2025-09-25 23:57:45,043 - training.trainer - INFO - Epoch 35/100 completed in 263.39s - Train Loss: 5.3814, Train Acc: 0.298, Val Loss: 5.6593, Val Acc: 0.259
2025-09-25 23:57:45,392 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-25 23:57:52,873 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.8933, Acc=0.275, PPL=362.61
2025-09-25 23:58:00,581 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.4526, Acc=0.321, PPL=233.37
2025-09-25 23:58:08,216 - training.trainer - INFO - Epoch 35, Step 118704: Loss=6.3718, Acc=0.203, PPL=585.11
2025-09-25 23:58:15,749 - training.trainer - INFO - Epoch 35, Step 118804: Loss=5.4958, Acc=0.283, PPL=243.66
2025-09-25 23:58:23,118 - training.trainer - INFO - Epoch 35, Step 118904: Loss=4.4119, Acc=0.400, PPL=82.43
2025-09-25 23:58:30,458 - training.trainer - INFO - Epoch 35, Step 119004: Loss=5.1245, Acc=0.281, PPL=168.09
2025-09-25 23:58:37,728 - training.trainer - INFO - Epoch 35, Step 119104: Loss=6.0644, Acc=0.255, PPL=430.25
2025-09-25 23:58:45,282 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.8230, Acc=0.276, PPL=338.00
2025-09-25 23:58:52,690 - training.trainer - INFO - Epoch 35, Step 119304: Loss=2.7062, Acc=0.588, PPL=14.97
2025-09-25 23:58:59,909 - training.trainer - INFO - Epoch 35, Step 119404: Loss=5.4548, Acc=0.219, PPL=233.87
2025-09-25 23:59:07,219 - training.trainer - INFO - Epoch 35, Step 119504: Loss=3.6166, Acc=0.444, PPL=37.21
2025-09-25 23:59:14,762 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.2717, Acc=0.306, PPL=194.76
2025-09-25 23:59:22,151 - training.trainer - INFO - Epoch 35, Step 119704: Loss=4.6236, Acc=0.474, PPL=101.86
2025-09-25 23:59:29,494 - training.trainer - INFO - Epoch 35, Step 119804: Loss=6.3239, Acc=0.208, PPL=557.73
2025-09-25 23:59:36,971 - training.trainer - INFO - Epoch 35, Step 119904: Loss=5.5160, Acc=0.238, PPL=248.65
2025-09-25 23:59:44,512 - training.trainer - INFO - Epoch 35, Step 120004: Loss=4.8847, Acc=0.368, PPL=132.25
2025-09-25 23:59:52,256 - training.trainer - INFO - Epoch 35, Step 120104: Loss=6.0855, Acc=0.357, PPL=439.42
2025-09-25 23:59:59,676 - training.trainer - INFO - Epoch 35, Step 120204: Loss=5.2561, Acc=0.250, PPL=191.74
2025-09-26 00:00:07,160 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.3314, Acc=0.240, PPL=206.72
2025-09-26 00:00:14,511 - training.trainer - INFO - Epoch 35, Step 120404: Loss=5.4668, Acc=0.306, PPL=236.69
2025-09-26 00:00:21,842 - training.trainer - INFO - Epoch 35, Step 120504: Loss=5.6245, Acc=0.250, PPL=277.13
2025-09-26 00:00:29,453 - training.trainer - INFO - Epoch 35, Step 120604: Loss=6.3570, Acc=0.196, PPL=576.50
2025-09-26 00:00:36,769 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.7082, Acc=0.233, PPL=301.32
2025-09-26 00:00:44,145 - training.trainer - INFO - Epoch 35, Step 120804: Loss=4.6450, Acc=0.259, PPL=104.06
2025-09-26 00:00:51,437 - training.trainer - INFO - Epoch 35, Step 120904: Loss=5.8965, Acc=0.250, PPL=363.77
2025-09-26 00:00:59,004 - training.trainer - INFO - Epoch 35, Step 121004: Loss=5.9963, Acc=0.239, PPL=401.93
2025-09-26 00:01:06,429 - training.trainer - INFO - Epoch 35, Step 121104: Loss=6.4083, Acc=0.243, PPL=606.85
2025-09-26 00:01:13,813 - training.trainer - INFO - Epoch 35, Step 121204: Loss=5.1914, Acc=0.250, PPL=179.71
2025-09-26 00:01:21,132 - training.trainer - INFO - Epoch 35, Step 121304: Loss=3.1478, Acc=0.625, PPL=23.28
2025-09-26 00:01:28,469 - training.trainer - INFO - Epoch 35, Step 121404: Loss=5.2245, Acc=0.278, PPL=185.76
2025-09-26 00:01:35,860 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.5859, Acc=0.308, PPL=266.65
2025-09-26 00:01:43,237 - training.trainer - INFO - Epoch 35, Step 121604: Loss=5.7968, Acc=0.225, PPL=329.26
2025-09-26 00:01:50,788 - training.trainer - INFO - Epoch 35, Step 121704: Loss=5.6492, Acc=0.225, PPL=284.06
2025-09-26 00:02:10,554 - training.trainer - INFO - Epoch 36/100 completed in 265.16s - Train Loss: 5.3598, Train Acc: 0.300, Val Loss: 5.6463, Val Acc: 0.263
2025-09-26 00:02:11,238 - training.trainer - INFO - New best model saved with validation loss: 5.6463
2025-09-26 00:02:11,239 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_36.pt
2025-09-26 00:02:19,079 - training.trainer - INFO - Epoch 36, Step 121887: Loss=5.6799, Acc=0.256, PPL=292.93
2025-09-26 00:02:26,550 - training.trainer - INFO - Epoch 36, Step 121987: Loss=5.7319, Acc=0.257, PPL=308.56
2025-09-26 00:02:34,219 - training.trainer - INFO - Epoch 36, Step 122087: Loss=5.7851, Acc=0.300, PPL=325.41
2025-09-26 00:02:41,693 - training.trainer - INFO - Epoch 36, Step 122187: Loss=5.3636, Acc=0.326, PPL=213.49
2025-09-26 00:02:49,177 - training.trainer - INFO - Epoch 36, Step 122287: Loss=5.8845, Acc=0.289, PPL=359.42
2025-09-26 00:02:56,900 - training.trainer - INFO - Epoch 36, Step 122387: Loss=5.8860, Acc=0.286, PPL=359.96
2025-09-26 00:03:04,285 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.2963, Acc=0.208, PPL=199.61
2025-09-26 00:03:12,082 - training.trainer - INFO - Epoch 36, Step 122587: Loss=4.1032, Acc=0.565, PPL=60.53
2025-09-26 00:03:19,585 - training.trainer - INFO - Epoch 36, Step 122687: Loss=5.8258, Acc=0.262, PPL=338.93
2025-09-26 00:03:26,961 - training.trainer - INFO - Epoch 36, Step 122787: Loss=5.6732, Acc=0.308, PPL=290.96
2025-09-26 00:03:34,349 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.2823, Acc=0.321, PPL=196.83
2025-09-26 00:03:41,844 - training.trainer - INFO - Epoch 36, Step 122987: Loss=6.1704, Acc=0.227, PPL=478.39
2025-09-26 00:03:49,163 - training.trainer - INFO - Epoch 36, Step 123087: Loss=6.7009, Acc=0.188, PPL=813.13
2025-09-26 00:03:56,499 - training.trainer - INFO - Epoch 36, Step 123187: Loss=5.4647, Acc=0.321, PPL=236.19
2025-09-26 00:04:03,964 - training.trainer - INFO - Epoch 36, Step 123287: Loss=5.7628, Acc=0.242, PPL=318.23
2025-09-26 00:04:11,504 - training.trainer - INFO - Epoch 36, Step 123387: Loss=4.5459, Acc=0.268, PPL=94.25
2025-09-26 00:04:19,015 - training.trainer - INFO - Epoch 36, Step 123487: Loss=6.0211, Acc=0.136, PPL=412.02
2025-09-26 00:04:26,397 - training.trainer - INFO - Epoch 36, Step 123587: Loss=4.8237, Acc=0.308, PPL=124.42
2025-09-26 00:04:33,831 - training.trainer - INFO - Epoch 36, Step 123687: Loss=6.3730, Acc=0.194, PPL=585.79
2025-09-26 00:04:41,271 - training.trainer - INFO - Epoch 36, Step 123787: Loss=4.5113, Acc=0.364, PPL=91.04
2025-09-26 00:04:48,721 - training.trainer - INFO - Epoch 36, Step 123887: Loss=2.8149, Acc=0.586, PPL=16.69
2025-09-26 00:04:56,154 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.7716, Acc=0.185, PPL=321.06
2025-09-26 00:05:03,482 - training.trainer - INFO - Epoch 36, Step 124087: Loss=4.3263, Acc=0.385, PPL=75.67
2025-09-26 00:05:11,721 - training.trainer - INFO - Epoch 36, Step 124187: Loss=5.1587, Acc=0.400, PPL=173.94
2025-09-26 00:05:19,441 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.2684, Acc=0.228, PPL=194.10
2025-09-26 00:05:26,970 - training.trainer - INFO - Epoch 36, Step 124387: Loss=4.7723, Acc=0.448, PPL=118.19
2025-09-26 00:05:34,607 - training.trainer - INFO - Epoch 36, Step 124487: Loss=5.2456, Acc=0.345, PPL=189.74
2025-09-26 00:05:42,196 - training.trainer - INFO - Epoch 36, Step 124587: Loss=5.9762, Acc=0.215, PPL=393.93
2025-09-26 00:05:49,677 - training.trainer - INFO - Epoch 36, Step 124687: Loss=5.6227, Acc=0.317, PPL=276.64
2025-09-26 00:05:57,248 - training.trainer - INFO - Epoch 36, Step 124787: Loss=1.9850, Acc=0.750, PPL=7.28
2025-09-26 00:06:04,680 - training.trainer - INFO - Epoch 36, Step 124887: Loss=6.2617, Acc=0.257, PPL=524.09
2025-09-26 00:06:12,215 - training.trainer - INFO - Epoch 36, Step 124987: Loss=5.5391, Acc=0.366, PPL=254.45
2025-09-26 00:06:19,732 - training.trainer - INFO - Epoch 36, Step 125087: Loss=5.1867, Acc=0.343, PPL=178.88
2025-09-26 00:06:39,649 - training.trainer - INFO - Epoch 37/100 completed in 268.41s - Train Loss: 5.3458, Train Acc: 0.303, Val Loss: 5.6595, Val Acc: 0.259
2025-09-26 00:06:47,414 - training.trainer - INFO - Epoch 37, Step 125270: Loss=5.3474, Acc=0.333, PPL=210.07
2025-09-26 00:06:54,838 - training.trainer - INFO - Epoch 37, Step 125370: Loss=4.5521, Acc=0.357, PPL=94.83
2025-09-26 00:07:02,296 - training.trainer - INFO - Epoch 37, Step 125470: Loss=5.0852, Acc=0.290, PPL=161.61
2025-09-26 00:07:09,721 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.2033, Acc=0.375, PPL=181.87
2025-09-26 00:07:17,187 - training.trainer - INFO - Epoch 37, Step 125670: Loss=4.9548, Acc=0.407, PPL=141.85
2025-09-26 00:07:24,537 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.2653, Acc=0.244, PPL=193.51
2025-09-26 00:07:32,037 - training.trainer - INFO - Epoch 37, Step 125870: Loss=5.3825, Acc=0.257, PPL=217.56
2025-09-26 00:07:39,439 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.6416, Acc=0.273, PPL=281.92
2025-09-26 00:07:47,032 - training.trainer - INFO - Epoch 37, Step 126070: Loss=5.5132, Acc=0.213, PPL=247.94
2025-09-26 00:07:54,399 - training.trainer - INFO - Epoch 37, Step 126170: Loss=4.6938, Acc=0.333, PPL=109.27
2025-09-26 00:08:02,016 - training.trainer - INFO - Epoch 37, Step 126270: Loss=5.1225, Acc=0.303, PPL=167.76
2025-09-26 00:08:09,809 - training.trainer - INFO - Epoch 37, Step 126370: Loss=5.3204, Acc=0.400, PPL=204.47
2025-09-26 00:08:17,551 - training.trainer - INFO - Epoch 37, Step 126470: Loss=5.6374, Acc=0.278, PPL=280.74
2025-09-26 00:08:25,215 - training.trainer - INFO - Epoch 37, Step 126570: Loss=4.6698, Acc=0.375, PPL=106.68
2025-09-26 00:08:32,972 - training.trainer - INFO - Epoch 37, Step 126670: Loss=6.0635, Acc=0.238, PPL=429.87
2025-09-26 00:08:40,721 - training.trainer - INFO - Epoch 37, Step 126770: Loss=4.2619, Acc=0.368, PPL=70.95
2025-09-26 00:08:48,521 - training.trainer - INFO - Epoch 37, Step 126870: Loss=6.0669, Acc=0.158, PPL=431.34
2025-09-26 00:08:56,157 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.1262, Acc=0.381, PPL=168.37
2025-09-26 00:09:03,699 - training.trainer - INFO - Epoch 37, Step 127070: Loss=6.1239, Acc=0.114, PPL=456.63
2025-09-26 00:09:11,343 - training.trainer - INFO - Epoch 37, Step 127170: Loss=5.4521, Acc=0.310, PPL=233.25
2025-09-26 00:09:18,806 - training.trainer - INFO - Epoch 37, Step 127270: Loss=5.6719, Acc=0.186, PPL=290.58
2025-09-26 00:09:26,284 - training.trainer - INFO - Epoch 37, Step 127370: Loss=6.1828, Acc=0.226, PPL=484.37
2025-09-26 00:09:33,645 - training.trainer - INFO - Epoch 37, Step 127470: Loss=4.8154, Acc=0.413, PPL=123.40
2025-09-26 00:09:40,962 - training.trainer - INFO - Epoch 37, Step 127570: Loss=5.9836, Acc=0.208, PPL=396.86
2025-09-26 00:09:48,412 - training.trainer - INFO - Epoch 37, Step 127670: Loss=5.5220, Acc=0.250, PPL=250.13
2025-09-26 00:09:55,933 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.0979, Acc=0.321, PPL=163.68
2025-09-26 00:10:03,335 - training.trainer - INFO - Epoch 37, Step 127870: Loss=5.2868, Acc=0.318, PPL=197.72
2025-09-26 00:10:10,910 - training.trainer - INFO - Epoch 37, Step 127970: Loss=5.1986, Acc=0.308, PPL=181.01
2025-09-26 00:10:18,358 - training.trainer - INFO - Epoch 37, Step 128070: Loss=5.1805, Acc=0.341, PPL=177.77
2025-09-26 00:10:25,980 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.2325, Acc=0.333, PPL=187.26
2025-09-26 00:10:33,355 - training.trainer - INFO - Epoch 37, Step 128270: Loss=5.7922, Acc=0.240, PPL=327.73
2025-09-26 00:10:40,587 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.4702, Acc=0.342, PPL=237.52
2025-09-26 00:10:47,836 - training.trainer - INFO - Epoch 37, Step 128470: Loss=3.7371, Acc=0.517, PPL=41.98
2025-09-26 00:11:07,211 - training.trainer - INFO - Epoch 38/100 completed in 267.56s - Train Loss: 5.3252, Train Acc: 0.306, Val Loss: 5.6698, Val Acc: 0.261
2025-09-26 00:11:13,867 - training.trainer - INFO - Epoch 38, Step 128653: Loss=5.4599, Acc=0.205, PPL=235.08
2025-09-26 00:11:20,524 - training.trainer - INFO - Epoch 38, Step 128753: Loss=5.3226, Acc=0.429, PPL=204.92
2025-09-26 00:11:28,135 - training.trainer - INFO - Epoch 38, Step 128853: Loss=5.4079, Acc=0.326, PPL=223.17
2025-09-26 00:11:35,464 - training.trainer - INFO - Epoch 38, Step 128953: Loss=4.9027, Acc=0.343, PPL=134.66
2025-09-26 00:11:42,763 - training.trainer - INFO - Epoch 38, Step 129053: Loss=5.6130, Acc=0.308, PPL=273.95
2025-09-26 00:11:50,099 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.0480, Acc=0.382, PPL=155.70
2025-09-26 00:11:57,645 - training.trainer - INFO - Epoch 38, Step 129253: Loss=3.5588, Acc=0.682, PPL=35.12
2025-09-26 00:12:04,936 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.1793, Acc=0.423, PPL=177.55
2025-09-26 00:12:12,342 - training.trainer - INFO - Epoch 38, Step 129453: Loss=6.2302, Acc=0.200, PPL=507.88
2025-09-26 00:12:19,768 - training.trainer - INFO - Epoch 38, Step 129553: Loss=4.7262, Acc=0.426, PPL=112.86
2025-09-26 00:12:27,300 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.4535, Acc=0.286, PPL=233.57
2025-09-26 00:12:34,959 - training.trainer - INFO - Epoch 38, Step 129753: Loss=5.9636, Acc=0.176, PPL=389.00
2025-09-26 00:12:42,603 - training.trainer - INFO - Epoch 38, Step 129853: Loss=5.4056, Acc=0.229, PPL=222.64
2025-09-26 00:12:50,087 - training.trainer - INFO - Epoch 38, Step 129953: Loss=5.4603, Acc=0.204, PPL=235.17
2025-09-26 00:12:57,484 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.6843, Acc=0.220, PPL=294.22
2025-09-26 00:13:05,060 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.5133, Acc=0.371, PPL=247.97
2025-09-26 00:13:12,611 - training.trainer - INFO - Epoch 38, Step 130253: Loss=4.3190, Acc=0.340, PPL=75.12
2025-09-26 00:13:20,151 - training.trainer - INFO - Epoch 38, Step 130353: Loss=5.3102, Acc=0.310, PPL=202.40
2025-09-26 00:13:27,837 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.4494, Acc=0.239, PPL=232.61
2025-09-26 00:13:35,352 - training.trainer - INFO - Epoch 38, Step 130553: Loss=5.6024, Acc=0.243, PPL=271.06
2025-09-26 00:13:43,003 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.1107, Acc=0.407, PPL=165.79
2025-09-26 00:13:50,541 - training.trainer - INFO - Epoch 38, Step 130753: Loss=5.5733, Acc=0.270, PPL=263.30
2025-09-26 00:13:57,973 - training.trainer - INFO - Epoch 38, Step 130853: Loss=6.2783, Acc=0.200, PPL=532.86
2025-09-26 00:14:05,506 - training.trainer - INFO - Epoch 38, Step 130953: Loss=4.2350, Acc=0.404, PPL=69.06
2025-09-26 00:14:13,093 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.1300, Acc=0.360, PPL=169.01
2025-09-26 00:14:20,633 - training.trainer - INFO - Epoch 38, Step 131153: Loss=5.8530, Acc=0.211, PPL=348.26
2025-09-26 00:14:28,120 - training.trainer - INFO - Epoch 38, Step 131253: Loss=6.0888, Acc=0.196, PPL=440.90
2025-09-26 00:14:35,690 - training.trainer - INFO - Epoch 38, Step 131353: Loss=5.5794, Acc=0.316, PPL=264.92
2025-09-26 00:14:43,309 - training.trainer - INFO - Epoch 38, Step 131453: Loss=5.9777, Acc=0.263, PPL=394.54
2025-09-26 00:14:50,829 - training.trainer - INFO - Epoch 38, Step 131553: Loss=5.5329, Acc=0.192, PPL=252.88
2025-09-26 00:14:58,441 - training.trainer - INFO - Epoch 38, Step 131653: Loss=5.8343, Acc=0.333, PPL=341.81
2025-09-26 00:15:05,967 - training.trainer - INFO - Epoch 38, Step 131753: Loss=5.8387, Acc=0.188, PPL=343.34
2025-09-26 00:15:13,506 - training.trainer - INFO - Epoch 38, Step 131853: Loss=4.4873, Acc=0.483, PPL=88.88
2025-09-26 00:15:33,852 - training.trainer - INFO - Epoch 39/100 completed in 266.64s - Train Loss: 5.3121, Train Acc: 0.309, Val Loss: 5.6647, Val Acc: 0.258
2025-09-26 00:15:41,550 - training.trainer - INFO - Epoch 39, Step 132036: Loss=4.2480, Acc=0.409, PPL=69.96
2025-09-26 00:15:48,692 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.2478, Acc=0.312, PPL=190.15
2025-09-26 00:15:56,253 - training.trainer - INFO - Epoch 39, Step 132236: Loss=5.8674, Acc=0.243, PPL=353.32
2025-09-26 00:16:03,827 - training.trainer - INFO - Epoch 39, Step 132336: Loss=5.9305, Acc=0.263, PPL=376.34
2025-09-26 00:16:11,221 - training.trainer - INFO - Epoch 39, Step 132436: Loss=5.3058, Acc=0.303, PPL=201.49
2025-09-26 00:16:18,769 - training.trainer - INFO - Epoch 39, Step 132536: Loss=5.9262, Acc=0.240, PPL=374.71
2025-09-26 00:16:26,477 - training.trainer - INFO - Epoch 39, Step 132636: Loss=4.5608, Acc=0.368, PPL=95.66
2025-09-26 00:16:33,932 - training.trainer - INFO - Epoch 39, Step 132736: Loss=4.9050, Acc=0.364, PPL=134.96
2025-09-26 00:16:41,209 - training.trainer - INFO - Epoch 39, Step 132836: Loss=5.6763, Acc=0.226, PPL=291.88
2025-09-26 00:16:48,649 - training.trainer - INFO - Epoch 39, Step 132936: Loss=6.0155, Acc=0.217, PPL=409.72
2025-09-26 00:16:56,149 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.2691, Acc=0.444, PPL=194.25
2025-09-26 00:17:03,458 - training.trainer - INFO - Epoch 39, Step 133136: Loss=6.0437, Acc=0.203, PPL=421.46
2025-09-26 00:17:10,651 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.4628, Acc=0.290, PPL=235.76
2025-09-26 00:17:18,124 - training.trainer - INFO - Epoch 39, Step 133336: Loss=4.8241, Acc=0.304, PPL=124.47
2025-09-26 00:17:25,575 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.2759, Acc=0.267, PPL=195.56
2025-09-26 00:17:32,834 - training.trainer - INFO - Epoch 39, Step 133536: Loss=5.2746, Acc=0.333, PPL=195.31
2025-09-26 00:17:40,109 - training.trainer - INFO - Epoch 39, Step 133636: Loss=5.4690, Acc=0.341, PPL=237.23
2025-09-26 00:17:47,363 - training.trainer - INFO - Epoch 39, Step 133736: Loss=5.4145, Acc=0.375, PPL=224.65
2025-09-26 00:17:54,652 - training.trainer - INFO - Epoch 39, Step 133836: Loss=5.2917, Acc=0.265, PPL=198.68
2025-09-26 00:18:02,107 - training.trainer - INFO - Epoch 39, Step 133936: Loss=4.3192, Acc=0.444, PPL=75.13
2025-09-26 00:18:09,478 - training.trainer - INFO - Epoch 39, Step 134036: Loss=6.0386, Acc=0.154, PPL=419.33
2025-09-26 00:18:16,835 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.6623, Acc=0.275, PPL=287.82
2025-09-26 00:18:24,201 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.6090, Acc=0.229, PPL=272.87
2025-09-26 00:18:32,110 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.8231, Acc=0.237, PPL=338.02
2025-09-26 00:18:39,580 - training.trainer - INFO - Epoch 39, Step 134436: Loss=4.9545, Acc=0.273, PPL=141.82
2025-09-26 00:18:46,864 - training.trainer - INFO - Epoch 39, Step 134536: Loss=5.3473, Acc=0.326, PPL=210.04
2025-09-26 00:18:54,180 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.7164, Acc=0.268, PPL=303.81
2025-09-26 00:19:01,494 - training.trainer - INFO - Epoch 39, Step 134736: Loss=4.9117, Acc=0.357, PPL=135.87
2025-09-26 00:19:08,831 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.4970, Acc=0.167, PPL=243.96
2025-09-26 00:19:16,191 - training.trainer - INFO - Epoch 39, Step 134936: Loss=3.3510, Acc=0.565, PPL=28.53
2025-09-26 00:19:23,581 - training.trainer - INFO - Epoch 39, Step 135036: Loss=5.3630, Acc=0.353, PPL=213.36
2025-09-26 00:19:30,866 - training.trainer - INFO - Epoch 39, Step 135136: Loss=5.3806, Acc=0.231, PPL=217.14
2025-09-26 00:19:38,216 - training.trainer - INFO - Epoch 39, Step 135236: Loss=5.1917, Acc=0.220, PPL=179.78
2025-09-26 00:19:56,648 - training.trainer - INFO - Epoch 40/100 completed in 262.80s - Train Loss: 5.3015, Train Acc: 0.312, Val Loss: 5.6788, Val Acc: 0.261
2025-09-26 00:19:56,961 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-26 00:20:03,870 - training.trainer - INFO - Epoch 40, Step 135419: Loss=5.8218, Acc=0.176, PPL=337.57
2025-09-26 00:20:11,204 - training.trainer - INFO - Epoch 40, Step 135519: Loss=5.2702, Acc=0.429, PPL=194.45
2025-09-26 00:20:18,430 - training.trainer - INFO - Epoch 40, Step 135619: Loss=5.0340, Acc=0.290, PPL=153.55
2025-09-26 00:20:25,697 - training.trainer - INFO - Epoch 40, Step 135719: Loss=5.1831, Acc=0.333, PPL=178.23
2025-09-26 00:20:32,955 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.3961, Acc=0.275, PPL=220.54
2025-09-26 00:20:40,378 - training.trainer - INFO - Epoch 40, Step 135919: Loss=5.1529, Acc=0.237, PPL=172.93
2025-09-26 00:20:47,859 - training.trainer - INFO - Epoch 40, Step 136019: Loss=6.0387, Acc=0.391, PPL=419.35
2025-09-26 00:20:55,480 - training.trainer - INFO - Epoch 40, Step 136119: Loss=5.0088, Acc=0.333, PPL=149.72
2025-09-26 00:21:02,737 - training.trainer - INFO - Epoch 40, Step 136219: Loss=5.6002, Acc=0.314, PPL=270.47
2025-09-26 00:21:09,932 - training.trainer - INFO - Epoch 40, Step 136319: Loss=5.7323, Acc=0.220, PPL=308.67
2025-09-26 00:21:17,277 - training.trainer - INFO - Epoch 40, Step 136419: Loss=5.4016, Acc=0.339, PPL=221.76
2025-09-26 00:21:24,405 - training.trainer - INFO - Epoch 40, Step 136519: Loss=5.1556, Acc=0.276, PPL=173.39
2025-09-26 00:21:31,634 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.5356, Acc=0.268, PPL=253.55
2025-09-26 00:21:38,897 - training.trainer - INFO - Epoch 40, Step 136719: Loss=5.4886, Acc=0.291, PPL=241.92
2025-09-26 00:21:46,071 - training.trainer - INFO - Epoch 40, Step 136819: Loss=6.3123, Acc=0.146, PPL=551.31
2025-09-26 00:21:53,450 - training.trainer - INFO - Epoch 40, Step 136919: Loss=5.7715, Acc=0.222, PPL=321.01
2025-09-26 00:22:00,671 - training.trainer - INFO - Epoch 40, Step 137019: Loss=6.2474, Acc=0.240, PPL=516.67
2025-09-26 00:22:07,917 - training.trainer - INFO - Epoch 40, Step 137119: Loss=5.7715, Acc=0.181, PPL=321.03
2025-09-26 00:22:15,286 - training.trainer - INFO - Epoch 40, Step 137219: Loss=4.0503, Acc=0.528, PPL=57.41
2025-09-26 00:22:22,719 - training.trainer - INFO - Epoch 40, Step 137319: Loss=6.2835, Acc=0.250, PPL=535.64
2025-09-26 00:22:29,954 - training.trainer - INFO - Epoch 40, Step 137419: Loss=5.0792, Acc=0.308, PPL=160.65
2025-09-26 00:22:37,216 - training.trainer - INFO - Epoch 40, Step 137519: Loss=5.7084, Acc=0.240, PPL=301.39
2025-09-26 00:22:44,596 - training.trainer - INFO - Epoch 40, Step 137619: Loss=6.0671, Acc=0.214, PPL=431.43
2025-09-26 00:22:52,141 - training.trainer - INFO - Epoch 40, Step 137719: Loss=5.3048, Acc=0.375, PPL=201.30
2025-09-26 00:22:59,656 - training.trainer - INFO - Epoch 40, Step 137819: Loss=4.6487, Acc=0.350, PPL=104.44
2025-09-26 00:23:07,123 - training.trainer - INFO - Epoch 40, Step 137919: Loss=5.6110, Acc=0.203, PPL=273.41
2025-09-26 00:23:14,649 - training.trainer - INFO - Epoch 40, Step 138019: Loss=5.7191, Acc=0.184, PPL=304.64
2025-09-26 00:23:22,072 - training.trainer - INFO - Epoch 40, Step 138119: Loss=5.2306, Acc=0.290, PPL=186.90
2025-09-26 00:23:29,512 - training.trainer - INFO - Epoch 40, Step 138219: Loss=5.4566, Acc=0.262, PPL=234.31
2025-09-26 00:23:37,119 - training.trainer - INFO - Epoch 40, Step 138319: Loss=5.2533, Acc=0.231, PPL=191.20
2025-09-26 00:23:44,347 - training.trainer - INFO - Epoch 40, Step 138419: Loss=5.6297, Acc=0.289, PPL=278.57
2025-09-26 00:23:51,655 - training.trainer - INFO - Epoch 40, Step 138519: Loss=5.5516, Acc=0.176, PPL=257.64
2025-09-26 00:23:59,177 - training.trainer - INFO - Epoch 40, Step 138619: Loss=5.8561, Acc=0.294, PPL=349.34
2025-09-26 00:24:17,816 - training.trainer - INFO - Epoch 41/100 completed in 260.85s - Train Loss: 5.2830, Train Acc: 0.314, Val Loss: 5.6754, Val Acc: 0.262
2025-09-26 00:24:24,281 - training.trainer - INFO - Epoch 41, Step 138802: Loss=5.4726, Acc=0.286, PPL=238.08
2025-09-26 00:24:30,715 - training.trainer - INFO - Epoch 41, Step 138902: Loss=3.8871, Acc=0.519, PPL=48.77
2025-09-26 00:24:38,123 - training.trainer - INFO - Epoch 41, Step 139002: Loss=4.8239, Acc=0.308, PPL=124.45
2025-09-26 00:24:45,328 - training.trainer - INFO - Epoch 41, Step 139102: Loss=6.3293, Acc=0.192, PPL=560.78
2025-09-26 00:24:52,624 - training.trainer - INFO - Epoch 41, Step 139202: Loss=6.4491, Acc=0.204, PPL=632.11
2025-09-26 00:25:00,074 - training.trainer - INFO - Epoch 41, Step 139302: Loss=4.9881, Acc=0.286, PPL=146.66
2025-09-26 00:25:07,608 - training.trainer - INFO - Epoch 41, Step 139402: Loss=6.2288, Acc=0.261, PPL=507.12
2025-09-26 00:25:15,135 - training.trainer - INFO - Epoch 41, Step 139502: Loss=5.6019, Acc=0.357, PPL=270.94
2025-09-26 00:25:22,635 - training.trainer - INFO - Epoch 41, Step 139602: Loss=4.7120, Acc=0.379, PPL=111.27
2025-09-26 00:25:30,084 - training.trainer - INFO - Epoch 41, Step 139702: Loss=5.1931, Acc=0.293, PPL=180.02
2025-09-26 00:25:37,615 - training.trainer - INFO - Epoch 41, Step 139802: Loss=5.7128, Acc=0.297, PPL=302.72
2025-09-26 00:25:45,298 - training.trainer - INFO - Epoch 41, Step 139902: Loss=2.8225, Acc=0.651, PPL=16.82
2025-09-26 00:25:52,803 - training.trainer - INFO - Epoch 41, Step 140002: Loss=4.5530, Acc=0.462, PPL=94.91
2025-09-26 00:26:00,089 - training.trainer - INFO - Epoch 41, Step 140102: Loss=5.8289, Acc=0.241, PPL=339.97
2025-09-26 00:26:07,543 - training.trainer - INFO - Epoch 41, Step 140202: Loss=5.9999, Acc=0.122, PPL=403.40
2025-09-26 00:26:14,991 - training.trainer - INFO - Epoch 41, Step 140302: Loss=5.3199, Acc=0.387, PPL=204.35
2025-09-26 00:26:22,530 - training.trainer - INFO - Epoch 41, Step 140402: Loss=6.1306, Acc=0.224, PPL=459.73
2025-09-26 00:26:30,041 - training.trainer - INFO - Epoch 41, Step 140502: Loss=6.4444, Acc=0.200, PPL=629.17
2025-09-26 00:26:37,370 - training.trainer - INFO - Epoch 41, Step 140602: Loss=5.4768, Acc=0.280, PPL=239.07
2025-09-26 00:26:44,943 - training.trainer - INFO - Epoch 41, Step 140702: Loss=4.3942, Acc=0.444, PPL=80.98
2025-09-26 00:26:52,281 - training.trainer - INFO - Epoch 41, Step 140802: Loss=5.5639, Acc=0.290, PPL=260.84
2025-09-26 00:26:59,596 - training.trainer - INFO - Epoch 41, Step 140902: Loss=6.1264, Acc=0.222, PPL=457.80
2025-09-26 00:27:07,127 - training.trainer - INFO - Epoch 41, Step 141002: Loss=5.6580, Acc=0.280, PPL=286.59
2025-09-26 00:27:14,657 - training.trainer - INFO - Epoch 41, Step 141102: Loss=6.2651, Acc=0.263, PPL=525.89
2025-09-26 00:27:22,214 - training.trainer - INFO - Epoch 41, Step 141202: Loss=5.2501, Acc=0.318, PPL=190.59
2025-09-26 00:27:29,753 - training.trainer - INFO - Epoch 41, Step 141302: Loss=4.9755, Acc=0.368, PPL=144.82
2025-09-26 00:27:37,210 - training.trainer - INFO - Epoch 41, Step 141402: Loss=5.7364, Acc=0.260, PPL=309.93
2025-09-26 00:27:44,620 - training.trainer - INFO - Epoch 41, Step 141502: Loss=5.3652, Acc=0.324, PPL=213.83
2025-09-26 00:27:52,158 - training.trainer - INFO - Epoch 41, Step 141602: Loss=4.2255, Acc=0.439, PPL=68.41
2025-09-26 00:27:59,427 - training.trainer - INFO - Epoch 41, Step 141702: Loss=5.7029, Acc=0.262, PPL=299.73
2025-09-26 00:28:06,758 - training.trainer - INFO - Epoch 41, Step 141802: Loss=4.1768, Acc=0.333, PPL=65.16
2025-09-26 00:28:14,120 - training.trainer - INFO - Epoch 41, Step 141902: Loss=5.8174, Acc=0.207, PPL=336.11
2025-09-26 00:28:21,519 - training.trainer - INFO - Epoch 41, Step 142002: Loss=5.2129, Acc=0.446, PPL=183.63
2025-09-26 00:28:39,872 - training.trainer - INFO - Epoch 42/100 completed in 262.06s - Train Loss: 5.2753, Train Acc: 0.314, Val Loss: 5.6820, Val Acc: 0.260
2025-09-26 00:28:46,588 - training.trainer - INFO - Epoch 42, Step 142185: Loss=4.4886, Acc=0.405, PPL=89.00
2025-09-26 00:28:53,176 - training.trainer - INFO - Epoch 42, Step 142285: Loss=5.2021, Acc=0.288, PPL=181.66
2025-09-26 00:29:00,162 - training.trainer - INFO - Epoch 42, Step 142385: Loss=5.6531, Acc=0.293, PPL=285.16
2025-09-26 00:29:07,574 - training.trainer - INFO - Epoch 42, Step 142485: Loss=6.0061, Acc=0.238, PPL=405.88
2025-09-26 00:29:15,076 - training.trainer - INFO - Epoch 42, Step 142585: Loss=6.0760, Acc=0.356, PPL=435.31
2025-09-26 00:29:22,476 - training.trainer - INFO - Epoch 42, Step 142685: Loss=4.9007, Acc=0.409, PPL=134.38
2025-09-26 00:29:29,843 - training.trainer - INFO - Epoch 42, Step 142785: Loss=5.7216, Acc=0.174, PPL=305.39
2025-09-26 00:29:37,027 - training.trainer - INFO - Epoch 42, Step 142885: Loss=5.0300, Acc=0.355, PPL=152.94
2025-09-26 00:29:44,375 - training.trainer - INFO - Epoch 42, Step 142985: Loss=4.6538, Acc=0.438, PPL=104.99
2025-09-26 00:29:51,676 - training.trainer - INFO - Epoch 42, Step 143085: Loss=5.8587, Acc=0.292, PPL=350.28
2025-09-26 00:29:58,976 - training.trainer - INFO - Epoch 42, Step 143185: Loss=5.5746, Acc=0.315, PPL=263.63
2025-09-26 00:30:06,689 - training.trainer - INFO - Epoch 42, Step 143285: Loss=5.4200, Acc=0.303, PPL=225.88
2025-09-26 00:30:14,022 - training.trainer - INFO - Epoch 42, Step 143385: Loss=4.9359, Acc=0.370, PPL=139.20
2025-09-26 00:30:21,295 - training.trainer - INFO - Epoch 42, Step 143485: Loss=4.8568, Acc=0.333, PPL=128.61
2025-09-26 00:30:28,664 - training.trainer - INFO - Epoch 42, Step 143585: Loss=5.1871, Acc=0.333, PPL=178.95
2025-09-26 00:30:36,025 - training.trainer - INFO - Epoch 42, Step 143685: Loss=5.2077, Acc=0.294, PPL=182.68
2025-09-26 00:30:43,280 - training.trainer - INFO - Epoch 42, Step 143785: Loss=5.1397, Acc=0.357, PPL=170.67
2025-09-26 00:30:50,517 - training.trainer - INFO - Epoch 42, Step 143885: Loss=5.8533, Acc=0.267, PPL=348.39
2025-09-26 00:30:57,973 - training.trainer - INFO - Epoch 42, Step 143985: Loss=5.1047, Acc=0.296, PPL=164.79
2025-09-26 00:31:05,333 - training.trainer - INFO - Epoch 42, Step 144085: Loss=5.8360, Acc=0.224, PPL=342.41
2025-09-26 00:31:12,599 - training.trainer - INFO - Epoch 42, Step 144185: Loss=5.4191, Acc=0.302, PPL=225.68
2025-09-26 00:31:20,334 - training.trainer - INFO - Epoch 42, Step 144285: Loss=4.9929, Acc=0.345, PPL=147.36
2025-09-26 00:31:27,840 - training.trainer - INFO - Epoch 42, Step 144385: Loss=5.1196, Acc=0.235, PPL=167.27
2025-09-26 00:31:35,348 - training.trainer - INFO - Epoch 42, Step 144485: Loss=4.2902, Acc=0.417, PPL=72.98
2025-09-26 00:31:42,718 - training.trainer - INFO - Epoch 42, Step 144585: Loss=5.4627, Acc=0.250, PPL=235.74
2025-09-26 00:31:50,310 - training.trainer - INFO - Epoch 42, Step 144685: Loss=6.0718, Acc=0.236, PPL=433.44
2025-09-26 00:31:57,588 - training.trainer - INFO - Epoch 42, Step 144785: Loss=5.2417, Acc=0.342, PPL=188.98
2025-09-26 00:32:04,827 - training.trainer - INFO - Epoch 42, Step 144885: Loss=5.4328, Acc=0.316, PPL=228.78
2025-09-26 00:32:12,268 - training.trainer - INFO - Epoch 42, Step 144985: Loss=5.2092, Acc=0.300, PPL=182.94
2025-09-26 00:32:19,521 - training.trainer - INFO - Epoch 42, Step 145085: Loss=5.8904, Acc=0.246, PPL=361.55
2025-09-26 00:32:26,728 - training.trainer - INFO - Epoch 42, Step 145185: Loss=4.2345, Acc=0.444, PPL=69.02
2025-09-26 00:32:33,933 - training.trainer - INFO - Epoch 42, Step 145285: Loss=6.1245, Acc=0.139, PPL=456.92
2025-09-26 00:32:41,404 - training.trainer - INFO - Epoch 42, Step 145385: Loss=5.0274, Acc=0.324, PPL=152.53
2025-09-26 00:32:59,730 - training.trainer - INFO - Epoch 43/100 completed in 259.86s - Train Loss: 5.2561, Train Acc: 0.319, Val Loss: 5.6850, Val Acc: 0.262
2025-09-26 00:33:06,173 - training.trainer - INFO - Epoch 43, Step 145568: Loss=5.2341, Acc=0.300, PPL=187.55
2025-09-26 00:33:12,346 - training.trainer - INFO - Epoch 43, Step 145668: Loss=5.9373, Acc=0.235, PPL=378.90
2025-09-26 00:33:18,687 - training.trainer - INFO - Epoch 43, Step 145768: Loss=4.8556, Acc=0.265, PPL=128.46
2025-09-26 00:33:25,507 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.3869, Acc=0.303, PPL=218.52
2025-09-26 00:33:32,914 - training.trainer - INFO - Epoch 43, Step 145968: Loss=4.6131, Acc=0.500, PPL=100.80
2025-09-26 00:33:40,373 - training.trainer - INFO - Epoch 43, Step 146068: Loss=5.9014, Acc=0.238, PPL=365.53
2025-09-26 00:33:47,792 - training.trainer - INFO - Epoch 43, Step 146168: Loss=4.3683, Acc=0.422, PPL=78.91
2025-09-26 00:33:55,322 - training.trainer - INFO - Epoch 43, Step 146268: Loss=4.7633, Acc=0.396, PPL=117.13
2025-09-26 00:34:02,615 - training.trainer - INFO - Epoch 43, Step 146368: Loss=6.0670, Acc=0.214, PPL=431.40
2025-09-26 00:34:09,945 - training.trainer - INFO - Epoch 43, Step 146468: Loss=5.4004, Acc=0.378, PPL=221.50
2025-09-26 00:34:17,340 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.7080, Acc=0.244, PPL=301.26
2025-09-26 00:34:24,853 - training.trainer - INFO - Epoch 43, Step 146668: Loss=5.1017, Acc=0.326, PPL=164.29
2025-09-26 00:34:32,191 - training.trainer - INFO - Epoch 43, Step 146768: Loss=4.1653, Acc=0.450, PPL=64.41
2025-09-26 00:34:39,582 - training.trainer - INFO - Epoch 43, Step 146868: Loss=5.4298, Acc=0.393, PPL=228.11
2025-09-26 00:34:47,108 - training.trainer - INFO - Epoch 43, Step 146968: Loss=3.6659, Acc=0.577, PPL=39.09
2025-09-26 00:34:54,797 - training.trainer - INFO - Epoch 43, Step 147068: Loss=5.2321, Acc=0.278, PPL=187.18
2025-09-26 00:35:02,273 - training.trainer - INFO - Epoch 43, Step 147168: Loss=5.1991, Acc=0.261, PPL=181.10
2025-09-26 00:35:09,831 - training.trainer - INFO - Epoch 43, Step 147268: Loss=6.0134, Acc=0.293, PPL=408.85
2025-09-26 00:35:17,182 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.6537, Acc=0.217, PPL=285.35
2025-09-26 00:35:24,609 - training.trainer - INFO - Epoch 43, Step 147468: Loss=5.6949, Acc=0.239, PPL=297.36
2025-09-26 00:35:32,181 - training.trainer - INFO - Epoch 43, Step 147568: Loss=4.1137, Acc=0.500, PPL=61.17
2025-09-26 00:35:39,465 - training.trainer - INFO - Epoch 43, Step 147668: Loss=5.2102, Acc=0.375, PPL=183.13
2025-09-26 00:35:46,908 - training.trainer - INFO - Epoch 43, Step 147768: Loss=5.8222, Acc=0.222, PPL=337.71
2025-09-26 00:35:54,267 - training.trainer - INFO - Epoch 43, Step 147868: Loss=6.1902, Acc=0.235, PPL=487.93
2025-09-26 00:36:01,786 - training.trainer - INFO - Epoch 43, Step 147968: Loss=5.9741, Acc=0.259, PPL=393.10
2025-09-26 00:36:09,202 - training.trainer - INFO - Epoch 43, Step 148068: Loss=5.8726, Acc=0.357, PPL=355.15
2025-09-26 00:36:16,719 - training.trainer - INFO - Epoch 43, Step 148168: Loss=5.9121, Acc=0.167, PPL=369.47
2025-09-26 00:36:24,183 - training.trainer - INFO - Epoch 43, Step 148268: Loss=4.9944, Acc=0.333, PPL=147.59
2025-09-26 00:36:31,625 - training.trainer - INFO - Epoch 43, Step 148368: Loss=4.9491, Acc=0.273, PPL=141.05
2025-09-26 00:36:39,556 - training.trainer - INFO - Epoch 43, Step 148468: Loss=4.2708, Acc=0.370, PPL=71.58
2025-09-26 00:36:47,250 - training.trainer - INFO - Epoch 43, Step 148568: Loss=5.3044, Acc=0.286, PPL=201.22
2025-09-26 00:36:54,646 - training.trainer - INFO - Epoch 43, Step 148668: Loss=4.9082, Acc=0.403, PPL=135.40
2025-09-26 00:37:01,927 - training.trainer - INFO - Epoch 43, Step 148768: Loss=4.9909, Acc=0.277, PPL=147.07
2025-09-26 00:37:20,856 - training.trainer - INFO - Epoch 44/100 completed in 261.13s - Train Loss: 5.2357, Train Acc: 0.322, Val Loss: 5.6955, Val Acc: 0.259
2025-09-26 00:37:28,723 - training.trainer - INFO - Epoch 44, Step 148951: Loss=6.2089, Acc=0.286, PPL=497.17
2025-09-26 00:37:36,177 - training.trainer - INFO - Epoch 44, Step 149051: Loss=4.8662, Acc=0.281, PPL=129.82
2025-09-26 00:37:43,721 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.5492, Acc=0.208, PPL=257.04
2025-09-26 00:37:51,325 - training.trainer - INFO - Epoch 44, Step 149251: Loss=5.8236, Acc=0.292, PPL=338.18
2025-09-26 00:37:58,908 - training.trainer - INFO - Epoch 44, Step 149351: Loss=5.6106, Acc=0.360, PPL=273.31
2025-09-26 00:38:06,424 - training.trainer - INFO - Epoch 44, Step 149451: Loss=5.1081, Acc=0.297, PPL=165.36
2025-09-26 00:38:13,996 - training.trainer - INFO - Epoch 44, Step 149551: Loss=5.6813, Acc=0.295, PPL=293.32
2025-09-26 00:38:21,451 - training.trainer - INFO - Epoch 44, Step 149651: Loss=5.2547, Acc=0.352, PPL=191.47
2025-09-26 00:38:28,698 - training.trainer - INFO - Epoch 44, Step 149751: Loss=6.3508, Acc=0.187, PPL=572.93
2025-09-26 00:38:36,069 - training.trainer - INFO - Epoch 44, Step 149851: Loss=4.9778, Acc=0.292, PPL=145.16
2025-09-26 00:38:43,461 - training.trainer - INFO - Epoch 44, Step 149951: Loss=5.2339, Acc=0.370, PPL=187.53
2025-09-26 00:38:50,904 - training.trainer - INFO - Epoch 44, Step 150051: Loss=4.0839, Acc=0.364, PPL=59.38
2025-09-26 00:38:58,229 - training.trainer - INFO - Epoch 44, Step 150151: Loss=5.8148, Acc=0.245, PPL=335.21
2025-09-26 00:39:05,444 - training.trainer - INFO - Epoch 44, Step 150251: Loss=5.1277, Acc=0.273, PPL=168.62
2025-09-26 00:39:12,977 - training.trainer - INFO - Epoch 44, Step 150351: Loss=5.2645, Acc=0.429, PPL=193.35
2025-09-26 00:39:20,442 - training.trainer - INFO - Epoch 44, Step 150451: Loss=5.6552, Acc=0.220, PPL=285.77
2025-09-26 00:39:27,671 - training.trainer - INFO - Epoch 44, Step 150551: Loss=4.9722, Acc=0.333, PPL=144.35
2025-09-26 00:39:34,832 - training.trainer - INFO - Epoch 44, Step 150651: Loss=4.8770, Acc=0.345, PPL=131.24
2025-09-26 00:39:42,053 - training.trainer - INFO - Epoch 44, Step 150751: Loss=5.6739, Acc=0.271, PPL=291.16
2025-09-26 00:39:49,897 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.5019, Acc=0.294, PPL=245.16
2025-09-26 00:39:57,342 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.3827, Acc=0.350, PPL=217.61
2025-09-26 00:40:04,731 - training.trainer - INFO - Epoch 44, Step 151051: Loss=6.3763, Acc=0.226, PPL=587.75
2025-09-26 00:40:12,132 - training.trainer - INFO - Epoch 44, Step 151151: Loss=6.8658, Acc=0.148, PPL=958.90
2025-09-26 00:40:19,355 - training.trainer - INFO - Epoch 44, Step 151251: Loss=5.0421, Acc=0.364, PPL=154.80
2025-09-26 00:40:26,704 - training.trainer - INFO - Epoch 44, Step 151351: Loss=5.4807, Acc=0.286, PPL=240.00
2025-09-26 00:40:33,954 - training.trainer - INFO - Epoch 44, Step 151451: Loss=5.7604, Acc=0.222, PPL=317.46
2025-09-26 00:40:41,455 - training.trainer - INFO - Epoch 44, Step 151551: Loss=5.4718, Acc=0.267, PPL=237.88
2025-09-26 00:40:48,964 - training.trainer - INFO - Epoch 44, Step 151651: Loss=5.0178, Acc=0.355, PPL=151.08
2025-09-26 00:40:56,350 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.1214, Acc=0.267, PPL=167.56
2025-09-26 00:41:03,793 - training.trainer - INFO - Epoch 44, Step 151851: Loss=3.1602, Acc=0.545, PPL=23.57
2025-09-26 00:41:11,256 - training.trainer - INFO - Epoch 44, Step 151951: Loss=4.9379, Acc=0.388, PPL=139.47
2025-09-26 00:41:18,884 - training.trainer - INFO - Epoch 44, Step 152051: Loss=5.8151, Acc=0.250, PPL=335.32
2025-09-26 00:41:26,382 - training.trainer - INFO - Epoch 44, Step 152151: Loss=6.5772, Acc=0.222, PPL=718.50
2025-09-26 00:41:45,680 - training.trainer - INFO - Epoch 45/100 completed in 264.82s - Train Loss: 5.2262, Train Acc: 0.324, Val Loss: 5.6835, Val Acc: 0.261
2025-09-26 00:41:46,066 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-26 00:41:53,735 - training.trainer - INFO - Epoch 45, Step 152334: Loss=5.4586, Acc=0.262, PPL=234.77
2025-09-26 00:42:01,132 - training.trainer - INFO - Epoch 45, Step 152434: Loss=5.4497, Acc=0.286, PPL=232.69
2025-09-26 00:42:08,417 - training.trainer - INFO - Epoch 45, Step 152534: Loss=3.9434, Acc=0.640, PPL=51.59
2025-09-26 00:42:15,643 - training.trainer - INFO - Epoch 45, Step 152634: Loss=4.4381, Acc=0.382, PPL=84.62
2025-09-26 00:42:22,894 - training.trainer - INFO - Epoch 45, Step 152734: Loss=5.4150, Acc=0.304, PPL=224.75
2025-09-26 00:42:30,311 - training.trainer - INFO - Epoch 45, Step 152834: Loss=4.5345, Acc=0.455, PPL=93.18
2025-09-26 00:42:37,918 - training.trainer - INFO - Epoch 45, Step 152934: Loss=6.9217, Acc=0.222, PPL=1014.02
2025-09-26 00:42:45,161 - training.trainer - INFO - Epoch 45, Step 153034: Loss=6.3869, Acc=0.219, PPL=594.04
2025-09-26 00:42:52,520 - training.trainer - INFO - Epoch 45, Step 153134: Loss=5.3477, Acc=0.306, PPL=210.13
2025-09-26 00:42:59,809 - training.trainer - INFO - Epoch 45, Step 153234: Loss=4.1833, Acc=0.581, PPL=65.58
2025-09-26 00:43:07,172 - training.trainer - INFO - Epoch 45, Step 153334: Loss=5.1081, Acc=0.333, PPL=165.36
2025-09-26 00:43:14,486 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.1687, Acc=0.267, PPL=175.68
2025-09-26 00:43:21,876 - training.trainer - INFO - Epoch 45, Step 153534: Loss=5.6306, Acc=0.250, PPL=278.82
2025-09-26 00:43:29,065 - training.trainer - INFO - Epoch 45, Step 153634: Loss=5.0085, Acc=0.400, PPL=149.68
2025-09-26 00:43:36,955 - training.trainer - INFO - Epoch 45, Step 153734: Loss=5.1567, Acc=0.310, PPL=173.60
2025-09-26 00:43:44,595 - training.trainer - INFO - Epoch 45, Step 153834: Loss=4.9863, Acc=0.357, PPL=146.39
2025-09-26 00:43:51,812 - training.trainer - INFO - Epoch 45, Step 153934: Loss=6.0012, Acc=0.217, PPL=403.91
2025-09-26 00:43:58,986 - training.trainer - INFO - Epoch 45, Step 154034: Loss=4.7265, Acc=0.368, PPL=112.90
2025-09-26 00:44:06,248 - training.trainer - INFO - Epoch 45, Step 154134: Loss=6.2420, Acc=0.176, PPL=513.88
2025-09-26 00:44:13,817 - training.trainer - INFO - Epoch 45, Step 154234: Loss=5.6808, Acc=0.277, PPL=293.18
2025-09-26 00:44:21,209 - training.trainer - INFO - Epoch 45, Step 154334: Loss=5.7513, Acc=0.303, PPL=314.61
2025-09-26 00:44:28,508 - training.trainer - INFO - Epoch 45, Step 154434: Loss=5.7876, Acc=0.246, PPL=326.23
2025-09-26 00:44:35,914 - training.trainer - INFO - Epoch 45, Step 154534: Loss=5.1246, Acc=0.327, PPL=168.11
2025-09-26 00:44:43,251 - training.trainer - INFO - Epoch 45, Step 154634: Loss=6.1290, Acc=0.175, PPL=458.96
2025-09-26 00:44:50,647 - training.trainer - INFO - Epoch 45, Step 154734: Loss=5.3760, Acc=0.234, PPL=216.15
2025-09-26 00:44:57,881 - training.trainer - INFO - Epoch 45, Step 154834: Loss=5.1576, Acc=0.267, PPL=173.75
2025-09-26 00:45:05,115 - training.trainer - INFO - Epoch 45, Step 154934: Loss=3.8643, Acc=0.464, PPL=47.67
2025-09-26 00:45:12,369 - training.trainer - INFO - Epoch 45, Step 155034: Loss=2.7203, Acc=0.611, PPL=15.19
2025-09-26 00:45:19,758 - training.trainer - INFO - Epoch 45, Step 155134: Loss=5.2610, Acc=0.343, PPL=192.67
2025-09-26 00:45:27,067 - training.trainer - INFO - Epoch 45, Step 155234: Loss=5.1540, Acc=0.364, PPL=173.12
2025-09-26 00:45:34,311 - training.trainer - INFO - Epoch 45, Step 155334: Loss=4.3371, Acc=0.314, PPL=76.49
2025-09-26 00:45:41,794 - training.trainer - INFO - Epoch 45, Step 155434: Loss=4.3186, Acc=0.500, PPL=75.08
2025-09-26 00:45:49,498 - training.trainer - INFO - Epoch 45, Step 155534: Loss=5.5236, Acc=0.320, PPL=250.53
2025-09-26 00:46:08,688 - training.trainer - INFO - Epoch 46/100 completed in 262.62s - Train Loss: 5.2152, Train Acc: 0.326, Val Loss: 5.6934, Val Acc: 0.264
2025-09-26 00:46:16,757 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.4048, Acc=0.263, PPL=222.47
2025-09-26 00:46:24,435 - training.trainer - INFO - Epoch 46, Step 155817: Loss=5.2722, Acc=0.280, PPL=194.83
2025-09-26 00:46:31,781 - training.trainer - INFO - Epoch 46, Step 155917: Loss=5.7837, Acc=0.294, PPL=324.97
2025-09-26 00:46:39,125 - training.trainer - INFO - Epoch 46, Step 156017: Loss=3.9590, Acc=0.500, PPL=52.41
2025-09-26 00:46:46,411 - training.trainer - INFO - Epoch 46, Step 156117: Loss=5.8665, Acc=0.173, PPL=353.01
2025-09-26 00:46:53,696 - training.trainer - INFO - Epoch 46, Step 156217: Loss=4.6963, Acc=0.364, PPL=109.55
2025-09-26 00:47:01,423 - training.trainer - INFO - Epoch 46, Step 156317: Loss=5.0657, Acc=0.385, PPL=158.48
2025-09-26 00:47:08,755 - training.trainer - INFO - Epoch 46, Step 156417: Loss=5.5326, Acc=0.300, PPL=252.81
2025-09-26 00:47:16,024 - training.trainer - INFO - Epoch 46, Step 156517: Loss=4.0186, Acc=0.556, PPL=55.62
2025-09-26 00:47:23,271 - training.trainer - INFO - Epoch 46, Step 156617: Loss=5.1944, Acc=0.220, PPL=180.27
2025-09-26 00:47:30,704 - training.trainer - INFO - Epoch 46, Step 156717: Loss=5.0706, Acc=0.304, PPL=159.27
2025-09-26 00:47:38,081 - training.trainer - INFO - Epoch 46, Step 156817: Loss=5.5971, Acc=0.310, PPL=269.64
2025-09-26 00:47:45,308 - training.trainer - INFO - Epoch 46, Step 156917: Loss=5.2645, Acc=0.268, PPL=193.35
2025-09-26 00:47:52,543 - training.trainer - INFO - Epoch 46, Step 157017: Loss=4.6703, Acc=0.436, PPL=106.73
2025-09-26 00:47:59,750 - training.trainer - INFO - Epoch 46, Step 157117: Loss=4.8357, Acc=0.360, PPL=125.93
2025-09-26 00:48:07,032 - training.trainer - INFO - Epoch 46, Step 157217: Loss=5.2438, Acc=0.333, PPL=189.39
2025-09-26 00:48:14,234 - training.trainer - INFO - Epoch 46, Step 157317: Loss=2.7673, Acc=0.684, PPL=15.92
2025-09-26 00:48:21,403 - training.trainer - INFO - Epoch 46, Step 157417: Loss=2.5349, Acc=0.682, PPL=12.62
2025-09-26 00:48:28,619 - training.trainer - INFO - Epoch 46, Step 157517: Loss=5.0937, Acc=0.273, PPL=162.99
2025-09-26 00:48:36,011 - training.trainer - INFO - Epoch 46, Step 157617: Loss=6.0560, Acc=0.240, PPL=426.68
2025-09-26 00:48:43,323 - training.trainer - INFO - Epoch 46, Step 157717: Loss=5.3019, Acc=0.375, PPL=200.72
2025-09-26 00:48:50,551 - training.trainer - INFO - Epoch 46, Step 157817: Loss=4.8100, Acc=0.357, PPL=122.73
2025-09-26 00:48:57,722 - training.trainer - INFO - Epoch 46, Step 157917: Loss=5.2346, Acc=0.302, PPL=187.66
2025-09-26 00:49:04,893 - training.trainer - INFO - Epoch 46, Step 158017: Loss=5.8897, Acc=0.222, PPL=361.29
2025-09-26 00:49:12,206 - training.trainer - INFO - Epoch 46, Step 158117: Loss=4.4484, Acc=0.429, PPL=85.49
2025-09-26 00:49:19,498 - training.trainer - INFO - Epoch 46, Step 158217: Loss=4.0858, Acc=0.600, PPL=59.49
2025-09-26 00:49:26,691 - training.trainer - INFO - Epoch 46, Step 158317: Loss=5.7811, Acc=0.281, PPL=324.10
2025-09-26 00:49:33,882 - training.trainer - INFO - Epoch 46, Step 158417: Loss=4.6816, Acc=0.333, PPL=107.94
2025-09-26 00:49:41,192 - training.trainer - INFO - Epoch 46, Step 158517: Loss=5.6026, Acc=0.219, PPL=271.13
2025-09-26 00:49:48,382 - training.trainer - INFO - Epoch 46, Step 158617: Loss=5.5468, Acc=0.250, PPL=256.43
2025-09-26 00:49:55,761 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.9440, Acc=0.234, PPL=381.46
2025-09-26 00:50:03,297 - training.trainer - INFO - Epoch 46, Step 158817: Loss=5.6323, Acc=0.244, PPL=279.31
2025-09-26 00:50:10,964 - training.trainer - INFO - Epoch 46, Step 158917: Loss=5.4074, Acc=0.351, PPL=223.05
2025-09-26 00:50:29,821 - training.trainer - INFO - Epoch 47/100 completed in 261.13s - Train Loss: 5.1966, Train Acc: 0.328, Val Loss: 5.7025, Val Acc: 0.262
2025-09-26 00:50:37,796 - training.trainer - INFO - Epoch 47, Step 159100: Loss=5.8999, Acc=0.268, PPL=364.99
2025-09-26 00:50:45,509 - training.trainer - INFO - Epoch 47, Step 159200: Loss=5.7492, Acc=0.257, PPL=313.95
2025-09-26 00:50:52,969 - training.trainer - INFO - Epoch 47, Step 159300: Loss=5.0165, Acc=0.364, PPL=150.88
2025-09-26 00:51:00,632 - training.trainer - INFO - Epoch 47, Step 159400: Loss=5.4367, Acc=0.225, PPL=229.69
2025-09-26 00:51:08,038 - training.trainer - INFO - Epoch 47, Step 159500: Loss=4.8774, Acc=0.389, PPL=131.29
2025-09-26 00:51:15,483 - training.trainer - INFO - Epoch 47, Step 159600: Loss=3.9273, Acc=0.540, PPL=50.77
2025-09-26 00:51:23,025 - training.trainer - INFO - Epoch 47, Step 159700: Loss=5.5927, Acc=0.192, PPL=268.46
2025-09-26 00:51:30,550 - training.trainer - INFO - Epoch 47, Step 159800: Loss=5.5686, Acc=0.259, PPL=262.08
2025-09-26 00:51:37,960 - training.trainer - INFO - Epoch 47, Step 159900: Loss=4.3580, Acc=0.583, PPL=78.10
2025-09-26 00:51:45,339 - training.trainer - INFO - Epoch 47, Step 160000: Loss=4.6965, Acc=0.304, PPL=109.56
2025-09-26 00:51:52,736 - training.trainer - INFO - Epoch 47, Step 160100: Loss=5.0011, Acc=0.383, PPL=148.58
2025-09-26 00:52:00,164 - training.trainer - INFO - Epoch 47, Step 160200: Loss=3.8072, Acc=0.560, PPL=45.02
2025-09-26 00:52:07,536 - training.trainer - INFO - Epoch 47, Step 160300: Loss=4.7137, Acc=0.389, PPL=111.46
2025-09-26 00:52:14,828 - training.trainer - INFO - Epoch 47, Step 160400: Loss=5.4087, Acc=0.333, PPL=223.33
2025-09-26 00:52:22,120 - training.trainer - INFO - Epoch 47, Step 160500: Loss=5.4074, Acc=0.235, PPL=223.06
2025-09-26 00:52:29,496 - training.trainer - INFO - Epoch 47, Step 160600: Loss=5.3661, Acc=0.224, PPL=214.02
2025-09-26 00:52:36,991 - training.trainer - INFO - Epoch 47, Step 160700: Loss=5.0721, Acc=0.339, PPL=159.51
2025-09-26 00:52:44,292 - training.trainer - INFO - Epoch 47, Step 160800: Loss=5.5112, Acc=0.271, PPL=247.46
2025-09-26 00:52:51,605 - training.trainer - INFO - Epoch 47, Step 160900: Loss=4.6073, Acc=0.444, PPL=100.21
2025-09-26 00:52:59,152 - training.trainer - INFO - Epoch 47, Step 161000: Loss=4.7195, Acc=0.329, PPL=112.11
2025-09-26 00:53:06,667 - training.trainer - INFO - Epoch 47, Step 161100: Loss=5.5912, Acc=0.359, PPL=268.05
2025-09-26 00:53:14,164 - training.trainer - INFO - Epoch 47, Step 161200: Loss=6.3228, Acc=0.297, PPL=557.15
2025-09-26 00:53:21,720 - training.trainer - INFO - Epoch 47, Step 161300: Loss=5.0518, Acc=0.333, PPL=156.31
2025-09-26 00:53:29,467 - training.trainer - INFO - Epoch 47, Step 161400: Loss=4.6687, Acc=0.333, PPL=106.56
2025-09-26 00:53:36,746 - training.trainer - INFO - Epoch 47, Step 161500: Loss=4.5522, Acc=0.423, PPL=94.84
2025-09-26 00:53:44,139 - training.trainer - INFO - Epoch 47, Step 161600: Loss=3.7386, Acc=0.500, PPL=42.04
2025-09-26 00:53:51,537 - training.trainer - INFO - Epoch 47, Step 161700: Loss=5.9123, Acc=0.240, PPL=369.54
2025-09-26 00:53:59,022 - training.trainer - INFO - Epoch 47, Step 161800: Loss=4.7274, Acc=0.462, PPL=113.00
2025-09-26 00:54:06,388 - training.trainer - INFO - Epoch 47, Step 161900: Loss=5.7575, Acc=0.316, PPL=316.54
2025-09-26 00:54:13,896 - training.trainer - INFO - Epoch 47, Step 162000: Loss=5.1347, Acc=0.424, PPL=169.82
2025-09-26 00:54:21,404 - training.trainer - INFO - Epoch 47, Step 162100: Loss=4.9150, Acc=0.295, PPL=136.32
2025-09-26 00:54:28,936 - training.trainer - INFO - Epoch 47, Step 162200: Loss=5.5782, Acc=0.241, PPL=264.60
2025-09-26 00:54:36,513 - training.trainer - INFO - Epoch 47, Step 162300: Loss=5.6201, Acc=0.312, PPL=275.91
2025-09-26 00:54:55,646 - training.trainer - INFO - Epoch 48/100 completed in 265.82s - Train Loss: 5.1805, Train Acc: 0.332, Val Loss: 5.6933, Val Acc: 0.263
2025-09-26 00:55:03,645 - training.trainer - INFO - Epoch 48, Step 162483: Loss=4.0928, Acc=0.448, PPL=59.91
2025-09-26 00:55:11,220 - training.trainer - INFO - Epoch 48, Step 162583: Loss=6.2811, Acc=0.250, PPL=534.37
2025-09-26 00:55:18,736 - training.trainer - INFO - Epoch 48, Step 162683: Loss=5.6415, Acc=0.293, PPL=281.87
2025-09-26 00:55:26,032 - training.trainer - INFO - Epoch 48, Step 162783: Loss=6.0449, Acc=0.407, PPL=421.95
2025-09-26 00:55:33,300 - training.trainer - INFO - Epoch 48, Step 162883: Loss=5.5986, Acc=0.250, PPL=270.06
2025-09-26 00:55:40,688 - training.trainer - INFO - Epoch 48, Step 162983: Loss=5.1316, Acc=0.429, PPL=169.29
2025-09-26 00:55:48,051 - training.trainer - INFO - Epoch 48, Step 163083: Loss=5.0147, Acc=0.306, PPL=150.60
2025-09-26 00:55:55,345 - training.trainer - INFO - Epoch 48, Step 163183: Loss=5.8041, Acc=0.302, PPL=331.66
2025-09-26 00:56:02,660 - training.trainer - INFO - Epoch 48, Step 163283: Loss=5.4525, Acc=0.321, PPL=233.34
2025-09-26 00:56:10,031 - training.trainer - INFO - Epoch 48, Step 163383: Loss=5.2978, Acc=0.389, PPL=199.89
2025-09-26 00:56:17,574 - training.trainer - INFO - Epoch 48, Step 163483: Loss=5.6406, Acc=0.242, PPL=281.64
2025-09-26 00:56:24,938 - training.trainer - INFO - Epoch 48, Step 163583: Loss=5.3358, Acc=0.282, PPL=207.64
2025-09-26 00:56:32,260 - training.trainer - INFO - Epoch 48, Step 163683: Loss=6.2513, Acc=0.238, PPL=518.69
2025-09-26 00:56:39,755 - training.trainer - INFO - Epoch 48, Step 163783: Loss=5.2607, Acc=0.307, PPL=192.62
2025-09-26 00:56:47,220 - training.trainer - INFO - Epoch 48, Step 163883: Loss=6.0036, Acc=0.218, PPL=404.88
2025-09-26 00:56:54,550 - training.trainer - INFO - Epoch 48, Step 163983: Loss=4.9582, Acc=0.394, PPL=142.34
2025-09-26 00:57:01,874 - training.trainer - INFO - Epoch 48, Step 164083: Loss=4.9059, Acc=0.394, PPL=135.09
2025-09-26 00:57:09,107 - training.trainer - INFO - Epoch 48, Step 164183: Loss=5.1152, Acc=0.333, PPL=166.54
2025-09-26 00:57:16,315 - training.trainer - INFO - Epoch 48, Step 164283: Loss=5.4081, Acc=0.400, PPL=223.21
2025-09-26 00:57:23,670 - training.trainer - INFO - Epoch 48, Step 164383: Loss=5.2827, Acc=0.364, PPL=196.90
2025-09-26 00:57:31,029 - training.trainer - INFO - Epoch 48, Step 164483: Loss=4.2722, Acc=0.439, PPL=71.68
2025-09-26 00:57:38,267 - training.trainer - INFO - Epoch 48, Step 164583: Loss=5.8051, Acc=0.270, PPL=332.00
2025-09-26 00:57:45,504 - training.trainer - INFO - Epoch 48, Step 164683: Loss=4.8864, Acc=0.364, PPL=132.47
2025-09-26 00:57:52,863 - training.trainer - INFO - Epoch 48, Step 164783: Loss=4.8823, Acc=0.257, PPL=131.93
2025-09-26 00:58:00,082 - training.trainer - INFO - Epoch 48, Step 164883: Loss=5.0832, Acc=0.241, PPL=161.28
2025-09-26 00:58:07,287 - training.trainer - INFO - Epoch 48, Step 164983: Loss=4.8286, Acc=0.346, PPL=125.03
2025-09-26 00:58:14,645 - training.trainer - INFO - Epoch 48, Step 165083: Loss=4.4315, Acc=0.375, PPL=84.06
2025-09-26 00:58:21,896 - training.trainer - INFO - Epoch 48, Step 165183: Loss=5.0976, Acc=0.275, PPL=163.64
2025-09-26 00:58:29,203 - training.trainer - INFO - Epoch 48, Step 165283: Loss=4.4526, Acc=0.360, PPL=85.85
2025-09-26 00:58:36,498 - training.trainer - INFO - Epoch 48, Step 165383: Loss=4.9114, Acc=0.333, PPL=135.83
2025-09-26 00:58:43,927 - training.trainer - INFO - Epoch 48, Step 165483: Loss=5.5749, Acc=0.294, PPL=263.73
2025-09-26 00:58:51,638 - training.trainer - INFO - Epoch 48, Step 165583: Loss=5.2502, Acc=0.340, PPL=190.61
2025-09-26 00:58:59,167 - training.trainer - INFO - Epoch 48, Step 165683: Loss=2.8942, Acc=0.789, PPL=18.07
2025-09-26 00:59:17,705 - training.trainer - INFO - Epoch 49/100 completed in 262.06s - Train Loss: 5.1665, Train Acc: 0.335, Val Loss: 5.7048, Val Acc: 0.265
2025-09-26 00:59:25,752 - training.trainer - INFO - Epoch 49, Step 165866: Loss=5.1662, Acc=0.395, PPL=175.24
2025-09-26 00:59:33,556 - training.trainer - INFO - Epoch 49, Step 165966: Loss=5.8687, Acc=0.153, PPL=353.79
2025-09-26 00:59:40,963 - training.trainer - INFO - Epoch 49, Step 166066: Loss=4.5157, Acc=0.421, PPL=91.45
2025-09-26 00:59:48,340 - training.trainer - INFO - Epoch 49, Step 166166: Loss=6.0737, Acc=0.282, PPL=434.27
2025-09-26 00:59:55,629 - training.trainer - INFO - Epoch 49, Step 166266: Loss=4.5400, Acc=0.400, PPL=93.69
2025-09-26 01:00:03,275 - training.trainer - INFO - Epoch 49, Step 166366: Loss=5.4627, Acc=0.267, PPL=235.72
2025-09-26 01:00:10,627 - training.trainer - INFO - Epoch 49, Step 166466: Loss=4.8282, Acc=0.407, PPL=124.99
2025-09-26 01:00:17,983 - training.trainer - INFO - Epoch 49, Step 166566: Loss=5.8521, Acc=0.300, PPL=347.95
2025-09-26 01:00:25,235 - training.trainer - INFO - Epoch 49, Step 166666: Loss=5.4366, Acc=0.270, PPL=229.66
2025-09-26 01:00:32,666 - training.trainer - INFO - Epoch 49, Step 166766: Loss=4.4075, Acc=0.476, PPL=82.06
2025-09-26 01:00:40,047 - training.trainer - INFO - Epoch 49, Step 166866: Loss=5.3232, Acc=0.343, PPL=205.04
2025-09-26 01:00:47,296 - training.trainer - INFO - Epoch 49, Step 166966: Loss=5.7278, Acc=0.232, PPL=307.29
2025-09-26 01:00:54,729 - training.trainer - INFO - Epoch 49, Step 167066: Loss=5.7386, Acc=0.324, PPL=310.64
2025-09-26 01:01:01,929 - training.trainer - INFO - Epoch 49, Step 167166: Loss=4.6187, Acc=0.459, PPL=101.37
2025-09-26 01:01:09,457 - training.trainer - INFO - Epoch 49, Step 167266: Loss=4.8075, Acc=0.303, PPL=122.43
2025-09-26 01:01:16,681 - training.trainer - INFO - Epoch 49, Step 167366: Loss=4.1052, Acc=0.417, PPL=60.65
2025-09-26 01:01:23,876 - training.trainer - INFO - Epoch 49, Step 167466: Loss=5.0645, Acc=0.421, PPL=158.29
2025-09-26 01:01:31,252 - training.trainer - INFO - Epoch 49, Step 167566: Loss=4.8572, Acc=0.200, PPL=128.67
2025-09-26 01:01:38,686 - training.trainer - INFO - Epoch 49, Step 167666: Loss=5.8776, Acc=0.258, PPL=356.94
2025-09-26 01:01:46,415 - training.trainer - INFO - Epoch 49, Step 167766: Loss=3.9923, Acc=0.435, PPL=54.18
2025-09-26 01:01:53,970 - training.trainer - INFO - Epoch 49, Step 167866: Loss=5.8841, Acc=0.234, PPL=359.28
2025-09-26 01:02:01,497 - training.trainer - INFO - Epoch 49, Step 167966: Loss=4.3677, Acc=0.447, PPL=78.86
2025-09-26 01:02:08,992 - training.trainer - INFO - Epoch 49, Step 168066: Loss=5.3695, Acc=0.219, PPL=214.76
2025-09-26 01:02:16,449 - training.trainer - INFO - Epoch 49, Step 168166: Loss=5.0820, Acc=0.292, PPL=161.10
2025-09-26 01:02:23,835 - training.trainer - INFO - Epoch 49, Step 168266: Loss=6.0574, Acc=0.200, PPL=427.25
2025-09-26 01:02:31,152 - training.trainer - INFO - Epoch 49, Step 168366: Loss=3.2162, Acc=0.704, PPL=24.93
2025-09-26 01:02:38,451 - training.trainer - INFO - Epoch 49, Step 168466: Loss=5.4816, Acc=0.347, PPL=240.22
2025-09-26 01:02:46,192 - training.trainer - INFO - Epoch 49, Step 168566: Loss=5.7928, Acc=0.294, PPL=327.94
2025-09-26 01:02:53,484 - training.trainer - INFO - Epoch 49, Step 168666: Loss=6.0183, Acc=0.359, PPL=410.90
2025-09-26 01:03:00,821 - training.trainer - INFO - Epoch 49, Step 168766: Loss=5.8985, Acc=0.203, PPL=364.50
2025-09-26 01:03:08,120 - training.trainer - INFO - Epoch 49, Step 168866: Loss=5.5491, Acc=0.288, PPL=257.02
2025-09-26 01:03:15,534 - training.trainer - INFO - Epoch 49, Step 168966: Loss=4.5891, Acc=0.394, PPL=98.40
2025-09-26 01:03:22,932 - training.trainer - INFO - Epoch 49, Step 169066: Loss=6.2548, Acc=0.217, PPL=520.51
2025-09-26 01:03:41,976 - training.trainer - INFO - Epoch 50/100 completed in 264.27s - Train Loss: 5.1566, Train Acc: 0.337, Val Loss: 5.7118, Val Acc: 0.261
2025-09-26 01:03:42,332 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-26 01:03:49,220 - training.trainer - INFO - Epoch 50, Step 169249: Loss=6.1883, Acc=0.235, PPL=487.02
2025-09-26 01:03:55,759 - training.trainer - INFO - Epoch 50, Step 169349: Loss=5.1561, Acc=0.260, PPL=173.49
2025-09-26 01:04:02,059 - training.trainer - INFO - Epoch 50, Step 169449: Loss=4.3704, Acc=0.360, PPL=79.07
2025-09-26 01:04:08,328 - training.trainer - INFO - Epoch 50, Step 169549: Loss=4.3986, Acc=0.273, PPL=81.33
2025-09-26 01:04:14,593 - training.trainer - INFO - Epoch 50, Step 169649: Loss=5.3187, Acc=0.294, PPL=204.12
2025-09-26 01:04:21,610 - training.trainer - INFO - Epoch 50, Step 169749: Loss=5.6726, Acc=0.348, PPL=290.80
2025-09-26 01:04:28,775 - training.trainer - INFO - Epoch 50, Step 169849: Loss=5.8200, Acc=0.298, PPL=336.99
2025-09-26 01:04:35,721 - training.trainer - INFO - Epoch 50, Step 169949: Loss=5.2964, Acc=0.360, PPL=199.61
2025-09-26 01:04:43,285 - training.trainer - INFO - Epoch 50, Step 170049: Loss=5.7150, Acc=0.308, PPL=303.39
2025-09-26 01:04:50,666 - training.trainer - INFO - Epoch 50, Step 170149: Loss=4.4677, Acc=0.423, PPL=87.15
2025-09-26 01:04:58,037 - training.trainer - INFO - Epoch 50, Step 170249: Loss=4.5296, Acc=0.481, PPL=92.72
2025-09-26 01:05:05,330 - training.trainer - INFO - Epoch 50, Step 170349: Loss=5.7509, Acc=0.438, PPL=314.49
2025-09-26 01:05:12,589 - training.trainer - INFO - Epoch 50, Step 170449: Loss=3.6693, Acc=0.560, PPL=39.22
2025-09-26 01:05:20,242 - training.trainer - INFO - Epoch 50, Step 170549: Loss=5.8189, Acc=0.200, PPL=336.60
2025-09-26 01:05:27,605 - training.trainer - INFO - Epoch 50, Step 170649: Loss=6.0670, Acc=0.240, PPL=431.38
2025-09-26 01:05:34,973 - training.trainer - INFO - Epoch 50, Step 170749: Loss=5.8367, Acc=0.283, PPL=342.66
2025-09-26 01:05:42,345 - training.trainer - INFO - Epoch 50, Step 170849: Loss=5.1611, Acc=0.279, PPL=174.36
2025-09-26 01:05:49,643 - training.trainer - INFO - Epoch 50, Step 170949: Loss=5.2688, Acc=0.366, PPL=194.19
2025-09-26 01:05:56,927 - training.trainer - INFO - Epoch 50, Step 171049: Loss=5.1699, Acc=0.455, PPL=175.89
2025-09-26 01:06:04,430 - training.trainer - INFO - Epoch 50, Step 171149: Loss=4.9668, Acc=0.375, PPL=143.57
2025-09-26 01:06:11,829 - training.trainer - INFO - Epoch 50, Step 171249: Loss=5.8706, Acc=0.195, PPL=354.47
2025-09-26 01:06:19,321 - training.trainer - INFO - Epoch 50, Step 171349: Loss=3.9213, Acc=0.562, PPL=50.47
2025-09-26 01:06:26,684 - training.trainer - INFO - Epoch 50, Step 171449: Loss=4.4840, Acc=0.350, PPL=88.58
2025-09-26 01:06:34,262 - training.trainer - INFO - Epoch 50, Step 171549: Loss=5.7332, Acc=0.270, PPL=308.95
2025-09-26 01:06:41,650 - training.trainer - INFO - Epoch 50, Step 171649: Loss=4.1369, Acc=0.533, PPL=62.61
2025-09-26 01:06:49,230 - training.trainer - INFO - Epoch 50, Step 171749: Loss=5.1176, Acc=0.282, PPL=166.93
2025-09-26 01:06:56,752 - training.trainer - INFO - Epoch 50, Step 171849: Loss=5.2797, Acc=0.233, PPL=196.31
2025-09-26 01:07:04,226 - training.trainer - INFO - Epoch 50, Step 171949: Loss=5.7248, Acc=0.231, PPL=306.36
2025-09-26 01:07:11,873 - training.trainer - INFO - Epoch 50, Step 172049: Loss=5.1502, Acc=0.143, PPL=172.46
2025-09-26 01:07:19,302 - training.trainer - INFO - Epoch 50, Step 172149: Loss=5.6519, Acc=0.293, PPL=284.82
2025-09-26 01:07:26,665 - training.trainer - INFO - Epoch 50, Step 172249: Loss=5.8795, Acc=0.280, PPL=357.64
2025-09-26 01:07:34,100 - training.trainer - INFO - Epoch 50, Step 172349: Loss=5.2725, Acc=0.345, PPL=194.90
2025-09-26 01:07:41,833 - training.trainer - INFO - Epoch 50, Step 172449: Loss=5.4126, Acc=0.281, PPL=224.22
2025-09-26 01:08:00,561 - training.trainer - INFO - Epoch 51/100 completed in 258.23s - Train Loss: 5.1445, Train Acc: 0.336, Val Loss: 5.7141, Val Acc: 0.262
2025-09-26 01:08:00,562 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-09-26 01:08:00,562 - training.trainer - INFO - Training completed!
2025-09-26 01:08:00,562 - __main__ - INFO - Training completed successfully!
2025-09-26 01:08:00,712 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-26 01:08:00,741 - __main__ - INFO - Process completed!
2025-09-26 01:08:06,705 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-26 01:08:06,705 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-26 01:08:06,705 - __main__ - INFO - Starting model evaluation
2025-09-26 01:08:07,449 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-26 01:13:49,954 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-26 01:13:49,970 - __main__ - INFO - Process completed!
2025-09-26 01:13:54,948 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-26 01:13:54,948 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-26 01:13:54,948 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-09-26 01:13:55,537 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-26 01:14:16,790 - __main__ - INFO - Inference completed successfully!
2025-09-26 01:14:16,798 - __main__ - INFO - Process completed!
2025-09-27 12:35:54,851 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-27 12:35:54,852 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-27 12:35:54,852 - __main__ - INFO - Starting model evaluation
2025-09-27 12:35:55,635 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-27 20:09:19,319 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-27 20:09:19,319 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-27 20:09:19,319 - __main__ - INFO - Starting training pipeline
2025-09-27 20:09:19,428 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-09-27 20:09:19,458 - __main__ - INFO - GPU: NVIDIA A30
2025-09-27 20:09:19,458 - __main__ - INFO - GPU Memory: 23.5 GB
2025-09-27 20:09:19,459 - __main__ - INFO - Loading training data...
2025-09-27 20:09:27,146 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-27 20:09:27,146 - __main__ - INFO - Processing train split...
2025-09-27 20:09:27,231 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-27 20:09:27,232 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-27 20:10:11,210 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-27 20:10:54,927 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-27 20:11:39,421 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-27 20:12:22,708 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-27 20:13:05,749 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-27 20:13:47,916 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-27 20:14:20,540 - __main__ - INFO - Processing val split...
2025-09-27 20:14:20,763 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-27 20:14:20,764 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-27 20:14:53,320 - __main__ - INFO - Processing test split...
2025-09-27 20:14:53,536 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-27 20:14:53,536 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-27 20:15:26,071 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-27 20:15:26,072 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-27 20:15:26,087 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-09-27 20:15:26,087 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-27 20:15:26,087 - __main__ - INFO - Creating model architecture...
2025-09-27 20:15:26,372 - __main__ - INFO - Model created successfully
2025-09-27 20:15:26,372 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-27 20:15:26,372 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-27 20:15:26,373 - __main__ - INFO - Using device: cuda
2025-09-27 20:15:26,373 - __main__ - INFO - Creating trainer...
2025-09-27 20:15:26,373 - __main__ - INFO - Moving model to cuda...
2025-09-27 20:15:26,676 - __main__ - INFO - Model moved to cuda
2025-09-27 20:15:26,676 - __main__ - INFO - Model parameters are on: cuda:0
2025-09-27 20:15:27,952 - __main__ - INFO - Trainer created successfully
2025-09-27 20:15:27,953 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-09-27 20:15:27,953 - __main__ - INFO - Starting training...
2025-09-27 20:15:27,953 - __main__ - INFO - Training configuration:
2025-09-27 20:15:27,953 - __main__ - INFO -   - Epochs: 100
2025-09-27 20:15:27,953 - __main__ - INFO -   - Batch size: 32
2025-09-27 20:15:27,953 - __main__ - INFO -   - Learning rate: 1e-5
2025-09-27 20:15:27,953 - __main__ - INFO -   - Training samples: 6765
2025-09-27 20:15:27,953 - __main__ - INFO -   - Validation samples: 845
2025-09-27 20:15:27,953 - training.trainer - INFO - Starting training for 100 epochs
2025-09-27 20:15:27,954 - training.trainer - INFO - Model parameters: 16,680,032
2025-09-27 20:15:27,954 - training.trainer - INFO - Training on device: cuda
2025-09-27 20:16:07,825 - training.trainer - INFO - Epoch 0, Step 99: Loss=9.1116, Acc=0.065, 
2025-09-27 20:16:44,362 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.8976, Acc=0.073, 
2025-09-27 20:17:01,142 - training.trainer - INFO - Epoch 1/100 completed in 93.19s - Train Loss: 9.1293, Train Acc: 0.057, Val Loss: 8.8211, Val Acc: 0.069
2025-09-27 20:17:01,754 - training.trainer - INFO - New best model saved with validation loss: 8.8211
2025-09-27 20:17:01,754 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-27 20:17:46,419 - training.trainer - INFO - Epoch 1, Step 311: Loss=8.6883, Acc=0.068, 
2025-09-27 20:18:28,445 - training.trainer - INFO - Epoch 1, Step 411: Loss=8.4423, Acc=0.077, 
2025-09-27 20:18:44,290 - training.trainer - INFO - Epoch 2/100 completed in 102.54s - Train Loss: 8.6530, Train Acc: 0.074, Val Loss: 8.3822, Val Acc: 0.084
2025-09-27 20:18:45,081 - training.trainer - INFO - New best model saved with validation loss: 8.3822
2025-09-27 20:18:45,081 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-27 20:19:29,868 - training.trainer - INFO - Epoch 2, Step 523: Loss=8.2123, Acc=0.095, 
2025-09-27 20:20:11,293 - training.trainer - INFO - Epoch 2, Step 623: Loss=8.0249, Acc=0.087, 
2025-09-27 20:20:28,090 - training.trainer - INFO - Epoch 3/100 completed in 103.01s - Train Loss: 8.2127, Train Acc: 0.089, Val Loss: 7.9560, Val Acc: 0.092
2025-09-27 20:20:28,791 - training.trainer - INFO - New best model saved with validation loss: 7.9560
2025-09-27 20:20:28,792 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-27 20:21:12,422 - training.trainer - INFO - Epoch 3, Step 735: Loss=7.8256, Acc=0.092, 
2025-09-27 20:21:57,152 - training.trainer - INFO - Epoch 3, Step 835: Loss=7.5877, Acc=0.088, 
2025-09-27 20:22:14,391 - training.trainer - INFO - Epoch 4/100 completed in 105.60s - Train Loss: 7.8111, Train Acc: 0.096, Val Loss: 7.6001, Val Acc: 0.097
2025-09-27 20:22:15,220 - training.trainer - INFO - New best model saved with validation loss: 7.6001
2025-09-27 20:22:15,220 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-27 20:23:02,513 - training.trainer - INFO - Epoch 4, Step 947: Loss=7.4851, Acc=0.090, 
2025-09-27 20:23:47,171 - training.trainer - INFO - Epoch 4, Step 1047: Loss=7.4503, Acc=0.093, 
2025-09-27 20:24:05,138 - training.trainer - INFO - Epoch 5/100 completed in 109.92s - Train Loss: 7.4706, Train Acc: 0.102, Val Loss: 7.3043, Val Acc: 0.101
2025-09-27 20:24:05,512 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-27 20:24:06,248 - training.trainer - INFO - New best model saved with validation loss: 7.3043
2025-09-27 20:24:06,248 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-27 20:24:51,843 - training.trainer - INFO - Epoch 5, Step 1159: Loss=7.2631, Acc=0.108, 
2025-09-27 20:25:36,634 - training.trainer - INFO - Epoch 5, Step 1259: Loss=7.0635, Acc=0.105, 
2025-09-27 20:25:53,822 - training.trainer - INFO - Epoch 6/100 completed in 107.57s - Train Loss: 7.1891, Train Acc: 0.107, Val Loss: 7.0703, Val Acc: 0.110
2025-09-27 20:25:54,487 - training.trainer - INFO - New best model saved with validation loss: 7.0703
2025-09-27 20:25:54,487 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-27 20:26:40,623 - training.trainer - INFO - Epoch 6, Step 1371: Loss=6.9394, Acc=0.117, 
2025-09-27 20:27:25,536 - training.trainer - INFO - Epoch 6, Step 1471: Loss=6.8889, Acc=0.116, 
2025-09-27 20:27:42,745 - training.trainer - INFO - Epoch 7/100 completed in 108.26s - Train Loss: 6.9717, Train Acc: 0.115, Val Loss: 6.9040, Val Acc: 0.114
2025-09-27 20:27:43,407 - training.trainer - INFO - New best model saved with validation loss: 6.9040
2025-09-27 20:27:43,407 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-27 20:28:28,990 - training.trainer - INFO - Epoch 7, Step 1583: Loss=6.7758, Acc=0.118, 
2025-09-27 20:29:16,202 - training.trainer - INFO - Epoch 7, Step 1683: Loss=6.7338, Acc=0.128, 
2025-09-27 20:29:33,997 - training.trainer - INFO - Epoch 8/100 completed in 110.59s - Train Loss: 6.8223, Train Acc: 0.123, Val Loss: 6.7929, Val Acc: 0.129
2025-09-27 20:29:34,653 - training.trainer - INFO - New best model saved with validation loss: 6.7929
2025-09-27 20:29:34,653 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-09-27 20:30:28,357 - training.trainer - INFO - Epoch 8, Step 1795: Loss=6.7570, Acc=0.146, 
2025-09-27 20:31:18,318 - training.trainer - INFO - Epoch 8, Step 1895: Loss=6.7467, Acc=0.145, 
2025-09-27 20:31:36,934 - training.trainer - INFO - Epoch 9/100 completed in 122.28s - Train Loss: 6.7345, Train Acc: 0.131, Val Loss: 6.7319, Val Acc: 0.133
2025-09-27 20:31:37,854 - training.trainer - INFO - New best model saved with validation loss: 6.7319
2025-09-27 20:31:37,854 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-27 20:32:27,840 - training.trainer - INFO - Epoch 9, Step 2007: Loss=6.6941, Acc=0.130, 
2025-09-27 20:33:17,974 - training.trainer - INFO - Epoch 9, Step 2107: Loss=6.8162, Acc=0.123, 
2025-09-27 20:33:35,613 - training.trainer - INFO - Epoch 10/100 completed in 117.76s - Train Loss: 6.6865, Train Acc: 0.132, Val Loss: 6.6907, Val Acc: 0.135
2025-09-27 20:33:36,051 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-27 20:33:36,838 - training.trainer - INFO - New best model saved with validation loss: 6.6907
2025-09-27 20:33:36,839 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-27 20:34:24,061 - training.trainer - INFO - Epoch 10, Step 2219: Loss=6.7375, Acc=0.120, 
2025-09-27 20:35:13,915 - training.trainer - INFO - Epoch 10, Step 2319: Loss=6.6512, Acc=0.141, 
2025-09-27 20:35:34,035 - training.trainer - INFO - Epoch 11/100 completed in 117.20s - Train Loss: 6.6485, Train Acc: 0.134, Val Loss: 6.6522, Val Acc: 0.140
2025-09-27 20:35:34,663 - training.trainer - INFO - New best model saved with validation loss: 6.6522
2025-09-27 20:35:34,663 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-27 20:36:24,242 - training.trainer - INFO - Epoch 11, Step 2431: Loss=6.6957, Acc=0.124, 
2025-09-27 20:37:14,493 - training.trainer - INFO - Epoch 11, Step 2531: Loss=6.6608, Acc=0.163, 
2025-09-27 20:37:34,476 - training.trainer - INFO - Epoch 12/100 completed in 119.81s - Train Loss: 6.6108, Train Acc: 0.144, Val Loss: 6.6142, Val Acc: 0.150
2025-09-27 20:37:35,128 - training.trainer - INFO - New best model saved with validation loss: 6.6142
2025-09-27 20:37:35,128 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-09-27 20:38:23,385 - training.trainer - INFO - Epoch 12, Step 2643: Loss=6.4423, Acc=0.163, 
2025-09-27 20:39:09,350 - training.trainer - INFO - Epoch 12, Step 2743: Loss=6.4379, Acc=0.198, 
2025-09-27 20:39:27,977 - training.trainer - INFO - Epoch 13/100 completed in 112.85s - Train Loss: 6.5727, Train Acc: 0.149, Val Loss: 6.5710, Val Acc: 0.154
2025-09-27 20:39:28,723 - training.trainer - INFO - New best model saved with validation loss: 6.5710
2025-09-27 20:39:28,723 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-27 20:40:17,737 - training.trainer - INFO - Epoch 13, Step 2855: Loss=6.4730, Acc=0.162, 
2025-09-27 20:41:05,256 - training.trainer - INFO - Epoch 13, Step 2955: Loss=6.5275, Acc=0.152, 
2025-09-27 20:41:23,584 - training.trainer - INFO - Epoch 14/100 completed in 114.86s - Train Loss: 6.5351, Train Acc: 0.151, Val Loss: 6.5389, Val Acc: 0.154
2025-09-27 20:41:24,276 - training.trainer - INFO - New best model saved with validation loss: 6.5389
2025-09-27 20:41:24,276 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-27 20:42:09,029 - training.trainer - INFO - Epoch 14, Step 3067: Loss=6.3928, Acc=0.169, 
2025-09-27 20:42:54,752 - training.trainer - INFO - Epoch 14, Step 3167: Loss=6.5788, Acc=0.147, 
2025-09-27 20:43:15,042 - training.trainer - INFO - Epoch 15/100 completed in 110.77s - Train Loss: 6.5022, Train Acc: 0.154, Val Loss: 6.5130, Val Acc: 0.157
2025-09-27 20:43:15,442 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-27 20:43:16,314 - training.trainer - INFO - New best model saved with validation loss: 6.5130
2025-09-27 20:43:16,314 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-27 20:44:01,670 - training.trainer - INFO - Epoch 15, Step 3279: Loss=6.3956, Acc=0.158, 
2025-09-27 20:44:45,781 - training.trainer - INFO - Epoch 15, Step 3379: Loss=6.5568, Acc=0.149, 
2025-09-27 20:45:03,367 - training.trainer - INFO - Epoch 16/100 completed in 107.05s - Train Loss: 6.4721, Train Acc: 0.155, Val Loss: 6.4882, Val Acc: 0.157
2025-09-27 20:45:04,098 - training.trainer - INFO - New best model saved with validation loss: 6.4882
2025-09-27 20:45:04,098 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-27 20:45:50,246 - training.trainer - INFO - Epoch 16, Step 3491: Loss=6.5350, Acc=0.165, 
2025-09-27 20:46:37,413 - training.trainer - INFO - Epoch 16, Step 3591: Loss=6.3982, Acc=0.133, 
2025-09-27 20:46:55,333 - training.trainer - INFO - Epoch 17/100 completed in 111.23s - Train Loss: 6.4458, Train Acc: 0.156, Val Loss: 6.4603, Val Acc: 0.156
2025-09-27 20:46:56,122 - training.trainer - INFO - New best model saved with validation loss: 6.4603
2025-09-27 20:46:56,122 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-27 20:47:43,299 - training.trainer - INFO - Epoch 17, Step 3703: Loss=6.3893, Acc=0.163, 
2025-09-27 20:48:31,407 - training.trainer - INFO - Epoch 17, Step 3803: Loss=6.3710, Acc=0.170, 
2025-09-27 20:48:49,688 - training.trainer - INFO - Epoch 18/100 completed in 113.57s - Train Loss: 6.4211, Train Acc: 0.157, Val Loss: 6.4417, Val Acc: 0.157
2025-09-27 20:48:50,438 - training.trainer - INFO - New best model saved with validation loss: 6.4417
2025-09-27 20:48:50,438 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-27 20:49:40,836 - training.trainer - INFO - Epoch 18, Step 3915: Loss=6.5147, Acc=0.163, 
2025-09-27 20:50:29,203 - training.trainer - INFO - Epoch 18, Step 4015: Loss=6.4440, Acc=0.162, 
2025-09-27 20:50:46,507 - training.trainer - INFO - Epoch 19/100 completed in 116.07s - Train Loss: 6.3965, Train Acc: 0.158, Val Loss: 6.4236, Val Acc: 0.159
2025-09-27 20:50:47,194 - training.trainer - INFO - New best model saved with validation loss: 6.4236
2025-09-27 20:50:47,194 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-27 20:51:38,878 - training.trainer - INFO - Epoch 19, Step 4127: Loss=6.3307, Acc=0.171, 
2025-09-27 20:52:25,592 - training.trainer - INFO - Epoch 19, Step 4227: Loss=6.2762, Acc=0.171, 
2025-09-27 20:52:44,692 - training.trainer - INFO - Epoch 20/100 completed in 117.50s - Train Loss: 6.3758, Train Acc: 0.159, Val Loss: 6.4002, Val Acc: 0.160
2025-09-27 20:52:45,018 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-27 20:52:45,622 - training.trainer - INFO - New best model saved with validation loss: 6.4002
2025-09-27 20:52:45,622 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-27 20:53:35,210 - training.trainer - INFO - Epoch 20, Step 4339: Loss=6.2883, Acc=0.185, 
2025-09-27 20:54:22,419 - training.trainer - INFO - Epoch 20, Step 4439: Loss=6.2828, Acc=0.197, 
2025-09-27 20:54:40,138 - training.trainer - INFO - Epoch 21/100 completed in 114.52s - Train Loss: 6.3533, Train Acc: 0.160, Val Loss: 6.3852, Val Acc: 0.162
2025-09-27 20:54:40,918 - training.trainer - INFO - New best model saved with validation loss: 6.3852
2025-09-27 20:54:40,919 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-09-27 20:55:28,880 - training.trainer - INFO - Epoch 21, Step 4551: Loss=6.3686, Acc=0.164, 
2025-09-27 20:56:16,079 - training.trainer - INFO - Epoch 21, Step 4651: Loss=6.4329, Acc=0.153, 
2025-09-27 20:56:34,719 - training.trainer - INFO - Epoch 22/100 completed in 113.80s - Train Loss: 6.3336, Train Acc: 0.161, Val Loss: 6.3639, Val Acc: 0.161
2025-09-27 20:56:35,454 - training.trainer - INFO - New best model saved with validation loss: 6.3639
2025-09-27 20:56:35,454 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-09-27 20:57:27,209 - training.trainer - INFO - Epoch 22, Step 4763: Loss=6.2085, Acc=0.152, 
2025-09-27 20:58:15,766 - training.trainer - INFO - Epoch 22, Step 4863: Loss=6.2920, Acc=0.178, 
2025-09-27 20:58:35,023 - training.trainer - INFO - Epoch 23/100 completed in 119.57s - Train Loss: 6.3125, Train Acc: 0.162, Val Loss: 6.3498, Val Acc: 0.160
2025-09-27 20:58:35,909 - training.trainer - INFO - New best model saved with validation loss: 6.3498
2025-09-27 20:58:35,910 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-09-27 20:59:28,564 - training.trainer - INFO - Epoch 23, Step 4975: Loss=6.4974, Acc=0.153, 
2025-09-27 21:00:14,891 - training.trainer - INFO - Epoch 23, Step 5075: Loss=6.4486, Acc=0.162, 
2025-09-27 21:00:34,645 - training.trainer - INFO - Epoch 24/100 completed in 118.73s - Train Loss: 6.2948, Train Acc: 0.163, Val Loss: 6.3339, Val Acc: 0.161
2025-09-27 21:00:35,435 - training.trainer - INFO - New best model saved with validation loss: 6.3339
2025-09-27 21:00:35,435 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-09-27 21:01:26,055 - training.trainer - INFO - Epoch 24, Step 5187: Loss=6.2155, Acc=0.161, 
2025-09-27 21:02:12,818 - training.trainer - INFO - Epoch 24, Step 5287: Loss=6.1990, Acc=0.183, 
2025-09-27 21:02:30,622 - training.trainer - INFO - Epoch 25/100 completed in 115.19s - Train Loss: 6.2753, Train Acc: 0.165, Val Loss: 6.3165, Val Acc: 0.163
2025-09-27 21:02:30,969 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-27 21:02:31,641 - training.trainer - INFO - New best model saved with validation loss: 6.3165
2025-09-27 21:02:31,642 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-27 21:03:22,216 - training.trainer - INFO - Epoch 25, Step 5399: Loss=6.2576, Acc=0.158, 
2025-09-27 21:04:10,264 - training.trainer - INFO - Epoch 25, Step 5499: Loss=6.4462, Acc=0.154, 
2025-09-27 21:04:29,900 - training.trainer - INFO - Epoch 26/100 completed in 118.26s - Train Loss: 6.2582, Train Acc: 0.165, Val Loss: 6.3028, Val Acc: 0.163
2025-09-27 21:04:30,599 - training.trainer - INFO - New best model saved with validation loss: 6.3028
2025-09-27 21:04:30,599 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_26.pt
2025-09-27 21:05:21,379 - training.trainer - INFO - Epoch 26, Step 5611: Loss=6.2596, Acc=0.164, 
2025-09-27 21:06:09,148 - training.trainer - INFO - Epoch 26, Step 5711: Loss=6.2712, Acc=0.167, 
2025-09-27 21:06:27,116 - training.trainer - INFO - Epoch 27/100 completed in 116.52s - Train Loss: 6.2414, Train Acc: 0.167, Val Loss: 6.2878, Val Acc: 0.164
2025-09-27 21:06:27,817 - training.trainer - INFO - New best model saved with validation loss: 6.2878
2025-09-27 21:06:27,817 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_27.pt
2025-09-27 21:07:16,530 - training.trainer - INFO - Epoch 27, Step 5823: Loss=6.2899, Acc=0.164, 
2025-09-27 21:08:07,046 - training.trainer - INFO - Epoch 27, Step 5923: Loss=6.2031, Acc=0.190, 
2025-09-27 21:08:27,685 - training.trainer - INFO - Epoch 28/100 completed in 119.87s - Train Loss: 6.2264, Train Acc: 0.168, Val Loss: 6.2721, Val Acc: 0.164
2025-09-27 21:08:28,370 - training.trainer - INFO - New best model saved with validation loss: 6.2721
2025-09-27 21:08:28,371 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_28.pt
2025-09-27 21:09:15,622 - training.trainer - INFO - Epoch 28, Step 6035: Loss=6.2827, Acc=0.166, 
2025-09-27 21:10:02,941 - training.trainer - INFO - Epoch 28, Step 6135: Loss=6.1383, Acc=0.165, 
2025-09-27 21:10:21,178 - training.trainer - INFO - Epoch 29/100 completed in 112.81s - Train Loss: 6.2098, Train Acc: 0.169, Val Loss: 6.2628, Val Acc: 0.164
2025-09-27 21:10:21,805 - training.trainer - INFO - New best model saved with validation loss: 6.2628
2025-09-27 21:10:21,806 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_29.pt
2025-09-27 21:11:04,898 - training.trainer - INFO - Epoch 29, Step 6247: Loss=6.1329, Acc=0.174, 
2025-09-27 21:11:47,548 - training.trainer - INFO - Epoch 29, Step 6347: Loss=6.3066, Acc=0.166, 
2025-09-27 21:12:05,308 - training.trainer - INFO - Epoch 30/100 completed in 103.50s - Train Loss: 6.1966, Train Acc: 0.170, Val Loss: 6.2515, Val Acc: 0.165
2025-09-27 21:12:05,695 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-27 21:12:06,471 - training.trainer - INFO - New best model saved with validation loss: 6.2515
2025-09-27 21:12:06,471 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-27 21:12:49,787 - training.trainer - INFO - Epoch 30, Step 6459: Loss=6.3059, Acc=0.185, 
2025-09-27 21:13:32,994 - training.trainer - INFO - Epoch 30, Step 6559: Loss=6.1403, Acc=0.188, 
2025-09-27 21:13:51,310 - training.trainer - INFO - Epoch 31/100 completed in 104.84s - Train Loss: 6.1835, Train Acc: 0.172, Val Loss: 6.2378, Val Acc: 0.168
2025-09-27 21:13:51,994 - training.trainer - INFO - New best model saved with validation loss: 6.2378
2025-09-27 21:13:51,995 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_31.pt
2025-09-27 21:14:37,290 - training.trainer - INFO - Epoch 31, Step 6671: Loss=5.9528, Acc=0.198, 
2025-09-27 21:15:19,552 - training.trainer - INFO - Epoch 31, Step 6771: Loss=6.2346, Acc=0.174, 
2025-09-27 21:15:37,895 - training.trainer - INFO - Epoch 32/100 completed in 105.90s - Train Loss: 6.1697, Train Acc: 0.172, Val Loss: 6.2270, Val Acc: 0.168
2025-09-27 21:15:38,724 - training.trainer - INFO - New best model saved with validation loss: 6.2270
2025-09-27 21:15:38,724 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_32.pt
2025-09-27 21:16:23,133 - training.trainer - INFO - Epoch 32, Step 6883: Loss=5.9754, Acc=0.204, 
2025-09-27 21:17:07,791 - training.trainer - INFO - Epoch 32, Step 6983: Loss=6.2124, Acc=0.168, 
2025-09-27 21:17:25,435 - training.trainer - INFO - Epoch 33/100 completed in 106.71s - Train Loss: 6.1556, Train Acc: 0.173, Val Loss: 6.2166, Val Acc: 0.169
2025-09-27 21:17:26,177 - training.trainer - INFO - New best model saved with validation loss: 6.2166
2025-09-27 21:17:26,177 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_33.pt
2025-09-27 21:18:11,450 - training.trainer - INFO - Epoch 33, Step 7095: Loss=6.2063, Acc=0.196, 
2025-09-27 21:18:53,362 - training.trainer - INFO - Epoch 33, Step 7195: Loss=6.0694, Acc=0.177, 
2025-09-27 21:19:10,671 - training.trainer - INFO - Epoch 34/100 completed in 104.49s - Train Loss: 6.1429, Train Acc: 0.174, Val Loss: 6.2115, Val Acc: 0.168
2025-09-27 21:19:11,334 - training.trainer - INFO - New best model saved with validation loss: 6.2115
2025-09-27 21:19:11,334 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_34.pt
2025-09-27 21:19:57,432 - training.trainer - INFO - Epoch 34, Step 7307: Loss=6.1332, Acc=0.170, 
2025-09-27 21:20:39,948 - training.trainer - INFO - Epoch 34, Step 7407: Loss=6.3219, Acc=0.176, 
2025-09-27 21:20:58,190 - training.trainer - INFO - Epoch 35/100 completed in 106.86s - Train Loss: 6.1328, Train Acc: 0.175, Val Loss: 6.1984, Val Acc: 0.168
2025-09-27 21:20:58,563 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-27 21:20:59,328 - training.trainer - INFO - New best model saved with validation loss: 6.1984
2025-09-27 21:20:59,328 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-27 21:21:44,732 - training.trainer - INFO - Epoch 35, Step 7519: Loss=6.1333, Acc=0.174, 
2025-09-27 21:22:29,868 - training.trainer - INFO - Epoch 35, Step 7619: Loss=6.2117, Acc=0.162, 
2025-09-27 21:22:45,533 - training.trainer - INFO - Epoch 36/100 completed in 106.20s - Train Loss: 6.1187, Train Acc: 0.176, Val Loss: 6.1876, Val Acc: 0.170
2025-09-27 21:22:46,160 - training.trainer - INFO - New best model saved with validation loss: 6.1876
2025-09-27 21:22:46,161 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_36.pt
2025-09-27 21:23:34,155 - training.trainer - INFO - Epoch 36, Step 7731: Loss=6.1375, Acc=0.180, 
2025-09-27 21:24:19,497 - training.trainer - INFO - Epoch 36, Step 7831: Loss=6.2701, Acc=0.169, 
2025-09-27 21:24:35,659 - training.trainer - INFO - Epoch 37/100 completed in 109.50s - Train Loss: 6.1095, Train Acc: 0.176, Val Loss: 6.1756, Val Acc: 0.171
2025-09-27 21:24:36,318 - training.trainer - INFO - New best model saved with validation loss: 6.1756
2025-09-27 21:24:36,318 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_37.pt
2025-09-27 21:25:21,538 - training.trainer - INFO - Epoch 37, Step 7943: Loss=6.2220, Acc=0.175, 
2025-09-27 21:26:05,873 - training.trainer - INFO - Epoch 37, Step 8043: Loss=6.2168, Acc=0.160, 
2025-09-27 21:26:23,616 - training.trainer - INFO - Epoch 38/100 completed in 107.30s - Train Loss: 6.0988, Train Acc: 0.177, Val Loss: 6.1702, Val Acc: 0.171
2025-09-27 21:26:24,420 - training.trainer - INFO - New best model saved with validation loss: 6.1702
2025-09-27 21:26:24,421 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_38.pt
2025-09-27 21:27:08,933 - training.trainer - INFO - Epoch 38, Step 8155: Loss=6.0388, Acc=0.158, 
2025-09-27 21:27:53,224 - training.trainer - INFO - Epoch 38, Step 8255: Loss=6.0934, Acc=0.173, 
2025-09-27 21:28:11,591 - training.trainer - INFO - Epoch 39/100 completed in 107.17s - Train Loss: 6.0886, Train Acc: 0.178, Val Loss: 6.1633, Val Acc: 0.172
2025-09-27 21:28:12,322 - training.trainer - INFO - New best model saved with validation loss: 6.1633
2025-09-27 21:28:12,323 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_39.pt
2025-09-27 21:29:03,189 - training.trainer - INFO - Epoch 39, Step 8367: Loss=6.2856, Acc=0.150, 
2025-09-27 21:29:47,221 - training.trainer - INFO - Epoch 39, Step 8467: Loss=6.0498, Acc=0.212, 
2025-09-27 21:30:05,556 - training.trainer - INFO - Epoch 40/100 completed in 113.23s - Train Loss: 6.0791, Train Acc: 0.178, Val Loss: 6.1559, Val Acc: 0.172
2025-09-27 21:30:05,878 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-27 21:30:06,492 - training.trainer - INFO - New best model saved with validation loss: 6.1559
2025-09-27 21:30:06,492 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-27 21:30:55,724 - training.trainer - INFO - Epoch 40, Step 8579: Loss=6.0587, Acc=0.180, 
2025-09-27 21:31:40,902 - training.trainer - INFO - Epoch 40, Step 8679: Loss=6.0200, Acc=0.169, 
2025-09-27 21:31:57,770 - training.trainer - INFO - Epoch 41/100 completed in 111.28s - Train Loss: 6.0715, Train Acc: 0.178, Val Loss: 6.1505, Val Acc: 0.173
2025-09-27 21:31:58,531 - training.trainer - INFO - New best model saved with validation loss: 6.1505
2025-09-27 21:31:58,531 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_41.pt
2025-09-27 21:32:50,932 - training.trainer - INFO - Epoch 41, Step 8791: Loss=6.0295, Acc=0.180, 
2025-09-27 21:33:37,693 - training.trainer - INFO - Epoch 41, Step 8891: Loss=6.0060, Acc=0.197, 
2025-09-27 21:33:56,628 - training.trainer - INFO - Epoch 42/100 completed in 118.10s - Train Loss: 6.0612, Train Acc: 0.179, Val Loss: 6.1377, Val Acc: 0.175
2025-09-27 21:33:57,234 - training.trainer - INFO - New best model saved with validation loss: 6.1377
2025-09-27 21:33:57,234 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_42.pt
2025-09-27 21:34:47,493 - training.trainer - INFO - Epoch 42, Step 9003: Loss=6.1329, Acc=0.164, 
2025-09-27 21:35:37,573 - training.trainer - INFO - Epoch 42, Step 9103: Loss=6.0990, Acc=0.197, 
2025-09-27 21:35:56,736 - training.trainer - INFO - Epoch 43/100 completed in 119.50s - Train Loss: 6.0532, Train Acc: 0.180, Val Loss: 6.1322, Val Acc: 0.174
2025-09-27 21:35:57,376 - training.trainer - INFO - New best model saved with validation loss: 6.1322
2025-09-27 21:35:57,377 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_43.pt
2025-09-27 21:36:47,891 - training.trainer - INFO - Epoch 43, Step 9215: Loss=6.1477, Acc=0.160, 
2025-09-27 21:37:36,005 - training.trainer - INFO - Epoch 43, Step 9315: Loss=6.1661, Acc=0.179, 
2025-09-27 21:37:54,179 - training.trainer - INFO - Epoch 44/100 completed in 116.80s - Train Loss: 6.0440, Train Acc: 0.180, Val Loss: 6.1285, Val Acc: 0.174
2025-09-27 21:37:54,881 - training.trainer - INFO - New best model saved with validation loss: 6.1285
2025-09-27 21:37:54,882 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_44.pt
2025-09-27 21:38:48,618 - training.trainer - INFO - Epoch 44, Step 9427: Loss=5.9974, Acc=0.185, 
2025-09-27 21:39:36,967 - training.trainer - INFO - Epoch 44, Step 9527: Loss=6.1209, Acc=0.197, 
2025-09-27 21:39:55,376 - training.trainer - INFO - Epoch 45/100 completed in 120.49s - Train Loss: 6.0348, Train Acc: 0.182, Val Loss: 6.1211, Val Acc: 0.175
2025-09-27 21:39:55,733 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-27 21:39:56,491 - training.trainer - INFO - New best model saved with validation loss: 6.1211
2025-09-27 21:39:56,491 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-27 21:40:50,149 - training.trainer - INFO - Epoch 45, Step 9639: Loss=5.8512, Acc=0.184, 
2025-09-27 21:41:37,811 - training.trainer - INFO - Epoch 45, Step 9739: Loss=6.0636, Acc=0.167, 
2025-09-27 21:41:56,840 - training.trainer - INFO - Epoch 46/100 completed in 120.35s - Train Loss: 6.0280, Train Acc: 0.181, Val Loss: 6.1065, Val Acc: 0.177
2025-09-27 21:41:57,564 - training.trainer - INFO - New best model saved with validation loss: 6.1065
2025-09-27 21:41:57,564 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_46.pt
2025-09-27 21:42:48,648 - training.trainer - INFO - Epoch 46, Step 9851: Loss=5.9458, Acc=0.175, 
2025-09-27 21:43:35,825 - training.trainer - INFO - Epoch 46, Step 9951: Loss=6.0556, Acc=0.203, 
2025-09-27 21:43:52,380 - training.trainer - INFO - Epoch 47/100 completed in 114.82s - Train Loss: 6.0212, Train Acc: 0.182, Val Loss: 6.1082, Val Acc: 0.177
2025-09-27 21:44:43,001 - training.trainer - INFO - Epoch 47, Step 10063: Loss=6.1970, Acc=0.163, 
2025-09-27 21:45:31,816 - training.trainer - INFO - Epoch 47, Step 10163: Loss=5.7923, Acc=0.199, 
2025-09-27 21:45:51,633 - training.trainer - INFO - Epoch 48/100 completed in 119.25s - Train Loss: 6.0153, Train Acc: 0.184, Val Loss: 6.1049, Val Acc: 0.176
2025-09-27 21:45:52,247 - training.trainer - INFO - New best model saved with validation loss: 6.1049
2025-09-27 21:45:52,247 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_48.pt
2025-09-27 21:46:40,635 - training.trainer - INFO - Epoch 48, Step 10275: Loss=5.9109, Acc=0.203, 
2025-09-27 21:47:32,222 - training.trainer - INFO - Epoch 48, Step 10375: Loss=5.9992, Acc=0.179, 
2025-09-27 21:47:53,533 - training.trainer - INFO - Epoch 49/100 completed in 121.28s - Train Loss: 6.0068, Train Acc: 0.183, Val Loss: 6.0999, Val Acc: 0.177
2025-09-27 21:47:54,259 - training.trainer - INFO - New best model saved with validation loss: 6.0999
2025-09-27 21:47:54,259 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_49.pt
2025-09-27 21:48:45,883 - training.trainer - INFO - Epoch 49, Step 10487: Loss=5.9683, Acc=0.186, 
2025-09-27 21:49:37,793 - training.trainer - INFO - Epoch 49, Step 10587: Loss=5.9701, Acc=0.167, 
2025-09-27 21:49:58,554 - training.trainer - INFO - Epoch 50/100 completed in 124.29s - Train Loss: 5.9992, Train Acc: 0.183, Val Loss: 6.0899, Val Acc: 0.179
2025-09-27 21:49:58,864 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-27 21:49:59,465 - training.trainer - INFO - New best model saved with validation loss: 6.0899
2025-09-27 21:49:59,465 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-09-27 21:50:54,343 - training.trainer - INFO - Epoch 50, Step 10699: Loss=5.9843, Acc=0.181, 
2025-09-27 21:51:44,340 - training.trainer - INFO - Epoch 50, Step 10799: Loss=6.2611, Acc=0.147, 
2025-09-27 21:52:03,456 - training.trainer - INFO - Epoch 51/100 completed in 123.99s - Train Loss: 5.9925, Train Acc: 0.184, Val Loss: 6.0864, Val Acc: 0.180
2025-09-27 21:52:04,268 - training.trainer - INFO - New best model saved with validation loss: 6.0864
2025-09-27 21:52:04,268 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_51.pt
2025-09-27 21:52:55,230 - training.trainer - INFO - Epoch 51, Step 10911: Loss=6.0899, Acc=0.190, 
2025-09-27 21:53:45,339 - training.trainer - INFO - Epoch 51, Step 11011: Loss=5.8964, Acc=0.203, 
2025-09-27 21:54:04,602 - training.trainer - INFO - Epoch 52/100 completed in 120.33s - Train Loss: 5.9863, Train Acc: 0.185, Val Loss: 6.0758, Val Acc: 0.181
2025-09-27 21:54:05,230 - training.trainer - INFO - New best model saved with validation loss: 6.0758
2025-09-27 21:54:05,230 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_52.pt
2025-09-27 21:54:55,904 - training.trainer - INFO - Epoch 52, Step 11123: Loss=5.9548, Acc=0.196, 
2025-09-27 21:55:43,607 - training.trainer - INFO - Epoch 52, Step 11223: Loss=6.1439, Acc=0.180, 
2025-09-27 21:56:02,333 - training.trainer - INFO - Epoch 53/100 completed in 117.10s - Train Loss: 5.9811, Train Acc: 0.184, Val Loss: 6.0767, Val Acc: 0.180
2025-09-27 21:56:53,163 - training.trainer - INFO - Epoch 53, Step 11335: Loss=5.8755, Acc=0.204, 
2025-09-27 21:57:46,078 - training.trainer - INFO - Epoch 53, Step 11435: Loss=5.8787, Acc=0.182, 
2025-09-27 21:58:05,773 - training.trainer - INFO - Epoch 54/100 completed in 123.44s - Train Loss: 5.9745, Train Acc: 0.186, Val Loss: 6.0771, Val Acc: 0.180
2025-09-27 21:58:55,552 - training.trainer - INFO - Epoch 54, Step 11547: Loss=5.8640, Acc=0.201, 
2025-09-27 21:59:43,780 - training.trainer - INFO - Epoch 54, Step 11647: Loss=6.1342, Acc=0.163, 
2025-09-27 22:00:02,891 - training.trainer - INFO - Epoch 55/100 completed in 117.12s - Train Loss: 5.9717, Train Acc: 0.186, Val Loss: 6.0655, Val Acc: 0.183
2025-09-27 22:00:03,271 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_55.pt
2025-09-27 22:00:04,063 - training.trainer - INFO - New best model saved with validation loss: 6.0655
2025-09-27 22:00:04,063 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_55.pt
2025-09-27 22:00:57,111 - training.trainer - INFO - Epoch 55, Step 11759: Loss=6.0050, Acc=0.166, 
2025-09-27 22:01:50,882 - training.trainer - INFO - Epoch 55, Step 11859: Loss=5.9523, Acc=0.205, 
2025-09-27 22:02:11,535 - training.trainer - INFO - Epoch 56/100 completed in 127.47s - Train Loss: 5.9643, Train Acc: 0.187, Val Loss: 6.0621, Val Acc: 0.183
2025-09-27 22:02:12,158 - training.trainer - INFO - New best model saved with validation loss: 6.0621
2025-09-27 22:02:12,159 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_56.pt
2025-09-27 22:03:08,084 - training.trainer - INFO - Epoch 56, Step 11971: Loss=5.9795, Acc=0.178, 
2025-09-27 22:03:55,446 - training.trainer - INFO - Epoch 56, Step 12071: Loss=6.0396, Acc=0.178, 
2025-09-27 22:04:15,891 - training.trainer - INFO - Epoch 57/100 completed in 123.73s - Train Loss: 5.9582, Train Acc: 0.187, Val Loss: 6.0526, Val Acc: 0.182
2025-09-27 22:04:16,559 - training.trainer - INFO - New best model saved with validation loss: 6.0526
2025-09-27 22:04:16,559 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_57.pt
2025-09-27 22:05:15,651 - training.trainer - INFO - Epoch 57, Step 12183: Loss=6.0487, Acc=0.176, 
2025-09-27 22:06:10,753 - training.trainer - INFO - Epoch 57, Step 12283: Loss=5.8669, Acc=0.202, 
2025-09-27 22:06:30,917 - training.trainer - INFO - Epoch 58/100 completed in 134.36s - Train Loss: 5.9544, Train Acc: 0.188, Val Loss: 6.0533, Val Acc: 0.183
2025-09-27 22:07:30,234 - training.trainer - INFO - Epoch 58, Step 12395: Loss=5.9370, Acc=0.191, 
2025-09-27 22:08:29,040 - training.trainer - INFO - Epoch 58, Step 12495: Loss=5.9067, Acc=0.192, 
2025-09-27 22:08:51,157 - training.trainer - INFO - Epoch 59/100 completed in 140.24s - Train Loss: 5.9507, Train Acc: 0.188, Val Loss: 6.0474, Val Acc: 0.185
2025-09-27 22:08:51,764 - training.trainer - INFO - New best model saved with validation loss: 6.0474
2025-09-27 22:08:51,764 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_59.pt
2025-09-27 22:09:50,345 - training.trainer - INFO - Epoch 59, Step 12607: Loss=5.9015, Acc=0.207, 
2025-09-27 22:10:44,879 - training.trainer - INFO - Epoch 59, Step 12707: Loss=6.1929, Acc=0.163, 
2025-09-27 22:11:06,170 - training.trainer - INFO - Epoch 60/100 completed in 134.41s - Train Loss: 5.9458, Train Acc: 0.189, Val Loss: 6.0445, Val Acc: 0.185
2025-09-27 22:11:06,568 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_60.pt
2025-09-27 22:11:07,308 - training.trainer - INFO - New best model saved with validation loss: 6.0445
2025-09-27 22:11:07,308 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_60.pt
2025-09-27 22:12:02,411 - training.trainer - INFO - Epoch 60, Step 12819: Loss=5.9107, Acc=0.181, 
2025-09-27 22:12:58,264 - training.trainer - INFO - Epoch 60, Step 12919: Loss=5.9051, Acc=0.183, 
2025-09-27 22:13:20,955 - training.trainer - INFO - Epoch 61/100 completed in 133.65s - Train Loss: 5.9426, Train Acc: 0.189, Val Loss: 6.0416, Val Acc: 0.185
2025-09-27 22:13:21,734 - training.trainer - INFO - New best model saved with validation loss: 6.0416
2025-09-27 22:13:21,735 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_61.pt
2025-09-27 22:14:19,397 - training.trainer - INFO - Epoch 61, Step 13031: Loss=6.0054, Acc=0.173, 
2025-09-27 22:15:16,309 - training.trainer - INFO - Epoch 61, Step 13131: Loss=6.0310, Acc=0.175, 
2025-09-27 22:15:37,413 - training.trainer - INFO - Epoch 62/100 completed in 135.68s - Train Loss: 5.9361, Train Acc: 0.190, Val Loss: 6.0384, Val Acc: 0.185
2025-09-27 22:15:38,007 - training.trainer - INFO - New best model saved with validation loss: 6.0384
2025-09-27 22:15:38,008 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_62.pt
2025-09-27 22:16:34,102 - training.trainer - INFO - Epoch 62, Step 13243: Loss=6.0030, Acc=0.183, 
2025-09-27 22:17:31,308 - training.trainer - INFO - Epoch 62, Step 13343: Loss=6.0148, Acc=0.178, 
2025-09-27 22:17:50,918 - training.trainer - INFO - Epoch 63/100 completed in 132.91s - Train Loss: 5.9330, Train Acc: 0.190, Val Loss: 6.0349, Val Acc: 0.186
2025-09-27 22:17:51,697 - training.trainer - INFO - New best model saved with validation loss: 6.0349
2025-09-27 22:17:51,698 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_63.pt
2025-09-27 22:18:50,579 - training.trainer - INFO - Epoch 63, Step 13455: Loss=5.9462, Acc=0.187, 
2025-09-27 22:19:49,783 - training.trainer - INFO - Epoch 63, Step 13555: Loss=5.9943, Acc=0.210, 
2025-09-27 22:20:11,164 - training.trainer - INFO - Epoch 64/100 completed in 139.47s - Train Loss: 5.9299, Train Acc: 0.189, Val Loss: 6.0314, Val Acc: 0.186
2025-09-27 22:20:12,006 - training.trainer - INFO - New best model saved with validation loss: 6.0314
2025-09-27 22:20:12,006 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_64.pt
2025-09-27 22:21:13,525 - training.trainer - INFO - Epoch 64, Step 13667: Loss=5.8899, Acc=0.204, 
2025-09-27 22:22:10,137 - training.trainer - INFO - Epoch 64, Step 13767: Loss=5.9435, Acc=0.199, 
2025-09-27 22:22:33,749 - training.trainer - INFO - Epoch 65/100 completed in 141.74s - Train Loss: 5.9245, Train Acc: 0.191, Val Loss: 6.0318, Val Acc: 0.186
2025-09-27 22:22:34,128 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_65.pt
2025-09-27 22:23:30,363 - training.trainer - INFO - Epoch 65, Step 13879: Loss=5.8035, Acc=0.198, 
2025-09-27 22:24:25,899 - training.trainer - INFO - Epoch 65, Step 13979: Loss=6.0190, Acc=0.190, 
2025-09-27 22:24:49,446 - training.trainer - INFO - Epoch 66/100 completed in 135.32s - Train Loss: 5.9244, Train Acc: 0.192, Val Loss: 6.0298, Val Acc: 0.187
2025-09-27 22:24:50,171 - training.trainer - INFO - New best model saved with validation loss: 6.0298
2025-09-27 22:24:50,171 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_66.pt
2025-09-27 22:25:50,692 - training.trainer - INFO - Epoch 66, Step 14091: Loss=6.0032, Acc=0.177, 
2025-09-27 22:26:47,552 - training.trainer - INFO - Epoch 66, Step 14191: Loss=5.7671, Acc=0.208, 
2025-09-27 22:27:07,247 - training.trainer - INFO - Epoch 67/100 completed in 137.07s - Train Loss: 5.9220, Train Acc: 0.191, Val Loss: 6.0222, Val Acc: 0.187
2025-09-27 22:27:07,863 - training.trainer - INFO - New best model saved with validation loss: 6.0222
2025-09-27 22:27:07,864 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_67.pt
2025-09-27 22:28:06,084 - training.trainer - INFO - Epoch 67, Step 14303: Loss=6.0287, Acc=0.182, 
2025-09-27 22:29:07,666 - training.trainer - INFO - Epoch 67, Step 14403: Loss=5.8066, Acc=0.198, 
2025-09-27 22:29:31,198 - training.trainer - INFO - Epoch 68/100 completed in 143.33s - Train Loss: 5.9180, Train Acc: 0.191, Val Loss: 6.0249, Val Acc: 0.187
2025-09-27 22:30:29,090 - training.trainer - INFO - Epoch 68, Step 14515: Loss=5.9181, Acc=0.182, 
2025-09-27 22:31:26,917 - training.trainer - INFO - Epoch 68, Step 14615: Loss=5.8288, Acc=0.191, 
2025-09-27 22:31:48,835 - training.trainer - INFO - Epoch 69/100 completed in 137.64s - Train Loss: 5.9147, Train Acc: 0.192, Val Loss: 6.0199, Val Acc: 0.187
2025-09-27 22:31:49,437 - training.trainer - INFO - New best model saved with validation loss: 6.0199
2025-09-27 22:31:49,437 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_69.pt
2025-09-27 22:32:44,117 - training.trainer - INFO - Epoch 69, Step 14727: Loss=5.8050, Acc=0.206, 
2025-09-27 22:33:40,544 - training.trainer - INFO - Epoch 69, Step 14827: Loss=5.9246, Acc=0.187, 
2025-09-27 22:34:00,814 - training.trainer - INFO - Epoch 70/100 completed in 131.38s - Train Loss: 5.9119, Train Acc: 0.192, Val Loss: 6.0189, Val Acc: 0.187
2025-09-27 22:34:01,209 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_70.pt
2025-09-27 22:34:01,957 - training.trainer - INFO - New best model saved with validation loss: 6.0189
2025-09-27 22:34:01,957 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_70.pt
2025-09-27 22:34:59,424 - training.trainer - INFO - Epoch 70, Step 14939: Loss=5.8153, Acc=0.198, 
2025-09-27 22:35:53,244 - training.trainer - INFO - Epoch 70, Step 15039: Loss=5.9250, Acc=0.183, 
2025-09-27 22:36:12,920 - training.trainer - INFO - Epoch 71/100 completed in 130.96s - Train Loss: 5.9099, Train Acc: 0.192, Val Loss: 6.0205, Val Acc: 0.187
2025-09-27 22:37:10,428 - training.trainer - INFO - Epoch 71, Step 15151: Loss=6.0925, Acc=0.184, 
2025-09-27 22:38:02,768 - training.trainer - INFO - Epoch 71, Step 15251: Loss=6.0782, Acc=0.199, 
2025-09-27 22:38:23,923 - training.trainer - INFO - Epoch 72/100 completed in 131.00s - Train Loss: 5.9073, Train Acc: 0.192, Val Loss: 6.0144, Val Acc: 0.189
2025-09-27 22:38:24,672 - training.trainer - INFO - New best model saved with validation loss: 6.0144
2025-09-27 22:38:24,672 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_72.pt
2025-09-27 22:39:21,544 - training.trainer - INFO - Epoch 72, Step 15363: Loss=5.9115, Acc=0.194, 
2025-09-27 22:40:18,913 - training.trainer - INFO - Epoch 72, Step 15463: Loss=6.0168, Acc=0.189, 
2025-09-27 22:40:43,964 - training.trainer - INFO - Epoch 73/100 completed in 139.29s - Train Loss: 5.9062, Train Acc: 0.193, Val Loss: 6.0151, Val Acc: 0.188
2025-09-27 22:41:38,124 - training.trainer - INFO - Epoch 73, Step 15575: Loss=5.6188, Acc=0.212, 
2025-09-27 22:42:31,172 - training.trainer - INFO - Epoch 73, Step 15675: Loss=5.9183, Acc=0.199, 
2025-09-27 22:42:50,795 - training.trainer - INFO - Epoch 74/100 completed in 126.83s - Train Loss: 5.9013, Train Acc: 0.193, Val Loss: 6.0135, Val Acc: 0.188
2025-09-27 22:42:51,633 - training.trainer - INFO - New best model saved with validation loss: 6.0135
2025-09-27 22:42:51,634 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_74.pt
2025-09-27 22:43:53,311 - training.trainer - INFO - Epoch 74, Step 15787: Loss=5.9008, Acc=0.175, 
2025-09-27 22:44:48,351 - training.trainer - INFO - Epoch 74, Step 15887: Loss=5.9801, Acc=0.180, 
2025-09-27 22:45:06,892 - training.trainer - INFO - Epoch 75/100 completed in 135.26s - Train Loss: 5.9015, Train Acc: 0.193, Val Loss: 6.0107, Val Acc: 0.188
2025-09-27 22:45:07,253 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_75.pt
2025-09-27 22:45:07,930 - training.trainer - INFO - New best model saved with validation loss: 6.0107
2025-09-27 22:45:07,930 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_75.pt
2025-09-27 22:46:02,384 - training.trainer - INFO - Epoch 75, Step 15999: Loss=5.7335, Acc=0.203, 
2025-09-27 22:46:59,090 - training.trainer - INFO - Epoch 75, Step 16099: Loss=5.9037, Acc=0.199, 
2025-09-27 22:47:17,083 - training.trainer - INFO - Epoch 76/100 completed in 129.15s - Train Loss: 5.9000, Train Acc: 0.193, Val Loss: 6.0097, Val Acc: 0.189
2025-09-27 22:47:17,800 - training.trainer - INFO - New best model saved with validation loss: 6.0097
2025-09-27 22:47:17,801 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_76.pt
2025-09-27 22:48:18,094 - training.trainer - INFO - Epoch 76, Step 16211: Loss=5.8344, Acc=0.216, 
2025-09-27 22:49:09,489 - training.trainer - INFO - Epoch 76, Step 16311: Loss=5.7722, Acc=0.229, 
2025-09-27 22:49:29,957 - training.trainer - INFO - Epoch 77/100 completed in 132.16s - Train Loss: 5.8967, Train Acc: 0.194, Val Loss: 6.0098, Val Acc: 0.189
2025-09-27 22:50:23,238 - training.trainer - INFO - Epoch 77, Step 16423: Loss=5.7769, Acc=0.211, 
2025-09-27 22:51:13,286 - training.trainer - INFO - Epoch 77, Step 16523: Loss=5.9441, Acc=0.180, 
2025-09-27 22:51:33,685 - training.trainer - INFO - Epoch 78/100 completed in 123.73s - Train Loss: 5.8935, Train Acc: 0.194, Val Loss: 6.0086, Val Acc: 0.189
2025-09-27 22:51:34,483 - training.trainer - INFO - New best model saved with validation loss: 6.0086
2025-09-27 22:51:34,483 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_78.pt
2025-09-27 22:52:31,246 - training.trainer - INFO - Epoch 78, Step 16635: Loss=5.9493, Acc=0.192, 
2025-09-27 22:53:22,955 - training.trainer - INFO - Epoch 78, Step 16735: Loss=5.8882, Acc=0.186, 
2025-09-27 22:53:44,256 - training.trainer - INFO - Epoch 79/100 completed in 129.77s - Train Loss: 5.8939, Train Acc: 0.194, Val Loss: 6.0089, Val Acc: 0.189
2025-09-27 22:54:39,071 - training.trainer - INFO - Epoch 79, Step 16847: Loss=5.9269, Acc=0.200, 
2025-09-27 22:55:34,507 - training.trainer - INFO - Epoch 79, Step 16947: Loss=5.9783, Acc=0.184, 
2025-09-27 22:55:55,178 - training.trainer - INFO - Epoch 80/100 completed in 130.92s - Train Loss: 5.8926, Train Acc: 0.193, Val Loss: 6.0069, Val Acc: 0.189
2025-09-27 22:55:55,558 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_80.pt
2025-09-27 22:55:56,445 - training.trainer - INFO - New best model saved with validation loss: 6.0069
2025-09-27 22:55:56,445 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_80.pt
2025-09-27 22:56:55,025 - training.trainer - INFO - Epoch 80, Step 17059: Loss=5.7886, Acc=0.193, 
2025-09-27 22:57:47,878 - training.trainer - INFO - Epoch 80, Step 17159: Loss=6.0391, Acc=0.203, 
2025-09-27 22:58:07,923 - training.trainer - INFO - Epoch 81/100 completed in 131.48s - Train Loss: 5.8923, Train Acc: 0.194, Val Loss: 6.0047, Val Acc: 0.189
2025-09-27 22:58:08,748 - training.trainer - INFO - New best model saved with validation loss: 6.0047
2025-09-27 22:58:08,748 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_81.pt
2025-09-27 22:59:03,892 - training.trainer - INFO - Epoch 81, Step 17271: Loss=5.9911, Acc=0.185, 
2025-09-27 23:00:01,296 - training.trainer - INFO - Epoch 81, Step 17371: Loss=6.1219, Acc=0.189, 
2025-09-27 23:00:20,664 - training.trainer - INFO - Epoch 82/100 completed in 131.92s - Train Loss: 5.8904, Train Acc: 0.194, Val Loss: 6.0044, Val Acc: 0.189
2025-09-27 23:00:21,513 - training.trainer - INFO - New best model saved with validation loss: 6.0044
2025-09-27 23:00:21,513 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_82.pt
2025-09-27 23:01:17,389 - training.trainer - INFO - Epoch 82, Step 17483: Loss=5.8266, Acc=0.193, 
2025-09-27 23:02:19,279 - training.trainer - INFO - Epoch 82, Step 17583: Loss=5.9155, Acc=0.194, 
2025-09-27 23:02:38,711 - training.trainer - INFO - Epoch 83/100 completed in 137.20s - Train Loss: 5.8903, Train Acc: 0.193, Val Loss: 6.0043, Val Acc: 0.188
2025-09-27 23:02:39,307 - training.trainer - INFO - New best model saved with validation loss: 6.0043
2025-09-27 23:02:39,307 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_83.pt
2025-09-27 23:03:42,591 - training.trainer - INFO - Epoch 83, Step 17695: Loss=6.1680, Acc=0.159, 
2025-09-27 23:04:36,357 - training.trainer - INFO - Epoch 83, Step 17795: Loss=5.7310, Acc=0.216, 
2025-09-27 23:04:57,893 - training.trainer - INFO - Epoch 84/100 completed in 138.59s - Train Loss: 5.8886, Train Acc: 0.194, Val Loss: 6.0050, Val Acc: 0.189
2025-09-27 23:05:55,246 - training.trainer - INFO - Epoch 84, Step 17907: Loss=5.9236, Acc=0.203, 
2025-09-27 23:06:54,344 - training.trainer - INFO - Epoch 84, Step 18007: Loss=6.0268, Acc=0.194, 
2025-09-27 23:07:14,274 - training.trainer - INFO - Epoch 85/100 completed in 136.38s - Train Loss: 5.8880, Train Acc: 0.194, Val Loss: 6.0021, Val Acc: 0.189
2025-09-27 23:07:14,651 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_85.pt
2025-09-27 23:07:15,606 - training.trainer - INFO - New best model saved with validation loss: 6.0021
2025-09-27 23:07:15,607 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_85.pt
2025-09-27 23:08:11,868 - training.trainer - INFO - Epoch 85, Step 18119: Loss=5.9582, Acc=0.200, 
2025-09-27 23:09:08,931 - training.trainer - INFO - Epoch 85, Step 18219: Loss=5.9661, Acc=0.188, 
2025-09-27 23:09:31,116 - training.trainer - INFO - Epoch 86/100 completed in 135.51s - Train Loss: 5.8882, Train Acc: 0.195, Val Loss: 6.0047, Val Acc: 0.188
2025-09-27 23:10:30,905 - training.trainer - INFO - Epoch 86, Step 18331: Loss=5.9213, Acc=0.182, 
2025-09-27 23:11:23,445 - training.trainer - INFO - Epoch 86, Step 18431: Loss=6.0102, Acc=0.198, 
2025-09-27 23:11:46,411 - training.trainer - INFO - Epoch 87/100 completed in 135.29s - Train Loss: 5.8882, Train Acc: 0.195, Val Loss: 6.0025, Val Acc: 0.189
2025-09-27 23:12:39,160 - training.trainer - INFO - Epoch 87, Step 18543: Loss=5.7948, Acc=0.210, 
2025-09-27 23:13:34,972 - training.trainer - INFO - Epoch 87, Step 18643: Loss=6.0549, Acc=0.184, 
2025-09-27 23:13:53,800 - training.trainer - INFO - Epoch 88/100 completed in 127.39s - Train Loss: 5.8863, Train Acc: 0.195, Val Loss: 6.0028, Val Acc: 0.189
2025-09-27 23:14:50,619 - training.trainer - INFO - Epoch 88, Step 18755: Loss=5.8179, Acc=0.187, 
2025-09-27 23:15:43,618 - training.trainer - INFO - Epoch 88, Step 18855: Loss=5.9115, Acc=0.188, 
2025-09-27 23:16:03,140 - training.trainer - INFO - Epoch 89/100 completed in 129.34s - Train Loss: 5.8845, Train Acc: 0.195, Val Loss: 6.0000, Val Acc: 0.190
2025-09-27 23:16:03,793 - training.trainer - INFO - New best model saved with validation loss: 6.0000
2025-09-27 23:16:03,793 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_89.pt
2025-09-27 23:16:59,399 - training.trainer - INFO - Epoch 89, Step 18967: Loss=5.8648, Acc=0.201, 
2025-09-27 23:17:57,211 - training.trainer - INFO - Epoch 89, Step 19067: Loss=5.8435, Acc=0.193, 
2025-09-27 23:18:19,685 - training.trainer - INFO - Epoch 90/100 completed in 135.89s - Train Loss: 5.8846, Train Acc: 0.194, Val Loss: 5.9998, Val Acc: 0.189
2025-09-27 23:18:20,138 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_90.pt
2025-09-27 23:18:20,989 - training.trainer - INFO - New best model saved with validation loss: 5.9998
2025-09-27 23:18:20,990 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_90.pt
2025-09-27 23:19:20,136 - training.trainer - INFO - Epoch 90, Step 19179: Loss=5.8522, Acc=0.178, 
2025-09-27 23:20:11,802 - training.trainer - INFO - Epoch 90, Step 19279: Loss=6.0103, Acc=0.176, 
2025-09-27 23:20:34,139 - training.trainer - INFO - Epoch 91/100 completed in 133.15s - Train Loss: 5.8835, Train Acc: 0.194, Val Loss: 6.0000, Val Acc: 0.190
2025-09-27 23:21:28,478 - training.trainer - INFO - Epoch 91, Step 19391: Loss=5.9467, Acc=0.195, 
2025-09-27 23:22:26,091 - training.trainer - INFO - Epoch 91, Step 19491: Loss=5.9837, Acc=0.192, 
2025-09-27 23:22:46,425 - training.trainer - INFO - Epoch 92/100 completed in 132.29s - Train Loss: 5.8864, Train Acc: 0.194, Val Loss: 6.0000, Val Acc: 0.190
2025-09-27 23:23:42,698 - training.trainer - INFO - Epoch 92, Step 19603: Loss=5.9093, Acc=0.207, 
2025-09-27 23:24:37,430 - training.trainer - INFO - Epoch 92, Step 19703: Loss=5.6553, Acc=0.218, 
2025-09-27 23:24:59,083 - training.trainer - INFO - Epoch 93/100 completed in 132.66s - Train Loss: 5.8852, Train Acc: 0.195, Val Loss: 6.0000, Val Acc: 0.190
2025-09-27 23:25:57,891 - training.trainer - INFO - Epoch 93, Step 19815: Loss=5.8531, Acc=0.194, 
2025-09-27 23:26:49,222 - training.trainer - INFO - Epoch 93, Step 19915: Loss=5.7652, Acc=0.213, 
2025-09-27 23:27:10,060 - training.trainer - INFO - Epoch 94/100 completed in 130.98s - Train Loss: 5.8832, Train Acc: 0.194, Val Loss: 5.9993, Val Acc: 0.189
2025-09-27 23:27:10,761 - training.trainer - INFO - New best model saved with validation loss: 5.9993
2025-09-27 23:27:10,761 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_94.pt
2025-09-27 23:28:05,551 - training.trainer - INFO - Epoch 94, Step 20027: Loss=5.9410, Acc=0.190, 
2025-09-27 23:28:59,634 - training.trainer - INFO - Epoch 94, Step 20127: Loss=5.5828, Acc=0.198, 
2025-09-27 23:29:20,787 - training.trainer - INFO - Epoch 95/100 completed in 130.02s - Train Loss: 5.8835, Train Acc: 0.195, Val Loss: 6.0003, Val Acc: 0.189
2025-09-27 23:29:21,147 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_95.pt
2025-09-27 23:30:16,342 - training.trainer - INFO - Epoch 95, Step 20239: Loss=5.9174, Acc=0.201, 
2025-09-27 23:31:10,995 - training.trainer - INFO - Epoch 95, Step 20339: Loss=5.9096, Acc=0.205, 
2025-09-27 23:31:29,935 - training.trainer - INFO - Epoch 96/100 completed in 128.79s - Train Loss: 5.8840, Train Acc: 0.195, Val Loss: 5.9995, Val Acc: 0.190
2025-09-27 23:32:25,064 - training.trainer - INFO - Epoch 96, Step 20451: Loss=6.1293, Acc=0.180, 
2025-09-27 23:33:25,078 - training.trainer - INFO - Epoch 96, Step 20551: Loss=5.7991, Acc=0.212, 
2025-09-27 23:33:47,384 - training.trainer - INFO - Epoch 97/100 completed in 137.45s - Train Loss: 5.8810, Train Acc: 0.195, Val Loss: 5.9999, Val Acc: 0.189
2025-09-27 23:34:43,996 - training.trainer - INFO - Epoch 97, Step 20663: Loss=5.7994, Acc=0.197, 
2025-09-27 23:35:42,076 - training.trainer - INFO - Epoch 97, Step 20763: Loss=5.9282, Acc=0.188, 
2025-09-27 23:36:03,613 - training.trainer - INFO - Epoch 98/100 completed in 136.23s - Train Loss: 5.8813, Train Acc: 0.195, Val Loss: 5.9998, Val Acc: 0.190
2025-09-27 23:36:59,340 - training.trainer - INFO - Epoch 98, Step 20875: Loss=5.7582, Acc=0.201, 
2025-09-27 23:37:57,669 - training.trainer - INFO - Epoch 98, Step 20975: Loss=5.7809, Acc=0.210, 
2025-09-27 23:38:22,666 - training.trainer - INFO - Epoch 99/100 completed in 139.05s - Train Loss: 5.8834, Train Acc: 0.195, Val Loss: 5.9998, Val Acc: 0.190
2025-09-27 23:39:20,131 - training.trainer - INFO - Epoch 99, Step 21087: Loss=5.7023, Acc=0.204, 
2025-09-27 23:40:14,737 - training.trainer - INFO - Epoch 99, Step 21187: Loss=5.9174, Acc=0.195, 
2025-09-27 23:40:37,195 - training.trainer - INFO - Epoch 100/100 completed in 134.53s - Train Loss: 5.8822, Train Acc: 0.195, Val Loss: 5.9998, Val Acc: 0.190
2025-09-27 23:40:37,535 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_100.pt
2025-09-27 23:40:37,537 - training.trainer - INFO - Training completed!
2025-09-27 23:40:37,538 - __main__ - INFO - Training completed successfully!
2025-09-27 23:40:37,652 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-27 23:40:37,980 - __main__ - INFO - Process completed!
2025-09-27 23:40:57,303 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-27 23:40:57,304 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-27 23:40:57,304 - __main__ - INFO - Starting model evaluation
2025-09-27 23:40:58,765 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-27 23:52:13,559 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-27 23:52:13,593 - __main__ - INFO - Process completed!
2025-09-27 23:52:20,846 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-27 23:52:20,846 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-27 23:52:20,846 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-09-27 23:52:21,440 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-27 23:52:40,820 - __main__ - INFO - Inference completed successfully!
2025-09-27 23:52:40,831 - __main__ - INFO - Process completed!
2025-09-28 14:19:55,085 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-28 14:19:55,086 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-28 14:19:55,086 - __main__ - INFO - Starting training pipeline
2025-09-28 14:19:55,190 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-09-28 14:19:55,215 - __main__ - INFO - GPU: NVIDIA A30
2025-09-28 14:19:55,215 - __main__ - INFO - GPU Memory: 23.5 GB
2025-09-28 14:19:55,215 - __main__ - INFO - Loading training data...
2025-09-28 14:20:02,909 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-28 14:20:02,910 - __main__ - INFO - Processing train split...
2025-09-28 14:20:03,004 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-28 14:20:03,005 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-28 14:20:43,057 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-28 14:24:16,167 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-28 14:24:16,167 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-28 14:24:16,167 - __main__ - INFO - Starting training pipeline
2025-09-28 14:24:16,268 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-09-28 14:24:16,293 - __main__ - INFO - GPU: NVIDIA A30
2025-09-28 14:24:16,293 - __main__ - INFO - GPU Memory: 23.5 GB
2025-09-28 14:24:16,294 - __main__ - INFO - Loading training data...
2025-09-28 14:24:23,695 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-28 14:24:23,696 - __main__ - INFO - Processing train split...
2025-09-28 14:24:23,779 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-28 14:24:23,780 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-28 14:25:03,531 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-28 14:25:42,587 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-28 14:26:22,175 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-28 14:27:00,732 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-28 14:27:39,106 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-28 14:28:16,505 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-28 14:28:45,463 - __main__ - INFO - Processing val split...
2025-09-28 14:28:45,696 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-28 14:28:45,697 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-28 14:29:17,038 - __main__ - INFO - Processing test split...
2025-09-28 14:29:17,234 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-28 14:29:17,234 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-28 14:29:49,130 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-28 14:29:49,130 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-28 14:29:49,146 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-09-28 14:29:49,146 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-28 14:29:49,146 - __main__ - INFO - Creating model architecture...
2025-09-28 14:29:49,464 - __main__ - INFO - Model created successfully
2025-09-28 14:29:49,464 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-28 14:29:49,465 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-28 14:29:49,465 - __main__ - INFO - Using device: cuda
2025-09-28 14:29:49,465 - __main__ - INFO - Creating trainer...
2025-09-28 14:29:49,465 - __main__ - INFO - Moving model to cuda...
2025-09-28 14:29:49,759 - __main__ - INFO - Model moved to cuda
2025-09-28 14:29:49,760 - __main__ - INFO - Model parameters are on: cuda:0
2025-09-28 14:29:51,028 - __main__ - INFO - Trainer created successfully
2025-09-28 14:29:51,028 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-09-28 14:29:51,028 - __main__ - INFO - Starting training...
2025-09-28 14:29:51,028 - __main__ - INFO - Training configuration:
2025-09-28 14:29:51,029 - __main__ - INFO -   - Epochs: 100
2025-09-28 14:29:51,029 - __main__ - INFO -   - Batch size: 2
2025-09-28 14:29:51,029 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-28 14:29:51,029 - __main__ - INFO -   - Training samples: 6765
2025-09-28 14:29:51,029 - __main__ - INFO -   - Validation samples: 845
2025-09-28 14:29:51,029 - training.trainer - INFO - Starting training for 100 epochs
2025-09-28 14:29:51,029 - training.trainer - INFO - Model parameters: 16,680,032
2025-09-28 14:29:51,030 - training.trainer - INFO - Training on device: cuda
2025-09-28 14:29:59,370 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.7514, Acc=0.059, 
2025-09-28 14:30:06,440 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.1070, Acc=0.095, 
2025-09-28 14:30:13,475 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.6835, Acc=0.032, 
2025-09-28 14:30:20,416 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.4436, Acc=0.087, 
2025-09-28 14:30:27,572 - training.trainer - INFO - Epoch 0, Step 499: Loss=7.7002, Acc=0.056, 
2025-09-28 14:30:34,735 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.1300, Acc=0.111, 
2025-09-28 14:30:41,703 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.8212, Acc=0.076, 
2025-09-28 14:30:48,425 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.9740, Acc=0.150, 
2025-09-28 14:30:54,906 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.6820, Acc=0.190, 
2025-09-28 14:31:01,435 - training.trainer - INFO - Epoch 0, Step 999: Loss=7.0732, Acc=0.118, 
2025-09-28 14:31:07,997 - training.trainer - INFO - Epoch 0, Step 1099: Loss=7.1940, Acc=0.128, 
2025-09-28 14:31:14,433 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.6318, Acc=0.143, 
2025-09-28 14:31:20,961 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.5863, Acc=0.125, 
2025-09-28 14:31:28,127 - training.trainer - INFO - Epoch 0, Step 1399: Loss=6.4117, Acc=0.121, 
2025-09-28 14:31:35,487 - training.trainer - INFO - Epoch 0, Step 1499: Loss=6.3110, Acc=0.118, 
2025-09-28 14:31:43,094 - training.trainer - INFO - Epoch 0, Step 1599: Loss=7.0996, Acc=0.164, 
2025-09-28 14:31:50,606 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.7845, Acc=0.127, 
2025-09-28 14:31:57,938 - training.trainer - INFO - Epoch 0, Step 1799: Loss=5.8664, Acc=0.320, 
2025-09-28 14:32:05,636 - training.trainer - INFO - Epoch 0, Step 1899: Loss=7.2143, Acc=0.106, 
2025-09-28 14:32:13,415 - training.trainer - INFO - Epoch 0, Step 1999: Loss=7.0503, Acc=0.115, 
2025-09-28 14:32:20,878 - training.trainer - INFO - Epoch 0, Step 2099: Loss=7.1202, Acc=0.141, 
2025-09-28 14:32:28,387 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.8221, Acc=0.094, 
2025-09-28 14:32:35,788 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.5004, Acc=0.194, 
2025-09-28 14:32:43,326 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.5905, Acc=0.143, 
2025-09-28 14:32:51,174 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.0954, Acc=0.125, 
2025-09-28 14:32:58,702 - training.trainer - INFO - Epoch 0, Step 2599: Loss=7.0961, Acc=0.074, 
2025-09-28 14:33:06,277 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.2796, Acc=0.250, 
2025-09-28 14:33:13,806 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.2666, Acc=0.167, 
2025-09-28 14:33:21,291 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.2245, Acc=0.132, 
2025-09-28 14:33:28,799 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.5159, Acc=0.088, 
2025-09-28 14:33:36,358 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.3554, Acc=0.185, 
2025-09-28 14:33:43,965 - training.trainer - INFO - Epoch 0, Step 3199: Loss=6.5487, Acc=0.154, 
2025-09-28 14:33:51,501 - training.trainer - INFO - Epoch 0, Step 3299: Loss=5.9296, Acc=0.217, 
2025-09-28 14:34:10,499 - training.trainer - INFO - Epoch 1/100 completed in 259.47s - Train Loss: 6.8200, Train Acc: 0.131, Val Loss: 6.3624, Val Acc: 0.165
2025-09-28 14:34:11,244 - training.trainer - INFO - New best model saved with validation loss: 6.3624
2025-09-28 14:34:11,245 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-28 14:34:19,654 - training.trainer - INFO - Epoch 1, Step 3482: Loss=5.8738, Acc=0.267, 
2025-09-28 14:34:27,358 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.2341, Acc=0.179, 
2025-09-28 14:34:35,734 - training.trainer - INFO - Epoch 1, Step 3682: Loss=5.8842, Acc=0.200, 
2025-09-28 14:34:43,171 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.3906, Acc=0.109, 
2025-09-28 14:34:50,565 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.9399, Acc=0.104, 
2025-09-28 14:34:58,175 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.5386, Acc=0.140, 
2025-09-28 14:35:05,620 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.3406, Acc=0.182, 
2025-09-28 14:35:13,036 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.6197, Acc=0.205, 
2025-09-28 14:35:20,612 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.5409, Acc=0.159, 
2025-09-28 14:35:28,281 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.7435, Acc=0.110, 
2025-09-28 14:35:35,663 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.3632, Acc=0.200, 
2025-09-28 14:35:43,155 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.4367, Acc=0.150, 
2025-09-28 14:35:50,477 - training.trainer - INFO - Epoch 1, Step 4682: Loss=6.6270, Acc=0.146, 
2025-09-28 14:35:57,810 - training.trainer - INFO - Epoch 1, Step 4782: Loss=6.6026, Acc=0.100, 
2025-09-28 14:36:05,152 - training.trainer - INFO - Epoch 1, Step 4882: Loss=7.1159, Acc=0.200, 
2025-09-28 14:36:12,569 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.6081, Acc=0.094, 
2025-09-28 14:36:19,860 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.6977, Acc=0.143, 
2025-09-28 14:36:27,171 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.3816, Acc=0.143, 
2025-09-28 14:36:34,462 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.0355, Acc=0.231, 
2025-09-28 14:36:41,885 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.6594, Acc=0.132, 
2025-09-28 14:36:49,214 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.5608, Acc=0.065, 
2025-09-28 14:36:56,517 - training.trainer - INFO - Epoch 1, Step 5582: Loss=5.7935, Acc=0.231, 
2025-09-28 14:37:03,841 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.9187, Acc=0.167, 
2025-09-28 14:37:11,137 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.2059, Acc=0.231, 
2025-09-28 14:37:18,476 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.3311, Acc=0.080, 
2025-09-28 14:37:26,110 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.4826, Acc=0.200, 
2025-09-28 14:37:33,760 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.5264, Acc=0.085, 
2025-09-28 14:37:41,328 - training.trainer - INFO - Epoch 1, Step 6182: Loss=5.5081, Acc=0.250, 
2025-09-28 14:37:48,812 - training.trainer - INFO - Epoch 1, Step 6282: Loss=5.6591, Acc=0.417, 
2025-09-28 14:37:56,399 - training.trainer - INFO - Epoch 1, Step 6382: Loss=6.4876, Acc=0.092, 
2025-09-28 14:38:03,756 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.5971, Acc=0.113, 
2025-09-28 14:38:11,259 - training.trainer - INFO - Epoch 1, Step 6582: Loss=5.8489, Acc=0.212, 
2025-09-28 14:38:18,790 - training.trainer - INFO - Epoch 1, Step 6682: Loss=5.9890, Acc=0.158, 
2025-09-28 14:38:37,803 - training.trainer - INFO - Epoch 2/100 completed in 266.56s - Train Loss: 6.3095, Train Acc: 0.168, Val Loss: 6.1936, Val Acc: 0.177
2025-09-28 14:38:38,509 - training.trainer - INFO - New best model saved with validation loss: 6.1936
2025-09-28 14:38:38,510 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-28 14:38:46,459 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.1929, Acc=0.111, 
2025-09-28 14:38:54,062 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.3321, Acc=0.146, 
2025-09-28 14:39:01,612 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.2708, Acc=0.258, 
2025-09-28 14:39:09,012 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.3674, Acc=0.111, 
2025-09-28 14:39:16,702 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.7094, Acc=0.125, 
2025-09-28 14:39:24,047 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.8413, Acc=0.127, 
2025-09-28 14:39:31,359 - training.trainer - INFO - Epoch 2, Step 7465: Loss=6.3158, Acc=0.138, 
2025-09-28 14:39:38,600 - training.trainer - INFO - Epoch 2, Step 7565: Loss=6.6139, Acc=0.114, 
2025-09-28 14:39:46,140 - training.trainer - INFO - Epoch 2, Step 7665: Loss=5.6655, Acc=0.185, 
2025-09-28 14:39:53,319 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.6613, Acc=0.134, 
2025-09-28 14:40:00,673 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.7006, Acc=0.184, 
2025-09-28 14:40:08,212 - training.trainer - INFO - Epoch 2, Step 7965: Loss=5.6814, Acc=0.278, 
2025-09-28 14:40:15,845 - training.trainer - INFO - Epoch 2, Step 8065: Loss=5.5698, Acc=0.154, 
2025-09-28 14:40:23,408 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.5076, Acc=0.171, 
2025-09-28 14:40:30,974 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.8912, Acc=0.214, 
2025-09-28 14:40:38,748 - training.trainer - INFO - Epoch 2, Step 8365: Loss=5.8005, Acc=0.174, 
2025-09-28 14:40:46,145 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.0850, Acc=0.189, 
2025-09-28 14:40:53,405 - training.trainer - INFO - Epoch 2, Step 8565: Loss=6.3353, Acc=0.161, 
2025-09-28 14:41:00,620 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.6137, Acc=0.145, 
2025-09-28 14:41:08,080 - training.trainer - INFO - Epoch 2, Step 8765: Loss=5.9777, Acc=0.357, 
2025-09-28 14:41:15,436 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.5512, Acc=0.111, 
2025-09-28 14:41:22,860 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.9678, Acc=0.117, 
2025-09-28 14:41:30,199 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.7029, Acc=0.193, 
2025-09-28 14:41:37,497 - training.trainer - INFO - Epoch 2, Step 9165: Loss=5.3080, Acc=0.233, 
2025-09-28 14:41:44,783 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.0949, Acc=0.188, 
2025-09-28 14:41:52,008 - training.trainer - INFO - Epoch 2, Step 9365: Loss=5.3652, Acc=0.212, 
2025-09-28 14:41:59,194 - training.trainer - INFO - Epoch 2, Step 9465: Loss=5.9214, Acc=0.136, 
2025-09-28 14:42:06,420 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.5204, Acc=0.111, 
2025-09-28 14:42:13,655 - training.trainer - INFO - Epoch 2, Step 9665: Loss=6.0046, Acc=0.294, 
2025-09-28 14:42:20,841 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.7600, Acc=0.098, 
2025-09-28 14:42:28,265 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.1400, Acc=0.209, 
2025-09-28 14:42:35,522 - training.trainer - INFO - Epoch 2, Step 9965: Loss=6.4808, Acc=0.176, 
2025-09-28 14:42:42,729 - training.trainer - INFO - Epoch 2, Step 10065: Loss=6.1586, Acc=0.280, 
2025-09-28 14:43:01,461 - training.trainer - INFO - Epoch 3/100 completed in 262.95s - Train Loss: 6.2003, Train Acc: 0.176, Val Loss: 6.1099, Val Acc: 0.178
2025-09-28 14:43:02,147 - training.trainer - INFO - New best model saved with validation loss: 6.1099
2025-09-28 14:43:02,147 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-28 14:43:09,745 - training.trainer - INFO - Epoch 3, Step 10248: Loss=5.9397, Acc=0.150, 
2025-09-28 14:43:17,101 - training.trainer - INFO - Epoch 3, Step 10348: Loss=5.5589, Acc=0.207, 
2025-09-28 14:43:24,564 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.3596, Acc=0.140, 
2025-09-28 14:43:31,777 - training.trainer - INFO - Epoch 3, Step 10548: Loss=5.8572, Acc=0.172, 
2025-09-28 14:43:39,090 - training.trainer - INFO - Epoch 3, Step 10648: Loss=5.9195, Acc=0.196, 
2025-09-28 14:43:46,650 - training.trainer - INFO - Epoch 3, Step 10748: Loss=5.9055, Acc=0.292, 
2025-09-28 14:43:54,303 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.4555, Acc=0.167, 
2025-09-28 14:44:01,705 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.0457, Acc=0.205, 
2025-09-28 14:44:09,124 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.4428, Acc=0.132, 
2025-09-28 14:44:16,579 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.4939, Acc=0.130, 
2025-09-28 14:44:24,125 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.4447, Acc=0.181, 
2025-09-28 14:44:31,319 - training.trainer - INFO - Epoch 3, Step 11348: Loss=6.7640, Acc=0.101, 
2025-09-28 14:44:38,466 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.8149, Acc=0.142, 
2025-09-28 14:44:45,709 - training.trainer - INFO - Epoch 3, Step 11548: Loss=5.3690, Acc=0.250, 
2025-09-28 14:44:52,969 - training.trainer - INFO - Epoch 3, Step 11648: Loss=5.8896, Acc=0.174, 
2025-09-28 14:45:00,301 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.5903, Acc=0.261, 
2025-09-28 14:45:07,478 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.8274, Acc=0.125, 
2025-09-28 14:45:14,728 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.5839, Acc=0.167, 
2025-09-28 14:45:22,176 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.3837, Acc=0.189, 
2025-09-28 14:45:29,727 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.1536, Acc=0.235, 
2025-09-28 14:45:37,224 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.3869, Acc=0.174, 
2025-09-28 14:45:44,578 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.2859, Acc=0.205, 
2025-09-28 14:45:51,975 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.4517, Acc=0.179, 
2025-09-28 14:45:59,363 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.0117, Acc=0.242, 
2025-09-28 14:46:06,635 - training.trainer - INFO - Epoch 3, Step 12648: Loss=6.0218, Acc=0.238, 
2025-09-28 14:46:13,835 - training.trainer - INFO - Epoch 3, Step 12748: Loss=5.8702, Acc=0.172, 
2025-09-28 14:46:21,138 - training.trainer - INFO - Epoch 3, Step 12848: Loss=5.8311, Acc=0.281, 
2025-09-28 14:46:28,380 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.4311, Acc=0.123, 
2025-09-28 14:46:35,827 - training.trainer - INFO - Epoch 3, Step 13048: Loss=4.4331, Acc=0.455, 
2025-09-28 14:46:43,365 - training.trainer - INFO - Epoch 3, Step 13148: Loss=7.0769, Acc=0.106, 
2025-09-28 14:46:50,932 - training.trainer - INFO - Epoch 3, Step 13248: Loss=5.6929, Acc=0.177, 
2025-09-28 14:46:58,389 - training.trainer - INFO - Epoch 3, Step 13348: Loss=5.9468, Acc=0.119, 
2025-09-28 14:47:05,690 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.8151, Acc=0.123, 
2025-09-28 14:47:24,457 - training.trainer - INFO - Epoch 4/100 completed in 262.31s - Train Loss: 6.1288, Train Acc: 0.185, Val Loss: 6.0636, Val Acc: 0.195
2025-09-28 14:47:25,278 - training.trainer - INFO - New best model saved with validation loss: 6.0636
2025-09-28 14:47:25,278 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-28 14:47:33,078 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.1251, Acc=0.235, 
2025-09-28 14:47:40,633 - training.trainer - INFO - Epoch 4, Step 13731: Loss=6.2716, Acc=0.173, 
2025-09-28 14:47:47,988 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.4625, Acc=0.161, 
2025-09-28 14:47:55,466 - training.trainer - INFO - Epoch 4, Step 13931: Loss=5.1999, Acc=0.245, 
2025-09-28 14:48:02,857 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.6275, Acc=0.263, 
2025-09-28 14:48:10,280 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.1257, Acc=0.136, 
2025-09-28 14:48:17,820 - training.trainer - INFO - Epoch 4, Step 14231: Loss=4.3495, Acc=0.500, 
2025-09-28 14:48:25,457 - training.trainer - INFO - Epoch 4, Step 14331: Loss=6.1040, Acc=0.170, 
2025-09-28 14:48:32,853 - training.trainer - INFO - Epoch 4, Step 14431: Loss=5.5443, Acc=0.211, 
2025-09-28 14:48:40,219 - training.trainer - INFO - Epoch 4, Step 14531: Loss=5.9153, Acc=0.211, 
2025-09-28 14:48:47,595 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.1031, Acc=0.179, 
2025-09-28 14:48:54,939 - training.trainer - INFO - Epoch 4, Step 14731: Loss=5.5823, Acc=0.138, 
2025-09-28 14:49:02,191 - training.trainer - INFO - Epoch 4, Step 14831: Loss=6.5147, Acc=0.158, 
2025-09-28 14:49:09,427 - training.trainer - INFO - Epoch 4, Step 14931: Loss=5.2689, Acc=0.211, 
2025-09-28 14:49:16,734 - training.trainer - INFO - Epoch 4, Step 15031: Loss=6.3381, Acc=0.234, 
2025-09-28 14:49:24,015 - training.trainer - INFO - Epoch 4, Step 15131: Loss=6.1956, Acc=0.190, 
2025-09-28 14:49:31,334 - training.trainer - INFO - Epoch 4, Step 15231: Loss=6.9648, Acc=0.235, 
2025-09-28 14:49:38,578 - training.trainer - INFO - Epoch 4, Step 15331: Loss=5.6600, Acc=0.229, 
2025-09-28 14:49:45,899 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.1268, Acc=0.206, 
2025-09-28 14:49:53,514 - training.trainer - INFO - Epoch 4, Step 15531: Loss=5.9016, Acc=0.184, 
2025-09-28 14:50:00,761 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.7771, Acc=0.132, 
2025-09-28 14:50:08,053 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.0451, Acc=0.191, 
2025-09-28 14:50:15,303 - training.trainer - INFO - Epoch 4, Step 15831: Loss=5.7301, Acc=0.259, 
2025-09-28 14:50:22,505 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.6336, Acc=0.125, 
2025-09-28 14:50:29,824 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.3301, Acc=0.164, 
2025-09-28 14:50:37,042 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.0965, Acc=0.229, 
2025-09-28 14:50:44,434 - training.trainer - INFO - Epoch 4, Step 16231: Loss=6.3344, Acc=0.191, 
2025-09-28 14:50:51,956 - training.trainer - INFO - Epoch 4, Step 16331: Loss=5.9196, Acc=0.171, 
2025-09-28 14:50:59,362 - training.trainer - INFO - Epoch 4, Step 16431: Loss=6.4986, Acc=0.075, 
2025-09-28 14:51:06,620 - training.trainer - INFO - Epoch 4, Step 16531: Loss=6.0687, Acc=0.167, 
2025-09-28 14:51:13,833 - training.trainer - INFO - Epoch 4, Step 16631: Loss=5.5639, Acc=0.227, 
2025-09-28 14:51:21,330 - training.trainer - INFO - Epoch 4, Step 16731: Loss=6.3335, Acc=0.161, 
2025-09-28 14:51:28,832 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.2467, Acc=0.097, 
2025-09-28 14:51:47,618 - training.trainer - INFO - Epoch 5/100 completed in 262.34s - Train Loss: 6.0764, Train Acc: 0.194, Val Loss: 5.9908, Val Acc: 0.201
2025-09-28 14:51:47,940 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-28 14:51:48,647 - training.trainer - INFO - New best model saved with validation loss: 5.9908
2025-09-28 14:51:48,647 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-28 14:51:55,691 - training.trainer - INFO - Epoch 5, Step 17014: Loss=5.4639, Acc=0.171, 
2025-09-28 14:52:02,829 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.1575, Acc=0.146, 
2025-09-28 14:52:09,921 - training.trainer - INFO - Epoch 5, Step 17214: Loss=5.9674, Acc=0.176, 
2025-09-28 14:52:17,597 - training.trainer - INFO - Epoch 5, Step 17314: Loss=6.5982, Acc=0.161, 
2025-09-28 14:52:25,020 - training.trainer - INFO - Epoch 5, Step 17414: Loss=4.9334, Acc=0.412, 
2025-09-28 14:52:32,485 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.0652, Acc=0.162, 
2025-09-28 14:52:40,110 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.4839, Acc=0.200, 
2025-09-28 14:52:47,745 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.6455, Acc=0.211, 
2025-09-28 14:52:55,349 - training.trainer - INFO - Epoch 5, Step 17814: Loss=5.9880, Acc=0.188, 
2025-09-28 14:53:02,867 - training.trainer - INFO - Epoch 5, Step 17914: Loss=5.2167, Acc=0.250, 
2025-09-28 14:53:10,383 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.1140, Acc=0.154, 
2025-09-28 14:53:17,936 - training.trainer - INFO - Epoch 5, Step 18114: Loss=5.4993, Acc=0.265, 
2025-09-28 14:53:25,318 - training.trainer - INFO - Epoch 5, Step 18214: Loss=6.4793, Acc=0.103, 
2025-09-28 14:53:32,679 - training.trainer - INFO - Epoch 5, Step 18314: Loss=6.1756, Acc=0.167, 
2025-09-28 14:53:40,013 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.9891, Acc=0.286, 
2025-09-28 14:53:47,340 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.1657, Acc=0.167, 
2025-09-28 14:53:54,466 - training.trainer - INFO - Epoch 5, Step 18614: Loss=6.1383, Acc=0.241, 
2025-09-28 14:54:01,753 - training.trainer - INFO - Epoch 5, Step 18714: Loss=6.1973, Acc=0.111, 
2025-09-28 14:54:09,222 - training.trainer - INFO - Epoch 5, Step 18814: Loss=6.3877, Acc=0.220, 
2025-09-28 14:54:16,702 - training.trainer - INFO - Epoch 5, Step 18914: Loss=5.9001, Acc=0.191, 
2025-09-28 14:54:24,142 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.1368, Acc=0.211, 
2025-09-28 14:54:31,559 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.3229, Acc=0.195, 
2025-09-28 14:54:38,882 - training.trainer - INFO - Epoch 5, Step 19214: Loss=5.6292, Acc=0.276, 
2025-09-28 14:54:46,449 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.1478, Acc=0.220, 
2025-09-28 14:54:54,041 - training.trainer - INFO - Epoch 5, Step 19414: Loss=6.1607, Acc=0.194, 
2025-09-28 14:55:01,587 - training.trainer - INFO - Epoch 5, Step 19514: Loss=5.8401, Acc=0.200, 
2025-09-28 14:55:09,015 - training.trainer - INFO - Epoch 5, Step 19614: Loss=5.7296, Acc=0.206, 
2025-09-28 14:55:16,291 - training.trainer - INFO - Epoch 5, Step 19714: Loss=5.8328, Acc=0.179, 
2025-09-28 14:55:23,970 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.2449, Acc=0.212, 
2025-09-28 14:55:31,447 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.8850, Acc=0.357, 
2025-09-28 14:55:38,757 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.0724, Acc=0.176, 
2025-09-28 14:55:46,212 - training.trainer - INFO - Epoch 5, Step 20114: Loss=6.1907, Acc=0.136, 
2025-09-28 14:55:53,699 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.0676, Acc=0.194, 
2025-09-28 14:56:12,440 - training.trainer - INFO - Epoch 6/100 completed in 263.79s - Train Loss: 6.0289, Train Acc: 0.200, Val Loss: 5.9521, Val Acc: 0.208
2025-09-28 14:56:13,274 - training.trainer - INFO - New best model saved with validation loss: 5.9521
2025-09-28 14:56:13,275 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-28 14:56:21,032 - training.trainer - INFO - Epoch 6, Step 20397: Loss=5.9944, Acc=0.160, 
2025-09-28 14:56:28,440 - training.trainer - INFO - Epoch 6, Step 20497: Loss=4.8536, Acc=0.269, 
2025-09-28 14:56:35,881 - training.trainer - INFO - Epoch 6, Step 20597: Loss=5.8716, Acc=0.233, 
2025-09-28 14:56:43,219 - training.trainer - INFO - Epoch 6, Step 20697: Loss=5.8062, Acc=0.273, 
2025-09-28 14:56:50,660 - training.trainer - INFO - Epoch 6, Step 20797: Loss=6.0203, Acc=0.148, 
2025-09-28 14:56:58,097 - training.trainer - INFO - Epoch 6, Step 20897: Loss=5.9049, Acc=0.229, 
2025-09-28 14:57:05,501 - training.trainer - INFO - Epoch 6, Step 20997: Loss=6.5710, Acc=0.158, 
2025-09-28 14:57:13,110 - training.trainer - INFO - Epoch 6, Step 21097: Loss=5.3137, Acc=0.244, 
2025-09-28 14:57:20,527 - training.trainer - INFO - Epoch 6, Step 21197: Loss=5.4796, Acc=0.250, 
2025-09-28 14:57:28,001 - training.trainer - INFO - Epoch 6, Step 21297: Loss=6.2219, Acc=0.261, 
2025-09-28 14:57:35,679 - training.trainer - INFO - Epoch 6, Step 21397: Loss=6.1573, Acc=0.250, 
2025-09-28 14:57:43,163 - training.trainer - INFO - Epoch 6, Step 21497: Loss=5.9459, Acc=0.200, 
2025-09-28 14:57:50,429 - training.trainer - INFO - Epoch 6, Step 21597: Loss=5.6814, Acc=0.217, 
2025-09-28 14:57:57,733 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.6719, Acc=0.105, 
2025-09-28 14:58:05,301 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.1809, Acc=0.240, 
2025-09-28 14:58:12,765 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.1707, Acc=0.125, 
2025-09-28 14:58:20,502 - training.trainer - INFO - Epoch 6, Step 21997: Loss=6.1970, Acc=0.172, 
2025-09-28 14:58:27,754 - training.trainer - INFO - Epoch 6, Step 22097: Loss=5.4359, Acc=0.261, 
2025-09-28 14:58:35,085 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.1887, Acc=0.139, 
2025-09-28 14:58:42,291 - training.trainer - INFO - Epoch 6, Step 22297: Loss=5.1463, Acc=0.286, 
2025-09-28 14:58:49,522 - training.trainer - INFO - Epoch 6, Step 22397: Loss=6.5497, Acc=0.171, 
2025-09-28 14:58:57,103 - training.trainer - INFO - Epoch 6, Step 22497: Loss=4.6266, Acc=0.375, 
2025-09-28 14:59:04,625 - training.trainer - INFO - Epoch 6, Step 22597: Loss=6.8625, Acc=0.121, 
2025-09-28 14:59:12,177 - training.trainer - INFO - Epoch 6, Step 22697: Loss=6.3234, Acc=0.158, 
2025-09-28 14:59:19,560 - training.trainer - INFO - Epoch 6, Step 22797: Loss=6.0129, Acc=0.226, 
2025-09-28 14:59:26,809 - training.trainer - INFO - Epoch 6, Step 22897: Loss=5.8596, Acc=0.118, 
2025-09-28 14:59:34,173 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.7702, Acc=0.116, 
2025-09-28 14:59:41,667 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.3606, Acc=0.149, 
2025-09-28 14:59:49,030 - training.trainer - INFO - Epoch 6, Step 23197: Loss=5.5770, Acc=0.265, 
2025-09-28 14:59:56,240 - training.trainer - INFO - Epoch 6, Step 23297: Loss=6.4456, Acc=0.132, 
2025-09-28 15:00:03,636 - training.trainer - INFO - Epoch 6, Step 23397: Loss=5.6658, Acc=0.214, 
2025-09-28 15:00:10,974 - training.trainer - INFO - Epoch 6, Step 23497: Loss=5.9358, Acc=0.163, 
2025-09-28 15:00:18,287 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.2942, Acc=0.109, 
2025-09-28 15:00:36,509 - training.trainer - INFO - Epoch 7/100 completed in 263.23s - Train Loss: 5.9867, Train Acc: 0.207, Val Loss: 5.9236, Val Acc: 0.213
2025-09-28 15:00:37,271 - training.trainer - INFO - New best model saved with validation loss: 5.9236
2025-09-28 15:00:37,272 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-28 15:00:45,278 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.1343, Acc=0.176, 
2025-09-28 15:00:52,840 - training.trainer - INFO - Epoch 7, Step 23880: Loss=6.1672, Acc=0.154, 
2025-09-28 15:01:00,144 - training.trainer - INFO - Epoch 7, Step 23980: Loss=5.7374, Acc=0.233, 
2025-09-28 15:01:07,554 - training.trainer - INFO - Epoch 7, Step 24080: Loss=6.3408, Acc=0.125, 
2025-09-28 15:01:14,871 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.4356, Acc=0.132, 
2025-09-28 15:01:22,183 - training.trainer - INFO - Epoch 7, Step 24280: Loss=6.5282, Acc=0.118, 
2025-09-28 15:01:29,577 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.3725, Acc=0.164, 
2025-09-28 15:01:36,792 - training.trainer - INFO - Epoch 7, Step 24480: Loss=5.6859, Acc=0.206, 
2025-09-28 15:01:44,642 - training.trainer - INFO - Epoch 7, Step 24580: Loss=4.4648, Acc=0.467, 
2025-09-28 15:01:52,110 - training.trainer - INFO - Epoch 7, Step 24680: Loss=5.9551, Acc=0.222, 
2025-09-28 15:01:59,767 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.2551, Acc=0.179, 
2025-09-28 15:02:07,171 - training.trainer - INFO - Epoch 7, Step 24880: Loss=5.4735, Acc=0.212, 
2025-09-28 15:02:14,514 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.0311, Acc=0.300, 
2025-09-28 15:02:22,203 - training.trainer - INFO - Epoch 7, Step 25080: Loss=5.7381, Acc=0.167, 
2025-09-28 15:02:29,693 - training.trainer - INFO - Epoch 7, Step 25180: Loss=5.8562, Acc=0.200, 
2025-09-28 15:02:36,832 - training.trainer - INFO - Epoch 7, Step 25280: Loss=5.0038, Acc=0.333, 
2025-09-28 15:02:44,031 - training.trainer - INFO - Epoch 7, Step 25380: Loss=5.6229, Acc=0.300, 
2025-09-28 15:02:51,348 - training.trainer - INFO - Epoch 7, Step 25480: Loss=6.8787, Acc=0.179, 
2025-09-28 15:02:58,772 - training.trainer - INFO - Epoch 7, Step 25580: Loss=5.7733, Acc=0.417, 
2025-09-28 15:03:06,173 - training.trainer - INFO - Epoch 7, Step 25680: Loss=6.7602, Acc=0.184, 
2025-09-28 15:03:13,432 - training.trainer - INFO - Epoch 7, Step 25780: Loss=7.2173, Acc=0.104, 
2025-09-28 15:03:20,663 - training.trainer - INFO - Epoch 7, Step 25880: Loss=4.4355, Acc=0.364, 
2025-09-28 15:03:27,772 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.2786, Acc=0.267, 
2025-09-28 15:03:35,112 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.1748, Acc=0.085, 
2025-09-28 15:03:42,375 - training.trainer - INFO - Epoch 7, Step 26180: Loss=6.5116, Acc=0.098, 
2025-09-28 15:03:49,654 - training.trainer - INFO - Epoch 7, Step 26280: Loss=6.4644, Acc=0.241, 
2025-09-28 15:03:56,908 - training.trainer - INFO - Epoch 7, Step 26380: Loss=6.1797, Acc=0.184, 
2025-09-28 15:04:04,244 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.4140, Acc=0.261, 
2025-09-28 15:04:11,439 - training.trainer - INFO - Epoch 7, Step 26580: Loss=6.1241, Acc=0.174, 
2025-09-28 15:04:18,706 - training.trainer - INFO - Epoch 7, Step 26680: Loss=5.4894, Acc=0.276, 
2025-09-28 15:04:25,874 - training.trainer - INFO - Epoch 7, Step 26780: Loss=6.0016, Acc=0.171, 
2025-09-28 15:04:33,145 - training.trainer - INFO - Epoch 7, Step 26880: Loss=6.3386, Acc=0.229, 
2025-09-28 15:04:40,455 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.8829, Acc=0.212, 
2025-09-28 15:04:59,564 - training.trainer - INFO - Epoch 8/100 completed in 262.29s - Train Loss: 5.9411, Train Acc: 0.212, Val Loss: 5.8953, Val Acc: 0.216
2025-09-28 15:05:00,359 - training.trainer - INFO - New best model saved with validation loss: 5.8953
2025-09-28 15:05:00,359 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-09-28 15:05:08,162 - training.trainer - INFO - Epoch 8, Step 27163: Loss=5.5298, Acc=0.182, 
2025-09-28 15:05:15,496 - training.trainer - INFO - Epoch 8, Step 27263: Loss=6.3446, Acc=0.156, 
2025-09-28 15:05:22,695 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.8151, Acc=0.182, 
2025-09-28 15:05:30,231 - training.trainer - INFO - Epoch 8, Step 27463: Loss=5.9551, Acc=0.269, 
2025-09-28 15:05:37,503 - training.trainer - INFO - Epoch 8, Step 27563: Loss=6.6046, Acc=0.104, 
2025-09-28 15:05:45,083 - training.trainer - INFO - Epoch 8, Step 27663: Loss=5.9794, Acc=0.226, 
2025-09-28 15:05:52,675 - training.trainer - INFO - Epoch 8, Step 27763: Loss=5.8249, Acc=0.174, 
2025-09-28 15:05:59,908 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.1512, Acc=0.163, 
2025-09-28 15:06:07,292 - training.trainer - INFO - Epoch 8, Step 27963: Loss=5.8074, Acc=0.297, 
2025-09-28 15:06:14,859 - training.trainer - INFO - Epoch 8, Step 28063: Loss=6.2992, Acc=0.130, 
2025-09-28 15:06:22,188 - training.trainer - INFO - Epoch 8, Step 28163: Loss=5.9359, Acc=0.227, 
2025-09-28 15:06:29,561 - training.trainer - INFO - Epoch 8, Step 28263: Loss=5.8629, Acc=0.250, 
2025-09-28 15:06:37,108 - training.trainer - INFO - Epoch 8, Step 28363: Loss=6.4205, Acc=0.222, 
2025-09-28 15:06:44,481 - training.trainer - INFO - Epoch 8, Step 28463: Loss=6.3419, Acc=0.182, 
2025-09-28 15:06:51,882 - training.trainer - INFO - Epoch 8, Step 28563: Loss=5.8643, Acc=0.188, 
2025-09-28 15:06:59,374 - training.trainer - INFO - Epoch 8, Step 28663: Loss=5.4225, Acc=0.194, 
2025-09-28 15:07:06,714 - training.trainer - INFO - Epoch 8, Step 28763: Loss=5.9377, Acc=0.211, 
2025-09-28 15:07:14,120 - training.trainer - INFO - Epoch 8, Step 28863: Loss=6.1863, Acc=0.316, 
2025-09-28 15:07:21,509 - training.trainer - INFO - Epoch 8, Step 28963: Loss=5.9019, Acc=0.214, 
2025-09-28 15:07:28,783 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.9526, Acc=0.121, 
2025-09-28 15:07:35,975 - training.trainer - INFO - Epoch 8, Step 29163: Loss=6.3066, Acc=0.114, 
2025-09-28 15:07:43,176 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.0319, Acc=0.120, 
2025-09-28 15:07:50,355 - training.trainer - INFO - Epoch 8, Step 29363: Loss=5.8842, Acc=0.176, 
2025-09-28 15:07:58,106 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.7238, Acc=0.156, 
2025-09-28 15:08:05,598 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.6099, Acc=0.214, 
2025-09-28 15:08:13,062 - training.trainer - INFO - Epoch 8, Step 29663: Loss=4.7877, Acc=0.227, 
2025-09-28 15:08:20,579 - training.trainer - INFO - Epoch 8, Step 29763: Loss=6.7589, Acc=0.148, 
2025-09-28 15:08:28,003 - training.trainer - INFO - Epoch 8, Step 29863: Loss=6.6348, Acc=0.150, 
2025-09-28 15:08:35,397 - training.trainer - INFO - Epoch 8, Step 29963: Loss=5.0360, Acc=0.296, 
2025-09-28 15:08:42,738 - training.trainer - INFO - Epoch 8, Step 30063: Loss=6.3747, Acc=0.231, 
2025-09-28 15:08:50,285 - training.trainer - INFO - Epoch 8, Step 30163: Loss=6.2480, Acc=0.179, 
2025-09-28 15:08:57,912 - training.trainer - INFO - Epoch 8, Step 30263: Loss=6.4865, Acc=0.144, 
2025-09-28 15:09:05,536 - training.trainer - INFO - Epoch 8, Step 30363: Loss=6.0090, Acc=0.200, 
2025-09-28 15:09:23,974 - training.trainer - INFO - Epoch 9/100 completed in 263.61s - Train Loss: 5.9052, Train Acc: 0.219, Val Loss: 5.8628, Val Acc: 0.221
2025-09-28 15:09:24,759 - training.trainer - INFO - New best model saved with validation loss: 5.8628
2025-09-28 15:09:24,760 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-28 15:09:32,216 - training.trainer - INFO - Epoch 9, Step 30546: Loss=5.9704, Acc=0.220, 
2025-09-28 15:09:39,245 - training.trainer - INFO - Epoch 9, Step 30646: Loss=6.1355, Acc=0.235, 
2025-09-28 15:09:46,584 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.1155, Acc=0.182, 
2025-09-28 15:09:54,089 - training.trainer - INFO - Epoch 9, Step 30846: Loss=5.7290, Acc=0.171, 
2025-09-28 15:10:01,474 - training.trainer - INFO - Epoch 9, Step 30946: Loss=4.9377, Acc=0.290, 
2025-09-28 15:10:08,919 - training.trainer - INFO - Epoch 9, Step 31046: Loss=4.8467, Acc=0.312, 
2025-09-28 15:10:16,369 - training.trainer - INFO - Epoch 9, Step 31146: Loss=6.0402, Acc=0.209, 
2025-09-28 15:10:23,724 - training.trainer - INFO - Epoch 9, Step 31246: Loss=6.2637, Acc=0.128, 
2025-09-28 15:10:31,109 - training.trainer - INFO - Epoch 9, Step 31346: Loss=5.9393, Acc=0.200, 
2025-09-28 15:10:38,517 - training.trainer - INFO - Epoch 9, Step 31446: Loss=6.6436, Acc=0.200, 
2025-09-28 15:10:45,925 - training.trainer - INFO - Epoch 9, Step 31546: Loss=6.3705, Acc=0.156, 
2025-09-28 15:10:53,300 - training.trainer - INFO - Epoch 9, Step 31646: Loss=5.4283, Acc=0.297, 
2025-09-28 15:11:00,596 - training.trainer - INFO - Epoch 9, Step 31746: Loss=4.2001, Acc=0.312, 
2025-09-28 15:11:08,050 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.1767, Acc=0.169, 
2025-09-28 15:11:15,468 - training.trainer - INFO - Epoch 9, Step 31946: Loss=5.7365, Acc=0.232, 
2025-09-28 15:11:22,836 - training.trainer - INFO - Epoch 9, Step 32046: Loss=5.6592, Acc=0.171, 
2025-09-28 15:11:30,147 - training.trainer - INFO - Epoch 9, Step 32146: Loss=6.1454, Acc=0.194, 
2025-09-28 15:11:37,449 - training.trainer - INFO - Epoch 9, Step 32246: Loss=5.9359, Acc=0.245, 
2025-09-28 15:11:45,143 - training.trainer - INFO - Epoch 9, Step 32346: Loss=6.8248, Acc=0.143, 
2025-09-28 15:11:52,478 - training.trainer - INFO - Epoch 9, Step 32446: Loss=6.2716, Acc=0.208, 
2025-09-28 15:11:59,767 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.6492, Acc=0.195, 
2025-09-28 15:12:07,095 - training.trainer - INFO - Epoch 9, Step 32646: Loss=5.3567, Acc=0.250, 
2025-09-28 15:12:14,502 - training.trainer - INFO - Epoch 9, Step 32746: Loss=6.3764, Acc=0.186, 
2025-09-28 15:12:21,775 - training.trainer - INFO - Epoch 9, Step 32846: Loss=6.2469, Acc=0.149, 
2025-09-28 15:12:29,162 - training.trainer - INFO - Epoch 9, Step 32946: Loss=6.1406, Acc=0.200, 
2025-09-28 15:12:36,606 - training.trainer - INFO - Epoch 9, Step 33046: Loss=4.4058, Acc=0.360, 
2025-09-28 15:12:44,123 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.4263, Acc=0.167, 
2025-09-28 15:12:51,583 - training.trainer - INFO - Epoch 9, Step 33246: Loss=5.9632, Acc=0.148, 
2025-09-28 15:12:58,908 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.1717, Acc=0.194, 
2025-09-28 15:13:06,223 - training.trainer - INFO - Epoch 9, Step 33446: Loss=5.5130, Acc=0.257, 
2025-09-28 15:13:13,711 - training.trainer - INFO - Epoch 9, Step 33546: Loss=5.8919, Acc=0.289, 
2025-09-28 15:13:21,219 - training.trainer - INFO - Epoch 9, Step 33646: Loss=6.2575, Acc=0.143, 
2025-09-28 15:13:28,692 - training.trainer - INFO - Epoch 9, Step 33746: Loss=6.6486, Acc=0.152, 
2025-09-28 15:13:47,863 - training.trainer - INFO - Epoch 10/100 completed in 263.10s - Train Loss: 5.8696, Train Acc: 0.224, Val Loss: 5.8214, Val Acc: 0.228
2025-09-28 15:13:48,204 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-28 15:13:48,860 - training.trainer - INFO - New best model saved with validation loss: 5.8214
2025-09-28 15:13:48,860 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-28 15:13:56,510 - training.trainer - INFO - Epoch 10, Step 33929: Loss=5.7390, Acc=0.154, 
2025-09-28 15:14:03,855 - training.trainer - INFO - Epoch 10, Step 34029: Loss=4.9987, Acc=0.278, 
2025-09-28 15:14:11,399 - training.trainer - INFO - Epoch 10, Step 34129: Loss=4.9078, Acc=0.263, 
2025-09-28 15:14:18,851 - training.trainer - INFO - Epoch 10, Step 34229: Loss=5.3275, Acc=0.353, 
2025-09-28 15:14:26,273 - training.trainer - INFO - Epoch 10, Step 34329: Loss=6.0994, Acc=0.267, 
2025-09-28 15:14:33,650 - training.trainer - INFO - Epoch 10, Step 34429: Loss=4.9336, Acc=0.385, 
2025-09-28 15:14:41,101 - training.trainer - INFO - Epoch 10, Step 34529: Loss=5.0775, Acc=0.360, 
2025-09-28 15:14:48,633 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.9486, Acc=0.243, 
2025-09-28 15:14:56,066 - training.trainer - INFO - Epoch 10, Step 34729: Loss=5.4817, Acc=0.200, 
2025-09-28 15:15:03,486 - training.trainer - INFO - Epoch 10, Step 34829: Loss=6.4314, Acc=0.167, 
2025-09-28 15:15:10,773 - training.trainer - INFO - Epoch 10, Step 34929: Loss=6.1455, Acc=0.121, 
2025-09-28 15:15:18,104 - training.trainer - INFO - Epoch 10, Step 35029: Loss=6.6557, Acc=0.237, 
2025-09-28 15:15:25,368 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.1115, Acc=0.176, 
2025-09-28 15:15:32,636 - training.trainer - INFO - Epoch 10, Step 35229: Loss=6.1654, Acc=0.194, 
2025-09-28 15:15:40,027 - training.trainer - INFO - Epoch 10, Step 35329: Loss=6.5049, Acc=0.196, 
2025-09-28 15:15:47,245 - training.trainer - INFO - Epoch 10, Step 35429: Loss=6.4399, Acc=0.188, 
2025-09-28 15:15:55,147 - training.trainer - INFO - Epoch 10, Step 35529: Loss=6.6694, Acc=0.094, 
2025-09-28 15:16:02,396 - training.trainer - INFO - Epoch 10, Step 35629: Loss=5.2995, Acc=0.291, 
2025-09-28 15:16:09,733 - training.trainer - INFO - Epoch 10, Step 35729: Loss=5.4777, Acc=0.220, 
2025-09-28 15:16:17,132 - training.trainer - INFO - Epoch 10, Step 35829: Loss=5.6883, Acc=0.206, 
2025-09-28 15:16:24,410 - training.trainer - INFO - Epoch 10, Step 35929: Loss=6.1258, Acc=0.177, 
2025-09-28 15:16:31,647 - training.trainer - INFO - Epoch 10, Step 36029: Loss=6.9754, Acc=0.094, 
2025-09-28 15:16:39,028 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.7346, Acc=0.167, 
2025-09-28 15:16:46,393 - training.trainer - INFO - Epoch 10, Step 36229: Loss=5.2766, Acc=0.292, 
2025-09-28 15:16:53,844 - training.trainer - INFO - Epoch 10, Step 36329: Loss=5.8452, Acc=0.206, 
2025-09-28 15:17:01,283 - training.trainer - INFO - Epoch 10, Step 36429: Loss=4.5375, Acc=0.323, 
2025-09-28 15:17:08,879 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.9228, Acc=0.227, 
2025-09-28 15:17:16,328 - training.trainer - INFO - Epoch 10, Step 36629: Loss=5.7171, Acc=0.364, 
2025-09-28 15:17:23,845 - training.trainer - INFO - Epoch 10, Step 36729: Loss=6.2966, Acc=0.250, 
2025-09-28 15:17:31,295 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.6134, Acc=0.135, 
2025-09-28 15:17:38,812 - training.trainer - INFO - Epoch 10, Step 36929: Loss=6.1569, Acc=0.222, 
2025-09-28 15:17:46,384 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.9333, Acc=0.222, 
2025-09-28 15:17:53,817 - training.trainer - INFO - Epoch 10, Step 37129: Loss=5.8864, Acc=0.292, 
2025-09-28 15:18:12,468 - training.trainer - INFO - Epoch 11/100 completed in 263.61s - Train Loss: 5.8436, Train Acc: 0.228, Val Loss: 5.8129, Val Acc: 0.230
2025-09-28 15:18:13,281 - training.trainer - INFO - New best model saved with validation loss: 5.8129
2025-09-28 15:18:13,281 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-28 15:18:20,942 - training.trainer - INFO - Epoch 11, Step 37312: Loss=5.8334, Acc=0.204, 
2025-09-28 15:18:28,162 - training.trainer - INFO - Epoch 11, Step 37412: Loss=5.9338, Acc=0.238, 
2025-09-28 15:18:35,592 - training.trainer - INFO - Epoch 11, Step 37512: Loss=4.6864, Acc=0.379, 
2025-09-28 15:18:42,997 - training.trainer - INFO - Epoch 11, Step 37612: Loss=6.1776, Acc=0.218, 
2025-09-28 15:18:50,391 - training.trainer - INFO - Epoch 11, Step 37712: Loss=5.8664, Acc=0.161, 
2025-09-28 15:18:57,815 - training.trainer - INFO - Epoch 11, Step 37812: Loss=5.4856, Acc=0.176, 
2025-09-28 15:19:05,187 - training.trainer - INFO - Epoch 11, Step 37912: Loss=5.4031, Acc=0.296, 
2025-09-28 15:19:12,526 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.3593, Acc=0.206, 
2025-09-28 15:19:19,949 - training.trainer - INFO - Epoch 11, Step 38112: Loss=5.3748, Acc=0.281, 
2025-09-28 15:19:27,275 - training.trainer - INFO - Epoch 11, Step 38212: Loss=5.2712, Acc=0.312, 
2025-09-28 15:19:34,682 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.4672, Acc=0.234, 
2025-09-28 15:19:42,290 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.9804, Acc=0.179, 
2025-09-28 15:19:49,744 - training.trainer - INFO - Epoch 11, Step 38512: Loss=4.8238, Acc=0.368, 
2025-09-28 15:19:57,309 - training.trainer - INFO - Epoch 11, Step 38612: Loss=5.3681, Acc=0.259, 
2025-09-28 15:20:04,675 - training.trainer - INFO - Epoch 11, Step 38712: Loss=6.5036, Acc=0.179, 
2025-09-28 15:20:12,015 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.8131, Acc=0.364, 
2025-09-28 15:20:19,410 - training.trainer - INFO - Epoch 11, Step 38912: Loss=6.0950, Acc=0.250, 
2025-09-28 15:20:26,886 - training.trainer - INFO - Epoch 11, Step 39012: Loss=5.3262, Acc=0.364, 
2025-09-28 15:20:34,362 - training.trainer - INFO - Epoch 11, Step 39112: Loss=4.9731, Acc=0.414, 
2025-09-28 15:20:41,936 - training.trainer - INFO - Epoch 11, Step 39212: Loss=6.8091, Acc=0.133, 
2025-09-28 15:20:49,518 - training.trainer - INFO - Epoch 11, Step 39312: Loss=6.0217, Acc=0.213, 
2025-09-28 15:20:56,997 - training.trainer - INFO - Epoch 11, Step 39412: Loss=5.3026, Acc=0.375, 
2025-09-28 15:21:04,550 - training.trainer - INFO - Epoch 11, Step 39512: Loss=5.0264, Acc=0.290, 
2025-09-28 15:21:12,029 - training.trainer - INFO - Epoch 11, Step 39612: Loss=6.1331, Acc=0.200, 
2025-09-28 15:21:19,532 - training.trainer - INFO - Epoch 11, Step 39712: Loss=6.2364, Acc=0.172, 
2025-09-28 15:21:27,323 - training.trainer - INFO - Epoch 11, Step 39812: Loss=6.6350, Acc=0.134, 
2025-09-28 15:21:34,817 - training.trainer - INFO - Epoch 11, Step 39912: Loss=5.7906, Acc=0.250, 
2025-09-28 15:21:42,253 - training.trainer - INFO - Epoch 11, Step 40012: Loss=6.3753, Acc=0.175, 
2025-09-28 15:21:49,815 - training.trainer - INFO - Epoch 11, Step 40112: Loss=5.7709, Acc=0.200, 
2025-09-28 15:21:57,387 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.7948, Acc=0.174, 
2025-09-28 15:22:04,917 - training.trainer - INFO - Epoch 11, Step 40312: Loss=6.0927, Acc=0.326, 
2025-09-28 15:22:12,406 - training.trainer - INFO - Epoch 11, Step 40412: Loss=6.1861, Acc=0.259, 
2025-09-28 15:22:19,795 - training.trainer - INFO - Epoch 11, Step 40512: Loss=5.3433, Acc=0.300, 
2025-09-28 15:22:38,209 - training.trainer - INFO - Epoch 12/100 completed in 264.93s - Train Loss: 5.8138, Train Acc: 0.232, Val Loss: 5.7885, Val Acc: 0.231
2025-09-28 15:22:38,961 - training.trainer - INFO - New best model saved with validation loss: 5.7885
2025-09-28 15:22:38,962 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-09-28 15:22:47,087 - training.trainer - INFO - Epoch 12, Step 40695: Loss=5.8307, Acc=0.216, 
2025-09-28 15:22:54,671 - training.trainer - INFO - Epoch 12, Step 40795: Loss=4.1529, Acc=0.444, 
2025-09-28 15:23:02,123 - training.trainer - INFO - Epoch 12, Step 40895: Loss=6.3367, Acc=0.150, 
2025-09-28 15:23:09,524 - training.trainer - INFO - Epoch 12, Step 40995: Loss=4.5344, Acc=0.478, 
2025-09-28 15:23:16,934 - training.trainer - INFO - Epoch 12, Step 41095: Loss=5.9831, Acc=0.217, 
2025-09-28 15:23:24,317 - training.trainer - INFO - Epoch 12, Step 41195: Loss=6.5115, Acc=0.195, 
2025-09-28 15:23:31,759 - training.trainer - INFO - Epoch 12, Step 41295: Loss=3.5354, Acc=0.548, 
2025-09-28 15:23:39,194 - training.trainer - INFO - Epoch 12, Step 41395: Loss=5.9205, Acc=0.182, 
2025-09-28 15:23:46,597 - training.trainer - INFO - Epoch 12, Step 41495: Loss=5.0864, Acc=0.346, 
2025-09-28 15:23:53,913 - training.trainer - INFO - Epoch 12, Step 41595: Loss=5.9943, Acc=0.158, 
2025-09-28 15:24:01,283 - training.trainer - INFO - Epoch 12, Step 41695: Loss=6.1000, Acc=0.232, 
2025-09-28 15:24:08,638 - training.trainer - INFO - Epoch 12, Step 41795: Loss=5.2345, Acc=0.250, 
2025-09-28 15:24:16,028 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.0140, Acc=0.222, 
2025-09-28 15:24:23,456 - training.trainer - INFO - Epoch 12, Step 41995: Loss=6.1970, Acc=0.147, 
2025-09-28 15:24:30,837 - training.trainer - INFO - Epoch 12, Step 42095: Loss=5.6701, Acc=0.243, 
2025-09-28 15:24:38,204 - training.trainer - INFO - Epoch 12, Step 42195: Loss=5.7216, Acc=0.277, 
2025-09-28 15:24:45,533 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.7172, Acc=0.333, 
2025-09-28 15:24:52,927 - training.trainer - INFO - Epoch 12, Step 42395: Loss=6.0318, Acc=0.219, 
2025-09-28 15:25:00,295 - training.trainer - INFO - Epoch 12, Step 42495: Loss=5.4665, Acc=0.226, 
2025-09-28 15:25:07,634 - training.trainer - INFO - Epoch 12, Step 42595: Loss=5.6326, Acc=0.229, 
2025-09-28 15:25:15,118 - training.trainer - INFO - Epoch 12, Step 42695: Loss=6.1012, Acc=0.174, 
2025-09-28 15:25:22,541 - training.trainer - INFO - Epoch 12, Step 42795: Loss=5.9678, Acc=0.217, 
2025-09-28 15:25:30,095 - training.trainer - INFO - Epoch 12, Step 42895: Loss=5.6602, Acc=0.240, 
2025-09-28 15:25:37,675 - training.trainer - INFO - Epoch 12, Step 42995: Loss=5.3359, Acc=0.282, 
2025-09-28 15:25:45,121 - training.trainer - INFO - Epoch 12, Step 43095: Loss=6.3060, Acc=0.135, 
2025-09-28 15:25:52,769 - training.trainer - INFO - Epoch 12, Step 43195: Loss=5.2496, Acc=0.333, 
2025-09-28 15:26:00,307 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.4767, Acc=0.100, 
2025-09-28 15:26:07,754 - training.trainer - INFO - Epoch 12, Step 43395: Loss=5.1768, Acc=0.276, 
2025-09-28 15:26:15,142 - training.trainer - INFO - Epoch 12, Step 43495: Loss=5.9849, Acc=0.194, 
2025-09-28 15:26:22,368 - training.trainer - INFO - Epoch 12, Step 43595: Loss=6.5117, Acc=0.134, 
2025-09-28 15:26:29,660 - training.trainer - INFO - Epoch 12, Step 43695: Loss=5.7837, Acc=0.357, 
2025-09-28 15:26:36,925 - training.trainer - INFO - Epoch 12, Step 43795: Loss=5.5537, Acc=0.265, 
2025-09-28 15:26:44,298 - training.trainer - INFO - Epoch 12, Step 43895: Loss=6.4075, Acc=0.085, 
2025-09-28 15:27:03,865 - training.trainer - INFO - Epoch 13/100 completed in 264.90s - Train Loss: 5.7922, Train Acc: 0.235, Val Loss: 5.7746, Val Acc: 0.233
2025-09-28 15:27:04,569 - training.trainer - INFO - New best model saved with validation loss: 5.7746
2025-09-28 15:27:04,569 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-28 15:27:11,497 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.4004, Acc=0.147, 
2025-09-28 15:27:17,912 - training.trainer - INFO - Epoch 13, Step 44178: Loss=5.8960, Acc=0.171, 
2025-09-28 15:27:24,340 - training.trainer - INFO - Epoch 13, Step 44278: Loss=5.0390, Acc=0.300, 
2025-09-28 15:27:30,535 - training.trainer - INFO - Epoch 13, Step 44378: Loss=5.8300, Acc=0.208, 
2025-09-28 15:27:36,817 - training.trainer - INFO - Epoch 13, Step 44478: Loss=4.7305, Acc=0.333, 
2025-09-28 15:27:43,033 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.4962, Acc=0.298, 
2025-09-28 15:27:49,196 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.9274, Acc=0.217, 
2025-09-28 15:27:55,698 - training.trainer - INFO - Epoch 13, Step 44778: Loss=4.1966, Acc=0.353, 
2025-09-28 15:28:02,253 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.7811, Acc=0.289, 
2025-09-28 15:28:09,321 - training.trainer - INFO - Epoch 13, Step 44978: Loss=6.6335, Acc=0.125, 
2025-09-28 15:28:16,486 - training.trainer - INFO - Epoch 13, Step 45078: Loss=4.3305, Acc=0.333, 
2025-09-28 15:28:24,016 - training.trainer - INFO - Epoch 13, Step 45178: Loss=4.9490, Acc=0.318, 
2025-09-28 15:28:31,444 - training.trainer - INFO - Epoch 13, Step 45278: Loss=6.7739, Acc=0.121, 
2025-09-28 15:28:38,882 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.4518, Acc=0.191, 
2025-09-28 15:28:46,193 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.9231, Acc=0.183, 
2025-09-28 15:28:53,547 - training.trainer - INFO - Epoch 13, Step 45578: Loss=5.7213, Acc=0.190, 
2025-09-28 15:29:00,769 - training.trainer - INFO - Epoch 13, Step 45678: Loss=5.5837, Acc=0.265, 
2025-09-28 15:29:08,208 - training.trainer - INFO - Epoch 13, Step 45778: Loss=5.9804, Acc=0.217, 
2025-09-28 15:29:15,702 - training.trainer - INFO - Epoch 13, Step 45878: Loss=6.0387, Acc=0.206, 
2025-09-28 15:29:23,132 - training.trainer - INFO - Epoch 13, Step 45978: Loss=6.3853, Acc=0.158, 
2025-09-28 15:29:30,518 - training.trainer - INFO - Epoch 13, Step 46078: Loss=6.2472, Acc=0.128, 
2025-09-28 15:29:37,929 - training.trainer - INFO - Epoch 13, Step 46178: Loss=5.7123, Acc=0.188, 
2025-09-28 15:29:45,330 - training.trainer - INFO - Epoch 13, Step 46278: Loss=5.4881, Acc=0.333, 
2025-09-28 15:29:52,851 - training.trainer - INFO - Epoch 13, Step 46378: Loss=7.0097, Acc=0.186, 
2025-09-28 15:30:00,528 - training.trainer - INFO - Epoch 13, Step 46478: Loss=5.4952, Acc=0.267, 
2025-09-28 15:30:08,108 - training.trainer - INFO - Epoch 13, Step 46578: Loss=6.0561, Acc=0.250, 
2025-09-28 15:30:15,750 - training.trainer - INFO - Epoch 13, Step 46678: Loss=5.7830, Acc=0.286, 
2025-09-28 15:30:23,220 - training.trainer - INFO - Epoch 13, Step 46778: Loss=7.3456, Acc=0.172, 
2025-09-28 15:30:30,653 - training.trainer - INFO - Epoch 13, Step 46878: Loss=5.2267, Acc=0.375, 
2025-09-28 15:30:38,054 - training.trainer - INFO - Epoch 13, Step 46978: Loss=5.2207, Acc=0.333, 
2025-09-28 15:30:45,414 - training.trainer - INFO - Epoch 13, Step 47078: Loss=6.0134, Acc=0.212, 
2025-09-28 15:30:52,940 - training.trainer - INFO - Epoch 13, Step 47178: Loss=6.2368, Acc=0.133, 
2025-09-28 15:31:00,326 - training.trainer - INFO - Epoch 13, Step 47278: Loss=5.3042, Acc=0.273, 
2025-09-28 15:31:19,286 - training.trainer - INFO - Epoch 14/100 completed in 254.72s - Train Loss: 5.7647, Train Acc: 0.238, Val Loss: 5.7560, Val Acc: 0.239
2025-09-28 15:31:19,987 - training.trainer - INFO - New best model saved with validation loss: 5.7560
2025-09-28 15:31:19,988 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-28 15:31:27,955 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.9137, Acc=0.228, 
2025-09-28 15:31:35,425 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.4474, Acc=0.239, 
2025-09-28 15:31:43,062 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.2009, Acc=0.344, 
2025-09-28 15:31:50,875 - training.trainer - INFO - Epoch 14, Step 47761: Loss=6.1976, Acc=0.134, 
2025-09-28 15:31:58,456 - training.trainer - INFO - Epoch 14, Step 47861: Loss=3.7110, Acc=0.478, 
2025-09-28 15:32:05,902 - training.trainer - INFO - Epoch 14, Step 47961: Loss=6.0180, Acc=0.233, 
2025-09-28 15:32:13,167 - training.trainer - INFO - Epoch 14, Step 48061: Loss=6.7375, Acc=0.170, 
2025-09-28 15:32:20,456 - training.trainer - INFO - Epoch 14, Step 48161: Loss=4.8177, Acc=0.375, 
2025-09-28 15:32:27,918 - training.trainer - INFO - Epoch 14, Step 48261: Loss=5.6546, Acc=0.237, 
2025-09-28 15:32:35,230 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.1562, Acc=0.333, 
2025-09-28 15:32:42,610 - training.trainer - INFO - Epoch 14, Step 48461: Loss=5.9741, Acc=0.145, 
2025-09-28 15:32:49,953 - training.trainer - INFO - Epoch 14, Step 48561: Loss=6.1710, Acc=0.268, 
2025-09-28 15:32:57,247 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.7538, Acc=0.149, 
2025-09-28 15:33:04,599 - training.trainer - INFO - Epoch 14, Step 48761: Loss=6.2890, Acc=0.162, 
2025-09-28 15:33:11,887 - training.trainer - INFO - Epoch 14, Step 48861: Loss=5.7539, Acc=0.224, 
2025-09-28 15:33:19,259 - training.trainer - INFO - Epoch 14, Step 48961: Loss=5.9802, Acc=0.206, 
2025-09-28 15:33:26,625 - training.trainer - INFO - Epoch 14, Step 49061: Loss=6.2913, Acc=0.308, 
2025-09-28 15:33:33,866 - training.trainer - INFO - Epoch 14, Step 49161: Loss=6.3785, Acc=0.129, 
2025-09-28 15:33:41,585 - training.trainer - INFO - Epoch 14, Step 49261: Loss=6.3029, Acc=0.152, 
2025-09-28 15:33:48,983 - training.trainer - INFO - Epoch 14, Step 49361: Loss=6.3411, Acc=0.258, 
2025-09-28 15:33:56,304 - training.trainer - INFO - Epoch 14, Step 49461: Loss=5.7873, Acc=0.235, 
2025-09-28 15:34:03,613 - training.trainer - INFO - Epoch 14, Step 49561: Loss=6.2920, Acc=0.149, 
2025-09-28 15:34:11,081 - training.trainer - INFO - Epoch 14, Step 49661: Loss=6.6776, Acc=0.206, 
2025-09-28 15:34:18,484 - training.trainer - INFO - Epoch 14, Step 49761: Loss=5.5534, Acc=0.429, 
2025-09-28 15:34:25,851 - training.trainer - INFO - Epoch 14, Step 49861: Loss=4.8346, Acc=0.419, 
2025-09-28 15:34:33,170 - training.trainer - INFO - Epoch 14, Step 49961: Loss=6.0300, Acc=0.158, 
2025-09-28 15:34:40,428 - training.trainer - INFO - Epoch 14, Step 50061: Loss=5.7456, Acc=0.205, 
2025-09-28 15:34:47,648 - training.trainer - INFO - Epoch 14, Step 50161: Loss=5.6392, Acc=0.276, 
2025-09-28 15:34:55,099 - training.trainer - INFO - Epoch 14, Step 50261: Loss=5.5970, Acc=0.294, 
2025-09-28 15:35:02,314 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.9416, Acc=0.176, 
2025-09-28 15:35:09,721 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.5952, Acc=0.240, 
2025-09-28 15:35:17,139 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.6558, Acc=0.237, 
2025-09-28 15:35:24,427 - training.trainer - INFO - Epoch 14, Step 50661: Loss=5.0890, Acc=0.350, 
2025-09-28 15:35:43,641 - training.trainer - INFO - Epoch 15/100 completed in 263.65s - Train Loss: 5.7460, Train Acc: 0.242, Val Loss: 5.7485, Val Acc: 0.238
2025-09-28 15:35:43,987 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-28 15:35:44,657 - training.trainer - INFO - New best model saved with validation loss: 5.7485
2025-09-28 15:35:44,657 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-28 15:35:52,537 - training.trainer - INFO - Epoch 15, Step 50844: Loss=5.4837, Acc=0.321, 
2025-09-28 15:35:59,999 - training.trainer - INFO - Epoch 15, Step 50944: Loss=6.2768, Acc=0.250, 
2025-09-28 15:36:07,583 - training.trainer - INFO - Epoch 15, Step 51044: Loss=6.1670, Acc=0.145, 
2025-09-28 15:36:14,936 - training.trainer - INFO - Epoch 15, Step 51144: Loss=5.4926, Acc=0.333, 
2025-09-28 15:36:22,466 - training.trainer - INFO - Epoch 15, Step 51244: Loss=6.0361, Acc=0.164, 
2025-09-28 15:36:29,985 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.4927, Acc=0.455, 
2025-09-28 15:36:37,386 - training.trainer - INFO - Epoch 15, Step 51444: Loss=5.6206, Acc=0.278, 
2025-09-28 15:36:44,808 - training.trainer - INFO - Epoch 15, Step 51544: Loss=5.5186, Acc=0.210, 
2025-09-28 15:36:52,251 - training.trainer - INFO - Epoch 15, Step 51644: Loss=3.9661, Acc=0.528, 
2025-09-28 15:36:59,609 - training.trainer - INFO - Epoch 15, Step 51744: Loss=5.7089, Acc=0.280, 
2025-09-28 15:37:07,079 - training.trainer - INFO - Epoch 15, Step 51844: Loss=5.6382, Acc=0.179, 
2025-09-28 15:37:14,417 - training.trainer - INFO - Epoch 15, Step 51944: Loss=5.7863, Acc=0.188, 
2025-09-28 15:37:21,826 - training.trainer - INFO - Epoch 15, Step 52044: Loss=5.7038, Acc=0.151, 
2025-09-28 15:37:29,140 - training.trainer - INFO - Epoch 15, Step 52144: Loss=5.6423, Acc=0.292, 
2025-09-28 15:37:36,425 - training.trainer - INFO - Epoch 15, Step 52244: Loss=5.5010, Acc=0.231, 
2025-09-28 15:37:43,996 - training.trainer - INFO - Epoch 15, Step 52344: Loss=6.0544, Acc=0.116, 
2025-09-28 15:37:51,371 - training.trainer - INFO - Epoch 15, Step 52444: Loss=5.9400, Acc=0.154, 
2025-09-28 15:37:58,848 - training.trainer - INFO - Epoch 15, Step 52544: Loss=5.4914, Acc=0.312, 
2025-09-28 15:38:06,161 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.0603, Acc=0.241, 
2025-09-28 15:38:13,538 - training.trainer - INFO - Epoch 15, Step 52744: Loss=6.2301, Acc=0.235, 
2025-09-28 15:38:20,844 - training.trainer - INFO - Epoch 15, Step 52844: Loss=4.8592, Acc=0.250, 
2025-09-28 15:38:28,251 - training.trainer - INFO - Epoch 15, Step 52944: Loss=6.3014, Acc=0.190, 
2025-09-28 15:38:35,535 - training.trainer - INFO - Epoch 15, Step 53044: Loss=6.7048, Acc=0.133, 
2025-09-28 15:38:42,861 - training.trainer - INFO - Epoch 15, Step 53144: Loss=6.4077, Acc=0.148, 
2025-09-28 15:38:50,256 - training.trainer - INFO - Epoch 15, Step 53244: Loss=4.9556, Acc=0.242, 
2025-09-28 15:38:57,603 - training.trainer - INFO - Epoch 15, Step 53344: Loss=6.0160, Acc=0.189, 
2025-09-28 15:39:04,974 - training.trainer - INFO - Epoch 15, Step 53444: Loss=6.0050, Acc=0.277, 
2025-09-28 15:39:12,278 - training.trainer - INFO - Epoch 15, Step 53544: Loss=6.1497, Acc=0.222, 
2025-09-28 15:39:19,588 - training.trainer - INFO - Epoch 15, Step 53644: Loss=5.8371, Acc=0.275, 
2025-09-28 15:39:26,857 - training.trainer - INFO - Epoch 15, Step 53744: Loss=5.5570, Acc=0.250, 
2025-09-28 15:39:34,281 - training.trainer - INFO - Epoch 15, Step 53844: Loss=6.3006, Acc=0.179, 
2025-09-28 15:39:41,746 - training.trainer - INFO - Epoch 15, Step 53944: Loss=5.8277, Acc=0.217, 
2025-09-28 15:39:49,264 - training.trainer - INFO - Epoch 15, Step 54044: Loss=5.6637, Acc=0.310, 
2025-09-28 15:40:08,967 - training.trainer - INFO - Epoch 16/100 completed in 264.31s - Train Loss: 5.7243, Train Acc: 0.245, Val Loss: 5.7388, Val Acc: 0.240
2025-09-28 15:40:09,753 - training.trainer - INFO - New best model saved with validation loss: 5.7388
2025-09-28 15:40:09,754 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-28 15:40:17,741 - training.trainer - INFO - Epoch 16, Step 54227: Loss=6.4780, Acc=0.102, 
2025-09-28 15:40:25,319 - training.trainer - INFO - Epoch 16, Step 54327: Loss=5.5014, Acc=0.271, 
2025-09-28 15:40:32,932 - training.trainer - INFO - Epoch 16, Step 54427: Loss=5.9169, Acc=0.211, 
2025-09-28 15:40:40,433 - training.trainer - INFO - Epoch 16, Step 54527: Loss=5.0649, Acc=0.308, 
2025-09-28 15:40:47,924 - training.trainer - INFO - Epoch 16, Step 54627: Loss=6.1237, Acc=0.179, 
2025-09-28 15:40:55,347 - training.trainer - INFO - Epoch 16, Step 54727: Loss=6.9631, Acc=0.214, 
2025-09-28 15:41:02,587 - training.trainer - INFO - Epoch 16, Step 54827: Loss=6.1372, Acc=0.186, 
2025-09-28 15:41:09,996 - training.trainer - INFO - Epoch 16, Step 54927: Loss=6.2955, Acc=0.184, 
2025-09-28 15:41:17,370 - training.trainer - INFO - Epoch 16, Step 55027: Loss=5.9402, Acc=0.226, 
2025-09-28 15:41:24,581 - training.trainer - INFO - Epoch 16, Step 55127: Loss=6.5545, Acc=0.083, 
2025-09-28 15:41:32,034 - training.trainer - INFO - Epoch 16, Step 55227: Loss=5.2283, Acc=0.286, 
2025-09-28 15:41:39,501 - training.trainer - INFO - Epoch 16, Step 55327: Loss=6.4249, Acc=0.148, 
2025-09-28 15:41:46,873 - training.trainer - INFO - Epoch 16, Step 55427: Loss=6.5610, Acc=0.210, 
2025-09-28 15:41:54,218 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.2415, Acc=0.293, 
2025-09-28 15:42:01,653 - training.trainer - INFO - Epoch 16, Step 55627: Loss=5.8778, Acc=0.310, 
2025-09-28 15:42:09,015 - training.trainer - INFO - Epoch 16, Step 55727: Loss=5.3367, Acc=0.318, 
2025-09-28 15:42:16,564 - training.trainer - INFO - Epoch 16, Step 55827: Loss=5.7741, Acc=0.208, 
2025-09-28 15:42:23,996 - training.trainer - INFO - Epoch 16, Step 55927: Loss=5.7386, Acc=0.375, 
2025-09-28 15:42:31,440 - training.trainer - INFO - Epoch 16, Step 56027: Loss=5.3001, Acc=0.304, 
2025-09-28 15:42:38,972 - training.trainer - INFO - Epoch 16, Step 56127: Loss=5.7405, Acc=0.222, 
2025-09-28 15:42:46,435 - training.trainer - INFO - Epoch 16, Step 56227: Loss=7.0476, Acc=0.200, 
2025-09-28 15:42:53,938 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.3229, Acc=0.182, 
2025-09-28 15:43:01,296 - training.trainer - INFO - Epoch 16, Step 56427: Loss=6.0661, Acc=0.256, 
2025-09-28 15:43:08,685 - training.trainer - INFO - Epoch 16, Step 56527: Loss=6.2767, Acc=0.111, 
2025-09-28 15:43:16,363 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.6275, Acc=0.264, 
2025-09-28 15:43:23,978 - training.trainer - INFO - Epoch 16, Step 56727: Loss=6.1315, Acc=0.214, 
2025-09-28 15:43:31,451 - training.trainer - INFO - Epoch 16, Step 56827: Loss=4.8258, Acc=0.333, 
2025-09-28 15:43:38,912 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.2148, Acc=0.385, 
2025-09-28 15:43:46,278 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.5054, Acc=0.294, 
2025-09-28 15:43:53,838 - training.trainer - INFO - Epoch 16, Step 57127: Loss=5.6679, Acc=0.158, 
2025-09-28 15:44:01,235 - training.trainer - INFO - Epoch 16, Step 57227: Loss=5.8870, Acc=0.222, 
2025-09-28 15:44:08,624 - training.trainer - INFO - Epoch 16, Step 57327: Loss=6.6581, Acc=0.190, 
2025-09-28 15:44:16,181 - training.trainer - INFO - Epoch 16, Step 57427: Loss=5.7694, Acc=0.220, 
2025-09-28 15:44:35,620 - training.trainer - INFO - Epoch 17/100 completed in 265.87s - Train Loss: 5.7052, Train Acc: 0.250, Val Loss: 5.7286, Val Acc: 0.246
2025-09-28 15:44:36,250 - training.trainer - INFO - New best model saved with validation loss: 5.7286
2025-09-28 15:44:36,250 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-28 15:44:43,720 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.0387, Acc=0.382, 
2025-09-28 15:44:51,406 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.9549, Acc=0.203, 
2025-09-28 15:44:59,104 - training.trainer - INFO - Epoch 17, Step 57810: Loss=6.5315, Acc=0.125, 
2025-09-28 15:45:06,588 - training.trainer - INFO - Epoch 17, Step 57910: Loss=5.3747, Acc=0.375, 
2025-09-28 15:45:14,003 - training.trainer - INFO - Epoch 17, Step 58010: Loss=4.7148, Acc=0.450, 
2025-09-28 15:45:21,405 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.9341, Acc=0.370, 
2025-09-28 15:45:28,791 - training.trainer - INFO - Epoch 17, Step 58210: Loss=5.8207, Acc=0.214, 
2025-09-28 15:45:36,223 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.8444, Acc=0.294, 
2025-09-28 15:45:43,576 - training.trainer - INFO - Epoch 17, Step 58410: Loss=6.1177, Acc=0.241, 
2025-09-28 15:45:51,057 - training.trainer - INFO - Epoch 17, Step 58510: Loss=6.0481, Acc=0.273, 
2025-09-28 15:45:58,594 - training.trainer - INFO - Epoch 17, Step 58610: Loss=4.2161, Acc=0.458, 
2025-09-28 15:46:06,221 - training.trainer - INFO - Epoch 17, Step 58710: Loss=5.9115, Acc=0.250, 
2025-09-28 15:46:13,987 - training.trainer - INFO - Epoch 17, Step 58810: Loss=6.3514, Acc=0.273, 
2025-09-28 15:46:21,365 - training.trainer - INFO - Epoch 17, Step 58910: Loss=5.4941, Acc=0.268, 
2025-09-28 15:46:28,657 - training.trainer - INFO - Epoch 17, Step 59010: Loss=5.7810, Acc=0.281, 
2025-09-28 15:46:35,980 - training.trainer - INFO - Epoch 17, Step 59110: Loss=5.8631, Acc=0.238, 
2025-09-28 15:46:43,353 - training.trainer - INFO - Epoch 17, Step 59210: Loss=4.9237, Acc=0.318, 
2025-09-28 15:46:50,701 - training.trainer - INFO - Epoch 17, Step 59310: Loss=4.2687, Acc=0.421, 
2025-09-28 15:46:58,161 - training.trainer - INFO - Epoch 17, Step 59410: Loss=5.9213, Acc=0.180, 
2025-09-28 15:47:05,546 - training.trainer - INFO - Epoch 17, Step 59510: Loss=6.0788, Acc=0.178, 
2025-09-28 15:47:12,882 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.1800, Acc=0.250, 
2025-09-28 15:47:20,246 - training.trainer - INFO - Epoch 17, Step 59710: Loss=6.0244, Acc=0.238, 
2025-09-28 15:47:27,622 - training.trainer - INFO - Epoch 17, Step 59810: Loss=6.9457, Acc=0.125, 
2025-09-28 15:47:34,962 - training.trainer - INFO - Epoch 17, Step 59910: Loss=5.8349, Acc=0.205, 
2025-09-28 15:47:42,281 - training.trainer - INFO - Epoch 17, Step 60010: Loss=5.9707, Acc=0.239, 
2025-09-28 15:47:49,630 - training.trainer - INFO - Epoch 17, Step 60110: Loss=5.7605, Acc=0.173, 
2025-09-28 15:47:56,968 - training.trainer - INFO - Epoch 17, Step 60210: Loss=5.7767, Acc=0.235, 
2025-09-28 15:48:04,417 - training.trainer - INFO - Epoch 17, Step 60310: Loss=6.7448, Acc=0.205, 
2025-09-28 15:48:12,021 - training.trainer - INFO - Epoch 17, Step 60410: Loss=5.2150, Acc=0.205, 
2025-09-28 15:48:19,474 - training.trainer - INFO - Epoch 17, Step 60510: Loss=6.7548, Acc=0.127, 
2025-09-28 15:48:26,838 - training.trainer - INFO - Epoch 17, Step 60610: Loss=5.9164, Acc=0.214, 
2025-09-28 15:48:34,286 - training.trainer - INFO - Epoch 17, Step 60710: Loss=5.5071, Acc=0.226, 
2025-09-28 15:48:42,017 - training.trainer - INFO - Epoch 17, Step 60810: Loss=6.1096, Acc=0.200, 
2025-09-28 15:49:00,914 - training.trainer - INFO - Epoch 18/100 completed in 264.66s - Train Loss: 5.6875, Train Acc: 0.251, Val Loss: 5.7140, Val Acc: 0.246
2025-09-28 15:49:01,520 - training.trainer - INFO - New best model saved with validation loss: 5.7140
2025-09-28 15:49:01,520 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-28 15:49:08,306 - training.trainer - INFO - Epoch 18, Step 60993: Loss=5.6375, Acc=0.238, 
2025-09-28 15:49:14,664 - training.trainer - INFO - Epoch 18, Step 61093: Loss=5.3283, Acc=0.282, 
2025-09-28 15:49:21,338 - training.trainer - INFO - Epoch 18, Step 61193: Loss=5.0821, Acc=0.343, 
2025-09-28 15:49:28,699 - training.trainer - INFO - Epoch 18, Step 61293: Loss=4.7163, Acc=0.387, 
2025-09-28 15:49:36,026 - training.trainer - INFO - Epoch 18, Step 61393: Loss=5.9230, Acc=0.143, 
2025-09-28 15:49:43,615 - training.trainer - INFO - Epoch 18, Step 61493: Loss=6.7893, Acc=0.124, 
2025-09-28 15:49:51,128 - training.trainer - INFO - Epoch 18, Step 61593: Loss=6.6419, Acc=0.125, 
2025-09-28 15:49:58,938 - training.trainer - INFO - Epoch 18, Step 61693: Loss=5.2042, Acc=0.273, 
2025-09-28 15:50:06,494 - training.trainer - INFO - Epoch 18, Step 61793: Loss=6.1689, Acc=0.190, 
2025-09-28 15:50:13,752 - training.trainer - INFO - Epoch 18, Step 61893: Loss=4.8716, Acc=0.238, 
2025-09-28 15:50:20,949 - training.trainer - INFO - Epoch 18, Step 61993: Loss=5.5093, Acc=0.200, 
2025-09-28 15:50:28,289 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.9395, Acc=0.238, 
2025-09-28 15:50:35,714 - training.trainer - INFO - Epoch 18, Step 62193: Loss=6.3775, Acc=0.231, 
2025-09-28 15:50:43,207 - training.trainer - INFO - Epoch 18, Step 62293: Loss=5.3906, Acc=0.421, 
2025-09-28 15:50:50,592 - training.trainer - INFO - Epoch 18, Step 62393: Loss=6.3144, Acc=0.132, 
2025-09-28 15:50:58,084 - training.trainer - INFO - Epoch 18, Step 62493: Loss=6.8625, Acc=0.130, 
2025-09-28 15:51:05,504 - training.trainer - INFO - Epoch 18, Step 62593: Loss=6.2454, Acc=0.259, 
2025-09-28 15:51:13,018 - training.trainer - INFO - Epoch 18, Step 62693: Loss=5.5001, Acc=0.250, 
2025-09-28 15:51:20,483 - training.trainer - INFO - Epoch 18, Step 62793: Loss=4.7197, Acc=0.355, 
2025-09-28 15:51:27,860 - training.trainer - INFO - Epoch 18, Step 62893: Loss=5.1685, Acc=0.257, 
2025-09-28 15:51:35,188 - training.trainer - INFO - Epoch 18, Step 62993: Loss=5.9366, Acc=0.281, 
2025-09-28 15:51:42,595 - training.trainer - INFO - Epoch 18, Step 63093: Loss=5.8794, Acc=0.231, 
2025-09-28 15:51:49,963 - training.trainer - INFO - Epoch 18, Step 63193: Loss=6.6935, Acc=0.183, 
2025-09-28 15:51:57,235 - training.trainer - INFO - Epoch 18, Step 63293: Loss=6.4140, Acc=0.143, 
2025-09-28 15:52:04,391 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.0825, Acc=0.348, 
2025-09-28 15:52:11,942 - training.trainer - INFO - Epoch 18, Step 63493: Loss=5.9065, Acc=0.237, 
2025-09-28 15:52:19,334 - training.trainer - INFO - Epoch 18, Step 63593: Loss=5.4727, Acc=0.323, 
2025-09-28 15:52:26,580 - training.trainer - INFO - Epoch 18, Step 63693: Loss=5.4351, Acc=0.241, 
2025-09-28 15:52:33,863 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.0749, Acc=0.312, 
2025-09-28 15:52:41,395 - training.trainer - INFO - Epoch 18, Step 63893: Loss=4.8397, Acc=0.458, 
2025-09-28 15:52:48,793 - training.trainer - INFO - Epoch 18, Step 63993: Loss=5.6292, Acc=0.256, 
2025-09-28 15:52:56,044 - training.trainer - INFO - Epoch 18, Step 64093: Loss=5.2939, Acc=0.200, 
2025-09-28 15:53:03,289 - training.trainer - INFO - Epoch 18, Step 64193: Loss=6.0701, Acc=0.239, 
2025-09-28 15:53:22,191 - training.trainer - INFO - Epoch 19/100 completed in 260.67s - Train Loss: 5.6619, Train Acc: 0.254, Val Loss: 5.7014, Val Acc: 0.249
2025-09-28 15:53:22,924 - training.trainer - INFO - New best model saved with validation loss: 5.7014
2025-09-28 15:53:22,924 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-28 15:53:30,615 - training.trainer - INFO - Epoch 19, Step 64376: Loss=5.3986, Acc=0.259, 
2025-09-28 15:53:38,000 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.6273, Acc=0.286, 
2025-09-28 15:53:45,755 - training.trainer - INFO - Epoch 19, Step 64576: Loss=5.9362, Acc=0.233, 
2025-09-28 15:53:53,137 - training.trainer - INFO - Epoch 19, Step 64676: Loss=5.9106, Acc=0.220, 
2025-09-28 15:54:00,540 - training.trainer - INFO - Epoch 19, Step 64776: Loss=5.0635, Acc=0.290, 
2025-09-28 15:54:07,912 - training.trainer - INFO - Epoch 19, Step 64876: Loss=6.6079, Acc=0.143, 
2025-09-28 15:54:15,269 - training.trainer - INFO - Epoch 19, Step 64976: Loss=4.3552, Acc=0.417, 
2025-09-28 15:54:22,755 - training.trainer - INFO - Epoch 19, Step 65076: Loss=6.3760, Acc=0.194, 
2025-09-28 15:54:30,169 - training.trainer - INFO - Epoch 19, Step 65176: Loss=6.0405, Acc=0.229, 
2025-09-28 15:54:37,433 - training.trainer - INFO - Epoch 19, Step 65276: Loss=5.4234, Acc=0.345, 
2025-09-28 15:54:44,795 - training.trainer - INFO - Epoch 19, Step 65376: Loss=6.1197, Acc=0.203, 
2025-09-28 15:54:52,230 - training.trainer - INFO - Epoch 19, Step 65476: Loss=5.8351, Acc=0.188, 
2025-09-28 15:54:59,561 - training.trainer - INFO - Epoch 19, Step 65576: Loss=6.1872, Acc=0.214, 
2025-09-28 15:55:06,897 - training.trainer - INFO - Epoch 19, Step 65676: Loss=5.9751, Acc=0.273, 
2025-09-28 15:55:14,241 - training.trainer - INFO - Epoch 19, Step 65776: Loss=6.7605, Acc=0.216, 
2025-09-28 15:55:21,567 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.8675, Acc=0.182, 
2025-09-28 15:55:29,015 - training.trainer - INFO - Epoch 19, Step 65976: Loss=4.7528, Acc=0.321, 
2025-09-28 15:55:36,385 - training.trainer - INFO - Epoch 19, Step 66076: Loss=6.0437, Acc=0.234, 
2025-09-28 15:55:43,682 - training.trainer - INFO - Epoch 19, Step 66176: Loss=4.6824, Acc=0.350, 
2025-09-28 15:55:51,105 - training.trainer - INFO - Epoch 19, Step 66276: Loss=4.3999, Acc=0.400, 
2025-09-28 15:55:58,602 - training.trainer - INFO - Epoch 19, Step 66376: Loss=4.7205, Acc=0.342, 
2025-09-28 15:56:06,102 - training.trainer - INFO - Epoch 19, Step 66476: Loss=5.5402, Acc=0.139, 
2025-09-28 15:56:13,510 - training.trainer - INFO - Epoch 19, Step 66576: Loss=4.2813, Acc=0.458, 
2025-09-28 15:56:20,874 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.2173, Acc=0.259, 
2025-09-28 15:56:28,446 - training.trainer - INFO - Epoch 19, Step 66776: Loss=5.5926, Acc=0.296, 
2025-09-28 15:56:35,996 - training.trainer - INFO - Epoch 19, Step 66876: Loss=6.3039, Acc=0.104, 
2025-09-28 15:56:43,567 - training.trainer - INFO - Epoch 19, Step 66976: Loss=5.6923, Acc=0.250, 
2025-09-28 15:56:50,997 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.3067, Acc=0.296, 
2025-09-28 15:56:58,365 - training.trainer - INFO - Epoch 19, Step 67176: Loss=5.8359, Acc=0.167, 
2025-09-28 15:57:05,832 - training.trainer - INFO - Epoch 19, Step 67276: Loss=5.1978, Acc=0.250, 
2025-09-28 15:57:13,250 - training.trainer - INFO - Epoch 19, Step 67376: Loss=5.8519, Acc=0.206, 
2025-09-28 15:57:20,492 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.6816, Acc=0.217, 
2025-09-28 15:57:27,724 - training.trainer - INFO - Epoch 19, Step 67576: Loss=6.1125, Acc=0.159, 
2025-09-28 15:57:46,153 - training.trainer - INFO - Epoch 20/100 completed in 263.23s - Train Loss: 5.6379, Train Acc: 0.257, Val Loss: 5.6929, Val Acc: 0.249
2025-09-28 15:57:46,509 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-28 15:57:47,156 - training.trainer - INFO - New best model saved with validation loss: 5.6929
2025-09-28 15:57:47,157 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-28 15:57:54,992 - training.trainer - INFO - Epoch 20, Step 67759: Loss=5.9513, Acc=0.357, 
2025-09-28 15:58:02,360 - training.trainer - INFO - Epoch 20, Step 67859: Loss=6.7135, Acc=0.139, 
2025-09-28 15:58:09,711 - training.trainer - INFO - Epoch 20, Step 67959: Loss=5.9309, Acc=0.242, 
2025-09-28 15:58:16,987 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.9912, Acc=0.220, 
2025-09-28 15:58:24,281 - training.trainer - INFO - Epoch 20, Step 68159: Loss=6.0040, Acc=0.211, 
2025-09-28 15:58:31,642 - training.trainer - INFO - Epoch 20, Step 68259: Loss=5.5683, Acc=0.211, 
2025-09-28 15:58:38,919 - training.trainer - INFO - Epoch 20, Step 68359: Loss=6.0928, Acc=0.284, 
2025-09-28 15:58:46,160 - training.trainer - INFO - Epoch 20, Step 68459: Loss=5.4565, Acc=0.318, 
2025-09-28 15:58:53,548 - training.trainer - INFO - Epoch 20, Step 68559: Loss=6.1242, Acc=0.219, 
2025-09-28 15:59:01,046 - training.trainer - INFO - Epoch 20, Step 68659: Loss=6.5694, Acc=0.200, 
2025-09-28 15:59:08,317 - training.trainer - INFO - Epoch 20, Step 68759: Loss=6.0832, Acc=0.184, 
2025-09-28 15:59:15,638 - training.trainer - INFO - Epoch 20, Step 68859: Loss=5.9324, Acc=0.277, 
2025-09-28 15:59:22,877 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.9138, Acc=0.242, 
2025-09-28 15:59:30,248 - training.trainer - INFO - Epoch 20, Step 69059: Loss=5.5650, Acc=0.343, 
2025-09-28 15:59:37,756 - training.trainer - INFO - Epoch 20, Step 69159: Loss=5.1846, Acc=0.344, 
2025-09-28 15:59:45,149 - training.trainer - INFO - Epoch 20, Step 69259: Loss=5.8006, Acc=0.333, 
2025-09-28 15:59:52,410 - training.trainer - INFO - Epoch 20, Step 69359: Loss=5.5661, Acc=0.263, 
2025-09-28 15:59:59,646 - training.trainer - INFO - Epoch 20, Step 69459: Loss=5.2641, Acc=0.290, 
2025-09-28 16:00:06,925 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.2088, Acc=0.333, 
2025-09-28 16:00:14,181 - training.trainer - INFO - Epoch 20, Step 69659: Loss=6.0060, Acc=0.294, 
2025-09-28 16:00:21,468 - training.trainer - INFO - Epoch 20, Step 69759: Loss=5.7317, Acc=0.167, 
2025-09-28 16:00:28,710 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.5086, Acc=0.278, 
2025-09-28 16:00:35,928 - training.trainer - INFO - Epoch 20, Step 69959: Loss=6.3433, Acc=0.267, 
2025-09-28 16:00:43,184 - training.trainer - INFO - Epoch 20, Step 70059: Loss=5.6258, Acc=0.246, 
2025-09-28 16:00:50,484 - training.trainer - INFO - Epoch 20, Step 70159: Loss=6.2880, Acc=0.158, 
2025-09-28 16:00:57,890 - training.trainer - INFO - Epoch 20, Step 70259: Loss=4.5448, Acc=0.292, 
2025-09-28 16:01:05,432 - training.trainer - INFO - Epoch 20, Step 70359: Loss=5.6795, Acc=0.348, 
2025-09-28 16:01:12,879 - training.trainer - INFO - Epoch 20, Step 70459: Loss=6.0112, Acc=0.311, 
2025-09-28 16:01:20,376 - training.trainer - INFO - Epoch 20, Step 70559: Loss=4.9812, Acc=0.348, 
2025-09-28 16:01:27,768 - training.trainer - INFO - Epoch 20, Step 70659: Loss=6.0444, Acc=0.224, 
2025-09-28 16:01:35,062 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.8655, Acc=0.222, 
2025-09-28 16:01:42,308 - training.trainer - INFO - Epoch 20, Step 70859: Loss=5.3725, Acc=0.273, 
2025-09-28 16:01:49,566 - training.trainer - INFO - Epoch 20, Step 70959: Loss=6.0837, Acc=0.189, 
2025-09-28 16:02:08,365 - training.trainer - INFO - Epoch 21/100 completed in 261.21s - Train Loss: 5.6225, Train Acc: 0.260, Val Loss: 5.6942, Val Acc: 0.248
2025-09-28 16:02:15,622 - training.trainer - INFO - Epoch 21, Step 71142: Loss=5.3787, Acc=0.275, 
2025-09-28 16:02:22,329 - training.trainer - INFO - Epoch 21, Step 71242: Loss=5.8481, Acc=0.229, 
2025-09-28 16:02:29,510 - training.trainer - INFO - Epoch 21, Step 71342: Loss=3.9052, Acc=0.391, 
2025-09-28 16:02:36,955 - training.trainer - INFO - Epoch 21, Step 71442: Loss=5.8765, Acc=0.348, 
2025-09-28 16:02:44,343 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.8082, Acc=0.195, 
2025-09-28 16:02:51,702 - training.trainer - INFO - Epoch 21, Step 71642: Loss=5.6626, Acc=0.381, 
2025-09-28 16:02:59,206 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.5314, Acc=0.175, 
2025-09-28 16:03:06,808 - training.trainer - INFO - Epoch 21, Step 71842: Loss=5.4857, Acc=0.315, 
2025-09-28 16:03:14,365 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.7318, Acc=0.179, 
2025-09-28 16:03:21,883 - training.trainer - INFO - Epoch 21, Step 72042: Loss=5.9351, Acc=0.182, 
2025-09-28 16:03:29,600 - training.trainer - INFO - Epoch 21, Step 72142: Loss=5.8152, Acc=0.216, 
2025-09-28 16:03:37,150 - training.trainer - INFO - Epoch 21, Step 72242: Loss=6.2989, Acc=0.218, 
2025-09-28 16:03:44,531 - training.trainer - INFO - Epoch 21, Step 72342: Loss=5.5576, Acc=0.227, 
2025-09-28 16:03:52,001 - training.trainer - INFO - Epoch 21, Step 72442: Loss=6.3222, Acc=0.133, 
2025-09-28 16:03:59,418 - training.trainer - INFO - Epoch 21, Step 72542: Loss=4.9510, Acc=0.300, 
2025-09-28 16:04:06,990 - training.trainer - INFO - Epoch 21, Step 72642: Loss=6.1576, Acc=0.200, 
2025-09-28 16:04:14,342 - training.trainer - INFO - Epoch 21, Step 72742: Loss=4.4490, Acc=0.462, 
2025-09-28 16:04:21,805 - training.trainer - INFO - Epoch 21, Step 72842: Loss=5.8813, Acc=0.213, 
2025-09-28 16:04:29,200 - training.trainer - INFO - Epoch 21, Step 72942: Loss=6.8092, Acc=0.288, 
2025-09-28 16:04:36,574 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.3457, Acc=0.295, 
2025-09-28 16:04:44,064 - training.trainer - INFO - Epoch 21, Step 73142: Loss=5.0693, Acc=0.441, 
2025-09-28 16:04:51,506 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.6909, Acc=0.211, 
2025-09-28 16:04:58,837 - training.trainer - INFO - Epoch 21, Step 73342: Loss=6.0245, Acc=0.208, 
2025-09-28 16:05:06,235 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.6617, Acc=0.244, 
2025-09-28 16:05:13,829 - training.trainer - INFO - Epoch 21, Step 73542: Loss=5.2056, Acc=0.333, 
2025-09-28 16:05:21,656 - training.trainer - INFO - Epoch 21, Step 73642: Loss=3.7875, Acc=0.481, 
2025-09-28 16:05:29,035 - training.trainer - INFO - Epoch 21, Step 73742: Loss=5.9641, Acc=0.164, 
2025-09-28 16:05:36,366 - training.trainer - INFO - Epoch 21, Step 73842: Loss=5.9922, Acc=0.175, 
2025-09-28 16:05:43,840 - training.trainer - INFO - Epoch 21, Step 73942: Loss=5.2168, Acc=0.241, 
2025-09-28 16:05:51,323 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.3835, Acc=0.250, 
2025-09-28 16:05:59,053 - training.trainer - INFO - Epoch 21, Step 74142: Loss=5.3580, Acc=0.385, 
2025-09-28 16:06:06,495 - training.trainer - INFO - Epoch 21, Step 74242: Loss=4.5190, Acc=0.350, 
2025-09-28 16:06:13,932 - training.trainer - INFO - Epoch 21, Step 74342: Loss=5.4616, Acc=0.283, 
2025-09-28 16:06:32,631 - training.trainer - INFO - Epoch 22/100 completed in 264.26s - Train Loss: 5.5999, Train Acc: 0.264, Val Loss: 5.6748, Val Acc: 0.254
2025-09-28 16:06:33,484 - training.trainer - INFO - New best model saved with validation loss: 5.6748
2025-09-28 16:06:33,485 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-09-28 16:06:41,463 - training.trainer - INFO - Epoch 22, Step 74525: Loss=5.8524, Acc=0.333, 
2025-09-28 16:06:48,897 - training.trainer - INFO - Epoch 22, Step 74625: Loss=5.5653, Acc=0.212, 
2025-09-28 16:06:56,464 - training.trainer - INFO - Epoch 22, Step 74725: Loss=4.2539, Acc=0.371, 
2025-09-28 16:07:03,941 - training.trainer - INFO - Epoch 22, Step 74825: Loss=4.2702, Acc=0.250, 
2025-09-28 16:07:11,479 - training.trainer - INFO - Epoch 22, Step 74925: Loss=5.9468, Acc=0.278, 
2025-09-28 16:07:18,979 - training.trainer - INFO - Epoch 22, Step 75025: Loss=5.7416, Acc=0.233, 
2025-09-28 16:07:26,488 - training.trainer - INFO - Epoch 22, Step 75125: Loss=3.9829, Acc=0.346, 
2025-09-28 16:07:33,894 - training.trainer - INFO - Epoch 22, Step 75225: Loss=3.1365, Acc=0.609, 
2025-09-28 16:07:41,351 - training.trainer - INFO - Epoch 22, Step 75325: Loss=5.0784, Acc=0.300, 
2025-09-28 16:07:48,791 - training.trainer - INFO - Epoch 22, Step 75425: Loss=4.4493, Acc=0.429, 
2025-09-28 16:07:56,376 - training.trainer - INFO - Epoch 22, Step 75525: Loss=5.5208, Acc=0.357, 
2025-09-28 16:08:03,783 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.7358, Acc=0.216, 
2025-09-28 16:08:11,544 - training.trainer - INFO - Epoch 22, Step 75725: Loss=5.7966, Acc=0.269, 
2025-09-28 16:08:19,014 - training.trainer - INFO - Epoch 22, Step 75825: Loss=5.9496, Acc=0.208, 
2025-09-28 16:08:26,510 - training.trainer - INFO - Epoch 22, Step 75925: Loss=5.8661, Acc=0.267, 
2025-09-28 16:08:33,917 - training.trainer - INFO - Epoch 22, Step 76025: Loss=5.9367, Acc=0.306, 
2025-09-28 16:08:41,219 - training.trainer - INFO - Epoch 22, Step 76125: Loss=5.9332, Acc=0.250, 
2025-09-28 16:08:48,536 - training.trainer - INFO - Epoch 22, Step 76225: Loss=6.2234, Acc=0.204, 
2025-09-28 16:08:55,943 - training.trainer - INFO - Epoch 22, Step 76325: Loss=5.9956, Acc=0.304, 
2025-09-28 16:09:03,425 - training.trainer - INFO - Epoch 22, Step 76425: Loss=4.8973, Acc=0.280, 
2025-09-28 16:09:10,876 - training.trainer - INFO - Epoch 22, Step 76525: Loss=6.5346, Acc=0.172, 
2025-09-28 16:09:18,464 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.6936, Acc=0.290, 
2025-09-28 16:09:25,862 - training.trainer - INFO - Epoch 22, Step 76725: Loss=6.0904, Acc=0.164, 
2025-09-28 16:09:33,217 - training.trainer - INFO - Epoch 22, Step 76825: Loss=5.6418, Acc=0.296, 
2025-09-28 16:09:40,641 - training.trainer - INFO - Epoch 22, Step 76925: Loss=6.9494, Acc=0.186, 
2025-09-28 16:09:48,058 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.9113, Acc=0.213, 
2025-09-28 16:09:55,382 - training.trainer - INFO - Epoch 22, Step 77125: Loss=6.0720, Acc=0.238, 
2025-09-28 16:10:02,727 - training.trainer - INFO - Epoch 22, Step 77225: Loss=5.5218, Acc=0.318, 
2025-09-28 16:10:10,093 - training.trainer - INFO - Epoch 22, Step 77325: Loss=5.6063, Acc=0.219, 
2025-09-28 16:10:17,390 - training.trainer - INFO - Epoch 22, Step 77425: Loss=4.4382, Acc=0.350, 
2025-09-28 16:10:24,706 - training.trainer - INFO - Epoch 22, Step 77525: Loss=5.8967, Acc=0.282, 
2025-09-28 16:10:32,081 - training.trainer - INFO - Epoch 22, Step 77625: Loss=5.6965, Acc=0.118, 
2025-09-28 16:10:39,406 - training.trainer - INFO - Epoch 22, Step 77725: Loss=5.6245, Acc=0.245, 
2025-09-28 16:10:58,215 - training.trainer - INFO - Epoch 23/100 completed in 264.73s - Train Loss: 5.5792, Train Acc: 0.267, Val Loss: 5.6775, Val Acc: 0.252
2025-09-28 16:11:05,151 - training.trainer - INFO - Epoch 23, Step 77908: Loss=6.0207, Acc=0.179, 
2025-09-28 16:11:11,706 - training.trainer - INFO - Epoch 23, Step 78008: Loss=5.3142, Acc=0.238, 
2025-09-28 16:11:18,072 - training.trainer - INFO - Epoch 23, Step 78108: Loss=5.9959, Acc=0.212, 
2025-09-28 16:11:24,371 - training.trainer - INFO - Epoch 23, Step 78208: Loss=4.0585, Acc=0.462, 
2025-09-28 16:11:30,761 - training.trainer - INFO - Epoch 23, Step 78308: Loss=6.6775, Acc=0.154, 
2025-09-28 16:11:37,176 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.7858, Acc=0.140, 
2025-09-28 16:11:44,652 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.7670, Acc=0.222, 
2025-09-28 16:11:52,340 - training.trainer - INFO - Epoch 23, Step 78608: Loss=5.1676, Acc=0.265, 
2025-09-28 16:11:59,770 - training.trainer - INFO - Epoch 23, Step 78708: Loss=5.1554, Acc=0.375, 
2025-09-28 16:12:07,425 - training.trainer - INFO - Epoch 23, Step 78808: Loss=6.0253, Acc=0.229, 
2025-09-28 16:12:14,979 - training.trainer - INFO - Epoch 23, Step 78908: Loss=4.1542, Acc=0.448, 
2025-09-28 16:12:22,627 - training.trainer - INFO - Epoch 23, Step 79008: Loss=5.7411, Acc=0.222, 
2025-09-28 16:12:30,311 - training.trainer - INFO - Epoch 23, Step 79108: Loss=6.1504, Acc=0.143, 
2025-09-28 16:12:37,866 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.6093, Acc=0.261, 
2025-09-28 16:12:45,281 - training.trainer - INFO - Epoch 23, Step 79308: Loss=6.1216, Acc=0.188, 
2025-09-28 16:12:52,777 - training.trainer - INFO - Epoch 23, Step 79408: Loss=6.2157, Acc=0.171, 
2025-09-28 16:13:00,128 - training.trainer - INFO - Epoch 23, Step 79508: Loss=5.0209, Acc=0.323, 
2025-09-28 16:13:07,609 - training.trainer - INFO - Epoch 23, Step 79608: Loss=4.7138, Acc=0.350, 
2025-09-28 16:13:15,040 - training.trainer - INFO - Epoch 23, Step 79708: Loss=6.0191, Acc=0.167, 
2025-09-28 16:13:22,666 - training.trainer - INFO - Epoch 23, Step 79808: Loss=4.9244, Acc=0.324, 
2025-09-28 16:13:30,294 - training.trainer - INFO - Epoch 23, Step 79908: Loss=6.4166, Acc=0.151, 
2025-09-28 16:13:37,785 - training.trainer - INFO - Epoch 23, Step 80008: Loss=4.6291, Acc=0.355, 
2025-09-28 16:13:45,134 - training.trainer - INFO - Epoch 23, Step 80108: Loss=6.0438, Acc=0.240, 
2025-09-28 16:13:52,523 - training.trainer - INFO - Epoch 23, Step 80208: Loss=6.2117, Acc=0.184, 
2025-09-28 16:14:00,070 - training.trainer - INFO - Epoch 23, Step 80308: Loss=5.8771, Acc=0.184, 
2025-09-28 16:14:07,518 - training.trainer - INFO - Epoch 23, Step 80408: Loss=6.0146, Acc=0.200, 
2025-09-28 16:14:14,951 - training.trainer - INFO - Epoch 23, Step 80508: Loss=5.7729, Acc=0.263, 
2025-09-28 16:14:22,298 - training.trainer - INFO - Epoch 23, Step 80608: Loss=5.6612, Acc=0.269, 
2025-09-28 16:14:29,900 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.0390, Acc=0.500, 
2025-09-28 16:14:37,465 - training.trainer - INFO - Epoch 23, Step 80808: Loss=6.0797, Acc=0.219, 
2025-09-28 16:14:44,958 - training.trainer - INFO - Epoch 23, Step 80908: Loss=5.7961, Acc=0.220, 
2025-09-28 16:14:52,546 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.8647, Acc=0.209, 
2025-09-28 16:15:00,104 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.9636, Acc=0.256, 
2025-09-28 16:15:19,106 - training.trainer - INFO - Epoch 24/100 completed in 260.89s - Train Loss: 5.5552, Train Acc: 0.270, Val Loss: 5.6753, Val Acc: 0.253
2025-09-28 16:15:27,553 - training.trainer - INFO - Epoch 24, Step 81291: Loss=5.3423, Acc=0.306, 
2025-09-28 16:15:35,220 - training.trainer - INFO - Epoch 24, Step 81391: Loss=5.4651, Acc=0.295, 
2025-09-28 16:15:42,991 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.5203, Acc=0.268, 
2025-09-28 16:15:50,515 - training.trainer - INFO - Epoch 24, Step 81591: Loss=5.0927, Acc=0.341, 
2025-09-28 16:15:57,988 - training.trainer - INFO - Epoch 24, Step 81691: Loss=5.4177, Acc=0.237, 
2025-09-28 16:16:05,438 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.5934, Acc=0.300, 
2025-09-28 16:16:12,778 - training.trainer - INFO - Epoch 24, Step 81891: Loss=4.9022, Acc=0.333, 
2025-09-28 16:16:20,056 - training.trainer - INFO - Epoch 24, Step 81991: Loss=4.7792, Acc=0.333, 
2025-09-28 16:16:27,385 - training.trainer - INFO - Epoch 24, Step 82091: Loss=4.7805, Acc=0.273, 
2025-09-28 16:16:34,726 - training.trainer - INFO - Epoch 24, Step 82191: Loss=6.1905, Acc=0.204, 
2025-09-28 16:16:42,133 - training.trainer - INFO - Epoch 24, Step 82291: Loss=5.7459, Acc=0.300, 
2025-09-28 16:16:49,544 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.1752, Acc=0.467, 
2025-09-28 16:16:56,972 - training.trainer - INFO - Epoch 24, Step 82491: Loss=4.1764, Acc=0.512, 
2025-09-28 16:17:04,321 - training.trainer - INFO - Epoch 24, Step 82591: Loss=6.3498, Acc=0.209, 
2025-09-28 16:17:11,664 - training.trainer - INFO - Epoch 24, Step 82691: Loss=3.4138, Acc=0.600, 
2025-09-28 16:17:19,088 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.9554, Acc=0.213, 
2025-09-28 16:17:26,379 - training.trainer - INFO - Epoch 24, Step 82891: Loss=5.6219, Acc=0.115, 
2025-09-28 16:17:33,724 - training.trainer - INFO - Epoch 24, Step 82991: Loss=5.7876, Acc=0.222, 
2025-09-28 16:17:41,029 - training.trainer - INFO - Epoch 24, Step 83091: Loss=5.3872, Acc=0.208, 
2025-09-28 16:17:48,398 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.9343, Acc=0.196, 
2025-09-28 16:17:55,677 - training.trainer - INFO - Epoch 24, Step 83291: Loss=5.8030, Acc=0.208, 
2025-09-28 16:18:03,124 - training.trainer - INFO - Epoch 24, Step 83391: Loss=5.7845, Acc=0.196, 
2025-09-28 16:18:10,481 - training.trainer - INFO - Epoch 24, Step 83491: Loss=6.2056, Acc=0.184, 
2025-09-28 16:18:17,821 - training.trainer - INFO - Epoch 24, Step 83591: Loss=5.9372, Acc=0.256, 
2025-09-28 16:18:25,145 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.6844, Acc=0.214, 
2025-09-28 16:18:32,479 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.7022, Acc=0.294, 
2025-09-28 16:18:39,822 - training.trainer - INFO - Epoch 24, Step 83891: Loss=4.9947, Acc=0.308, 
2025-09-28 16:18:47,258 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.3159, Acc=0.400, 
2025-09-28 16:18:54,716 - training.trainer - INFO - Epoch 24, Step 84091: Loss=6.4914, Acc=0.154, 
2025-09-28 16:19:02,179 - training.trainer - INFO - Epoch 24, Step 84191: Loss=6.3975, Acc=0.200, 
2025-09-28 16:19:09,615 - training.trainer - INFO - Epoch 24, Step 84291: Loss=5.7814, Acc=0.226, 
2025-09-28 16:19:16,923 - training.trainer - INFO - Epoch 24, Step 84391: Loss=5.5239, Acc=0.222, 
2025-09-28 16:19:24,584 - training.trainer - INFO - Epoch 24, Step 84491: Loss=5.1346, Acc=0.333, 
2025-09-28 16:19:43,906 - training.trainer - INFO - Epoch 25/100 completed in 264.80s - Train Loss: 5.5402, Train Acc: 0.271, Val Loss: 5.6575, Val Acc: 0.259
2025-09-28 16:19:44,241 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-28 16:19:44,936 - training.trainer - INFO - New best model saved with validation loss: 5.6575
2025-09-28 16:19:44,936 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-28 16:19:53,144 - training.trainer - INFO - Epoch 25, Step 84674: Loss=6.1471, Acc=0.216, 
2025-09-28 16:20:00,669 - training.trainer - INFO - Epoch 25, Step 84774: Loss=5.6003, Acc=0.263, 
2025-09-28 16:20:08,067 - training.trainer - INFO - Epoch 25, Step 84874: Loss=5.4601, Acc=0.256, 
2025-09-28 16:20:15,400 - training.trainer - INFO - Epoch 25, Step 84974: Loss=4.6389, Acc=0.441, 
2025-09-28 16:20:22,697 - training.trainer - INFO - Epoch 25, Step 85074: Loss=5.7956, Acc=0.208, 
2025-09-28 16:20:30,143 - training.trainer - INFO - Epoch 25, Step 85174: Loss=5.6558, Acc=0.200, 
2025-09-28 16:20:37,521 - training.trainer - INFO - Epoch 25, Step 85274: Loss=4.2808, Acc=0.500, 
2025-09-28 16:20:44,860 - training.trainer - INFO - Epoch 25, Step 85374: Loss=6.6446, Acc=0.220, 
2025-09-28 16:20:52,407 - training.trainer - INFO - Epoch 25, Step 85474: Loss=6.1568, Acc=0.277, 
2025-09-28 16:20:59,883 - training.trainer - INFO - Epoch 25, Step 85574: Loss=5.7732, Acc=0.267, 
2025-09-28 16:21:07,416 - training.trainer - INFO - Epoch 25, Step 85674: Loss=5.9516, Acc=0.232, 
2025-09-28 16:21:14,815 - training.trainer - INFO - Epoch 25, Step 85774: Loss=5.5725, Acc=0.269, 
2025-09-28 16:21:22,205 - training.trainer - INFO - Epoch 25, Step 85874: Loss=6.4719, Acc=0.171, 
2025-09-28 16:21:29,623 - training.trainer - INFO - Epoch 25, Step 85974: Loss=4.5674, Acc=0.357, 
2025-09-28 16:21:37,184 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.7798, Acc=0.250, 
2025-09-28 16:21:44,817 - training.trainer - INFO - Epoch 25, Step 86174: Loss=6.4228, Acc=0.149, 
2025-09-28 16:21:52,239 - training.trainer - INFO - Epoch 25, Step 86274: Loss=5.6214, Acc=0.250, 
2025-09-28 16:21:59,628 - training.trainer - INFO - Epoch 25, Step 86374: Loss=6.3278, Acc=0.194, 
2025-09-28 16:22:06,961 - training.trainer - INFO - Epoch 25, Step 86474: Loss=6.3045, Acc=0.169, 
2025-09-28 16:22:14,413 - training.trainer - INFO - Epoch 25, Step 86574: Loss=5.6441, Acc=0.294, 
2025-09-28 16:22:21,812 - training.trainer - INFO - Epoch 25, Step 86674: Loss=6.2073, Acc=0.150, 
2025-09-28 16:22:29,178 - training.trainer - INFO - Epoch 25, Step 86774: Loss=3.9321, Acc=0.586, 
2025-09-28 16:22:36,621 - training.trainer - INFO - Epoch 25, Step 86874: Loss=5.6024, Acc=0.250, 
2025-09-28 16:22:44,091 - training.trainer - INFO - Epoch 25, Step 86974: Loss=4.9525, Acc=0.292, 
2025-09-28 16:22:51,399 - training.trainer - INFO - Epoch 25, Step 87074: Loss=5.5413, Acc=0.222, 
2025-09-28 16:22:58,834 - training.trainer - INFO - Epoch 25, Step 87174: Loss=5.2360, Acc=0.320, 
2025-09-28 16:23:06,196 - training.trainer - INFO - Epoch 25, Step 87274: Loss=6.1548, Acc=0.263, 
2025-09-28 16:23:13,651 - training.trainer - INFO - Epoch 25, Step 87374: Loss=6.0346, Acc=0.172, 
2025-09-28 16:23:21,011 - training.trainer - INFO - Epoch 25, Step 87474: Loss=6.0008, Acc=0.192, 
2025-09-28 16:23:28,391 - training.trainer - INFO - Epoch 25, Step 87574: Loss=6.1101, Acc=0.219, 
2025-09-28 16:23:35,936 - training.trainer - INFO - Epoch 25, Step 87674: Loss=5.3687, Acc=0.250, 
2025-09-28 16:23:43,400 - training.trainer - INFO - Epoch 25, Step 87774: Loss=4.3933, Acc=0.467, 
2025-09-28 16:23:51,006 - training.trainer - INFO - Epoch 25, Step 87874: Loss=2.7054, Acc=0.714, 
2025-09-28 16:24:10,416 - training.trainer - INFO - Epoch 26/100 completed in 265.48s - Train Loss: 5.5224, Train Acc: 0.275, Val Loss: 5.6743, Val Acc: 0.256
2025-09-28 16:24:18,581 - training.trainer - INFO - Epoch 26, Step 88057: Loss=6.0152, Acc=0.196, 
2025-09-28 16:24:26,222 - training.trainer - INFO - Epoch 26, Step 88157: Loss=4.9240, Acc=0.333, 
2025-09-28 16:24:33,674 - training.trainer - INFO - Epoch 26, Step 88257: Loss=6.1601, Acc=0.271, 
2025-09-28 16:24:41,032 - training.trainer - INFO - Epoch 26, Step 88357: Loss=6.0541, Acc=0.231, 
2025-09-28 16:24:48,367 - training.trainer - INFO - Epoch 26, Step 88457: Loss=5.2980, Acc=0.167, 
2025-09-28 16:24:55,819 - training.trainer - INFO - Epoch 26, Step 88557: Loss=6.2320, Acc=0.173, 
2025-09-28 16:25:03,214 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.6611, Acc=0.244, 
2025-09-28 16:25:10,911 - training.trainer - INFO - Epoch 26, Step 88757: Loss=5.6012, Acc=0.278, 
2025-09-28 16:25:18,293 - training.trainer - INFO - Epoch 26, Step 88857: Loss=6.0670, Acc=0.213, 
2025-09-28 16:25:25,738 - training.trainer - INFO - Epoch 26, Step 88957: Loss=6.0613, Acc=0.250, 
2025-09-28 16:25:33,140 - training.trainer - INFO - Epoch 26, Step 89057: Loss=6.5952, Acc=0.184, 
2025-09-28 16:25:40,583 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.7955, Acc=0.196, 
2025-09-28 16:25:47,931 - training.trainer - INFO - Epoch 26, Step 89257: Loss=4.4740, Acc=0.400, 
2025-09-28 16:25:55,253 - training.trainer - INFO - Epoch 26, Step 89357: Loss=6.6055, Acc=0.179, 
2025-09-28 16:26:02,676 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.1011, Acc=0.355, 
2025-09-28 16:26:10,057 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.7296, Acc=0.254, 
2025-09-28 16:26:17,609 - training.trainer - INFO - Epoch 26, Step 89657: Loss=5.0657, Acc=0.292, 
2025-09-28 16:26:25,113 - training.trainer - INFO - Epoch 26, Step 89757: Loss=5.4252, Acc=0.286, 
2025-09-28 16:26:32,743 - training.trainer - INFO - Epoch 26, Step 89857: Loss=6.2014, Acc=0.216, 
2025-09-28 16:26:40,400 - training.trainer - INFO - Epoch 26, Step 89957: Loss=6.0814, Acc=0.187, 
2025-09-28 16:26:47,836 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.6846, Acc=0.324, 
2025-09-28 16:26:55,151 - training.trainer - INFO - Epoch 26, Step 90157: Loss=5.9240, Acc=0.231, 
2025-09-28 16:27:02,440 - training.trainer - INFO - Epoch 26, Step 90257: Loss=3.3049, Acc=0.636, 
2025-09-28 16:27:09,784 - training.trainer - INFO - Epoch 26, Step 90357: Loss=5.3301, Acc=0.303, 
2025-09-28 16:27:17,029 - training.trainer - INFO - Epoch 26, Step 90457: Loss=5.5192, Acc=0.229, 
2025-09-28 16:27:24,229 - training.trainer - INFO - Epoch 26, Step 90557: Loss=4.4235, Acc=0.500, 
2025-09-28 16:27:31,508 - training.trainer - INFO - Epoch 26, Step 90657: Loss=4.0250, Acc=0.550, 
2025-09-28 16:27:38,845 - training.trainer - INFO - Epoch 26, Step 90757: Loss=5.7248, Acc=0.227, 
2025-09-28 16:27:46,091 - training.trainer - INFO - Epoch 26, Step 90857: Loss=6.4413, Acc=0.140, 
2025-09-28 16:27:53,582 - training.trainer - INFO - Epoch 26, Step 90957: Loss=5.1890, Acc=0.261, 
2025-09-28 16:28:01,125 - training.trainer - INFO - Epoch 26, Step 91057: Loss=4.8867, Acc=0.304, 
2025-09-28 16:28:08,581 - training.trainer - INFO - Epoch 26, Step 91157: Loss=6.2035, Acc=0.189, 
2025-09-28 16:28:16,186 - training.trainer - INFO - Epoch 26, Step 91257: Loss=3.3239, Acc=0.455, 
2025-09-28 16:28:35,110 - training.trainer - INFO - Epoch 27/100 completed in 264.69s - Train Loss: 5.5071, Train Acc: 0.278, Val Loss: 5.6734, Val Acc: 0.255
2025-09-28 16:28:43,145 - training.trainer - INFO - Epoch 27, Step 91440: Loss=4.9171, Acc=0.367, 
2025-09-28 16:28:50,601 - training.trainer - INFO - Epoch 27, Step 91540: Loss=5.3670, Acc=0.346, 
2025-09-28 16:28:57,879 - training.trainer - INFO - Epoch 27, Step 91640: Loss=5.4772, Acc=0.263, 
2025-09-28 16:29:05,138 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.8551, Acc=0.188, 
2025-09-28 16:29:12,402 - training.trainer - INFO - Epoch 27, Step 91840: Loss=5.9680, Acc=0.269, 
2025-09-28 16:29:19,714 - training.trainer - INFO - Epoch 27, Step 91940: Loss=4.7962, Acc=0.571, 
2025-09-28 16:29:26,958 - training.trainer - INFO - Epoch 27, Step 92040: Loss=5.9101, Acc=0.210, 
2025-09-28 16:29:34,251 - training.trainer - INFO - Epoch 27, Step 92140: Loss=5.1084, Acc=0.312, 
2025-09-28 16:29:41,625 - training.trainer - INFO - Epoch 27, Step 92240: Loss=5.5172, Acc=0.293, 
2025-09-28 16:29:48,981 - training.trainer - INFO - Epoch 27, Step 92340: Loss=4.7315, Acc=0.400, 
2025-09-28 16:29:56,277 - training.trainer - INFO - Epoch 27, Step 92440: Loss=6.2111, Acc=0.156, 
2025-09-28 16:30:03,596 - training.trainer - INFO - Epoch 27, Step 92540: Loss=5.0487, Acc=0.462, 
2025-09-28 16:30:10,881 - training.trainer - INFO - Epoch 27, Step 92640: Loss=5.7939, Acc=0.222, 
2025-09-28 16:30:18,182 - training.trainer - INFO - Epoch 27, Step 92740: Loss=4.9781, Acc=0.367, 
2025-09-28 16:30:25,479 - training.trainer - INFO - Epoch 27, Step 92840: Loss=5.7148, Acc=0.280, 
2025-09-28 16:30:32,811 - training.trainer - INFO - Epoch 27, Step 92940: Loss=3.3380, Acc=0.609, 
2025-09-28 16:30:40,090 - training.trainer - INFO - Epoch 27, Step 93040: Loss=4.8549, Acc=0.381, 
2025-09-28 16:30:47,376 - training.trainer - INFO - Epoch 27, Step 93140: Loss=5.4503, Acc=0.250, 
2025-09-28 16:30:54,700 - training.trainer - INFO - Epoch 27, Step 93240: Loss=4.8961, Acc=0.331, 
2025-09-28 16:31:02,023 - training.trainer - INFO - Epoch 27, Step 93340: Loss=6.0025, Acc=0.217, 
2025-09-28 16:31:09,413 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.6667, Acc=0.182, 
2025-09-28 16:31:16,700 - training.trainer - INFO - Epoch 27, Step 93540: Loss=5.7404, Acc=0.200, 
2025-09-28 16:31:24,263 - training.trainer - INFO - Epoch 27, Step 93640: Loss=6.6042, Acc=0.122, 
2025-09-28 16:31:31,661 - training.trainer - INFO - Epoch 27, Step 93740: Loss=3.0794, Acc=0.476, 
2025-09-28 16:31:38,984 - training.trainer - INFO - Epoch 27, Step 93840: Loss=4.6636, Acc=0.440, 
2025-09-28 16:31:46,228 - training.trainer - INFO - Epoch 27, Step 93940: Loss=5.4802, Acc=0.243, 
2025-09-28 16:31:53,558 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.6027, Acc=0.231, 
2025-09-28 16:32:00,841 - training.trainer - INFO - Epoch 27, Step 94140: Loss=6.2028, Acc=0.128, 
2025-09-28 16:32:08,087 - training.trainer - INFO - Epoch 27, Step 94240: Loss=5.4459, Acc=0.265, 
2025-09-28 16:32:15,414 - training.trainer - INFO - Epoch 27, Step 94340: Loss=6.1491, Acc=0.189, 
2025-09-28 16:32:22,820 - training.trainer - INFO - Epoch 27, Step 94440: Loss=5.8327, Acc=0.216, 
2025-09-28 16:32:30,035 - training.trainer - INFO - Epoch 27, Step 94540: Loss=5.9072, Acc=0.235, 
2025-09-28 16:32:37,513 - training.trainer - INFO - Epoch 27, Step 94640: Loss=4.8600, Acc=0.299, 
2025-09-28 16:32:56,718 - training.trainer - INFO - Epoch 28/100 completed in 261.61s - Train Loss: 5.4923, Train Acc: 0.280, Val Loss: 5.6615, Val Acc: 0.255
2025-09-28 16:33:04,488 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.7460, Acc=0.348, 
2025-09-28 16:33:11,769 - training.trainer - INFO - Epoch 28, Step 94923: Loss=6.1396, Acc=0.269, 
2025-09-28 16:33:19,187 - training.trainer - INFO - Epoch 28, Step 95023: Loss=5.1921, Acc=0.222, 
2025-09-28 16:33:26,621 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.9292, Acc=0.265, 
2025-09-28 16:33:33,876 - training.trainer - INFO - Epoch 28, Step 95223: Loss=6.5203, Acc=0.128, 
2025-09-28 16:33:41,264 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.5120, Acc=0.333, 
2025-09-28 16:33:48,915 - training.trainer - INFO - Epoch 28, Step 95423: Loss=5.6805, Acc=0.224, 
2025-09-28 16:33:56,222 - training.trainer - INFO - Epoch 28, Step 95523: Loss=5.4924, Acc=0.267, 
2025-09-28 16:34:03,493 - training.trainer - INFO - Epoch 28, Step 95623: Loss=5.5456, Acc=0.222, 
2025-09-28 16:34:10,800 - training.trainer - INFO - Epoch 28, Step 95723: Loss=6.5267, Acc=0.221, 
2025-09-28 16:34:18,110 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.5161, Acc=0.314, 
2025-09-28 16:34:25,335 - training.trainer - INFO - Epoch 28, Step 95923: Loss=5.8079, Acc=0.160, 
2025-09-28 16:34:32,690 - training.trainer - INFO - Epoch 28, Step 96023: Loss=4.2523, Acc=0.444, 
2025-09-28 16:34:40,017 - training.trainer - INFO - Epoch 28, Step 96123: Loss=6.0760, Acc=0.257, 
2025-09-28 16:34:47,433 - training.trainer - INFO - Epoch 28, Step 96223: Loss=5.0427, Acc=0.273, 
2025-09-28 16:34:54,797 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.4883, Acc=0.194, 
2025-09-28 16:35:02,256 - training.trainer - INFO - Epoch 28, Step 96423: Loss=6.1964, Acc=0.185, 
2025-09-28 16:35:09,541 - training.trainer - INFO - Epoch 28, Step 96523: Loss=5.5190, Acc=0.288, 
2025-09-28 16:35:17,142 - training.trainer - INFO - Epoch 28, Step 96623: Loss=5.3906, Acc=0.343, 
2025-09-28 16:35:24,690 - training.trainer - INFO - Epoch 28, Step 96723: Loss=5.1484, Acc=0.205, 
2025-09-28 16:35:32,420 - training.trainer - INFO - Epoch 28, Step 96823: Loss=5.1577, Acc=0.346, 
2025-09-28 16:35:39,753 - training.trainer - INFO - Epoch 28, Step 96923: Loss=4.9792, Acc=0.381, 
2025-09-28 16:35:47,262 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.4637, Acc=0.254, 
2025-09-28 16:35:54,738 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.2496, Acc=0.235, 
2025-09-28 16:36:02,146 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.1870, Acc=0.263, 
2025-09-28 16:36:09,484 - training.trainer - INFO - Epoch 28, Step 97323: Loss=5.8313, Acc=0.176, 
2025-09-28 16:36:16,936 - training.trainer - INFO - Epoch 28, Step 97423: Loss=6.2835, Acc=0.273, 
2025-09-28 16:36:24,573 - training.trainer - INFO - Epoch 28, Step 97523: Loss=6.1471, Acc=0.262, 
2025-09-28 16:36:32,207 - training.trainer - INFO - Epoch 28, Step 97623: Loss=4.6634, Acc=0.383, 
2025-09-28 16:36:39,752 - training.trainer - INFO - Epoch 28, Step 97723: Loss=5.6190, Acc=0.286, 
2025-09-28 16:36:47,146 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.9584, Acc=0.229, 
2025-09-28 16:36:54,571 - training.trainer - INFO - Epoch 28, Step 97923: Loss=6.2732, Acc=0.184, 
2025-09-28 16:37:02,055 - training.trainer - INFO - Epoch 28, Step 98023: Loss=5.6968, Acc=0.244, 
2025-09-28 16:37:21,271 - training.trainer - INFO - Epoch 29/100 completed in 264.55s - Train Loss: 5.4739, Train Acc: 0.283, Val Loss: 5.6609, Val Acc: 0.259
2025-09-28 16:37:29,158 - training.trainer - INFO - Epoch 29, Step 98206: Loss=5.8928, Acc=0.167, 
2025-09-28 16:37:36,560 - training.trainer - INFO - Epoch 29, Step 98306: Loss=2.9588, Acc=0.731, 
2025-09-28 16:37:44,045 - training.trainer - INFO - Epoch 29, Step 98406: Loss=5.6409, Acc=0.217, 
2025-09-28 16:37:51,514 - training.trainer - INFO - Epoch 29, Step 98506: Loss=4.8827, Acc=0.290, 
2025-09-28 16:37:58,659 - training.trainer - INFO - Epoch 29, Step 98606: Loss=4.7605, Acc=0.333, 
2025-09-28 16:38:05,803 - training.trainer - INFO - Epoch 29, Step 98706: Loss=5.3353, Acc=0.250, 
2025-09-28 16:38:13,093 - training.trainer - INFO - Epoch 29, Step 98806: Loss=6.1574, Acc=0.250, 
2025-09-28 16:38:20,366 - training.trainer - INFO - Epoch 29, Step 98906: Loss=5.9125, Acc=0.193, 
2025-09-28 16:38:27,698 - training.trainer - INFO - Epoch 29, Step 99006: Loss=5.7702, Acc=0.349, 
2025-09-28 16:38:35,077 - training.trainer - INFO - Epoch 29, Step 99106: Loss=4.9879, Acc=0.357, 
2025-09-28 16:38:42,418 - training.trainer - INFO - Epoch 29, Step 99206: Loss=5.2119, Acc=0.200, 
2025-09-28 16:38:50,258 - training.trainer - INFO - Epoch 29, Step 99306: Loss=5.7440, Acc=0.167, 
2025-09-28 16:38:57,497 - training.trainer - INFO - Epoch 29, Step 99406: Loss=5.3642, Acc=0.243, 
2025-09-28 16:39:04,778 - training.trainer - INFO - Epoch 29, Step 99506: Loss=6.0018, Acc=0.230, 
2025-09-28 16:39:11,955 - training.trainer - INFO - Epoch 29, Step 99606: Loss=6.3016, Acc=0.143, 
2025-09-28 16:39:19,192 - training.trainer - INFO - Epoch 29, Step 99706: Loss=5.0550, Acc=0.235, 
2025-09-28 16:39:26,458 - training.trainer - INFO - Epoch 29, Step 99806: Loss=6.1032, Acc=0.265, 
2025-09-28 16:39:33,821 - training.trainer - INFO - Epoch 29, Step 99906: Loss=6.6395, Acc=0.165, 
2025-09-28 16:39:41,170 - training.trainer - INFO - Epoch 29, Step 100006: Loss=5.7483, Acc=0.216, 
2025-09-28 16:39:48,463 - training.trainer - INFO - Epoch 29, Step 100106: Loss=5.7676, Acc=0.273, 
2025-09-28 16:39:55,791 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.2000, Acc=0.297, 
2025-09-28 16:40:03,057 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.6305, Acc=0.158, 
2025-09-28 16:40:10,417 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.8442, Acc=0.240, 
2025-09-28 16:40:17,707 - training.trainer - INFO - Epoch 29, Step 100506: Loss=6.0952, Acc=0.274, 
2025-09-28 16:40:25,037 - training.trainer - INFO - Epoch 29, Step 100606: Loss=6.5358, Acc=0.189, 
2025-09-28 16:40:32,425 - training.trainer - INFO - Epoch 29, Step 100706: Loss=5.1469, Acc=0.320, 
2025-09-28 16:40:39,668 - training.trainer - INFO - Epoch 29, Step 100806: Loss=4.8163, Acc=0.342, 
2025-09-28 16:40:46,900 - training.trainer - INFO - Epoch 29, Step 100906: Loss=5.0472, Acc=0.300, 
2025-09-28 16:40:54,246 - training.trainer - INFO - Epoch 29, Step 101006: Loss=5.7081, Acc=0.278, 
2025-09-28 16:41:01,545 - training.trainer - INFO - Epoch 29, Step 101106: Loss=5.4029, Acc=0.345, 
2025-09-28 16:41:08,821 - training.trainer - INFO - Epoch 29, Step 101206: Loss=5.9045, Acc=0.296, 
2025-09-28 16:41:16,111 - training.trainer - INFO - Epoch 29, Step 101306: Loss=3.5878, Acc=0.593, 
2025-09-28 16:41:23,505 - training.trainer - INFO - Epoch 29, Step 101406: Loss=5.9109, Acc=0.244, 
2025-09-28 16:41:41,971 - training.trainer - INFO - Epoch 30/100 completed in 260.70s - Train Loss: 5.4561, Train Acc: 0.285, Val Loss: 5.6580, Val Acc: 0.258
2025-09-28 16:41:42,335 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-28 16:41:50,129 - training.trainer - INFO - Epoch 30, Step 101589: Loss=5.9089, Acc=0.242, 
2025-09-28 16:41:57,761 - training.trainer - INFO - Epoch 30, Step 101689: Loss=5.5171, Acc=0.268, 
2025-09-28 16:42:05,277 - training.trainer - INFO - Epoch 30, Step 101789: Loss=5.5572, Acc=0.284, 
2025-09-28 16:42:12,694 - training.trainer - INFO - Epoch 30, Step 101889: Loss=4.0803, Acc=0.385, 
2025-09-28 16:42:19,990 - training.trainer - INFO - Epoch 30, Step 101989: Loss=5.5939, Acc=0.341, 
2025-09-28 16:42:27,379 - training.trainer - INFO - Epoch 30, Step 102089: Loss=5.4835, Acc=0.208, 
2025-09-28 16:42:35,054 - training.trainer - INFO - Epoch 30, Step 102189: Loss=3.2619, Acc=0.579, 
2025-09-28 16:42:42,542 - training.trainer - INFO - Epoch 30, Step 102289: Loss=5.8665, Acc=0.231, 
2025-09-28 16:42:49,877 - training.trainer - INFO - Epoch 30, Step 102389: Loss=6.2590, Acc=0.156, 
2025-09-28 16:42:57,205 - training.trainer - INFO - Epoch 30, Step 102489: Loss=4.5943, Acc=0.306, 
2025-09-28 16:43:04,653 - training.trainer - INFO - Epoch 30, Step 102589: Loss=4.7375, Acc=0.474, 
2025-09-28 16:43:12,059 - training.trainer - INFO - Epoch 30, Step 102689: Loss=6.3760, Acc=0.226, 
2025-09-28 16:43:19,554 - training.trainer - INFO - Epoch 30, Step 102789: Loss=5.4620, Acc=0.333, 
2025-09-28 16:43:27,226 - training.trainer - INFO - Epoch 30, Step 102889: Loss=4.7575, Acc=0.279, 
2025-09-28 16:43:34,569 - training.trainer - INFO - Epoch 30, Step 102989: Loss=6.2863, Acc=0.190, 
2025-09-28 16:43:41,902 - training.trainer - INFO - Epoch 30, Step 103089: Loss=4.8338, Acc=0.333, 
2025-09-28 16:43:49,211 - training.trainer - INFO - Epoch 30, Step 103189: Loss=3.8829, Acc=0.400, 
2025-09-28 16:43:56,570 - training.trainer - INFO - Epoch 30, Step 103289: Loss=5.6519, Acc=0.281, 
2025-09-28 16:44:03,905 - training.trainer - INFO - Epoch 30, Step 103389: Loss=5.2363, Acc=0.389, 
2025-09-28 16:44:11,227 - training.trainer - INFO - Epoch 30, Step 103489: Loss=4.7927, Acc=0.306, 
2025-09-28 16:44:18,510 - training.trainer - INFO - Epoch 30, Step 103589: Loss=4.0976, Acc=0.452, 
2025-09-28 16:44:25,877 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.5694, Acc=0.318, 
2025-09-28 16:44:33,174 - training.trainer - INFO - Epoch 30, Step 103789: Loss=5.1444, Acc=0.333, 
2025-09-28 16:44:40,763 - training.trainer - INFO - Epoch 30, Step 103889: Loss=5.3538, Acc=0.345, 
2025-09-28 16:44:48,075 - training.trainer - INFO - Epoch 30, Step 103989: Loss=6.1181, Acc=0.316, 
2025-09-28 16:44:55,381 - training.trainer - INFO - Epoch 30, Step 104089: Loss=5.3806, Acc=0.256, 
2025-09-28 16:45:02,761 - training.trainer - INFO - Epoch 30, Step 104189: Loss=5.4729, Acc=0.279, 
2025-09-28 16:45:10,456 - training.trainer - INFO - Epoch 30, Step 104289: Loss=5.1498, Acc=0.237, 
2025-09-28 16:45:18,016 - training.trainer - INFO - Epoch 30, Step 104389: Loss=6.1465, Acc=0.203, 
2025-09-28 16:45:25,516 - training.trainer - INFO - Epoch 30, Step 104489: Loss=6.2146, Acc=0.261, 
2025-09-28 16:45:32,934 - training.trainer - INFO - Epoch 30, Step 104589: Loss=5.8616, Acc=0.216, 
2025-09-28 16:45:40,549 - training.trainer - INFO - Epoch 30, Step 104689: Loss=5.6028, Acc=0.324, 
2025-09-28 16:45:48,150 - training.trainer - INFO - Epoch 30, Step 104789: Loss=5.8452, Acc=0.143, 
2025-09-28 16:46:07,976 - training.trainer - INFO - Epoch 31/100 completed in 265.64s - Train Loss: 5.4366, Train Acc: 0.289, Val Loss: 5.6604, Val Acc: 0.256
2025-09-28 16:46:15,717 - training.trainer - INFO - Epoch 31, Step 104972: Loss=3.8408, Acc=0.500, 
2025-09-28 16:46:23,333 - training.trainer - INFO - Epoch 31, Step 105072: Loss=6.8799, Acc=0.167, 
2025-09-28 16:46:30,975 - training.trainer - INFO - Epoch 31, Step 105172: Loss=4.8774, Acc=0.320, 
2025-09-28 16:46:38,558 - training.trainer - INFO - Epoch 31, Step 105272: Loss=5.8726, Acc=0.212, 
2025-09-28 16:46:46,115 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.0366, Acc=0.265, 
2025-09-28 16:46:53,607 - training.trainer - INFO - Epoch 31, Step 105472: Loss=6.0119, Acc=0.244, 
2025-09-28 16:47:01,072 - training.trainer - INFO - Epoch 31, Step 105572: Loss=4.7408, Acc=0.325, 
2025-09-28 16:47:08,483 - training.trainer - INFO - Epoch 31, Step 105672: Loss=5.3002, Acc=0.250, 
2025-09-28 16:47:16,024 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.9642, Acc=0.147, 
2025-09-28 16:47:23,398 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.6934, Acc=0.213, 
2025-09-28 16:47:30,907 - training.trainer - INFO - Epoch 31, Step 105972: Loss=4.3597, Acc=0.433, 
2025-09-28 16:47:38,491 - training.trainer - INFO - Epoch 31, Step 106072: Loss=4.5686, Acc=0.455, 
2025-09-28 16:47:45,925 - training.trainer - INFO - Epoch 31, Step 106172: Loss=6.4143, Acc=0.216, 
2025-09-28 16:47:53,466 - training.trainer - INFO - Epoch 31, Step 106272: Loss=5.0303, Acc=0.250, 
2025-09-28 16:48:00,923 - training.trainer - INFO - Epoch 31, Step 106372: Loss=6.0195, Acc=0.211, 
2025-09-28 16:48:08,434 - training.trainer - INFO - Epoch 31, Step 106472: Loss=4.7365, Acc=0.414, 
2025-09-28 16:48:15,916 - training.trainer - INFO - Epoch 31, Step 106572: Loss=5.4780, Acc=0.265, 
2025-09-28 16:48:23,507 - training.trainer - INFO - Epoch 31, Step 106672: Loss=5.8615, Acc=0.244, 
2025-09-28 16:48:31,018 - training.trainer - INFO - Epoch 31, Step 106772: Loss=4.9822, Acc=0.280, 
2025-09-28 16:48:38,687 - training.trainer - INFO - Epoch 31, Step 106872: Loss=5.4422, Acc=0.263, 
2025-09-28 16:48:46,052 - training.trainer - INFO - Epoch 31, Step 106972: Loss=4.5444, Acc=0.400, 
2025-09-28 16:48:53,319 - training.trainer - INFO - Epoch 31, Step 107072: Loss=3.9469, Acc=0.438, 
2025-09-28 16:49:00,702 - training.trainer - INFO - Epoch 31, Step 107172: Loss=5.3971, Acc=0.316, 
2025-09-28 16:49:08,167 - training.trainer - INFO - Epoch 31, Step 107272: Loss=5.5416, Acc=0.304, 
2025-09-28 16:49:15,455 - training.trainer - INFO - Epoch 31, Step 107372: Loss=4.4519, Acc=0.409, 
2025-09-28 16:49:22,770 - training.trainer - INFO - Epoch 31, Step 107472: Loss=5.6915, Acc=0.238, 
2025-09-28 16:49:30,145 - training.trainer - INFO - Epoch 31, Step 107572: Loss=5.5963, Acc=0.224, 
2025-09-28 16:49:37,486 - training.trainer - INFO - Epoch 31, Step 107672: Loss=5.1700, Acc=0.231, 
2025-09-28 16:49:45,080 - training.trainer - INFO - Epoch 31, Step 107772: Loss=5.6174, Acc=0.231, 
2025-09-28 16:49:52,415 - training.trainer - INFO - Epoch 31, Step 107872: Loss=5.8093, Acc=0.273, 
2025-09-28 16:49:59,694 - training.trainer - INFO - Epoch 31, Step 107972: Loss=5.4441, Acc=0.261, 
2025-09-28 16:50:07,010 - training.trainer - INFO - Epoch 31, Step 108072: Loss=4.8735, Acc=0.353, 
2025-09-28 16:50:14,514 - training.trainer - INFO - Epoch 31, Step 108172: Loss=6.0780, Acc=0.163, 
2025-09-28 16:50:33,077 - training.trainer - INFO - Epoch 32/100 completed in 265.10s - Train Loss: 5.4199, Train Acc: 0.291, Val Loss: 5.6681, Val Acc: 0.257
2025-09-28 16:50:39,774 - training.trainer - INFO - Epoch 32, Step 108355: Loss=5.4568, Acc=0.310, 
2025-09-28 16:50:46,124 - training.trainer - INFO - Epoch 32, Step 108455: Loss=3.7791, Acc=0.593, 
2025-09-28 16:50:53,090 - training.trainer - INFO - Epoch 32, Step 108555: Loss=5.6239, Acc=0.294, 
2025-09-28 16:51:00,301 - training.trainer - INFO - Epoch 32, Step 108655: Loss=5.0192, Acc=0.317, 
2025-09-28 16:51:07,657 - training.trainer - INFO - Epoch 32, Step 108755: Loss=5.9274, Acc=0.232, 
2025-09-28 16:51:14,911 - training.trainer - INFO - Epoch 32, Step 108855: Loss=4.3065, Acc=0.419, 
2025-09-28 16:51:22,296 - training.trainer - INFO - Epoch 32, Step 108955: Loss=4.5343, Acc=0.475, 
2025-09-28 16:51:29,674 - training.trainer - INFO - Epoch 32, Step 109055: Loss=5.8787, Acc=0.147, 
2025-09-28 16:51:36,881 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.4084, Acc=0.294, 
2025-09-28 16:51:44,246 - training.trainer - INFO - Epoch 32, Step 109255: Loss=5.2665, Acc=0.270, 
2025-09-28 16:51:51,872 - training.trainer - INFO - Epoch 32, Step 109355: Loss=5.7519, Acc=0.237, 
2025-09-28 16:51:59,377 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.6317, Acc=0.250, 
2025-09-28 16:52:06,631 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.2690, Acc=0.200, 
2025-09-28 16:52:14,267 - training.trainer - INFO - Epoch 32, Step 109655: Loss=3.0747, Acc=0.700, 
2025-09-28 16:52:22,049 - training.trainer - INFO - Epoch 32, Step 109755: Loss=5.7871, Acc=0.268, 
2025-09-28 16:52:29,839 - training.trainer - INFO - Epoch 32, Step 109855: Loss=6.0077, Acc=0.231, 
2025-09-28 16:52:37,425 - training.trainer - INFO - Epoch 32, Step 109955: Loss=4.9498, Acc=0.333, 
2025-09-28 16:52:44,966 - training.trainer - INFO - Epoch 32, Step 110055: Loss=5.4558, Acc=0.289, 
2025-09-28 16:52:52,574 - training.trainer - INFO - Epoch 32, Step 110155: Loss=5.7625, Acc=0.265, 
2025-09-28 16:53:00,101 - training.trainer - INFO - Epoch 32, Step 110255: Loss=4.9916, Acc=0.351, 
2025-09-28 16:53:07,448 - training.trainer - INFO - Epoch 32, Step 110355: Loss=5.3556, Acc=0.351, 
2025-09-28 16:53:14,832 - training.trainer - INFO - Epoch 32, Step 110455: Loss=4.7887, Acc=0.419, 
2025-09-28 16:53:22,267 - training.trainer - INFO - Epoch 32, Step 110555: Loss=5.8204, Acc=0.250, 
2025-09-28 16:53:29,622 - training.trainer - INFO - Epoch 32, Step 110655: Loss=3.2696, Acc=0.667, 
2025-09-28 16:53:37,040 - training.trainer - INFO - Epoch 32, Step 110755: Loss=3.7527, Acc=0.524, 
2025-09-28 16:53:44,387 - training.trainer - INFO - Epoch 32, Step 110855: Loss=4.5877, Acc=0.375, 
2025-09-28 16:53:51,819 - training.trainer - INFO - Epoch 32, Step 110955: Loss=4.2320, Acc=0.440, 
2025-09-28 16:53:59,186 - training.trainer - INFO - Epoch 32, Step 111055: Loss=5.0183, Acc=0.500, 
2025-09-28 16:54:06,668 - training.trainer - INFO - Epoch 32, Step 111155: Loss=5.6257, Acc=0.242, 
2025-09-28 16:54:14,048 - training.trainer - INFO - Epoch 32, Step 111255: Loss=4.9394, Acc=0.364, 
2025-09-28 16:54:21,486 - training.trainer - INFO - Epoch 32, Step 111355: Loss=5.3080, Acc=0.310, 
2025-09-28 16:54:28,862 - training.trainer - INFO - Epoch 32, Step 111455: Loss=6.0616, Acc=0.200, 
2025-09-28 16:54:36,229 - training.trainer - INFO - Epoch 32, Step 111555: Loss=5.1422, Acc=0.406, 
2025-09-28 16:54:55,193 - training.trainer - INFO - Epoch 33/100 completed in 262.12s - Train Loss: 5.3999, Train Acc: 0.294, Val Loss: 5.6620, Val Acc: 0.258
2025-09-28 16:55:02,536 - training.trainer - INFO - Epoch 33, Step 111738: Loss=6.0208, Acc=0.185, 
2025-09-28 16:55:10,087 - training.trainer - INFO - Epoch 33, Step 111838: Loss=5.5960, Acc=0.296, 
2025-09-28 16:55:17,742 - training.trainer - INFO - Epoch 33, Step 111938: Loss=4.9637, Acc=0.314, 
2025-09-28 16:55:25,274 - training.trainer - INFO - Epoch 33, Step 112038: Loss=4.7560, Acc=0.381, 
2025-09-28 16:55:32,904 - training.trainer - INFO - Epoch 33, Step 112138: Loss=6.1202, Acc=0.143, 
2025-09-28 16:55:40,443 - training.trainer - INFO - Epoch 33, Step 112238: Loss=5.0793, Acc=0.429, 
2025-09-28 16:55:48,036 - training.trainer - INFO - Epoch 33, Step 112338: Loss=5.1031, Acc=0.280, 
2025-09-28 16:55:55,559 - training.trainer - INFO - Epoch 33, Step 112438: Loss=5.4630, Acc=0.272, 
2025-09-28 16:56:03,094 - training.trainer - INFO - Epoch 33, Step 112538: Loss=5.6351, Acc=0.261, 
2025-09-28 16:56:10,602 - training.trainer - INFO - Epoch 33, Step 112638: Loss=4.8258, Acc=0.342, 
2025-09-28 16:56:18,157 - training.trainer - INFO - Epoch 33, Step 112738: Loss=4.8609, Acc=0.367, 
2025-09-28 16:56:25,704 - training.trainer - INFO - Epoch 33, Step 112838: Loss=5.5385, Acc=0.333, 
2025-09-28 16:56:33,060 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.0743, Acc=0.280, 
2025-09-28 16:56:40,447 - training.trainer - INFO - Epoch 33, Step 113038: Loss=4.2963, Acc=0.345, 
2025-09-28 16:56:47,855 - training.trainer - INFO - Epoch 33, Step 113138: Loss=5.9097, Acc=0.217, 
2025-09-28 16:56:55,347 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.8276, Acc=0.250, 
2025-09-28 16:57:02,917 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.2930, Acc=0.357, 
2025-09-28 16:57:10,170 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.5945, Acc=0.314, 
2025-09-28 16:57:17,403 - training.trainer - INFO - Epoch 33, Step 113538: Loss=5.4142, Acc=0.258, 
2025-09-28 16:57:24,670 - training.trainer - INFO - Epoch 33, Step 113638: Loss=5.8618, Acc=0.250, 
2025-09-28 16:57:31,849 - training.trainer - INFO - Epoch 33, Step 113738: Loss=4.5360, Acc=0.452, 
2025-09-28 16:57:39,080 - training.trainer - INFO - Epoch 33, Step 113838: Loss=5.1760, Acc=0.303, 
2025-09-28 16:57:46,285 - training.trainer - INFO - Epoch 33, Step 113938: Loss=5.7435, Acc=0.186, 
2025-09-28 16:57:53,504 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.5488, Acc=0.360, 
2025-09-28 16:58:00,810 - training.trainer - INFO - Epoch 33, Step 114138: Loss=5.8511, Acc=0.308, 
2025-09-28 16:58:08,049 - training.trainer - INFO - Epoch 33, Step 114238: Loss=5.2515, Acc=0.407, 
2025-09-28 16:58:15,401 - training.trainer - INFO - Epoch 33, Step 114338: Loss=6.0927, Acc=0.239, 
2025-09-28 16:58:22,620 - training.trainer - INFO - Epoch 33, Step 114438: Loss=5.2957, Acc=0.207, 
2025-09-28 16:58:29,822 - training.trainer - INFO - Epoch 33, Step 114538: Loss=4.6243, Acc=0.385, 
2025-09-28 16:58:37,004 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.8864, Acc=0.250, 
2025-09-28 16:58:44,300 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.3252, Acc=0.302, 
2025-09-28 16:58:51,594 - training.trainer - INFO - Epoch 33, Step 114838: Loss=5.7082, Acc=0.176, 
2025-09-28 16:58:58,841 - training.trainer - INFO - Epoch 33, Step 114938: Loss=3.6486, Acc=0.421, 
2025-09-28 16:59:17,400 - training.trainer - INFO - Epoch 34/100 completed in 262.21s - Train Loss: 5.3859, Train Acc: 0.296, Val Loss: 5.6555, Val Acc: 0.261
2025-09-28 16:59:18,006 - training.trainer - INFO - New best model saved with validation loss: 5.6555
2025-09-28 16:59:18,007 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_34.pt
2025-09-28 16:59:25,988 - training.trainer - INFO - Epoch 34, Step 115121: Loss=6.2979, Acc=0.171, 
2025-09-28 16:59:33,285 - training.trainer - INFO - Epoch 34, Step 115221: Loss=3.6234, Acc=0.600, 
2025-09-28 16:59:40,600 - training.trainer - INFO - Epoch 34, Step 115321: Loss=5.5771, Acc=0.235, 
2025-09-28 16:59:47,810 - training.trainer - INFO - Epoch 34, Step 115421: Loss=5.1960, Acc=0.312, 
2025-09-28 16:59:55,063 - training.trainer - INFO - Epoch 34, Step 115521: Loss=6.1695, Acc=0.233, 
2025-09-28 17:00:02,408 - training.trainer - INFO - Epoch 34, Step 115621: Loss=5.3488, Acc=0.275, 
2025-09-28 17:00:09,623 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.5580, Acc=0.310, 
2025-09-28 17:00:17,077 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.0514, Acc=0.357, 
2025-09-28 17:00:24,655 - training.trainer - INFO - Epoch 34, Step 115921: Loss=4.8881, Acc=0.268, 
2025-09-28 17:00:32,110 - training.trainer - INFO - Epoch 34, Step 116021: Loss=5.8220, Acc=0.265, 
2025-09-28 17:00:39,657 - training.trainer - INFO - Epoch 34, Step 116121: Loss=4.8019, Acc=0.348, 
2025-09-28 17:00:47,029 - training.trainer - INFO - Epoch 34, Step 116221: Loss=5.9040, Acc=0.237, 
2025-09-28 17:00:54,329 - training.trainer - INFO - Epoch 34, Step 116321: Loss=5.2519, Acc=0.286, 
2025-09-28 17:01:01,612 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.3755, Acc=0.238, 
2025-09-28 17:01:09,150 - training.trainer - INFO - Epoch 34, Step 116521: Loss=5.5050, Acc=0.240, 
2025-09-28 17:01:16,562 - training.trainer - INFO - Epoch 34, Step 116621: Loss=6.2218, Acc=0.219, 
2025-09-28 17:01:24,003 - training.trainer - INFO - Epoch 34, Step 116721: Loss=5.3754, Acc=0.375, 
2025-09-28 17:01:31,496 - training.trainer - INFO - Epoch 34, Step 116821: Loss=5.6292, Acc=0.250, 
2025-09-28 17:01:38,855 - training.trainer - INFO - Epoch 34, Step 116921: Loss=6.4416, Acc=0.145, 
2025-09-28 17:01:46,254 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.5572, Acc=0.231, 
2025-09-28 17:01:53,564 - training.trainer - INFO - Epoch 34, Step 117121: Loss=3.6396, Acc=0.450, 
2025-09-28 17:02:00,874 - training.trainer - INFO - Epoch 34, Step 117221: Loss=6.0201, Acc=0.236, 
2025-09-28 17:02:08,479 - training.trainer - INFO - Epoch 34, Step 117321: Loss=4.5840, Acc=0.419, 
2025-09-28 17:02:16,018 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.0444, Acc=0.339, 
2025-09-28 17:02:23,532 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.3682, Acc=0.317, 
2025-09-28 17:02:30,703 - training.trainer - INFO - Epoch 34, Step 117621: Loss=5.5574, Acc=0.256, 
2025-09-28 17:02:38,043 - training.trainer - INFO - Epoch 34, Step 117721: Loss=6.1170, Acc=0.206, 
2025-09-28 17:02:45,522 - training.trainer - INFO - Epoch 34, Step 117821: Loss=4.9492, Acc=0.378, 
2025-09-28 17:02:53,127 - training.trainer - INFO - Epoch 34, Step 117921: Loss=3.9497, Acc=0.485, 
2025-09-28 17:03:00,509 - training.trainer - INFO - Epoch 34, Step 118021: Loss=5.9845, Acc=0.250, 
2025-09-28 17:03:08,024 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.4294, Acc=0.324, 
2025-09-28 17:03:15,315 - training.trainer - INFO - Epoch 34, Step 118221: Loss=5.8871, Acc=0.226, 
2025-09-28 17:03:22,605 - training.trainer - INFO - Epoch 34, Step 118321: Loss=6.1231, Acc=0.158, 
2025-09-28 17:03:41,326 - training.trainer - INFO - Epoch 35/100 completed in 263.32s - Train Loss: 5.3755, Train Acc: 0.298, Val Loss: 5.6618, Val Acc: 0.260
2025-09-28 17:03:41,744 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-28 17:03:49,419 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.4307, Acc=0.340, 
2025-09-28 17:03:56,685 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.6361, Acc=0.280, 
2025-09-28 17:04:03,974 - training.trainer - INFO - Epoch 35, Step 118704: Loss=4.0307, Acc=0.481, 
2025-09-28 17:04:11,271 - training.trainer - INFO - Epoch 35, Step 118804: Loss=5.7014, Acc=0.385, 
2025-09-28 17:04:18,516 - training.trainer - INFO - Epoch 35, Step 118904: Loss=5.2019, Acc=0.367, 
2025-09-28 17:04:26,171 - training.trainer - INFO - Epoch 35, Step 119004: Loss=4.2297, Acc=0.476, 
2025-09-28 17:04:33,632 - training.trainer - INFO - Epoch 35, Step 119104: Loss=5.3970, Acc=0.286, 
2025-09-28 17:04:41,047 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.0247, Acc=0.324, 
2025-09-28 17:04:48,557 - training.trainer - INFO - Epoch 35, Step 119304: Loss=5.2369, Acc=0.325, 
2025-09-28 17:04:56,328 - training.trainer - INFO - Epoch 35, Step 119404: Loss=4.6983, Acc=0.360, 
2025-09-28 17:05:04,001 - training.trainer - INFO - Epoch 35, Step 119504: Loss=5.5927, Acc=0.419, 
2025-09-28 17:05:12,197 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.5963, Acc=0.200, 
2025-09-28 17:05:19,693 - training.trainer - INFO - Epoch 35, Step 119704: Loss=5.4007, Acc=0.417, 
2025-09-28 17:05:27,194 - training.trainer - INFO - Epoch 35, Step 119804: Loss=5.5616, Acc=0.261, 
2025-09-28 17:05:34,624 - training.trainer - INFO - Epoch 35, Step 119904: Loss=5.8204, Acc=0.241, 
2025-09-28 17:05:42,055 - training.trainer - INFO - Epoch 35, Step 120004: Loss=6.2261, Acc=0.190, 
2025-09-28 17:05:49,558 - training.trainer - INFO - Epoch 35, Step 120104: Loss=6.0116, Acc=0.205, 
2025-09-28 17:05:57,107 - training.trainer - INFO - Epoch 35, Step 120204: Loss=5.5548, Acc=0.271, 
2025-09-28 17:06:04,562 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.4767, Acc=0.197, 
2025-09-28 17:06:11,962 - training.trainer - INFO - Epoch 35, Step 120404: Loss=3.4162, Acc=0.625, 
2025-09-28 17:06:19,406 - training.trainer - INFO - Epoch 35, Step 120504: Loss=5.1516, Acc=0.379, 
2025-09-28 17:06:26,753 - training.trainer - INFO - Epoch 35, Step 120604: Loss=6.0390, Acc=0.273, 
2025-09-28 17:06:34,118 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.9161, Acc=0.242, 
2025-09-28 17:06:41,565 - training.trainer - INFO - Epoch 35, Step 120804: Loss=5.5376, Acc=0.280, 
2025-09-28 17:06:48,980 - training.trainer - INFO - Epoch 35, Step 120904: Loss=4.7427, Acc=0.348, 
2025-09-28 17:06:56,438 - training.trainer - INFO - Epoch 35, Step 121004: Loss=4.8737, Acc=0.188, 
2025-09-28 17:07:03,914 - training.trainer - INFO - Epoch 35, Step 121104: Loss=6.2047, Acc=0.231, 
2025-09-28 17:07:11,186 - training.trainer - INFO - Epoch 35, Step 121204: Loss=5.2165, Acc=0.310, 
2025-09-28 17:07:18,437 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.0654, Acc=0.318, 
2025-09-28 17:07:25,834 - training.trainer - INFO - Epoch 35, Step 121404: Loss=3.9231, Acc=0.538, 
2025-09-28 17:07:33,074 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.5571, Acc=0.270, 
2025-09-28 17:07:40,385 - training.trainer - INFO - Epoch 35, Step 121604: Loss=4.2031, Acc=0.421, 
2025-09-28 17:07:47,701 - training.trainer - INFO - Epoch 35, Step 121704: Loss=4.5450, Acc=0.403, 
2025-09-28 17:08:06,333 - training.trainer - INFO - Epoch 36/100 completed in 264.59s - Train Loss: 5.3561, Train Acc: 0.301, Val Loss: 5.6616, Val Acc: 0.261
2025-09-28 17:08:13,767 - training.trainer - INFO - Epoch 36, Step 121887: Loss=5.6126, Acc=0.375, 
2025-09-28 17:08:21,109 - training.trainer - INFO - Epoch 36, Step 121987: Loss=5.7112, Acc=0.303, 
2025-09-28 17:08:28,472 - training.trainer - INFO - Epoch 36, Step 122087: Loss=4.1644, Acc=0.355, 
2025-09-28 17:08:36,013 - training.trainer - INFO - Epoch 36, Step 122187: Loss=5.3969, Acc=0.250, 
2025-09-28 17:08:43,533 - training.trainer - INFO - Epoch 36, Step 122287: Loss=4.7514, Acc=0.300, 
2025-09-28 17:08:51,113 - training.trainer - INFO - Epoch 36, Step 122387: Loss=5.5004, Acc=0.378, 
2025-09-28 17:08:58,697 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.1158, Acc=0.321, 
2025-09-28 17:09:06,244 - training.trainer - INFO - Epoch 36, Step 122587: Loss=5.6144, Acc=0.226, 
2025-09-28 17:09:13,712 - training.trainer - INFO - Epoch 36, Step 122687: Loss=6.3059, Acc=0.250, 
2025-09-28 17:09:21,177 - training.trainer - INFO - Epoch 36, Step 122787: Loss=4.0010, Acc=0.440, 
2025-09-28 17:09:28,637 - training.trainer - INFO - Epoch 36, Step 122887: Loss=6.1095, Acc=0.225, 
2025-09-28 17:09:36,058 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.8956, Acc=0.243, 
2025-09-28 17:09:43,794 - training.trainer - INFO - Epoch 36, Step 123087: Loss=4.8255, Acc=0.263, 
2025-09-28 17:09:51,253 - training.trainer - INFO - Epoch 36, Step 123187: Loss=6.0582, Acc=0.304, 
2025-09-28 17:09:58,780 - training.trainer - INFO - Epoch 36, Step 123287: Loss=5.0088, Acc=0.276, 
2025-09-28 17:10:06,287 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.7705, Acc=0.227, 
2025-09-28 17:10:13,780 - training.trainer - INFO - Epoch 36, Step 123487: Loss=4.3969, Acc=0.435, 
2025-09-28 17:10:21,196 - training.trainer - INFO - Epoch 36, Step 123587: Loss=5.2434, Acc=0.276, 
2025-09-28 17:10:28,510 - training.trainer - INFO - Epoch 36, Step 123687: Loss=4.9822, Acc=0.327, 
2025-09-28 17:10:36,129 - training.trainer - INFO - Epoch 36, Step 123787: Loss=5.6601, Acc=0.275, 
2025-09-28 17:10:43,754 - training.trainer - INFO - Epoch 36, Step 123887: Loss=3.6544, Acc=0.600, 
2025-09-28 17:10:51,196 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.7884, Acc=0.257, 
2025-09-28 17:10:58,547 - training.trainer - INFO - Epoch 36, Step 124087: Loss=5.7875, Acc=0.302, 
2025-09-28 17:11:05,939 - training.trainer - INFO - Epoch 36, Step 124187: Loss=5.9333, Acc=0.312, 
2025-09-28 17:11:13,451 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.5499, Acc=0.263, 
2025-09-28 17:11:21,050 - training.trainer - INFO - Epoch 36, Step 124387: Loss=3.4806, Acc=0.538, 
2025-09-28 17:11:28,333 - training.trainer - INFO - Epoch 36, Step 124487: Loss=4.9007, Acc=0.333, 
2025-09-28 17:11:35,721 - training.trainer - INFO - Epoch 36, Step 124587: Loss=3.9893, Acc=0.429, 
2025-09-28 17:11:43,464 - training.trainer - INFO - Epoch 36, Step 124687: Loss=5.7790, Acc=0.246, 
2025-09-28 17:11:50,847 - training.trainer - INFO - Epoch 36, Step 124787: Loss=4.9875, Acc=0.297, 
2025-09-28 17:11:58,333 - training.trainer - INFO - Epoch 36, Step 124887: Loss=6.6785, Acc=0.255, 
2025-09-28 17:12:05,718 - training.trainer - INFO - Epoch 36, Step 124987: Loss=5.6443, Acc=0.235, 
2025-09-28 17:12:13,116 - training.trainer - INFO - Epoch 36, Step 125087: Loss=6.0227, Acc=0.255, 
2025-09-28 17:12:32,610 - training.trainer - INFO - Epoch 37/100 completed in 266.28s - Train Loss: 5.3360, Train Acc: 0.306, Val Loss: 5.6610, Val Acc: 0.260
2025-09-28 17:12:39,322 - training.trainer - INFO - Epoch 37, Step 125270: Loss=4.9937, Acc=0.375, 
2025-09-28 17:12:45,634 - training.trainer - INFO - Epoch 37, Step 125370: Loss=6.0152, Acc=0.125, 
2025-09-28 17:12:51,872 - training.trainer - INFO - Epoch 37, Step 125470: Loss=6.2974, Acc=0.214, 
2025-09-28 17:12:58,292 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.3873, Acc=0.343, 
2025-09-28 17:13:05,086 - training.trainer - INFO - Epoch 37, Step 125670: Loss=5.9750, Acc=0.250, 
2025-09-28 17:13:11,381 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.3134, Acc=0.292, 
2025-09-28 17:13:17,622 - training.trainer - INFO - Epoch 37, Step 125870: Loss=5.2183, Acc=0.357, 
2025-09-28 17:13:24,747 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.1414, Acc=0.320, 
2025-09-28 17:13:32,131 - training.trainer - INFO - Epoch 37, Step 126070: Loss=4.6124, Acc=0.439, 
2025-09-28 17:13:39,503 - training.trainer - INFO - Epoch 37, Step 126170: Loss=5.9428, Acc=0.232, 
2025-09-28 17:13:46,933 - training.trainer - INFO - Epoch 37, Step 126270: Loss=5.5064, Acc=0.261, 
2025-09-28 17:13:54,296 - training.trainer - INFO - Epoch 37, Step 126370: Loss=4.9509, Acc=0.412, 
2025-09-28 17:14:01,844 - training.trainer - INFO - Epoch 37, Step 126470: Loss=4.5325, Acc=0.417, 
2025-09-28 17:14:09,294 - training.trainer - INFO - Epoch 37, Step 126570: Loss=5.3379, Acc=0.244, 
2025-09-28 17:14:16,824 - training.trainer - INFO - Epoch 37, Step 126670: Loss=5.6826, Acc=0.353, 
2025-09-28 17:14:24,368 - training.trainer - INFO - Epoch 37, Step 126770: Loss=6.3342, Acc=0.182, 
2025-09-28 17:14:31,927 - training.trainer - INFO - Epoch 37, Step 126870: Loss=6.4459, Acc=0.195, 
2025-09-28 17:14:39,511 - training.trainer - INFO - Epoch 37, Step 126970: Loss=6.2582, Acc=0.197, 
2025-09-28 17:14:47,048 - training.trainer - INFO - Epoch 37, Step 127070: Loss=5.4702, Acc=0.210, 
2025-09-28 17:14:54,606 - training.trainer - INFO - Epoch 37, Step 127170: Loss=5.6931, Acc=0.293, 
2025-09-28 17:15:02,225 - training.trainer - INFO - Epoch 37, Step 127270: Loss=5.7334, Acc=0.224, 
2025-09-28 17:15:09,697 - training.trainer - INFO - Epoch 37, Step 127370: Loss=5.1712, Acc=0.276, 
2025-09-28 17:15:17,230 - training.trainer - INFO - Epoch 37, Step 127470: Loss=5.2850, Acc=0.261, 
2025-09-28 17:15:24,810 - training.trainer - INFO - Epoch 37, Step 127570: Loss=3.6765, Acc=0.593, 
2025-09-28 17:15:32,620 - training.trainer - INFO - Epoch 37, Step 127670: Loss=5.4631, Acc=0.286, 
2025-09-28 17:15:40,140 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.0621, Acc=0.390, 
2025-09-28 17:15:47,451 - training.trainer - INFO - Epoch 37, Step 127870: Loss=4.5330, Acc=0.393, 
2025-09-28 17:15:54,777 - training.trainer - INFO - Epoch 37, Step 127970: Loss=4.1990, Acc=0.333, 
2025-09-28 17:16:02,054 - training.trainer - INFO - Epoch 37, Step 128070: Loss=4.7511, Acc=0.436, 
2025-09-28 17:16:09,559 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.1536, Acc=0.220, 
2025-09-28 17:16:17,208 - training.trainer - INFO - Epoch 37, Step 128270: Loss=5.8152, Acc=0.258, 
2025-09-28 17:16:24,766 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.3486, Acc=0.282, 
2025-09-28 17:16:32,279 - training.trainer - INFO - Epoch 37, Step 128470: Loss=5.6826, Acc=0.333, 
2025-09-28 17:16:51,364 - training.trainer - INFO - Epoch 38/100 completed in 258.75s - Train Loss: 5.3133, Train Acc: 0.309, Val Loss: 5.6634, Val Acc: 0.261
2025-09-28 17:16:59,649 - training.trainer - INFO - Epoch 38, Step 128653: Loss=5.2352, Acc=0.304, 
2025-09-28 17:17:07,257 - training.trainer - INFO - Epoch 38, Step 128753: Loss=3.7997, Acc=0.596, 
2025-09-28 17:17:14,499 - training.trainer - INFO - Epoch 38, Step 128853: Loss=5.0149, Acc=0.240, 
2025-09-28 17:17:21,904 - training.trainer - INFO - Epoch 38, Step 128953: Loss=5.9617, Acc=0.300, 
2025-09-28 17:17:29,357 - training.trainer - INFO - Epoch 38, Step 129053: Loss=5.7836, Acc=0.220, 
2025-09-28 17:17:36,824 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.0536, Acc=0.389, 
2025-09-28 17:17:44,366 - training.trainer - INFO - Epoch 38, Step 129253: Loss=4.7362, Acc=0.323, 
2025-09-28 17:17:51,921 - training.trainer - INFO - Epoch 38, Step 129353: Loss=2.2761, Acc=0.762, 
2025-09-28 17:17:59,416 - training.trainer - INFO - Epoch 38, Step 129453: Loss=5.6981, Acc=0.189, 
2025-09-28 17:18:06,917 - training.trainer - INFO - Epoch 38, Step 129553: Loss=5.2250, Acc=0.435, 
2025-09-28 17:18:14,365 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.1129, Acc=0.358, 
2025-09-28 17:18:21,978 - training.trainer - INFO - Epoch 38, Step 129753: Loss=5.8805, Acc=0.231, 
2025-09-28 17:18:29,325 - training.trainer - INFO - Epoch 38, Step 129853: Loss=5.6781, Acc=0.241, 
2025-09-28 17:18:36,829 - training.trainer - INFO - Epoch 38, Step 129953: Loss=3.8469, Acc=0.421, 
2025-09-28 17:18:44,314 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.6610, Acc=0.273, 
2025-09-28 17:18:51,669 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.7686, Acc=0.290, 
2025-09-28 17:18:59,129 - training.trainer - INFO - Epoch 38, Step 130253: Loss=4.3339, Acc=0.500, 
2025-09-28 17:19:06,693 - training.trainer - INFO - Epoch 38, Step 130353: Loss=4.4918, Acc=0.348, 
2025-09-28 17:19:14,050 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.5599, Acc=0.333, 
2025-09-28 17:19:21,565 - training.trainer - INFO - Epoch 38, Step 130553: Loss=5.1825, Acc=0.278, 
2025-09-28 17:19:29,140 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.6577, Acc=0.233, 
2025-09-28 17:19:36,576 - training.trainer - INFO - Epoch 38, Step 130753: Loss=5.7562, Acc=0.318, 
2025-09-28 17:19:43,968 - training.trainer - INFO - Epoch 38, Step 130853: Loss=5.8674, Acc=0.345, 
2025-09-28 17:19:51,368 - training.trainer - INFO - Epoch 38, Step 130953: Loss=5.6790, Acc=0.253, 
2025-09-28 17:19:58,881 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.5890, Acc=0.281, 
2025-09-28 17:20:06,313 - training.trainer - INFO - Epoch 38, Step 131153: Loss=5.5782, Acc=0.367, 
2025-09-28 17:20:13,667 - training.trainer - INFO - Epoch 38, Step 131253: Loss=5.6185, Acc=0.205, 
2025-09-28 17:20:21,010 - training.trainer - INFO - Epoch 38, Step 131353: Loss=5.2949, Acc=0.220, 
2025-09-28 17:20:28,388 - training.trainer - INFO - Epoch 38, Step 131453: Loss=5.8862, Acc=0.192, 
2025-09-28 17:20:35,795 - training.trainer - INFO - Epoch 38, Step 131553: Loss=5.8471, Acc=0.244, 
2025-09-28 17:20:43,137 - training.trainer - INFO - Epoch 38, Step 131653: Loss=5.0363, Acc=0.348, 
2025-09-28 17:20:50,441 - training.trainer - INFO - Epoch 38, Step 131753: Loss=5.4253, Acc=0.375, 
2025-09-28 17:20:57,779 - training.trainer - INFO - Epoch 38, Step 131853: Loss=5.9307, Acc=0.311, 
2025-09-28 17:21:17,203 - training.trainer - INFO - Epoch 39/100 completed in 265.84s - Train Loss: 5.2993, Train Acc: 0.310, Val Loss: 5.6606, Val Acc: 0.262
2025-09-28 17:21:25,119 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.9102, Acc=0.203, 
2025-09-28 17:21:32,786 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.9547, Acc=0.175, 
2025-09-28 17:21:40,351 - training.trainer - INFO - Epoch 39, Step 132236: Loss=5.3364, Acc=0.429, 
2025-09-28 17:21:47,774 - training.trainer - INFO - Epoch 39, Step 132336: Loss=4.9188, Acc=0.345, 
2025-09-28 17:21:55,167 - training.trainer - INFO - Epoch 39, Step 132436: Loss=3.9853, Acc=0.486, 
2025-09-28 17:22:02,555 - training.trainer - INFO - Epoch 39, Step 132536: Loss=5.2294, Acc=0.191, 
2025-09-28 17:22:09,952 - training.trainer - INFO - Epoch 39, Step 132636: Loss=6.0555, Acc=0.321, 
2025-09-28 17:22:17,351 - training.trainer - INFO - Epoch 39, Step 132736: Loss=4.7088, Acc=0.511, 
2025-09-28 17:22:24,641 - training.trainer - INFO - Epoch 39, Step 132836: Loss=4.5624, Acc=0.429, 
2025-09-28 17:22:31,953 - training.trainer - INFO - Epoch 39, Step 132936: Loss=4.7423, Acc=0.405, 
2025-09-28 17:22:39,459 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.2050, Acc=0.308, 
2025-09-28 17:22:47,016 - training.trainer - INFO - Epoch 39, Step 133136: Loss=5.8644, Acc=0.156, 
2025-09-28 17:22:54,543 - training.trainer - INFO - Epoch 39, Step 133236: Loss=4.8415, Acc=0.333, 
2025-09-28 17:23:01,961 - training.trainer - INFO - Epoch 39, Step 133336: Loss=4.4152, Acc=0.429, 
2025-09-28 17:23:09,509 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.9070, Acc=0.214, 
2025-09-28 17:23:17,009 - training.trainer - INFO - Epoch 39, Step 133536: Loss=5.0958, Acc=0.278, 
2025-09-28 17:23:24,367 - training.trainer - INFO - Epoch 39, Step 133636: Loss=5.7433, Acc=0.239, 
2025-09-28 17:23:31,765 - training.trainer - INFO - Epoch 39, Step 133736: Loss=6.4985, Acc=0.211, 
2025-09-28 17:23:39,199 - training.trainer - INFO - Epoch 39, Step 133836: Loss=5.5402, Acc=0.267, 
2025-09-28 17:23:46,626 - training.trainer - INFO - Epoch 39, Step 133936: Loss=5.2311, Acc=0.308, 
2025-09-28 17:23:54,120 - training.trainer - INFO - Epoch 39, Step 134036: Loss=4.5135, Acc=0.316, 
2025-09-28 17:24:01,519 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.1165, Acc=0.259, 
2025-09-28 17:24:08,877 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.6595, Acc=0.266, 
2025-09-28 17:24:16,246 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.3253, Acc=0.241, 
2025-09-28 17:24:23,747 - training.trainer - INFO - Epoch 39, Step 134436: Loss=5.5504, Acc=0.245, 
2025-09-28 17:24:31,238 - training.trainer - INFO - Epoch 39, Step 134536: Loss=5.8735, Acc=0.195, 
2025-09-28 17:24:38,557 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.6687, Acc=0.302, 
2025-09-28 17:24:45,978 - training.trainer - INFO - Epoch 39, Step 134736: Loss=4.8994, Acc=0.423, 
2025-09-28 17:24:53,362 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.6462, Acc=0.375, 
2025-09-28 17:25:00,968 - training.trainer - INFO - Epoch 39, Step 134936: Loss=4.6717, Acc=0.414, 
2025-09-28 17:25:08,326 - training.trainer - INFO - Epoch 39, Step 135036: Loss=4.9005, Acc=0.400, 
2025-09-28 17:25:15,686 - training.trainer - INFO - Epoch 39, Step 135136: Loss=6.0065, Acc=0.233, 
2025-09-28 17:25:23,053 - training.trainer - INFO - Epoch 39, Step 135236: Loss=4.1703, Acc=0.421, 
2025-09-28 17:25:41,943 - training.trainer - INFO - Epoch 40/100 completed in 264.74s - Train Loss: 5.2901, Train Acc: 0.313, Val Loss: 5.6766, Val Acc: 0.263
2025-09-28 17:25:42,245 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-28 17:25:49,808 - training.trainer - INFO - Epoch 40, Step 135419: Loss=3.5396, Acc=0.533, 
2025-09-28 17:25:57,237 - training.trainer - INFO - Epoch 40, Step 135519: Loss=5.5811, Acc=0.268, 
2025-09-28 17:26:04,763 - training.trainer - INFO - Epoch 40, Step 135619: Loss=5.7478, Acc=0.279, 
2025-09-28 17:26:12,126 - training.trainer - INFO - Epoch 40, Step 135719: Loss=5.3987, Acc=0.312, 
2025-09-28 17:26:19,863 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.0907, Acc=0.353, 
2025-09-28 17:26:27,587 - training.trainer - INFO - Epoch 40, Step 135919: Loss=4.6640, Acc=0.389, 
2025-09-28 17:26:35,270 - training.trainer - INFO - Epoch 40, Step 136019: Loss=5.2613, Acc=0.333, 
2025-09-28 17:26:42,759 - training.trainer - INFO - Epoch 40, Step 136119: Loss=4.5602, Acc=0.455, 
2025-09-28 17:26:50,581 - training.trainer - INFO - Epoch 40, Step 136219: Loss=5.0681, Acc=0.450, 
2025-09-28 17:26:57,941 - training.trainer - INFO - Epoch 40, Step 136319: Loss=5.0372, Acc=0.318, 
2025-09-28 17:27:05,317 - training.trainer - INFO - Epoch 40, Step 136419: Loss=4.4340, Acc=0.383, 
2025-09-28 17:27:12,723 - training.trainer - INFO - Epoch 40, Step 136519: Loss=5.3751, Acc=0.333, 
2025-09-28 17:27:20,026 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.2537, Acc=0.275, 
2025-09-28 17:27:27,290 - training.trainer - INFO - Epoch 40, Step 136719: Loss=5.6843, Acc=0.253, 
2025-09-28 17:27:34,548 - training.trainer - INFO - Epoch 40, Step 136819: Loss=5.0604, Acc=0.432, 
2025-09-28 17:27:42,096 - training.trainer - INFO - Epoch 40, Step 136919: Loss=5.4657, Acc=0.275, 
2025-09-28 17:27:49,369 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.4519, Acc=0.267, 
2025-09-28 17:27:56,777 - training.trainer - INFO - Epoch 40, Step 137119: Loss=6.6980, Acc=0.179, 
2025-09-28 17:28:04,093 - training.trainer - INFO - Epoch 40, Step 137219: Loss=3.6916, Acc=0.618, 
2025-09-28 17:28:11,402 - training.trainer - INFO - Epoch 40, Step 137319: Loss=4.5776, Acc=0.333, 
2025-09-28 17:28:18,663 - training.trainer - INFO - Epoch 40, Step 137419: Loss=5.7177, Acc=0.241, 
2025-09-28 17:28:25,910 - training.trainer - INFO - Epoch 40, Step 137519: Loss=4.7632, Acc=0.378, 
2025-09-28 17:28:33,166 - training.trainer - INFO - Epoch 40, Step 137619: Loss=5.7377, Acc=0.184, 
2025-09-28 17:28:40,415 - training.trainer - INFO - Epoch 40, Step 137719: Loss=5.4307, Acc=0.259, 
2025-09-28 17:28:48,045 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.5485, Acc=0.222, 
2025-09-28 17:28:55,561 - training.trainer - INFO - Epoch 40, Step 137919: Loss=5.1243, Acc=0.260, 
2025-09-28 17:29:03,055 - training.trainer - INFO - Epoch 40, Step 138019: Loss=4.8732, Acc=0.353, 
2025-09-28 17:29:10,544 - training.trainer - INFO - Epoch 40, Step 138119: Loss=5.0057, Acc=0.407, 
2025-09-28 17:29:18,102 - training.trainer - INFO - Epoch 40, Step 138219: Loss=6.2761, Acc=0.195, 
2025-09-28 17:29:25,499 - training.trainer - INFO - Epoch 40, Step 138319: Loss=4.6992, Acc=0.432, 
2025-09-28 17:29:33,026 - training.trainer - INFO - Epoch 40, Step 138419: Loss=5.4949, Acc=0.351, 
2025-09-28 17:29:40,442 - training.trainer - INFO - Epoch 40, Step 138519: Loss=4.6098, Acc=0.375, 
2025-09-28 17:29:47,873 - training.trainer - INFO - Epoch 40, Step 138619: Loss=6.2667, Acc=0.262, 
2025-09-28 17:30:07,354 - training.trainer - INFO - Epoch 41/100 completed in 265.11s - Train Loss: 5.2779, Train Acc: 0.315, Val Loss: 5.6723, Val Acc: 0.258
2025-09-28 17:30:14,356 - training.trainer - INFO - Epoch 41, Step 138802: Loss=5.6193, Acc=0.212, 
2025-09-28 17:30:21,331 - training.trainer - INFO - Epoch 41, Step 138902: Loss=6.0189, Acc=0.261, 
2025-09-28 17:30:28,364 - training.trainer - INFO - Epoch 41, Step 139002: Loss=3.8211, Acc=0.429, 
2025-09-28 17:30:35,537 - training.trainer - INFO - Epoch 41, Step 139102: Loss=4.8040, Acc=0.404, 
2025-09-28 17:30:42,564 - training.trainer - INFO - Epoch 41, Step 139202: Loss=5.0599, Acc=0.283, 
2025-09-28 17:30:49,781 - training.trainer - INFO - Epoch 41, Step 139302: Loss=4.2075, Acc=0.480, 
2025-09-28 17:30:57,533 - training.trainer - INFO - Epoch 41, Step 139402: Loss=6.0833, Acc=0.303, 
2025-09-28 17:31:05,173 - training.trainer - INFO - Epoch 41, Step 139502: Loss=5.5980, Acc=0.219, 
2025-09-28 17:31:12,662 - training.trainer - INFO - Epoch 41, Step 139602: Loss=5.6041, Acc=0.294, 
2025-09-28 17:31:20,125 - training.trainer - INFO - Epoch 41, Step 139702: Loss=5.3038, Acc=0.333, 
2025-09-28 17:31:27,561 - training.trainer - INFO - Epoch 41, Step 139802: Loss=5.7676, Acc=0.270, 
2025-09-28 17:31:34,594 - training.trainer - INFO - Epoch 41, Step 139902: Loss=4.7506, Acc=0.366, 
2025-09-28 17:31:41,932 - training.trainer - INFO - Epoch 41, Step 140002: Loss=5.3968, Acc=0.341, 
2025-09-28 17:31:49,705 - training.trainer - INFO - Epoch 41, Step 140102: Loss=4.7399, Acc=0.412, 
2025-09-28 17:31:57,078 - training.trainer - INFO - Epoch 41, Step 140202: Loss=5.4481, Acc=0.316, 
2025-09-28 17:32:04,575 - training.trainer - INFO - Epoch 41, Step 140302: Loss=5.7551, Acc=0.268, 
2025-09-28 17:32:12,022 - training.trainer - INFO - Epoch 41, Step 140402: Loss=4.7953, Acc=0.244, 
2025-09-28 17:32:19,401 - training.trainer - INFO - Epoch 41, Step 140502: Loss=5.2455, Acc=0.326, 
2025-09-28 17:32:26,821 - training.trainer - INFO - Epoch 41, Step 140602: Loss=5.0772, Acc=0.244, 
2025-09-28 17:32:34,314 - training.trainer - INFO - Epoch 41, Step 140702: Loss=4.0078, Acc=0.474, 
2025-09-28 17:32:41,746 - training.trainer - INFO - Epoch 41, Step 140802: Loss=5.5327, Acc=0.300, 
2025-09-28 17:32:49,113 - training.trainer - INFO - Epoch 41, Step 140902: Loss=6.1646, Acc=0.189, 
2025-09-28 17:32:56,500 - training.trainer - INFO - Epoch 41, Step 141002: Loss=4.5715, Acc=0.375, 
2025-09-28 17:33:03,869 - training.trainer - INFO - Epoch 41, Step 141102: Loss=6.0088, Acc=0.219, 
2025-09-28 17:33:11,506 - training.trainer - INFO - Epoch 41, Step 141202: Loss=5.8600, Acc=0.275, 
2025-09-28 17:33:18,901 - training.trainer - INFO - Epoch 41, Step 141302: Loss=4.4254, Acc=0.471, 
2025-09-28 17:33:26,242 - training.trainer - INFO - Epoch 41, Step 141402: Loss=5.9920, Acc=0.122, 
2025-09-28 17:33:33,657 - training.trainer - INFO - Epoch 41, Step 141502: Loss=5.0298, Acc=0.367, 
2025-09-28 17:33:41,214 - training.trainer - INFO - Epoch 41, Step 141602: Loss=5.4150, Acc=0.200, 
2025-09-28 17:33:48,615 - training.trainer - INFO - Epoch 41, Step 141702: Loss=5.0352, Acc=0.353, 
2025-09-28 17:33:55,977 - training.trainer - INFO - Epoch 41, Step 141802: Loss=5.7050, Acc=0.321, 
2025-09-28 17:34:03,338 - training.trainer - INFO - Epoch 41, Step 141902: Loss=5.9142, Acc=0.200, 
2025-09-28 17:34:10,779 - training.trainer - INFO - Epoch 41, Step 142002: Loss=5.0481, Acc=0.308, 
2025-09-28 17:34:30,188 - training.trainer - INFO - Epoch 42/100 completed in 262.83s - Train Loss: 5.2617, Train Acc: 0.317, Val Loss: 5.6742, Val Acc: 0.263
2025-09-28 17:34:38,169 - training.trainer - INFO - Epoch 42, Step 142185: Loss=5.3887, Acc=0.333, 
2025-09-28 17:34:45,648 - training.trainer - INFO - Epoch 42, Step 142285: Loss=5.5344, Acc=0.364, 
2025-09-28 17:34:53,100 - training.trainer - INFO - Epoch 42, Step 142385: Loss=5.3962, Acc=0.429, 
2025-09-28 17:35:00,473 - training.trainer - INFO - Epoch 42, Step 142485: Loss=5.2691, Acc=0.321, 
2025-09-28 17:35:07,946 - training.trainer - INFO - Epoch 42, Step 142585: Loss=5.5824, Acc=0.236, 
2025-09-28 17:35:15,495 - training.trainer - INFO - Epoch 42, Step 142685: Loss=5.5223, Acc=0.289, 
2025-09-28 17:35:22,979 - training.trainer - INFO - Epoch 42, Step 142785: Loss=5.6105, Acc=0.257, 
2025-09-28 17:35:30,354 - training.trainer - INFO - Epoch 42, Step 142885: Loss=4.9444, Acc=0.455, 
2025-09-28 17:35:37,811 - training.trainer - INFO - Epoch 42, Step 142985: Loss=5.1859, Acc=0.412, 
2025-09-28 17:35:45,180 - training.trainer - INFO - Epoch 42, Step 143085: Loss=5.0130, Acc=0.292, 
2025-09-28 17:35:52,675 - training.trainer - INFO - Epoch 42, Step 143185: Loss=5.1620, Acc=0.286, 
2025-09-28 17:36:00,051 - training.trainer - INFO - Epoch 42, Step 143285: Loss=5.0537, Acc=0.237, 
2025-09-28 17:36:07,306 - training.trainer - INFO - Epoch 42, Step 143385: Loss=5.2100, Acc=0.304, 
2025-09-28 17:36:14,646 - training.trainer - INFO - Epoch 42, Step 143485: Loss=4.8487, Acc=0.333, 
2025-09-28 17:36:22,066 - training.trainer - INFO - Epoch 42, Step 143585: Loss=5.1885, Acc=0.225, 
2025-09-28 17:36:29,538 - training.trainer - INFO - Epoch 42, Step 143685: Loss=6.0471, Acc=0.219, 
2025-09-28 17:36:36,971 - training.trainer - INFO - Epoch 42, Step 143785: Loss=4.9412, Acc=0.429, 
2025-09-28 17:36:44,489 - training.trainer - INFO - Epoch 42, Step 143885: Loss=5.4938, Acc=0.342, 
2025-09-28 17:36:52,026 - training.trainer - INFO - Epoch 42, Step 143985: Loss=5.4663, Acc=0.283, 
2025-09-28 17:36:59,494 - training.trainer - INFO - Epoch 42, Step 144085: Loss=4.5485, Acc=0.333, 
2025-09-28 17:37:07,154 - training.trainer - INFO - Epoch 42, Step 144185: Loss=5.7107, Acc=0.273, 
2025-09-28 17:37:14,832 - training.trainer - INFO - Epoch 42, Step 144285: Loss=5.3486, Acc=0.175, 
2025-09-28 17:37:22,449 - training.trainer - INFO - Epoch 42, Step 144385: Loss=4.4605, Acc=0.300, 
2025-09-28 17:37:29,999 - training.trainer - INFO - Epoch 42, Step 144485: Loss=3.8643, Acc=0.423, 
2025-09-28 17:37:37,405 - training.trainer - INFO - Epoch 42, Step 144585: Loss=3.4473, Acc=0.467, 
2025-09-28 17:37:44,911 - training.trainer - INFO - Epoch 42, Step 144685: Loss=5.3464, Acc=0.300, 
2025-09-28 17:37:52,536 - training.trainer - INFO - Epoch 42, Step 144785: Loss=5.4375, Acc=0.235, 
2025-09-28 17:37:59,897 - training.trainer - INFO - Epoch 42, Step 144885: Loss=5.9141, Acc=0.167, 
2025-09-28 17:38:07,336 - training.trainer - INFO - Epoch 42, Step 144985: Loss=5.6605, Acc=0.333, 
2025-09-28 17:38:14,637 - training.trainer - INFO - Epoch 42, Step 145085: Loss=5.0830, Acc=0.356, 
2025-09-28 17:38:21,985 - training.trainer - INFO - Epoch 42, Step 145185: Loss=5.0662, Acc=0.355, 
2025-09-28 17:38:29,298 - training.trainer - INFO - Epoch 42, Step 145285: Loss=5.1421, Acc=0.280, 
2025-09-28 17:38:36,694 - training.trainer - INFO - Epoch 42, Step 145385: Loss=6.2797, Acc=0.222, 
2025-09-28 17:38:55,815 - training.trainer - INFO - Epoch 43/100 completed in 265.63s - Train Loss: 5.2480, Train Acc: 0.320, Val Loss: 5.6832, Val Acc: 0.265
2025-09-28 17:39:02,383 - training.trainer - INFO - Epoch 43, Step 145568: Loss=5.9854, Acc=0.286, 
2025-09-28 17:39:08,827 - training.trainer - INFO - Epoch 43, Step 145668: Loss=5.3869, Acc=0.362, 
2025-09-28 17:39:15,979 - training.trainer - INFO - Epoch 43, Step 145768: Loss=5.8143, Acc=0.232, 
2025-09-28 17:39:23,306 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.8491, Acc=0.259, 
2025-09-28 17:39:30,650 - training.trainer - INFO - Epoch 43, Step 145968: Loss=5.9550, Acc=0.282, 
2025-09-28 17:39:37,949 - training.trainer - INFO - Epoch 43, Step 146068: Loss=5.2376, Acc=0.359, 
2025-09-28 17:39:45,342 - training.trainer - INFO - Epoch 43, Step 146168: Loss=5.0714, Acc=0.349, 
2025-09-28 17:39:52,584 - training.trainer - INFO - Epoch 43, Step 146268: Loss=6.3895, Acc=0.269, 
2025-09-28 17:39:59,874 - training.trainer - INFO - Epoch 43, Step 146368: Loss=4.8570, Acc=0.464, 
2025-09-28 17:40:07,208 - training.trainer - INFO - Epoch 43, Step 146468: Loss=4.9385, Acc=0.308, 
2025-09-28 17:40:14,667 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.9164, Acc=0.196, 
2025-09-28 17:40:22,066 - training.trainer - INFO - Epoch 43, Step 146668: Loss=4.6784, Acc=0.385, 
2025-09-28 17:40:29,472 - training.trainer - INFO - Epoch 43, Step 146768: Loss=5.5791, Acc=0.292, 
2025-09-28 17:40:36,888 - training.trainer - INFO - Epoch 43, Step 146868: Loss=5.2411, Acc=0.341, 
2025-09-28 17:40:44,214 - training.trainer - INFO - Epoch 43, Step 146968: Loss=5.4969, Acc=0.225, 
2025-09-28 17:40:51,787 - training.trainer - INFO - Epoch 43, Step 147068: Loss=5.7468, Acc=0.213, 
2025-09-28 17:40:59,270 - training.trainer - INFO - Epoch 43, Step 147168: Loss=4.9553, Acc=0.267, 
2025-09-28 17:41:06,564 - training.trainer - INFO - Epoch 43, Step 147268: Loss=5.7444, Acc=0.241, 
2025-09-28 17:41:14,053 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.3596, Acc=0.297, 
2025-09-28 17:41:21,693 - training.trainer - INFO - Epoch 43, Step 147468: Loss=5.3910, Acc=0.385, 
2025-09-28 17:41:29,136 - training.trainer - INFO - Epoch 43, Step 147568: Loss=5.9639, Acc=0.265, 
2025-09-28 17:41:37,048 - training.trainer - INFO - Epoch 43, Step 147668: Loss=3.8771, Acc=0.368, 
2025-09-28 17:41:44,490 - training.trainer - INFO - Epoch 43, Step 147768: Loss=5.9490, Acc=0.269, 
2025-09-28 17:41:51,964 - training.trainer - INFO - Epoch 43, Step 147868: Loss=6.1739, Acc=0.182, 
2025-09-28 17:41:59,343 - training.trainer - INFO - Epoch 43, Step 147968: Loss=5.4206, Acc=0.276, 
2025-09-28 17:42:06,740 - training.trainer - INFO - Epoch 43, Step 148068: Loss=5.1873, Acc=0.333, 
2025-09-28 17:42:14,070 - training.trainer - INFO - Epoch 43, Step 148168: Loss=4.2095, Acc=0.364, 
2025-09-28 17:42:21,387 - training.trainer - INFO - Epoch 43, Step 148268: Loss=5.1198, Acc=0.293, 
2025-09-28 17:42:28,994 - training.trainer - INFO - Epoch 43, Step 148368: Loss=5.6367, Acc=0.241, 
2025-09-28 17:42:36,502 - training.trainer - INFO - Epoch 43, Step 148468: Loss=5.6943, Acc=0.302, 
2025-09-28 17:42:44,147 - training.trainer - INFO - Epoch 43, Step 148568: Loss=4.9100, Acc=0.267, 
2025-09-28 17:42:51,592 - training.trainer - INFO - Epoch 43, Step 148668: Loss=5.2316, Acc=0.321, 
2025-09-28 17:42:59,082 - training.trainer - INFO - Epoch 43, Step 148768: Loss=4.9201, Acc=0.412, 
2025-09-28 17:43:17,839 - training.trainer - INFO - Epoch 44/100 completed in 262.02s - Train Loss: 5.2267, Train Acc: 0.322, Val Loss: 5.6874, Val Acc: 0.261
2025-09-28 17:43:24,870 - training.trainer - INFO - Epoch 44, Step 148951: Loss=4.9630, Acc=0.375, 
2025-09-28 17:43:32,440 - training.trainer - INFO - Epoch 44, Step 149051: Loss=4.2079, Acc=0.318, 
2025-09-28 17:43:39,859 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.2226, Acc=0.333, 
2025-09-28 17:43:47,246 - training.trainer - INFO - Epoch 44, Step 149251: Loss=5.1098, Acc=0.500, 
2025-09-28 17:43:54,726 - training.trainer - INFO - Epoch 44, Step 149351: Loss=4.2167, Acc=0.455, 
2025-09-28 17:44:02,133 - training.trainer - INFO - Epoch 44, Step 149451: Loss=4.8089, Acc=0.308, 
2025-09-28 17:44:09,469 - training.trainer - INFO - Epoch 44, Step 149551: Loss=5.5663, Acc=0.303, 
2025-09-28 17:44:16,906 - training.trainer - INFO - Epoch 44, Step 149651: Loss=5.3026, Acc=0.351, 
2025-09-28 17:44:24,254 - training.trainer - INFO - Epoch 44, Step 149751: Loss=4.5037, Acc=0.500, 
2025-09-28 17:44:31,568 - training.trainer - INFO - Epoch 44, Step 149851: Loss=5.1333, Acc=0.220, 
2025-09-28 17:44:38,947 - training.trainer - INFO - Epoch 44, Step 149951: Loss=5.6816, Acc=0.232, 
2025-09-28 17:44:46,293 - training.trainer - INFO - Epoch 44, Step 150051: Loss=4.8606, Acc=0.391, 
2025-09-28 17:44:53,713 - training.trainer - INFO - Epoch 44, Step 150151: Loss=5.0057, Acc=0.346, 
2025-09-28 17:45:01,079 - training.trainer - INFO - Epoch 44, Step 150251: Loss=4.3223, Acc=0.462, 
2025-09-28 17:45:08,839 - training.trainer - INFO - Epoch 44, Step 150351: Loss=5.2220, Acc=0.346, 
2025-09-28 17:45:16,192 - training.trainer - INFO - Epoch 44, Step 150451: Loss=2.4775, Acc=0.632, 
2025-09-28 17:45:23,637 - training.trainer - INFO - Epoch 44, Step 150551: Loss=4.5949, Acc=0.333, 
2025-09-28 17:45:31,001 - training.trainer - INFO - Epoch 44, Step 150651: Loss=5.6301, Acc=0.250, 
2025-09-28 17:45:38,270 - training.trainer - INFO - Epoch 44, Step 150751: Loss=4.6004, Acc=0.350, 
2025-09-28 17:45:45,663 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.0354, Acc=0.256, 
2025-09-28 17:45:52,994 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.4186, Acc=0.333, 
2025-09-28 17:46:00,394 - training.trainer - INFO - Epoch 44, Step 151051: Loss=5.4645, Acc=0.234, 
2025-09-28 17:46:07,678 - training.trainer - INFO - Epoch 44, Step 151151: Loss=5.6125, Acc=0.393, 
2025-09-28 17:46:15,115 - training.trainer - INFO - Epoch 44, Step 151251: Loss=6.2422, Acc=0.159, 
2025-09-28 17:46:22,506 - training.trainer - INFO - Epoch 44, Step 151351: Loss=5.1245, Acc=0.312, 
2025-09-28 17:46:29,967 - training.trainer - INFO - Epoch 44, Step 151451: Loss=5.0485, Acc=0.387, 
2025-09-28 17:46:37,315 - training.trainer - INFO - Epoch 44, Step 151551: Loss=5.2945, Acc=0.375, 
2025-09-28 17:46:44,632 - training.trainer - INFO - Epoch 44, Step 151651: Loss=5.5152, Acc=0.255, 
2025-09-28 17:46:52,240 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.4624, Acc=0.244, 
2025-09-28 17:46:59,595 - training.trainer - INFO - Epoch 44, Step 151851: Loss=5.1109, Acc=0.298, 
2025-09-28 17:47:07,172 - training.trainer - INFO - Epoch 44, Step 151951: Loss=5.6831, Acc=0.192, 
2025-09-28 17:47:14,817 - training.trainer - INFO - Epoch 44, Step 152051: Loss=5.6933, Acc=0.250, 
2025-09-28 17:47:22,470 - training.trainer - INFO - Epoch 44, Step 152151: Loss=6.1629, Acc=0.244, 
2025-09-28 17:47:42,132 - training.trainer - INFO - Epoch 45/100 completed in 264.29s - Train Loss: 5.2158, Train Acc: 0.325, Val Loss: 5.6775, Val Acc: 0.263
2025-09-28 17:47:42,533 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-28 17:47:50,568 - training.trainer - INFO - Epoch 45, Step 152334: Loss=4.6814, Acc=0.364, 
2025-09-28 17:47:58,161 - training.trainer - INFO - Epoch 45, Step 152434: Loss=5.6355, Acc=0.235, 
2025-09-28 17:48:05,752 - training.trainer - INFO - Epoch 45, Step 152534: Loss=5.6467, Acc=0.220, 
2025-09-28 17:48:13,265 - training.trainer - INFO - Epoch 45, Step 152634: Loss=3.8341, Acc=0.579, 
2025-09-28 17:48:20,700 - training.trainer - INFO - Epoch 45, Step 152734: Loss=6.0991, Acc=0.233, 
2025-09-28 17:48:28,346 - training.trainer - INFO - Epoch 45, Step 152834: Loss=5.4438, Acc=0.242, 
2025-09-28 17:48:35,818 - training.trainer - INFO - Epoch 45, Step 152934: Loss=5.5960, Acc=0.207, 
2025-09-28 17:48:43,281 - training.trainer - INFO - Epoch 45, Step 153034: Loss=5.1146, Acc=0.378, 
2025-09-28 17:48:50,710 - training.trainer - INFO - Epoch 45, Step 153134: Loss=5.0447, Acc=0.300, 
2025-09-28 17:48:58,419 - training.trainer - INFO - Epoch 45, Step 153234: Loss=4.7356, Acc=0.300, 
2025-09-28 17:49:05,824 - training.trainer - INFO - Epoch 45, Step 153334: Loss=5.9142, Acc=0.244, 
2025-09-28 17:49:13,220 - training.trainer - INFO - Epoch 45, Step 153434: Loss=4.7344, Acc=0.417, 
2025-09-28 17:49:20,716 - training.trainer - INFO - Epoch 45, Step 153534: Loss=5.4449, Acc=0.255, 
2025-09-28 17:49:28,145 - training.trainer - INFO - Epoch 45, Step 153634: Loss=5.4168, Acc=0.233, 
2025-09-28 17:49:35,688 - training.trainer - INFO - Epoch 45, Step 153734: Loss=5.7495, Acc=0.254, 
2025-09-28 17:49:43,222 - training.trainer - INFO - Epoch 45, Step 153834: Loss=5.8676, Acc=0.222, 
2025-09-28 17:49:50,698 - training.trainer - INFO - Epoch 45, Step 153934: Loss=5.4636, Acc=0.320, 
2025-09-28 17:49:58,159 - training.trainer - INFO - Epoch 45, Step 154034: Loss=5.1947, Acc=0.262, 
2025-09-28 17:50:05,647 - training.trainer - INFO - Epoch 45, Step 154134: Loss=5.5798, Acc=0.303, 
2025-09-28 17:50:13,095 - training.trainer - INFO - Epoch 45, Step 154234: Loss=6.0667, Acc=0.279, 
2025-09-28 17:50:20,503 - training.trainer - INFO - Epoch 45, Step 154334: Loss=5.0079, Acc=0.343, 
2025-09-28 17:50:27,918 - training.trainer - INFO - Epoch 45, Step 154434: Loss=4.9316, Acc=0.267, 
2025-09-28 17:50:35,366 - training.trainer - INFO - Epoch 45, Step 154534: Loss=4.6373, Acc=0.438, 
2025-09-28 17:50:42,773 - training.trainer - INFO - Epoch 45, Step 154634: Loss=5.4175, Acc=0.310, 
2025-09-28 17:50:50,417 - training.trainer - INFO - Epoch 45, Step 154734: Loss=3.9008, Acc=0.500, 
2025-09-28 17:50:57,837 - training.trainer - INFO - Epoch 45, Step 154834: Loss=5.2199, Acc=0.296, 
2025-09-28 17:51:05,250 - training.trainer - INFO - Epoch 45, Step 154934: Loss=5.2901, Acc=0.219, 
2025-09-28 17:51:13,020 - training.trainer - INFO - Epoch 45, Step 155034: Loss=5.2096, Acc=0.344, 
2025-09-28 17:51:20,405 - training.trainer - INFO - Epoch 45, Step 155134: Loss=4.6603, Acc=0.375, 
2025-09-28 17:51:27,806 - training.trainer - INFO - Epoch 45, Step 155234: Loss=5.2037, Acc=0.440, 
2025-09-28 17:51:35,181 - training.trainer - INFO - Epoch 45, Step 155334: Loss=4.2021, Acc=0.418, 
2025-09-28 17:51:42,667 - training.trainer - INFO - Epoch 45, Step 155434: Loss=5.3976, Acc=0.333, 
2025-09-28 17:51:50,138 - training.trainer - INFO - Epoch 45, Step 155534: Loss=5.6368, Acc=0.244, 
2025-09-28 17:52:08,795 - training.trainer - INFO - Epoch 46/100 completed in 266.26s - Train Loss: 5.1958, Train Acc: 0.327, Val Loss: 5.6933, Val Acc: 0.263
2025-09-28 17:52:15,508 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.2375, Acc=0.298, 
2025-09-28 17:52:21,920 - training.trainer - INFO - Epoch 46, Step 155817: Loss=5.1680, Acc=0.458, 
2025-09-28 17:52:29,247 - training.trainer - INFO - Epoch 46, Step 155917: Loss=4.3669, Acc=0.441, 
2025-09-28 17:52:36,611 - training.trainer - INFO - Epoch 46, Step 156017: Loss=5.6147, Acc=0.357, 
2025-09-28 17:52:43,901 - training.trainer - INFO - Epoch 46, Step 156117: Loss=5.0333, Acc=0.304, 
2025-09-28 17:52:51,387 - training.trainer - INFO - Epoch 46, Step 156217: Loss=4.9953, Acc=0.270, 
2025-09-28 17:52:58,773 - training.trainer - INFO - Epoch 46, Step 156317: Loss=5.2622, Acc=0.286, 
2025-09-28 17:53:06,207 - training.trainer - INFO - Epoch 46, Step 156417: Loss=5.3587, Acc=0.206, 
2025-09-28 17:53:13,526 - training.trainer - INFO - Epoch 46, Step 156517: Loss=4.9645, Acc=0.486, 
2025-09-28 17:53:21,002 - training.trainer - INFO - Epoch 46, Step 156617: Loss=5.6391, Acc=0.308, 
2025-09-28 17:53:28,368 - training.trainer - INFO - Epoch 46, Step 156717: Loss=4.9150, Acc=0.448, 
2025-09-28 17:53:35,702 - training.trainer - INFO - Epoch 46, Step 156817: Loss=5.2688, Acc=0.235, 
2025-09-28 17:53:43,162 - training.trainer - INFO - Epoch 46, Step 156917: Loss=5.4123, Acc=0.300, 
2025-09-28 17:53:50,547 - training.trainer - INFO - Epoch 46, Step 157017: Loss=5.2298, Acc=0.258, 
2025-09-28 17:53:58,057 - training.trainer - INFO - Epoch 46, Step 157117: Loss=4.4575, Acc=0.436, 
2025-09-28 17:54:05,357 - training.trainer - INFO - Epoch 46, Step 157217: Loss=5.1794, Acc=0.345, 
2025-09-28 17:54:12,685 - training.trainer - INFO - Epoch 46, Step 157317: Loss=4.9718, Acc=0.217, 
2025-09-28 17:54:20,043 - training.trainer - INFO - Epoch 46, Step 157417: Loss=5.3983, Acc=0.327, 
2025-09-28 17:54:27,439 - training.trainer - INFO - Epoch 46, Step 157517: Loss=6.0223, Acc=0.145, 
2025-09-28 17:54:34,947 - training.trainer - INFO - Epoch 46, Step 157617: Loss=5.0239, Acc=0.323, 
2025-09-28 17:54:42,267 - training.trainer - INFO - Epoch 46, Step 157717: Loss=5.5155, Acc=0.235, 
2025-09-28 17:54:49,623 - training.trainer - INFO - Epoch 46, Step 157817: Loss=5.3350, Acc=0.297, 
2025-09-28 17:54:57,087 - training.trainer - INFO - Epoch 46, Step 157917: Loss=3.5518, Acc=0.385, 
2025-09-28 17:55:04,489 - training.trainer - INFO - Epoch 46, Step 158017: Loss=5.5036, Acc=0.333, 
2025-09-28 17:55:12,047 - training.trainer - INFO - Epoch 46, Step 158117: Loss=5.5166, Acc=0.286, 
2025-09-28 17:55:19,475 - training.trainer - INFO - Epoch 46, Step 158217: Loss=6.1178, Acc=0.250, 
2025-09-28 17:55:26,930 - training.trainer - INFO - Epoch 46, Step 158317: Loss=5.1070, Acc=0.451, 
2025-09-28 17:55:34,439 - training.trainer - INFO - Epoch 46, Step 158417: Loss=4.0776, Acc=0.389, 
2025-09-28 17:55:41,801 - training.trainer - INFO - Epoch 46, Step 158517: Loss=5.8544, Acc=0.292, 
2025-09-28 17:55:49,334 - training.trainer - INFO - Epoch 46, Step 158617: Loss=5.7771, Acc=0.225, 
2025-09-28 17:55:56,698 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.3229, Acc=0.361, 
2025-09-28 17:56:04,123 - training.trainer - INFO - Epoch 46, Step 158817: Loss=4.8095, Acc=0.371, 
2025-09-28 17:56:11,517 - training.trainer - INFO - Epoch 46, Step 158917: Loss=5.6122, Acc=0.137, 
2025-09-28 17:56:30,314 - training.trainer - INFO - Epoch 47/100 completed in 261.52s - Train Loss: 5.1835, Train Acc: 0.331, Val Loss: 5.7097, Val Acc: 0.262
2025-09-28 17:56:38,150 - training.trainer - INFO - Epoch 47, Step 159100: Loss=5.7795, Acc=0.243, 
2025-09-28 17:56:45,528 - training.trainer - INFO - Epoch 47, Step 159200: Loss=5.7211, Acc=0.241, 
2025-09-28 17:56:52,853 - training.trainer - INFO - Epoch 47, Step 159300: Loss=5.8604, Acc=0.242, 
2025-09-28 17:57:00,261 - training.trainer - INFO - Epoch 47, Step 159400: Loss=5.4023, Acc=0.326, 
2025-09-28 17:57:07,643 - training.trainer - INFO - Epoch 47, Step 159500: Loss=4.4958, Acc=0.318, 
2025-09-28 17:57:14,949 - training.trainer - INFO - Epoch 47, Step 159600: Loss=3.4163, Acc=0.583, 
2025-09-28 17:57:22,255 - training.trainer - INFO - Epoch 47, Step 159700: Loss=5.5990, Acc=0.273, 
2025-09-28 17:57:29,605 - training.trainer - INFO - Epoch 47, Step 159800: Loss=4.3516, Acc=0.429, 
2025-09-28 17:57:36,981 - training.trainer - INFO - Epoch 47, Step 159900: Loss=5.8043, Acc=0.235, 
2025-09-28 17:57:44,360 - training.trainer - INFO - Epoch 47, Step 160000: Loss=5.6944, Acc=0.230, 
2025-09-28 17:57:51,703 - training.trainer - INFO - Epoch 47, Step 160100: Loss=5.0691, Acc=0.350, 
2025-09-28 17:57:59,020 - training.trainer - INFO - Epoch 47, Step 160200: Loss=5.2768, Acc=0.291, 
2025-09-28 17:58:06,508 - training.trainer - INFO - Epoch 47, Step 160300: Loss=4.5648, Acc=0.436, 
2025-09-28 17:58:13,944 - training.trainer - INFO - Epoch 47, Step 160400: Loss=6.0626, Acc=0.182, 
2025-09-28 17:58:21,359 - training.trainer - INFO - Epoch 47, Step 160500: Loss=5.0499, Acc=0.367, 
2025-09-28 17:58:28,712 - training.trainer - INFO - Epoch 47, Step 160600: Loss=5.3980, Acc=0.375, 
2025-09-28 17:58:36,157 - training.trainer - INFO - Epoch 47, Step 160700: Loss=5.5196, Acc=0.271, 
2025-09-28 17:58:43,597 - training.trainer - INFO - Epoch 47, Step 160800: Loss=5.8153, Acc=0.212, 
2025-09-28 17:58:51,248 - training.trainer - INFO - Epoch 47, Step 160900: Loss=6.0827, Acc=0.183, 
2025-09-28 17:58:58,713 - training.trainer - INFO - Epoch 47, Step 161000: Loss=4.2641, Acc=0.500, 
2025-09-28 17:59:06,115 - training.trainer - INFO - Epoch 47, Step 161100: Loss=5.0197, Acc=0.262, 
2025-09-28 17:59:13,515 - training.trainer - INFO - Epoch 47, Step 161200: Loss=5.5440, Acc=0.267, 
2025-09-28 17:59:20,927 - training.trainer - INFO - Epoch 47, Step 161300: Loss=4.9813, Acc=0.289, 
2025-09-28 17:59:28,254 - training.trainer - INFO - Epoch 47, Step 161400: Loss=5.2838, Acc=0.273, 
2025-09-28 17:59:35,634 - training.trainer - INFO - Epoch 47, Step 161500: Loss=5.7807, Acc=0.238, 
2025-09-28 17:59:43,038 - training.trainer - INFO - Epoch 47, Step 161600: Loss=5.8429, Acc=0.227, 
2025-09-28 17:59:50,384 - training.trainer - INFO - Epoch 47, Step 161700: Loss=5.6832, Acc=0.267, 
2025-09-28 17:59:57,922 - training.trainer - INFO - Epoch 47, Step 161800: Loss=5.7742, Acc=0.256, 
2025-09-28 18:00:05,493 - training.trainer - INFO - Epoch 47, Step 161900: Loss=5.7396, Acc=0.243, 
2025-09-28 18:00:12,902 - training.trainer - INFO - Epoch 47, Step 162000: Loss=6.1459, Acc=0.229, 
2025-09-28 18:00:20,286 - training.trainer - INFO - Epoch 47, Step 162100: Loss=5.9937, Acc=0.286, 
2025-09-28 18:00:27,788 - training.trainer - INFO - Epoch 47, Step 162200: Loss=5.2424, Acc=0.318, 
2025-09-28 18:00:35,273 - training.trainer - INFO - Epoch 47, Step 162300: Loss=5.4436, Acc=0.333, 
2025-09-28 18:00:54,590 - training.trainer - INFO - Epoch 48/100 completed in 264.27s - Train Loss: 5.1714, Train Acc: 0.332, Val Loss: 5.7010, Val Acc: 0.262
2025-09-28 18:01:02,452 - training.trainer - INFO - Epoch 48, Step 162483: Loss=5.8816, Acc=0.245, 
2025-09-28 18:01:09,826 - training.trainer - INFO - Epoch 48, Step 162583: Loss=3.8089, Acc=0.581, 
2025-09-28 18:01:17,280 - training.trainer - INFO - Epoch 48, Step 162683: Loss=5.7453, Acc=0.192, 
2025-09-28 18:01:24,937 - training.trainer - INFO - Epoch 48, Step 162783: Loss=5.0657, Acc=0.286, 
2025-09-28 18:01:32,515 - training.trainer - INFO - Epoch 48, Step 162883: Loss=4.6626, Acc=0.292, 
2025-09-28 18:01:39,943 - training.trainer - INFO - Epoch 48, Step 162983: Loss=5.7374, Acc=0.261, 
2025-09-28 18:01:47,257 - training.trainer - INFO - Epoch 48, Step 163083: Loss=5.3884, Acc=0.314, 
2025-09-28 18:01:54,578 - training.trainer - INFO - Epoch 48, Step 163183: Loss=3.9060, Acc=0.565, 
2025-09-28 18:02:02,070 - training.trainer - INFO - Epoch 48, Step 163283: Loss=3.4207, Acc=0.500, 
2025-09-28 18:02:09,645 - training.trainer - INFO - Epoch 48, Step 163383: Loss=4.8324, Acc=0.353, 
2025-09-28 18:02:16,986 - training.trainer - INFO - Epoch 48, Step 163483: Loss=4.5787, Acc=0.333, 
2025-09-28 18:02:24,376 - training.trainer - INFO - Epoch 48, Step 163583: Loss=5.4998, Acc=0.190, 
2025-09-28 18:02:31,817 - training.trainer - INFO - Epoch 48, Step 163683: Loss=6.1369, Acc=0.231, 
2025-09-28 18:02:39,341 - training.trainer - INFO - Epoch 48, Step 163783: Loss=5.1105, Acc=0.300, 
2025-09-28 18:02:46,745 - training.trainer - INFO - Epoch 48, Step 163883: Loss=5.4334, Acc=0.220, 
2025-09-28 18:02:54,209 - training.trainer - INFO - Epoch 48, Step 163983: Loss=5.3040, Acc=0.375, 
2025-09-28 18:03:01,640 - training.trainer - INFO - Epoch 48, Step 164083: Loss=5.6783, Acc=0.200, 
2025-09-28 18:03:09,529 - training.trainer - INFO - Epoch 48, Step 164183: Loss=4.7915, Acc=0.304, 
2025-09-28 18:03:16,893 - training.trainer - INFO - Epoch 48, Step 164283: Loss=4.6847, Acc=0.391, 
2025-09-28 18:03:24,323 - training.trainer - INFO - Epoch 48, Step 164383: Loss=3.0049, Acc=0.667, 
2025-09-28 18:03:31,779 - training.trainer - INFO - Epoch 48, Step 164483: Loss=5.3599, Acc=0.279, 
2025-09-28 18:03:39,490 - training.trainer - INFO - Epoch 48, Step 164583: Loss=4.8176, Acc=0.292, 
2025-09-28 18:03:46,928 - training.trainer - INFO - Epoch 48, Step 164683: Loss=6.1679, Acc=0.258, 
2025-09-28 18:03:54,362 - training.trainer - INFO - Epoch 48, Step 164783: Loss=5.2336, Acc=0.390, 
2025-09-28 18:04:01,727 - training.trainer - INFO - Epoch 48, Step 164883: Loss=4.9446, Acc=0.361, 
2025-09-28 18:04:09,115 - training.trainer - INFO - Epoch 48, Step 164983: Loss=4.4180, Acc=0.308, 
2025-09-28 18:04:16,711 - training.trainer - INFO - Epoch 48, Step 165083: Loss=5.2260, Acc=0.292, 
2025-09-28 18:04:24,220 - training.trainer - INFO - Epoch 48, Step 165183: Loss=3.8659, Acc=0.583, 
2025-09-28 18:04:31,640 - training.trainer - INFO - Epoch 48, Step 165283: Loss=5.2987, Acc=0.324, 
2025-09-28 18:04:39,186 - training.trainer - INFO - Epoch 48, Step 165383: Loss=5.6776, Acc=0.203, 
2025-09-28 18:04:46,694 - training.trainer - INFO - Epoch 48, Step 165483: Loss=4.7998, Acc=0.298, 
2025-09-28 18:04:54,075 - training.trainer - INFO - Epoch 48, Step 165583: Loss=4.4427, Acc=0.348, 
2025-09-28 18:05:01,573 - training.trainer - INFO - Epoch 48, Step 165683: Loss=5.0283, Acc=0.314, 
2025-09-28 18:05:20,482 - training.trainer - INFO - Epoch 49/100 completed in 265.89s - Train Loss: 5.1609, Train Acc: 0.334, Val Loss: 5.7146, Val Acc: 0.261
2025-09-28 18:05:20,483 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-09-28 18:05:20,483 - training.trainer - INFO - Training completed!
2025-09-28 18:05:20,484 - __main__ - INFO - Training completed successfully!
2025-09-28 18:05:20,591 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-28 18:05:20,864 - __main__ - INFO - Process completed!
2025-09-28 18:05:32,584 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-28 18:05:32,584 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-28 18:05:32,585 - __main__ - INFO - Starting model evaluation
2025-09-28 18:05:33,792 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-28 18:10:54,823 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-28 18:10:54,840 - __main__ - INFO - Process completed!
2025-09-28 18:11:01,169 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-28 18:11:01,169 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-28 18:11:01,170 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-09-28 18:11:01,924 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-28 18:14:19,450 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-28 18:14:19,450 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-28 18:14:19,450 - __main__ - ERROR - Input file required for inference mode
2025-09-28 18:16:00,565 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-28 18:16:00,565 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-28 18:16:00,565 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-09-28 18:16:01,074 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-28 18:16:21,761 - __main__ - INFO - Inference completed successfully!
2025-09-28 18:16:21,772 - __main__ - INFO - Process completed!
2025-09-28 18:23:07,083 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-09-28 18:23:07,083 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-28 18:23:07,083 - __main__ - INFO - Starting training pipeline
2025-09-28 18:23:07,190 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-09-28 18:23:07,219 - __main__ - INFO - GPU: NVIDIA A30
2025-09-28 18:23:07,219 - __main__ - INFO - GPU Memory: 23.5 GB
2025-09-28 18:23:07,220 - __main__ - INFO - Loading training data...
2025-09-28 18:23:14,730 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-09-28 18:23:14,730 - __main__ - INFO - Processing train split...
2025-09-28 18:23:14,817 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-09-28 18:23:14,817 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-09-28 18:23:56,013 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-09-28 18:24:36,516 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-09-28 18:25:17,821 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-09-28 18:25:58,032 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-09-28 18:26:38,200 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-09-28 18:27:16,930 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-09-28 18:27:47,065 - __main__ - INFO - Processing val split...
2025-09-28 18:27:47,286 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-09-28 18:27:47,286 - __main__ - INFO -   Processed 0/845 samples from val...
2025-09-28 18:28:20,001 - __main__ - INFO - Processing test split...
2025-09-28 18:28:20,205 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-09-28 18:28:20,205 - __main__ - INFO -   Processed 0/847 samples from test...
2025-09-28 18:28:53,111 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-09-28 18:28:53,111 - __main__ - INFO - Creating vocabulary from training texts...
2025-09-28 18:28:53,131 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-09-28 18:28:53,131 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-09-28 18:28:53,132 - __main__ - INFO - Creating model architecture...
2025-09-28 18:28:53,444 - __main__ - INFO - Model created successfully
2025-09-28 18:28:53,446 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-09-28 18:28:53,446 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-09-28 18:28:53,447 - __main__ - INFO - Using device: cuda
2025-09-28 18:28:53,447 - __main__ - INFO - Creating trainer...
2025-09-28 18:28:53,447 - __main__ - INFO - Moving model to cuda...
2025-09-28 18:28:53,748 - __main__ - INFO - Model moved to cuda
2025-09-28 18:28:53,748 - __main__ - INFO - Model parameters are on: cuda:0
2025-09-28 18:28:55,339 - __main__ - INFO - Trainer created successfully
2025-09-28 18:28:55,339 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-09-28 18:28:55,339 - __main__ - INFO - Starting training...
2025-09-28 18:28:55,339 - __main__ - INFO - Training configuration:
2025-09-28 18:28:55,339 - __main__ - INFO -   - Epochs: 100
2025-09-28 18:28:55,339 - __main__ - INFO -   - Batch size: 2
2025-09-28 18:28:55,339 - __main__ - INFO -   - Learning rate: 3e-5
2025-09-28 18:28:55,339 - __main__ - INFO -   - Training samples: 6765
2025-09-28 18:28:55,340 - __main__ - INFO -   - Validation samples: 845
2025-09-28 18:28:55,340 - training.trainer - INFO - Starting training for 100 epochs
2025-09-28 18:28:55,340 - training.trainer - INFO - Model parameters: 16,680,032
2025-09-28 18:28:55,340 - training.trainer - INFO - Training on device: cuda
2025-09-28 18:29:04,069 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.8287, Acc=0.028, 
2025-09-28 18:29:11,264 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.2795, Acc=0.093, 
2025-09-28 18:29:18,561 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.7574, Acc=0.054, 
2025-09-28 18:29:25,776 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.3822, Acc=0.073, 
2025-09-28 18:29:32,476 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.7729, Acc=0.211, 
2025-09-28 18:29:39,538 - training.trainer - INFO - Epoch 0, Step 599: Loss=6.9718, Acc=0.050, 
2025-09-28 18:29:46,461 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.9735, Acc=0.267, 
2025-09-28 18:29:53,785 - training.trainer - INFO - Epoch 0, Step 799: Loss=7.2335, Acc=0.147, 
2025-09-28 18:30:01,156 - training.trainer - INFO - Epoch 0, Step 899: Loss=7.4127, Acc=0.130, 
2025-09-28 18:30:08,563 - training.trainer - INFO - Epoch 0, Step 999: Loss=6.8172, Acc=0.060, 
2025-09-28 18:30:15,980 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.1491, Acc=0.200, 
2025-09-28 18:30:22,740 - training.trainer - INFO - Epoch 0, Step 1199: Loss=5.5006, Acc=0.238, 
2025-09-28 18:30:30,467 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.8359, Acc=0.102, 
2025-09-28 18:30:38,362 - training.trainer - INFO - Epoch 0, Step 1399: Loss=7.0280, Acc=0.093, 
2025-09-28 18:30:46,187 - training.trainer - INFO - Epoch 0, Step 1499: Loss=6.6355, Acc=0.091, 
2025-09-28 18:30:54,037 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.7915, Acc=0.136, 
2025-09-28 18:31:01,835 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.5972, Acc=0.107, 
2025-09-28 18:31:09,538 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.3825, Acc=0.143, 
2025-09-28 18:31:17,203 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.8087, Acc=0.103, 
2025-09-28 18:31:24,989 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.4727, Acc=0.128, 
2025-09-28 18:31:32,834 - training.trainer - INFO - Epoch 0, Step 2099: Loss=7.1085, Acc=0.148, 
2025-09-28 18:31:40,507 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.8675, Acc=0.114, 
2025-09-28 18:31:48,044 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.5921, Acc=0.156, 
2025-09-28 18:31:55,687 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.3142, Acc=0.300, 
2025-09-28 18:32:03,325 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.8232, Acc=0.152, 
2025-09-28 18:32:10,979 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.7236, Acc=0.130, 
2025-09-28 18:32:18,744 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.7541, Acc=0.167, 
2025-09-28 18:32:26,389 - training.trainer - INFO - Epoch 0, Step 2799: Loss=5.9017, Acc=0.179, 
2025-09-28 18:32:33,935 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.6740, Acc=0.109, 
2025-09-28 18:32:41,655 - training.trainer - INFO - Epoch 0, Step 2999: Loss=5.8141, Acc=0.211, 
2025-09-28 18:32:49,174 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.6537, Acc=0.132, 
2025-09-28 18:32:56,598 - training.trainer - INFO - Epoch 0, Step 3199: Loss=6.4955, Acc=0.132, 
2025-09-28 18:33:04,085 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.9654, Acc=0.208, 
2025-09-28 18:33:23,391 - training.trainer - INFO - Epoch 1/100 completed in 268.05s - Train Loss: 6.8312, Train Acc: 0.128, Val Loss: 6.3555, Val Acc: 0.166
2025-09-28 18:33:23,972 - training.trainer - INFO - New best model saved with validation loss: 6.3555
2025-09-28 18:33:23,972 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-09-28 18:33:31,421 - training.trainer - INFO - Epoch 1, Step 3482: Loss=5.6513, Acc=0.227, 
2025-09-28 18:33:38,697 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.5302, Acc=0.177, 
2025-09-28 18:33:46,191 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.5326, Acc=0.156, 
2025-09-28 18:33:53,579 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.3603, Acc=0.214, 
2025-09-28 18:34:01,262 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.5014, Acc=0.148, 
2025-09-28 18:34:08,874 - training.trainer - INFO - Epoch 1, Step 3982: Loss=5.9709, Acc=0.200, 
2025-09-28 18:34:16,428 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.5180, Acc=0.094, 
2025-09-28 18:34:24,083 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.5398, Acc=0.125, 
2025-09-28 18:34:31,708 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.2191, Acc=0.211, 
2025-09-28 18:34:39,320 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.1019, Acc=0.155, 
2025-09-28 18:34:46,903 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.7117, Acc=0.152, 
2025-09-28 18:34:54,550 - training.trainer - INFO - Epoch 1, Step 4582: Loss=5.8056, Acc=0.149, 
2025-09-28 18:35:02,052 - training.trainer - INFO - Epoch 1, Step 4682: Loss=6.8972, Acc=0.082, 
2025-09-28 18:35:09,609 - training.trainer - INFO - Epoch 1, Step 4782: Loss=6.4510, Acc=0.114, 
2025-09-28 18:35:17,221 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.8557, Acc=0.146, 
2025-09-28 18:35:24,764 - training.trainer - INFO - Epoch 1, Step 4982: Loss=5.9074, Acc=0.182, 
2025-09-28 18:35:32,221 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.1242, Acc=0.079, 
2025-09-28 18:35:39,755 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.6220, Acc=0.103, 
2025-09-28 18:35:47,375 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.9291, Acc=0.115, 
2025-09-28 18:35:54,879 - training.trainer - INFO - Epoch 1, Step 5382: Loss=5.8887, Acc=0.333, 
2025-09-28 18:36:02,365 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.1862, Acc=0.163, 
2025-09-28 18:36:09,839 - training.trainer - INFO - Epoch 1, Step 5582: Loss=6.8320, Acc=0.104, 
2025-09-28 18:36:17,290 - training.trainer - INFO - Epoch 1, Step 5682: Loss=7.6054, Acc=0.106, 
2025-09-28 18:36:24,733 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.4350, Acc=0.120, 
2025-09-28 18:36:32,699 - training.trainer - INFO - Epoch 1, Step 5882: Loss=5.9805, Acc=0.167, 
2025-09-28 18:36:40,295 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.8856, Acc=0.133, 
2025-09-28 18:36:47,850 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.7897, Acc=0.164, 
2025-09-28 18:36:55,388 - training.trainer - INFO - Epoch 1, Step 6182: Loss=5.2092, Acc=0.286, 
2025-09-28 18:37:02,928 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.0581, Acc=0.200, 
2025-09-28 18:37:10,389 - training.trainer - INFO - Epoch 1, Step 6382: Loss=5.8384, Acc=0.205, 
2025-09-28 18:37:17,823 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.0441, Acc=0.151, 
2025-09-28 18:37:25,339 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.1748, Acc=0.150, 
2025-09-28 18:37:32,876 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.4177, Acc=0.162, 
2025-09-28 18:37:51,871 - training.trainer - INFO - Epoch 2/100 completed in 267.90s - Train Loss: 6.3152, Train Acc: 0.168, Val Loss: 6.1940, Val Acc: 0.177
2025-09-28 18:37:52,734 - training.trainer - INFO - New best model saved with validation loss: 6.1940
2025-09-28 18:37:52,734 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-09-28 18:38:00,603 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.1458, Acc=0.143, 
2025-09-28 18:38:07,995 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.5317, Acc=0.143, 
2025-09-28 18:38:15,441 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.6116, Acc=0.132, 
2025-09-28 18:38:22,918 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.5055, Acc=0.113, 
2025-09-28 18:38:30,305 - training.trainer - INFO - Epoch 2, Step 7265: Loss=5.6743, Acc=0.217, 
2025-09-28 18:38:37,705 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.3004, Acc=0.154, 
2025-09-28 18:38:45,226 - training.trainer - INFO - Epoch 2, Step 7465: Loss=6.3953, Acc=0.158, 
2025-09-28 18:38:52,692 - training.trainer - INFO - Epoch 2, Step 7565: Loss=5.7716, Acc=0.182, 
2025-09-28 18:39:00,089 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.1380, Acc=0.250, 
2025-09-28 18:39:07,465 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.9709, Acc=0.133, 
2025-09-28 18:39:14,997 - training.trainer - INFO - Epoch 2, Step 7865: Loss=5.7723, Acc=0.212, 
2025-09-28 18:39:22,323 - training.trainer - INFO - Epoch 2, Step 7965: Loss=6.5362, Acc=0.125, 
2025-09-28 18:39:29,716 - training.trainer - INFO - Epoch 2, Step 8065: Loss=5.9114, Acc=0.154, 
2025-09-28 18:39:37,116 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.1084, Acc=0.133, 
2025-09-28 18:39:44,711 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.5433, Acc=0.095, 
2025-09-28 18:39:52,453 - training.trainer - INFO - Epoch 2, Step 8365: Loss=5.9678, Acc=0.179, 
2025-09-28 18:39:59,935 - training.trainer - INFO - Epoch 2, Step 8465: Loss=5.7525, Acc=0.316, 
2025-09-28 18:40:07,506 - training.trainer - INFO - Epoch 2, Step 8565: Loss=6.3999, Acc=0.132, 
2025-09-28 18:40:14,953 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.2461, Acc=0.132, 
2025-09-28 18:40:22,556 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.1107, Acc=0.174, 
2025-09-28 18:40:29,965 - training.trainer - INFO - Epoch 2, Step 8865: Loss=5.8066, Acc=0.250, 
2025-09-28 18:40:37,440 - training.trainer - INFO - Epoch 2, Step 8965: Loss=5.6991, Acc=0.162, 
2025-09-28 18:40:44,906 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.3724, Acc=0.194, 
2025-09-28 18:40:52,560 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.1391, Acc=0.186, 
2025-09-28 18:40:59,889 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.5554, Acc=0.229, 
2025-09-28 18:41:07,188 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.5637, Acc=0.098, 
2025-09-28 18:41:14,559 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.3578, Acc=0.136, 
2025-09-28 18:41:21,896 - training.trainer - INFO - Epoch 2, Step 9565: Loss=5.9389, Acc=0.234, 
2025-09-28 18:41:29,184 - training.trainer - INFO - Epoch 2, Step 9665: Loss=6.0766, Acc=0.133, 
2025-09-28 18:41:36,429 - training.trainer - INFO - Epoch 2, Step 9765: Loss=5.7126, Acc=0.148, 
2025-09-28 18:41:43,562 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.0550, Acc=0.200, 
2025-09-28 18:41:50,859 - training.trainer - INFO - Epoch 2, Step 9965: Loss=5.7020, Acc=0.353, 
2025-09-28 18:41:58,229 - training.trainer - INFO - Epoch 2, Step 10065: Loss=5.8831, Acc=0.125, 
2025-09-28 18:42:17,927 - training.trainer - INFO - Epoch 3/100 completed in 265.19s - Train Loss: 6.1991, Train Acc: 0.179, Val Loss: 6.1159, Val Acc: 0.185
2025-09-28 18:42:18,528 - training.trainer - INFO - New best model saved with validation loss: 6.1159
2025-09-28 18:42:18,529 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-09-28 18:42:25,434 - training.trainer - INFO - Epoch 3, Step 10248: Loss=5.0554, Acc=0.333, 
2025-09-28 18:42:32,994 - training.trainer - INFO - Epoch 3, Step 10348: Loss=6.5252, Acc=0.120, 
2025-09-28 18:42:40,528 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.1653, Acc=0.204, 
2025-09-28 18:42:47,737 - training.trainer - INFO - Epoch 3, Step 10548: Loss=6.3691, Acc=0.191, 
2025-09-28 18:42:55,327 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.1874, Acc=0.180, 
2025-09-28 18:43:02,798 - training.trainer - INFO - Epoch 3, Step 10748: Loss=5.6226, Acc=0.192, 
2025-09-28 18:43:10,258 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.2132, Acc=0.226, 
2025-09-28 18:43:17,665 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.0949, Acc=0.241, 
2025-09-28 18:43:25,073 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.2052, Acc=0.163, 
2025-09-28 18:43:32,490 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.1318, Acc=0.128, 
2025-09-28 18:43:39,933 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.6742, Acc=0.111, 
2025-09-28 18:43:47,272 - training.trainer - INFO - Epoch 3, Step 11348: Loss=5.8622, Acc=0.195, 
2025-09-28 18:43:54,611 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.0264, Acc=0.226, 
2025-09-28 18:44:01,907 - training.trainer - INFO - Epoch 3, Step 11548: Loss=6.6256, Acc=0.137, 
2025-09-28 18:44:09,342 - training.trainer - INFO - Epoch 3, Step 11648: Loss=6.4577, Acc=0.120, 
2025-09-28 18:44:16,758 - training.trainer - INFO - Epoch 3, Step 11748: Loss=6.5837, Acc=0.171, 
2025-09-28 18:44:24,040 - training.trainer - INFO - Epoch 3, Step 11848: Loss=6.1307, Acc=0.114, 
2025-09-28 18:44:31,449 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.4801, Acc=0.214, 
2025-09-28 18:44:38,893 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.3123, Acc=0.121, 
2025-09-28 18:44:46,495 - training.trainer - INFO - Epoch 3, Step 12148: Loss=5.9805, Acc=0.333, 
2025-09-28 18:44:53,847 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.0382, Acc=0.171, 
2025-09-28 18:45:01,307 - training.trainer - INFO - Epoch 3, Step 12348: Loss=5.9919, Acc=0.229, 
2025-09-28 18:45:08,702 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.5350, Acc=0.136, 
2025-09-28 18:45:16,152 - training.trainer - INFO - Epoch 3, Step 12548: Loss=5.4642, Acc=0.333, 
2025-09-28 18:45:23,614 - training.trainer - INFO - Epoch 3, Step 12648: Loss=6.4176, Acc=0.167, 
2025-09-28 18:45:30,953 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.0791, Acc=0.172, 
2025-09-28 18:45:38,493 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.1779, Acc=0.107, 
2025-09-28 18:45:45,905 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.7011, Acc=0.103, 
2025-09-28 18:45:53,200 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.1184, Acc=0.209, 
2025-09-28 18:46:00,509 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.4100, Acc=0.143, 
2025-09-28 18:46:08,257 - training.trainer - INFO - Epoch 3, Step 13248: Loss=7.0130, Acc=0.133, 
2025-09-28 18:46:15,765 - training.trainer - INFO - Epoch 3, Step 13348: Loss=5.8035, Acc=0.231, 
2025-09-28 18:46:23,322 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.0956, Acc=0.231, 
2025-09-28 18:46:42,629 - training.trainer - INFO - Epoch 4/100 completed in 264.10s - Train Loss: 6.1316, Train Acc: 0.186, Val Loss: 6.0463, Val Acc: 0.195
2025-09-28 18:46:43,362 - training.trainer - INFO - New best model saved with validation loss: 6.0463
2025-09-28 18:46:43,362 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-09-28 18:46:51,201 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.1864, Acc=0.179, 
2025-09-28 18:46:58,784 - training.trainer - INFO - Epoch 4, Step 13731: Loss=6.4991, Acc=0.220, 
2025-09-28 18:47:06,231 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.2603, Acc=0.172, 
2025-09-28 18:47:13,758 - training.trainer - INFO - Epoch 4, Step 13931: Loss=7.0084, Acc=0.084, 
2025-09-28 18:47:21,215 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.6272, Acc=0.222, 
2025-09-28 18:47:29,098 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.5736, Acc=0.100, 
2025-09-28 18:47:36,634 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.2002, Acc=0.182, 
2025-09-28 18:47:44,171 - training.trainer - INFO - Epoch 4, Step 14331: Loss=5.9328, Acc=0.280, 
2025-09-28 18:47:51,570 - training.trainer - INFO - Epoch 4, Step 14431: Loss=6.0597, Acc=0.250, 
2025-09-28 18:47:59,004 - training.trainer - INFO - Epoch 4, Step 14531: Loss=5.0654, Acc=0.250, 
2025-09-28 18:48:06,297 - training.trainer - INFO - Epoch 4, Step 14631: Loss=4.8216, Acc=0.318, 
2025-09-28 18:48:13,603 - training.trainer - INFO - Epoch 4, Step 14731: Loss=6.0042, Acc=0.179, 
2025-09-28 18:48:20,798 - training.trainer - INFO - Epoch 4, Step 14831: Loss=5.9313, Acc=0.241, 
2025-09-28 18:48:28,070 - training.trainer - INFO - Epoch 4, Step 14931: Loss=5.8749, Acc=0.286, 
2025-09-28 18:48:35,343 - training.trainer - INFO - Epoch 4, Step 15031: Loss=5.4872, Acc=0.190, 
2025-09-28 18:48:42,562 - training.trainer - INFO - Epoch 4, Step 15131: Loss=5.9471, Acc=0.226, 
2025-09-28 18:48:49,714 - training.trainer - INFO - Epoch 4, Step 15231: Loss=5.5403, Acc=0.174, 
2025-09-28 18:48:56,954 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.3940, Acc=0.171, 
2025-09-28 18:49:04,254 - training.trainer - INFO - Epoch 4, Step 15431: Loss=5.2890, Acc=0.391, 
2025-09-28 18:49:11,458 - training.trainer - INFO - Epoch 4, Step 15531: Loss=5.9293, Acc=0.308, 
2025-09-28 18:49:18,757 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.5810, Acc=0.182, 
2025-09-28 18:49:26,101 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.1737, Acc=0.161, 
2025-09-28 18:49:33,351 - training.trainer - INFO - Epoch 4, Step 15831: Loss=6.4783, Acc=0.182, 
2025-09-28 18:49:40,931 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.3352, Acc=0.175, 
2025-09-28 18:49:48,157 - training.trainer - INFO - Epoch 4, Step 16031: Loss=5.7783, Acc=0.222, 
2025-09-28 18:49:55,536 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.1990, Acc=0.206, 
2025-09-28 18:50:02,996 - training.trainer - INFO - Epoch 4, Step 16231: Loss=6.1371, Acc=0.125, 
2025-09-28 18:50:10,449 - training.trainer - INFO - Epoch 4, Step 16331: Loss=6.4284, Acc=0.146, 
2025-09-28 18:50:17,852 - training.trainer - INFO - Epoch 4, Step 16431: Loss=6.5158, Acc=0.160, 
2025-09-28 18:50:25,186 - training.trainer - INFO - Epoch 4, Step 16531: Loss=6.2519, Acc=0.200, 
2025-09-28 18:50:32,568 - training.trainer - INFO - Epoch 4, Step 16631: Loss=6.0920, Acc=0.158, 
2025-09-28 18:50:40,014 - training.trainer - INFO - Epoch 4, Step 16731: Loss=5.3344, Acc=0.275, 
2025-09-28 18:50:47,395 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.4277, Acc=0.146, 
2025-09-28 18:51:06,552 - training.trainer - INFO - Epoch 5/100 completed in 263.19s - Train Loss: 6.0790, Train Acc: 0.195, Val Loss: 5.9967, Val Acc: 0.202
2025-09-28 18:51:06,911 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-28 18:51:07,669 - training.trainer - INFO - New best model saved with validation loss: 5.9967
2025-09-28 18:51:07,669 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-09-28 18:51:15,586 - training.trainer - INFO - Epoch 5, Step 17014: Loss=6.5229, Acc=0.090, 
2025-09-28 18:51:22,975 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.1983, Acc=0.205, 
2025-09-28 18:51:30,319 - training.trainer - INFO - Epoch 5, Step 17214: Loss=6.5771, Acc=0.167, 
2025-09-28 18:51:37,694 - training.trainer - INFO - Epoch 5, Step 17314: Loss=5.3585, Acc=0.400, 
2025-09-28 18:51:45,140 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.6371, Acc=0.152, 
2025-09-28 18:51:52,595 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.6431, Acc=0.160, 
2025-09-28 18:52:00,144 - training.trainer - INFO - Epoch 5, Step 17614: Loss=5.1908, Acc=0.250, 
2025-09-28 18:52:07,636 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.6209, Acc=0.289, 
2025-09-28 18:52:14,980 - training.trainer - INFO - Epoch 5, Step 17814: Loss=6.6906, Acc=0.176, 
2025-09-28 18:52:22,274 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.7668, Acc=0.111, 
2025-09-28 18:52:29,627 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.5568, Acc=0.136, 
2025-09-28 18:52:37,043 - training.trainer - INFO - Epoch 5, Step 18114: Loss=5.8725, Acc=0.208, 
2025-09-28 18:52:44,292 - training.trainer - INFO - Epoch 5, Step 18214: Loss=6.7453, Acc=0.150, 
2025-09-28 18:52:51,637 - training.trainer - INFO - Epoch 5, Step 18314: Loss=6.6276, Acc=0.167, 
2025-09-28 18:52:59,030 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.0352, Acc=0.333, 
2025-09-28 18:53:06,541 - training.trainer - INFO - Epoch 5, Step 18514: Loss=5.6714, Acc=0.217, 
2025-09-28 18:53:13,969 - training.trainer - INFO - Epoch 5, Step 18614: Loss=6.7247, Acc=0.222, 
2025-09-28 18:53:21,394 - training.trainer - INFO - Epoch 5, Step 18714: Loss=3.2428, Acc=0.600, 
2025-09-28 18:53:28,900 - training.trainer - INFO - Epoch 5, Step 18814: Loss=5.8614, Acc=0.226, 
2025-09-28 18:53:36,255 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.9711, Acc=0.143, 
2025-09-28 18:53:43,505 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.0796, Acc=0.246, 
2025-09-28 18:53:50,862 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.2801, Acc=0.154, 
2025-09-28 18:53:58,250 - training.trainer - INFO - Epoch 5, Step 19214: Loss=6.2741, Acc=0.157, 
2025-09-28 18:54:05,567 - training.trainer - INFO - Epoch 5, Step 19314: Loss=5.0112, Acc=0.267, 
2025-09-28 18:54:12,780 - training.trainer - INFO - Epoch 5, Step 19414: Loss=7.0956, Acc=0.104, 
2025-09-28 18:54:20,376 - training.trainer - INFO - Epoch 5, Step 19514: Loss=6.0037, Acc=0.182, 
2025-09-28 18:54:27,557 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.0290, Acc=0.140, 
2025-09-28 18:54:35,031 - training.trainer - INFO - Epoch 5, Step 19714: Loss=5.5966, Acc=0.148, 
2025-09-28 18:54:42,391 - training.trainer - INFO - Epoch 5, Step 19814: Loss=5.3329, Acc=0.241, 
2025-09-28 18:54:49,685 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.6751, Acc=0.205, 
2025-09-28 18:54:57,178 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.3803, Acc=0.158, 
2025-09-28 18:55:04,618 - training.trainer - INFO - Epoch 5, Step 20114: Loss=5.2187, Acc=0.180, 
2025-09-28 18:55:12,075 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.5093, Acc=0.174, 
2025-09-28 18:55:31,033 - training.trainer - INFO - Epoch 6/100 completed in 263.36s - Train Loss: 6.0258, Train Acc: 0.202, Val Loss: 5.9555, Val Acc: 0.209
2025-09-28 18:55:31,873 - training.trainer - INFO - New best model saved with validation loss: 5.9555
2025-09-28 18:55:31,874 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-09-28 18:55:40,055 - training.trainer - INFO - Epoch 6, Step 20397: Loss=4.5772, Acc=0.318, 
2025-09-28 18:55:47,692 - training.trainer - INFO - Epoch 6, Step 20497: Loss=5.3901, Acc=0.333, 
2025-09-28 18:55:55,070 - training.trainer - INFO - Epoch 6, Step 20597: Loss=4.8596, Acc=0.357, 
2025-09-28 18:56:02,506 - training.trainer - INFO - Epoch 6, Step 20697: Loss=6.6572, Acc=0.111, 
2025-09-28 18:56:10,373 - training.trainer - INFO - Epoch 6, Step 20797: Loss=5.4470, Acc=0.273, 
2025-09-28 18:56:17,785 - training.trainer - INFO - Epoch 6, Step 20897: Loss=6.6861, Acc=0.123, 
2025-09-28 18:56:25,184 - training.trainer - INFO - Epoch 6, Step 20997: Loss=6.1335, Acc=0.192, 
2025-09-28 18:56:32,547 - training.trainer - INFO - Epoch 6, Step 21097: Loss=6.1710, Acc=0.182, 
2025-09-28 18:56:39,980 - training.trainer - INFO - Epoch 6, Step 21197: Loss=6.1992, Acc=0.260, 
2025-09-28 18:56:47,344 - training.trainer - INFO - Epoch 6, Step 21297: Loss=5.4365, Acc=0.214, 
2025-09-28 18:56:54,675 - training.trainer - INFO - Epoch 6, Step 21397: Loss=5.4238, Acc=0.259, 
2025-09-28 18:57:02,008 - training.trainer - INFO - Epoch 6, Step 21497: Loss=6.7684, Acc=0.179, 
2025-09-28 18:57:09,342 - training.trainer - INFO - Epoch 6, Step 21597: Loss=5.4190, Acc=0.273, 
2025-09-28 18:57:16,703 - training.trainer - INFO - Epoch 6, Step 21697: Loss=5.9299, Acc=0.163, 
2025-09-28 18:57:23,965 - training.trainer - INFO - Epoch 6, Step 21797: Loss=5.6081, Acc=0.273, 
2025-09-28 18:57:31,281 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.3419, Acc=0.162, 
2025-09-28 18:57:38,638 - training.trainer - INFO - Epoch 6, Step 21997: Loss=6.3005, Acc=0.286, 
2025-09-28 18:57:46,034 - training.trainer - INFO - Epoch 6, Step 22097: Loss=6.1522, Acc=0.136, 
2025-09-28 18:57:53,427 - training.trainer - INFO - Epoch 6, Step 22197: Loss=5.9371, Acc=0.231, 
2025-09-28 18:58:00,736 - training.trainer - INFO - Epoch 6, Step 22297: Loss=5.9265, Acc=0.236, 
2025-09-28 18:58:08,083 - training.trainer - INFO - Epoch 6, Step 22397: Loss=6.6042, Acc=0.122, 
2025-09-28 18:58:15,431 - training.trainer - INFO - Epoch 6, Step 22497: Loss=3.9803, Acc=0.278, 
2025-09-28 18:58:22,828 - training.trainer - INFO - Epoch 6, Step 22597: Loss=7.1290, Acc=0.123, 
2025-09-28 18:58:30,135 - training.trainer - INFO - Epoch 6, Step 22697: Loss=5.0669, Acc=0.265, 
2025-09-28 18:58:37,514 - training.trainer - INFO - Epoch 6, Step 22797: Loss=6.4612, Acc=0.179, 
2025-09-28 18:58:44,891 - training.trainer - INFO - Epoch 6, Step 22897: Loss=5.7957, Acc=0.188, 
2025-09-28 18:58:52,341 - training.trainer - INFO - Epoch 6, Step 22997: Loss=4.5460, Acc=0.317, 
2025-09-28 18:58:59,641 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.0619, Acc=0.167, 
2025-09-28 18:59:06,958 - training.trainer - INFO - Epoch 6, Step 23197: Loss=4.0029, Acc=0.455, 
2025-09-28 18:59:14,384 - training.trainer - INFO - Epoch 6, Step 23297: Loss=5.7959, Acc=0.156, 
2025-09-28 18:59:21,789 - training.trainer - INFO - Epoch 6, Step 23397: Loss=6.4946, Acc=0.137, 
2025-09-28 18:59:29,339 - training.trainer - INFO - Epoch 6, Step 23497: Loss=6.1069, Acc=0.182, 
2025-09-28 18:59:37,328 - training.trainer - INFO - Epoch 6, Step 23597: Loss=5.0428, Acc=0.208, 
2025-09-28 18:59:56,576 - training.trainer - INFO - Epoch 7/100 completed in 264.70s - Train Loss: 5.9834, Train Acc: 0.208, Val Loss: 5.9114, Val Acc: 0.217
2025-09-28 18:59:57,366 - training.trainer - INFO - New best model saved with validation loss: 5.9114
2025-09-28 18:59:57,367 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-09-28 19:00:04,462 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.5222, Acc=0.148, 
2025-09-28 19:00:11,257 - training.trainer - INFO - Epoch 7, Step 23880: Loss=5.8761, Acc=0.154, 
2025-09-28 19:00:18,018 - training.trainer - INFO - Epoch 7, Step 23980: Loss=6.5511, Acc=0.177, 
2025-09-28 19:00:24,860 - training.trainer - INFO - Epoch 7, Step 24080: Loss=6.1680, Acc=0.177, 
2025-09-28 19:00:31,793 - training.trainer - INFO - Epoch 7, Step 24180: Loss=6.0307, Acc=0.208, 
2025-09-28 19:00:38,232 - training.trainer - INFO - Epoch 7, Step 24280: Loss=6.0088, Acc=0.148, 
2025-09-28 19:00:45,475 - training.trainer - INFO - Epoch 7, Step 24380: Loss=4.8099, Acc=0.333, 
2025-09-28 19:00:53,081 - training.trainer - INFO - Epoch 7, Step 24480: Loss=5.8956, Acc=0.278, 
2025-09-28 19:01:00,526 - training.trainer - INFO - Epoch 7, Step 24580: Loss=6.6207, Acc=0.258, 
2025-09-28 19:01:07,994 - training.trainer - INFO - Epoch 7, Step 24680: Loss=5.2998, Acc=0.167, 
2025-09-28 19:01:15,359 - training.trainer - INFO - Epoch 7, Step 24780: Loss=5.0793, Acc=0.300, 
2025-09-28 19:01:22,722 - training.trainer - INFO - Epoch 7, Step 24880: Loss=5.3415, Acc=0.259, 
2025-09-28 19:01:30,073 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.4402, Acc=0.214, 
2025-09-28 19:01:37,614 - training.trainer - INFO - Epoch 7, Step 25080: Loss=6.4463, Acc=0.114, 
2025-09-28 19:01:44,991 - training.trainer - INFO - Epoch 7, Step 25180: Loss=5.8062, Acc=0.294, 
2025-09-28 19:01:52,376 - training.trainer - INFO - Epoch 7, Step 25280: Loss=6.1035, Acc=0.190, 
2025-09-28 19:01:59,859 - training.trainer - INFO - Epoch 7, Step 25380: Loss=6.1808, Acc=0.209, 
2025-09-28 19:02:07,411 - training.trainer - INFO - Epoch 7, Step 25480: Loss=5.7973, Acc=0.130, 
2025-09-28 19:02:14,689 - training.trainer - INFO - Epoch 7, Step 25580: Loss=5.8043, Acc=0.174, 
2025-09-28 19:02:22,385 - training.trainer - INFO - Epoch 7, Step 25680: Loss=6.4619, Acc=0.185, 
2025-09-28 19:02:30,090 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.4756, Acc=0.200, 
2025-09-28 19:02:37,609 - training.trainer - INFO - Epoch 7, Step 25880: Loss=5.7135, Acc=0.231, 
2025-09-28 19:02:45,243 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.0645, Acc=0.188, 
2025-09-28 19:02:52,547 - training.trainer - INFO - Epoch 7, Step 26080: Loss=5.8149, Acc=0.235, 
2025-09-28 19:02:59,817 - training.trainer - INFO - Epoch 7, Step 26180: Loss=5.5360, Acc=0.286, 
2025-09-28 19:03:07,079 - training.trainer - INFO - Epoch 7, Step 26280: Loss=5.5401, Acc=0.205, 
2025-09-28 19:03:14,390 - training.trainer - INFO - Epoch 7, Step 26380: Loss=3.8036, Acc=0.474, 
2025-09-28 19:03:21,710 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.4086, Acc=0.182, 
2025-09-28 19:03:29,135 - training.trainer - INFO - Epoch 7, Step 26580: Loss=6.4929, Acc=0.215, 
2025-09-28 19:03:36,461 - training.trainer - INFO - Epoch 7, Step 26680: Loss=4.6232, Acc=0.333, 
2025-09-28 19:03:43,692 - training.trainer - INFO - Epoch 7, Step 26780: Loss=5.8222, Acc=0.139, 
2025-09-28 19:03:51,035 - training.trainer - INFO - Epoch 7, Step 26880: Loss=5.3990, Acc=0.227, 
2025-09-28 19:03:58,300 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.5883, Acc=0.263, 
2025-09-28 19:04:18,256 - training.trainer - INFO - Epoch 8/100 completed in 260.89s - Train Loss: 5.9360, Train Acc: 0.215, Val Loss: 5.8833, Val Acc: 0.221
2025-09-28 19:04:19,010 - training.trainer - INFO - New best model saved with validation loss: 5.8833
2025-09-28 19:04:19,011 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-09-28 19:04:27,019 - training.trainer - INFO - Epoch 8, Step 27163: Loss=6.1649, Acc=0.182, 
2025-09-28 19:04:34,371 - training.trainer - INFO - Epoch 8, Step 27263: Loss=5.7533, Acc=0.200, 
2025-09-28 19:04:42,317 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.5346, Acc=0.196, 
2025-09-28 19:04:49,799 - training.trainer - INFO - Epoch 8, Step 27463: Loss=5.8985, Acc=0.262, 
2025-09-28 19:04:57,341 - training.trainer - INFO - Epoch 8, Step 27563: Loss=5.5925, Acc=0.212, 
2025-09-28 19:05:04,637 - training.trainer - INFO - Epoch 8, Step 27663: Loss=6.5637, Acc=0.172, 
2025-09-28 19:05:11,943 - training.trainer - INFO - Epoch 8, Step 27763: Loss=6.5535, Acc=0.175, 
2025-09-28 19:05:19,286 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.4772, Acc=0.175, 
2025-09-28 19:05:26,722 - training.trainer - INFO - Epoch 8, Step 27963: Loss=6.2380, Acc=0.182, 
2025-09-28 19:05:34,018 - training.trainer - INFO - Epoch 8, Step 28063: Loss=6.1040, Acc=0.240, 
2025-09-28 19:05:41,344 - training.trainer - INFO - Epoch 8, Step 28163: Loss=5.5199, Acc=0.267, 
2025-09-28 19:05:48,594 - training.trainer - INFO - Epoch 8, Step 28263: Loss=5.4232, Acc=0.300, 
2025-09-28 19:05:55,953 - training.trainer - INFO - Epoch 8, Step 28363: Loss=5.6821, Acc=0.149, 
2025-09-28 19:06:03,328 - training.trainer - INFO - Epoch 8, Step 28463: Loss=5.9312, Acc=0.196, 
2025-09-28 19:06:10,653 - training.trainer - INFO - Epoch 8, Step 28563: Loss=5.8080, Acc=0.250, 
2025-09-28 19:06:18,081 - training.trainer - INFO - Epoch 8, Step 28663: Loss=5.9586, Acc=0.196, 
2025-09-28 19:06:25,491 - training.trainer - INFO - Epoch 8, Step 28763: Loss=6.2147, Acc=0.158, 
2025-09-28 19:06:33,109 - training.trainer - INFO - Epoch 8, Step 28863: Loss=5.6623, Acc=0.333, 
2025-09-28 19:06:40,728 - training.trainer - INFO - Epoch 8, Step 28963: Loss=6.1592, Acc=0.235, 
2025-09-28 19:06:48,184 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.4491, Acc=0.235, 
2025-09-28 19:06:55,612 - training.trainer - INFO - Epoch 8, Step 29163: Loss=6.4257, Acc=0.113, 
2025-09-28 19:07:03,253 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.3839, Acc=0.141, 
2025-09-28 19:07:10,793 - training.trainer - INFO - Epoch 8, Step 29363: Loss=5.8301, Acc=0.150, 
2025-09-28 19:07:18,342 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.1727, Acc=0.116, 
2025-09-28 19:07:25,918 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.1206, Acc=0.375, 
2025-09-28 19:07:33,500 - training.trainer - INFO - Epoch 8, Step 29663: Loss=5.5445, Acc=0.216, 
2025-09-28 19:07:41,226 - training.trainer - INFO - Epoch 8, Step 29763: Loss=6.0374, Acc=0.250, 
2025-09-28 19:07:48,795 - training.trainer - INFO - Epoch 8, Step 29863: Loss=5.7386, Acc=0.261, 
2025-09-28 19:07:56,308 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.2040, Acc=0.207, 
2025-09-28 19:08:03,801 - training.trainer - INFO - Epoch 8, Step 30063: Loss=6.1459, Acc=0.111, 
2025-09-28 19:08:10,896 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.9341, Acc=0.154, 
2025-09-28 19:08:18,055 - training.trainer - INFO - Epoch 8, Step 30263: Loss=5.8597, Acc=0.186, 
2025-09-28 19:08:25,600 - training.trainer - INFO - Epoch 8, Step 30363: Loss=6.1208, Acc=0.147, 
2025-09-28 19:08:44,819 - training.trainer - INFO - Epoch 9/100 completed in 265.81s - Train Loss: 5.9086, Train Acc: 0.219, Val Loss: 5.8522, Val Acc: 0.223
2025-09-28 19:08:45,514 - training.trainer - INFO - New best model saved with validation loss: 5.8522
2025-09-28 19:08:45,515 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-09-28 19:08:53,505 - training.trainer - INFO - Epoch 9, Step 30546: Loss=6.0717, Acc=0.136, 
2025-09-28 19:09:01,085 - training.trainer - INFO - Epoch 9, Step 30646: Loss=5.2105, Acc=0.222, 
2025-09-28 19:09:08,575 - training.trainer - INFO - Epoch 9, Step 30746: Loss=5.6611, Acc=0.225, 
2025-09-28 19:09:16,205 - training.trainer - INFO - Epoch 9, Step 30846: Loss=6.7742, Acc=0.156, 
2025-09-28 19:09:23,647 - training.trainer - INFO - Epoch 9, Step 30946: Loss=5.9768, Acc=0.200, 
2025-09-28 19:09:31,059 - training.trainer - INFO - Epoch 9, Step 31046: Loss=5.5276, Acc=0.333, 
2025-09-28 19:09:38,517 - training.trainer - INFO - Epoch 9, Step 31146: Loss=6.0984, Acc=0.224, 
2025-09-28 19:09:46,083 - training.trainer - INFO - Epoch 9, Step 31246: Loss=5.6320, Acc=0.172, 
2025-09-28 19:09:53,635 - training.trainer - INFO - Epoch 9, Step 31346: Loss=5.6742, Acc=0.269, 
2025-09-28 19:10:01,291 - training.trainer - INFO - Epoch 9, Step 31446: Loss=6.2891, Acc=0.161, 
2025-09-28 19:10:08,844 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.8248, Acc=0.227, 
2025-09-28 19:10:16,340 - training.trainer - INFO - Epoch 9, Step 31646: Loss=4.8815, Acc=0.320, 
2025-09-28 19:10:23,766 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.2125, Acc=0.263, 
2025-09-28 19:10:31,104 - training.trainer - INFO - Epoch 9, Step 31846: Loss=5.7240, Acc=0.167, 
2025-09-28 19:10:38,438 - training.trainer - INFO - Epoch 9, Step 31946: Loss=6.0118, Acc=0.207, 
2025-09-28 19:10:45,822 - training.trainer - INFO - Epoch 9, Step 32046: Loss=6.3738, Acc=0.158, 
2025-09-28 19:10:53,186 - training.trainer - INFO - Epoch 9, Step 32146: Loss=6.1060, Acc=0.128, 
2025-09-28 19:11:00,704 - training.trainer - INFO - Epoch 9, Step 32246: Loss=6.3585, Acc=0.222, 
2025-09-28 19:11:08,156 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.9046, Acc=0.185, 
2025-09-28 19:11:15,574 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.0471, Acc=0.294, 
2025-09-28 19:11:22,927 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.8082, Acc=0.250, 
2025-09-28 19:11:30,473 - training.trainer - INFO - Epoch 9, Step 32646: Loss=6.3005, Acc=0.194, 
2025-09-28 19:11:37,974 - training.trainer - INFO - Epoch 9, Step 32746: Loss=6.2523, Acc=0.188, 
2025-09-28 19:11:45,288 - training.trainer - INFO - Epoch 9, Step 32846: Loss=6.4173, Acc=0.250, 
2025-09-28 19:11:52,605 - training.trainer - INFO - Epoch 9, Step 32946: Loss=6.8068, Acc=0.200, 
2025-09-28 19:12:00,133 - training.trainer - INFO - Epoch 9, Step 33046: Loss=5.6696, Acc=0.208, 
2025-09-28 19:12:07,725 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.7542, Acc=0.140, 
2025-09-28 19:12:15,143 - training.trainer - INFO - Epoch 9, Step 33246: Loss=3.7889, Acc=0.471, 
2025-09-28 19:12:23,124 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.2516, Acc=0.220, 
2025-09-28 19:12:30,662 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.1214, Acc=0.157, 
2025-09-28 19:12:38,071 - training.trainer - INFO - Epoch 9, Step 33546: Loss=6.0102, Acc=0.194, 
2025-09-28 19:12:45,603 - training.trainer - INFO - Epoch 9, Step 33646: Loss=5.2399, Acc=0.423, 
2025-09-28 19:12:53,079 - training.trainer - INFO - Epoch 9, Step 33746: Loss=6.1739, Acc=0.167, 
2025-09-28 19:13:12,529 - training.trainer - INFO - Epoch 10/100 completed in 267.01s - Train Loss: 5.8766, Train Acc: 0.224, Val Loss: 5.8406, Val Acc: 0.225
2025-09-28 19:13:12,892 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-28 19:13:13,582 - training.trainer - INFO - New best model saved with validation loss: 5.8406
2025-09-28 19:13:13,583 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-09-28 19:13:21,605 - training.trainer - INFO - Epoch 10, Step 33929: Loss=6.1887, Acc=0.136, 
2025-09-28 19:13:29,263 - training.trainer - INFO - Epoch 10, Step 34029: Loss=4.4387, Acc=0.350, 
2025-09-28 19:13:36,794 - training.trainer - INFO - Epoch 10, Step 34129: Loss=5.9710, Acc=0.286, 
2025-09-28 19:13:44,153 - training.trainer - INFO - Epoch 10, Step 34229: Loss=5.8717, Acc=0.267, 
2025-09-28 19:13:51,620 - training.trainer - INFO - Epoch 10, Step 34329: Loss=5.5902, Acc=0.180, 
2025-09-28 19:13:58,971 - training.trainer - INFO - Epoch 10, Step 34429: Loss=6.1114, Acc=0.200, 
2025-09-28 19:14:06,431 - training.trainer - INFO - Epoch 10, Step 34529: Loss=6.7109, Acc=0.135, 
2025-09-28 19:14:13,990 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.7674, Acc=0.250, 
2025-09-28 19:14:21,416 - training.trainer - INFO - Epoch 10, Step 34729: Loss=4.8774, Acc=0.300, 
2025-09-28 19:14:28,825 - training.trainer - INFO - Epoch 10, Step 34829: Loss=5.6391, Acc=0.160, 
2025-09-28 19:14:36,491 - training.trainer - INFO - Epoch 10, Step 34929: Loss=6.3015, Acc=0.182, 
2025-09-28 19:14:43,986 - training.trainer - INFO - Epoch 10, Step 35029: Loss=6.9666, Acc=0.179, 
2025-09-28 19:14:51,450 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.1125, Acc=0.175, 
2025-09-28 19:14:58,779 - training.trainer - INFO - Epoch 10, Step 35229: Loss=5.7803, Acc=0.267, 
2025-09-28 19:15:06,186 - training.trainer - INFO - Epoch 10, Step 35329: Loss=5.7908, Acc=0.205, 
2025-09-28 19:15:13,571 - training.trainer - INFO - Epoch 10, Step 35429: Loss=5.8143, Acc=0.278, 
2025-09-28 19:15:20,905 - training.trainer - INFO - Epoch 10, Step 35529: Loss=7.0407, Acc=0.185, 
2025-09-28 19:15:28,266 - training.trainer - INFO - Epoch 10, Step 35629: Loss=6.3336, Acc=0.167, 
2025-09-28 19:15:35,670 - training.trainer - INFO - Epoch 10, Step 35729: Loss=5.6796, Acc=0.235, 
2025-09-28 19:15:43,198 - training.trainer - INFO - Epoch 10, Step 35829: Loss=6.6686, Acc=0.183, 
2025-09-28 19:15:50,696 - training.trainer - INFO - Epoch 10, Step 35929: Loss=5.3355, Acc=0.250, 
2025-09-28 19:15:58,199 - training.trainer - INFO - Epoch 10, Step 36029: Loss=6.9430, Acc=0.159, 
2025-09-28 19:16:05,739 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.0692, Acc=0.250, 
2025-09-28 19:16:13,244 - training.trainer - INFO - Epoch 10, Step 36229: Loss=5.7083, Acc=0.250, 
2025-09-28 19:16:21,067 - training.trainer - INFO - Epoch 10, Step 36329: Loss=5.8423, Acc=0.286, 
2025-09-28 19:16:28,439 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.4724, Acc=0.205, 
2025-09-28 19:16:35,875 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.2289, Acc=0.321, 
2025-09-28 19:16:43,302 - training.trainer - INFO - Epoch 10, Step 36629: Loss=4.2158, Acc=0.385, 
2025-09-28 19:16:50,748 - training.trainer - INFO - Epoch 10, Step 36729: Loss=6.7154, Acc=0.171, 
2025-09-28 19:16:58,120 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.8241, Acc=0.172, 
2025-09-28 19:17:05,511 - training.trainer - INFO - Epoch 10, Step 36929: Loss=5.9090, Acc=0.227, 
2025-09-28 19:17:12,876 - training.trainer - INFO - Epoch 10, Step 37029: Loss=7.0040, Acc=0.121, 
2025-09-28 19:17:20,289 - training.trainer - INFO - Epoch 10, Step 37129: Loss=4.7397, Acc=0.294, 
2025-09-28 19:17:39,249 - training.trainer - INFO - Epoch 11/100 completed in 265.67s - Train Loss: 5.8530, Train Acc: 0.229, Val Loss: 5.8132, Val Acc: 0.229
2025-09-28 19:17:40,076 - training.trainer - INFO - New best model saved with validation loss: 5.8132
2025-09-28 19:17:40,076 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-09-28 19:17:48,232 - training.trainer - INFO - Epoch 11, Step 37312: Loss=5.6393, Acc=0.304, 
2025-09-28 19:17:56,154 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.1934, Acc=0.217, 
2025-09-28 19:18:03,662 - training.trainer - INFO - Epoch 11, Step 37512: Loss=6.2690, Acc=0.145, 
2025-09-28 19:18:11,073 - training.trainer - INFO - Epoch 11, Step 37612: Loss=5.1815, Acc=0.387, 
2025-09-28 19:18:18,459 - training.trainer - INFO - Epoch 11, Step 37712: Loss=6.1490, Acc=0.225, 
2025-09-28 19:18:25,930 - training.trainer - INFO - Epoch 11, Step 37812: Loss=5.4751, Acc=0.250, 
2025-09-28 19:18:33,418 - training.trainer - INFO - Epoch 11, Step 37912: Loss=6.0597, Acc=0.229, 
2025-09-28 19:18:40,897 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.2352, Acc=0.444, 
2025-09-28 19:18:48,286 - training.trainer - INFO - Epoch 11, Step 38112: Loss=6.2553, Acc=0.200, 
2025-09-28 19:18:55,596 - training.trainer - INFO - Epoch 11, Step 38212: Loss=5.7246, Acc=0.227, 
2025-09-28 19:19:03,041 - training.trainer - INFO - Epoch 11, Step 38312: Loss=5.9985, Acc=0.170, 
2025-09-28 19:19:10,418 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.9914, Acc=0.200, 
2025-09-28 19:19:17,792 - training.trainer - INFO - Epoch 11, Step 38512: Loss=4.0319, Acc=0.500, 
2025-09-28 19:19:25,201 - training.trainer - INFO - Epoch 11, Step 38612: Loss=6.3050, Acc=0.190, 
2025-09-28 19:19:32,657 - training.trainer - INFO - Epoch 11, Step 38712: Loss=6.5280, Acc=0.154, 
2025-09-28 19:19:40,156 - training.trainer - INFO - Epoch 11, Step 38812: Loss=6.7746, Acc=0.206, 
2025-09-28 19:19:47,520 - training.trainer - INFO - Epoch 11, Step 38912: Loss=5.1288, Acc=0.263, 
2025-09-28 19:19:54,897 - training.trainer - INFO - Epoch 11, Step 39012: Loss=6.7979, Acc=0.123, 
2025-09-28 19:20:02,175 - training.trainer - INFO - Epoch 11, Step 39112: Loss=6.4630, Acc=0.211, 
2025-09-28 19:20:09,551 - training.trainer - INFO - Epoch 11, Step 39212: Loss=5.3701, Acc=0.310, 
2025-09-28 19:20:16,872 - training.trainer - INFO - Epoch 11, Step 39312: Loss=6.0792, Acc=0.194, 
2025-09-28 19:20:24,463 - training.trainer - INFO - Epoch 11, Step 39412: Loss=6.0963, Acc=0.164, 
2025-09-28 19:20:32,088 - training.trainer - INFO - Epoch 11, Step 39512: Loss=5.7990, Acc=0.213, 
2025-09-28 19:20:39,616 - training.trainer - INFO - Epoch 11, Step 39612: Loss=4.7402, Acc=0.297, 
2025-09-28 19:20:47,045 - training.trainer - INFO - Epoch 11, Step 39712: Loss=5.5019, Acc=0.237, 
2025-09-28 19:20:54,457 - training.trainer - INFO - Epoch 11, Step 39812: Loss=5.6286, Acc=0.276, 
2025-09-28 19:21:01,808 - training.trainer - INFO - Epoch 11, Step 39912: Loss=6.5226, Acc=0.128, 
2025-09-28 19:21:09,369 - training.trainer - INFO - Epoch 11, Step 40012: Loss=5.7006, Acc=0.370, 
2025-09-28 19:21:16,832 - training.trainer - INFO - Epoch 11, Step 40112: Loss=6.2252, Acc=0.183, 
2025-09-28 19:21:24,126 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.9478, Acc=0.214, 
2025-09-28 19:21:31,515 - training.trainer - INFO - Epoch 11, Step 40312: Loss=6.0810, Acc=0.245, 
2025-09-28 19:21:38,978 - training.trainer - INFO - Epoch 11, Step 40412: Loss=6.5804, Acc=0.123, 
2025-09-28 19:21:46,762 - training.trainer - INFO - Epoch 11, Step 40512: Loss=5.6475, Acc=0.222, 
2025-09-28 19:22:06,155 - training.trainer - INFO - Epoch 12/100 completed in 266.08s - Train Loss: 5.8273, Train Acc: 0.230, Val Loss: 5.7924, Val Acc: 0.231
2025-09-28 19:22:06,989 - training.trainer - INFO - New best model saved with validation loss: 5.7924
2025-09-28 19:22:06,990 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-09-28 19:22:14,749 - training.trainer - INFO - Epoch 12, Step 40695: Loss=4.7853, Acc=0.409, 
2025-09-28 19:22:22,227 - training.trainer - INFO - Epoch 12, Step 40795: Loss=6.3393, Acc=0.174, 
2025-09-28 19:22:29,665 - training.trainer - INFO - Epoch 12, Step 40895: Loss=5.3061, Acc=0.333, 
2025-09-28 19:22:37,369 - training.trainer - INFO - Epoch 12, Step 40995: Loss=5.5096, Acc=0.196, 
2025-09-28 19:22:44,835 - training.trainer - INFO - Epoch 12, Step 41095: Loss=5.7489, Acc=0.250, 
2025-09-28 19:22:52,701 - training.trainer - INFO - Epoch 12, Step 41195: Loss=5.4839, Acc=0.213, 
2025-09-28 19:23:00,160 - training.trainer - INFO - Epoch 12, Step 41295: Loss=5.2672, Acc=0.238, 
2025-09-28 19:23:07,582 - training.trainer - INFO - Epoch 12, Step 41395: Loss=4.2592, Acc=0.440, 
2025-09-28 19:23:14,988 - training.trainer - INFO - Epoch 12, Step 41495: Loss=5.5316, Acc=0.205, 
2025-09-28 19:23:22,512 - training.trainer - INFO - Epoch 12, Step 41595: Loss=5.0391, Acc=0.250, 
2025-09-28 19:23:29,986 - training.trainer - INFO - Epoch 12, Step 41695: Loss=5.8798, Acc=0.229, 
2025-09-28 19:23:37,384 - training.trainer - INFO - Epoch 12, Step 41795: Loss=5.3175, Acc=0.314, 
2025-09-28 19:23:44,733 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.0975, Acc=0.200, 
2025-09-28 19:23:52,113 - training.trainer - INFO - Epoch 12, Step 41995: Loss=5.7867, Acc=0.250, 
2025-09-28 19:23:59,623 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.0969, Acc=0.276, 
2025-09-28 19:24:07,090 - training.trainer - INFO - Epoch 12, Step 42195: Loss=6.3659, Acc=0.179, 
2025-09-28 19:24:14,589 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.5649, Acc=0.250, 
2025-09-28 19:24:22,043 - training.trainer - INFO - Epoch 12, Step 42395: Loss=4.7857, Acc=0.323, 
2025-09-28 19:24:29,456 - training.trainer - INFO - Epoch 12, Step 42495: Loss=5.6796, Acc=0.143, 
2025-09-28 19:24:36,951 - training.trainer - INFO - Epoch 12, Step 42595: Loss=6.3917, Acc=0.169, 
2025-09-28 19:24:44,304 - training.trainer - INFO - Epoch 12, Step 42695: Loss=6.1912, Acc=0.169, 
2025-09-28 19:24:51,650 - training.trainer - INFO - Epoch 12, Step 42795: Loss=6.6945, Acc=0.238, 
2025-09-28 19:24:58,955 - training.trainer - INFO - Epoch 12, Step 42895: Loss=5.9892, Acc=0.190, 
2025-09-28 19:25:06,440 - training.trainer - INFO - Epoch 12, Step 42995: Loss=5.7001, Acc=0.273, 
2025-09-28 19:25:14,114 - training.trainer - INFO - Epoch 12, Step 43095: Loss=6.3814, Acc=0.173, 
2025-09-28 19:25:21,760 - training.trainer - INFO - Epoch 12, Step 43195: Loss=6.0927, Acc=0.167, 
2025-09-28 19:25:29,235 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.1371, Acc=0.192, 
2025-09-28 19:25:36,734 - training.trainer - INFO - Epoch 12, Step 43395: Loss=5.9393, Acc=0.243, 
2025-09-28 19:25:44,216 - training.trainer - INFO - Epoch 12, Step 43495: Loss=6.1050, Acc=0.250, 
2025-09-28 19:25:51,735 - training.trainer - INFO - Epoch 12, Step 43595: Loss=6.3766, Acc=0.191, 
2025-09-28 19:25:59,161 - training.trainer - INFO - Epoch 12, Step 43695: Loss=5.6164, Acc=0.250, 
2025-09-28 19:26:06,533 - training.trainer - INFO - Epoch 12, Step 43795: Loss=5.7984, Acc=0.200, 
2025-09-28 19:26:13,951 - training.trainer - INFO - Epoch 12, Step 43895: Loss=5.3974, Acc=0.255, 
2025-09-28 19:26:32,806 - training.trainer - INFO - Epoch 13/100 completed in 265.82s - Train Loss: 5.8021, Train Acc: 0.235, Val Loss: 5.7748, Val Acc: 0.233
2025-09-28 19:26:33,575 - training.trainer - INFO - New best model saved with validation loss: 5.7748
2025-09-28 19:26:33,576 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-09-28 19:26:40,936 - training.trainer - INFO - Epoch 13, Step 44078: Loss=4.8940, Acc=0.407, 
2025-09-28 19:26:48,001 - training.trainer - INFO - Epoch 13, Step 44178: Loss=4.2933, Acc=0.471, 
2025-09-28 19:26:54,982 - training.trainer - INFO - Epoch 13, Step 44278: Loss=5.1705, Acc=0.259, 
2025-09-28 19:27:01,976 - training.trainer - INFO - Epoch 13, Step 44378: Loss=5.8174, Acc=0.226, 
2025-09-28 19:27:08,989 - training.trainer - INFO - Epoch 13, Step 44478: Loss=5.3774, Acc=0.259, 
2025-09-28 19:27:16,442 - training.trainer - INFO - Epoch 13, Step 44578: Loss=6.2061, Acc=0.153, 
2025-09-28 19:27:23,819 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.4802, Acc=0.367, 
2025-09-28 19:27:31,356 - training.trainer - INFO - Epoch 13, Step 44778: Loss=6.8575, Acc=0.143, 
2025-09-28 19:27:38,927 - training.trainer - INFO - Epoch 13, Step 44878: Loss=4.8405, Acc=0.381, 
2025-09-28 19:27:46,714 - training.trainer - INFO - Epoch 13, Step 44978: Loss=5.7628, Acc=0.200, 
2025-09-28 19:27:54,335 - training.trainer - INFO - Epoch 13, Step 45078: Loss=6.0973, Acc=0.227, 
2025-09-28 19:28:02,070 - training.trainer - INFO - Epoch 13, Step 45178: Loss=6.1424, Acc=0.120, 
2025-09-28 19:28:09,610 - training.trainer - INFO - Epoch 13, Step 45278: Loss=6.3372, Acc=0.125, 
2025-09-28 19:28:17,064 - training.trainer - INFO - Epoch 13, Step 45378: Loss=5.8018, Acc=0.259, 
2025-09-28 19:28:24,494 - training.trainer - INFO - Epoch 13, Step 45478: Loss=4.3551, Acc=0.406, 
2025-09-28 19:28:31,742 - training.trainer - INFO - Epoch 13, Step 45578: Loss=5.7803, Acc=0.250, 
2025-09-28 19:28:39,323 - training.trainer - INFO - Epoch 13, Step 45678: Loss=6.0702, Acc=0.239, 
2025-09-28 19:28:46,708 - training.trainer - INFO - Epoch 13, Step 45778: Loss=5.1112, Acc=0.263, 
2025-09-28 19:28:54,000 - training.trainer - INFO - Epoch 13, Step 45878: Loss=6.0844, Acc=0.231, 
2025-09-28 19:29:01,448 - training.trainer - INFO - Epoch 13, Step 45978: Loss=5.5935, Acc=0.350, 
2025-09-28 19:29:08,758 - training.trainer - INFO - Epoch 13, Step 46078: Loss=6.0491, Acc=0.146, 
2025-09-28 19:29:16,427 - training.trainer - INFO - Epoch 13, Step 46178: Loss=6.1823, Acc=0.212, 
2025-09-28 19:29:23,856 - training.trainer - INFO - Epoch 13, Step 46278: Loss=5.8485, Acc=0.227, 
2025-09-28 19:29:31,246 - training.trainer - INFO - Epoch 13, Step 46378: Loss=6.8178, Acc=0.200, 
2025-09-28 19:29:38,519 - training.trainer - INFO - Epoch 13, Step 46478: Loss=6.0262, Acc=0.217, 
2025-09-28 19:29:45,916 - training.trainer - INFO - Epoch 13, Step 46578: Loss=5.8100, Acc=0.122, 
2025-09-28 19:29:53,209 - training.trainer - INFO - Epoch 13, Step 46678: Loss=6.2863, Acc=0.158, 
2025-09-28 19:30:00,620 - training.trainer - INFO - Epoch 13, Step 46778: Loss=6.6192, Acc=0.167, 
2025-09-28 19:30:07,944 - training.trainer - INFO - Epoch 13, Step 46878: Loss=6.0024, Acc=0.254, 
2025-09-28 19:30:15,173 - training.trainer - INFO - Epoch 13, Step 46978: Loss=5.8201, Acc=0.182, 
2025-09-28 19:30:22,487 - training.trainer - INFO - Epoch 13, Step 47078: Loss=5.2133, Acc=0.367, 
2025-09-28 19:30:29,753 - training.trainer - INFO - Epoch 13, Step 47178: Loss=5.9927, Acc=0.308, 
2025-09-28 19:30:37,346 - training.trainer - INFO - Epoch 13, Step 47278: Loss=6.1813, Acc=0.222, 
2025-09-28 19:30:56,718 - training.trainer - INFO - Epoch 14/100 completed in 263.14s - Train Loss: 5.7748, Train Acc: 0.238, Val Loss: 5.7719, Val Acc: 0.235
2025-09-28 19:30:57,309 - training.trainer - INFO - New best model saved with validation loss: 5.7719
2025-09-28 19:30:57,309 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-09-28 19:31:04,147 - training.trainer - INFO - Epoch 14, Step 47461: Loss=6.2635, Acc=0.262, 
2025-09-28 19:31:10,344 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.3864, Acc=0.318, 
2025-09-28 19:31:16,568 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.5323, Acc=0.286, 
2025-09-28 19:31:23,438 - training.trainer - INFO - Epoch 14, Step 47761: Loss=5.1427, Acc=0.275, 
2025-09-28 19:31:31,135 - training.trainer - INFO - Epoch 14, Step 47861: Loss=6.6165, Acc=0.129, 
2025-09-28 19:31:38,857 - training.trainer - INFO - Epoch 14, Step 47961: Loss=6.0771, Acc=0.173, 
2025-09-28 19:31:46,262 - training.trainer - INFO - Epoch 14, Step 48061: Loss=6.2504, Acc=0.158, 
2025-09-28 19:31:53,739 - training.trainer - INFO - Epoch 14, Step 48161: Loss=6.1512, Acc=0.167, 
2025-09-28 19:32:01,228 - training.trainer - INFO - Epoch 14, Step 48261: Loss=6.2343, Acc=0.167, 
2025-09-28 19:32:08,752 - training.trainer - INFO - Epoch 14, Step 48361: Loss=6.3100, Acc=0.187, 
2025-09-28 19:32:16,350 - training.trainer - INFO - Epoch 14, Step 48461: Loss=6.0299, Acc=0.195, 
2025-09-28 19:32:23,771 - training.trainer - INFO - Epoch 14, Step 48561: Loss=5.9170, Acc=0.206, 
2025-09-28 19:32:31,077 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.7159, Acc=0.257, 
2025-09-28 19:32:38,424 - training.trainer - INFO - Epoch 14, Step 48761: Loss=5.2240, Acc=0.286, 
2025-09-28 19:32:45,937 - training.trainer - INFO - Epoch 14, Step 48861: Loss=5.5123, Acc=0.267, 
2025-09-28 19:32:53,247 - training.trainer - INFO - Epoch 14, Step 48961: Loss=6.1929, Acc=0.250, 
2025-09-28 19:33:00,565 - training.trainer - INFO - Epoch 14, Step 49061: Loss=5.9865, Acc=0.173, 
2025-09-28 19:33:08,070 - training.trainer - INFO - Epoch 14, Step 49161: Loss=6.5651, Acc=0.152, 
2025-09-28 19:33:15,378 - training.trainer - INFO - Epoch 14, Step 49261: Loss=4.8222, Acc=0.368, 
2025-09-28 19:33:22,843 - training.trainer - INFO - Epoch 14, Step 49361: Loss=5.5163, Acc=0.250, 
2025-09-28 19:33:30,119 - training.trainer - INFO - Epoch 14, Step 49461: Loss=5.9687, Acc=0.178, 
2025-09-28 19:33:37,490 - training.trainer - INFO - Epoch 14, Step 49561: Loss=3.2253, Acc=0.652, 
2025-09-28 19:33:44,806 - training.trainer - INFO - Epoch 14, Step 49661: Loss=5.6522, Acc=0.344, 
2025-09-28 19:33:52,406 - training.trainer - INFO - Epoch 14, Step 49761: Loss=5.3407, Acc=0.350, 
2025-09-28 19:33:59,702 - training.trainer - INFO - Epoch 14, Step 49861: Loss=4.8852, Acc=0.474, 
2025-09-28 19:34:06,966 - training.trainer - INFO - Epoch 14, Step 49961: Loss=5.7577, Acc=0.250, 
2025-09-28 19:34:14,246 - training.trainer - INFO - Epoch 14, Step 50061: Loss=6.2305, Acc=0.141, 
2025-09-28 19:34:21,675 - training.trainer - INFO - Epoch 14, Step 50161: Loss=6.3165, Acc=0.119, 
2025-09-28 19:34:29,177 - training.trainer - INFO - Epoch 14, Step 50261: Loss=5.8726, Acc=0.106, 
2025-09-28 19:34:36,761 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.5357, Acc=0.179, 
2025-09-28 19:34:44,081 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.5164, Acc=0.387, 
2025-09-28 19:34:51,436 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.4548, Acc=0.237, 
2025-09-28 19:34:59,104 - training.trainer - INFO - Epoch 14, Step 50661: Loss=5.9502, Acc=0.200, 
2025-09-28 19:35:18,445 - training.trainer - INFO - Epoch 15/100 completed in 261.14s - Train Loss: 5.7586, Train Acc: 0.242, Val Loss: 5.7512, Val Acc: 0.240
2025-09-28 19:35:18,823 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-28 19:35:19,514 - training.trainer - INFO - New best model saved with validation loss: 5.7512
2025-09-28 19:35:19,514 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-09-28 19:35:27,302 - training.trainer - INFO - Epoch 15, Step 50844: Loss=6.0385, Acc=0.290, 
2025-09-28 19:35:34,929 - training.trainer - INFO - Epoch 15, Step 50944: Loss=6.2890, Acc=0.160, 
2025-09-28 19:35:42,231 - training.trainer - INFO - Epoch 15, Step 51044: Loss=4.5390, Acc=0.379, 
2025-09-28 19:35:49,717 - training.trainer - INFO - Epoch 15, Step 51144: Loss=5.8221, Acc=0.233, 
2025-09-28 19:35:57,390 - training.trainer - INFO - Epoch 15, Step 51244: Loss=5.6441, Acc=0.244, 
2025-09-28 19:36:04,815 - training.trainer - INFO - Epoch 15, Step 51344: Loss=6.0994, Acc=0.192, 
2025-09-28 19:36:12,404 - training.trainer - INFO - Epoch 15, Step 51444: Loss=5.4888, Acc=0.312, 
2025-09-28 19:36:19,922 - training.trainer - INFO - Epoch 15, Step 51544: Loss=6.3439, Acc=0.133, 
2025-09-28 19:36:27,308 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.6853, Acc=0.225, 
2025-09-28 19:36:34,673 - training.trainer - INFO - Epoch 15, Step 51744: Loss=5.3095, Acc=0.269, 
2025-09-28 19:36:42,067 - training.trainer - INFO - Epoch 15, Step 51844: Loss=5.8747, Acc=0.236, 
2025-09-28 19:36:49,339 - training.trainer - INFO - Epoch 15, Step 51944: Loss=6.4648, Acc=0.191, 
2025-09-28 19:36:56,677 - training.trainer - INFO - Epoch 15, Step 52044: Loss=6.3282, Acc=0.243, 
2025-09-28 19:37:04,023 - training.trainer - INFO - Epoch 15, Step 52144: Loss=4.6782, Acc=0.250, 
2025-09-28 19:37:11,416 - training.trainer - INFO - Epoch 15, Step 52244: Loss=5.8235, Acc=0.217, 
2025-09-28 19:37:18,714 - training.trainer - INFO - Epoch 15, Step 52344: Loss=6.1167, Acc=0.286, 
2025-09-28 19:37:26,011 - training.trainer - INFO - Epoch 15, Step 52444: Loss=6.1098, Acc=0.185, 
2025-09-28 19:37:33,413 - training.trainer - INFO - Epoch 15, Step 52544: Loss=6.5276, Acc=0.192, 
2025-09-28 19:37:40,733 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.6534, Acc=0.276, 
2025-09-28 19:37:47,950 - training.trainer - INFO - Epoch 15, Step 52744: Loss=5.4046, Acc=0.240, 
2025-09-28 19:37:55,201 - training.trainer - INFO - Epoch 15, Step 52844: Loss=6.5659, Acc=0.145, 
2025-09-28 19:38:02,489 - training.trainer - INFO - Epoch 15, Step 52944: Loss=6.0212, Acc=0.216, 
2025-09-28 19:38:09,875 - training.trainer - INFO - Epoch 15, Step 53044: Loss=6.3034, Acc=0.250, 
2025-09-28 19:38:17,417 - training.trainer - INFO - Epoch 15, Step 53144: Loss=6.0949, Acc=0.194, 
2025-09-28 19:38:24,957 - training.trainer - INFO - Epoch 15, Step 53244: Loss=6.1507, Acc=0.190, 
2025-09-28 19:38:32,472 - training.trainer - INFO - Epoch 15, Step 53344: Loss=6.2189, Acc=0.171, 
2025-09-28 19:38:40,042 - training.trainer - INFO - Epoch 15, Step 53444: Loss=6.0460, Acc=0.224, 
2025-09-28 19:38:47,487 - training.trainer - INFO - Epoch 15, Step 53544: Loss=6.4576, Acc=0.238, 
2025-09-28 19:38:54,872 - training.trainer - INFO - Epoch 15, Step 53644: Loss=5.7804, Acc=0.184, 
2025-09-28 19:39:02,286 - training.trainer - INFO - Epoch 15, Step 53744: Loss=6.1225, Acc=0.229, 
2025-09-28 19:39:09,613 - training.trainer - INFO - Epoch 15, Step 53844: Loss=5.7089, Acc=0.217, 
2025-09-28 19:39:17,185 - training.trainer - INFO - Epoch 15, Step 53944: Loss=6.1939, Acc=0.250, 
2025-09-28 19:39:24,598 - training.trainer - INFO - Epoch 15, Step 54044: Loss=4.7416, Acc=0.438, 
2025-09-28 19:39:43,828 - training.trainer - INFO - Epoch 16/100 completed in 264.31s - Train Loss: 5.7355, Train Acc: 0.244, Val Loss: 5.7340, Val Acc: 0.245
2025-09-28 19:39:44,435 - training.trainer - INFO - New best model saved with validation loss: 5.7340
2025-09-28 19:39:44,436 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-09-28 19:39:52,366 - training.trainer - INFO - Epoch 16, Step 54227: Loss=5.8924, Acc=0.400, 
2025-09-28 19:40:00,169 - training.trainer - INFO - Epoch 16, Step 54327: Loss=4.9946, Acc=0.258, 
2025-09-28 19:40:07,762 - training.trainer - INFO - Epoch 16, Step 54427: Loss=6.3254, Acc=0.200, 
2025-09-28 19:40:15,131 - training.trainer - INFO - Epoch 16, Step 54527: Loss=5.3383, Acc=0.278, 
2025-09-28 19:40:23,114 - training.trainer - INFO - Epoch 16, Step 54627: Loss=5.5769, Acc=0.241, 
2025-09-28 19:40:30,597 - training.trainer - INFO - Epoch 16, Step 54727: Loss=6.0449, Acc=0.183, 
2025-09-28 19:40:38,086 - training.trainer - INFO - Epoch 16, Step 54827: Loss=5.5385, Acc=0.257, 
2025-09-28 19:40:45,398 - training.trainer - INFO - Epoch 16, Step 54927: Loss=5.6507, Acc=0.256, 
2025-09-28 19:40:52,738 - training.trainer - INFO - Epoch 16, Step 55027: Loss=5.1000, Acc=0.286, 
2025-09-28 19:41:00,109 - training.trainer - INFO - Epoch 16, Step 55127: Loss=5.4686, Acc=0.189, 
2025-09-28 19:41:07,425 - training.trainer - INFO - Epoch 16, Step 55227: Loss=5.4661, Acc=0.250, 
2025-09-28 19:41:14,700 - training.trainer - INFO - Epoch 16, Step 55327: Loss=6.4964, Acc=0.152, 
2025-09-28 19:41:22,029 - training.trainer - INFO - Epoch 16, Step 55427: Loss=6.2383, Acc=0.214, 
2025-09-28 19:41:29,334 - training.trainer - INFO - Epoch 16, Step 55527: Loss=4.8306, Acc=0.333, 
2025-09-28 19:41:36,558 - training.trainer - INFO - Epoch 16, Step 55627: Loss=5.9992, Acc=0.308, 
2025-09-28 19:41:43,766 - training.trainer - INFO - Epoch 16, Step 55727: Loss=6.4571, Acc=0.147, 
2025-09-28 19:41:50,954 - training.trainer - INFO - Epoch 16, Step 55827: Loss=5.7555, Acc=0.306, 
2025-09-28 19:41:58,198 - training.trainer - INFO - Epoch 16, Step 55927: Loss=5.9473, Acc=0.231, 
2025-09-28 19:42:05,576 - training.trainer - INFO - Epoch 16, Step 56027: Loss=4.3673, Acc=0.400, 
2025-09-28 19:42:12,892 - training.trainer - INFO - Epoch 16, Step 56127: Loss=6.2279, Acc=0.137, 
2025-09-28 19:42:20,170 - training.trainer - INFO - Epoch 16, Step 56227: Loss=6.0647, Acc=0.209, 
2025-09-28 19:42:27,429 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.9404, Acc=0.222, 
2025-09-28 19:42:34,692 - training.trainer - INFO - Epoch 16, Step 56427: Loss=5.8740, Acc=0.212, 
2025-09-28 19:42:42,069 - training.trainer - INFO - Epoch 16, Step 56527: Loss=5.4695, Acc=0.273, 
2025-09-28 19:42:49,326 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.6370, Acc=0.219, 
2025-09-28 19:42:56,659 - training.trainer - INFO - Epoch 16, Step 56727: Loss=6.4962, Acc=0.179, 
2025-09-28 19:43:03,893 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.9372, Acc=0.233, 
2025-09-28 19:43:11,321 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.5260, Acc=0.245, 
2025-09-28 19:43:18,629 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.5741, Acc=0.237, 
2025-09-28 19:43:25,876 - training.trainer - INFO - Epoch 16, Step 57127: Loss=6.1238, Acc=0.172, 
2025-09-28 19:43:33,267 - training.trainer - INFO - Epoch 16, Step 57227: Loss=6.0472, Acc=0.200, 
2025-09-28 19:43:40,593 - training.trainer - INFO - Epoch 16, Step 57327: Loss=5.3023, Acc=0.265, 
2025-09-28 19:43:47,934 - training.trainer - INFO - Epoch 16, Step 57427: Loss=5.9986, Acc=0.286, 
2025-09-28 19:44:06,821 - training.trainer - INFO - Epoch 17/100 completed in 262.38s - Train Loss: 5.7076, Train Acc: 0.248, Val Loss: 5.7271, Val Acc: 0.244
2025-09-28 19:44:07,500 - training.trainer - INFO - New best model saved with validation loss: 5.7271
2025-09-28 19:44:07,500 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-09-28 19:44:15,317 - training.trainer - INFO - Epoch 17, Step 57610: Loss=6.0022, Acc=0.206, 
2025-09-28 19:44:23,108 - training.trainer - INFO - Epoch 17, Step 57710: Loss=6.0688, Acc=0.200, 
2025-09-28 19:44:30,456 - training.trainer - INFO - Epoch 17, Step 57810: Loss=5.5044, Acc=0.333, 
2025-09-28 19:44:37,755 - training.trainer - INFO - Epoch 17, Step 57910: Loss=6.8411, Acc=0.135, 
2025-09-28 19:44:45,137 - training.trainer - INFO - Epoch 17, Step 58010: Loss=6.1821, Acc=0.169, 
2025-09-28 19:44:52,408 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.0212, Acc=0.267, 
2025-09-28 19:44:59,805 - training.trainer - INFO - Epoch 17, Step 58210: Loss=5.8778, Acc=0.188, 
2025-09-28 19:45:07,112 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.6799, Acc=0.353, 
2025-09-28 19:45:14,602 - training.trainer - INFO - Epoch 17, Step 58410: Loss=6.4093, Acc=0.115, 
2025-09-28 19:45:22,208 - training.trainer - INFO - Epoch 17, Step 58510: Loss=4.2441, Acc=0.545, 
2025-09-28 19:45:29,618 - training.trainer - INFO - Epoch 17, Step 58610: Loss=6.0183, Acc=0.146, 
2025-09-28 19:45:36,958 - training.trainer - INFO - Epoch 17, Step 58710: Loss=5.5760, Acc=0.292, 
2025-09-28 19:45:44,237 - training.trainer - INFO - Epoch 17, Step 58810: Loss=5.9651, Acc=0.206, 
2025-09-28 19:45:51,550 - training.trainer - INFO - Epoch 17, Step 58910: Loss=6.1401, Acc=0.225, 
2025-09-28 19:45:58,855 - training.trainer - INFO - Epoch 17, Step 59010: Loss=6.6506, Acc=0.159, 
2025-09-28 19:46:06,134 - training.trainer - INFO - Epoch 17, Step 59110: Loss=4.9966, Acc=0.444, 
2025-09-28 19:46:13,392 - training.trainer - INFO - Epoch 17, Step 59210: Loss=5.8399, Acc=0.279, 
2025-09-28 19:46:20,640 - training.trainer - INFO - Epoch 17, Step 59310: Loss=5.8613, Acc=0.191, 
2025-09-28 19:46:28,269 - training.trainer - INFO - Epoch 17, Step 59410: Loss=6.3444, Acc=0.145, 
2025-09-28 19:46:35,577 - training.trainer - INFO - Epoch 17, Step 59510: Loss=5.8343, Acc=0.243, 
2025-09-28 19:46:42,956 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.2621, Acc=0.182, 
2025-09-28 19:46:50,276 - training.trainer - INFO - Epoch 17, Step 59710: Loss=5.7297, Acc=0.231, 
2025-09-28 19:46:57,587 - training.trainer - INFO - Epoch 17, Step 59810: Loss=5.7112, Acc=0.271, 
2025-09-28 19:47:04,919 - training.trainer - INFO - Epoch 17, Step 59910: Loss=6.4954, Acc=0.114, 
2025-09-28 19:47:12,178 - training.trainer - INFO - Epoch 17, Step 60010: Loss=6.3221, Acc=0.210, 
2025-09-28 19:47:19,496 - training.trainer - INFO - Epoch 17, Step 60110: Loss=5.3689, Acc=0.250, 
2025-09-28 19:47:26,986 - training.trainer - INFO - Epoch 17, Step 60210: Loss=5.4687, Acc=0.222, 
2025-09-28 19:47:34,369 - training.trainer - INFO - Epoch 17, Step 60310: Loss=4.6957, Acc=0.375, 
2025-09-28 19:47:41,633 - training.trainer - INFO - Epoch 17, Step 60410: Loss=5.6202, Acc=0.265, 
2025-09-28 19:47:48,822 - training.trainer - INFO - Epoch 17, Step 60510: Loss=5.9230, Acc=0.181, 
2025-09-28 19:47:56,041 - training.trainer - INFO - Epoch 17, Step 60610: Loss=5.3918, Acc=0.268, 
2025-09-28 19:48:03,339 - training.trainer - INFO - Epoch 17, Step 60710: Loss=6.0349, Acc=0.261, 
2025-09-28 19:48:10,529 - training.trainer - INFO - Epoch 17, Step 60810: Loss=5.6925, Acc=0.167, 
2025-09-28 19:48:29,883 - training.trainer - INFO - Epoch 18/100 completed in 262.38s - Train Loss: 5.6846, Train Acc: 0.252, Val Loss: 5.7265, Val Acc: 0.244
2025-09-28 19:48:30,699 - training.trainer - INFO - New best model saved with validation loss: 5.7265
2025-09-28 19:48:30,700 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-09-28 19:48:38,240 - training.trainer - INFO - Epoch 18, Step 60993: Loss=4.6471, Acc=0.250, 
2025-09-28 19:48:45,534 - training.trainer - INFO - Epoch 18, Step 61093: Loss=4.9784, Acc=0.345, 
2025-09-28 19:48:52,853 - training.trainer - INFO - Epoch 18, Step 61193: Loss=5.9389, Acc=0.169, 
2025-09-28 19:49:00,188 - training.trainer - INFO - Epoch 18, Step 61293: Loss=4.5190, Acc=0.500, 
2025-09-28 19:49:07,514 - training.trainer - INFO - Epoch 18, Step 61393: Loss=5.9553, Acc=0.235, 
2025-09-28 19:49:14,821 - training.trainer - INFO - Epoch 18, Step 61493: Loss=6.3078, Acc=0.208, 
2025-09-28 19:49:22,280 - training.trainer - INFO - Epoch 18, Step 61593: Loss=6.7444, Acc=0.121, 
2025-09-28 19:49:29,649 - training.trainer - INFO - Epoch 18, Step 61693: Loss=6.5315, Acc=0.171, 
2025-09-28 19:49:36,929 - training.trainer - INFO - Epoch 18, Step 61793: Loss=6.0516, Acc=0.205, 
2025-09-28 19:49:44,262 - training.trainer - INFO - Epoch 18, Step 61893: Loss=4.6705, Acc=0.294, 
2025-09-28 19:49:51,545 - training.trainer - INFO - Epoch 18, Step 61993: Loss=6.5063, Acc=0.217, 
2025-09-28 19:49:58,847 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.6606, Acc=0.333, 
2025-09-28 19:50:06,313 - training.trainer - INFO - Epoch 18, Step 62193: Loss=5.0065, Acc=0.300, 
2025-09-28 19:50:13,741 - training.trainer - INFO - Epoch 18, Step 62293: Loss=5.1029, Acc=0.256, 
2025-09-28 19:50:21,043 - training.trainer - INFO - Epoch 18, Step 62393: Loss=5.6461, Acc=0.214, 
2025-09-28 19:50:28,357 - training.trainer - INFO - Epoch 18, Step 62493: Loss=5.9591, Acc=0.182, 
2025-09-28 19:50:35,775 - training.trainer - INFO - Epoch 18, Step 62593: Loss=5.6480, Acc=0.250, 
2025-09-28 19:50:43,261 - training.trainer - INFO - Epoch 18, Step 62693: Loss=5.4796, Acc=0.286, 
2025-09-28 19:50:50,601 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.7245, Acc=0.276, 
2025-09-28 19:50:57,995 - training.trainer - INFO - Epoch 18, Step 62893: Loss=4.5971, Acc=0.474, 
2025-09-28 19:51:05,329 - training.trainer - INFO - Epoch 18, Step 62993: Loss=6.1732, Acc=0.163, 
2025-09-28 19:51:12,714 - training.trainer - INFO - Epoch 18, Step 63093: Loss=6.0851, Acc=0.196, 
2025-09-28 19:51:20,128 - training.trainer - INFO - Epoch 18, Step 63193: Loss=5.5877, Acc=0.209, 
2025-09-28 19:51:27,651 - training.trainer - INFO - Epoch 18, Step 63293: Loss=5.9785, Acc=0.147, 
2025-09-28 19:51:35,152 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.8257, Acc=0.250, 
2025-09-28 19:51:42,437 - training.trainer - INFO - Epoch 18, Step 63493: Loss=3.8362, Acc=0.447, 
2025-09-28 19:51:49,783 - training.trainer - INFO - Epoch 18, Step 63593: Loss=6.1029, Acc=0.139, 
2025-09-28 19:51:57,103 - training.trainer - INFO - Epoch 18, Step 63693: Loss=3.9992, Acc=0.571, 
2025-09-28 19:52:04,452 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.9401, Acc=0.241, 
2025-09-28 19:52:11,791 - training.trainer - INFO - Epoch 18, Step 63893: Loss=5.4289, Acc=0.194, 
2025-09-28 19:52:19,216 - training.trainer - INFO - Epoch 18, Step 63993: Loss=5.3842, Acc=0.250, 
2025-09-28 19:52:26,611 - training.trainer - INFO - Epoch 18, Step 64093: Loss=5.4276, Acc=0.243, 
2025-09-28 19:52:33,965 - training.trainer - INFO - Epoch 18, Step 64193: Loss=3.6454, Acc=0.667, 
2025-09-28 19:52:52,685 - training.trainer - INFO - Epoch 19/100 completed in 261.99s - Train Loss: 5.6713, Train Acc: 0.253, Val Loss: 5.7118, Val Acc: 0.247
2025-09-28 19:52:53,492 - training.trainer - INFO - New best model saved with validation loss: 5.7118
2025-09-28 19:52:53,492 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-09-28 19:53:01,590 - training.trainer - INFO - Epoch 19, Step 64376: Loss=5.9389, Acc=0.186, 
2025-09-28 19:53:09,414 - training.trainer - INFO - Epoch 19, Step 64476: Loss=6.1568, Acc=0.139, 
2025-09-28 19:53:16,885 - training.trainer - INFO - Epoch 19, Step 64576: Loss=5.0798, Acc=0.370, 
2025-09-28 19:53:24,407 - training.trainer - INFO - Epoch 19, Step 64676: Loss=5.5839, Acc=0.321, 
2025-09-28 19:53:31,962 - training.trainer - INFO - Epoch 19, Step 64776: Loss=6.3624, Acc=0.151, 
2025-09-28 19:53:39,282 - training.trainer - INFO - Epoch 19, Step 64876: Loss=5.6498, Acc=0.176, 
2025-09-28 19:53:46,655 - training.trainer - INFO - Epoch 19, Step 64976: Loss=6.0123, Acc=0.282, 
2025-09-28 19:53:54,102 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.6152, Acc=0.245, 
2025-09-28 19:54:01,472 - training.trainer - INFO - Epoch 19, Step 65176: Loss=5.9918, Acc=0.180, 
2025-09-28 19:54:09,139 - training.trainer - INFO - Epoch 19, Step 65276: Loss=5.5379, Acc=0.237, 
2025-09-28 19:54:16,642 - training.trainer - INFO - Epoch 19, Step 65376: Loss=4.9936, Acc=0.292, 
2025-09-28 19:54:24,181 - training.trainer - INFO - Epoch 19, Step 65476: Loss=5.5502, Acc=0.241, 
2025-09-28 19:54:31,629 - training.trainer - INFO - Epoch 19, Step 65576: Loss=4.9874, Acc=0.275, 
2025-09-28 19:54:39,210 - training.trainer - INFO - Epoch 19, Step 65676: Loss=5.6100, Acc=0.268, 
2025-09-28 19:54:46,677 - training.trainer - INFO - Epoch 19, Step 65776: Loss=6.5760, Acc=0.098, 
2025-09-28 19:54:54,017 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.8117, Acc=0.224, 
2025-09-28 19:55:01,638 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.9735, Acc=0.246, 
2025-09-28 19:55:09,279 - training.trainer - INFO - Epoch 19, Step 66076: Loss=5.9156, Acc=0.278, 
2025-09-28 19:55:16,787 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.3119, Acc=0.250, 
2025-09-28 19:55:24,064 - training.trainer - INFO - Epoch 19, Step 66276: Loss=5.7837, Acc=0.189, 
2025-09-28 19:55:31,575 - training.trainer - INFO - Epoch 19, Step 66376: Loss=5.9593, Acc=0.231, 
2025-09-28 19:55:39,268 - training.trainer - INFO - Epoch 19, Step 66476: Loss=6.0136, Acc=0.208, 
2025-09-28 19:55:46,711 - training.trainer - INFO - Epoch 19, Step 66576: Loss=5.0155, Acc=0.389, 
2025-09-28 19:55:54,172 - training.trainer - INFO - Epoch 19, Step 66676: Loss=6.0820, Acc=0.184, 
2025-09-28 19:56:01,625 - training.trainer - INFO - Epoch 19, Step 66776: Loss=5.9038, Acc=0.267, 
2025-09-28 19:56:09,242 - training.trainer - INFO - Epoch 19, Step 66876: Loss=6.0604, Acc=0.200, 
2025-09-28 19:56:16,939 - training.trainer - INFO - Epoch 19, Step 66976: Loss=5.8901, Acc=0.281, 
2025-09-28 19:56:24,391 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.0114, Acc=0.261, 
2025-09-28 19:56:31,848 - training.trainer - INFO - Epoch 19, Step 67176: Loss=4.3381, Acc=0.333, 
2025-09-28 19:56:39,254 - training.trainer - INFO - Epoch 19, Step 67276: Loss=5.8568, Acc=0.233, 
2025-09-28 19:56:46,796 - training.trainer - INFO - Epoch 19, Step 67376: Loss=6.0236, Acc=0.250, 
2025-09-28 19:56:54,262 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.1508, Acc=0.355, 
2025-09-28 19:57:01,739 - training.trainer - INFO - Epoch 19, Step 67576: Loss=5.9854, Acc=0.217, 
2025-09-28 19:57:21,202 - training.trainer - INFO - Epoch 20/100 completed in 267.71s - Train Loss: 5.6456, Train Acc: 0.257, Val Loss: 5.6961, Val Acc: 0.250
2025-09-28 19:57:21,529 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-28 19:57:22,327 - training.trainer - INFO - New best model saved with validation loss: 5.6961
2025-09-28 19:57:22,327 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-09-28 19:57:30,171 - training.trainer - INFO - Epoch 20, Step 67759: Loss=5.9286, Acc=0.268, 
2025-09-28 19:57:37,548 - training.trainer - INFO - Epoch 20, Step 67859: Loss=6.2230, Acc=0.167, 
2025-09-28 19:57:45,042 - training.trainer - INFO - Epoch 20, Step 67959: Loss=5.5471, Acc=0.250, 
2025-09-28 19:57:52,649 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.5251, Acc=0.188, 
2025-09-28 19:58:00,140 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.6616, Acc=0.333, 
2025-09-28 19:58:07,645 - training.trainer - INFO - Epoch 20, Step 68259: Loss=4.4369, Acc=0.353, 
2025-09-28 19:58:15,131 - training.trainer - INFO - Epoch 20, Step 68359: Loss=5.4712, Acc=0.300, 
2025-09-28 19:58:22,656 - training.trainer - INFO - Epoch 20, Step 68459: Loss=4.5651, Acc=0.333, 
2025-09-28 19:58:30,086 - training.trainer - INFO - Epoch 20, Step 68559: Loss=5.4983, Acc=0.333, 
2025-09-28 19:58:37,602 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.4118, Acc=0.241, 
2025-09-28 19:58:45,190 - training.trainer - INFO - Epoch 20, Step 68759: Loss=6.3246, Acc=0.167, 
2025-09-28 19:58:52,712 - training.trainer - INFO - Epoch 20, Step 68859: Loss=5.8937, Acc=0.200, 
2025-09-28 19:59:00,413 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.1678, Acc=0.352, 
2025-09-28 19:59:08,003 - training.trainer - INFO - Epoch 20, Step 69059: Loss=5.6890, Acc=0.182, 
2025-09-28 19:59:15,967 - training.trainer - INFO - Epoch 20, Step 69159: Loss=6.2726, Acc=0.125, 
2025-09-28 19:59:23,511 - training.trainer - INFO - Epoch 20, Step 69259: Loss=6.0256, Acc=0.241, 
2025-09-28 19:59:30,985 - training.trainer - INFO - Epoch 20, Step 69359: Loss=5.1667, Acc=0.294, 
2025-09-28 19:59:38,427 - training.trainer - INFO - Epoch 20, Step 69459: Loss=6.1730, Acc=0.206, 
2025-09-28 19:59:46,023 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.0591, Acc=0.214, 
2025-09-28 19:59:53,451 - training.trainer - INFO - Epoch 20, Step 69659: Loss=4.5270, Acc=0.368, 
2025-09-28 20:00:01,122 - training.trainer - INFO - Epoch 20, Step 69759: Loss=6.1756, Acc=0.200, 
2025-09-28 20:00:08,616 - training.trainer - INFO - Epoch 20, Step 69859: Loss=6.4333, Acc=0.149, 
2025-09-28 20:00:16,171 - training.trainer - INFO - Epoch 20, Step 69959: Loss=5.7895, Acc=0.310, 
2025-09-28 20:00:23,709 - training.trainer - INFO - Epoch 20, Step 70059: Loss=6.4248, Acc=0.189, 
2025-09-28 20:00:31,235 - training.trainer - INFO - Epoch 20, Step 70159: Loss=4.2758, Acc=0.542, 
2025-09-28 20:00:38,891 - training.trainer - INFO - Epoch 20, Step 70259: Loss=6.4240, Acc=0.134, 
2025-09-28 20:00:46,351 - training.trainer - INFO - Epoch 20, Step 70359: Loss=5.5176, Acc=0.211, 
2025-09-28 20:00:53,859 - training.trainer - INFO - Epoch 20, Step 70459: Loss=6.2107, Acc=0.367, 
2025-09-28 20:01:01,359 - training.trainer - INFO - Epoch 20, Step 70559: Loss=5.1540, Acc=0.250, 
2025-09-28 20:01:08,961 - training.trainer - INFO - Epoch 20, Step 70659: Loss=6.3276, Acc=0.211, 
2025-09-28 20:01:16,406 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.5892, Acc=0.236, 
2025-09-28 20:01:24,009 - training.trainer - INFO - Epoch 20, Step 70859: Loss=5.9434, Acc=0.286, 
2025-09-28 20:01:31,567 - training.trainer - INFO - Epoch 20, Step 70959: Loss=6.1423, Acc=0.243, 
2025-09-28 20:01:50,449 - training.trainer - INFO - Epoch 21/100 completed in 268.12s - Train Loss: 5.6273, Train Acc: 0.260, Val Loss: 5.7092, Val Acc: 0.247
2025-09-28 20:01:57,360 - training.trainer - INFO - Epoch 21, Step 71142: Loss=5.5132, Acc=0.136, 
2025-09-28 20:02:03,829 - training.trainer - INFO - Epoch 21, Step 71242: Loss=5.6984, Acc=0.220, 
2025-09-28 20:02:11,255 - training.trainer - INFO - Epoch 21, Step 71342: Loss=5.2942, Acc=0.185, 
2025-09-28 20:02:18,653 - training.trainer - INFO - Epoch 21, Step 71442: Loss=5.0224, Acc=0.294, 
2025-09-28 20:02:26,012 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.5046, Acc=0.333, 
2025-09-28 20:02:33,478 - training.trainer - INFO - Epoch 21, Step 71642: Loss=6.0218, Acc=0.256, 
2025-09-28 20:02:40,993 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.7161, Acc=0.279, 
2025-09-28 20:02:48,480 - training.trainer - INFO - Epoch 21, Step 71842: Loss=5.5699, Acc=0.200, 
2025-09-28 20:02:55,863 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.5409, Acc=0.235, 
2025-09-28 20:03:03,353 - training.trainer - INFO - Epoch 21, Step 72042: Loss=5.6483, Acc=0.200, 
2025-09-28 20:03:10,792 - training.trainer - INFO - Epoch 21, Step 72142: Loss=6.1656, Acc=0.184, 
2025-09-28 20:03:18,249 - training.trainer - INFO - Epoch 21, Step 72242: Loss=6.4134, Acc=0.167, 
2025-09-28 20:03:25,641 - training.trainer - INFO - Epoch 21, Step 72342: Loss=6.5415, Acc=0.233, 
2025-09-28 20:03:33,038 - training.trainer - INFO - Epoch 21, Step 72442: Loss=6.3697, Acc=0.155, 
2025-09-28 20:03:40,417 - training.trainer - INFO - Epoch 21, Step 72542: Loss=4.9755, Acc=0.421, 
2025-09-28 20:03:47,819 - training.trainer - INFO - Epoch 21, Step 72642: Loss=5.5956, Acc=0.243, 
2025-09-28 20:03:55,540 - training.trainer - INFO - Epoch 21, Step 72742: Loss=5.6012, Acc=0.318, 
2025-09-28 20:04:02,952 - training.trainer - INFO - Epoch 21, Step 72842: Loss=6.3384, Acc=0.180, 
2025-09-28 20:04:10,366 - training.trainer - INFO - Epoch 21, Step 72942: Loss=5.6507, Acc=0.276, 
2025-09-28 20:04:17,759 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.9764, Acc=0.231, 
2025-09-28 20:04:25,274 - training.trainer - INFO - Epoch 21, Step 73142: Loss=6.3799, Acc=0.250, 
2025-09-28 20:04:32,925 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.3299, Acc=0.212, 
2025-09-28 20:04:40,299 - training.trainer - INFO - Epoch 21, Step 73342: Loss=5.7068, Acc=0.259, 
2025-09-28 20:04:47,724 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.5402, Acc=0.250, 
2025-09-28 20:04:55,404 - training.trainer - INFO - Epoch 21, Step 73542: Loss=5.9641, Acc=0.225, 
2025-09-28 20:05:02,947 - training.trainer - INFO - Epoch 21, Step 73642: Loss=6.1342, Acc=0.179, 
2025-09-28 20:05:10,499 - training.trainer - INFO - Epoch 21, Step 73742: Loss=6.2078, Acc=0.179, 
2025-09-28 20:05:17,838 - training.trainer - INFO - Epoch 21, Step 73842: Loss=4.8070, Acc=0.289, 
2025-09-28 20:05:25,196 - training.trainer - INFO - Epoch 21, Step 73942: Loss=6.2664, Acc=0.151, 
2025-09-28 20:05:32,698 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.7639, Acc=0.229, 
2025-09-28 20:05:40,235 - training.trainer - INFO - Epoch 21, Step 74142: Loss=6.6554, Acc=0.133, 
2025-09-28 20:05:47,759 - training.trainer - INFO - Epoch 21, Step 74242: Loss=6.3583, Acc=0.217, 
2025-09-28 20:05:55,203 - training.trainer - INFO - Epoch 21, Step 74342: Loss=4.9986, Acc=0.412, 
2025-09-28 20:06:14,107 - training.trainer - INFO - Epoch 22/100 completed in 263.66s - Train Loss: 5.6039, Train Acc: 0.264, Val Loss: 5.6865, Val Acc: 0.252
2025-09-28 20:06:14,726 - training.trainer - INFO - New best model saved with validation loss: 5.6865
2025-09-28 20:06:14,726 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-09-28 20:06:21,579 - training.trainer - INFO - Epoch 22, Step 74525: Loss=6.0305, Acc=0.300, 
2025-09-28 20:06:28,273 - training.trainer - INFO - Epoch 22, Step 74625: Loss=6.1491, Acc=0.211, 
2025-09-28 20:06:35,689 - training.trainer - INFO - Epoch 22, Step 74725: Loss=3.8308, Acc=0.583, 
2025-09-28 20:06:43,222 - training.trainer - INFO - Epoch 22, Step 74825: Loss=7.0087, Acc=0.200, 
2025-09-28 20:06:50,716 - training.trainer - INFO - Epoch 22, Step 74925: Loss=5.7221, Acc=0.244, 
2025-09-28 20:06:58,115 - training.trainer - INFO - Epoch 22, Step 75025: Loss=5.5741, Acc=0.219, 
2025-09-28 20:07:05,549 - training.trainer - INFO - Epoch 22, Step 75125: Loss=5.7259, Acc=0.273, 
2025-09-28 20:07:13,159 - training.trainer - INFO - Epoch 22, Step 75225: Loss=4.8685, Acc=0.389, 
2025-09-28 20:07:20,661 - training.trainer - INFO - Epoch 22, Step 75325: Loss=5.1242, Acc=0.276, 
2025-09-28 20:07:28,098 - training.trainer - INFO - Epoch 22, Step 75425: Loss=6.2016, Acc=0.151, 
2025-09-28 20:07:35,777 - training.trainer - INFO - Epoch 22, Step 75525: Loss=5.9666, Acc=0.231, 
2025-09-28 20:07:43,413 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.3558, Acc=0.194, 
2025-09-28 20:07:50,834 - training.trainer - INFO - Epoch 22, Step 75725: Loss=4.9812, Acc=0.280, 
2025-09-28 20:07:58,503 - training.trainer - INFO - Epoch 22, Step 75825: Loss=6.3911, Acc=0.171, 
2025-09-28 20:08:06,071 - training.trainer - INFO - Epoch 22, Step 75925: Loss=5.4944, Acc=0.319, 
2025-09-28 20:08:13,762 - training.trainer - INFO - Epoch 22, Step 76025: Loss=5.4608, Acc=0.224, 
2025-09-28 20:08:21,188 - training.trainer - INFO - Epoch 22, Step 76125: Loss=4.4474, Acc=0.476, 
2025-09-28 20:08:28,644 - training.trainer - INFO - Epoch 22, Step 76225: Loss=6.4295, Acc=0.163, 
2025-09-28 20:08:36,015 - training.trainer - INFO - Epoch 22, Step 76325: Loss=5.4898, Acc=0.254, 
2025-09-28 20:08:43,342 - training.trainer - INFO - Epoch 22, Step 76425: Loss=6.2742, Acc=0.350, 
2025-09-28 20:08:50,897 - training.trainer - INFO - Epoch 22, Step 76525: Loss=6.5234, Acc=0.219, 
2025-09-28 20:08:58,368 - training.trainer - INFO - Epoch 22, Step 76625: Loss=6.4071, Acc=0.185, 
2025-09-28 20:09:05,731 - training.trainer - INFO - Epoch 22, Step 76725: Loss=5.1688, Acc=0.294, 
2025-09-28 20:09:13,076 - training.trainer - INFO - Epoch 22, Step 76825: Loss=5.4125, Acc=0.314, 
2025-09-28 20:09:20,449 - training.trainer - INFO - Epoch 22, Step 76925: Loss=4.1871, Acc=0.522, 
2025-09-28 20:09:28,287 - training.trainer - INFO - Epoch 22, Step 77025: Loss=6.4918, Acc=0.174, 
2025-09-28 20:09:35,682 - training.trainer - INFO - Epoch 22, Step 77125: Loss=6.4127, Acc=0.267, 
2025-09-28 20:09:43,245 - training.trainer - INFO - Epoch 22, Step 77225: Loss=6.0153, Acc=0.160, 
2025-09-28 20:09:50,848 - training.trainer - INFO - Epoch 22, Step 77325: Loss=6.5393, Acc=0.156, 
2025-09-28 20:09:58,404 - training.trainer - INFO - Epoch 22, Step 77425: Loss=5.2042, Acc=0.400, 
2025-09-28 20:10:05,993 - training.trainer - INFO - Epoch 22, Step 77525: Loss=6.0365, Acc=0.275, 
2025-09-28 20:10:13,498 - training.trainer - INFO - Epoch 22, Step 77625: Loss=6.1679, Acc=0.179, 
2025-09-28 20:10:21,055 - training.trainer - INFO - Epoch 22, Step 77725: Loss=5.5308, Acc=0.289, 
2025-09-28 20:10:40,768 - training.trainer - INFO - Epoch 23/100 completed in 266.04s - Train Loss: 5.5918, Train Acc: 0.266, Val Loss: 5.6783, Val Acc: 0.254
2025-09-28 20:10:41,406 - training.trainer - INFO - New best model saved with validation loss: 5.6783
2025-09-28 20:10:41,406 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-09-28 20:10:49,191 - training.trainer - INFO - Epoch 23, Step 77908: Loss=5.0781, Acc=0.326, 
2025-09-28 20:10:56,779 - training.trainer - INFO - Epoch 23, Step 78008: Loss=5.4414, Acc=0.280, 
2025-09-28 20:11:04,332 - training.trainer - INFO - Epoch 23, Step 78108: Loss=5.9067, Acc=0.255, 
2025-09-28 20:11:12,144 - training.trainer - INFO - Epoch 23, Step 78208: Loss=5.5649, Acc=0.235, 
2025-09-28 20:11:19,710 - training.trainer - INFO - Epoch 23, Step 78308: Loss=5.4071, Acc=0.259, 
2025-09-28 20:11:27,138 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.7283, Acc=0.190, 
2025-09-28 20:11:34,711 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.5799, Acc=0.224, 
2025-09-28 20:11:42,208 - training.trainer - INFO - Epoch 23, Step 78608: Loss=5.8140, Acc=0.258, 
2025-09-28 20:11:49,594 - training.trainer - INFO - Epoch 23, Step 78708: Loss=6.3018, Acc=0.295, 
2025-09-28 20:11:57,001 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.8461, Acc=0.267, 
2025-09-28 20:12:04,843 - training.trainer - INFO - Epoch 23, Step 78908: Loss=4.0005, Acc=0.324, 
2025-09-28 20:12:12,286 - training.trainer - INFO - Epoch 23, Step 79008: Loss=5.1542, Acc=0.400, 
2025-09-28 20:12:19,624 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.7328, Acc=0.276, 
2025-09-28 20:12:26,987 - training.trainer - INFO - Epoch 23, Step 79208: Loss=6.1711, Acc=0.258, 
2025-09-28 20:12:34,489 - training.trainer - INFO - Epoch 23, Step 79308: Loss=4.2958, Acc=0.375, 
2025-09-28 20:12:41,859 - training.trainer - INFO - Epoch 23, Step 79408: Loss=6.4289, Acc=0.216, 
2025-09-28 20:12:49,262 - training.trainer - INFO - Epoch 23, Step 79508: Loss=6.2922, Acc=0.200, 
2025-09-28 20:12:56,653 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.8070, Acc=0.214, 
2025-09-28 20:13:04,008 - training.trainer - INFO - Epoch 23, Step 79708: Loss=5.9097, Acc=0.231, 
2025-09-28 20:13:11,443 - training.trainer - INFO - Epoch 23, Step 79808: Loss=5.6604, Acc=0.286, 
2025-09-28 20:13:18,842 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.5699, Acc=0.316, 
2025-09-28 20:13:26,208 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.6300, Acc=0.186, 
2025-09-28 20:13:33,573 - training.trainer - INFO - Epoch 23, Step 80108: Loss=6.1430, Acc=0.262, 
2025-09-28 20:13:41,016 - training.trainer - INFO - Epoch 23, Step 80208: Loss=4.4775, Acc=0.417, 
2025-09-28 20:13:48,374 - training.trainer - INFO - Epoch 23, Step 80308: Loss=5.8547, Acc=0.222, 
2025-09-28 20:13:55,925 - training.trainer - INFO - Epoch 23, Step 80408: Loss=5.5690, Acc=0.375, 
2025-09-28 20:14:03,478 - training.trainer - INFO - Epoch 23, Step 80508: Loss=6.0984, Acc=0.227, 
2025-09-28 20:14:10,971 - training.trainer - INFO - Epoch 23, Step 80608: Loss=6.8790, Acc=0.182, 
2025-09-28 20:14:18,442 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.0866, Acc=0.393, 
2025-09-28 20:14:26,247 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.7081, Acc=0.348, 
2025-09-28 20:14:33,564 - training.trainer - INFO - Epoch 23, Step 80908: Loss=4.4748, Acc=0.500, 
2025-09-28 20:14:41,127 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.5690, Acc=0.333, 
2025-09-28 20:14:48,568 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.4534, Acc=0.221, 
2025-09-28 20:15:07,841 - training.trainer - INFO - Epoch 24/100 completed in 266.43s - Train Loss: 5.5721, Train Acc: 0.268, Val Loss: 5.6629, Val Acc: 0.252
2025-09-28 20:15:08,481 - training.trainer - INFO - New best model saved with validation loss: 5.6629
2025-09-28 20:15:08,482 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-09-28 20:15:15,387 - training.trainer - INFO - Epoch 24, Step 81291: Loss=5.4820, Acc=0.228, 
2025-09-28 20:15:22,388 - training.trainer - INFO - Epoch 24, Step 81391: Loss=5.0548, Acc=0.409, 
2025-09-28 20:15:29,193 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.5919, Acc=0.200, 
2025-09-28 20:15:35,963 - training.trainer - INFO - Epoch 24, Step 81591: Loss=5.9067, Acc=0.250, 
2025-09-28 20:15:42,425 - training.trainer - INFO - Epoch 24, Step 81691: Loss=5.1950, Acc=0.258, 
2025-09-28 20:15:49,036 - training.trainer - INFO - Epoch 24, Step 81791: Loss=6.5552, Acc=0.200, 
2025-09-28 20:15:55,564 - training.trainer - INFO - Epoch 24, Step 81891: Loss=5.9014, Acc=0.189, 
2025-09-28 20:16:02,205 - training.trainer - INFO - Epoch 24, Step 81991: Loss=5.9001, Acc=0.191, 
2025-09-28 20:16:09,274 - training.trainer - INFO - Epoch 24, Step 82091: Loss=5.2804, Acc=0.304, 
2025-09-28 20:16:16,477 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.6103, Acc=0.271, 
2025-09-28 20:16:23,858 - training.trainer - INFO - Epoch 24, Step 82291: Loss=5.7680, Acc=0.269, 
2025-09-28 20:16:31,219 - training.trainer - INFO - Epoch 24, Step 82391: Loss=4.9532, Acc=0.250, 
2025-09-28 20:16:38,675 - training.trainer - INFO - Epoch 24, Step 82491: Loss=4.1806, Acc=0.385, 
2025-09-28 20:16:46,117 - training.trainer - INFO - Epoch 24, Step 82591: Loss=5.9433, Acc=0.139, 
2025-09-28 20:16:53,506 - training.trainer - INFO - Epoch 24, Step 82691: Loss=6.3774, Acc=0.175, 
2025-09-28 20:17:00,915 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.9634, Acc=0.208, 
2025-09-28 20:17:08,225 - training.trainer - INFO - Epoch 24, Step 82891: Loss=5.5960, Acc=0.115, 
2025-09-28 20:17:15,601 - training.trainer - INFO - Epoch 24, Step 82991: Loss=4.0453, Acc=0.500, 
2025-09-28 20:17:23,073 - training.trainer - INFO - Epoch 24, Step 83091: Loss=5.4690, Acc=0.265, 
2025-09-28 20:17:30,632 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.9985, Acc=0.261, 
2025-09-28 20:17:38,115 - training.trainer - INFO - Epoch 24, Step 83291: Loss=4.8216, Acc=0.302, 
2025-09-28 20:17:45,516 - training.trainer - INFO - Epoch 24, Step 83391: Loss=6.0193, Acc=0.238, 
2025-09-28 20:17:52,908 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.6475, Acc=0.250, 
2025-09-28 20:18:00,330 - training.trainer - INFO - Epoch 24, Step 83591: Loss=5.3797, Acc=0.261, 
2025-09-28 20:18:07,939 - training.trainer - INFO - Epoch 24, Step 83691: Loss=3.5033, Acc=0.600, 
2025-09-28 20:18:15,265 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.6108, Acc=0.293, 
2025-09-28 20:18:22,499 - training.trainer - INFO - Epoch 24, Step 83891: Loss=5.9917, Acc=0.190, 
2025-09-28 20:18:30,017 - training.trainer - INFO - Epoch 24, Step 83991: Loss=4.5993, Acc=0.480, 
2025-09-28 20:18:37,489 - training.trainer - INFO - Epoch 24, Step 84091: Loss=6.1241, Acc=0.300, 
2025-09-28 20:18:44,862 - training.trainer - INFO - Epoch 24, Step 84191: Loss=5.9089, Acc=0.232, 
2025-09-28 20:18:52,238 - training.trainer - INFO - Epoch 24, Step 84291: Loss=6.0521, Acc=0.200, 
2025-09-28 20:18:59,698 - training.trainer - INFO - Epoch 24, Step 84391: Loss=6.6163, Acc=0.207, 
2025-09-28 20:19:07,115 - training.trainer - INFO - Epoch 24, Step 84491: Loss=6.8728, Acc=0.207, 
2025-09-28 20:19:26,151 - training.trainer - INFO - Epoch 25/100 completed in 257.67s - Train Loss: 5.5502, Train Acc: 0.273, Val Loss: 5.6766, Val Acc: 0.253
2025-09-28 20:19:26,455 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-09-28 20:19:34,430 - training.trainer - INFO - Epoch 25, Step 84674: Loss=5.3511, Acc=0.310, 
2025-09-28 20:19:41,802 - training.trainer - INFO - Epoch 25, Step 84774: Loss=5.1259, Acc=0.241, 
2025-09-28 20:19:49,129 - training.trainer - INFO - Epoch 25, Step 84874: Loss=5.6334, Acc=0.212, 
2025-09-28 20:19:56,654 - training.trainer - INFO - Epoch 25, Step 84974: Loss=5.5459, Acc=0.308, 
2025-09-28 20:20:04,276 - training.trainer - INFO - Epoch 25, Step 85074: Loss=4.2533, Acc=0.524, 
2025-09-28 20:20:12,237 - training.trainer - INFO - Epoch 25, Step 85174: Loss=5.6372, Acc=0.273, 
2025-09-28 20:20:19,953 - training.trainer - INFO - Epoch 25, Step 85274: Loss=4.2123, Acc=0.423, 
2025-09-28 20:20:28,200 - training.trainer - INFO - Epoch 25, Step 85374: Loss=6.0465, Acc=0.217, 
2025-09-28 20:20:36,816 - training.trainer - INFO - Epoch 25, Step 85474: Loss=6.1654, Acc=0.231, 
2025-09-28 20:20:46,276 - training.trainer - INFO - Epoch 25, Step 85574: Loss=4.2528, Acc=0.474, 
2025-09-28 20:20:54,721 - training.trainer - INFO - Epoch 25, Step 85674: Loss=5.6361, Acc=0.220, 
2025-09-28 20:21:02,480 - training.trainer - INFO - Epoch 25, Step 85774: Loss=4.4968, Acc=0.387, 
2025-09-28 20:21:11,180 - training.trainer - INFO - Epoch 25, Step 85874: Loss=5.8936, Acc=0.235, 
2025-09-28 20:21:20,404 - training.trainer - INFO - Epoch 25, Step 85974: Loss=5.6547, Acc=0.231, 
2025-09-28 20:21:28,408 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.0298, Acc=0.278, 
2025-09-28 20:21:36,605 - training.trainer - INFO - Epoch 25, Step 86174: Loss=4.3594, Acc=0.303, 
2025-09-28 20:21:44,909 - training.trainer - INFO - Epoch 25, Step 86274: Loss=5.7247, Acc=0.210, 
2025-09-28 20:21:53,469 - training.trainer - INFO - Epoch 25, Step 86374: Loss=6.0990, Acc=0.174, 
2025-09-28 20:22:01,765 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.0664, Acc=0.364, 
2025-09-28 20:22:08,578 - training.trainer - INFO - Epoch 25, Step 86574: Loss=5.1778, Acc=0.257, 
2025-09-28 20:22:15,271 - training.trainer - INFO - Epoch 25, Step 86674: Loss=5.6228, Acc=0.333, 
2025-09-28 20:22:22,519 - training.trainer - INFO - Epoch 25, Step 86774: Loss=5.4678, Acc=0.216, 
2025-09-28 20:22:29,180 - training.trainer - INFO - Epoch 25, Step 86874: Loss=5.5648, Acc=0.345, 
2025-09-28 20:22:35,888 - training.trainer - INFO - Epoch 25, Step 86974: Loss=6.7100, Acc=0.190, 
2025-09-28 20:22:42,613 - training.trainer - INFO - Epoch 25, Step 87074: Loss=6.0785, Acc=0.157, 
2025-09-28 20:22:49,626 - training.trainer - INFO - Epoch 25, Step 87174: Loss=5.5206, Acc=0.318, 
2025-09-28 20:22:56,355 - training.trainer - INFO - Epoch 25, Step 87274: Loss=5.7822, Acc=0.225, 
2025-09-28 20:23:04,268 - training.trainer - INFO - Epoch 25, Step 87374: Loss=4.7516, Acc=0.379, 
2025-09-28 20:23:12,436 - training.trainer - INFO - Epoch 25, Step 87474: Loss=5.9306, Acc=0.236, 
2025-09-28 20:23:19,714 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.8254, Acc=0.222, 
2025-09-28 20:23:27,364 - training.trainer - INFO - Epoch 25, Step 87674: Loss=4.1271, Acc=0.476, 
2025-09-28 20:23:34,010 - training.trainer - INFO - Epoch 25, Step 87774: Loss=6.0876, Acc=0.190, 
2025-09-28 20:23:40,739 - training.trainer - INFO - Epoch 25, Step 87874: Loss=5.7631, Acc=0.286, 
2025-09-28 20:23:59,982 - training.trainer - INFO - Epoch 26/100 completed in 273.53s - Train Loss: 5.5373, Train Acc: 0.273, Val Loss: 5.6699, Val Acc: 0.255
2025-09-28 20:24:06,912 - training.trainer - INFO - Epoch 26, Step 88057: Loss=3.4588, Acc=0.652, 
2025-09-28 20:24:13,408 - training.trainer - INFO - Epoch 26, Step 88157: Loss=5.5991, Acc=0.254, 
2025-09-28 20:24:20,279 - training.trainer - INFO - Epoch 26, Step 88257: Loss=5.1339, Acc=0.318, 
2025-09-28 20:24:27,008 - training.trainer - INFO - Epoch 26, Step 88357: Loss=6.0321, Acc=0.263, 
2025-09-28 20:24:33,220 - training.trainer - INFO - Epoch 26, Step 88457: Loss=5.6315, Acc=0.277, 
2025-09-28 20:24:40,040 - training.trainer - INFO - Epoch 26, Step 88557: Loss=4.4012, Acc=0.389, 
2025-09-28 20:24:46,263 - training.trainer - INFO - Epoch 26, Step 88657: Loss=6.2096, Acc=0.205, 
2025-09-28 20:24:52,625 - training.trainer - INFO - Epoch 26, Step 88757: Loss=6.1116, Acc=0.216, 
2025-09-28 20:24:58,873 - training.trainer - INFO - Epoch 26, Step 88857: Loss=4.8412, Acc=0.308, 
2025-09-28 20:25:05,119 - training.trainer - INFO - Epoch 26, Step 88957: Loss=5.1711, Acc=0.308, 
2025-09-28 20:25:12,052 - training.trainer - INFO - Epoch 26, Step 89057: Loss=5.7926, Acc=0.205, 
2025-09-28 20:25:19,506 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.7368, Acc=0.280, 
2025-09-28 20:25:26,711 - training.trainer - INFO - Epoch 26, Step 89257: Loss=4.9971, Acc=0.320, 
2025-09-28 20:25:33,134 - training.trainer - INFO - Epoch 26, Step 89357: Loss=5.7978, Acc=0.244, 
2025-09-28 20:25:39,390 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.3754, Acc=0.216, 
2025-09-28 20:25:45,603 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.5914, Acc=0.254, 
2025-09-28 20:25:51,868 - training.trainer - INFO - Epoch 26, Step 89657: Loss=4.9546, Acc=0.312, 
2025-09-28 20:25:58,164 - training.trainer - INFO - Epoch 26, Step 89757: Loss=5.7408, Acc=0.309, 
2025-09-28 20:26:04,501 - training.trainer - INFO - Epoch 26, Step 89857: Loss=5.8254, Acc=0.205, 
2025-09-28 20:26:11,596 - training.trainer - INFO - Epoch 26, Step 89957: Loss=5.9215, Acc=0.200, 
2025-09-28 20:26:18,871 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.4304, Acc=0.414, 
2025-09-28 20:26:26,154 - training.trainer - INFO - Epoch 26, Step 90157: Loss=6.5251, Acc=0.190, 
2025-09-28 20:26:33,506 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.1836, Acc=0.250, 
2025-09-28 20:26:40,747 - training.trainer - INFO - Epoch 26, Step 90357: Loss=4.4964, Acc=0.318, 
2025-09-28 20:26:48,024 - training.trainer - INFO - Epoch 26, Step 90457: Loss=6.0590, Acc=0.217, 
2025-09-28 20:26:55,326 - training.trainer - INFO - Epoch 26, Step 90557: Loss=6.5805, Acc=0.143, 
2025-09-28 20:27:02,699 - training.trainer - INFO - Epoch 26, Step 90657: Loss=5.9201, Acc=0.262, 
2025-09-28 20:27:10,037 - training.trainer - INFO - Epoch 26, Step 90757: Loss=5.8368, Acc=0.222, 
2025-09-28 20:27:17,340 - training.trainer - INFO - Epoch 26, Step 90857: Loss=5.7639, Acc=0.231, 
2025-09-28 20:27:24,817 - training.trainer - INFO - Epoch 26, Step 90957: Loss=3.3832, Acc=0.556, 
2025-09-28 20:27:32,275 - training.trainer - INFO - Epoch 26, Step 91057: Loss=5.1687, Acc=0.360, 
2025-09-28 20:27:39,633 - training.trainer - INFO - Epoch 26, Step 91157: Loss=6.3106, Acc=0.227, 
2025-09-28 20:27:47,010 - training.trainer - INFO - Epoch 26, Step 91257: Loss=4.6418, Acc=0.323, 
2025-09-28 20:28:05,759 - training.trainer - INFO - Epoch 27/100 completed in 245.78s - Train Loss: 5.5152, Train Acc: 0.277, Val Loss: 5.6635, Val Acc: 0.253
2025-09-28 20:28:12,402 - training.trainer - INFO - Epoch 27, Step 91440: Loss=6.1639, Acc=0.286, 
2025-09-28 20:28:18,709 - training.trainer - INFO - Epoch 27, Step 91540: Loss=4.7912, Acc=0.462, 
2025-09-28 20:28:25,546 - training.trainer - INFO - Epoch 27, Step 91640: Loss=4.6506, Acc=0.500, 
2025-09-28 20:28:31,986 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.7667, Acc=0.250, 
2025-09-28 20:28:38,816 - training.trainer - INFO - Epoch 27, Step 91840: Loss=5.7840, Acc=0.263, 
2025-09-28 20:28:46,076 - training.trainer - INFO - Epoch 27, Step 91940: Loss=5.3299, Acc=0.308, 
2025-09-28 20:28:53,147 - training.trainer - INFO - Epoch 27, Step 92040: Loss=6.4453, Acc=0.134, 
2025-09-28 20:29:00,113 - training.trainer - INFO - Epoch 27, Step 92140: Loss=4.9763, Acc=0.286, 
2025-09-28 20:29:06,850 - training.trainer - INFO - Epoch 27, Step 92240: Loss=4.4259, Acc=0.440, 
2025-09-28 20:29:14,150 - training.trainer - INFO - Epoch 27, Step 92340: Loss=6.2007, Acc=0.158, 
2025-09-28 20:29:21,573 - training.trainer - INFO - Epoch 27, Step 92440: Loss=5.9719, Acc=0.200, 
2025-09-28 20:29:29,203 - training.trainer - INFO - Epoch 27, Step 92540: Loss=5.6510, Acc=0.206, 
2025-09-28 20:29:36,642 - training.trainer - INFO - Epoch 27, Step 92640: Loss=4.7847, Acc=0.324, 
2025-09-28 20:29:44,150 - training.trainer - INFO - Epoch 27, Step 92740: Loss=6.5602, Acc=0.143, 
2025-09-28 20:29:51,646 - training.trainer - INFO - Epoch 27, Step 92840: Loss=5.3865, Acc=0.214, 
2025-09-28 20:29:59,083 - training.trainer - INFO - Epoch 27, Step 92940: Loss=4.0347, Acc=0.185, 
2025-09-28 20:30:06,361 - training.trainer - INFO - Epoch 27, Step 93040: Loss=6.0639, Acc=0.235, 
2025-09-28 20:30:13,619 - training.trainer - INFO - Epoch 27, Step 93140: Loss=5.6703, Acc=0.319, 
2025-09-28 20:30:20,853 - training.trainer - INFO - Epoch 27, Step 93240: Loss=5.3294, Acc=0.462, 
2025-09-28 20:30:28,077 - training.trainer - INFO - Epoch 27, Step 93340: Loss=6.5086, Acc=0.195, 
2025-09-28 20:30:35,496 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.8910, Acc=0.169, 
2025-09-28 20:30:42,898 - training.trainer - INFO - Epoch 27, Step 93540: Loss=6.6943, Acc=0.159, 
2025-09-28 20:30:50,211 - training.trainer - INFO - Epoch 27, Step 93640: Loss=5.6348, Acc=0.250, 
2025-09-28 20:30:57,425 - training.trainer - INFO - Epoch 27, Step 93740: Loss=5.2879, Acc=0.278, 
2025-09-28 20:31:04,667 - training.trainer - INFO - Epoch 27, Step 93840: Loss=6.1728, Acc=0.195, 
2025-09-28 20:31:11,602 - training.trainer - INFO - Epoch 27, Step 93940: Loss=5.5483, Acc=0.333, 
2025-09-28 20:31:18,551 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.2654, Acc=0.278, 
2025-09-28 20:31:25,941 - training.trainer - INFO - Epoch 27, Step 94140: Loss=5.5984, Acc=0.241, 
2025-09-28 20:31:33,749 - training.trainer - INFO - Epoch 27, Step 94240: Loss=5.9746, Acc=0.348, 
2025-09-28 20:31:41,300 - training.trainer - INFO - Epoch 27, Step 94340: Loss=5.5136, Acc=0.227, 
2025-09-28 20:31:49,364 - training.trainer - INFO - Epoch 27, Step 94440: Loss=5.6166, Acc=0.197, 
2025-09-28 20:31:56,931 - training.trainer - INFO - Epoch 27, Step 94540: Loss=4.7065, Acc=0.409, 
2025-09-28 20:32:04,655 - training.trainer - INFO - Epoch 27, Step 94640: Loss=5.2488, Acc=0.188, 
2025-09-28 20:32:26,700 - training.trainer - INFO - Epoch 28/100 completed in 260.94s - Train Loss: 5.5018, Train Acc: 0.279, Val Loss: 5.6592, Val Acc: 0.252
2025-09-28 20:32:27,370 - training.trainer - INFO - New best model saved with validation loss: 5.6592
2025-09-28 20:32:27,370 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_28.pt
2025-09-28 20:32:35,938 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.6253, Acc=0.250, 
2025-09-28 20:32:43,247 - training.trainer - INFO - Epoch 28, Step 94923: Loss=5.2833, Acc=0.312, 
2025-09-28 20:32:50,766 - training.trainer - INFO - Epoch 28, Step 95023: Loss=5.8087, Acc=0.276, 
2025-09-28 20:32:58,256 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.3660, Acc=0.267, 
2025-09-28 20:33:06,487 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.0679, Acc=0.226, 
2025-09-28 20:33:13,770 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.5378, Acc=0.263, 
2025-09-28 20:33:21,080 - training.trainer - INFO - Epoch 28, Step 95423: Loss=5.5846, Acc=0.240, 
2025-09-28 20:33:28,789 - training.trainer - INFO - Epoch 28, Step 95523: Loss=4.5537, Acc=0.400, 
2025-09-28 20:33:36,173 - training.trainer - INFO - Epoch 28, Step 95623: Loss=5.4290, Acc=0.213, 
2025-09-28 20:33:43,916 - training.trainer - INFO - Epoch 28, Step 95723: Loss=5.2707, Acc=0.237, 
2025-09-28 20:33:50,827 - training.trainer - INFO - Epoch 28, Step 95823: Loss=4.7256, Acc=0.421, 
2025-09-28 20:33:57,666 - training.trainer - INFO - Epoch 28, Step 95923: Loss=6.0277, Acc=0.190, 
2025-09-28 20:34:04,433 - training.trainer - INFO - Epoch 28, Step 96023: Loss=4.9532, Acc=0.392, 
2025-09-28 20:34:11,412 - training.trainer - INFO - Epoch 28, Step 96123: Loss=4.8719, Acc=0.276, 
2025-09-28 20:34:18,089 - training.trainer - INFO - Epoch 28, Step 96223: Loss=5.0861, Acc=0.352, 
2025-09-28 20:34:24,852 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.8099, Acc=0.281, 
2025-09-28 20:34:31,661 - training.trainer - INFO - Epoch 28, Step 96423: Loss=5.4157, Acc=0.294, 
2025-09-28 20:34:39,180 - training.trainer - INFO - Epoch 28, Step 96523: Loss=5.5465, Acc=0.250, 
2025-09-28 20:34:46,240 - training.trainer - INFO - Epoch 28, Step 96623: Loss=5.7938, Acc=0.197, 
2025-09-28 20:34:53,241 - training.trainer - INFO - Epoch 28, Step 96723: Loss=6.2542, Acc=0.231, 
2025-09-28 20:35:00,886 - training.trainer - INFO - Epoch 28, Step 96823: Loss=6.1981, Acc=0.238, 
2025-09-28 20:35:08,147 - training.trainer - INFO - Epoch 28, Step 96923: Loss=5.7502, Acc=0.209, 
2025-09-28 20:35:14,950 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.8807, Acc=0.182, 
2025-09-28 20:35:21,202 - training.trainer - INFO - Epoch 28, Step 97123: Loss=4.5332, Acc=0.556, 
2025-09-28 20:35:27,787 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.3951, Acc=0.333, 
2025-09-28 20:35:34,123 - training.trainer - INFO - Epoch 28, Step 97323: Loss=5.5656, Acc=0.259, 
2025-09-28 20:35:40,872 - training.trainer - INFO - Epoch 28, Step 97423: Loss=5.8899, Acc=0.280, 
2025-09-28 20:35:47,530 - training.trainer - INFO - Epoch 28, Step 97523: Loss=4.9362, Acc=0.469, 
2025-09-28 20:35:54,253 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.7747, Acc=0.222, 
2025-09-28 20:36:00,695 - training.trainer - INFO - Epoch 28, Step 97723: Loss=5.4077, Acc=0.250, 
2025-09-28 20:36:06,896 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.1723, Acc=0.235, 
2025-09-28 20:36:13,075 - training.trainer - INFO - Epoch 28, Step 97923: Loss=5.7687, Acc=0.267, 
2025-09-28 20:36:19,877 - training.trainer - INFO - Epoch 28, Step 98023: Loss=6.0357, Acc=0.224, 
2025-09-28 20:36:38,504 - training.trainer - INFO - Epoch 29/100 completed in 251.13s - Train Loss: 5.4867, Train Acc: 0.281, Val Loss: 5.6666, Val Acc: 0.252
2025-09-28 20:36:45,734 - training.trainer - INFO - Epoch 29, Step 98206: Loss=5.8312, Acc=0.257, 
2025-09-28 20:36:53,011 - training.trainer - INFO - Epoch 29, Step 98306: Loss=5.3693, Acc=0.320, 
2025-09-28 20:37:00,308 - training.trainer - INFO - Epoch 29, Step 98406: Loss=5.9447, Acc=0.233, 
2025-09-28 20:37:07,807 - training.trainer - INFO - Epoch 29, Step 98506: Loss=5.7746, Acc=0.268, 
2025-09-28 20:37:15,353 - training.trainer - INFO - Epoch 29, Step 98606: Loss=5.8797, Acc=0.190, 
2025-09-28 20:37:22,716 - training.trainer - INFO - Epoch 29, Step 98706: Loss=5.7558, Acc=0.214, 
2025-09-28 20:37:29,568 - training.trainer - INFO - Epoch 29, Step 98806: Loss=5.8421, Acc=0.177, 
2025-09-28 20:37:36,205 - training.trainer - INFO - Epoch 29, Step 98906: Loss=5.6747, Acc=0.261, 
2025-09-28 20:37:43,246 - training.trainer - INFO - Epoch 29, Step 99006: Loss=5.5650, Acc=0.250, 
2025-09-28 20:37:49,669 - training.trainer - INFO - Epoch 29, Step 99106: Loss=5.1402, Acc=0.275, 
2025-09-28 20:37:56,705 - training.trainer - INFO - Epoch 29, Step 99206: Loss=6.2760, Acc=0.200, 
2025-09-28 20:38:04,099 - training.trainer - INFO - Epoch 29, Step 99306: Loss=5.8926, Acc=0.343, 
2025-09-28 20:38:11,455 - training.trainer - INFO - Epoch 29, Step 99406: Loss=4.8185, Acc=0.435, 
2025-09-28 20:38:18,858 - training.trainer - INFO - Epoch 29, Step 99506: Loss=5.8085, Acc=0.242, 
2025-09-28 20:38:26,150 - training.trainer - INFO - Epoch 29, Step 99606: Loss=6.1270, Acc=0.214, 
2025-09-28 20:38:33,447 - training.trainer - INFO - Epoch 29, Step 99706: Loss=6.0779, Acc=0.227, 
2025-09-28 20:38:40,713 - training.trainer - INFO - Epoch 29, Step 99806: Loss=6.1533, Acc=0.256, 
2025-09-28 20:38:48,024 - training.trainer - INFO - Epoch 29, Step 99906: Loss=4.4699, Acc=0.481, 
2025-09-28 20:38:55,487 - training.trainer - INFO - Epoch 29, Step 100006: Loss=5.0183, Acc=0.455, 
2025-09-28 20:39:02,887 - training.trainer - INFO - Epoch 29, Step 100106: Loss=6.0528, Acc=0.188, 
2025-09-28 20:39:10,220 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.8337, Acc=0.227, 
2025-09-28 20:39:17,714 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.3910, Acc=0.289, 
2025-09-28 20:39:25,155 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.5458, Acc=0.273, 
2025-09-28 20:39:32,591 - training.trainer - INFO - Epoch 29, Step 100506: Loss=5.8535, Acc=0.176, 
2025-09-28 20:39:39,994 - training.trainer - INFO - Epoch 29, Step 100606: Loss=5.1293, Acc=0.355, 
2025-09-28 20:39:47,382 - training.trainer - INFO - Epoch 29, Step 100706: Loss=4.7480, Acc=0.383, 
2025-09-28 20:39:54,786 - training.trainer - INFO - Epoch 29, Step 100806: Loss=4.7708, Acc=0.310, 
2025-09-28 20:40:02,231 - training.trainer - INFO - Epoch 29, Step 100906: Loss=3.9757, Acc=0.450, 
2025-09-28 20:40:09,616 - training.trainer - INFO - Epoch 29, Step 101006: Loss=5.7757, Acc=0.217, 
2025-09-28 20:40:16,988 - training.trainer - INFO - Epoch 29, Step 101106: Loss=5.6098, Acc=0.325, 
2025-09-28 20:40:24,430 - training.trainer - INFO - Epoch 29, Step 101206: Loss=5.9644, Acc=0.180, 
2025-09-28 20:40:31,796 - training.trainer - INFO - Epoch 29, Step 101306: Loss=4.4341, Acc=0.400, 
2025-09-28 20:40:39,201 - training.trainer - INFO - Epoch 29, Step 101406: Loss=5.1630, Acc=0.458, 
2025-09-28 20:40:58,461 - training.trainer - INFO - Epoch 30/100 completed in 259.96s - Train Loss: 5.4662, Train Acc: 0.285, Val Loss: 5.6617, Val Acc: 0.255
2025-09-28 20:40:58,763 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-09-28 20:41:05,827 - training.trainer - INFO - Epoch 30, Step 101589: Loss=6.0606, Acc=0.225, 
2025-09-28 20:41:13,314 - training.trainer - INFO - Epoch 30, Step 101689: Loss=5.9206, Acc=0.229, 
2025-09-28 20:41:20,989 - training.trainer - INFO - Epoch 30, Step 101789: Loss=5.1810, Acc=0.321, 
2025-09-28 20:41:28,594 - training.trainer - INFO - Epoch 30, Step 101889: Loss=5.6930, Acc=0.233, 
2025-09-28 20:41:36,115 - training.trainer - INFO - Epoch 30, Step 101989: Loss=5.7919, Acc=0.154, 
2025-09-28 20:41:43,533 - training.trainer - INFO - Epoch 30, Step 102089: Loss=5.6894, Acc=0.281, 
2025-09-28 20:41:50,892 - training.trainer - INFO - Epoch 30, Step 102189: Loss=4.1015, Acc=0.333, 
2025-09-28 20:41:58,295 - training.trainer - INFO - Epoch 30, Step 102289: Loss=5.4945, Acc=0.349, 
2025-09-28 20:42:05,805 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.1467, Acc=0.212, 
2025-09-28 20:42:13,402 - training.trainer - INFO - Epoch 30, Step 102489: Loss=5.3801, Acc=0.222, 
2025-09-28 20:42:20,723 - training.trainer - INFO - Epoch 30, Step 102589: Loss=4.8400, Acc=0.323, 
2025-09-28 20:42:28,080 - training.trainer - INFO - Epoch 30, Step 102689: Loss=4.5634, Acc=0.294, 
2025-09-28 20:42:35,530 - training.trainer - INFO - Epoch 30, Step 102789: Loss=6.1832, Acc=0.213, 
2025-09-28 20:42:42,889 - training.trainer - INFO - Epoch 30, Step 102889: Loss=4.3924, Acc=0.312, 
2025-09-28 20:42:50,213 - training.trainer - INFO - Epoch 30, Step 102989: Loss=5.4106, Acc=0.262, 
2025-09-28 20:42:57,651 - training.trainer - INFO - Epoch 30, Step 103089: Loss=5.7199, Acc=0.209, 
2025-09-28 20:43:04,964 - training.trainer - INFO - Epoch 30, Step 103189: Loss=5.7359, Acc=0.321, 
2025-09-28 20:43:12,310 - training.trainer - INFO - Epoch 30, Step 103289: Loss=5.7614, Acc=0.217, 
2025-09-28 20:43:19,645 - training.trainer - INFO - Epoch 30, Step 103389: Loss=4.6803, Acc=0.304, 
2025-09-28 20:43:26,903 - training.trainer - INFO - Epoch 30, Step 103489: Loss=5.2591, Acc=0.286, 
2025-09-28 20:43:34,155 - training.trainer - INFO - Epoch 30, Step 103589: Loss=6.0299, Acc=0.203, 
2025-09-28 20:43:41,449 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.5454, Acc=0.247, 
2025-09-28 20:43:48,742 - training.trainer - INFO - Epoch 30, Step 103789: Loss=5.2858, Acc=0.300, 
2025-09-28 20:43:56,148 - training.trainer - INFO - Epoch 30, Step 103889: Loss=5.0903, Acc=0.481, 
2025-09-28 20:44:03,469 - training.trainer - INFO - Epoch 30, Step 103989: Loss=5.8107, Acc=0.273, 
2025-09-28 20:44:10,812 - training.trainer - INFO - Epoch 30, Step 104089: Loss=5.9338, Acc=0.208, 
2025-09-28 20:44:18,174 - training.trainer - INFO - Epoch 30, Step 104189: Loss=5.5237, Acc=0.263, 
2025-09-28 20:44:25,542 - training.trainer - INFO - Epoch 30, Step 104289: Loss=5.1719, Acc=0.222, 
2025-09-28 20:44:32,919 - training.trainer - INFO - Epoch 30, Step 104389: Loss=4.6881, Acc=0.231, 
2025-09-28 20:44:40,332 - training.trainer - INFO - Epoch 30, Step 104489: Loss=5.6546, Acc=0.300, 
2025-09-28 20:44:47,638 - training.trainer - INFO - Epoch 30, Step 104589: Loss=5.4283, Acc=0.382, 
2025-09-28 20:44:54,876 - training.trainer - INFO - Epoch 30, Step 104689: Loss=5.9744, Acc=0.244, 
2025-09-28 20:45:02,126 - training.trainer - INFO - Epoch 30, Step 104789: Loss=6.1378, Acc=0.179, 
2025-09-28 20:45:20,776 - training.trainer - INFO - Epoch 31/100 completed in 262.01s - Train Loss: 5.4502, Train Acc: 0.287, Val Loss: 5.6513, Val Acc: 0.256
2025-09-28 20:45:21,517 - training.trainer - INFO - New best model saved with validation loss: 5.6513
2025-09-28 20:45:21,517 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_31.pt
2025-09-28 20:45:28,465 - training.trainer - INFO - Epoch 31, Step 104972: Loss=5.9488, Acc=0.194, 
2025-09-28 20:45:35,968 - training.trainer - INFO - Epoch 31, Step 105072: Loss=5.6256, Acc=0.397, 
2025-09-28 20:45:42,639 - training.trainer - INFO - Epoch 31, Step 105172: Loss=5.4548, Acc=0.273, 
2025-09-28 20:45:49,748 - training.trainer - INFO - Epoch 31, Step 105272: Loss=5.8760, Acc=0.250, 
2025-09-28 20:45:57,153 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.6096, Acc=0.233, 
2025-09-28 20:46:04,618 - training.trainer - INFO - Epoch 31, Step 105472: Loss=5.2717, Acc=0.375, 
2025-09-28 20:46:12,211 - training.trainer - INFO - Epoch 31, Step 105572: Loss=6.4352, Acc=0.220, 
2025-09-28 20:46:19,620 - training.trainer - INFO - Epoch 31, Step 105672: Loss=5.3019, Acc=0.233, 
2025-09-28 20:46:27,097 - training.trainer - INFO - Epoch 31, Step 105772: Loss=4.9249, Acc=0.302, 
2025-09-28 20:46:34,430 - training.trainer - INFO - Epoch 31, Step 105872: Loss=4.9834, Acc=0.296, 
2025-09-28 20:46:41,699 - training.trainer - INFO - Epoch 31, Step 105972: Loss=6.2789, Acc=0.240, 
2025-09-28 20:46:48,947 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.1691, Acc=0.259, 
2025-09-28 20:46:56,460 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.1810, Acc=0.231, 
2025-09-28 20:47:03,661 - training.trainer - INFO - Epoch 31, Step 106272: Loss=4.6385, Acc=0.344, 
2025-09-28 20:47:10,889 - training.trainer - INFO - Epoch 31, Step 106372: Loss=4.0458, Acc=0.536, 
2025-09-28 20:47:18,129 - training.trainer - INFO - Epoch 31, Step 106472: Loss=5.4732, Acc=0.222, 
2025-09-28 20:47:25,557 - training.trainer - INFO - Epoch 31, Step 106572: Loss=6.2558, Acc=0.220, 
2025-09-28 20:47:32,981 - training.trainer - INFO - Epoch 31, Step 106672: Loss=5.1728, Acc=0.250, 
2025-09-28 20:47:40,202 - training.trainer - INFO - Epoch 31, Step 106772: Loss=5.4269, Acc=0.267, 
2025-09-28 20:47:47,607 - training.trainer - INFO - Epoch 31, Step 106872: Loss=4.7399, Acc=0.379, 
2025-09-28 20:47:54,998 - training.trainer - INFO - Epoch 31, Step 106972: Loss=5.7022, Acc=0.240, 
2025-09-28 20:48:02,260 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.5020, Acc=0.296, 
2025-09-28 20:48:09,533 - training.trainer - INFO - Epoch 31, Step 107172: Loss=5.4824, Acc=0.265, 
2025-09-28 20:48:16,757 - training.trainer - INFO - Epoch 31, Step 107272: Loss=6.1181, Acc=0.231, 
2025-09-28 20:48:24,021 - training.trainer - INFO - Epoch 31, Step 107372: Loss=5.5812, Acc=0.250, 
2025-09-28 20:48:31,239 - training.trainer - INFO - Epoch 31, Step 107472: Loss=5.7988, Acc=0.239, 
2025-09-28 20:48:38,665 - training.trainer - INFO - Epoch 31, Step 107572: Loss=4.5571, Acc=0.348, 
2025-09-28 20:48:46,272 - training.trainer - INFO - Epoch 31, Step 107672: Loss=5.5012, Acc=0.200, 
2025-09-28 20:48:53,656 - training.trainer - INFO - Epoch 31, Step 107772: Loss=6.2550, Acc=0.172, 
2025-09-28 20:49:01,049 - training.trainer - INFO - Epoch 31, Step 107872: Loss=5.5311, Acc=0.300, 
2025-09-28 20:49:08,468 - training.trainer - INFO - Epoch 31, Step 107972: Loss=5.3725, Acc=0.320, 
2025-09-28 20:49:15,854 - training.trainer - INFO - Epoch 31, Step 108072: Loss=5.4968, Acc=0.333, 
2025-09-28 20:49:23,325 - training.trainer - INFO - Epoch 31, Step 108172: Loss=4.6980, Acc=0.385, 
2025-09-28 20:49:42,549 - training.trainer - INFO - Epoch 32/100 completed in 261.03s - Train Loss: 5.4280, Train Acc: 0.290, Val Loss: 5.6419, Val Acc: 0.259
2025-09-28 20:49:43,247 - training.trainer - INFO - New best model saved with validation loss: 5.6419
2025-09-28 20:49:43,247 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_32.pt
2025-09-28 20:49:49,895 - training.trainer - INFO - Epoch 32, Step 108355: Loss=6.0620, Acc=0.256, 
2025-09-28 20:49:57,078 - training.trainer - INFO - Epoch 32, Step 108455: Loss=6.0487, Acc=0.171, 
2025-09-28 20:50:04,507 - training.trainer - INFO - Epoch 32, Step 108555: Loss=5.4320, Acc=0.289, 
2025-09-28 20:50:11,952 - training.trainer - INFO - Epoch 32, Step 108655: Loss=5.8264, Acc=0.240, 
2025-09-28 20:50:19,384 - training.trainer - INFO - Epoch 32, Step 108755: Loss=6.0614, Acc=0.216, 
2025-09-28 20:50:26,724 - training.trainer - INFO - Epoch 32, Step 108855: Loss=4.9492, Acc=0.353, 
2025-09-28 20:50:34,125 - training.trainer - INFO - Epoch 32, Step 108955: Loss=5.7769, Acc=0.191, 
2025-09-28 20:50:41,607 - training.trainer - INFO - Epoch 32, Step 109055: Loss=4.9954, Acc=0.391, 
2025-09-28 20:50:49,114 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.5672, Acc=0.257, 
2025-09-28 20:50:56,487 - training.trainer - INFO - Epoch 32, Step 109255: Loss=5.3756, Acc=0.381, 
2025-09-28 20:51:03,885 - training.trainer - INFO - Epoch 32, Step 109355: Loss=5.0204, Acc=0.240, 
2025-09-28 20:51:11,282 - training.trainer - INFO - Epoch 32, Step 109455: Loss=6.3662, Acc=0.198, 
2025-09-28 20:51:18,702 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.5980, Acc=0.295, 
2025-09-28 20:51:26,119 - training.trainer - INFO - Epoch 32, Step 109655: Loss=6.2122, Acc=0.279, 
2025-09-28 20:51:33,507 - training.trainer - INFO - Epoch 32, Step 109755: Loss=5.8013, Acc=0.263, 
2025-09-28 20:51:40,846 - training.trainer - INFO - Epoch 32, Step 109855: Loss=4.9086, Acc=0.219, 
2025-09-28 20:51:48,323 - training.trainer - INFO - Epoch 32, Step 109955: Loss=6.5661, Acc=0.138, 
2025-09-28 20:51:55,648 - training.trainer - INFO - Epoch 32, Step 110055: Loss=5.2913, Acc=0.231, 
2025-09-28 20:52:03,076 - training.trainer - INFO - Epoch 32, Step 110155: Loss=4.8263, Acc=0.350, 
2025-09-28 20:52:10,465 - training.trainer - INFO - Epoch 32, Step 110255: Loss=6.0571, Acc=0.200, 
2025-09-28 20:52:17,672 - training.trainer - INFO - Epoch 32, Step 110355: Loss=6.1063, Acc=0.156, 
2025-09-28 20:52:25,236 - training.trainer - INFO - Epoch 32, Step 110455: Loss=5.9432, Acc=0.263, 
2025-09-28 20:52:32,773 - training.trainer - INFO - Epoch 32, Step 110555: Loss=6.4600, Acc=0.170, 
2025-09-28 20:52:40,303 - training.trainer - INFO - Epoch 32, Step 110655: Loss=5.6217, Acc=0.233, 
2025-09-28 20:52:47,762 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.4329, Acc=0.300, 
2025-09-28 20:52:55,154 - training.trainer - INFO - Epoch 32, Step 110855: Loss=3.7240, Acc=0.524, 
2025-09-28 20:53:02,754 - training.trainer - INFO - Epoch 32, Step 110955: Loss=6.3649, Acc=0.188, 
2025-09-28 20:53:10,133 - training.trainer - INFO - Epoch 32, Step 111055: Loss=5.7905, Acc=0.282, 
2025-09-28 20:53:17,707 - training.trainer - INFO - Epoch 32, Step 111155: Loss=5.2216, Acc=0.200, 
2025-09-28 20:53:25,278 - training.trainer - INFO - Epoch 32, Step 111255: Loss=4.7661, Acc=0.273, 
2025-09-28 20:53:32,881 - training.trainer - INFO - Epoch 32, Step 111355: Loss=5.1515, Acc=0.345, 
2025-09-28 20:53:40,378 - training.trainer - INFO - Epoch 32, Step 111455: Loss=2.4129, Acc=0.767, 
2025-09-28 20:53:47,872 - training.trainer - INFO - Epoch 32, Step 111555: Loss=5.4671, Acc=0.278, 
2025-09-28 20:54:07,434 - training.trainer - INFO - Epoch 33/100 completed in 264.19s - Train Loss: 5.4109, Train Acc: 0.294, Val Loss: 5.6438, Val Acc: 0.258
2025-09-28 20:54:15,331 - training.trainer - INFO - Epoch 33, Step 111738: Loss=3.9632, Acc=0.400, 
2025-09-28 20:54:22,883 - training.trainer - INFO - Epoch 33, Step 111838: Loss=5.4058, Acc=0.367, 
2025-09-28 20:54:30,421 - training.trainer - INFO - Epoch 33, Step 111938: Loss=5.3828, Acc=0.214, 
2025-09-28 20:54:37,875 - training.trainer - INFO - Epoch 33, Step 112038: Loss=6.4568, Acc=0.200, 
2025-09-28 20:54:45,199 - training.trainer - INFO - Epoch 33, Step 112138: Loss=5.9666, Acc=0.237, 
2025-09-28 20:54:52,518 - training.trainer - INFO - Epoch 33, Step 112238: Loss=5.5153, Acc=0.241, 
2025-09-28 20:54:59,906 - training.trainer - INFO - Epoch 33, Step 112338: Loss=5.8909, Acc=0.234, 
2025-09-28 20:55:07,295 - training.trainer - INFO - Epoch 33, Step 112438: Loss=5.2500, Acc=0.238, 
2025-09-28 20:55:14,941 - training.trainer - INFO - Epoch 33, Step 112538: Loss=6.1363, Acc=0.239, 
2025-09-28 20:55:22,338 - training.trainer - INFO - Epoch 33, Step 112638: Loss=6.1941, Acc=0.226, 
2025-09-28 20:55:29,946 - training.trainer - INFO - Epoch 33, Step 112738: Loss=4.6400, Acc=0.350, 
2025-09-28 20:55:37,453 - training.trainer - INFO - Epoch 33, Step 112838: Loss=5.7431, Acc=0.294, 
2025-09-28 20:55:44,924 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.4146, Acc=0.262, 
2025-09-28 20:55:52,277 - training.trainer - INFO - Epoch 33, Step 113038: Loss=4.9698, Acc=0.233, 
2025-09-28 20:55:59,713 - training.trainer - INFO - Epoch 33, Step 113138: Loss=5.2899, Acc=0.400, 
2025-09-28 20:56:07,127 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.6300, Acc=0.250, 
2025-09-28 20:56:14,640 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.1271, Acc=0.333, 
2025-09-28 20:56:22,336 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.8408, Acc=0.214, 
2025-09-28 20:56:29,913 - training.trainer - INFO - Epoch 33, Step 113538: Loss=5.3098, Acc=0.295, 
2025-09-28 20:56:37,241 - training.trainer - INFO - Epoch 33, Step 113638: Loss=5.7021, Acc=0.200, 
2025-09-28 20:56:44,601 - training.trainer - INFO - Epoch 33, Step 113738: Loss=5.4250, Acc=0.273, 
2025-09-28 20:56:52,024 - training.trainer - INFO - Epoch 33, Step 113838: Loss=5.4965, Acc=0.189, 
2025-09-28 20:56:59,711 - training.trainer - INFO - Epoch 33, Step 113938: Loss=5.5076, Acc=0.366, 
2025-09-28 20:57:07,228 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.4662, Acc=0.276, 
2025-09-28 20:57:14,653 - training.trainer - INFO - Epoch 33, Step 114138: Loss=4.7631, Acc=0.429, 
2025-09-28 20:57:22,115 - training.trainer - INFO - Epoch 33, Step 114238: Loss=5.6465, Acc=0.227, 
2025-09-28 20:57:29,485 - training.trainer - INFO - Epoch 33, Step 114338: Loss=5.8624, Acc=0.240, 
2025-09-28 20:57:36,906 - training.trainer - INFO - Epoch 33, Step 114438: Loss=5.3959, Acc=0.400, 
2025-09-28 20:57:44,372 - training.trainer - INFO - Epoch 33, Step 114538: Loss=4.9823, Acc=0.406, 
2025-09-28 20:57:51,826 - training.trainer - INFO - Epoch 33, Step 114638: Loss=4.2924, Acc=0.409, 
2025-09-28 20:57:59,232 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.1668, Acc=0.333, 
2025-09-28 20:58:06,642 - training.trainer - INFO - Epoch 33, Step 114838: Loss=5.7308, Acc=0.355, 
2025-09-28 20:58:13,995 - training.trainer - INFO - Epoch 33, Step 114938: Loss=6.0836, Acc=0.250, 
2025-09-28 20:58:32,495 - training.trainer - INFO - Epoch 34/100 completed in 265.06s - Train Loss: 5.4007, Train Acc: 0.296, Val Loss: 5.6520, Val Acc: 0.257
2025-09-28 20:58:40,388 - training.trainer - INFO - Epoch 34, Step 115121: Loss=5.0191, Acc=0.375, 
2025-09-28 20:58:47,904 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.3779, Acc=0.269, 
2025-09-28 20:58:55,441 - training.trainer - INFO - Epoch 34, Step 115321: Loss=6.3025, Acc=0.206, 
2025-09-28 20:59:03,011 - training.trainer - INFO - Epoch 34, Step 115421: Loss=5.7577, Acc=0.263, 
2025-09-28 20:59:10,462 - training.trainer - INFO - Epoch 34, Step 115521: Loss=6.0527, Acc=0.233, 
2025-09-28 20:59:17,887 - training.trainer - INFO - Epoch 34, Step 115621: Loss=5.9671, Acc=0.263, 
2025-09-28 20:59:25,342 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.0216, Acc=0.364, 
2025-09-28 20:59:32,747 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.1213, Acc=0.343, 
2025-09-28 20:59:40,237 - training.trainer - INFO - Epoch 34, Step 115921: Loss=4.6630, Acc=0.333, 
2025-09-28 20:59:47,664 - training.trainer - INFO - Epoch 34, Step 116021: Loss=6.2916, Acc=0.226, 
2025-09-28 20:59:55,146 - training.trainer - INFO - Epoch 34, Step 116121: Loss=5.8076, Acc=0.325, 
2025-09-28 21:00:02,687 - training.trainer - INFO - Epoch 34, Step 116221: Loss=5.9889, Acc=0.189, 
2025-09-28 21:00:10,072 - training.trainer - INFO - Epoch 34, Step 116321: Loss=5.0555, Acc=0.357, 
2025-09-28 21:00:17,485 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.5083, Acc=0.205, 
2025-09-28 21:00:24,854 - training.trainer - INFO - Epoch 34, Step 116521: Loss=6.1177, Acc=0.240, 
2025-09-28 21:00:32,586 - training.trainer - INFO - Epoch 34, Step 116621: Loss=6.0364, Acc=0.235, 
2025-09-28 21:00:40,119 - training.trainer - INFO - Epoch 34, Step 116721: Loss=5.1786, Acc=0.417, 
2025-09-28 21:00:47,506 - training.trainer - INFO - Epoch 34, Step 116821: Loss=4.3009, Acc=0.366, 
2025-09-28 21:00:55,055 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.3624, Acc=0.310, 
2025-09-28 21:01:02,396 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.1207, Acc=0.238, 
2025-09-28 21:01:09,935 - training.trainer - INFO - Epoch 34, Step 117121: Loss=6.1606, Acc=0.133, 
2025-09-28 21:01:17,463 - training.trainer - INFO - Epoch 34, Step 117221: Loss=6.1731, Acc=0.237, 
2025-09-28 21:01:24,875 - training.trainer - INFO - Epoch 34, Step 117321: Loss=4.6352, Acc=0.438, 
2025-09-28 21:01:32,163 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.1541, Acc=0.371, 
2025-09-28 21:01:39,495 - training.trainer - INFO - Epoch 34, Step 117521: Loss=6.3034, Acc=0.203, 
2025-09-28 21:01:46,805 - training.trainer - INFO - Epoch 34, Step 117621: Loss=5.9976, Acc=0.184, 
2025-09-28 21:01:54,008 - training.trainer - INFO - Epoch 34, Step 117721: Loss=4.8298, Acc=0.426, 
2025-09-28 21:02:01,284 - training.trainer - INFO - Epoch 34, Step 117821: Loss=6.4951, Acc=0.213, 
2025-09-28 21:02:08,542 - training.trainer - INFO - Epoch 34, Step 117921: Loss=5.9245, Acc=0.208, 
2025-09-28 21:02:15,829 - training.trainer - INFO - Epoch 34, Step 118021: Loss=5.2362, Acc=0.294, 
2025-09-28 21:02:23,011 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.9637, Acc=0.250, 
2025-09-28 21:02:30,313 - training.trainer - INFO - Epoch 34, Step 118221: Loss=6.3832, Acc=0.200, 
2025-09-28 21:02:37,755 - training.trainer - INFO - Epoch 34, Step 118321: Loss=6.7819, Acc=0.250, 
2025-09-28 21:02:56,886 - training.trainer - INFO - Epoch 35/100 completed in 264.39s - Train Loss: 5.3811, Train Acc: 0.299, Val Loss: 5.6496, Val Acc: 0.261
2025-09-28 21:02:57,174 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-09-28 21:03:04,432 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.7561, Acc=0.180, 
2025-09-28 21:03:11,825 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.8881, Acc=0.224, 
2025-09-28 21:03:19,060 - training.trainer - INFO - Epoch 35, Step 118704: Loss=5.2163, Acc=0.250, 
2025-09-28 21:03:26,034 - training.trainer - INFO - Epoch 35, Step 118804: Loss=5.6749, Acc=0.250, 
2025-09-28 21:03:32,993 - training.trainer - INFO - Epoch 35, Step 118904: Loss=5.0989, Acc=0.366, 
2025-09-28 21:03:40,051 - training.trainer - INFO - Epoch 35, Step 119004: Loss=4.6361, Acc=0.300, 
2025-09-28 21:03:47,240 - training.trainer - INFO - Epoch 35, Step 119104: Loss=4.8628, Acc=0.406, 
2025-09-28 21:03:54,695 - training.trainer - INFO - Epoch 35, Step 119204: Loss=6.5909, Acc=0.152, 
2025-09-28 21:04:02,155 - training.trainer - INFO - Epoch 35, Step 119304: Loss=4.3986, Acc=0.296, 
2025-09-28 21:04:09,630 - training.trainer - INFO - Epoch 35, Step 119404: Loss=6.0258, Acc=0.227, 
2025-09-28 21:04:17,122 - training.trainer - INFO - Epoch 35, Step 119504: Loss=4.3814, Acc=0.406, 
2025-09-28 21:04:24,639 - training.trainer - INFO - Epoch 35, Step 119604: Loss=4.4311, Acc=0.406, 
2025-09-28 21:04:32,075 - training.trainer - INFO - Epoch 35, Step 119704: Loss=6.2177, Acc=0.175, 
2025-09-28 21:04:39,429 - training.trainer - INFO - Epoch 35, Step 119804: Loss=5.8670, Acc=0.211, 
2025-09-28 21:04:46,855 - training.trainer - INFO - Epoch 35, Step 119904: Loss=4.3574, Acc=0.353, 
2025-09-28 21:04:54,283 - training.trainer - INFO - Epoch 35, Step 120004: Loss=5.6254, Acc=0.237, 
2025-09-28 21:05:01,696 - training.trainer - INFO - Epoch 35, Step 120104: Loss=6.2750, Acc=0.244, 
2025-09-28 21:05:09,122 - training.trainer - INFO - Epoch 35, Step 120204: Loss=5.1904, Acc=0.391, 
2025-09-28 21:05:16,482 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.2515, Acc=0.268, 
2025-09-28 21:05:23,865 - training.trainer - INFO - Epoch 35, Step 120404: Loss=5.2075, Acc=0.298, 
2025-09-28 21:05:31,228 - training.trainer - INFO - Epoch 35, Step 120504: Loss=3.6575, Acc=0.465, 
2025-09-28 21:05:38,535 - training.trainer - INFO - Epoch 35, Step 120604: Loss=5.6182, Acc=0.189, 
2025-09-28 21:05:45,917 - training.trainer - INFO - Epoch 35, Step 120704: Loss=4.9522, Acc=0.259, 
2025-09-28 21:05:53,319 - training.trainer - INFO - Epoch 35, Step 120804: Loss=6.1803, Acc=0.191, 
2025-09-28 21:06:00,989 - training.trainer - INFO - Epoch 35, Step 120904: Loss=5.5814, Acc=0.228, 
2025-09-28 21:06:08,381 - training.trainer - INFO - Epoch 35, Step 121004: Loss=4.5467, Acc=0.372, 
2025-09-28 21:06:15,750 - training.trainer - INFO - Epoch 35, Step 121104: Loss=3.4863, Acc=0.686, 
2025-09-28 21:06:23,165 - training.trainer - INFO - Epoch 35, Step 121204: Loss=6.2158, Acc=0.160, 
2025-09-28 21:06:30,463 - training.trainer - INFO - Epoch 35, Step 121304: Loss=2.4108, Acc=0.696, 
2025-09-28 21:06:37,912 - training.trainer - INFO - Epoch 35, Step 121404: Loss=6.1703, Acc=0.162, 
2025-09-28 21:06:45,324 - training.trainer - INFO - Epoch 35, Step 121504: Loss=6.3186, Acc=0.217, 
2025-09-28 21:06:52,701 - training.trainer - INFO - Epoch 35, Step 121604: Loss=6.2813, Acc=0.228, 
2025-09-28 21:07:00,142 - training.trainer - INFO - Epoch 35, Step 121704: Loss=6.2232, Acc=0.211, 
2025-09-28 21:07:18,602 - training.trainer - INFO - Epoch 36/100 completed in 261.43s - Train Loss: 5.3675, Train Acc: 0.299, Val Loss: 5.6494, Val Acc: 0.258
2025-09-28 21:07:25,863 - training.trainer - INFO - Epoch 36, Step 121887: Loss=4.5897, Acc=0.500, 
2025-09-28 21:07:32,900 - training.trainer - INFO - Epoch 36, Step 121987: Loss=5.9203, Acc=0.226, 
2025-09-28 21:07:40,511 - training.trainer - INFO - Epoch 36, Step 122087: Loss=5.5442, Acc=0.222, 
2025-09-28 21:07:48,366 - training.trainer - INFO - Epoch 36, Step 122187: Loss=5.9030, Acc=0.258, 
2025-09-28 21:07:55,824 - training.trainer - INFO - Epoch 36, Step 122287: Loss=5.0971, Acc=0.333, 
2025-09-28 21:08:03,191 - training.trainer - INFO - Epoch 36, Step 122387: Loss=6.6828, Acc=0.216, 
2025-09-28 21:08:10,473 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.3153, Acc=0.293, 
2025-09-28 21:08:17,801 - training.trainer - INFO - Epoch 36, Step 122587: Loss=4.9666, Acc=0.286, 
2025-09-28 21:08:25,093 - training.trainer - INFO - Epoch 36, Step 122687: Loss=5.2582, Acc=0.289, 
2025-09-28 21:08:32,357 - training.trainer - INFO - Epoch 36, Step 122787: Loss=5.7837, Acc=0.200, 
2025-09-28 21:08:39,682 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.6187, Acc=0.388, 
2025-09-28 21:08:47,023 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.8989, Acc=0.250, 
2025-09-28 21:08:54,309 - training.trainer - INFO - Epoch 36, Step 123087: Loss=5.3519, Acc=0.300, 
2025-09-28 21:09:01,557 - training.trainer - INFO - Epoch 36, Step 123187: Loss=5.6692, Acc=0.294, 
2025-09-28 21:09:08,825 - training.trainer - INFO - Epoch 36, Step 123287: Loss=5.6664, Acc=0.220, 
2025-09-28 21:09:16,084 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.7383, Acc=0.289, 
2025-09-28 21:09:23,479 - training.trainer - INFO - Epoch 36, Step 123487: Loss=5.4402, Acc=0.261, 
2025-09-28 21:09:30,774 - training.trainer - INFO - Epoch 36, Step 123587: Loss=6.0780, Acc=0.250, 
2025-09-28 21:09:38,058 - training.trainer - INFO - Epoch 36, Step 123687: Loss=5.6252, Acc=0.273, 
2025-09-28 21:09:45,416 - training.trainer - INFO - Epoch 36, Step 123787: Loss=5.6371, Acc=0.268, 
2025-09-28 21:09:52,720 - training.trainer - INFO - Epoch 36, Step 123887: Loss=5.9096, Acc=0.253, 
2025-09-28 21:10:00,161 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.8019, Acc=0.200, 
2025-09-28 21:10:07,585 - training.trainer - INFO - Epoch 36, Step 124087: Loss=5.1989, Acc=0.360, 
2025-09-28 21:10:15,028 - training.trainer - INFO - Epoch 36, Step 124187: Loss=4.6946, Acc=0.333, 
2025-09-28 21:10:22,474 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.4109, Acc=0.256, 
2025-09-28 21:10:29,970 - training.trainer - INFO - Epoch 36, Step 124387: Loss=5.2667, Acc=0.308, 
2025-09-28 21:10:37,344 - training.trainer - INFO - Epoch 36, Step 124487: Loss=5.4884, Acc=0.185, 
2025-09-28 21:10:44,872 - training.trainer - INFO - Epoch 36, Step 124587: Loss=5.6119, Acc=0.324, 
2025-09-28 21:10:52,166 - training.trainer - INFO - Epoch 36, Step 124687: Loss=3.3907, Acc=0.576, 
2025-09-28 21:10:59,571 - training.trainer - INFO - Epoch 36, Step 124787: Loss=5.8584, Acc=0.171, 
2025-09-28 21:11:06,844 - training.trainer - INFO - Epoch 36, Step 124887: Loss=5.2585, Acc=0.212, 
2025-09-28 21:11:14,144 - training.trainer - INFO - Epoch 36, Step 124987: Loss=3.0345, Acc=0.625, 
2025-09-28 21:11:21,430 - training.trainer - INFO - Epoch 36, Step 125087: Loss=4.4793, Acc=0.312, 
2025-09-28 21:11:40,224 - training.trainer - INFO - Epoch 37/100 completed in 261.62s - Train Loss: 5.3445, Train Acc: 0.304, Val Loss: 5.6636, Val Acc: 0.258
2025-09-28 21:11:47,963 - training.trainer - INFO - Epoch 37, Step 125270: Loss=4.9994, Acc=0.321, 
2025-09-28 21:11:55,502 - training.trainer - INFO - Epoch 37, Step 125370: Loss=5.8181, Acc=0.243, 
2025-09-28 21:12:03,000 - training.trainer - INFO - Epoch 37, Step 125470: Loss=5.4255, Acc=0.226, 
2025-09-28 21:12:10,511 - training.trainer - INFO - Epoch 37, Step 125570: Loss=6.1340, Acc=0.200, 
2025-09-28 21:12:18,113 - training.trainer - INFO - Epoch 37, Step 125670: Loss=6.0208, Acc=0.227, 
2025-09-28 21:12:25,510 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.9722, Acc=0.324, 
2025-09-28 21:12:32,740 - training.trainer - INFO - Epoch 37, Step 125870: Loss=5.0499, Acc=0.217, 
2025-09-28 21:12:40,037 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.4452, Acc=0.286, 
2025-09-28 21:12:47,246 - training.trainer - INFO - Epoch 37, Step 126070: Loss=5.8427, Acc=0.304, 
2025-09-28 21:12:54,650 - training.trainer - INFO - Epoch 37, Step 126170: Loss=5.7151, Acc=0.260, 
2025-09-28 21:13:02,183 - training.trainer - INFO - Epoch 37, Step 126270: Loss=5.6846, Acc=0.152, 
2025-09-28 21:13:09,723 - training.trainer - INFO - Epoch 37, Step 126370: Loss=5.0792, Acc=0.364, 
2025-09-28 21:13:17,240 - training.trainer - INFO - Epoch 37, Step 126470: Loss=5.8540, Acc=0.231, 
2025-09-28 21:13:24,441 - training.trainer - INFO - Epoch 37, Step 126570: Loss=5.7573, Acc=0.244, 
2025-09-28 21:13:31,722 - training.trainer - INFO - Epoch 37, Step 126670: Loss=5.4263, Acc=0.200, 
2025-09-28 21:13:39,059 - training.trainer - INFO - Epoch 37, Step 126770: Loss=6.3229, Acc=0.182, 
2025-09-28 21:13:46,356 - training.trainer - INFO - Epoch 37, Step 126870: Loss=5.1565, Acc=0.280, 
2025-09-28 21:13:53,735 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.4372, Acc=0.259, 
2025-09-28 21:14:01,260 - training.trainer - INFO - Epoch 37, Step 127070: Loss=5.6308, Acc=0.224, 
2025-09-28 21:14:08,619 - training.trainer - INFO - Epoch 37, Step 127170: Loss=3.6891, Acc=0.529, 
2025-09-28 21:14:15,903 - training.trainer - INFO - Epoch 37, Step 127270: Loss=5.0107, Acc=0.318, 
2025-09-28 21:14:23,233 - training.trainer - INFO - Epoch 37, Step 127370: Loss=4.7846, Acc=0.393, 
2025-09-28 21:14:30,563 - training.trainer - INFO - Epoch 37, Step 127470: Loss=6.0314, Acc=0.194, 
2025-09-28 21:14:37,945 - training.trainer - INFO - Epoch 37, Step 127570: Loss=4.7629, Acc=0.387, 
2025-09-28 21:14:45,232 - training.trainer - INFO - Epoch 37, Step 127670: Loss=5.9113, Acc=0.257, 
2025-09-28 21:14:52,533 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.2857, Acc=0.292, 
2025-09-28 21:14:59,791 - training.trainer - INFO - Epoch 37, Step 127870: Loss=5.4470, Acc=0.200, 
2025-09-28 21:15:07,013 - training.trainer - INFO - Epoch 37, Step 127970: Loss=5.0282, Acc=0.333, 
2025-09-28 21:15:14,377 - training.trainer - INFO - Epoch 37, Step 128070: Loss=5.0098, Acc=0.267, 
2025-09-28 21:15:21,621 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.6700, Acc=0.286, 
2025-09-28 21:15:28,853 - training.trainer - INFO - Epoch 37, Step 128270: Loss=6.0684, Acc=0.200, 
2025-09-28 21:15:36,092 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.9604, Acc=0.244, 
2025-09-28 21:15:43,310 - training.trainer - INFO - Epoch 37, Step 128470: Loss=5.4398, Acc=0.360, 
2025-09-28 21:16:01,625 - training.trainer - INFO - Epoch 38/100 completed in 261.40s - Train Loss: 5.3321, Train Acc: 0.307, Val Loss: 5.6707, Val Acc: 0.261
2025-09-28 21:16:08,163 - training.trainer - INFO - Epoch 38, Step 128653: Loss=5.9228, Acc=0.235, 
2025-09-28 21:16:14,349 - training.trainer - INFO - Epoch 38, Step 128753: Loss=4.5543, Acc=0.280, 
2025-09-28 21:16:20,723 - training.trainer - INFO - Epoch 38, Step 128853: Loss=5.5475, Acc=0.150, 
2025-09-28 21:16:27,774 - training.trainer - INFO - Epoch 38, Step 128953: Loss=5.5477, Acc=0.327, 
2025-09-28 21:16:34,738 - training.trainer - INFO - Epoch 38, Step 129053: Loss=5.4911, Acc=0.250, 
2025-09-28 21:16:41,734 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.1620, Acc=0.333, 
2025-09-28 21:16:49,062 - training.trainer - INFO - Epoch 38, Step 129253: Loss=2.2751, Acc=0.760, 
2025-09-28 21:16:56,356 - training.trainer - INFO - Epoch 38, Step 129353: Loss=4.3299, Acc=0.407, 
2025-09-28 21:17:02,898 - training.trainer - INFO - Epoch 38, Step 129453: Loss=6.3867, Acc=0.231, 
2025-09-28 21:17:09,413 - training.trainer - INFO - Epoch 38, Step 129553: Loss=6.1866, Acc=0.290, 
2025-09-28 21:17:16,597 - training.trainer - INFO - Epoch 38, Step 129653: Loss=6.3164, Acc=0.212, 
2025-09-28 21:17:24,023 - training.trainer - INFO - Epoch 38, Step 129753: Loss=5.2450, Acc=0.250, 
2025-09-28 21:17:31,595 - training.trainer - INFO - Epoch 38, Step 129853: Loss=5.3000, Acc=0.308, 
2025-09-28 21:17:39,131 - training.trainer - INFO - Epoch 38, Step 129953: Loss=5.8076, Acc=0.278, 
2025-09-28 21:17:46,662 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.1776, Acc=0.378, 
2025-09-28 21:17:54,083 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.9034, Acc=0.295, 
2025-09-28 21:18:01,556 - training.trainer - INFO - Epoch 38, Step 130253: Loss=5.3467, Acc=0.378, 
2025-09-28 21:18:09,107 - training.trainer - INFO - Epoch 38, Step 130353: Loss=3.4752, Acc=0.562, 
2025-09-28 21:18:16,505 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.9984, Acc=0.250, 
2025-09-28 21:18:23,898 - training.trainer - INFO - Epoch 38, Step 130553: Loss=4.7215, Acc=0.297, 
2025-09-28 21:18:31,414 - training.trainer - INFO - Epoch 38, Step 130653: Loss=4.8999, Acc=0.298, 
2025-09-28 21:18:38,838 - training.trainer - INFO - Epoch 38, Step 130753: Loss=4.0373, Acc=0.481, 
2025-09-28 21:18:46,273 - training.trainer - INFO - Epoch 38, Step 130853: Loss=5.8842, Acc=0.231, 
2025-09-28 21:18:53,731 - training.trainer - INFO - Epoch 38, Step 130953: Loss=6.3687, Acc=0.176, 
2025-09-28 21:19:01,139 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.2935, Acc=0.333, 
2025-09-28 21:19:08,594 - training.trainer - INFO - Epoch 38, Step 131153: Loss=6.7318, Acc=0.180, 
2025-09-28 21:19:15,988 - training.trainer - INFO - Epoch 38, Step 131253: Loss=6.0127, Acc=0.233, 
2025-09-28 21:19:23,461 - training.trainer - INFO - Epoch 38, Step 131353: Loss=6.0518, Acc=0.220, 
2025-09-28 21:19:30,961 - training.trainer - INFO - Epoch 38, Step 131453: Loss=5.9606, Acc=0.283, 
2025-09-28 21:19:38,419 - training.trainer - INFO - Epoch 38, Step 131553: Loss=5.3867, Acc=0.342, 
2025-09-28 21:19:45,917 - training.trainer - INFO - Epoch 38, Step 131653: Loss=4.9105, Acc=0.333, 
2025-09-28 21:19:53,342 - training.trainer - INFO - Epoch 38, Step 131753: Loss=5.6667, Acc=0.286, 
2025-09-28 21:20:00,795 - training.trainer - INFO - Epoch 38, Step 131853: Loss=5.1537, Acc=0.391, 
2025-09-28 21:20:19,714 - training.trainer - INFO - Epoch 39/100 completed in 258.09s - Train Loss: 5.3201, Train Acc: 0.308, Val Loss: 5.6746, Val Acc: 0.258
2025-09-28 21:20:27,512 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.1057, Acc=0.368, 
2025-09-28 21:20:34,923 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.2044, Acc=0.345, 
2025-09-28 21:20:42,367 - training.trainer - INFO - Epoch 39, Step 132236: Loss=4.1956, Acc=0.448, 
2025-09-28 21:20:49,820 - training.trainer - INFO - Epoch 39, Step 132336: Loss=3.8195, Acc=0.630, 
2025-09-28 21:20:57,257 - training.trainer - INFO - Epoch 39, Step 132436: Loss=5.7184, Acc=0.333, 
2025-09-28 21:21:04,754 - training.trainer - INFO - Epoch 39, Step 132536: Loss=5.0500, Acc=0.316, 
2025-09-28 21:21:12,197 - training.trainer - INFO - Epoch 39, Step 132636: Loss=4.3831, Acc=0.424, 
2025-09-28 21:21:19,621 - training.trainer - INFO - Epoch 39, Step 132736: Loss=5.4579, Acc=0.349, 
2025-09-28 21:21:27,056 - training.trainer - INFO - Epoch 39, Step 132836: Loss=5.7746, Acc=0.208, 
2025-09-28 21:21:34,460 - training.trainer - INFO - Epoch 39, Step 132936: Loss=3.2764, Acc=0.556, 
2025-09-28 21:21:41,744 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.4807, Acc=0.268, 
2025-09-28 21:21:49,042 - training.trainer - INFO - Epoch 39, Step 133136: Loss=5.5337, Acc=0.250, 
2025-09-28 21:21:56,401 - training.trainer - INFO - Epoch 39, Step 133236: Loss=4.9838, Acc=0.350, 
2025-09-28 21:22:04,005 - training.trainer - INFO - Epoch 39, Step 133336: Loss=5.9366, Acc=0.296, 
2025-09-28 21:22:11,477 - training.trainer - INFO - Epoch 39, Step 133436: Loss=6.2241, Acc=0.281, 
2025-09-28 21:22:18,855 - training.trainer - INFO - Epoch 39, Step 133536: Loss=6.0514, Acc=0.290, 
2025-09-28 21:22:26,256 - training.trainer - INFO - Epoch 39, Step 133636: Loss=5.4167, Acc=0.227, 
2025-09-28 21:22:33,751 - training.trainer - INFO - Epoch 39, Step 133736: Loss=5.7188, Acc=0.314, 
2025-09-28 21:22:41,323 - training.trainer - INFO - Epoch 39, Step 133836: Loss=4.3244, Acc=0.440, 
2025-09-28 21:22:48,761 - training.trainer - INFO - Epoch 39, Step 133936: Loss=5.7484, Acc=0.300, 
2025-09-28 21:22:56,334 - training.trainer - INFO - Epoch 39, Step 134036: Loss=5.2980, Acc=0.194, 
2025-09-28 21:23:03,829 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.5161, Acc=0.343, 
2025-09-28 21:23:11,231 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.0949, Acc=0.370, 
2025-09-28 21:23:18,768 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.5467, Acc=0.161, 
2025-09-28 21:23:26,094 - training.trainer - INFO - Epoch 39, Step 134436: Loss=4.3350, Acc=0.387, 
2025-09-28 21:23:33,438 - training.trainer - INFO - Epoch 39, Step 134536: Loss=6.3543, Acc=0.179, 
2025-09-28 21:23:40,776 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.0850, Acc=0.356, 
2025-09-28 21:23:48,136 - training.trainer - INFO - Epoch 39, Step 134736: Loss=6.1546, Acc=0.262, 
2025-09-28 21:23:55,339 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.2057, Acc=0.294, 
2025-09-28 21:24:02,471 - training.trainer - INFO - Epoch 39, Step 134936: Loss=3.9891, Acc=0.480, 
2025-09-28 21:24:09,817 - training.trainer - INFO - Epoch 39, Step 135036: Loss=5.1436, Acc=0.217, 
2025-09-28 21:24:17,496 - training.trainer - INFO - Epoch 39, Step 135136: Loss=5.8310, Acc=0.250, 
2025-09-28 21:24:24,986 - training.trainer - INFO - Epoch 39, Step 135236: Loss=4.6598, Acc=0.333, 
2025-09-28 21:24:43,608 - training.trainer - INFO - Epoch 40/100 completed in 263.89s - Train Loss: 5.2999, Train Acc: 0.312, Val Loss: 5.6706, Val Acc: 0.257
2025-09-28 21:24:43,913 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-09-28 21:24:51,387 - training.trainer - INFO - Epoch 40, Step 135419: Loss=6.1368, Acc=0.205, 
2025-09-28 21:24:58,759 - training.trainer - INFO - Epoch 40, Step 135519: Loss=5.6729, Acc=0.273, 
2025-09-28 21:25:06,107 - training.trainer - INFO - Epoch 40, Step 135619: Loss=4.9501, Acc=0.375, 
2025-09-28 21:25:13,519 - training.trainer - INFO - Epoch 40, Step 135719: Loss=5.2843, Acc=0.368, 
2025-09-28 21:25:21,290 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.3492, Acc=0.343, 
2025-09-28 21:25:28,642 - training.trainer - INFO - Epoch 40, Step 135919: Loss=5.4854, Acc=0.279, 
2025-09-28 21:25:36,060 - training.trainer - INFO - Epoch 40, Step 136019: Loss=5.9735, Acc=0.242, 
2025-09-28 21:25:43,404 - training.trainer - INFO - Epoch 40, Step 136119: Loss=3.1620, Acc=0.650, 
2025-09-28 21:25:50,960 - training.trainer - INFO - Epoch 40, Step 136219: Loss=5.6625, Acc=0.243, 
2025-09-28 21:25:58,542 - training.trainer - INFO - Epoch 40, Step 136319: Loss=4.9713, Acc=0.419, 
2025-09-28 21:26:06,248 - training.trainer - INFO - Epoch 40, Step 136419: Loss=6.1274, Acc=0.198, 
2025-09-28 21:26:13,693 - training.trainer - INFO - Epoch 40, Step 136519: Loss=4.9903, Acc=0.436, 
2025-09-28 21:26:21,171 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.5911, Acc=0.275, 
2025-09-28 21:26:28,714 - training.trainer - INFO - Epoch 40, Step 136719: Loss=5.5939, Acc=0.226, 
2025-09-28 21:26:36,273 - training.trainer - INFO - Epoch 40, Step 136819: Loss=5.2140, Acc=0.244, 
2025-09-28 21:26:43,819 - training.trainer - INFO - Epoch 40, Step 136919: Loss=5.8151, Acc=0.216, 
2025-09-28 21:26:51,351 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.4377, Acc=0.300, 
2025-09-28 21:26:58,771 - training.trainer - INFO - Epoch 40, Step 137119: Loss=5.4216, Acc=0.255, 
2025-09-28 21:27:06,214 - training.trainer - INFO - Epoch 40, Step 137219: Loss=5.7621, Acc=0.262, 
2025-09-28 21:27:13,896 - training.trainer - INFO - Epoch 40, Step 137319: Loss=4.1749, Acc=0.462, 
2025-09-28 21:27:21,325 - training.trainer - INFO - Epoch 40, Step 137419: Loss=5.2925, Acc=0.327, 
2025-09-28 21:27:28,941 - training.trainer - INFO - Epoch 40, Step 137519: Loss=5.1050, Acc=0.321, 
2025-09-28 21:27:36,434 - training.trainer - INFO - Epoch 40, Step 137619: Loss=5.8085, Acc=0.241, 
2025-09-28 21:27:43,735 - training.trainer - INFO - Epoch 40, Step 137719: Loss=5.7542, Acc=0.268, 
2025-09-28 21:27:51,058 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.2935, Acc=0.391, 
2025-09-28 21:27:58,565 - training.trainer - INFO - Epoch 40, Step 137919: Loss=4.8646, Acc=0.304, 
2025-09-28 21:28:06,082 - training.trainer - INFO - Epoch 40, Step 138019: Loss=3.5340, Acc=0.568, 
2025-09-28 21:28:13,515 - training.trainer - INFO - Epoch 40, Step 138119: Loss=4.9733, Acc=0.476, 
2025-09-28 21:28:21,094 - training.trainer - INFO - Epoch 40, Step 138219: Loss=4.6405, Acc=0.375, 
2025-09-28 21:28:28,603 - training.trainer - INFO - Epoch 40, Step 138319: Loss=3.7109, Acc=0.444, 
2025-09-28 21:28:36,164 - training.trainer - INFO - Epoch 40, Step 138419: Loss=4.8117, Acc=0.391, 
2025-09-28 21:28:43,647 - training.trainer - INFO - Epoch 40, Step 138519: Loss=5.8239, Acc=0.208, 
2025-09-28 21:28:51,225 - training.trainer - INFO - Epoch 40, Step 138619: Loss=5.6126, Acc=0.333, 
2025-09-28 21:29:10,289 - training.trainer - INFO - Epoch 41/100 completed in 266.38s - Train Loss: 5.2835, Train Acc: 0.313, Val Loss: 5.6728, Val Acc: 0.259
2025-09-28 21:29:18,115 - training.trainer - INFO - Epoch 41, Step 138802: Loss=5.1606, Acc=0.262, 
2025-09-28 21:29:25,702 - training.trainer - INFO - Epoch 41, Step 138902: Loss=5.9553, Acc=0.233, 
2025-09-28 21:29:33,128 - training.trainer - INFO - Epoch 41, Step 139002: Loss=5.8895, Acc=0.156, 
2025-09-28 21:29:40,724 - training.trainer - INFO - Epoch 41, Step 139102: Loss=5.2349, Acc=0.302, 
2025-09-28 21:29:48,125 - training.trainer - INFO - Epoch 41, Step 139202: Loss=5.9472, Acc=0.328, 
2025-09-28 21:29:55,496 - training.trainer - INFO - Epoch 41, Step 139302: Loss=5.7157, Acc=0.283, 
2025-09-28 21:30:02,890 - training.trainer - INFO - Epoch 41, Step 139402: Loss=4.4394, Acc=0.333, 
2025-09-28 21:30:10,352 - training.trainer - INFO - Epoch 41, Step 139502: Loss=5.2572, Acc=0.263, 
2025-09-28 21:30:17,772 - training.trainer - INFO - Epoch 41, Step 139602: Loss=5.8589, Acc=0.389, 
2025-09-28 21:30:25,146 - training.trainer - INFO - Epoch 41, Step 139702: Loss=4.4708, Acc=0.467, 
2025-09-28 21:30:32,576 - training.trainer - INFO - Epoch 41, Step 139802: Loss=6.1439, Acc=0.214, 
2025-09-28 21:30:39,952 - training.trainer - INFO - Epoch 41, Step 139902: Loss=5.8198, Acc=0.235, 
2025-09-28 21:30:47,415 - training.trainer - INFO - Epoch 41, Step 140002: Loss=5.3258, Acc=0.279, 
2025-09-28 21:30:54,801 - training.trainer - INFO - Epoch 41, Step 140102: Loss=5.3179, Acc=0.382, 
2025-09-28 21:31:02,106 - training.trainer - INFO - Epoch 41, Step 140202: Loss=4.3090, Acc=0.444, 
2025-09-28 21:31:09,574 - training.trainer - INFO - Epoch 41, Step 140302: Loss=5.6303, Acc=0.243, 
2025-09-28 21:31:17,146 - training.trainer - INFO - Epoch 41, Step 140402: Loss=5.2438, Acc=0.310, 
2025-09-28 21:31:24,576 - training.trainer - INFO - Epoch 41, Step 140502: Loss=5.5609, Acc=0.311, 
2025-09-28 21:31:32,074 - training.trainer - INFO - Epoch 41, Step 140602: Loss=5.4951, Acc=0.302, 
2025-09-28 21:31:39,489 - training.trainer - INFO - Epoch 41, Step 140702: Loss=5.6122, Acc=0.229, 
2025-09-28 21:31:46,905 - training.trainer - INFO - Epoch 41, Step 140802: Loss=4.3780, Acc=0.323, 
2025-09-28 21:31:54,570 - training.trainer - INFO - Epoch 41, Step 140902: Loss=6.0008, Acc=0.219, 
2025-09-28 21:32:02,268 - training.trainer - INFO - Epoch 41, Step 141002: Loss=6.1801, Acc=0.326, 
2025-09-28 21:32:09,680 - training.trainer - INFO - Epoch 41, Step 141102: Loss=5.3513, Acc=0.238, 
2025-09-28 21:32:16,961 - training.trainer - INFO - Epoch 41, Step 141202: Loss=5.6339, Acc=0.276, 
2025-09-28 21:32:24,380 - training.trainer - INFO - Epoch 41, Step 141302: Loss=5.9684, Acc=0.257, 
2025-09-28 21:32:31,794 - training.trainer - INFO - Epoch 41, Step 141402: Loss=3.9922, Acc=0.477, 
2025-09-28 21:32:39,082 - training.trainer - INFO - Epoch 41, Step 141502: Loss=5.5789, Acc=0.218, 
2025-09-28 21:32:46,450 - training.trainer - INFO - Epoch 41, Step 141602: Loss=5.6746, Acc=0.308, 
2025-09-28 21:32:53,951 - training.trainer - INFO - Epoch 41, Step 141702: Loss=5.5725, Acc=0.345, 
2025-09-28 21:33:01,412 - training.trainer - INFO - Epoch 41, Step 141802: Loss=5.8461, Acc=0.213, 
2025-09-28 21:33:08,963 - training.trainer - INFO - Epoch 41, Step 141902: Loss=3.9306, Acc=0.526, 
2025-09-28 21:33:16,505 - training.trainer - INFO - Epoch 41, Step 142002: Loss=5.8634, Acc=0.152, 
2025-09-28 21:33:35,202 - training.trainer - INFO - Epoch 42/100 completed in 264.91s - Train Loss: 5.2668, Train Acc: 0.317, Val Loss: 5.6588, Val Acc: 0.260
2025-09-28 21:33:42,922 - training.trainer - INFO - Epoch 42, Step 142185: Loss=4.5001, Acc=0.478, 
2025-09-28 21:33:50,619 - training.trainer - INFO - Epoch 42, Step 142285: Loss=5.1391, Acc=0.400, 
2025-09-28 21:33:57,987 - training.trainer - INFO - Epoch 42, Step 142385: Loss=5.5116, Acc=0.356, 
2025-09-28 21:34:05,522 - training.trainer - INFO - Epoch 42, Step 142485: Loss=5.8178, Acc=0.188, 
2025-09-28 21:34:12,932 - training.trainer - INFO - Epoch 42, Step 142585: Loss=5.5325, Acc=0.296, 
2025-09-28 21:34:20,256 - training.trainer - INFO - Epoch 42, Step 142685: Loss=5.6218, Acc=0.160, 
2025-09-28 21:34:27,575 - training.trainer - INFO - Epoch 42, Step 142785: Loss=4.8516, Acc=0.450, 
2025-09-28 21:34:34,947 - training.trainer - INFO - Epoch 42, Step 142885: Loss=5.9480, Acc=0.255, 
2025-09-28 21:34:42,304 - training.trainer - INFO - Epoch 42, Step 142985: Loss=4.3845, Acc=0.474, 
2025-09-28 21:34:49,710 - training.trainer - INFO - Epoch 42, Step 143085: Loss=5.7268, Acc=0.333, 
2025-09-28 21:34:57,085 - training.trainer - INFO - Epoch 42, Step 143185: Loss=5.1476, Acc=0.368, 
2025-09-28 21:35:04,525 - training.trainer - INFO - Epoch 42, Step 143285: Loss=5.8567, Acc=0.200, 
2025-09-28 21:35:11,856 - training.trainer - INFO - Epoch 42, Step 143385: Loss=5.7059, Acc=0.244, 
2025-09-28 21:35:19,433 - training.trainer - INFO - Epoch 42, Step 143485: Loss=3.8802, Acc=0.520, 
2025-09-28 21:35:26,874 - training.trainer - INFO - Epoch 42, Step 143585: Loss=5.0587, Acc=0.385, 
2025-09-28 21:35:34,358 - training.trainer - INFO - Epoch 42, Step 143685: Loss=5.1348, Acc=0.333, 
2025-09-28 21:35:41,821 - training.trainer - INFO - Epoch 42, Step 143785: Loss=5.9784, Acc=0.204, 
2025-09-28 21:35:49,385 - training.trainer - INFO - Epoch 42, Step 143885: Loss=5.8013, Acc=0.200, 
2025-09-28 21:35:57,022 - training.trainer - INFO - Epoch 42, Step 143985: Loss=4.2507, Acc=0.368, 
2025-09-28 21:36:04,530 - training.trainer - INFO - Epoch 42, Step 144085: Loss=4.8222, Acc=0.383, 
2025-09-28 21:36:12,050 - training.trainer - INFO - Epoch 42, Step 144185: Loss=4.3318, Acc=0.476, 
2025-09-28 21:36:19,498 - training.trainer - INFO - Epoch 42, Step 144285: Loss=4.5392, Acc=0.400, 
2025-09-28 21:36:26,915 - training.trainer - INFO - Epoch 42, Step 144385: Loss=5.2587, Acc=0.280, 
2025-09-28 21:36:34,328 - training.trainer - INFO - Epoch 42, Step 144485: Loss=5.9500, Acc=0.233, 
2025-09-28 21:36:41,737 - training.trainer - INFO - Epoch 42, Step 144585: Loss=3.9249, Acc=0.583, 
2025-09-28 21:36:49,244 - training.trainer - INFO - Epoch 42, Step 144685: Loss=5.0339, Acc=0.302, 
2025-09-28 21:36:56,577 - training.trainer - INFO - Epoch 42, Step 144785: Loss=4.8203, Acc=0.368, 
2025-09-28 21:37:03,945 - training.trainer - INFO - Epoch 42, Step 144885: Loss=4.3183, Acc=0.500, 
2025-09-28 21:37:11,364 - training.trainer - INFO - Epoch 42, Step 144985: Loss=4.8354, Acc=0.402, 
2025-09-28 21:37:18,724 - training.trainer - INFO - Epoch 42, Step 145085: Loss=4.5904, Acc=0.241, 
2025-09-28 21:37:26,062 - training.trainer - INFO - Epoch 42, Step 145185: Loss=5.5690, Acc=0.261, 
2025-09-28 21:37:33,537 - training.trainer - INFO - Epoch 42, Step 145285: Loss=4.3474, Acc=0.500, 
2025-09-28 21:37:40,902 - training.trainer - INFO - Epoch 42, Step 145385: Loss=4.8419, Acc=0.375, 
2025-09-28 21:37:59,249 - training.trainer - INFO - Epoch 43/100 completed in 264.05s - Train Loss: 5.2576, Train Acc: 0.318, Val Loss: 5.6703, Val Acc: 0.263
2025-09-28 21:38:06,872 - training.trainer - INFO - Epoch 43, Step 145568: Loss=5.5368, Acc=0.244, 
2025-09-28 21:38:14,590 - training.trainer - INFO - Epoch 43, Step 145668: Loss=4.7456, Acc=0.397, 
2025-09-28 21:38:22,142 - training.trainer - INFO - Epoch 43, Step 145768: Loss=5.5447, Acc=0.295, 
2025-09-28 21:38:29,631 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.2297, Acc=0.293, 
2025-09-28 21:38:37,053 - training.trainer - INFO - Epoch 43, Step 145968: Loss=5.5363, Acc=0.280, 
2025-09-28 21:38:44,480 - training.trainer - INFO - Epoch 43, Step 146068: Loss=5.2526, Acc=0.300, 
2025-09-28 21:38:51,814 - training.trainer - INFO - Epoch 43, Step 146168: Loss=5.8563, Acc=0.275, 
2025-09-28 21:38:59,226 - training.trainer - INFO - Epoch 43, Step 146268: Loss=3.5856, Acc=0.560, 
2025-09-28 21:39:06,577 - training.trainer - INFO - Epoch 43, Step 146368: Loss=4.9867, Acc=0.325, 
2025-09-28 21:39:13,934 - training.trainer - INFO - Epoch 43, Step 146468: Loss=5.5396, Acc=0.250, 
2025-09-28 21:39:21,352 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.6141, Acc=0.302, 
2025-09-28 21:39:28,853 - training.trainer - INFO - Epoch 43, Step 146668: Loss=4.9405, Acc=0.328, 
2025-09-28 21:39:36,319 - training.trainer - INFO - Epoch 43, Step 146768: Loss=5.1356, Acc=0.265, 
2025-09-28 21:39:43,660 - training.trainer - INFO - Epoch 43, Step 146868: Loss=5.6238, Acc=0.283, 
2025-09-28 21:39:50,950 - training.trainer - INFO - Epoch 43, Step 146968: Loss=5.3818, Acc=0.300, 
2025-09-28 21:39:58,199 - training.trainer - INFO - Epoch 43, Step 147068: Loss=4.9606, Acc=0.500, 
2025-09-28 21:40:05,569 - training.trainer - INFO - Epoch 43, Step 147168: Loss=5.6913, Acc=0.286, 
2025-09-28 21:40:13,106 - training.trainer - INFO - Epoch 43, Step 147268: Loss=6.1256, Acc=0.238, 
2025-09-28 21:40:20,601 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.6491, Acc=0.229, 
2025-09-28 21:40:28,108 - training.trainer - INFO - Epoch 43, Step 147468: Loss=5.3872, Acc=0.244, 
2025-09-28 21:40:35,903 - training.trainer - INFO - Epoch 43, Step 147568: Loss=4.0140, Acc=0.522, 
2025-09-28 21:40:43,403 - training.trainer - INFO - Epoch 43, Step 147668: Loss=5.5878, Acc=0.283, 
2025-09-28 21:40:50,752 - training.trainer - INFO - Epoch 43, Step 147768: Loss=5.5052, Acc=0.286, 
2025-09-28 21:40:58,085 - training.trainer - INFO - Epoch 43, Step 147868: Loss=5.3012, Acc=0.250, 
2025-09-28 21:41:05,562 - training.trainer - INFO - Epoch 43, Step 147968: Loss=4.9324, Acc=0.307, 
2025-09-28 21:41:13,040 - training.trainer - INFO - Epoch 43, Step 148068: Loss=4.9154, Acc=0.323, 
2025-09-28 21:41:20,489 - training.trainer - INFO - Epoch 43, Step 148168: Loss=5.0373, Acc=0.355, 
2025-09-28 21:41:27,898 - training.trainer - INFO - Epoch 43, Step 148268: Loss=5.3699, Acc=0.286, 
2025-09-28 21:41:35,212 - training.trainer - INFO - Epoch 43, Step 148368: Loss=5.5546, Acc=0.296, 
2025-09-28 21:41:42,584 - training.trainer - INFO - Epoch 43, Step 148468: Loss=5.7659, Acc=0.260, 
2025-09-28 21:41:50,009 - training.trainer - INFO - Epoch 43, Step 148568: Loss=5.7908, Acc=0.333, 
2025-09-28 21:41:57,472 - training.trainer - INFO - Epoch 43, Step 148668: Loss=4.6646, Acc=0.308, 
2025-09-28 21:42:04,947 - training.trainer - INFO - Epoch 43, Step 148768: Loss=4.5196, Acc=0.318, 
2025-09-28 21:42:24,045 - training.trainer - INFO - Epoch 44/100 completed in 264.80s - Train Loss: 5.2458, Train Acc: 0.320, Val Loss: 5.6924, Val Acc: 0.259
2025-09-28 21:42:31,975 - training.trainer - INFO - Epoch 44, Step 148951: Loss=4.5466, Acc=0.365, 
2025-09-28 21:42:39,635 - training.trainer - INFO - Epoch 44, Step 149051: Loss=6.0147, Acc=0.243, 
2025-09-28 21:42:47,051 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.5897, Acc=0.250, 
2025-09-28 21:42:54,381 - training.trainer - INFO - Epoch 44, Step 149251: Loss=6.7256, Acc=0.147, 
2025-09-28 21:43:01,885 - training.trainer - INFO - Epoch 44, Step 149351: Loss=5.7582, Acc=0.283, 
2025-09-28 21:43:09,227 - training.trainer - INFO - Epoch 44, Step 149451: Loss=5.3552, Acc=0.321, 
2025-09-28 21:43:16,638 - training.trainer - INFO - Epoch 44, Step 149551: Loss=6.0458, Acc=0.235, 
2025-09-28 21:43:24,013 - training.trainer - INFO - Epoch 44, Step 149651: Loss=6.0069, Acc=0.290, 
2025-09-28 21:43:31,460 - training.trainer - INFO - Epoch 44, Step 149751: Loss=5.1137, Acc=0.387, 
2025-09-28 21:43:38,893 - training.trainer - INFO - Epoch 44, Step 149851: Loss=5.7205, Acc=0.320, 
2025-09-28 21:43:46,361 - training.trainer - INFO - Epoch 44, Step 149951: Loss=5.2150, Acc=0.395, 
2025-09-28 21:43:53,862 - training.trainer - INFO - Epoch 44, Step 150051: Loss=5.9605, Acc=0.316, 
2025-09-28 21:44:01,234 - training.trainer - INFO - Epoch 44, Step 150151: Loss=4.4291, Acc=0.500, 
2025-09-28 21:44:08,681 - training.trainer - INFO - Epoch 44, Step 150251: Loss=4.0606, Acc=0.318, 
2025-09-28 21:44:16,017 - training.trainer - INFO - Epoch 44, Step 150351: Loss=4.7759, Acc=0.415, 
2025-09-28 21:44:23,429 - training.trainer - INFO - Epoch 44, Step 150451: Loss=4.5472, Acc=0.455, 
2025-09-28 21:44:30,962 - training.trainer - INFO - Epoch 44, Step 150551: Loss=5.9000, Acc=0.259, 
2025-09-28 21:44:38,735 - training.trainer - INFO - Epoch 44, Step 150651: Loss=5.0248, Acc=0.353, 
2025-09-28 21:44:46,391 - training.trainer - INFO - Epoch 44, Step 150751: Loss=2.9185, Acc=0.636, 
2025-09-28 21:44:53,992 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.6548, Acc=0.306, 
2025-09-28 21:45:01,524 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.3516, Acc=0.314, 
2025-09-28 21:45:08,980 - training.trainer - INFO - Epoch 44, Step 151051: Loss=4.1399, Acc=0.594, 
2025-09-28 21:45:16,446 - training.trainer - INFO - Epoch 44, Step 151151: Loss=4.5882, Acc=0.400, 
2025-09-28 21:45:23,872 - training.trainer - INFO - Epoch 44, Step 151251: Loss=5.6677, Acc=0.239, 
2025-09-28 21:45:31,363 - training.trainer - INFO - Epoch 44, Step 151351: Loss=5.6209, Acc=0.217, 
2025-09-28 21:45:38,732 - training.trainer - INFO - Epoch 44, Step 151451: Loss=5.5948, Acc=0.273, 
2025-09-28 21:45:46,093 - training.trainer - INFO - Epoch 44, Step 151551: Loss=4.8032, Acc=0.351, 
2025-09-28 21:45:53,552 - training.trainer - INFO - Epoch 44, Step 151651: Loss=4.6556, Acc=0.364, 
2025-09-28 21:46:00,950 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.1443, Acc=0.206, 
2025-09-28 21:46:08,275 - training.trainer - INFO - Epoch 44, Step 151851: Loss=6.3951, Acc=0.231, 
2025-09-28 21:46:15,628 - training.trainer - INFO - Epoch 44, Step 151951: Loss=2.7305, Acc=0.686, 
2025-09-28 21:46:23,003 - training.trainer - INFO - Epoch 44, Step 152051: Loss=3.0736, Acc=0.611, 
2025-09-28 21:46:30,393 - training.trainer - INFO - Epoch 44, Step 152151: Loss=6.0806, Acc=0.186, 
2025-09-28 21:46:49,074 - training.trainer - INFO - Epoch 45/100 completed in 265.03s - Train Loss: 5.2246, Train Acc: 0.324, Val Loss: 5.6812, Val Acc: 0.261
2025-09-28 21:46:49,404 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-09-28 21:46:55,975 - training.trainer - INFO - Epoch 45, Step 152334: Loss=5.3834, Acc=0.280, 
2025-09-28 21:47:02,182 - training.trainer - INFO - Epoch 45, Step 152434: Loss=5.9168, Acc=0.229, 
2025-09-28 21:47:08,495 - training.trainer - INFO - Epoch 45, Step 152534: Loss=4.9001, Acc=0.400, 
2025-09-28 21:47:14,742 - training.trainer - INFO - Epoch 45, Step 152634: Loss=5.5835, Acc=0.238, 
2025-09-28 21:47:21,005 - training.trainer - INFO - Epoch 45, Step 152734: Loss=5.8214, Acc=0.258, 
2025-09-28 21:47:27,200 - training.trainer - INFO - Epoch 45, Step 152834: Loss=5.4777, Acc=0.324, 
2025-09-28 21:47:33,671 - training.trainer - INFO - Epoch 45, Step 152934: Loss=6.1531, Acc=0.237, 
2025-09-28 21:47:39,948 - training.trainer - INFO - Epoch 45, Step 153034: Loss=5.2827, Acc=0.182, 
2025-09-28 21:47:46,773 - training.trainer - INFO - Epoch 45, Step 153134: Loss=5.6696, Acc=0.220, 
2025-09-28 21:47:53,605 - training.trainer - INFO - Epoch 45, Step 153234: Loss=6.3097, Acc=0.190, 
2025-09-28 21:47:59,813 - training.trainer - INFO - Epoch 45, Step 153334: Loss=6.4052, Acc=0.164, 
2025-09-28 21:48:06,507 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.5994, Acc=0.265, 
2025-09-28 21:48:13,717 - training.trainer - INFO - Epoch 45, Step 153534: Loss=2.8096, Acc=0.667, 
2025-09-28 21:48:21,091 - training.trainer - INFO - Epoch 45, Step 153634: Loss=3.3536, Acc=0.600, 
2025-09-28 21:48:28,533 - training.trainer - INFO - Epoch 45, Step 153734: Loss=5.7928, Acc=0.207, 
2025-09-28 21:48:36,073 - training.trainer - INFO - Epoch 45, Step 153834: Loss=5.6190, Acc=0.189, 
2025-09-28 21:48:43,467 - training.trainer - INFO - Epoch 45, Step 153934: Loss=5.0654, Acc=0.286, 
2025-09-28 21:48:50,761 - training.trainer - INFO - Epoch 45, Step 154034: Loss=6.0281, Acc=0.195, 
2025-09-28 21:48:58,165 - training.trainer - INFO - Epoch 45, Step 154134: Loss=5.5944, Acc=0.192, 
2025-09-28 21:49:05,538 - training.trainer - INFO - Epoch 45, Step 154234: Loss=6.1536, Acc=0.250, 
2025-09-28 21:49:13,225 - training.trainer - INFO - Epoch 45, Step 154334: Loss=3.6506, Acc=0.333, 
2025-09-28 21:49:20,685 - training.trainer - INFO - Epoch 45, Step 154434: Loss=5.6248, Acc=0.286, 
2025-09-28 21:49:28,020 - training.trainer - INFO - Epoch 45, Step 154534: Loss=6.3117, Acc=0.178, 
2025-09-28 21:49:35,352 - training.trainer - INFO - Epoch 45, Step 154634: Loss=5.5780, Acc=0.310, 
2025-09-28 21:49:42,700 - training.trainer - INFO - Epoch 45, Step 154734: Loss=4.5566, Acc=0.333, 
2025-09-28 21:49:50,209 - training.trainer - INFO - Epoch 45, Step 154834: Loss=4.5423, Acc=0.393, 
2025-09-28 21:49:57,563 - training.trainer - INFO - Epoch 45, Step 154934: Loss=5.5531, Acc=0.239, 
2025-09-28 21:50:04,936 - training.trainer - INFO - Epoch 45, Step 155034: Loss=4.3764, Acc=0.304, 
2025-09-28 21:50:12,310 - training.trainer - INFO - Epoch 45, Step 155134: Loss=4.3517, Acc=0.440, 
2025-09-28 21:50:19,712 - training.trainer - INFO - Epoch 45, Step 155234: Loss=3.7687, Acc=0.588, 
2025-09-28 21:50:27,139 - training.trainer - INFO - Epoch 45, Step 155334: Loss=5.7187, Acc=0.333, 
2025-09-28 21:50:34,486 - training.trainer - INFO - Epoch 45, Step 155434: Loss=5.8407, Acc=0.234, 
2025-09-28 21:50:41,847 - training.trainer - INFO - Epoch 45, Step 155534: Loss=4.9737, Acc=0.391, 
2025-09-28 21:51:00,282 - training.trainer - INFO - Epoch 46/100 completed in 250.88s - Train Loss: 5.2118, Train Acc: 0.326, Val Loss: 5.6884, Val Acc: 0.261
2025-09-28 21:51:07,073 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.0399, Acc=0.250, 
2025-09-28 21:51:13,255 - training.trainer - INFO - Epoch 46, Step 155817: Loss=5.6166, Acc=0.256, 
2025-09-28 21:51:19,596 - training.trainer - INFO - Epoch 46, Step 155917: Loss=4.3629, Acc=0.471, 
2025-09-28 21:51:26,500 - training.trainer - INFO - Epoch 46, Step 156017: Loss=5.3546, Acc=0.400, 
2025-09-28 21:51:32,878 - training.trainer - INFO - Epoch 46, Step 156117: Loss=5.8622, Acc=0.240, 
2025-09-28 21:51:39,286 - training.trainer - INFO - Epoch 46, Step 156217: Loss=5.2833, Acc=0.304, 
2025-09-28 21:51:45,444 - training.trainer - INFO - Epoch 46, Step 156317: Loss=5.4910, Acc=0.295, 
2025-09-28 21:51:51,654 - training.trainer - INFO - Epoch 46, Step 156417: Loss=4.9544, Acc=0.343, 
2025-09-28 21:51:57,888 - training.trainer - INFO - Epoch 46, Step 156517: Loss=5.2761, Acc=0.385, 
2025-09-28 21:52:04,212 - training.trainer - INFO - Epoch 46, Step 156617: Loss=5.4763, Acc=0.214, 
2025-09-28 21:52:10,583 - training.trainer - INFO - Epoch 46, Step 156717: Loss=5.9613, Acc=0.289, 
2025-09-28 21:52:16,913 - training.trainer - INFO - Epoch 46, Step 156817: Loss=4.8617, Acc=0.290, 
2025-09-28 21:52:23,146 - training.trainer - INFO - Epoch 46, Step 156917: Loss=5.0904, Acc=0.317, 
2025-09-28 21:52:29,367 - training.trainer - INFO - Epoch 46, Step 157017: Loss=4.8117, Acc=0.345, 
2025-09-28 21:52:35,682 - training.trainer - INFO - Epoch 46, Step 157117: Loss=5.1931, Acc=0.262, 
2025-09-28 21:52:41,869 - training.trainer - INFO - Epoch 46, Step 157217: Loss=4.0563, Acc=0.538, 
2025-09-28 21:52:48,114 - training.trainer - INFO - Epoch 46, Step 157317: Loss=5.7258, Acc=0.333, 
2025-09-28 21:52:54,306 - training.trainer - INFO - Epoch 46, Step 157417: Loss=4.9193, Acc=0.385, 
2025-09-28 21:53:00,570 - training.trainer - INFO - Epoch 46, Step 157517: Loss=4.4536, Acc=0.522, 
2025-09-28 21:53:06,927 - training.trainer - INFO - Epoch 46, Step 157617: Loss=5.4410, Acc=0.250, 
2025-09-28 21:53:13,159 - training.trainer - INFO - Epoch 46, Step 157717: Loss=5.7702, Acc=0.240, 
2025-09-28 21:53:19,378 - training.trainer - INFO - Epoch 46, Step 157817: Loss=2.6368, Acc=0.842, 
2025-09-28 21:53:25,741 - training.trainer - INFO - Epoch 46, Step 157917: Loss=4.8325, Acc=0.528, 
2025-09-28 21:53:32,026 - training.trainer - INFO - Epoch 46, Step 158017: Loss=5.0671, Acc=0.371, 
2025-09-28 21:53:38,330 - training.trainer - INFO - Epoch 46, Step 158117: Loss=4.1309, Acc=0.375, 
2025-09-28 21:53:44,603 - training.trainer - INFO - Epoch 46, Step 158217: Loss=5.2409, Acc=0.303, 
2025-09-28 21:53:50,861 - training.trainer - INFO - Epoch 46, Step 158317: Loss=5.4171, Acc=0.323, 
2025-09-28 21:53:57,081 - training.trainer - INFO - Epoch 46, Step 158417: Loss=5.1719, Acc=0.327, 
2025-09-28 21:54:03,294 - training.trainer - INFO - Epoch 46, Step 158517: Loss=5.7379, Acc=0.295, 
2025-09-28 21:54:09,562 - training.trainer - INFO - Epoch 46, Step 158617: Loss=6.2332, Acc=0.167, 
2025-09-28 21:54:16,044 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.0775, Acc=0.464, 
2025-09-28 21:54:22,282 - training.trainer - INFO - Epoch 46, Step 158817: Loss=5.8683, Acc=0.265, 
2025-09-28 21:54:28,529 - training.trainer - INFO - Epoch 46, Step 158917: Loss=5.4200, Acc=0.382, 
2025-09-28 21:54:47,352 - training.trainer - INFO - Epoch 47/100 completed in 227.07s - Train Loss: 5.1995, Train Acc: 0.329, Val Loss: 5.6878, Val Acc: 0.260
2025-09-28 21:54:47,358 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-09-28 21:54:47,358 - training.trainer - INFO - Training completed!
2025-09-28 21:54:47,360 - __main__ - INFO - Training completed successfully!
2025-09-28 21:54:47,460 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-09-28 21:54:47,722 - __main__ - INFO - Process completed!
2025-09-28 21:55:01,412 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-09-28 21:55:01,412 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-28 21:55:01,413 - __main__ - INFO - Starting model evaluation
2025-09-28 21:55:02,167 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-29 03:34:31,018 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-09-29 03:34:31,033 - __main__ - INFO - Process completed!
2025-09-29 03:34:37,740 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-09-29 03:34:37,740 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-09-29 03:34:37,740 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-09-29 03:34:38,339 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-09-29 03:34:59,453 - __main__ - INFO - Inference completed successfully!
2025-09-29 03:34:59,464 - __main__ - INFO - Process completed!
2025-10-01 23:21:29,381 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-01 23:21:29,382 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-01 23:21:29,382 - __main__ - INFO - Starting training pipeline
2025-10-01 23:21:29,491 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-01 23:21:29,513 - __main__ - INFO - GPU: NVIDIA A30
2025-10-01 23:21:29,514 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-01 23:21:29,514 - __main__ - INFO - Loading training data...
2025-10-01 23:22:14,198 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-01 23:22:14,199 - __main__ - INFO - Processing train split...
2025-10-01 23:22:14,311 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-01 23:22:14,311 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-01 23:23:10,969 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-01 23:24:04,825 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-01 23:24:50,920 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-01 23:25:35,466 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-01 23:26:19,711 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-01 23:27:03,145 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-01 23:27:36,749 - __main__ - INFO - Processing val split...
2025-10-01 23:27:36,964 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-01 23:27:36,964 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-01 23:28:13,611 - __main__ - INFO - Processing test split...
2025-10-01 23:28:13,809 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-01 23:28:13,809 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-01 23:28:50,877 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-01 23:28:50,878 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-01 23:28:50,894 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-01 23:28:50,894 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-01 23:28:50,894 - __main__ - INFO - Creating model architecture...
2025-10-01 23:28:51,340 - __main__ - INFO - Model created successfully
2025-10-01 23:28:51,341 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-01 23:28:51,341 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-01 23:28:51,341 - __main__ - INFO - Using device: cuda
2025-10-01 23:28:51,341 - __main__ - INFO - Creating trainer...
2025-10-01 23:28:51,341 - __main__ - INFO - Moving model to cuda...
2025-10-01 23:28:51,675 - __main__ - INFO - Model moved to cuda
2025-10-01 23:28:51,675 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-01 23:28:54,140 - __main__ - INFO - Trainer created successfully
2025-10-01 23:28:54,141 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-01 23:28:54,141 - __main__ - INFO - Starting training...
2025-10-01 23:28:54,141 - __main__ - INFO - Training configuration:
2025-10-01 23:28:54,141 - __main__ - INFO -   - Epochs: 250
2025-10-01 23:28:54,141 - __main__ - INFO -   - Batch size: 2
2025-10-01 23:28:54,141 - __main__ - INFO -   - Learning rate: 5e-4
2025-10-01 23:28:54,141 - __main__ - INFO -   - Training samples: 6765
2025-10-01 23:28:54,141 - __main__ - INFO -   - Validation samples: 845
2025-10-01 23:28:54,141 - training.trainer - INFO - Starting training for 250 epochs
2025-10-01 23:28:54,142 - training.trainer - INFO - Model parameters: 16,680,032
2025-10-01 23:28:54,142 - training.trainer - INFO - Training on device: cuda
2025-10-01 23:29:04,933 - training.trainer - INFO - Epoch 0, Step 99: Loss=6.8747, Acc=0.035, 
2025-10-01 23:29:13,368 - training.trainer - INFO - Epoch 0, Step 199: Loss=7.3360, Acc=0.033, 
2025-10-01 23:29:21,769 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.1664, Acc=0.019, 
2025-10-01 23:29:29,831 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.5397, Acc=0.071, 
2025-10-01 23:29:37,851 - training.trainer - INFO - Epoch 0, Step 499: Loss=7.2187, Acc=0.073, 
2025-10-01 23:29:45,823 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.2932, Acc=0.016, 
2025-10-01 23:29:53,551 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.5472, Acc=0.083, 
2025-10-01 23:30:01,459 - training.trainer - INFO - Epoch 0, Step 799: Loss=7.2238, Acc=0.080, 
2025-10-01 23:30:09,262 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.4494, Acc=0.051, 
2025-10-01 23:30:17,276 - training.trainer - INFO - Epoch 0, Step 999: Loss=7.1826, Acc=0.080, 
2025-10-01 23:30:24,926 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.2144, Acc=0.000, 
2025-10-01 23:30:32,593 - training.trainer - INFO - Epoch 0, Step 1199: Loss=7.2755, Acc=0.000, 
2025-10-01 23:30:40,328 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.8406, Acc=0.075, 
2025-10-01 23:30:48,139 - training.trainer - INFO - Epoch 0, Step 1399: Loss=7.0540, Acc=0.200, 
2025-10-01 23:30:55,981 - training.trainer - INFO - Epoch 0, Step 1499: Loss=7.0590, Acc=0.000, 
2025-10-01 23:31:03,896 - training.trainer - INFO - Epoch 0, Step 1599: Loss=7.6854, Acc=0.045, 
2025-10-01 23:31:11,797 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.9072, Acc=0.033, 
2025-10-01 23:31:19,446 - training.trainer - INFO - Epoch 0, Step 1799: Loss=7.0405, Acc=0.125, 
2025-10-01 23:31:27,156 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.6683, Acc=0.030, 
2025-10-01 23:31:34,818 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.9742, Acc=0.071, 
2025-10-01 23:31:42,418 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.8627, Acc=0.043, 
2025-10-01 23:31:50,327 - training.trainer - INFO - Epoch 0, Step 2199: Loss=7.0083, Acc=0.022, 
2025-10-01 23:31:58,064 - training.trainer - INFO - Epoch 0, Step 2299: Loss=7.0291, Acc=0.028, 
2025-10-01 23:32:05,865 - training.trainer - INFO - Epoch 0, Step 2399: Loss=7.2688, Acc=0.048, 
2025-10-01 23:32:13,588 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.9991, Acc=0.065, 
2025-10-01 23:32:21,306 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.2569, Acc=0.111, 
2025-10-01 23:32:29,099 - training.trainer - INFO - Epoch 0, Step 2699: Loss=7.5953, Acc=0.056, 
2025-10-01 23:32:36,671 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.6053, Acc=0.080, 
2025-10-01 23:32:44,073 - training.trainer - INFO - Epoch 0, Step 2899: Loss=7.5431, Acc=0.016, 
2025-10-01 23:32:51,502 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.5151, Acc=0.091, 
2025-10-01 23:32:59,213 - training.trainer - INFO - Epoch 0, Step 3099: Loss=7.0094, Acc=0.080, 
2025-10-01 23:33:06,752 - training.trainer - INFO - Epoch 0, Step 3199: Loss=7.5393, Acc=0.035, 
2025-10-01 23:33:14,347 - training.trainer - INFO - Epoch 0, Step 3299: Loss=7.6258, Acc=0.077, 
2025-10-01 23:33:33,283 - training.trainer - INFO - Epoch 1/250 completed in 279.14s - Train Loss: 6.9669, Train Acc: 0.059, Val Loss: 6.8684, Val Acc: 0.063
2025-10-01 23:33:33,923 - training.trainer - INFO - New best model saved with validation loss: 6.8684
2025-10-01 23:33:33,923 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-01 23:33:40,548 - training.trainer - INFO - Epoch 1, Step 3482: Loss=6.9159, Acc=0.024, 
2025-10-01 23:33:46,759 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.8202, Acc=0.037, 
2025-10-01 23:33:52,914 - training.trainer - INFO - Epoch 1, Step 3682: Loss=5.9938, Acc=0.036, 
2025-10-01 23:33:59,307 - training.trainer - INFO - Epoch 1, Step 3782: Loss=7.0526, Acc=0.018, 
2025-10-01 23:34:07,118 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.8275, Acc=0.016, 
2025-10-01 23:34:14,528 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.5825, Acc=0.023, 
2025-10-01 23:34:21,983 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.0634, Acc=0.095, 
2025-10-01 23:34:29,571 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.3480, Acc=0.051, 
2025-10-01 23:34:37,250 - training.trainer - INFO - Epoch 1, Step 4282: Loss=7.2168, Acc=0.044, 
2025-10-01 23:34:45,331 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.9753, Acc=0.027, 
2025-10-01 23:34:52,960 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.6304, Acc=0.034, 
2025-10-01 23:35:00,532 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.6758, Acc=0.043, 
2025-10-01 23:35:08,189 - training.trainer - INFO - Epoch 1, Step 4682: Loss=7.0725, Acc=0.019, 
2025-10-01 23:35:15,753 - training.trainer - INFO - Epoch 1, Step 4782: Loss=7.7082, Acc=0.022, 
2025-10-01 23:35:23,292 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.9097, Acc=0.130, 
2025-10-01 23:35:30,868 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.4774, Acc=0.071, 
2025-10-01 23:35:38,567 - training.trainer - INFO - Epoch 1, Step 5082: Loss=7.3285, Acc=0.051, 
2025-10-01 23:35:46,161 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.8480, Acc=0.087, 
2025-10-01 23:35:53,670 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.9277, Acc=0.083, 
2025-10-01 23:36:01,310 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.6321, Acc=0.100, 
2025-10-01 23:36:09,238 - training.trainer - INFO - Epoch 1, Step 5482: Loss=7.3474, Acc=0.000, 
2025-10-01 23:36:16,899 - training.trainer - INFO - Epoch 1, Step 5582: Loss=7.3023, Acc=0.057, 
2025-10-01 23:36:24,432 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.9707, Acc=0.042, 
2025-10-01 23:36:31,948 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.5792, Acc=0.059, 
2025-10-01 23:36:39,399 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.8921, Acc=0.026, 
2025-10-01 23:36:47,087 - training.trainer - INFO - Epoch 1, Step 5982: Loss=7.3063, Acc=0.052, 
2025-10-01 23:36:54,633 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.6827, Acc=0.111, 
2025-10-01 23:37:02,246 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.5260, Acc=0.083, 
2025-10-01 23:37:09,687 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.8031, Acc=0.032, 
2025-10-01 23:37:17,303 - training.trainer - INFO - Epoch 1, Step 6382: Loss=6.7614, Acc=0.034, 
2025-10-01 23:37:24,782 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.7995, Acc=0.062, 
2025-10-01 23:37:32,304 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.9363, Acc=0.022, 
2025-10-01 23:37:40,096 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.5436, Acc=0.062, 
2025-10-01 23:37:59,314 - training.trainer - INFO - Epoch 2/250 completed in 265.39s - Train Loss: 6.8730, Train Acc: 0.061, Val Loss: 6.8180, Val Acc: 0.063
2025-10-01 23:37:59,949 - training.trainer - INFO - New best model saved with validation loss: 6.8180
2025-10-01 23:37:59,949 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-01 23:38:08,309 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.1378, Acc=0.188, 
2025-10-01 23:38:15,877 - training.trainer - INFO - Epoch 2, Step 6965: Loss=7.3389, Acc=0.158, 
2025-10-01 23:38:23,390 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.9999, Acc=0.033, 
2025-10-01 23:38:30,825 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.6793, Acc=0.048, 
2025-10-01 23:38:38,272 - training.trainer - INFO - Epoch 2, Step 7265: Loss=5.7529, Acc=0.190, 
2025-10-01 23:38:45,715 - training.trainer - INFO - Epoch 2, Step 7365: Loss=7.5280, Acc=0.111, 
2025-10-01 23:38:53,256 - training.trainer - INFO - Epoch 2, Step 7465: Loss=6.8059, Acc=0.032, 
2025-10-01 23:39:00,766 - training.trainer - INFO - Epoch 2, Step 7565: Loss=7.1411, Acc=0.019, 
2025-10-01 23:39:08,246 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.5128, Acc=0.057, 
2025-10-01 23:39:15,838 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.9230, Acc=0.019, 
2025-10-01 23:39:23,392 - training.trainer - INFO - Epoch 2, Step 7865: Loss=7.5470, Acc=0.048, 
2025-10-01 23:39:31,186 - training.trainer - INFO - Epoch 2, Step 7965: Loss=7.0656, Acc=0.067, 
2025-10-01 23:39:38,616 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.9882, Acc=0.143, 
2025-10-01 23:39:46,067 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.1299, Acc=0.111, 
2025-10-01 23:39:53,705 - training.trainer - INFO - Epoch 2, Step 8265: Loss=7.5223, Acc=0.051, 
2025-10-01 23:40:01,503 - training.trainer - INFO - Epoch 2, Step 8365: Loss=7.3989, Acc=0.029, 
2025-10-01 23:40:09,069 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.8521, Acc=0.143, 
2025-10-01 23:40:16,736 - training.trainer - INFO - Epoch 2, Step 8565: Loss=7.1586, Acc=0.000, 
2025-10-01 23:40:24,433 - training.trainer - INFO - Epoch 2, Step 8665: Loss=7.4421, Acc=0.049, 
2025-10-01 23:40:32,000 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.9632, Acc=0.054, 
2025-10-01 23:40:39,504 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.6917, Acc=0.086, 
2025-10-01 23:40:47,039 - training.trainer - INFO - Epoch 2, Step 8965: Loss=7.4226, Acc=0.045, 
2025-10-01 23:40:54,470 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.0509, Acc=0.105, 
2025-10-01 23:41:01,898 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.6968, Acc=0.081, 
2025-10-01 23:41:09,424 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.3000, Acc=0.091, 
2025-10-01 23:41:17,015 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.8104, Acc=0.037, 
2025-10-01 23:41:24,530 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.8960, Acc=0.012, 
2025-10-01 23:41:32,022 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.7778, Acc=0.133, 
2025-10-01 23:41:39,706 - training.trainer - INFO - Epoch 2, Step 9665: Loss=7.0824, Acc=0.049, 
2025-10-01 23:41:47,334 - training.trainer - INFO - Epoch 2, Step 9765: Loss=7.1461, Acc=0.097, 
2025-10-01 23:41:54,828 - training.trainer - INFO - Epoch 2, Step 9865: Loss=7.1999, Acc=0.069, 
2025-10-01 23:42:02,473 - training.trainer - INFO - Epoch 2, Step 9965: Loss=6.8831, Acc=0.062, 
2025-10-01 23:42:10,086 - training.trainer - INFO - Epoch 2, Step 10065: Loss=6.8426, Acc=0.065, 
2025-10-01 23:42:29,774 - training.trainer - INFO - Epoch 3/250 completed in 269.82s - Train Loss: 6.8510, Train Acc: 0.062, Val Loss: 6.8172, Val Acc: 0.063
2025-10-01 23:42:30,395 - training.trainer - INFO - New best model saved with validation loss: 6.8172
2025-10-01 23:42:30,395 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-10-01 23:42:38,192 - training.trainer - INFO - Epoch 3, Step 10248: Loss=7.3068, Acc=0.086, 
2025-10-01 23:42:45,792 - training.trainer - INFO - Epoch 3, Step 10348: Loss=6.6278, Acc=0.015, 
2025-10-01 23:42:53,410 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.8761, Acc=0.031, 
2025-10-01 23:43:00,939 - training.trainer - INFO - Epoch 3, Step 10548: Loss=7.0740, Acc=0.038, 
2025-10-01 23:43:08,878 - training.trainer - INFO - Epoch 3, Step 10648: Loss=7.0323, Acc=0.053, 
2025-10-01 23:43:16,443 - training.trainer - INFO - Epoch 3, Step 10748: Loss=7.5544, Acc=0.034, 
2025-10-01 23:43:24,232 - training.trainer - INFO - Epoch 3, Step 10848: Loss=7.0221, Acc=0.026, 
2025-10-01 23:43:31,923 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.1571, Acc=0.083, 
2025-10-01 23:43:39,343 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.7692, Acc=0.044, 
2025-10-01 23:43:46,787 - training.trainer - INFO - Epoch 3, Step 11148: Loss=7.2026, Acc=0.045, 
2025-10-01 23:43:54,313 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.5555, Acc=0.062, 
2025-10-01 23:44:01,662 - training.trainer - INFO - Epoch 3, Step 11348: Loss=6.8043, Acc=0.021, 
2025-10-01 23:44:09,260 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.7970, Acc=0.037, 
2025-10-01 23:44:16,730 - training.trainer - INFO - Epoch 3, Step 11548: Loss=7.0136, Acc=0.091, 
2025-10-01 23:44:24,339 - training.trainer - INFO - Epoch 3, Step 11648: Loss=7.2642, Acc=0.043, 
2025-10-01 23:44:32,025 - training.trainer - INFO - Epoch 3, Step 11748: Loss=6.6282, Acc=0.053, 
2025-10-01 23:44:39,878 - training.trainer - INFO - Epoch 3, Step 11848: Loss=6.9338, Acc=0.051, 
2025-10-01 23:44:47,651 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.8075, Acc=0.067, 
2025-10-01 23:44:55,288 - training.trainer - INFO - Epoch 3, Step 12048: Loss=7.3052, Acc=0.087, 
2025-10-01 23:45:03,145 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.7048, Acc=0.056, 
2025-10-01 23:45:10,701 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.6530, Acc=0.054, 
2025-10-01 23:45:18,535 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.9267, Acc=0.029, 
2025-10-01 23:45:26,048 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.2687, Acc=0.051, 
2025-10-01 23:45:33,606 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.9609, Acc=0.034, 
2025-10-01 23:45:40,887 - training.trainer - INFO - Epoch 3, Step 12648: Loss=7.3134, Acc=0.029, 
2025-10-01 23:45:48,235 - training.trainer - INFO - Epoch 3, Step 12748: Loss=7.5581, Acc=0.038, 
2025-10-01 23:45:55,491 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.7510, Acc=0.088, 
2025-10-01 23:46:02,889 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.7890, Acc=0.091, 
2025-10-01 23:46:10,176 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.8732, Acc=0.036, 
2025-10-01 23:46:17,465 - training.trainer - INFO - Epoch 3, Step 13148: Loss=7.3394, Acc=0.043, 
2025-10-01 23:46:25,226 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.7701, Acc=0.038, 
2025-10-01 23:46:32,905 - training.trainer - INFO - Epoch 3, Step 13348: Loss=6.5416, Acc=0.111, 
2025-10-01 23:46:40,403 - training.trainer - INFO - Epoch 3, Step 13448: Loss=7.5439, Acc=0.038, 
2025-10-01 23:46:59,797 - training.trainer - INFO - Epoch 4/250 completed in 269.40s - Train Loss: 6.8414, Train Acc: 0.060, Val Loss: 6.8549, Val Acc: 0.063
2025-10-01 23:47:07,360 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.8469, Acc=0.095, 
2025-10-01 23:47:14,696 - training.trainer - INFO - Epoch 4, Step 13731: Loss=6.4364, Acc=0.095, 
2025-10-01 23:47:21,992 - training.trainer - INFO - Epoch 4, Step 13831: Loss=7.1895, Acc=0.035, 
2025-10-01 23:47:29,338 - training.trainer - INFO - Epoch 4, Step 13931: Loss=7.1457, Acc=0.000, 
2025-10-01 23:47:36,663 - training.trainer - INFO - Epoch 4, Step 14031: Loss=7.3970, Acc=0.045, 
2025-10-01 23:47:44,109 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.5908, Acc=0.067, 
2025-10-01 23:47:51,415 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.6100, Acc=0.057, 
2025-10-01 23:47:58,671 - training.trainer - INFO - Epoch 4, Step 14331: Loss=6.7697, Acc=0.080, 
2025-10-01 23:48:06,082 - training.trainer - INFO - Epoch 4, Step 14431: Loss=6.9940, Acc=0.025, 
2025-10-01 23:48:13,485 - training.trainer - INFO - Epoch 4, Step 14531: Loss=6.7416, Acc=0.111, 
2025-10-01 23:48:21,314 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.7581, Acc=0.062, 
2025-10-01 23:48:28,680 - training.trainer - INFO - Epoch 4, Step 14731: Loss=6.7215, Acc=0.038, 
2025-10-01 23:48:36,211 - training.trainer - INFO - Epoch 4, Step 14831: Loss=6.9163, Acc=0.000, 
2025-10-01 23:48:43,539 - training.trainer - INFO - Epoch 4, Step 14931: Loss=7.1574, Acc=0.042, 
2025-10-01 23:48:51,050 - training.trainer - INFO - Epoch 4, Step 15031: Loss=7.3743, Acc=0.083, 
2025-10-01 23:48:58,666 - training.trainer - INFO - Epoch 4, Step 15131: Loss=6.6188, Acc=0.049, 
2025-10-01 23:49:06,032 - training.trainer - INFO - Epoch 4, Step 15231: Loss=6.7016, Acc=0.091, 
2025-10-01 23:49:13,332 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.3125, Acc=0.100, 
2025-10-01 23:49:20,729 - training.trainer - INFO - Epoch 4, Step 15431: Loss=7.7392, Acc=0.064, 
2025-10-01 23:49:28,003 - training.trainer - INFO - Epoch 4, Step 15531: Loss=6.8562, Acc=0.031, 
2025-10-01 23:49:35,355 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.6593, Acc=0.038, 
2025-10-01 23:49:42,701 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.8061, Acc=0.048, 
2025-10-01 23:49:50,030 - training.trainer - INFO - Epoch 4, Step 15831: Loss=6.3311, Acc=0.029, 
2025-10-01 23:49:57,471 - training.trainer - INFO - Epoch 4, Step 15931: Loss=5.9774, Acc=0.118, 
2025-10-01 23:50:04,838 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.6006, Acc=0.070, 
2025-10-01 23:50:12,171 - training.trainer - INFO - Epoch 4, Step 16131: Loss=7.5316, Acc=0.080, 
2025-10-01 23:50:19,432 - training.trainer - INFO - Epoch 4, Step 16231: Loss=7.2807, Acc=0.013, 
2025-10-01 23:50:26,979 - training.trainer - INFO - Epoch 4, Step 16331: Loss=6.7115, Acc=0.043, 
2025-10-01 23:50:34,242 - training.trainer - INFO - Epoch 4, Step 16431: Loss=7.0451, Acc=0.042, 
2025-10-01 23:50:41,746 - training.trainer - INFO - Epoch 4, Step 16531: Loss=6.4828, Acc=0.083, 
2025-10-01 23:50:49,045 - training.trainer - INFO - Epoch 4, Step 16631: Loss=7.3745, Acc=0.083, 
2025-10-01 23:50:56,423 - training.trainer - INFO - Epoch 4, Step 16731: Loss=7.1956, Acc=0.018, 
2025-10-01 23:51:03,709 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.9294, Acc=0.018, 
2025-10-01 23:51:22,712 - training.trainer - INFO - Epoch 5/250 completed in 262.91s - Train Loss: 6.8292, Train Acc: 0.061, Val Loss: 6.8249, Val Acc: 0.063
2025-10-01 23:51:23,045 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-01 23:51:29,813 - training.trainer - INFO - Epoch 5, Step 17014: Loss=6.7248, Acc=0.043, 
2025-10-01 23:51:35,951 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.8801, Acc=0.023, 
2025-10-01 23:51:42,121 - training.trainer - INFO - Epoch 5, Step 17214: Loss=6.7284, Acc=0.038, 
2025-10-01 23:51:48,563 - training.trainer - INFO - Epoch 5, Step 17314: Loss=6.4207, Acc=0.118, 
2025-10-01 23:51:54,783 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.8707, Acc=0.022, 
2025-10-01 23:52:01,123 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.9800, Acc=0.095, 
2025-10-01 23:52:07,478 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.9991, Acc=0.014, 
2025-10-01 23:52:13,703 - training.trainer - INFO - Epoch 5, Step 17714: Loss=7.4540, Acc=0.067, 
2025-10-01 23:52:19,949 - training.trainer - INFO - Epoch 5, Step 17814: Loss=7.0799, Acc=0.031, 
2025-10-01 23:52:26,312 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.6403, Acc=0.067, 
2025-10-01 23:52:32,501 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.7371, Acc=0.095, 
2025-10-01 23:52:38,822 - training.trainer - INFO - Epoch 5, Step 18114: Loss=7.1210, Acc=0.049, 
2025-10-01 23:52:45,110 - training.trainer - INFO - Epoch 5, Step 18214: Loss=7.0088, Acc=0.036, 
2025-10-01 23:52:51,263 - training.trainer - INFO - Epoch 5, Step 18314: Loss=6.8720, Acc=0.047, 
2025-10-01 23:52:57,475 - training.trainer - INFO - Epoch 5, Step 18414: Loss=6.9337, Acc=0.095, 
2025-10-01 23:53:04,108 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.6577, Acc=0.059, 
2025-10-01 23:53:10,407 - training.trainer - INFO - Epoch 5, Step 18614: Loss=7.1337, Acc=0.014, 
2025-10-01 23:53:16,585 - training.trainer - INFO - Epoch 5, Step 18714: Loss=6.6596, Acc=0.054, 
2025-10-01 23:53:22,883 - training.trainer - INFO - Epoch 5, Step 18814: Loss=6.9722, Acc=0.038, 
2025-10-01 23:53:29,452 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.2900, Acc=0.077, 
2025-10-01 23:53:36,390 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.3423, Acc=0.000, 
2025-10-01 23:53:43,437 - training.trainer - INFO - Epoch 5, Step 19114: Loss=7.0737, Acc=0.032, 
2025-10-01 23:53:50,564 - training.trainer - INFO - Epoch 5, Step 19214: Loss=6.9502, Acc=0.069, 
2025-10-01 23:53:57,881 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.8785, Acc=0.017, 
2025-10-01 23:54:05,186 - training.trainer - INFO - Epoch 5, Step 19414: Loss=6.2878, Acc=0.150, 
2025-10-01 23:54:12,910 - training.trainer - INFO - Epoch 5, Step 19514: Loss=7.2806, Acc=0.000, 
2025-10-01 23:54:20,150 - training.trainer - INFO - Epoch 5, Step 19614: Loss=7.2768, Acc=0.022, 
2025-10-01 23:54:27,377 - training.trainer - INFO - Epoch 5, Step 19714: Loss=7.4298, Acc=0.103, 
2025-10-01 23:54:34,850 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.5950, Acc=0.073, 
2025-10-01 23:54:42,172 - training.trainer - INFO - Epoch 5, Step 19914: Loss=7.0061, Acc=0.014, 
2025-10-01 23:54:49,615 - training.trainer - INFO - Epoch 5, Step 20014: Loss=7.1299, Acc=0.053, 
2025-10-01 23:54:57,128 - training.trainer - INFO - Epoch 5, Step 20114: Loss=6.3131, Acc=0.033, 
2025-10-01 23:55:04,407 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.4478, Acc=0.068, 
2025-10-01 23:55:23,832 - training.trainer - INFO - Epoch 6/250 completed in 240.79s - Train Loss: 6.8287, Train Acc: 0.061, Val Loss: 6.8203, Val Acc: 0.063
2025-10-01 23:55:32,180 - training.trainer - INFO - Epoch 6, Step 20397: Loss=6.6359, Acc=0.031, 
2025-10-01 23:55:39,573 - training.trainer - INFO - Epoch 6, Step 20497: Loss=7.1495, Acc=0.200, 
2025-10-01 23:55:46,888 - training.trainer - INFO - Epoch 6, Step 20597: Loss=7.1279, Acc=0.047, 
2025-10-01 23:55:54,270 - training.trainer - INFO - Epoch 6, Step 20697: Loss=7.3207, Acc=0.033, 
2025-10-01 23:56:01,605 - training.trainer - INFO - Epoch 6, Step 20797: Loss=6.4714, Acc=0.000, 
2025-10-01 23:56:08,975 - training.trainer - INFO - Epoch 6, Step 20897: Loss=6.7054, Acc=0.026, 
2025-10-01 23:56:16,342 - training.trainer - INFO - Epoch 6, Step 20997: Loss=6.5611, Acc=0.125, 
2025-10-01 23:56:23,754 - training.trainer - INFO - Epoch 6, Step 21097: Loss=7.0130, Acc=0.043, 
2025-10-01 23:56:31,046 - training.trainer - INFO - Epoch 6, Step 21197: Loss=6.5318, Acc=0.077, 
2025-10-01 23:56:38,292 - training.trainer - INFO - Epoch 6, Step 21297: Loss=7.1274, Acc=0.095, 
2025-10-01 23:56:45,510 - training.trainer - INFO - Epoch 6, Step 21397: Loss=6.7781, Acc=0.034, 
2025-10-01 23:56:52,725 - training.trainer - INFO - Epoch 6, Step 21497: Loss=7.2807, Acc=0.060, 
2025-10-01 23:57:00,049 - training.trainer - INFO - Epoch 6, Step 21597: Loss=7.2043, Acc=0.038, 
2025-10-01 23:57:07,341 - training.trainer - INFO - Epoch 6, Step 21697: Loss=7.1147, Acc=0.091, 
2025-10-01 23:57:14,874 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.9878, Acc=0.048, 
2025-10-01 23:57:22,190 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.6791, Acc=0.050, 
2025-10-01 23:57:29,708 - training.trainer - INFO - Epoch 6, Step 21997: Loss=6.9040, Acc=0.000, 
2025-10-01 23:57:36,922 - training.trainer - INFO - Epoch 6, Step 22097: Loss=7.1120, Acc=0.000, 
2025-10-01 23:57:44,205 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.6745, Acc=0.053, 
2025-10-01 23:57:51,539 - training.trainer - INFO - Epoch 6, Step 22297: Loss=6.9857, Acc=0.043, 
2025-10-01 23:57:59,036 - training.trainer - INFO - Epoch 6, Step 22397: Loss=6.3379, Acc=0.133, 
2025-10-01 23:58:06,603 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.9355, Acc=0.020, 
2025-10-01 23:58:13,925 - training.trainer - INFO - Epoch 6, Step 22597: Loss=7.2488, Acc=0.027, 
2025-10-01 23:58:21,332 - training.trainer - INFO - Epoch 6, Step 22697: Loss=6.9088, Acc=0.023, 
2025-10-01 23:58:28,806 - training.trainer - INFO - Epoch 6, Step 22797: Loss=6.9163, Acc=0.047, 
2025-10-01 23:58:36,315 - training.trainer - INFO - Epoch 6, Step 22897: Loss=6.2319, Acc=0.056, 
2025-10-01 23:58:43,512 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.4441, Acc=0.042, 
2025-10-01 23:58:50,081 - training.trainer - INFO - Epoch 6, Step 23097: Loss=7.1745, Acc=0.077, 
2025-10-01 23:58:57,706 - training.trainer - INFO - Epoch 6, Step 23197: Loss=7.1410, Acc=0.035, 
2025-10-01 23:59:05,349 - training.trainer - INFO - Epoch 6, Step 23297: Loss=7.0687, Acc=0.091, 
2025-10-01 23:59:13,039 - training.trainer - INFO - Epoch 6, Step 23397: Loss=6.4557, Acc=0.026, 
2025-10-01 23:59:21,204 - training.trainer - INFO - Epoch 6, Step 23497: Loss=6.8139, Acc=0.026, 
2025-10-01 23:59:28,860 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.6276, Acc=0.077, 
2025-10-01 23:59:48,202 - training.trainer - INFO - Epoch 7/250 completed in 264.37s - Train Loss: 6.8310, Train Acc: 0.060, Val Loss: 6.8295, Val Acc: 0.063
2025-10-01 23:59:56,138 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.9124, Acc=0.044, 
2025-10-02 00:00:03,775 - training.trainer - INFO - Epoch 7, Step 23880: Loss=7.0191, Acc=0.053, 
2025-10-02 00:00:11,475 - training.trainer - INFO - Epoch 7, Step 23980: Loss=6.3023, Acc=0.133, 
2025-10-02 00:00:19,252 - training.trainer - INFO - Epoch 7, Step 24080: Loss=7.6931, Acc=0.074, 
2025-10-02 00:00:26,986 - training.trainer - INFO - Epoch 7, Step 24180: Loss=6.7872, Acc=0.048, 
2025-10-02 00:00:34,518 - training.trainer - INFO - Epoch 7, Step 24280: Loss=6.5975, Acc=0.071, 
2025-10-02 00:00:42,203 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.0094, Acc=0.136, 
2025-10-02 00:00:49,895 - training.trainer - INFO - Epoch 7, Step 24480: Loss=7.1033, Acc=0.024, 
2025-10-02 00:00:57,445 - training.trainer - INFO - Epoch 7, Step 24580: Loss=6.2856, Acc=0.111, 
2025-10-02 00:01:04,914 - training.trainer - INFO - Epoch 7, Step 24680: Loss=7.0010, Acc=0.044, 
2025-10-02 00:01:12,900 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.9967, Acc=0.079, 
2025-10-02 00:01:20,754 - training.trainer - INFO - Epoch 7, Step 24880: Loss=7.3307, Acc=0.024, 
2025-10-02 00:01:28,367 - training.trainer - INFO - Epoch 7, Step 24980: Loss=6.3661, Acc=0.125, 
2025-10-02 00:01:35,832 - training.trainer - INFO - Epoch 7, Step 25080: Loss=6.3357, Acc=0.042, 
2025-10-02 00:01:43,183 - training.trainer - INFO - Epoch 7, Step 25180: Loss=7.0508, Acc=0.015, 
2025-10-02 00:01:50,590 - training.trainer - INFO - Epoch 7, Step 25280: Loss=6.4782, Acc=0.158, 
2025-10-02 00:01:58,055 - training.trainer - INFO - Epoch 7, Step 25380: Loss=7.3833, Acc=0.083, 
2025-10-02 00:02:05,616 - training.trainer - INFO - Epoch 7, Step 25480: Loss=6.4543, Acc=0.095, 
2025-10-02 00:02:13,135 - training.trainer - INFO - Epoch 7, Step 25580: Loss=7.3592, Acc=0.056, 
2025-10-02 00:02:20,532 - training.trainer - INFO - Epoch 7, Step 25680: Loss=7.0352, Acc=0.029, 
2025-10-02 00:02:27,802 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.7030, Acc=0.057, 
2025-10-02 00:02:35,079 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.6682, Acc=0.079, 
2025-10-02 00:02:42,494 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.4013, Acc=0.097, 
2025-10-02 00:02:49,803 - training.trainer - INFO - Epoch 7, Step 26080: Loss=7.0796, Acc=0.045, 
2025-10-02 00:02:57,164 - training.trainer - INFO - Epoch 7, Step 26180: Loss=6.9708, Acc=0.071, 
2025-10-02 00:03:04,509 - training.trainer - INFO - Epoch 7, Step 26280: Loss=7.2490, Acc=0.051, 
2025-10-02 00:03:12,017 - training.trainer - INFO - Epoch 7, Step 26380: Loss=6.5873, Acc=0.000, 
2025-10-02 00:03:19,536 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.9593, Acc=0.037, 
2025-10-02 00:03:26,968 - training.trainer - INFO - Epoch 7, Step 26580: Loss=7.4643, Acc=0.022, 
2025-10-02 00:03:34,449 - training.trainer - INFO - Epoch 7, Step 26680: Loss=6.6802, Acc=0.024, 
2025-10-02 00:03:42,022 - training.trainer - INFO - Epoch 7, Step 26780: Loss=6.6309, Acc=0.065, 
2025-10-02 00:03:49,305 - training.trainer - INFO - Epoch 7, Step 26880: Loss=7.0861, Acc=0.045, 
2025-10-02 00:03:56,706 - training.trainer - INFO - Epoch 7, Step 26980: Loss=7.5131, Acc=0.033, 
2025-10-02 00:04:16,343 - training.trainer - INFO - Epoch 8/250 completed in 268.14s - Train Loss: 6.8282, Train Acc: 0.061, Val Loss: 6.8218, Val Acc: 0.063
2025-10-02 00:04:24,478 - training.trainer - INFO - Epoch 8, Step 27163: Loss=6.6610, Acc=0.039, 
2025-10-02 00:04:31,875 - training.trainer - INFO - Epoch 8, Step 27263: Loss=6.2679, Acc=0.059, 
2025-10-02 00:04:39,183 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.8059, Acc=0.133, 
2025-10-02 00:04:46,650 - training.trainer - INFO - Epoch 8, Step 27463: Loss=6.3126, Acc=0.118, 
2025-10-02 00:04:53,884 - training.trainer - INFO - Epoch 8, Step 27563: Loss=6.8051, Acc=0.041, 
2025-10-02 00:05:01,193 - training.trainer - INFO - Epoch 8, Step 27663: Loss=7.3549, Acc=0.024, 
2025-10-02 00:05:08,474 - training.trainer - INFO - Epoch 8, Step 27763: Loss=7.3428, Acc=0.077, 
2025-10-02 00:05:15,848 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.8573, Acc=0.120, 
2025-10-02 00:05:23,202 - training.trainer - INFO - Epoch 8, Step 27963: Loss=5.9183, Acc=0.133, 
2025-10-02 00:05:30,693 - training.trainer - INFO - Epoch 8, Step 28063: Loss=5.6734, Acc=0.167, 
2025-10-02 00:05:38,225 - training.trainer - INFO - Epoch 8, Step 28163: Loss=7.2061, Acc=0.081, 
2025-10-02 00:05:45,813 - training.trainer - INFO - Epoch 8, Step 28263: Loss=7.0432, Acc=0.067, 
2025-10-02 00:05:53,282 - training.trainer - INFO - Epoch 8, Step 28363: Loss=7.0034, Acc=0.056, 
2025-10-02 00:06:00,721 - training.trainer - INFO - Epoch 8, Step 28463: Loss=7.0912, Acc=0.045, 
2025-10-02 00:06:08,268 - training.trainer - INFO - Epoch 8, Step 28563: Loss=7.1464, Acc=0.065, 
2025-10-02 00:06:15,733 - training.trainer - INFO - Epoch 8, Step 28663: Loss=7.4236, Acc=0.079, 
2025-10-02 00:06:23,106 - training.trainer - INFO - Epoch 8, Step 28763: Loss=6.6058, Acc=0.050, 
2025-10-02 00:06:30,340 - training.trainer - INFO - Epoch 8, Step 28863: Loss=6.5277, Acc=0.105, 
2025-10-02 00:06:37,213 - training.trainer - INFO - Epoch 8, Step 28963: Loss=7.0140, Acc=0.036, 
2025-10-02 00:06:43,810 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.5767, Acc=0.022, 
2025-10-02 00:06:51,146 - training.trainer - INFO - Epoch 8, Step 29163: Loss=6.4217, Acc=0.028, 
2025-10-02 00:06:58,449 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.9958, Acc=0.041, 
2025-10-02 00:07:05,736 - training.trainer - INFO - Epoch 8, Step 29363: Loss=7.1198, Acc=0.094, 
2025-10-02 00:07:13,001 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.3202, Acc=0.114, 
2025-10-02 00:07:20,247 - training.trainer - INFO - Epoch 8, Step 29563: Loss=6.7374, Acc=0.103, 
2025-10-02 00:07:27,496 - training.trainer - INFO - Epoch 8, Step 29663: Loss=6.8659, Acc=0.150, 
2025-10-02 00:07:34,725 - training.trainer - INFO - Epoch 8, Step 29763: Loss=6.5030, Acc=0.025, 
2025-10-02 00:07:41,982 - training.trainer - INFO - Epoch 8, Step 29863: Loss=7.3772, Acc=0.042, 
2025-10-02 00:07:49,281 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.3903, Acc=0.069, 
2025-10-02 00:07:56,627 - training.trainer - INFO - Epoch 8, Step 30063: Loss=6.5439, Acc=0.047, 
2025-10-02 00:08:03,918 - training.trainer - INFO - Epoch 8, Step 30163: Loss=6.8586, Acc=0.018, 
2025-10-02 00:08:11,195 - training.trainer - INFO - Epoch 8, Step 30263: Loss=7.0709, Acc=0.018, 
2025-10-02 00:08:18,705 - training.trainer - INFO - Epoch 8, Step 30363: Loss=7.1976, Acc=0.100, 
2025-10-02 00:08:37,890 - training.trainer - INFO - Epoch 9/250 completed in 261.55s - Train Loss: 6.8336, Train Acc: 0.062, Val Loss: 6.8270, Val Acc: 0.063
2025-10-02 00:08:44,307 - training.trainer - INFO - Epoch 9, Step 30546: Loss=7.0547, Acc=0.043, 
2025-10-02 00:08:50,637 - training.trainer - INFO - Epoch 9, Step 30646: Loss=7.0382, Acc=0.051, 
2025-10-02 00:08:56,858 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.8084, Acc=0.047, 
2025-10-02 00:09:03,482 - training.trainer - INFO - Epoch 9, Step 30846: Loss=6.6384, Acc=0.028, 
2025-10-02 00:09:11,029 - training.trainer - INFO - Epoch 9, Step 30946: Loss=7.7236, Acc=0.022, 
2025-10-02 00:09:18,574 - training.trainer - INFO - Epoch 9, Step 31046: Loss=6.7834, Acc=0.150, 
2025-10-02 00:09:26,130 - training.trainer - INFO - Epoch 9, Step 31146: Loss=6.7414, Acc=0.039, 
2025-10-02 00:09:33,747 - training.trainer - INFO - Epoch 9, Step 31246: Loss=6.9371, Acc=0.105, 
2025-10-02 00:09:41,231 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.5330, Acc=0.051, 
2025-10-02 00:09:48,600 - training.trainer - INFO - Epoch 9, Step 31446: Loss=6.7697, Acc=0.069, 
2025-10-02 00:09:56,111 - training.trainer - INFO - Epoch 9, Step 31546: Loss=6.6684, Acc=0.107, 
2025-10-02 00:10:03,445 - training.trainer - INFO - Epoch 9, Step 31646: Loss=6.8512, Acc=0.052, 
2025-10-02 00:10:10,736 - training.trainer - INFO - Epoch 9, Step 31746: Loss=7.3275, Acc=0.022, 
2025-10-02 00:10:18,183 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.3896, Acc=0.111, 
2025-10-02 00:10:25,599 - training.trainer - INFO - Epoch 9, Step 31946: Loss=7.2892, Acc=0.025, 
2025-10-02 00:10:32,949 - training.trainer - INFO - Epoch 9, Step 32046: Loss=6.7789, Acc=0.074, 
2025-10-02 00:10:40,236 - training.trainer - INFO - Epoch 9, Step 32146: Loss=6.5884, Acc=0.062, 
2025-10-02 00:10:47,539 - training.trainer - INFO - Epoch 9, Step 32246: Loss=7.2660, Acc=0.036, 
2025-10-02 00:10:54,864 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.9761, Acc=0.118, 
2025-10-02 00:11:02,304 - training.trainer - INFO - Epoch 9, Step 32446: Loss=7.0830, Acc=0.035, 
2025-10-02 00:11:09,781 - training.trainer - INFO - Epoch 9, Step 32546: Loss=6.8951, Acc=0.080, 
2025-10-02 00:11:17,245 - training.trainer - INFO - Epoch 9, Step 32646: Loss=6.3504, Acc=0.043, 
2025-10-02 00:11:24,688 - training.trainer - INFO - Epoch 9, Step 32746: Loss=6.7128, Acc=0.047, 
2025-10-02 00:11:32,241 - training.trainer - INFO - Epoch 9, Step 32846: Loss=6.7890, Acc=0.115, 
2025-10-02 00:11:39,685 - training.trainer - INFO - Epoch 9, Step 32946: Loss=7.2102, Acc=0.081, 
2025-10-02 00:11:47,068 - training.trainer - INFO - Epoch 9, Step 33046: Loss=6.9117, Acc=0.176, 
2025-10-02 00:11:54,387 - training.trainer - INFO - Epoch 9, Step 33146: Loss=7.2344, Acc=0.019, 
2025-10-02 00:12:01,977 - training.trainer - INFO - Epoch 9, Step 33246: Loss=6.6045, Acc=0.000, 
2025-10-02 00:12:09,696 - training.trainer - INFO - Epoch 9, Step 33346: Loss=7.0391, Acc=0.047, 
2025-10-02 00:12:17,342 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.5510, Acc=0.047, 
2025-10-02 00:12:24,855 - training.trainer - INFO - Epoch 9, Step 33546: Loss=7.1191, Acc=0.038, 
2025-10-02 00:12:32,387 - training.trainer - INFO - Epoch 9, Step 33646: Loss=7.1108, Acc=0.111, 
2025-10-02 00:12:40,113 - training.trainer - INFO - Epoch 9, Step 33746: Loss=6.0086, Acc=0.107, 
2025-10-02 00:12:59,569 - training.trainer - INFO - Epoch 10/250 completed in 261.68s - Train Loss: 6.8463, Train Acc: 0.061, Val Loss: 6.8308, Val Acc: 0.063
2025-10-02 00:12:59,974 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-02 00:13:08,753 - training.trainer - INFO - Epoch 10, Step 33929: Loss=6.9917, Acc=0.027, 
2025-10-02 00:13:16,606 - training.trainer - INFO - Epoch 10, Step 34029: Loss=6.8314, Acc=0.071, 
2025-10-02 00:13:24,160 - training.trainer - INFO - Epoch 10, Step 34129: Loss=7.0251, Acc=0.048, 
2025-10-02 00:13:31,477 - training.trainer - INFO - Epoch 10, Step 34229: Loss=7.1655, Acc=0.025, 
2025-10-02 00:13:38,843 - training.trainer - INFO - Epoch 10, Step 34329: Loss=6.7148, Acc=0.083, 
2025-10-02 00:13:46,345 - training.trainer - INFO - Epoch 10, Step 34429: Loss=6.7422, Acc=0.049, 
2025-10-02 00:13:53,692 - training.trainer - INFO - Epoch 10, Step 34529: Loss=7.7049, Acc=0.050, 
2025-10-02 00:14:01,102 - training.trainer - INFO - Epoch 10, Step 34629: Loss=7.1934, Acc=0.037, 
2025-10-02 00:14:08,438 - training.trainer - INFO - Epoch 10, Step 34729: Loss=6.2094, Acc=0.021, 
2025-10-02 00:14:16,000 - training.trainer - INFO - Epoch 10, Step 34829: Loss=7.0081, Acc=0.018, 
2025-10-02 00:14:23,409 - training.trainer - INFO - Epoch 10, Step 34929: Loss=7.2857, Acc=0.026, 
2025-10-02 00:14:30,705 - training.trainer - INFO - Epoch 10, Step 35029: Loss=7.2116, Acc=0.043, 
2025-10-02 00:14:38,029 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.2917, Acc=0.000, 
2025-10-02 00:14:45,371 - training.trainer - INFO - Epoch 10, Step 35229: Loss=6.9835, Acc=0.033, 
2025-10-02 00:14:52,947 - training.trainer - INFO - Epoch 10, Step 35329: Loss=6.5322, Acc=0.062, 
2025-10-02 00:15:00,275 - training.trainer - INFO - Epoch 10, Step 35429: Loss=6.4758, Acc=0.048, 
2025-10-02 00:15:07,539 - training.trainer - INFO - Epoch 10, Step 35529: Loss=7.3284, Acc=0.044, 
2025-10-02 00:15:15,152 - training.trainer - INFO - Epoch 10, Step 35629: Loss=6.5954, Acc=0.033, 
2025-10-02 00:15:22,682 - training.trainer - INFO - Epoch 10, Step 35729: Loss=6.9507, Acc=0.029, 
2025-10-02 00:15:30,030 - training.trainer - INFO - Epoch 10, Step 35829: Loss=6.3200, Acc=0.045, 
2025-10-02 00:15:37,387 - training.trainer - INFO - Epoch 10, Step 35929: Loss=6.3319, Acc=0.062, 
2025-10-02 00:15:44,805 - training.trainer - INFO - Epoch 10, Step 36029: Loss=7.3611, Acc=0.027, 
2025-10-02 00:15:52,258 - training.trainer - INFO - Epoch 10, Step 36129: Loss=6.8452, Acc=0.052, 
2025-10-02 00:15:59,782 - training.trainer - INFO - Epoch 10, Step 36229: Loss=6.1104, Acc=0.031, 
2025-10-02 00:16:07,152 - training.trainer - INFO - Epoch 10, Step 36329: Loss=7.0099, Acc=0.034, 
2025-10-02 00:16:14,571 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.6523, Acc=0.083, 
2025-10-02 00:16:22,101 - training.trainer - INFO - Epoch 10, Step 36529: Loss=6.9073, Acc=0.026, 
2025-10-02 00:16:29,763 - training.trainer - INFO - Epoch 10, Step 36629: Loss=6.1723, Acc=0.059, 
2025-10-02 00:16:37,272 - training.trainer - INFO - Epoch 10, Step 36729: Loss=6.7367, Acc=0.083, 
2025-10-02 00:16:44,632 - training.trainer - INFO - Epoch 10, Step 36829: Loss=7.2107, Acc=0.023, 
2025-10-02 00:16:51,952 - training.trainer - INFO - Epoch 10, Step 36929: Loss=7.2406, Acc=0.070, 
2025-10-02 00:16:59,433 - training.trainer - INFO - Epoch 10, Step 37029: Loss=7.4509, Acc=0.047, 
2025-10-02 00:17:06,835 - training.trainer - INFO - Epoch 10, Step 37129: Loss=6.6962, Acc=0.043, 
2025-10-02 00:17:26,219 - training.trainer - INFO - Epoch 11/250 completed in 266.24s - Train Loss: 6.8642, Train Acc: 0.061, Val Loss: 6.8445, Val Acc: 0.063
2025-10-02 00:17:33,560 - training.trainer - INFO - Epoch 11, Step 37312: Loss=7.1547, Acc=0.061, 
2025-10-02 00:17:41,574 - training.trainer - INFO - Epoch 11, Step 37412: Loss=7.5403, Acc=0.030, 
2025-10-02 00:17:48,915 - training.trainer - INFO - Epoch 11, Step 37512: Loss=7.1895, Acc=0.100, 
2025-10-02 00:17:56,291 - training.trainer - INFO - Epoch 11, Step 37612: Loss=6.5621, Acc=0.100, 
2025-10-02 00:18:03,847 - training.trainer - INFO - Epoch 11, Step 37712: Loss=7.5085, Acc=0.047, 
2025-10-02 00:18:11,622 - training.trainer - INFO - Epoch 11, Step 37812: Loss=7.2784, Acc=0.085, 
2025-10-02 00:18:19,213 - training.trainer - INFO - Epoch 11, Step 37912: Loss=6.1840, Acc=0.080, 
2025-10-02 00:18:26,794 - training.trainer - INFO - Epoch 11, Step 38012: Loss=6.6840, Acc=0.038, 
2025-10-02 00:18:34,392 - training.trainer - INFO - Epoch 11, Step 38112: Loss=7.5470, Acc=0.083, 
2025-10-02 00:18:42,062 - training.trainer - INFO - Epoch 11, Step 38212: Loss=7.1978, Acc=0.021, 
2025-10-02 00:18:49,531 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.7993, Acc=0.032, 
2025-10-02 00:18:57,094 - training.trainer - INFO - Epoch 11, Step 38412: Loss=6.8509, Acc=0.060, 
2025-10-02 00:19:04,434 - training.trainer - INFO - Epoch 11, Step 38512: Loss=7.1063, Acc=0.045, 
2025-10-02 00:19:11,941 - training.trainer - INFO - Epoch 11, Step 38612: Loss=7.5751, Acc=0.022, 
2025-10-02 00:19:19,294 - training.trainer - INFO - Epoch 11, Step 38712: Loss=7.2378, Acc=0.190, 
2025-10-02 00:19:26,822 - training.trainer - INFO - Epoch 11, Step 38812: Loss=7.1398, Acc=0.024, 
2025-10-02 00:19:34,434 - training.trainer - INFO - Epoch 11, Step 38912: Loss=7.4783, Acc=0.067, 
2025-10-02 00:19:42,011 - training.trainer - INFO - Epoch 11, Step 39012: Loss=6.6957, Acc=0.062, 
2025-10-02 00:19:49,662 - training.trainer - INFO - Epoch 11, Step 39112: Loss=7.8787, Acc=0.056, 
2025-10-02 00:19:57,193 - training.trainer - INFO - Epoch 11, Step 39212: Loss=6.8277, Acc=0.067, 
2025-10-02 00:20:04,843 - training.trainer - INFO - Epoch 11, Step 39312: Loss=7.0146, Acc=0.029, 
2025-10-02 00:20:12,356 - training.trainer - INFO - Epoch 11, Step 39412: Loss=6.9436, Acc=0.039, 
2025-10-02 00:20:19,884 - training.trainer - INFO - Epoch 11, Step 39512: Loss=6.7189, Acc=0.058, 
2025-10-02 00:20:27,525 - training.trainer - INFO - Epoch 11, Step 39612: Loss=6.4051, Acc=0.044, 
2025-10-02 00:20:35,212 - training.trainer - INFO - Epoch 11, Step 39712: Loss=6.2816, Acc=0.053, 
2025-10-02 00:20:42,748 - training.trainer - INFO - Epoch 11, Step 39812: Loss=6.5471, Acc=0.034, 
2025-10-02 00:20:50,588 - training.trainer - INFO - Epoch 11, Step 39912: Loss=7.0466, Acc=0.026, 
2025-10-02 00:20:58,163 - training.trainer - INFO - Epoch 11, Step 40012: Loss=6.9004, Acc=0.074, 
2025-10-02 00:21:05,665 - training.trainer - INFO - Epoch 11, Step 40112: Loss=7.4378, Acc=0.022, 
2025-10-02 00:21:13,256 - training.trainer - INFO - Epoch 11, Step 40212: Loss=7.4366, Acc=0.026, 
2025-10-02 00:21:20,939 - training.trainer - INFO - Epoch 11, Step 40312: Loss=6.2287, Acc=0.087, 
2025-10-02 00:21:28,557 - training.trainer - INFO - Epoch 11, Step 40412: Loss=7.3113, Acc=0.057, 
2025-10-02 00:21:36,183 - training.trainer - INFO - Epoch 11, Step 40512: Loss=7.2031, Acc=0.075, 
2025-10-02 00:21:54,683 - training.trainer - INFO - Epoch 12/250 completed in 268.46s - Train Loss: 6.8825, Train Acc: 0.061, Val Loss: 6.8583, Val Acc: 0.063
2025-10-02 00:22:02,139 - training.trainer - INFO - Epoch 12, Step 40695: Loss=6.9117, Acc=0.062, 
2025-10-02 00:22:09,499 - training.trainer - INFO - Epoch 12, Step 40795: Loss=7.6803, Acc=0.043, 
2025-10-02 00:22:16,914 - training.trainer - INFO - Epoch 12, Step 40895: Loss=6.5990, Acc=0.125, 
2025-10-02 00:22:24,573 - training.trainer - INFO - Epoch 12, Step 40995: Loss=6.2222, Acc=0.051, 
2025-10-02 00:22:31,951 - training.trainer - INFO - Epoch 12, Step 41095: Loss=6.8118, Acc=0.044, 
2025-10-02 00:22:39,468 - training.trainer - INFO - Epoch 12, Step 41195: Loss=6.8911, Acc=0.053, 
2025-10-02 00:22:47,033 - training.trainer - INFO - Epoch 12, Step 41295: Loss=6.6792, Acc=0.045, 
2025-10-02 00:22:54,344 - training.trainer - INFO - Epoch 12, Step 41395: Loss=6.2943, Acc=0.080, 
2025-10-02 00:23:01,804 - training.trainer - INFO - Epoch 12, Step 41495: Loss=6.1598, Acc=0.111, 
2025-10-02 00:23:09,206 - training.trainer - INFO - Epoch 12, Step 41595: Loss=6.8122, Acc=0.095, 
2025-10-02 00:23:16,514 - training.trainer - INFO - Epoch 12, Step 41695: Loss=6.7686, Acc=0.097, 
2025-10-02 00:23:23,974 - training.trainer - INFO - Epoch 12, Step 41795: Loss=7.1879, Acc=0.039, 
2025-10-02 00:23:31,411 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.9000, Acc=0.085, 
2025-10-02 00:23:38,720 - training.trainer - INFO - Epoch 12, Step 41995: Loss=6.8610, Acc=0.000, 
2025-10-02 00:23:46,023 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.7826, Acc=0.034, 
2025-10-02 00:23:53,778 - training.trainer - INFO - Epoch 12, Step 42195: Loss=7.1176, Acc=0.048, 
2025-10-02 00:24:01,122 - training.trainer - INFO - Epoch 12, Step 42295: Loss=7.7267, Acc=0.074, 
2025-10-02 00:24:08,577 - training.trainer - INFO - Epoch 12, Step 42395: Loss=6.7883, Acc=0.049, 
2025-10-02 00:24:15,956 - training.trainer - INFO - Epoch 12, Step 42495: Loss=6.4676, Acc=0.069, 
2025-10-02 00:24:23,266 - training.trainer - INFO - Epoch 12, Step 42595: Loss=6.1280, Acc=0.037, 
2025-10-02 00:24:30,628 - training.trainer - INFO - Epoch 12, Step 42695: Loss=7.4519, Acc=0.043, 
2025-10-02 00:24:38,075 - training.trainer - INFO - Epoch 12, Step 42795: Loss=7.7587, Acc=0.032, 
2025-10-02 00:24:45,477 - training.trainer - INFO - Epoch 12, Step 42895: Loss=7.0772, Acc=0.087, 
2025-10-02 00:24:53,194 - training.trainer - INFO - Epoch 12, Step 42995: Loss=7.5643, Acc=0.083, 
2025-10-02 00:25:00,495 - training.trainer - INFO - Epoch 12, Step 43095: Loss=7.3982, Acc=0.056, 
2025-10-02 00:25:07,798 - training.trainer - INFO - Epoch 12, Step 43195: Loss=6.4220, Acc=0.077, 
2025-10-02 00:25:15,532 - training.trainer - INFO - Epoch 12, Step 43295: Loss=7.5473, Acc=0.024, 
2025-10-02 00:25:22,888 - training.trainer - INFO - Epoch 12, Step 43395: Loss=7.0012, Acc=0.054, 
2025-10-02 00:25:30,253 - training.trainer - INFO - Epoch 12, Step 43495: Loss=6.6657, Acc=0.057, 
2025-10-02 00:25:37,687 - training.trainer - INFO - Epoch 12, Step 43595: Loss=7.2696, Acc=0.064, 
2025-10-02 00:25:45,159 - training.trainer - INFO - Epoch 12, Step 43695: Loss=7.2658, Acc=0.022, 
2025-10-02 00:25:52,453 - training.trainer - INFO - Epoch 12, Step 43795: Loss=7.3919, Acc=0.143, 
2025-10-02 00:26:00,073 - training.trainer - INFO - Epoch 12, Step 43895: Loss=6.8399, Acc=0.043, 
2025-10-02 00:26:19,262 - training.trainer - INFO - Epoch 13/250 completed in 264.58s - Train Loss: 6.8975, Train Acc: 0.061, Val Loss: 6.8620, Val Acc: 0.063
2025-10-02 00:26:26,068 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.6531, Acc=0.071, 
2025-10-02 00:26:32,244 - training.trainer - INFO - Epoch 13, Step 44178: Loss=6.4735, Acc=0.107, 
2025-10-02 00:26:38,531 - training.trainer - INFO - Epoch 13, Step 44278: Loss=6.8388, Acc=0.083, 
2025-10-02 00:26:44,686 - training.trainer - INFO - Epoch 13, Step 44378: Loss=6.7847, Acc=0.015, 
2025-10-02 00:26:51,036 - training.trainer - INFO - Epoch 13, Step 44478: Loss=6.8663, Acc=0.015, 
2025-10-02 00:26:57,251 - training.trainer - INFO - Epoch 13, Step 44578: Loss=6.4111, Acc=0.100, 
2025-10-02 00:27:03,503 - training.trainer - INFO - Epoch 13, Step 44678: Loss=6.7629, Acc=0.057, 
2025-10-02 00:27:09,661 - training.trainer - INFO - Epoch 13, Step 44778: Loss=7.4390, Acc=0.029, 
2025-10-02 00:27:15,973 - training.trainer - INFO - Epoch 13, Step 44878: Loss=6.5098, Acc=0.062, 
2025-10-02 00:27:22,336 - training.trainer - INFO - Epoch 13, Step 44978: Loss=7.9818, Acc=0.024, 
2025-10-02 00:27:28,612 - training.trainer - INFO - Epoch 13, Step 45078: Loss=6.9392, Acc=0.044, 
2025-10-02 00:27:34,811 - training.trainer - INFO - Epoch 13, Step 45178: Loss=6.3981, Acc=0.038, 
2025-10-02 00:27:41,121 - training.trainer - INFO - Epoch 13, Step 45278: Loss=7.0016, Acc=0.049, 
2025-10-02 00:27:47,691 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.1402, Acc=0.059, 
2025-10-02 00:27:54,186 - training.trainer - INFO - Epoch 13, Step 45478: Loss=6.2955, Acc=0.071, 
2025-10-02 00:28:01,274 - training.trainer - INFO - Epoch 13, Step 45578: Loss=7.1252, Acc=0.040, 
2025-10-02 00:28:08,876 - training.trainer - INFO - Epoch 13, Step 45678: Loss=7.4130, Acc=0.026, 
2025-10-02 00:28:16,549 - training.trainer - INFO - Epoch 13, Step 45778: Loss=6.4805, Acc=0.030, 
2025-10-02 00:28:24,047 - training.trainer - INFO - Epoch 13, Step 45878: Loss=6.1943, Acc=0.048, 
2025-10-02 00:28:31,857 - training.trainer - INFO - Epoch 13, Step 45978: Loss=6.6983, Acc=0.056, 
2025-10-02 00:28:39,353 - training.trainer - INFO - Epoch 13, Step 46078: Loss=6.3681, Acc=0.073, 
2025-10-02 00:28:46,831 - training.trainer - INFO - Epoch 13, Step 46178: Loss=7.0196, Acc=0.025, 
2025-10-02 00:28:54,389 - training.trainer - INFO - Epoch 13, Step 46278: Loss=6.5188, Acc=0.043, 
2025-10-02 00:29:02,018 - training.trainer - INFO - Epoch 13, Step 46378: Loss=7.3940, Acc=0.054, 
2025-10-02 00:29:09,701 - training.trainer - INFO - Epoch 13, Step 46478: Loss=6.9110, Acc=0.043, 
2025-10-02 00:29:17,288 - training.trainer - INFO - Epoch 13, Step 46578: Loss=7.1554, Acc=0.077, 
2025-10-02 00:29:24,779 - training.trainer - INFO - Epoch 13, Step 46678: Loss=7.1314, Acc=0.035, 
2025-10-02 00:29:32,224 - training.trainer - INFO - Epoch 13, Step 46778: Loss=6.8219, Acc=0.048, 
2025-10-02 00:29:39,792 - training.trainer - INFO - Epoch 13, Step 46878: Loss=7.3678, Acc=0.040, 
2025-10-02 00:29:47,534 - training.trainer - INFO - Epoch 13, Step 46978: Loss=7.3663, Acc=0.094, 
2025-10-02 00:29:55,241 - training.trainer - INFO - Epoch 13, Step 47078: Loss=7.6353, Acc=0.229, 
2025-10-02 00:30:02,723 - training.trainer - INFO - Epoch 13, Step 47178: Loss=6.6594, Acc=0.049, 
2025-10-02 00:30:10,338 - training.trainer - INFO - Epoch 13, Step 47278: Loss=7.0444, Acc=0.045, 
2025-10-02 00:30:30,043 - training.trainer - INFO - Epoch 14/250 completed in 250.78s - Train Loss: 6.9031, Train Acc: 0.061, Val Loss: 6.8747, Val Acc: 0.052
2025-10-02 00:30:38,287 - training.trainer - INFO - Epoch 14, Step 47461: Loss=6.6290, Acc=0.057, 
2025-10-02 00:30:45,870 - training.trainer - INFO - Epoch 14, Step 47561: Loss=6.6351, Acc=0.138, 
2025-10-02 00:30:53,436 - training.trainer - INFO - Epoch 14, Step 47661: Loss=6.8208, Acc=0.029, 
2025-10-02 00:31:00,827 - training.trainer - INFO - Epoch 14, Step 47761: Loss=6.9545, Acc=0.034, 
2025-10-02 00:31:08,645 - training.trainer - INFO - Epoch 14, Step 47861: Loss=6.6997, Acc=0.056, 
2025-10-02 00:31:16,334 - training.trainer - INFO - Epoch 14, Step 47961: Loss=7.3370, Acc=0.143, 
2025-10-02 00:31:23,823 - training.trainer - INFO - Epoch 14, Step 48061: Loss=7.3670, Acc=0.021, 
2025-10-02 00:31:31,613 - training.trainer - INFO - Epoch 14, Step 48161: Loss=6.7126, Acc=0.122, 
2025-10-02 00:31:39,094 - training.trainer - INFO - Epoch 14, Step 48261: Loss=6.2892, Acc=0.074, 
2025-10-02 00:31:46,707 - training.trainer - INFO - Epoch 14, Step 48361: Loss=6.8909, Acc=0.025, 
2025-10-02 00:31:54,198 - training.trainer - INFO - Epoch 14, Step 48461: Loss=7.4310, Acc=0.057, 
2025-10-02 00:32:01,590 - training.trainer - INFO - Epoch 14, Step 48561: Loss=7.7506, Acc=0.063, 
2025-10-02 00:32:08,991 - training.trainer - INFO - Epoch 14, Step 48661: Loss=6.7511, Acc=0.000, 
2025-10-02 00:32:16,665 - training.trainer - INFO - Epoch 14, Step 48761: Loss=7.0508, Acc=0.034, 
2025-10-02 00:32:24,035 - training.trainer - INFO - Epoch 14, Step 48861: Loss=7.2318, Acc=0.038, 
2025-10-02 00:32:31,547 - training.trainer - INFO - Epoch 14, Step 48961: Loss=7.1583, Acc=0.071, 
2025-10-02 00:32:39,007 - training.trainer - INFO - Epoch 14, Step 49061: Loss=7.0742, Acc=0.067, 
2025-10-02 00:32:46,491 - training.trainer - INFO - Epoch 14, Step 49161: Loss=7.5718, Acc=0.017, 
2025-10-02 00:32:54,133 - training.trainer - INFO - Epoch 14, Step 49261: Loss=6.6507, Acc=0.222, 
2025-10-02 00:33:01,558 - training.trainer - INFO - Epoch 14, Step 49361: Loss=6.3442, Acc=0.034, 
2025-10-02 00:33:09,022 - training.trainer - INFO - Epoch 14, Step 49461: Loss=6.6859, Acc=0.056, 
2025-10-02 00:33:16,461 - training.trainer - INFO - Epoch 14, Step 49561: Loss=6.3890, Acc=0.071, 
2025-10-02 00:33:24,038 - training.trainer - INFO - Epoch 14, Step 49661: Loss=7.0327, Acc=0.074, 
2025-10-02 00:33:31,469 - training.trainer - INFO - Epoch 14, Step 49761: Loss=6.9040, Acc=0.091, 
2025-10-02 00:33:38,948 - training.trainer - INFO - Epoch 14, Step 49861: Loss=7.1649, Acc=0.077, 
2025-10-02 00:33:46,421 - training.trainer - INFO - Epoch 14, Step 49961: Loss=6.5487, Acc=0.080, 
2025-10-02 00:33:53,951 - training.trainer - INFO - Epoch 14, Step 50061: Loss=7.0486, Acc=0.042, 
2025-10-02 00:34:01,453 - training.trainer - INFO - Epoch 14, Step 50161: Loss=6.6669, Acc=0.105, 
2025-10-02 00:34:08,866 - training.trainer - INFO - Epoch 14, Step 50261: Loss=7.2734, Acc=0.041, 
2025-10-02 00:34:16,259 - training.trainer - INFO - Epoch 14, Step 50361: Loss=7.0749, Acc=0.000, 
2025-10-02 00:34:23,664 - training.trainer - INFO - Epoch 14, Step 50461: Loss=7.1803, Acc=0.074, 
2025-10-02 00:34:31,234 - training.trainer - INFO - Epoch 14, Step 50561: Loss=6.8995, Acc=0.067, 
2025-10-02 00:34:38,681 - training.trainer - INFO - Epoch 14, Step 50661: Loss=6.4816, Acc=0.000, 
2025-10-02 00:34:58,399 - training.trainer - INFO - Epoch 15/250 completed in 268.36s - Train Loss: 6.9243, Train Acc: 0.059, Val Loss: 6.9018, Val Acc: 0.063
2025-10-02 00:34:58,702 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-02 00:35:05,632 - training.trainer - INFO - Epoch 15, Step 50844: Loss=6.8645, Acc=0.071, 
2025-10-02 00:35:11,929 - training.trainer - INFO - Epoch 15, Step 50944: Loss=6.4928, Acc=0.033, 
2025-10-02 00:35:18,520 - training.trainer - INFO - Epoch 15, Step 51044: Loss=7.1656, Acc=0.043, 
2025-10-02 00:35:25,954 - training.trainer - INFO - Epoch 15, Step 51144: Loss=7.1553, Acc=0.032, 
2025-10-02 00:35:33,412 - training.trainer - INFO - Epoch 15, Step 51244: Loss=7.3209, Acc=0.043, 
2025-10-02 00:35:40,798 - training.trainer - INFO - Epoch 15, Step 51344: Loss=7.2380, Acc=0.059, 
2025-10-02 00:35:48,546 - training.trainer - INFO - Epoch 15, Step 51444: Loss=6.8676, Acc=0.000, 
2025-10-02 00:35:56,304 - training.trainer - INFO - Epoch 15, Step 51544: Loss=7.6375, Acc=0.025, 
2025-10-02 00:36:03,981 - training.trainer - INFO - Epoch 15, Step 51644: Loss=6.8312, Acc=0.149, 
2025-10-02 00:36:11,771 - training.trainer - INFO - Epoch 15, Step 51744: Loss=7.2372, Acc=0.048, 
2025-10-02 00:36:19,358 - training.trainer - INFO - Epoch 15, Step 51844: Loss=7.2422, Acc=0.100, 
2025-10-02 00:36:27,161 - training.trainer - INFO - Epoch 15, Step 51944: Loss=6.5882, Acc=0.062, 
2025-10-02 00:36:34,881 - training.trainer - INFO - Epoch 15, Step 52044: Loss=7.4967, Acc=0.045, 
2025-10-02 00:36:42,751 - training.trainer - INFO - Epoch 15, Step 52144: Loss=7.6314, Acc=0.021, 
2025-10-02 00:36:50,221 - training.trainer - INFO - Epoch 15, Step 52244: Loss=7.2082, Acc=0.000, 
2025-10-02 00:36:57,934 - training.trainer - INFO - Epoch 15, Step 52344: Loss=7.0004, Acc=0.025, 
2025-10-02 00:37:05,513 - training.trainer - INFO - Epoch 15, Step 52444: Loss=6.8620, Acc=0.014, 
2025-10-02 00:37:13,147 - training.trainer - INFO - Epoch 15, Step 52544: Loss=6.9170, Acc=0.122, 
2025-10-02 00:37:20,642 - training.trainer - INFO - Epoch 15, Step 52644: Loss=6.6542, Acc=0.054, 
2025-10-02 00:37:28,129 - training.trainer - INFO - Epoch 15, Step 52744: Loss=7.2720, Acc=0.100, 
2025-10-02 00:37:35,587 - training.trainer - INFO - Epoch 15, Step 52844: Loss=6.8546, Acc=0.032, 
2025-10-02 00:37:43,128 - training.trainer - INFO - Epoch 15, Step 52944: Loss=6.1620, Acc=0.045, 
2025-10-02 00:37:50,547 - training.trainer - INFO - Epoch 15, Step 53044: Loss=7.2338, Acc=0.053, 
2025-10-02 00:37:57,894 - training.trainer - INFO - Epoch 15, Step 53144: Loss=7.4407, Acc=0.047, 
2025-10-02 00:38:05,252 - training.trainer - INFO - Epoch 15, Step 53244: Loss=6.6173, Acc=0.056, 
2025-10-02 00:38:12,625 - training.trainer - INFO - Epoch 15, Step 53344: Loss=6.9610, Acc=0.081, 
2025-10-02 00:38:20,189 - training.trainer - INFO - Epoch 15, Step 53444: Loss=7.3368, Acc=0.136, 
2025-10-02 00:38:27,555 - training.trainer - INFO - Epoch 15, Step 53544: Loss=6.8759, Acc=0.000, 
2025-10-02 00:38:34,923 - training.trainer - INFO - Epoch 15, Step 53644: Loss=7.4849, Acc=0.062, 
2025-10-02 00:38:42,241 - training.trainer - INFO - Epoch 15, Step 53744: Loss=7.0194, Acc=0.086, 
2025-10-02 00:38:49,682 - training.trainer - INFO - Epoch 15, Step 53844: Loss=7.1209, Acc=0.044, 
2025-10-02 00:38:57,010 - training.trainer - INFO - Epoch 15, Step 53944: Loss=7.2726, Acc=0.154, 
2025-10-02 00:39:04,396 - training.trainer - INFO - Epoch 15, Step 54044: Loss=7.0987, Acc=0.100, 
2025-10-02 00:39:23,298 - training.trainer - INFO - Epoch 16/250 completed in 264.60s - Train Loss: 6.9512, Train Acc: 0.059, Val Loss: 6.8911, Val Acc: 0.063
2025-10-02 00:39:30,750 - training.trainer - INFO - Epoch 16, Step 54227: Loss=7.2915, Acc=0.056, 
2025-10-02 00:39:37,954 - training.trainer - INFO - Epoch 16, Step 54327: Loss=7.1284, Acc=0.047, 
2025-10-02 00:39:44,951 - training.trainer - INFO - Epoch 16, Step 54427: Loss=6.3188, Acc=0.043, 
2025-10-02 00:39:52,201 - training.trainer - INFO - Epoch 16, Step 54527: Loss=7.7319, Acc=0.021, 
2025-10-02 00:39:59,310 - training.trainer - INFO - Epoch 16, Step 54627: Loss=6.9895, Acc=0.000, 
2025-10-02 00:40:06,883 - training.trainer - INFO - Epoch 16, Step 54727: Loss=6.7922, Acc=0.031, 
2025-10-02 00:40:14,506 - training.trainer - INFO - Epoch 16, Step 54827: Loss=7.1655, Acc=0.107, 
2025-10-02 00:40:22,156 - training.trainer - INFO - Epoch 16, Step 54927: Loss=7.4099, Acc=0.081, 
2025-10-02 00:40:29,833 - training.trainer - INFO - Epoch 16, Step 55027: Loss=7.4104, Acc=0.000, 
2025-10-02 00:40:37,171 - training.trainer - INFO - Epoch 16, Step 55127: Loss=6.5349, Acc=0.000, 
2025-10-02 00:40:44,342 - training.trainer - INFO - Epoch 16, Step 55227: Loss=6.3730, Acc=0.069, 
2025-10-02 00:40:51,940 - training.trainer - INFO - Epoch 16, Step 55327: Loss=6.8410, Acc=0.158, 
2025-10-02 00:40:59,493 - training.trainer - INFO - Epoch 16, Step 55427: Loss=7.1412, Acc=0.085, 
2025-10-02 00:41:06,936 - training.trainer - INFO - Epoch 16, Step 55527: Loss=7.2549, Acc=0.062, 
2025-10-02 00:41:14,336 - training.trainer - INFO - Epoch 16, Step 55627: Loss=6.8526, Acc=0.083, 
2025-10-02 00:41:21,682 - training.trainer - INFO - Epoch 16, Step 55727: Loss=6.7062, Acc=0.021, 
2025-10-02 00:41:29,041 - training.trainer - INFO - Epoch 16, Step 55827: Loss=6.8270, Acc=0.077, 
2025-10-02 00:41:36,783 - training.trainer - INFO - Epoch 16, Step 55927: Loss=6.8995, Acc=0.028, 
2025-10-02 00:41:44,369 - training.trainer - INFO - Epoch 16, Step 56027: Loss=7.0706, Acc=0.083, 
2025-10-02 00:41:51,940 - training.trainer - INFO - Epoch 16, Step 56127: Loss=7.2988, Acc=0.043, 
2025-10-02 00:41:59,463 - training.trainer - INFO - Epoch 16, Step 56227: Loss=6.9173, Acc=0.037, 
2025-10-02 00:42:07,299 - training.trainer - INFO - Epoch 16, Step 56327: Loss=7.1406, Acc=0.100, 
2025-10-02 00:42:14,928 - training.trainer - INFO - Epoch 16, Step 56427: Loss=7.1844, Acc=0.057, 
2025-10-02 00:42:22,462 - training.trainer - INFO - Epoch 16, Step 56527: Loss=7.5051, Acc=0.024, 
2025-10-02 00:42:29,875 - training.trainer - INFO - Epoch 16, Step 56627: Loss=7.5772, Acc=0.037, 
2025-10-02 00:42:37,326 - training.trainer - INFO - Epoch 16, Step 56727: Loss=6.6875, Acc=0.111, 
2025-10-02 00:42:44,684 - training.trainer - INFO - Epoch 16, Step 56827: Loss=6.6071, Acc=0.057, 
2025-10-02 00:42:52,113 - training.trainer - INFO - Epoch 16, Step 56927: Loss=7.1749, Acc=0.093, 
2025-10-02 00:42:59,561 - training.trainer - INFO - Epoch 16, Step 57027: Loss=6.4802, Acc=0.167, 
2025-10-02 00:43:06,894 - training.trainer - INFO - Epoch 16, Step 57127: Loss=7.2544, Acc=0.077, 
2025-10-02 00:43:14,399 - training.trainer - INFO - Epoch 16, Step 57227: Loss=6.7444, Acc=0.000, 
2025-10-02 00:43:21,766 - training.trainer - INFO - Epoch 16, Step 57327: Loss=6.3571, Acc=0.080, 
2025-10-02 00:43:29,138 - training.trainer - INFO - Epoch 16, Step 57427: Loss=6.7063, Acc=0.091, 
2025-10-02 00:43:48,484 - training.trainer - INFO - Epoch 17/250 completed in 265.19s - Train Loss: 6.9518, Train Acc: 0.058, Val Loss: 6.9009, Val Acc: 0.063
2025-10-02 00:43:55,104 - training.trainer - INFO - Epoch 17, Step 57610: Loss=6.9267, Acc=0.033, 
2025-10-02 00:44:02,053 - training.trainer - INFO - Epoch 17, Step 57710: Loss=6.5398, Acc=0.000, 
2025-10-02 00:44:08,874 - training.trainer - INFO - Epoch 17, Step 57810: Loss=6.9552, Acc=0.061, 
2025-10-02 00:44:15,951 - training.trainer - INFO - Epoch 17, Step 57910: Loss=6.8415, Acc=0.075, 
2025-10-02 00:44:23,477 - training.trainer - INFO - Epoch 17, Step 58010: Loss=7.4003, Acc=0.029, 
2025-10-02 00:44:31,028 - training.trainer - INFO - Epoch 17, Step 58110: Loss=6.4755, Acc=0.036, 
2025-10-02 00:44:38,546 - training.trainer - INFO - Epoch 17, Step 58210: Loss=6.2719, Acc=0.036, 
2025-10-02 00:44:45,926 - training.trainer - INFO - Epoch 17, Step 58310: Loss=7.1452, Acc=0.029, 
2025-10-02 00:44:53,415 - training.trainer - INFO - Epoch 17, Step 58410: Loss=6.9418, Acc=0.053, 
2025-10-02 00:45:00,974 - training.trainer - INFO - Epoch 17, Step 58510: Loss=7.0758, Acc=0.040, 
2025-10-02 00:45:08,573 - training.trainer - INFO - Epoch 17, Step 58610: Loss=7.0515, Acc=0.111, 
2025-10-02 00:45:16,032 - training.trainer - INFO - Epoch 17, Step 58710: Loss=7.1287, Acc=0.065, 
2025-10-02 00:45:23,763 - training.trainer - INFO - Epoch 17, Step 58810: Loss=7.3426, Acc=0.026, 
2025-10-02 00:45:31,463 - training.trainer - INFO - Epoch 17, Step 58910: Loss=6.6495, Acc=0.044, 
2025-10-02 00:45:38,590 - training.trainer - INFO - Epoch 17, Step 59010: Loss=7.3960, Acc=0.050, 
2025-10-02 00:45:45,910 - training.trainer - INFO - Epoch 17, Step 59110: Loss=7.3690, Acc=0.058, 
2025-10-02 00:45:53,556 - training.trainer - INFO - Epoch 17, Step 59210: Loss=6.9272, Acc=0.077, 
2025-10-02 00:46:01,237 - training.trainer - INFO - Epoch 17, Step 59310: Loss=7.3250, Acc=0.033, 
2025-10-02 00:46:08,844 - training.trainer - INFO - Epoch 17, Step 59410: Loss=7.1808, Acc=0.048, 
2025-10-02 00:46:16,417 - training.trainer - INFO - Epoch 17, Step 59510: Loss=6.4962, Acc=0.038, 
2025-10-02 00:46:24,295 - training.trainer - INFO - Epoch 17, Step 59610: Loss=6.8245, Acc=0.032, 
2025-10-02 00:46:32,059 - training.trainer - INFO - Epoch 17, Step 59710: Loss=7.0154, Acc=0.094, 
2025-10-02 00:46:39,515 - training.trainer - INFO - Epoch 17, Step 59810: Loss=6.3397, Acc=0.067, 
2025-10-02 00:46:47,000 - training.trainer - INFO - Epoch 17, Step 59910: Loss=7.3897, Acc=0.033, 
2025-10-02 00:46:54,610 - training.trainer - INFO - Epoch 17, Step 60010: Loss=6.7110, Acc=0.091, 
2025-10-02 00:47:02,318 - training.trainer - INFO - Epoch 17, Step 60110: Loss=6.3602, Acc=0.100, 
2025-10-02 00:47:09,871 - training.trainer - INFO - Epoch 17, Step 60210: Loss=7.0629, Acc=0.045, 
2025-10-02 00:47:17,440 - training.trainer - INFO - Epoch 17, Step 60310: Loss=6.6010, Acc=0.100, 
2025-10-02 00:47:25,086 - training.trainer - INFO - Epoch 17, Step 60410: Loss=6.7144, Acc=0.039, 
2025-10-02 00:47:32,850 - training.trainer - INFO - Epoch 17, Step 60510: Loss=6.9084, Acc=0.053, 
2025-10-02 00:47:40,294 - training.trainer - INFO - Epoch 17, Step 60610: Loss=6.5829, Acc=0.036, 
2025-10-02 00:47:47,785 - training.trainer - INFO - Epoch 17, Step 60710: Loss=7.4240, Acc=0.056, 
2025-10-02 00:47:55,313 - training.trainer - INFO - Epoch 17, Step 60810: Loss=7.3228, Acc=0.026, 
2025-10-02 00:48:14,697 - training.trainer - INFO - Epoch 18/250 completed in 266.21s - Train Loss: 6.9506, Train Acc: 0.058, Val Loss: 6.9021, Val Acc: 0.063
2025-10-02 00:48:14,697 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-02 00:48:14,698 - training.trainer - INFO - Training completed!
2025-10-02 00:48:14,698 - __main__ - INFO - Training completed successfully!
2025-10-02 00:48:14,808 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-02 00:48:14,823 - __main__ - INFO - Process completed!
2025-10-02 00:48:22,193 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-02 00:48:22,194 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-02 00:48:22,194 - __main__ - INFO - Starting model evaluation
2025-10-02 00:48:22,871 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-02 00:48:57,025 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-02 00:48:57,039 - __main__ - INFO - Process completed!
2025-10-02 00:49:04,153 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-10-02 00:49:04,153 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-02 00:49:04,153 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-10-02 00:49:04,732 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-02 00:49:20,318 - __main__ - INFO - Inference completed successfully!
2025-10-02 00:49:20,327 - __main__ - INFO - Process completed!
2025-10-02 21:29:24,628 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-02 21:29:24,629 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-02 21:29:24,629 - __main__ - INFO - Starting training pipeline
2025-10-02 21:29:24,755 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-02 21:29:24,789 - __main__ - INFO - GPU: NVIDIA A30
2025-10-02 21:29:24,789 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-02 21:29:24,789 - __main__ - INFO - Loading training data...
2025-10-02 21:30:08,824 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-02 21:30:08,825 - __main__ - INFO - Processing train split...
2025-10-02 21:30:09,118 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-02 21:30:09,118 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-02 21:31:00,782 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-02 21:31:56,696 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-02 21:32:52,573 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-02 21:33:44,896 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-02 21:34:29,164 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-02 21:35:12,304 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-02 21:35:45,425 - __main__ - INFO - Processing val split...
2025-10-02 21:35:45,648 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-02 21:35:45,648 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-02 21:36:21,944 - __main__ - INFO - Processing test split...
2025-10-02 21:36:22,170 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-02 21:36:22,170 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-02 21:36:59,279 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-02 21:36:59,279 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-02 21:36:59,294 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-02 21:36:59,295 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-02 21:36:59,295 - __main__ - INFO - Creating model architecture...
2025-10-02 21:36:59,777 - __main__ - INFO - Model created successfully
2025-10-02 21:36:59,777 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-02 21:36:59,777 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-02 21:36:59,778 - __main__ - INFO - Using device: cuda
2025-10-02 21:36:59,778 - __main__ - INFO - Creating trainer...
2025-10-02 21:36:59,778 - __main__ - INFO - Moving model to cuda...
2025-10-02 21:37:00,187 - __main__ - INFO - Model moved to cuda
2025-10-02 21:37:00,188 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-02 21:37:02,639 - __main__ - INFO - Trainer created successfully
2025-10-02 21:37:02,639 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-02 21:37:02,639 - __main__ - INFO - Starting training...
2025-10-02 21:37:02,639 - __main__ - INFO - Training configuration:
2025-10-02 21:37:02,639 - __main__ - INFO -   - Epochs: 250
2025-10-02 21:37:02,639 - __main__ - INFO -   - Batch size: 32
2025-10-02 21:37:02,639 - __main__ - INFO -   - Learning rate: 5e-4
2025-10-02 21:37:02,640 - __main__ - INFO -   - Training samples: 6765
2025-10-02 21:37:02,640 - __main__ - INFO -   - Validation samples: 845
2025-10-02 21:37:02,640 - training.trainer - INFO - Starting training for 250 epochs
2025-10-02 21:37:02,640 - training.trainer - INFO - Model parameters: 16,680,032
2025-10-02 21:37:02,640 - training.trainer - INFO - Training on device: cuda
2025-10-02 21:37:42,866 - training.trainer - INFO - Epoch 0, Step 99: Loss=6.9096, Acc=0.073, 
2025-10-02 21:38:19,083 - training.trainer - INFO - Epoch 0, Step 199: Loss=6.7900, Acc=0.090, 
2025-10-02 21:38:33,489 - training.trainer - INFO - Epoch 1/250 completed in 90.85s - Train Loss: 7.0523, Train Acc: 0.065, Val Loss: 6.7201, Val Acc: 0.118
2025-10-02 21:38:34,136 - training.trainer - INFO - New best model saved with validation loss: 6.7201
2025-10-02 21:38:34,137 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-02 21:39:12,532 - training.trainer - INFO - Epoch 1, Step 311: Loss=6.6311, Acc=0.103, 
2025-10-02 21:39:49,287 - training.trainer - INFO - Epoch 1, Step 411: Loss=6.7152, Acc=0.125, 
2025-10-02 21:40:04,294 - training.trainer - INFO - Epoch 2/250 completed in 90.16s - Train Loss: 6.6694, Train Acc: 0.113, Val Loss: 6.6680, Val Acc: 0.117
2025-10-02 21:40:04,974 - training.trainer - INFO - New best model saved with validation loss: 6.6680
2025-10-02 21:40:04,975 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-02 21:40:43,134 - training.trainer - INFO - Epoch 2, Step 523: Loss=6.6583, Acc=0.109, 
2025-10-02 21:41:19,287 - training.trainer - INFO - Epoch 2, Step 623: Loss=6.6319, Acc=0.121, 
2025-10-02 21:41:34,946 - training.trainer - INFO - Epoch 3/250 completed in 89.97s - Train Loss: 6.6258, Train Acc: 0.114, Val Loss: 6.6728, Val Acc: 0.116
2025-10-02 21:42:13,130 - training.trainer - INFO - Epoch 3, Step 735: Loss=6.7109, Acc=0.114, 
2025-10-02 21:42:50,880 - training.trainer - INFO - Epoch 3, Step 835: Loss=6.6455, Acc=0.101, 
2025-10-02 21:43:06,116 - training.trainer - INFO - Epoch 4/250 completed in 91.17s - Train Loss: 6.6024, Train Acc: 0.115, Val Loss: 6.6706, Val Acc: 0.116
2025-10-02 21:43:44,182 - training.trainer - INFO - Epoch 4, Step 947: Loss=6.4501, Acc=0.125, 
2025-10-02 21:44:20,353 - training.trainer - INFO - Epoch 4, Step 1047: Loss=6.6122, Acc=0.123, 
2025-10-02 21:44:34,306 - training.trainer - INFO - Epoch 5/250 completed in 88.19s - Train Loss: 6.5913, Train Acc: 0.114, Val Loss: 6.6513, Val Acc: 0.114
2025-10-02 21:44:34,687 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-02 21:44:35,394 - training.trainer - INFO - New best model saved with validation loss: 6.6513
2025-10-02 21:44:35,394 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-02 21:45:14,008 - training.trainer - INFO - Epoch 5, Step 1159: Loss=6.6160, Acc=0.106, 
2025-10-02 21:45:51,970 - training.trainer - INFO - Epoch 5, Step 1259: Loss=6.5123, Acc=0.133, 
2025-10-02 21:46:06,641 - training.trainer - INFO - Epoch 6/250 completed in 91.25s - Train Loss: 6.6042, Train Acc: 0.111, Val Loss: 6.6703, Val Acc: 0.118
2025-10-02 21:46:44,601 - training.trainer - INFO - Epoch 6, Step 1371: Loss=6.5809, Acc=0.122, 
2025-10-02 21:47:20,947 - training.trainer - INFO - Epoch 6, Step 1471: Loss=6.6783, Acc=0.078, 
2025-10-02 21:47:36,348 - training.trainer - INFO - Epoch 7/250 completed in 89.71s - Train Loss: 6.6196, Train Acc: 0.103, Val Loss: 6.7393, Val Acc: 0.092
2025-10-02 21:48:14,239 - training.trainer - INFO - Epoch 7, Step 1583: Loss=6.5362, Acc=0.078, 
2025-10-02 21:48:52,239 - training.trainer - INFO - Epoch 7, Step 1683: Loss=6.6655, Acc=0.072, 
2025-10-02 21:49:06,643 - training.trainer - INFO - Epoch 8/250 completed in 90.29s - Train Loss: 6.6396, Train Acc: 0.087, Val Loss: 6.7333, Val Acc: 0.089
2025-10-02 21:49:43,967 - training.trainer - INFO - Epoch 8, Step 1795: Loss=6.6038, Acc=0.125, 
2025-10-02 21:50:21,576 - training.trainer - INFO - Epoch 8, Step 1895: Loss=6.5860, Acc=0.118, 
2025-10-02 21:50:38,075 - training.trainer - INFO - Epoch 9/250 completed in 91.43s - Train Loss: 6.5631, Train Acc: 0.113, Val Loss: 6.7585, Val Acc: 0.092
2025-10-02 21:51:16,977 - training.trainer - INFO - Epoch 9, Step 2007: Loss=6.5460, Acc=0.126, 
2025-10-02 21:51:53,742 - training.trainer - INFO - Epoch 9, Step 2107: Loss=6.6600, Acc=0.107, 
2025-10-02 21:52:08,707 - training.trainer - INFO - Epoch 10/250 completed in 90.63s - Train Loss: 6.5606, Train Acc: 0.105, Val Loss: 6.8168, Val Acc: 0.068
2025-10-02 21:52:09,087 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-02 21:52:47,564 - training.trainer - INFO - Epoch 10, Step 2219: Loss=6.5644, Acc=0.053, 
2025-10-02 21:53:25,791 - training.trainer - INFO - Epoch 10, Step 2319: Loss=6.7030, Acc=0.083, 
2025-10-02 21:53:41,437 - training.trainer - INFO - Epoch 11/250 completed in 92.35s - Train Loss: 6.6349, Train Acc: 0.077, Val Loss: 7.2688, Val Acc: 0.035
2025-10-02 21:54:20,849 - training.trainer - INFO - Epoch 11, Step 2431: Loss=6.5925, Acc=0.072, 
2025-10-02 21:54:58,344 - training.trainer - INFO - Epoch 11, Step 2531: Loss=6.5362, Acc=0.075, 
2025-10-02 21:55:13,411 - training.trainer - INFO - Epoch 12/250 completed in 91.97s - Train Loss: 6.5974, Train Acc: 0.081, Val Loss: 7.2708, Val Acc: 0.030
2025-10-02 21:55:52,568 - training.trainer - INFO - Epoch 12, Step 2643: Loss=6.5878, Acc=0.064, 
2025-10-02 21:56:28,329 - training.trainer - INFO - Epoch 12, Step 2743: Loss=6.6631, Acc=0.090, 
2025-10-02 21:56:43,055 - training.trainer - INFO - Epoch 13/250 completed in 89.64s - Train Loss: 6.5771, Train Acc: 0.082, Val Loss: 7.3806, Val Acc: 0.022
2025-10-02 21:57:20,804 - training.trainer - INFO - Epoch 13, Step 2855: Loss=6.4995, Acc=0.087, 
2025-10-02 21:57:58,189 - training.trainer - INFO - Epoch 13, Step 2955: Loss=6.4913, Acc=0.105, 
2025-10-02 21:58:12,124 - training.trainer - INFO - Epoch 14/250 completed in 89.07s - Train Loss: 6.5565, Train Acc: 0.084, Val Loss: 7.3705, Val Acc: 0.020
2025-10-02 21:58:50,244 - training.trainer - INFO - Epoch 14, Step 3067: Loss=6.5899, Acc=0.086, 
2025-10-02 21:59:27,738 - training.trainer - INFO - Epoch 14, Step 3167: Loss=6.4971, Acc=0.077, 
2025-10-02 21:59:42,710 - training.trainer - INFO - Epoch 15/250 completed in 90.59s - Train Loss: 6.5374, Train Acc: 0.084, Val Loss: 7.4058, Val Acc: 0.021
2025-10-02 21:59:43,041 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-02 22:00:21,789 - training.trainer - INFO - Epoch 15, Step 3279: Loss=6.4560, Acc=0.087, 
2025-10-02 22:00:59,101 - training.trainer - INFO - Epoch 15, Step 3379: Loss=6.5068, Acc=0.078, 
2025-10-02 22:01:13,879 - training.trainer - INFO - Epoch 16/250 completed in 90.84s - Train Loss: 6.5226, Train Acc: 0.085, Val Loss: 7.4630, Val Acc: 0.022
2025-10-02 22:01:53,604 - training.trainer - INFO - Epoch 16, Step 3491: Loss=6.3897, Acc=0.079, 
2025-10-02 22:02:30,501 - training.trainer - INFO - Epoch 16, Step 3591: Loss=6.5137, Acc=0.091, 
2025-10-02 22:02:45,987 - training.trainer - INFO - Epoch 17/250 completed in 92.11s - Train Loss: 6.5061, Train Acc: 0.085, Val Loss: 7.4034, Val Acc: 0.023
2025-10-02 22:03:24,149 - training.trainer - INFO - Epoch 17, Step 3703: Loss=6.4926, Acc=0.096, 
2025-10-02 22:04:01,059 - training.trainer - INFO - Epoch 17, Step 3803: Loss=6.5229, Acc=0.080, 
2025-10-02 22:04:16,063 - training.trainer - INFO - Epoch 18/250 completed in 90.08s - Train Loss: 6.4915, Train Acc: 0.086, Val Loss: 7.4787, Val Acc: 0.024
2025-10-02 22:04:53,890 - training.trainer - INFO - Epoch 18, Step 3915: Loss=6.4448, Acc=0.102, 
2025-10-02 22:05:30,816 - training.trainer - INFO - Epoch 18, Step 4015: Loss=6.4165, Acc=0.097, 
2025-10-02 22:05:45,518 - training.trainer - INFO - Epoch 19/250 completed in 89.45s - Train Loss: 6.4714, Train Acc: 0.088, Val Loss: 7.4545, Val Acc: 0.023
2025-10-02 22:06:23,311 - training.trainer - INFO - Epoch 19, Step 4127: Loss=6.4452, Acc=0.068, 
2025-10-02 22:07:00,833 - training.trainer - INFO - Epoch 19, Step 4227: Loss=6.4808, Acc=0.076, 
2025-10-02 22:07:14,872 - training.trainer - INFO - Epoch 20/250 completed in 89.35s - Train Loss: 6.4552, Train Acc: 0.087, Val Loss: 7.4404, Val Acc: 0.021
2025-10-02 22:07:15,223 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-02 22:07:15,224 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-02 22:07:15,224 - training.trainer - INFO - Training completed!
2025-10-02 22:07:15,224 - __main__ - INFO - Training completed successfully!
2025-10-02 22:07:15,344 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-02 22:07:15,365 - __main__ - INFO - Process completed!
2025-10-02 22:07:23,573 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-02 22:07:23,574 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-02 22:07:23,574 - __main__ - INFO - Starting model evaluation
2025-10-02 22:07:24,360 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-02 22:18:36,164 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-02 22:18:36,175 - __main__ - INFO - Process completed!
2025-10-02 22:18:43,210 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-10-02 22:18:43,211 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-02 22:18:43,211 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-10-02 22:18:43,868 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-02 22:19:02,406 - __main__ - INFO - Inference completed successfully!
2025-10-02 22:19:02,415 - __main__ - INFO - Process completed!
2025-10-02 22:22:20,041 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-02 22:22:20,041 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-02 22:22:20,041 - __main__ - INFO - Starting model evaluation
2025-10-02 22:22:20,552 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-02 22:33:37,659 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-02 22:33:37,675 - __main__ - INFO - Process completed!
2025-10-02 22:54:04,880 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-02 22:54:04,881 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-02 22:54:04,881 - __main__ - INFO - Starting training pipeline
2025-10-02 22:54:04,980 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-02 22:54:05,001 - __main__ - INFO - GPU: NVIDIA A30
2025-10-02 22:54:05,002 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-02 22:54:05,002 - __main__ - INFO - Loading training data...
2025-10-02 22:54:12,470 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-02 22:54:12,471 - __main__ - INFO - Processing train split...
2025-10-02 22:54:12,555 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-02 22:54:12,555 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-02 22:54:53,188 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-02 22:55:34,001 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-02 22:56:14,821 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-02 22:56:54,526 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-02 22:57:32,589 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-02 22:57:32,589 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-02 22:57:32,589 - __main__ - INFO - Starting training pipeline
2025-10-02 22:57:32,694 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-02 22:57:32,717 - __main__ - INFO - GPU: NVIDIA A30
2025-10-02 22:57:32,717 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-02 22:57:32,717 - __main__ - INFO - Loading training data...
2025-10-02 22:57:40,175 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-02 22:57:40,175 - __main__ - INFO - Processing train split...
2025-10-02 22:57:40,259 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-02 22:57:40,260 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-02 22:58:20,302 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-02 22:59:00,713 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-02 22:59:41,257 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-02 23:00:20,741 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-02 23:01:00,227 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-02 23:01:38,420 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-02 23:02:08,191 - __main__ - INFO - Processing val split...
2025-10-02 23:02:08,408 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-02 23:02:08,408 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-02 23:02:40,678 - __main__ - INFO - Processing test split...
2025-10-02 23:02:40,896 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-02 23:02:40,896 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-02 23:03:13,534 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-02 23:03:13,535 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-02 23:03:13,550 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-02 23:03:13,550 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-02 23:03:13,550 - __main__ - INFO - Creating model architecture...
2025-10-02 23:03:13,881 - __main__ - INFO - Model created successfully
2025-10-02 23:03:13,882 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-02 23:03:13,882 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-02 23:03:13,882 - __main__ - INFO - Using device: cuda
2025-10-02 23:03:13,882 - __main__ - INFO - Creating trainer...
2025-10-02 23:03:13,882 - __main__ - INFO - Moving model to cuda...
2025-10-02 23:03:14,181 - __main__ - INFO - Model moved to cuda
2025-10-02 23:03:14,181 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-02 23:03:15,148 - __main__ - INFO - Trainer created successfully
2025-10-02 23:03:15,148 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-02 23:03:15,148 - __main__ - INFO - Starting training...
2025-10-02 23:03:15,148 - __main__ - INFO - Training configuration:
2025-10-02 23:03:15,148 - __main__ - INFO -   - Epochs: 1000
2025-10-02 23:03:15,148 - __main__ - INFO -   - Batch size: 32
2025-10-02 23:03:15,148 - __main__ - INFO -   - Learning rate: 1e-4
2025-10-02 23:03:15,148 - __main__ - INFO -   - Training samples: 6765
2025-10-02 23:03:15,148 - __main__ - INFO -   - Validation samples: 845
2025-10-02 23:03:15,148 - training.trainer - INFO - Starting training for 1000 epochs
2025-10-02 23:03:15,149 - training.trainer - INFO - Model parameters: 16,680,032
2025-10-02 23:03:15,149 - training.trainer - INFO - Training on device: cuda
2025-10-02 23:03:53,599 - training.trainer - INFO - Epoch 0, Step 99: Loss=7.5546, Acc=0.059, 
2025-10-02 23:04:29,394 - training.trainer - INFO - Epoch 0, Step 199: Loss=6.7754, Acc=0.143, 
2025-10-02 23:04:44,982 - training.trainer - INFO - Epoch 1/1000 completed in 89.83s - Train Loss: 7.6217, Train Acc: 0.085, Val Loss: 6.7010, Val Acc: 0.131
2025-10-02 23:04:45,675 - training.trainer - INFO - New best model saved with validation loss: 6.7010
2025-10-02 23:04:45,675 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-02 23:05:25,068 - training.trainer - INFO - Epoch 1, Step 311: Loss=6.5013, Acc=0.161, 
2025-10-02 23:06:03,591 - training.trainer - INFO - Epoch 1, Step 411: Loss=6.2687, Acc=0.168, 
2025-10-02 23:06:18,505 - training.trainer - INFO - Epoch 2/1000 completed in 92.83s - Train Loss: 6.5624, Train Acc: 0.143, Val Loss: 6.4099, Val Acc: 0.161
2025-10-02 23:06:19,239 - training.trainer - INFO - New best model saved with validation loss: 6.4099
2025-10-02 23:06:19,239 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-02 23:06:58,560 - training.trainer - INFO - Epoch 2, Step 523: Loss=6.1564, Acc=0.169, 
2025-10-02 23:07:35,207 - training.trainer - INFO - Epoch 2, Step 623: Loss=6.2901, Acc=0.162, 
2025-10-02 23:07:50,136 - training.trainer - INFO - Epoch 3/1000 completed in 90.90s - Train Loss: 6.3191, Train Acc: 0.160, Val Loss: 6.2616, Val Acc: 0.165
2025-10-02 23:07:50,736 - training.trainer - INFO - New best model saved with validation loss: 6.2616
2025-10-02 23:07:50,736 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-10-02 23:08:29,196 - training.trainer - INFO - Epoch 3, Step 735: Loss=6.2232, Acc=0.149, 
2025-10-02 23:09:06,932 - training.trainer - INFO - Epoch 3, Step 835: Loss=6.1242, Acc=0.194, 
2025-10-02 23:09:21,886 - training.trainer - INFO - Epoch 4/1000 completed in 91.15s - Train Loss: 6.1644, Train Acc: 0.170, Val Loss: 6.1377, Val Acc: 0.176
2025-10-02 23:09:22,671 - training.trainer - INFO - New best model saved with validation loss: 6.1377
2025-10-02 23:09:22,671 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-10-02 23:10:01,308 - training.trainer - INFO - Epoch 4, Step 947: Loss=6.0144, Acc=0.160, 
2025-10-02 23:10:38,360 - training.trainer - INFO - Epoch 4, Step 1047: Loss=6.0116, Acc=0.173, 
2025-10-02 23:10:52,215 - training.trainer - INFO - Epoch 5/1000 completed in 89.54s - Train Loss: 6.0477, Train Acc: 0.178, Val Loss: 6.0501, Val Acc: 0.184
2025-10-02 23:10:52,602 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-02 23:10:53,387 - training.trainer - INFO - New best model saved with validation loss: 6.0501
2025-10-02 23:10:53,387 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-02 23:11:31,774 - training.trainer - INFO - Epoch 5, Step 1159: Loss=6.0405, Acc=0.161, 
2025-10-02 23:12:08,605 - training.trainer - INFO - Epoch 5, Step 1259: Loss=5.9741, Acc=0.182, 
2025-10-02 23:12:23,309 - training.trainer - INFO - Epoch 6/1000 completed in 89.92s - Train Loss: 5.9521, Train Acc: 0.189, Val Loss: 6.0041, Val Acc: 0.189
2025-10-02 23:12:23,925 - training.trainer - INFO - New best model saved with validation loss: 6.0041
2025-10-02 23:12:23,925 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-10-02 23:13:03,175 - training.trainer - INFO - Epoch 6, Step 1371: Loss=5.9363, Acc=0.185, 
2025-10-02 23:13:41,020 - training.trainer - INFO - Epoch 6, Step 1471: Loss=6.0257, Acc=0.186, 
2025-10-02 23:13:55,516 - training.trainer - INFO - Epoch 7/1000 completed in 91.59s - Train Loss: 5.8655, Train Acc: 0.198, Val Loss: 5.9155, Val Acc: 0.200
2025-10-02 23:13:56,142 - training.trainer - INFO - New best model saved with validation loss: 5.9155
2025-10-02 23:13:56,142 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-10-02 23:14:34,945 - training.trainer - INFO - Epoch 7, Step 1583: Loss=5.6587, Acc=0.205, 
2025-10-02 23:15:12,716 - training.trainer - INFO - Epoch 7, Step 1683: Loss=5.9516, Acc=0.189, 
2025-10-02 23:15:27,169 - training.trainer - INFO - Epoch 8/1000 completed in 91.03s - Train Loss: 5.7846, Train Acc: 0.207, Val Loss: 5.8591, Val Acc: 0.209
2025-10-02 23:15:27,765 - training.trainer - INFO - New best model saved with validation loss: 5.8591
2025-10-02 23:15:27,765 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-10-02 23:16:05,791 - training.trainer - INFO - Epoch 8, Step 1795: Loss=5.6962, Acc=0.194, 
2025-10-02 23:16:42,432 - training.trainer - INFO - Epoch 8, Step 1895: Loss=5.5822, Acc=0.208, 
2025-10-02 23:16:57,785 - training.trainer - INFO - Epoch 9/1000 completed in 90.02s - Train Loss: 5.7122, Train Acc: 0.213, Val Loss: 5.8065, Val Acc: 0.215
2025-10-02 23:16:58,618 - training.trainer - INFO - New best model saved with validation loss: 5.8065
2025-10-02 23:16:58,619 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-10-02 23:17:37,326 - training.trainer - INFO - Epoch 9, Step 2007: Loss=5.6476, Acc=0.225, 
2025-10-02 23:18:15,132 - training.trainer - INFO - Epoch 9, Step 2107: Loss=5.7656, Acc=0.222, 
2025-10-02 23:18:29,316 - training.trainer - INFO - Epoch 10/1000 completed in 90.70s - Train Loss: 5.6436, Train Acc: 0.219, Val Loss: 5.7769, Val Acc: 0.216
2025-10-02 23:18:29,644 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-02 23:18:30,446 - training.trainer - INFO - New best model saved with validation loss: 5.7769
2025-10-02 23:18:30,446 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-02 23:19:10,704 - training.trainer - INFO - Epoch 10, Step 2219: Loss=5.8195, Acc=0.200, 
2025-10-02 23:19:47,123 - training.trainer - INFO - Epoch 10, Step 2319: Loss=5.6193, Acc=0.239, 
2025-10-02 23:20:01,742 - training.trainer - INFO - Epoch 11/1000 completed in 91.30s - Train Loss: 5.5858, Train Acc: 0.224, Val Loss: 5.7368, Val Acc: 0.221
2025-10-02 23:20:02,312 - training.trainer - INFO - New best model saved with validation loss: 5.7368
2025-10-02 23:20:02,312 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-10-02 23:20:41,639 - training.trainer - INFO - Epoch 11, Step 2431: Loss=5.5678, Acc=0.220, 
2025-10-02 23:21:19,117 - training.trainer - INFO - Epoch 11, Step 2531: Loss=5.5275, Acc=0.218, 
2025-10-02 23:21:33,730 - training.trainer - INFO - Epoch 12/1000 completed in 91.42s - Train Loss: 5.5336, Train Acc: 0.229, Val Loss: 5.7235, Val Acc: 0.221
2025-10-02 23:21:34,485 - training.trainer - INFO - New best model saved with validation loss: 5.7235
2025-10-02 23:21:34,485 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-10-02 23:22:13,432 - training.trainer - INFO - Epoch 12, Step 2643: Loss=5.1979, Acc=0.269, 
2025-10-02 23:22:50,923 - training.trainer - INFO - Epoch 12, Step 2743: Loss=5.3905, Acc=0.248, 
2025-10-02 23:23:05,827 - training.trainer - INFO - Epoch 13/1000 completed in 91.34s - Train Loss: 5.4860, Train Acc: 0.233, Val Loss: 5.6802, Val Acc: 0.224
2025-10-02 23:23:06,418 - training.trainer - INFO - New best model saved with validation loss: 5.6802
2025-10-02 23:23:06,419 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-10-02 23:23:45,137 - training.trainer - INFO - Epoch 13, Step 2855: Loss=5.5570, Acc=0.224, 
2025-10-02 23:24:21,924 - training.trainer - INFO - Epoch 13, Step 2955: Loss=5.6998, Acc=0.208, 
2025-10-02 23:24:37,252 - training.trainer - INFO - Epoch 14/1000 completed in 90.83s - Train Loss: 5.4377, Train Acc: 0.237, Val Loss: 5.6794, Val Acc: 0.227
2025-10-02 23:24:38,129 - training.trainer - INFO - New best model saved with validation loss: 5.6794
2025-10-02 23:24:38,130 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-10-02 23:25:16,817 - training.trainer - INFO - Epoch 14, Step 3067: Loss=5.3527, Acc=0.247, 
2025-10-02 23:25:54,216 - training.trainer - INFO - Epoch 14, Step 3167: Loss=5.4035, Acc=0.252, 
2025-10-02 23:26:08,680 - training.trainer - INFO - Epoch 15/1000 completed in 90.55s - Train Loss: 5.3937, Train Acc: 0.241, Val Loss: 5.6433, Val Acc: 0.232
2025-10-02 23:26:09,046 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-02 23:26:09,774 - training.trainer - INFO - New best model saved with validation loss: 5.6433
2025-10-02 23:26:09,775 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-02 23:26:49,730 - training.trainer - INFO - Epoch 15, Step 3279: Loss=5.3286, Acc=0.240, 
2025-10-02 23:27:26,376 - training.trainer - INFO - Epoch 15, Step 3379: Loss=5.3781, Acc=0.216, 
2025-10-02 23:27:41,201 - training.trainer - INFO - Epoch 16/1000 completed in 91.43s - Train Loss: 5.3473, Train Acc: 0.245, Val Loss: 5.6267, Val Acc: 0.231
2025-10-02 23:27:41,945 - training.trainer - INFO - New best model saved with validation loss: 5.6267
2025-10-02 23:27:41,945 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-10-02 23:28:20,111 - training.trainer - INFO - Epoch 16, Step 3491: Loss=5.0697, Acc=0.275, 
2025-10-02 23:28:58,017 - training.trainer - INFO - Epoch 16, Step 3591: Loss=5.2018, Acc=0.275, 
2025-10-02 23:29:13,274 - training.trainer - INFO - Epoch 17/1000 completed in 91.33s - Train Loss: 5.3093, Train Acc: 0.249, Val Loss: 5.6239, Val Acc: 0.232
2025-10-02 23:29:13,932 - training.trainer - INFO - New best model saved with validation loss: 5.6239
2025-10-02 23:29:13,932 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-10-02 23:29:53,687 - training.trainer - INFO - Epoch 17, Step 3703: Loss=5.3076, Acc=0.246, 
2025-10-02 23:30:30,791 - training.trainer - INFO - Epoch 17, Step 3803: Loss=5.3115, Acc=0.236, 
2025-10-02 23:30:45,000 - training.trainer - INFO - Epoch 18/1000 completed in 91.07s - Train Loss: 5.2689, Train Acc: 0.253, Val Loss: 5.6172, Val Acc: 0.235
2025-10-02 23:30:45,607 - training.trainer - INFO - New best model saved with validation loss: 5.6172
2025-10-02 23:30:45,607 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-10-02 23:31:27,966 - training.trainer - INFO - Epoch 18, Step 3915: Loss=5.3926, Acc=0.235, 
2025-10-02 23:32:05,596 - training.trainer - INFO - Epoch 18, Step 4015: Loss=5.2733, Acc=0.258, 
2025-10-02 23:32:22,602 - training.trainer - INFO - Epoch 19/1000 completed in 96.99s - Train Loss: 5.2287, Train Acc: 0.257, Val Loss: 5.5915, Val Acc: 0.235
2025-10-02 23:32:23,376 - training.trainer - INFO - New best model saved with validation loss: 5.5915
2025-10-02 23:32:23,376 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-10-02 23:33:06,099 - training.trainer - INFO - Epoch 19, Step 4127: Loss=5.3080, Acc=0.276, 
2025-10-02 23:33:48,199 - training.trainer - INFO - Epoch 19, Step 4227: Loss=5.4303, Acc=0.212, 
2025-10-02 23:34:03,411 - training.trainer - INFO - Epoch 20/1000 completed in 100.03s - Train Loss: 5.1886, Train Acc: 0.261, Val Loss: 5.5785, Val Acc: 0.238
2025-10-02 23:34:03,695 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-02 23:34:04,250 - training.trainer - INFO - New best model saved with validation loss: 5.5785
2025-10-02 23:34:04,250 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-02 23:34:46,544 - training.trainer - INFO - Epoch 20, Step 4339: Loss=5.1098, Acc=0.236, 
2025-10-02 23:35:25,236 - training.trainer - INFO - Epoch 20, Step 4439: Loss=5.0493, Acc=0.262, 
2025-10-02 23:35:39,830 - training.trainer - INFO - Epoch 21/1000 completed in 95.58s - Train Loss: 5.1519, Train Acc: 0.264, Val Loss: 5.5787, Val Acc: 0.237
2025-10-02 23:36:18,616 - training.trainer - INFO - Epoch 21, Step 4551: Loss=5.1060, Acc=0.280, 
2025-10-02 23:36:56,303 - training.trainer - INFO - Epoch 21, Step 4651: Loss=5.1846, Acc=0.266, 
2025-10-02 23:37:10,619 - training.trainer - INFO - Epoch 22/1000 completed in 90.79s - Train Loss: 5.1129, Train Acc: 0.268, Val Loss: 5.5633, Val Acc: 0.241
2025-10-02 23:37:11,388 - training.trainer - INFO - New best model saved with validation loss: 5.5633
2025-10-02 23:37:11,388 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-10-02 23:37:50,591 - training.trainer - INFO - Epoch 22, Step 4763: Loss=5.0216, Acc=0.272, 
2025-10-02 23:38:27,873 - training.trainer - INFO - Epoch 22, Step 4863: Loss=5.1132, Acc=0.273, 
2025-10-02 23:38:43,140 - training.trainer - INFO - Epoch 23/1000 completed in 91.75s - Train Loss: 5.0840, Train Acc: 0.271, Val Loss: 5.5581, Val Acc: 0.240
2025-10-02 23:38:43,932 - training.trainer - INFO - New best model saved with validation loss: 5.5581
2025-10-02 23:38:43,933 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-10-02 23:39:24,125 - training.trainer - INFO - Epoch 23, Step 4975: Loss=5.1502, Acc=0.266, 
2025-10-02 23:40:00,789 - training.trainer - INFO - Epoch 23, Step 5075: Loss=4.9389, Acc=0.272, 
2025-10-02 23:40:15,112 - training.trainer - INFO - Epoch 24/1000 completed in 91.18s - Train Loss: 5.0429, Train Acc: 0.275, Val Loss: 5.5563, Val Acc: 0.243
2025-10-02 23:40:15,826 - training.trainer - INFO - New best model saved with validation loss: 5.5563
2025-10-02 23:40:15,826 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-10-02 23:40:56,511 - training.trainer - INFO - Epoch 24, Step 5187: Loss=5.0464, Acc=0.271, 
2025-10-02 23:41:32,664 - training.trainer - INFO - Epoch 24, Step 5287: Loss=4.8957, Acc=0.291, 
2025-10-02 23:41:47,272 - training.trainer - INFO - Epoch 25/1000 completed in 91.45s - Train Loss: 5.0082, Train Acc: 0.278, Val Loss: 5.5335, Val Acc: 0.243
2025-10-02 23:41:47,660 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-02 23:41:48,503 - training.trainer - INFO - New best model saved with validation loss: 5.5335
2025-10-02 23:41:48,504 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-02 23:42:26,543 - training.trainer - INFO - Epoch 25, Step 5399: Loss=4.8390, Acc=0.302, 
2025-10-02 23:43:05,748 - training.trainer - INFO - Epoch 25, Step 5499: Loss=4.9034, Acc=0.293, 
2025-10-02 23:43:20,271 - training.trainer - INFO - Epoch 26/1000 completed in 91.77s - Train Loss: 4.9747, Train Acc: 0.282, Val Loss: 5.5291, Val Acc: 0.243
2025-10-02 23:43:20,849 - training.trainer - INFO - New best model saved with validation loss: 5.5291
2025-10-02 23:43:20,850 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_26.pt
2025-10-02 23:43:59,711 - training.trainer - INFO - Epoch 26, Step 5611: Loss=5.0241, Acc=0.266, 
2025-10-02 23:44:37,969 - training.trainer - INFO - Epoch 26, Step 5711: Loss=4.9481, Acc=0.288, 
2025-10-02 23:44:53,157 - training.trainer - INFO - Epoch 27/1000 completed in 92.31s - Train Loss: 4.9424, Train Acc: 0.285, Val Loss: 5.5216, Val Acc: 0.247
2025-10-02 23:44:53,875 - training.trainer - INFO - New best model saved with validation loss: 5.5216
2025-10-02 23:44:53,876 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_27.pt
2025-10-02 23:45:32,064 - training.trainer - INFO - Epoch 27, Step 5823: Loss=5.1567, Acc=0.265, 
2025-10-02 23:46:09,779 - training.trainer - INFO - Epoch 27, Step 5923: Loss=5.0863, Acc=0.275, 
2025-10-02 23:46:24,871 - training.trainer - INFO - Epoch 28/1000 completed in 90.99s - Train Loss: 4.9088, Train Acc: 0.289, Val Loss: 5.5279, Val Acc: 0.247
2025-10-02 23:47:09,299 - training.trainer - INFO - Epoch 28, Step 6035: Loss=5.0378, Acc=0.271, 
2025-10-02 23:47:50,194 - training.trainer - INFO - Epoch 28, Step 6135: Loss=4.8310, Acc=0.313, 
2025-10-02 23:48:05,291 - training.trainer - INFO - Epoch 29/1000 completed in 100.42s - Train Loss: 4.8724, Train Acc: 0.292, Val Loss: 5.5291, Val Acc: 0.246
2025-10-02 23:48:44,373 - training.trainer - INFO - Epoch 29, Step 6247: Loss=4.8734, Acc=0.276, 
2025-10-02 23:49:26,761 - training.trainer - INFO - Epoch 29, Step 6347: Loss=4.8186, Acc=0.290, 
2025-10-02 23:49:42,829 - training.trainer - INFO - Epoch 30/1000 completed in 97.54s - Train Loss: 4.8419, Train Acc: 0.295, Val Loss: 5.5235, Val Acc: 0.244
2025-10-02 23:49:43,256 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-10-02 23:50:23,549 - training.trainer - INFO - Epoch 30, Step 6459: Loss=4.9225, Acc=0.284, 
2025-10-02 23:51:03,953 - training.trainer - INFO - Epoch 30, Step 6559: Loss=4.9599, Acc=0.280, 
2025-10-02 23:51:20,637 - training.trainer - INFO - Epoch 31/1000 completed in 97.38s - Train Loss: 4.8101, Train Acc: 0.298, Val Loss: 5.5293, Val Acc: 0.249
2025-10-02 23:52:01,490 - training.trainer - INFO - Epoch 31, Step 6671: Loss=4.7780, Acc=0.306, 
2025-10-02 23:52:41,689 - training.trainer - INFO - Epoch 31, Step 6771: Loss=4.6847, Acc=0.309, 
2025-10-02 23:52:56,828 - training.trainer - INFO - Epoch 32/1000 completed in 96.19s - Train Loss: 4.7790, Train Acc: 0.301, Val Loss: 5.5172, Val Acc: 0.246
2025-10-02 23:52:57,502 - training.trainer - INFO - New best model saved with validation loss: 5.5172
2025-10-02 23:52:57,502 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_32.pt
2025-10-02 23:53:40,743 - training.trainer - INFO - Epoch 32, Step 6883: Loss=4.9119, Acc=0.284, 
2025-10-02 23:54:21,566 - training.trainer - INFO - Epoch 32, Step 6983: Loss=4.6020, Acc=0.300, 
2025-10-02 23:54:38,308 - training.trainer - INFO - Epoch 33/1000 completed in 100.81s - Train Loss: 4.7484, Train Acc: 0.305, Val Loss: 5.5312, Val Acc: 0.247
2025-10-02 23:55:18,073 - training.trainer - INFO - Epoch 33, Step 7095: Loss=4.6187, Acc=0.311, 
2025-10-02 23:56:01,107 - training.trainer - INFO - Epoch 33, Step 7195: Loss=4.7746, Acc=0.318, 
2025-10-02 23:56:17,801 - training.trainer - INFO - Epoch 34/1000 completed in 99.49s - Train Loss: 4.7138, Train Acc: 0.310, Val Loss: 5.5221, Val Acc: 0.249
2025-10-02 23:56:59,716 - training.trainer - INFO - Epoch 34, Step 7307: Loss=4.7174, Acc=0.288, 
2025-10-02 23:57:40,196 - training.trainer - INFO - Epoch 34, Step 7407: Loss=4.4804, Acc=0.348, 
2025-10-02 23:57:56,704 - training.trainer - INFO - Epoch 35/1000 completed in 98.90s - Train Loss: 4.6823, Train Acc: 0.314, Val Loss: 5.5103, Val Acc: 0.251
2025-10-02 23:57:57,241 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-10-02 23:57:58,084 - training.trainer - INFO - New best model saved with validation loss: 5.5103
2025-10-02 23:57:58,085 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-10-02 23:58:40,947 - training.trainer - INFO - Epoch 35, Step 7519: Loss=4.7065, Acc=0.307, 
2025-10-02 23:59:22,235 - training.trainer - INFO - Epoch 35, Step 7619: Loss=4.6395, Acc=0.328, 
2025-10-02 23:59:38,659 - training.trainer - INFO - Epoch 36/1000 completed in 100.57s - Train Loss: 4.6541, Train Acc: 0.315, Val Loss: 5.5170, Val Acc: 0.250
2025-10-03 00:00:21,454 - training.trainer - INFO - Epoch 36, Step 7731: Loss=4.8312, Acc=0.282, 
2025-10-03 00:01:00,899 - training.trainer - INFO - Epoch 36, Step 7831: Loss=4.8109, Acc=0.289, 
2025-10-03 00:01:21,658 - training.trainer - INFO - Epoch 37/1000 completed in 103.00s - Train Loss: 4.6257, Train Acc: 0.319, Val Loss: 5.5193, Val Acc: 0.251
2025-10-03 00:02:26,793 - training.trainer - INFO - Epoch 37, Step 7943: Loss=4.5715, Acc=0.307, 
2025-10-03 00:03:30,170 - training.trainer - INFO - Epoch 37, Step 8043: Loss=4.3871, Acc=0.366, 
2025-10-03 00:03:56,223 - training.trainer - INFO - Epoch 38/1000 completed in 154.56s - Train Loss: 4.5989, Train Acc: 0.321, Val Loss: 5.5266, Val Acc: 0.250
2025-10-03 00:04:57,834 - training.trainer - INFO - Epoch 38, Step 8155: Loss=4.6135, Acc=0.322, 
2025-10-03 00:05:54,215 - training.trainer - INFO - Epoch 38, Step 8255: Loss=4.3917, Acc=0.346, 
2025-10-03 00:06:23,525 - training.trainer - INFO - Epoch 39/1000 completed in 147.30s - Train Loss: 4.5685, Train Acc: 0.325, Val Loss: 5.5287, Val Acc: 0.250
2025-10-03 00:07:31,664 - training.trainer - INFO - Epoch 39, Step 8367: Loss=4.6270, Acc=0.307, 
2025-10-03 00:08:33,550 - training.trainer - INFO - Epoch 39, Step 8467: Loss=4.4982, Acc=0.327, 
2025-10-03 00:08:58,784 - training.trainer - INFO - Epoch 40/1000 completed in 155.26s - Train Loss: 4.5421, Train Acc: 0.327, Val Loss: 5.5203, Val Acc: 0.252
2025-10-03 00:08:59,188 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-10-03 00:10:00,840 - training.trainer - INFO - Epoch 40, Step 8579: Loss=4.6161, Acc=0.331, 
2025-10-03 00:11:01,665 - training.trainer - INFO - Epoch 40, Step 8679: Loss=4.5645, Acc=0.333, 
2025-10-03 00:11:24,649 - training.trainer - INFO - Epoch 41/1000 completed in 145.46s - Train Loss: 4.5091, Train Acc: 0.332, Val Loss: 5.5230, Val Acc: 0.253
2025-10-03 00:12:21,536 - training.trainer - INFO - Epoch 41, Step 8791: Loss=4.6227, Acc=0.292, 
2025-10-03 00:13:09,351 - training.trainer - INFO - Epoch 41, Step 8891: Loss=4.7457, Acc=0.308, 
2025-10-03 00:13:27,235 - training.trainer - INFO - Epoch 42/1000 completed in 122.59s - Train Loss: 4.4853, Train Acc: 0.334, Val Loss: 5.5191, Val Acc: 0.251
2025-10-03 00:14:14,329 - training.trainer - INFO - Epoch 42, Step 9003: Loss=4.4390, Acc=0.337, 
2025-10-03 00:15:00,709 - training.trainer - INFO - Epoch 42, Step 9103: Loss=4.4786, Acc=0.335, 
2025-10-03 00:15:18,833 - training.trainer - INFO - Epoch 43/1000 completed in 111.60s - Train Loss: 4.4561, Train Acc: 0.338, Val Loss: 5.5292, Val Acc: 0.251
2025-10-03 00:16:02,423 - training.trainer - INFO - Epoch 43, Step 9215: Loss=4.5219, Acc=0.328, 
2025-10-03 00:16:40,677 - training.trainer - INFO - Epoch 43, Step 9315: Loss=4.4284, Acc=0.331, 
2025-10-03 00:16:55,684 - training.trainer - INFO - Epoch 44/1000 completed in 96.85s - Train Loss: 4.4320, Train Acc: 0.341, Val Loss: 5.5359, Val Acc: 0.253
2025-10-03 00:17:32,887 - training.trainer - INFO - Epoch 44, Step 9427: Loss=4.3377, Acc=0.336, 
2025-10-03 00:18:11,106 - training.trainer - INFO - Epoch 44, Step 9527: Loss=4.4430, Acc=0.338, 
2025-10-03 00:18:26,846 - training.trainer - INFO - Epoch 45/1000 completed in 91.16s - Train Loss: 4.4064, Train Acc: 0.345, Val Loss: 5.5345, Val Acc: 0.251
2025-10-03 00:18:27,232 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-10-03 00:19:08,196 - training.trainer - INFO - Epoch 45, Step 9639: Loss=4.4867, Acc=0.332, 
2025-10-03 00:19:46,676 - training.trainer - INFO - Epoch 45, Step 9739: Loss=4.4036, Acc=0.355, 
2025-10-03 00:20:01,136 - training.trainer - INFO - Epoch 46/1000 completed in 93.90s - Train Loss: 4.3810, Train Acc: 0.349, Val Loss: 5.5339, Val Acc: 0.252
2025-10-03 00:20:40,634 - training.trainer - INFO - Epoch 46, Step 9851: Loss=4.3834, Acc=0.333, 
2025-10-03 00:21:19,070 - training.trainer - INFO - Epoch 46, Step 9951: Loss=4.3529, Acc=0.352, 
2025-10-03 00:21:34,326 - training.trainer - INFO - Epoch 47/1000 completed in 93.19s - Train Loss: 4.3578, Train Acc: 0.349, Val Loss: 5.5535, Val Acc: 0.253
2025-10-03 00:22:13,323 - training.trainer - INFO - Epoch 47, Step 10063: Loss=4.3101, Acc=0.343, 
2025-10-03 00:22:51,733 - training.trainer - INFO - Epoch 47, Step 10163: Loss=4.3060, Acc=0.341, 
2025-10-03 00:23:07,536 - training.trainer - INFO - Epoch 48/1000 completed in 93.21s - Train Loss: 4.3325, Train Acc: 0.353, Val Loss: 5.5425, Val Acc: 0.253
2025-10-03 00:23:48,451 - training.trainer - INFO - Epoch 48, Step 10275: Loss=4.2343, Acc=0.369, 
2025-10-03 00:24:26,679 - training.trainer - INFO - Epoch 48, Step 10375: Loss=4.2508, Acc=0.356, 
2025-10-03 00:24:41,744 - training.trainer - INFO - Epoch 49/1000 completed in 94.21s - Train Loss: 4.3071, Train Acc: 0.355, Val Loss: 5.5506, Val Acc: 0.251
2025-10-03 00:25:20,795 - training.trainer - INFO - Epoch 49, Step 10487: Loss=4.2686, Acc=0.350, 
2025-10-03 00:25:59,147 - training.trainer - INFO - Epoch 49, Step 10587: Loss=4.3951, Acc=0.331, 
2025-10-03 00:26:14,750 - training.trainer - INFO - Epoch 50/1000 completed in 93.00s - Train Loss: 4.2866, Train Acc: 0.358, Val Loss: 5.5401, Val Acc: 0.253
2025-10-03 00:26:15,108 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-10-03 00:26:15,109 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-03 00:26:15,109 - training.trainer - INFO - Training completed!
2025-10-03 00:26:15,109 - __main__ - INFO - Training completed successfully!
2025-10-03 00:26:15,241 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-03 00:26:15,273 - __main__ - INFO - Process completed!
2025-10-03 00:26:28,963 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-03 00:26:28,963 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-03 00:26:28,963 - __main__ - INFO - Starting model evaluation
2025-10-03 00:26:30,147 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-03 00:36:11,319 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-03 00:36:11,335 - __main__ - INFO - Process completed!
2025-10-03 00:36:17,661 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-10-03 00:36:17,662 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-03 00:36:17,662 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-10-03 00:36:18,204 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-03 00:36:35,862 - __main__ - INFO - Inference completed successfully!
2025-10-03 00:36:35,868 - __main__ - INFO - Process completed!
2025-10-04 18:22:15,788 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-04 18:22:15,790 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-04 18:22:15,790 - __main__ - INFO - Starting training pipeline
2025-10-04 18:22:15,922 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-04 18:22:15,960 - __main__ - INFO - GPU: NVIDIA A30
2025-10-04 18:22:15,960 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-04 18:22:15,960 - __main__ - INFO - Loading training data...
2025-10-04 18:23:00,553 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-04 18:23:00,554 - __main__ - INFO - Processing train split...
2025-10-04 18:23:00,660 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-04 18:23:00,661 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-04 18:23:58,032 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-04 18:24:55,949 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-04 18:25:50,187 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-04 18:26:35,897 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-04 18:27:21,641 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-04 18:28:07,395 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-04 18:28:42,762 - __main__ - INFO - Processing val split...
2025-10-04 18:28:42,980 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-04 18:28:42,980 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-04 18:29:21,112 - __main__ - INFO - Processing test split...
2025-10-04 18:29:21,326 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-04 18:29:21,326 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-04 18:30:07,271 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-04 18:30:07,271 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-04 18:30:07,291 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-04 18:30:07,291 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-04 18:30:07,291 - __main__ - INFO - Creating model architecture...
2025-10-04 18:30:07,958 - __main__ - INFO - Model created successfully
2025-10-04 18:30:07,959 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-04 18:30:07,959 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-04 18:30:07,959 - __main__ - INFO - Using device: cuda
2025-10-04 18:30:07,959 - __main__ - INFO - Creating trainer...
2025-10-04 18:30:07,959 - __main__ - INFO - Moving model to cuda...
2025-10-04 18:30:08,479 - __main__ - INFO - Model moved to cuda
2025-10-04 18:30:08,480 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-04 18:30:11,029 - __main__ - INFO - Trainer created successfully
2025-10-04 18:30:11,029 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-04 18:30:11,029 - __main__ - INFO - Starting training...
2025-10-04 18:30:11,029 - __main__ - INFO - Training configuration:
2025-10-04 18:30:11,029 - __main__ - INFO -   - Epochs: 100
2025-10-04 18:30:11,029 - __main__ - INFO -   - Batch size: 2
2025-10-04 18:30:11,029 - __main__ - INFO -   - Learning rate: 1e-4
2025-10-04 18:30:11,030 - __main__ - INFO -   - Training samples: 6765
2025-10-04 18:30:11,030 - __main__ - INFO -   - Validation samples: 845
2025-10-04 18:30:11,030 - training.trainer - INFO - Starting training for 100 epochs
2025-10-04 18:30:11,030 - training.trainer - INFO - Model parameters: 16,680,032
2025-10-04 18:30:11,030 - training.trainer - INFO - Training on device: cuda
2025-10-04 18:30:24,278 - training.trainer - INFO - Epoch 0, Step 99: Loss=7.8358, Acc=0.067, 
2025-10-04 18:30:33,016 - training.trainer - INFO - Epoch 0, Step 199: Loss=7.1162, Acc=0.045, 
2025-10-04 18:30:41,454 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.0846, Acc=0.211, 
2025-10-04 18:30:49,859 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.1678, Acc=0.148, 
2025-10-04 18:30:58,025 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.9597, Acc=0.216, 
2025-10-04 18:31:06,249 - training.trainer - INFO - Epoch 0, Step 599: Loss=6.8875, Acc=0.098, 
2025-10-04 18:31:14,352 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.4082, Acc=0.167, 
2025-10-04 18:31:22,452 - training.trainer - INFO - Epoch 0, Step 799: Loss=7.0715, Acc=0.100, 
2025-10-04 18:31:30,375 - training.trainer - INFO - Epoch 0, Step 899: Loss=7.0056, Acc=0.159, 
2025-10-04 18:31:38,274 - training.trainer - INFO - Epoch 0, Step 999: Loss=6.7769, Acc=0.129, 
2025-10-04 18:31:46,418 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.8059, Acc=0.208, 
2025-10-04 18:31:54,303 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.5709, Acc=0.156, 
2025-10-04 18:32:02,142 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.1663, Acc=0.161, 
2025-10-04 18:32:09,817 - training.trainer - INFO - Epoch 0, Step 1399: Loss=6.5485, Acc=0.174, 
2025-10-04 18:32:17,609 - training.trainer - INFO - Epoch 0, Step 1499: Loss=6.3127, Acc=0.128, 
2025-10-04 18:32:25,307 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.3541, Acc=0.162, 
2025-10-04 18:32:33,024 - training.trainer - INFO - Epoch 0, Step 1699: Loss=5.4825, Acc=0.200, 
2025-10-04 18:32:40,704 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.1500, Acc=0.161, 
2025-10-04 18:32:48,422 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.5659, Acc=0.184, 
2025-10-04 18:32:56,113 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.6429, Acc=0.120, 
2025-10-04 18:33:03,842 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.0940, Acc=0.137, 
2025-10-04 18:33:11,544 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.8933, Acc=0.094, 
2025-10-04 18:33:19,198 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.2844, Acc=0.148, 
2025-10-04 18:33:26,833 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.5344, Acc=0.103, 
2025-10-04 18:33:34,568 - training.trainer - INFO - Epoch 0, Step 2499: Loss=5.9595, Acc=0.250, 
2025-10-04 18:33:42,215 - training.trainer - INFO - Epoch 0, Step 2599: Loss=7.0143, Acc=0.139, 
2025-10-04 18:33:50,085 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.6412, Acc=0.129, 
2025-10-04 18:33:57,789 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.7914, Acc=0.182, 
2025-10-04 18:34:05,418 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.0501, Acc=0.179, 
2025-10-04 18:34:13,149 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.4703, Acc=0.182, 
2025-10-04 18:34:20,906 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.4213, Acc=0.100, 
2025-10-04 18:34:28,692 - training.trainer - INFO - Epoch 0, Step 3199: Loss=5.8058, Acc=0.133, 
2025-10-04 18:34:36,371 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.4649, Acc=0.205, 
2025-10-04 18:34:57,292 - training.trainer - INFO - Epoch 1/100 completed in 286.26s - Train Loss: 6.4818, Train Acc: 0.155, Val Loss: 6.1495, Val Acc: 0.183
2025-10-04 18:34:58,182 - training.trainer - INFO - New best model saved with validation loss: 6.1495
2025-10-04 18:34:58,183 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-04 18:35:06,268 - training.trainer - INFO - Epoch 1, Step 3482: Loss=5.4885, Acc=0.261, 
2025-10-04 18:35:13,812 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.3860, Acc=0.130, 
2025-10-04 18:35:21,520 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.5057, Acc=0.194, 
2025-10-04 18:35:28,923 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.4972, Acc=0.146, 
2025-10-04 18:35:36,421 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.1216, Acc=0.243, 
2025-10-04 18:35:44,020 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.2484, Acc=0.138, 
2025-10-04 18:35:51,602 - training.trainer - INFO - Epoch 1, Step 4082: Loss=5.9045, Acc=0.186, 
2025-10-04 18:35:59,178 - training.trainer - INFO - Epoch 1, Step 4182: Loss=5.9699, Acc=0.263, 
2025-10-04 18:36:06,753 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.5260, Acc=0.163, 
2025-10-04 18:36:14,145 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.6887, Acc=0.167, 
2025-10-04 18:36:21,670 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.0855, Acc=0.171, 
2025-10-04 18:36:29,108 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.8918, Acc=0.174, 
2025-10-04 18:36:36,572 - training.trainer - INFO - Epoch 1, Step 4682: Loss=6.0761, Acc=0.136, 
2025-10-04 18:36:44,115 - training.trainer - INFO - Epoch 1, Step 4782: Loss=5.8905, Acc=0.190, 
2025-10-04 18:36:51,906 - training.trainer - INFO - Epoch 1, Step 4882: Loss=5.8462, Acc=0.257, 
2025-10-04 18:36:59,404 - training.trainer - INFO - Epoch 1, Step 4982: Loss=5.3987, Acc=0.188, 
2025-10-04 18:37:06,805 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.3925, Acc=0.150, 
2025-10-04 18:37:14,208 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.3353, Acc=0.250, 
2025-10-04 18:37:21,598 - training.trainer - INFO - Epoch 1, Step 5282: Loss=5.9935, Acc=0.162, 
2025-10-04 18:37:29,140 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.3322, Acc=0.306, 
2025-10-04 18:37:36,681 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.0950, Acc=0.146, 
2025-10-04 18:37:44,200 - training.trainer - INFO - Epoch 1, Step 5582: Loss=5.7310, Acc=0.162, 
2025-10-04 18:37:51,652 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.0861, Acc=0.121, 
2025-10-04 18:37:59,250 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.1367, Acc=0.167, 
2025-10-04 18:38:06,841 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.3437, Acc=0.180, 
2025-10-04 18:38:14,296 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.3842, Acc=0.175, 
2025-10-04 18:38:21,843 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.4114, Acc=0.161, 
2025-10-04 18:38:29,266 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.0408, Acc=0.135, 
2025-10-04 18:38:37,013 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.0600, Acc=0.188, 
2025-10-04 18:38:44,413 - training.trainer - INFO - Epoch 1, Step 6382: Loss=6.8826, Acc=0.156, 
2025-10-04 18:38:51,927 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.1754, Acc=0.093, 
2025-10-04 18:38:59,388 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.6740, Acc=0.176, 
2025-10-04 18:39:06,903 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.3884, Acc=0.217, 
2025-10-04 18:39:26,952 - training.trainer - INFO - Epoch 2/100 completed in 268.77s - Train Loss: 6.0930, Train Acc: 0.191, Val Loss: 5.9761, Val Acc: 0.204
2025-10-04 18:39:27,783 - training.trainer - INFO - New best model saved with validation loss: 5.9761
2025-10-04 18:39:27,784 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-04 18:39:35,686 - training.trainer - INFO - Epoch 2, Step 6865: Loss=5.6187, Acc=0.121, 
2025-10-04 18:39:43,195 - training.trainer - INFO - Epoch 2, Step 6965: Loss=5.8416, Acc=0.195, 
2025-10-04 18:39:50,778 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.0137, Acc=0.160, 
2025-10-04 18:39:58,290 - training.trainer - INFO - Epoch 2, Step 7165: Loss=5.7511, Acc=0.191, 
2025-10-04 18:40:05,817 - training.trainer - INFO - Epoch 2, Step 7265: Loss=5.6635, Acc=0.195, 
2025-10-04 18:40:13,367 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.6770, Acc=0.194, 
2025-10-04 18:40:20,983 - training.trainer - INFO - Epoch 2, Step 7465: Loss=5.7056, Acc=0.188, 
2025-10-04 18:40:28,387 - training.trainer - INFO - Epoch 2, Step 7565: Loss=6.4384, Acc=0.222, 
2025-10-04 18:40:35,942 - training.trainer - INFO - Epoch 2, Step 7665: Loss=5.6761, Acc=0.240, 
2025-10-04 18:40:43,516 - training.trainer - INFO - Epoch 2, Step 7765: Loss=5.5267, Acc=0.255, 
2025-10-04 18:40:50,897 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.3736, Acc=0.211, 
2025-10-04 18:40:58,394 - training.trainer - INFO - Epoch 2, Step 7965: Loss=5.8977, Acc=0.259, 
2025-10-04 18:41:05,813 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.2552, Acc=0.227, 
2025-10-04 18:41:13,412 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.2595, Acc=0.174, 
2025-10-04 18:41:20,996 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.3197, Acc=0.214, 
2025-10-04 18:41:28,476 - training.trainer - INFO - Epoch 2, Step 8365: Loss=6.2812, Acc=0.183, 
2025-10-04 18:41:35,951 - training.trainer - INFO - Epoch 2, Step 8465: Loss=5.8889, Acc=0.300, 
2025-10-04 18:41:43,467 - training.trainer - INFO - Epoch 2, Step 8565: Loss=6.0098, Acc=0.172, 
2025-10-04 18:41:51,268 - training.trainer - INFO - Epoch 2, Step 8665: Loss=5.6009, Acc=0.250, 
2025-10-04 18:41:58,700 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.6019, Acc=0.184, 
2025-10-04 18:42:06,116 - training.trainer - INFO - Epoch 2, Step 8865: Loss=5.6592, Acc=0.286, 
2025-10-04 18:42:13,722 - training.trainer - INFO - Epoch 2, Step 8965: Loss=4.1117, Acc=0.364, 
2025-10-04 18:42:21,296 - training.trainer - INFO - Epoch 2, Step 9065: Loss=5.6992, Acc=0.250, 
2025-10-04 18:42:28,806 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.1642, Acc=0.200, 
2025-10-04 18:42:36,314 - training.trainer - INFO - Epoch 2, Step 9265: Loss=5.3950, Acc=0.203, 
2025-10-04 18:42:43,793 - training.trainer - INFO - Epoch 2, Step 9365: Loss=5.8850, Acc=0.172, 
2025-10-04 18:42:51,331 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.7935, Acc=0.140, 
2025-10-04 18:42:58,959 - training.trainer - INFO - Epoch 2, Step 9565: Loss=5.8397, Acc=0.429, 
2025-10-04 18:43:06,782 - training.trainer - INFO - Epoch 2, Step 9665: Loss=5.8450, Acc=0.239, 
2025-10-04 18:43:14,240 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.1372, Acc=0.121, 
2025-10-04 18:43:21,685 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.0590, Acc=0.178, 
2025-10-04 18:43:29,224 - training.trainer - INFO - Epoch 2, Step 9965: Loss=6.2386, Acc=0.118, 
2025-10-04 18:43:36,751 - training.trainer - INFO - Epoch 2, Step 10065: Loss=7.1199, Acc=0.122, 
2025-10-04 18:43:56,083 - training.trainer - INFO - Epoch 3/100 completed in 268.30s - Train Loss: 5.9519, Train Acc: 0.212, Val Loss: 5.8688, Val Acc: 0.220
2025-10-04 18:43:56,850 - training.trainer - INFO - New best model saved with validation loss: 5.8688
2025-10-04 18:43:56,850 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-10-04 18:44:04,777 - training.trainer - INFO - Epoch 3, Step 10248: Loss=6.3438, Acc=0.180, 
2025-10-04 18:44:12,199 - training.trainer - INFO - Epoch 3, Step 10348: Loss=5.7393, Acc=0.222, 
2025-10-04 18:44:19,694 - training.trainer - INFO - Epoch 3, Step 10448: Loss=5.7908, Acc=0.115, 
2025-10-04 18:44:27,230 - training.trainer - INFO - Epoch 3, Step 10548: Loss=5.4936, Acc=0.273, 
2025-10-04 18:44:34,756 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.0445, Acc=0.133, 
2025-10-04 18:44:42,268 - training.trainer - INFO - Epoch 3, Step 10748: Loss=4.0791, Acc=0.583, 
2025-10-04 18:44:49,769 - training.trainer - INFO - Epoch 3, Step 10848: Loss=7.0704, Acc=0.108, 
2025-10-04 18:44:57,154 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.7247, Acc=0.149, 
2025-10-04 18:45:04,662 - training.trainer - INFO - Epoch 3, Step 11048: Loss=5.8995, Acc=0.174, 
2025-10-04 18:45:12,109 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.5612, Acc=0.167, 
2025-10-04 18:45:19,445 - training.trainer - INFO - Epoch 3, Step 11248: Loss=5.4710, Acc=0.262, 
2025-10-04 18:45:26,848 - training.trainer - INFO - Epoch 3, Step 11348: Loss=5.7443, Acc=0.214, 
2025-10-04 18:45:34,204 - training.trainer - INFO - Epoch 3, Step 11448: Loss=5.0261, Acc=0.455, 
2025-10-04 18:45:41,646 - training.trainer - INFO - Epoch 3, Step 11548: Loss=6.0597, Acc=0.227, 
2025-10-04 18:45:49,005 - training.trainer - INFO - Epoch 3, Step 11648: Loss=5.1953, Acc=0.323, 
2025-10-04 18:45:56,607 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.3669, Acc=0.303, 
2025-10-04 18:46:03,954 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.5451, Acc=0.154, 
2025-10-04 18:46:11,506 - training.trainer - INFO - Epoch 3, Step 11948: Loss=5.6696, Acc=0.276, 
2025-10-04 18:46:18,901 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.3841, Acc=0.293, 
2025-10-04 18:46:26,323 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.3225, Acc=0.220, 
2025-10-04 18:46:33,759 - training.trainer - INFO - Epoch 3, Step 12248: Loss=5.9843, Acc=0.169, 
2025-10-04 18:46:41,095 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.4209, Acc=0.151, 
2025-10-04 18:46:48,480 - training.trainer - INFO - Epoch 3, Step 12448: Loss=5.7101, Acc=0.216, 
2025-10-04 18:46:55,760 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.3085, Acc=0.186, 
2025-10-04 18:47:03,115 - training.trainer - INFO - Epoch 3, Step 12648: Loss=5.5140, Acc=0.194, 
2025-10-04 18:47:10,660 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.0249, Acc=0.207, 
2025-10-04 18:47:18,225 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.0489, Acc=0.212, 
2025-10-04 18:47:25,727 - training.trainer - INFO - Epoch 3, Step 12948: Loss=5.0738, Acc=0.279, 
2025-10-04 18:47:33,169 - training.trainer - INFO - Epoch 3, Step 13048: Loss=7.0203, Acc=0.146, 
2025-10-04 18:47:40,821 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.8972, Acc=0.132, 
2025-10-04 18:47:48,408 - training.trainer - INFO - Epoch 3, Step 13248: Loss=5.6547, Acc=0.224, 
2025-10-04 18:47:56,041 - training.trainer - INFO - Epoch 3, Step 13348: Loss=6.0623, Acc=0.194, 
2025-10-04 18:48:03,408 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.7401, Acc=0.182, 
2025-10-04 18:48:22,282 - training.trainer - INFO - Epoch 4/100 completed in 265.43s - Train Loss: 5.8486, Train Acc: 0.229, Val Loss: 5.7975, Val Acc: 0.233
2025-10-04 18:48:22,947 - training.trainer - INFO - New best model saved with validation loss: 5.7975
2025-10-04 18:48:22,947 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-10-04 18:48:30,437 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.5550, Acc=0.194, 
2025-10-04 18:48:37,801 - training.trainer - INFO - Epoch 4, Step 13731: Loss=6.5210, Acc=0.286, 
2025-10-04 18:48:45,192 - training.trainer - INFO - Epoch 4, Step 13831: Loss=5.7151, Acc=0.259, 
2025-10-04 18:48:53,038 - training.trainer - INFO - Epoch 4, Step 13931: Loss=6.0565, Acc=0.216, 
2025-10-04 18:49:00,572 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.5267, Acc=0.308, 
2025-10-04 18:49:08,325 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.6345, Acc=0.148, 
2025-10-04 18:49:15,776 - training.trainer - INFO - Epoch 4, Step 14231: Loss=5.6571, Acc=0.200, 
2025-10-04 18:49:23,215 - training.trainer - INFO - Epoch 4, Step 14331: Loss=5.9778, Acc=0.160, 
2025-10-04 18:49:30,709 - training.trainer - INFO - Epoch 4, Step 14431: Loss=5.2136, Acc=0.296, 
2025-10-04 18:49:38,136 - training.trainer - INFO - Epoch 4, Step 14531: Loss=6.1989, Acc=0.176, 
2025-10-04 18:49:45,490 - training.trainer - INFO - Epoch 4, Step 14631: Loss=5.4403, Acc=0.360, 
2025-10-04 18:49:52,859 - training.trainer - INFO - Epoch 4, Step 14731: Loss=6.3493, Acc=0.195, 
2025-10-04 18:50:00,365 - training.trainer - INFO - Epoch 4, Step 14831: Loss=4.9535, Acc=0.289, 
2025-10-04 18:50:07,854 - training.trainer - INFO - Epoch 4, Step 14931: Loss=6.1357, Acc=0.146, 
2025-10-04 18:50:15,172 - training.trainer - INFO - Epoch 4, Step 15031: Loss=5.8271, Acc=0.255, 
2025-10-04 18:50:22,534 - training.trainer - INFO - Epoch 4, Step 15131: Loss=5.5690, Acc=0.184, 
2025-10-04 18:50:29,939 - training.trainer - INFO - Epoch 4, Step 15231: Loss=4.5148, Acc=0.357, 
2025-10-04 18:50:37,400 - training.trainer - INFO - Epoch 4, Step 15331: Loss=5.3674, Acc=0.412, 
2025-10-04 18:50:44,772 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.3720, Acc=0.273, 
2025-10-04 18:50:52,268 - training.trainer - INFO - Epoch 4, Step 15531: Loss=7.2277, Acc=0.138, 
2025-10-04 18:50:59,741 - training.trainer - INFO - Epoch 4, Step 15631: Loss=5.6004, Acc=0.237, 
2025-10-04 18:51:07,293 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.0450, Acc=0.182, 
2025-10-04 18:51:14,815 - training.trainer - INFO - Epoch 4, Step 15831: Loss=5.8306, Acc=0.154, 
2025-10-04 18:51:22,136 - training.trainer - INFO - Epoch 4, Step 15931: Loss=4.4986, Acc=0.333, 
2025-10-04 18:51:29,806 - training.trainer - INFO - Epoch 4, Step 16031: Loss=4.7171, Acc=0.296, 
2025-10-04 18:51:37,190 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.4478, Acc=0.240, 
2025-10-04 18:51:44,699 - training.trainer - INFO - Epoch 4, Step 16231: Loss=4.9701, Acc=0.235, 
2025-10-04 18:51:52,165 - training.trainer - INFO - Epoch 4, Step 16331: Loss=5.6384, Acc=0.225, 
2025-10-04 18:51:59,515 - training.trainer - INFO - Epoch 4, Step 16431: Loss=6.1441, Acc=0.125, 
2025-10-04 18:52:06,914 - training.trainer - INFO - Epoch 4, Step 16531: Loss=5.4491, Acc=0.297, 
2025-10-04 18:52:14,662 - training.trainer - INFO - Epoch 4, Step 16631: Loss=5.9201, Acc=0.250, 
2025-10-04 18:52:22,049 - training.trainer - INFO - Epoch 4, Step 16731: Loss=6.1666, Acc=0.179, 
2025-10-04 18:52:29,417 - training.trainer - INFO - Epoch 4, Step 16831: Loss=3.5265, Acc=0.611, 
2025-10-04 18:52:48,777 - training.trainer - INFO - Epoch 5/100 completed in 265.83s - Train Loss: 5.7652, Train Acc: 0.241, Val Loss: 5.7607, Val Acc: 0.242
2025-10-04 18:52:49,148 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-04 18:52:49,833 - training.trainer - INFO - New best model saved with validation loss: 5.7607
2025-10-04 18:52:49,833 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-04 18:52:57,737 - training.trainer - INFO - Epoch 5, Step 17014: Loss=5.5829, Acc=0.233, 
2025-10-04 18:53:05,196 - training.trainer - INFO - Epoch 5, Step 17114: Loss=5.9052, Acc=0.163, 
2025-10-04 18:53:12,822 - training.trainer - INFO - Epoch 5, Step 17214: Loss=5.5448, Acc=0.269, 
2025-10-04 18:53:20,534 - training.trainer - INFO - Epoch 5, Step 17314: Loss=4.6715, Acc=0.400, 
2025-10-04 18:53:28,098 - training.trainer - INFO - Epoch 5, Step 17414: Loss=5.5093, Acc=0.267, 
2025-10-04 18:53:35,464 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.4171, Acc=0.100, 
2025-10-04 18:53:42,814 - training.trainer - INFO - Epoch 5, Step 17614: Loss=5.6359, Acc=0.283, 
2025-10-04 18:53:50,183 - training.trainer - INFO - Epoch 5, Step 17714: Loss=5.3622, Acc=0.296, 
2025-10-04 18:53:58,052 - training.trainer - INFO - Epoch 5, Step 17814: Loss=6.3755, Acc=0.176, 
2025-10-04 18:54:05,691 - training.trainer - INFO - Epoch 5, Step 17914: Loss=5.9917, Acc=0.229, 
2025-10-04 18:54:13,216 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.4691, Acc=0.278, 
2025-10-04 18:54:20,640 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.1868, Acc=0.183, 
2025-10-04 18:54:28,117 - training.trainer - INFO - Epoch 5, Step 18214: Loss=5.8597, Acc=0.178, 
2025-10-04 18:54:35,637 - training.trainer - INFO - Epoch 5, Step 18314: Loss=5.5812, Acc=0.259, 
2025-10-04 18:54:43,338 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.0821, Acc=0.304, 
2025-10-04 18:54:50,777 - training.trainer - INFO - Epoch 5, Step 18514: Loss=5.8589, Acc=0.310, 
2025-10-04 18:54:58,343 - training.trainer - INFO - Epoch 5, Step 18614: Loss=5.1449, Acc=0.240, 
2025-10-04 18:55:05,817 - training.trainer - INFO - Epoch 5, Step 18714: Loss=5.2716, Acc=0.308, 
2025-10-04 18:55:13,252 - training.trainer - INFO - Epoch 5, Step 18814: Loss=5.7346, Acc=0.278, 
2025-10-04 18:55:20,763 - training.trainer - INFO - Epoch 5, Step 18914: Loss=5.7109, Acc=0.290, 
2025-10-04 18:55:28,354 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.0073, Acc=0.207, 
2025-10-04 18:55:35,451 - training.trainer - INFO - Epoch 5, Step 19114: Loss=5.9036, Acc=0.293, 
2025-10-04 18:55:42,883 - training.trainer - INFO - Epoch 5, Step 19214: Loss=5.7809, Acc=0.216, 
2025-10-04 18:55:50,327 - training.trainer - INFO - Epoch 5, Step 19314: Loss=4.9294, Acc=0.273, 
2025-10-04 18:55:57,735 - training.trainer - INFO - Epoch 5, Step 19414: Loss=4.8473, Acc=0.389, 
2025-10-04 18:56:05,479 - training.trainer - INFO - Epoch 5, Step 19514: Loss=6.0029, Acc=0.286, 
2025-10-04 18:56:12,935 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.2409, Acc=0.177, 
2025-10-04 18:56:20,591 - training.trainer - INFO - Epoch 5, Step 19714: Loss=5.6818, Acc=0.200, 
2025-10-04 18:56:28,232 - training.trainer - INFO - Epoch 5, Step 19814: Loss=5.8480, Acc=0.290, 
2025-10-04 18:56:35,814 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.6052, Acc=0.188, 
2025-10-04 18:56:43,408 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.4455, Acc=0.364, 
2025-10-04 18:56:50,972 - training.trainer - INFO - Epoch 5, Step 20114: Loss=5.6628, Acc=0.273, 
2025-10-04 18:56:58,411 - training.trainer - INFO - Epoch 5, Step 20214: Loss=5.1710, Acc=0.208, 
2025-10-04 18:57:17,923 - training.trainer - INFO - Epoch 6/100 completed in 268.09s - Train Loss: 5.6902, Train Acc: 0.253, Val Loss: 5.7253, Val Acc: 0.245
2025-10-04 18:57:18,643 - training.trainer - INFO - New best model saved with validation loss: 5.7253
2025-10-04 18:57:18,644 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-10-04 18:57:26,514 - training.trainer - INFO - Epoch 6, Step 20397: Loss=6.3476, Acc=0.183, 
2025-10-04 18:57:34,722 - training.trainer - INFO - Epoch 6, Step 20497: Loss=4.8973, Acc=0.361, 
2025-10-04 18:57:42,200 - training.trainer - INFO - Epoch 6, Step 20597: Loss=5.7967, Acc=0.269, 
2025-10-04 18:57:49,951 - training.trainer - INFO - Epoch 6, Step 20697: Loss=5.6655, Acc=0.417, 
2025-10-04 18:57:57,688 - training.trainer - INFO - Epoch 6, Step 20797: Loss=5.8330, Acc=0.267, 
2025-10-04 18:58:05,242 - training.trainer - INFO - Epoch 6, Step 20897: Loss=6.0778, Acc=0.157, 
2025-10-04 18:58:12,827 - training.trainer - INFO - Epoch 6, Step 20997: Loss=4.1825, Acc=0.462, 
2025-10-04 18:58:20,473 - training.trainer - INFO - Epoch 6, Step 21097: Loss=5.4854, Acc=0.312, 
2025-10-04 18:58:27,993 - training.trainer - INFO - Epoch 6, Step 21197: Loss=6.7720, Acc=0.122, 
2025-10-04 18:58:35,553 - training.trainer - INFO - Epoch 6, Step 21297: Loss=5.8348, Acc=0.206, 
2025-10-04 18:58:43,012 - training.trainer - INFO - Epoch 6, Step 21397: Loss=5.5970, Acc=0.444, 
2025-10-04 18:58:50,535 - training.trainer - INFO - Epoch 6, Step 21497: Loss=5.8618, Acc=0.250, 
2025-10-04 18:58:58,055 - training.trainer - INFO - Epoch 6, Step 21597: Loss=6.6927, Acc=0.162, 
2025-10-04 18:59:05,618 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.5133, Acc=0.182, 
2025-10-04 18:59:13,122 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.3334, Acc=0.147, 
2025-10-04 18:59:20,574 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.3700, Acc=0.148, 
2025-10-04 18:59:28,247 - training.trainer - INFO - Epoch 6, Step 21997: Loss=4.5034, Acc=0.389, 
2025-10-04 18:59:35,942 - training.trainer - INFO - Epoch 6, Step 22097: Loss=5.6892, Acc=0.245, 
2025-10-04 18:59:43,532 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.3224, Acc=0.238, 
2025-10-04 18:59:51,019 - training.trainer - INFO - Epoch 6, Step 22297: Loss=5.7052, Acc=0.273, 
2025-10-04 18:59:58,750 - training.trainer - INFO - Epoch 6, Step 22397: Loss=6.4034, Acc=0.231, 
2025-10-04 19:00:06,286 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.1662, Acc=0.106, 
2025-10-04 19:00:13,819 - training.trainer - INFO - Epoch 6, Step 22597: Loss=5.3069, Acc=0.320, 
2025-10-04 19:00:21,271 - training.trainer - INFO - Epoch 6, Step 22697: Loss=6.1563, Acc=0.381, 
2025-10-04 19:00:28,699 - training.trainer - INFO - Epoch 6, Step 22797: Loss=5.4399, Acc=0.217, 
2025-10-04 19:00:36,023 - training.trainer - INFO - Epoch 6, Step 22897: Loss=5.7977, Acc=0.179, 
2025-10-04 19:00:43,364 - training.trainer - INFO - Epoch 6, Step 22997: Loss=5.8041, Acc=0.304, 
2025-10-04 19:00:51,053 - training.trainer - INFO - Epoch 6, Step 23097: Loss=5.9802, Acc=0.222, 
2025-10-04 19:00:58,358 - training.trainer - INFO - Epoch 6, Step 23197: Loss=5.2909, Acc=0.229, 
2025-10-04 19:01:05,778 - training.trainer - INFO - Epoch 6, Step 23297: Loss=5.4637, Acc=0.255, 
2025-10-04 19:01:13,186 - training.trainer - INFO - Epoch 6, Step 23397: Loss=4.1532, Acc=0.333, 
2025-10-04 19:01:20,674 - training.trainer - INFO - Epoch 6, Step 23497: Loss=6.1341, Acc=0.214, 
2025-10-04 19:01:28,093 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.3694, Acc=0.250, 
2025-10-04 19:01:48,078 - training.trainer - INFO - Epoch 7/100 completed in 269.43s - Train Loss: 5.6178, Train Acc: 0.262, Val Loss: 5.7073, Val Acc: 0.252
2025-10-04 19:01:48,802 - training.trainer - INFO - New best model saved with validation loss: 5.7073
2025-10-04 19:01:48,803 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-10-04 19:01:56,447 - training.trainer - INFO - Epoch 7, Step 23780: Loss=5.0907, Acc=0.323, 
2025-10-04 19:02:03,462 - training.trainer - INFO - Epoch 7, Step 23880: Loss=5.2376, Acc=0.367, 
2025-10-04 19:02:11,032 - training.trainer - INFO - Epoch 7, Step 23980: Loss=5.2410, Acc=0.308, 
2025-10-04 19:02:18,541 - training.trainer - INFO - Epoch 7, Step 24080: Loss=4.7304, Acc=0.480, 
2025-10-04 19:02:26,110 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.4628, Acc=0.233, 
2025-10-04 19:02:33,631 - training.trainer - INFO - Epoch 7, Step 24280: Loss=5.3500, Acc=0.290, 
2025-10-04 19:02:41,195 - training.trainer - INFO - Epoch 7, Step 24380: Loss=3.4755, Acc=0.600, 
2025-10-04 19:02:48,825 - training.trainer - INFO - Epoch 7, Step 24480: Loss=4.3015, Acc=0.368, 
2025-10-04 19:02:56,518 - training.trainer - INFO - Epoch 7, Step 24580: Loss=5.8266, Acc=0.172, 
2025-10-04 19:03:04,164 - training.trainer - INFO - Epoch 7, Step 24680: Loss=5.0626, Acc=0.367, 
2025-10-04 19:03:11,721 - training.trainer - INFO - Epoch 7, Step 24780: Loss=4.1393, Acc=0.500, 
2025-10-04 19:03:19,300 - training.trainer - INFO - Epoch 7, Step 24880: Loss=3.6861, Acc=0.545, 
2025-10-04 19:03:26,832 - training.trainer - INFO - Epoch 7, Step 24980: Loss=4.4010, Acc=0.368, 
2025-10-04 19:03:34,411 - training.trainer - INFO - Epoch 7, Step 25080: Loss=5.8611, Acc=0.228, 
2025-10-04 19:03:41,884 - training.trainer - INFO - Epoch 7, Step 25180: Loss=5.1828, Acc=0.395, 
2025-10-04 19:03:49,686 - training.trainer - INFO - Epoch 7, Step 25280: Loss=4.4293, Acc=0.462, 
2025-10-04 19:03:57,033 - training.trainer - INFO - Epoch 7, Step 25380: Loss=4.7654, Acc=0.361, 
2025-10-04 19:04:04,702 - training.trainer - INFO - Epoch 7, Step 25480: Loss=6.1699, Acc=0.218, 
2025-10-04 19:04:12,326 - training.trainer - INFO - Epoch 7, Step 25580: Loss=6.2569, Acc=0.200, 
2025-10-04 19:04:19,741 - training.trainer - INFO - Epoch 7, Step 25680: Loss=5.5673, Acc=0.179, 
2025-10-04 19:04:27,301 - training.trainer - INFO - Epoch 7, Step 25780: Loss=5.1144, Acc=0.297, 
2025-10-04 19:04:34,778 - training.trainer - INFO - Epoch 7, Step 25880: Loss=5.7861, Acc=0.216, 
2025-10-04 19:04:42,461 - training.trainer - INFO - Epoch 7, Step 25980: Loss=4.8785, Acc=0.444, 
2025-10-04 19:04:49,967 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.6854, Acc=0.200, 
2025-10-04 19:04:57,606 - training.trainer - INFO - Epoch 7, Step 26180: Loss=5.8063, Acc=0.235, 
2025-10-04 19:05:05,282 - training.trainer - INFO - Epoch 7, Step 26280: Loss=6.0255, Acc=0.242, 
2025-10-04 19:05:12,990 - training.trainer - INFO - Epoch 7, Step 26380: Loss=5.4612, Acc=0.250, 
2025-10-04 19:05:20,561 - training.trainer - INFO - Epoch 7, Step 26480: Loss=5.7630, Acc=0.227, 
2025-10-04 19:05:28,164 - training.trainer - INFO - Epoch 7, Step 26580: Loss=5.7702, Acc=0.250, 
2025-10-04 19:05:35,606 - training.trainer - INFO - Epoch 7, Step 26680: Loss=6.4193, Acc=0.175, 
2025-10-04 19:05:43,239 - training.trainer - INFO - Epoch 7, Step 26780: Loss=3.4811, Acc=0.533, 
2025-10-04 19:05:50,735 - training.trainer - INFO - Epoch 7, Step 26880: Loss=6.1656, Acc=0.184, 
2025-10-04 19:05:58,223 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.4640, Acc=0.308, 
2025-10-04 19:06:17,847 - training.trainer - INFO - Epoch 8/100 completed in 269.04s - Train Loss: 5.5463, Train Acc: 0.274, Val Loss: 5.6940, Val Acc: 0.249
2025-10-04 19:06:18,616 - training.trainer - INFO - New best model saved with validation loss: 5.6940
2025-10-04 19:06:18,616 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-10-04 19:06:26,521 - training.trainer - INFO - Epoch 8, Step 27163: Loss=5.5593, Acc=0.274, 
2025-10-04 19:06:34,615 - training.trainer - INFO - Epoch 8, Step 27263: Loss=5.4186, Acc=0.250, 
2025-10-04 19:06:42,102 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.4638, Acc=0.231, 
2025-10-04 19:06:49,688 - training.trainer - INFO - Epoch 8, Step 27463: Loss=4.9874, Acc=0.255, 
2025-10-04 19:06:57,188 - training.trainer - INFO - Epoch 8, Step 27563: Loss=5.8848, Acc=0.228, 
2025-10-04 19:07:04,710 - training.trainer - INFO - Epoch 8, Step 27663: Loss=5.2367, Acc=0.295, 
2025-10-04 19:07:12,156 - training.trainer - INFO - Epoch 8, Step 27763: Loss=5.8070, Acc=0.263, 
2025-10-04 19:07:19,590 - training.trainer - INFO - Epoch 8, Step 27863: Loss=5.6491, Acc=0.259, 
2025-10-04 19:07:27,108 - training.trainer - INFO - Epoch 8, Step 27963: Loss=5.9475, Acc=0.168, 
2025-10-04 19:07:34,587 - training.trainer - INFO - Epoch 8, Step 28063: Loss=5.9084, Acc=0.308, 
2025-10-04 19:07:42,092 - training.trainer - INFO - Epoch 8, Step 28163: Loss=5.4991, Acc=0.276, 
2025-10-04 19:07:49,536 - training.trainer - INFO - Epoch 8, Step 28263: Loss=5.1716, Acc=0.310, 
2025-10-04 19:07:57,105 - training.trainer - INFO - Epoch 8, Step 28363: Loss=5.4258, Acc=0.292, 
2025-10-04 19:08:04,626 - training.trainer - INFO - Epoch 8, Step 28463: Loss=5.7660, Acc=0.222, 
2025-10-04 19:08:12,120 - training.trainer - INFO - Epoch 8, Step 28563: Loss=5.4293, Acc=0.227, 
2025-10-04 19:08:19,652 - training.trainer - INFO - Epoch 8, Step 28663: Loss=5.8502, Acc=0.171, 
2025-10-04 19:08:27,258 - training.trainer - INFO - Epoch 8, Step 28763: Loss=5.0061, Acc=0.304, 
2025-10-04 19:08:34,721 - training.trainer - INFO - Epoch 8, Step 28863: Loss=5.2524, Acc=0.219, 
2025-10-04 19:08:42,190 - training.trainer - INFO - Epoch 8, Step 28963: Loss=5.5161, Acc=0.324, 
2025-10-04 19:08:49,645 - training.trainer - INFO - Epoch 8, Step 29063: Loss=5.8994, Acc=0.257, 
2025-10-04 19:08:57,053 - training.trainer - INFO - Epoch 8, Step 29163: Loss=5.8448, Acc=0.213, 
2025-10-04 19:09:04,670 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.2741, Acc=0.239, 
2025-10-04 19:09:12,222 - training.trainer - INFO - Epoch 8, Step 29363: Loss=6.5271, Acc=0.304, 
2025-10-04 19:09:19,722 - training.trainer - INFO - Epoch 8, Step 29463: Loss=5.0430, Acc=0.298, 
2025-10-04 19:09:27,284 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.0634, Acc=0.261, 
2025-10-04 19:09:34,793 - training.trainer - INFO - Epoch 8, Step 29663: Loss=2.9076, Acc=0.657, 
2025-10-04 19:09:42,125 - training.trainer - INFO - Epoch 8, Step 29763: Loss=5.1527, Acc=0.174, 
2025-10-04 19:09:49,517 - training.trainer - INFO - Epoch 8, Step 29863: Loss=6.1887, Acc=0.250, 
2025-10-04 19:09:57,024 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.1067, Acc=0.222, 
2025-10-04 19:10:04,619 - training.trainer - INFO - Epoch 8, Step 30063: Loss=5.8781, Acc=0.207, 
2025-10-04 19:10:12,058 - training.trainer - INFO - Epoch 8, Step 30163: Loss=4.5729, Acc=0.219, 
2025-10-04 19:10:19,414 - training.trainer - INFO - Epoch 8, Step 30263: Loss=6.0280, Acc=0.255, 
2025-10-04 19:10:26,753 - training.trainer - INFO - Epoch 8, Step 30363: Loss=6.1755, Acc=0.145, 
2025-10-04 19:10:46,134 - training.trainer - INFO - Epoch 9/100 completed in 267.52s - Train Loss: 5.4841, Train Acc: 0.284, Val Loss: 5.6802, Val Acc: 0.251
2025-10-04 19:10:46,888 - training.trainer - INFO - New best model saved with validation loss: 5.6802
2025-10-04 19:10:46,888 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-10-04 19:10:54,468 - training.trainer - INFO - Epoch 9, Step 30546: Loss=6.4089, Acc=0.205, 
2025-10-04 19:11:01,943 - training.trainer - INFO - Epoch 9, Step 30646: Loss=6.3052, Acc=0.186, 
2025-10-04 19:11:09,311 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.2302, Acc=0.231, 
2025-10-04 19:11:16,922 - training.trainer - INFO - Epoch 9, Step 30846: Loss=5.5632, Acc=0.255, 
2025-10-04 19:11:24,402 - training.trainer - INFO - Epoch 9, Step 30946: Loss=5.7664, Acc=0.182, 
2025-10-04 19:11:31,910 - training.trainer - INFO - Epoch 9, Step 31046: Loss=4.3663, Acc=0.364, 
2025-10-04 19:11:39,355 - training.trainer - INFO - Epoch 9, Step 31146: Loss=5.8537, Acc=0.143, 
2025-10-04 19:11:47,034 - training.trainer - INFO - Epoch 9, Step 31246: Loss=4.2603, Acc=0.486, 
2025-10-04 19:11:54,544 - training.trainer - INFO - Epoch 9, Step 31346: Loss=4.6647, Acc=0.303, 
2025-10-04 19:12:02,085 - training.trainer - INFO - Epoch 9, Step 31446: Loss=5.0707, Acc=0.304, 
2025-10-04 19:12:09,585 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.8373, Acc=0.205, 
2025-10-04 19:12:17,308 - training.trainer - INFO - Epoch 9, Step 31646: Loss=5.1668, Acc=0.333, 
2025-10-04 19:12:24,872 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.3957, Acc=0.172, 
2025-10-04 19:12:32,658 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.0315, Acc=0.244, 
2025-10-04 19:12:40,163 - training.trainer - INFO - Epoch 9, Step 31946: Loss=5.7108, Acc=0.300, 
2025-10-04 19:12:47,615 - training.trainer - INFO - Epoch 9, Step 32046: Loss=5.5128, Acc=0.262, 
2025-10-04 19:12:55,099 - training.trainer - INFO - Epoch 9, Step 32146: Loss=5.1713, Acc=0.269, 
2025-10-04 19:13:02,493 - training.trainer - INFO - Epoch 9, Step 32246: Loss=5.4285, Acc=0.257, 
2025-10-04 19:13:09,944 - training.trainer - INFO - Epoch 9, Step 32346: Loss=4.5480, Acc=0.360, 
2025-10-04 19:13:17,373 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.7777, Acc=0.233, 
2025-10-04 19:13:24,911 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.4154, Acc=0.211, 
2025-10-04 19:13:32,292 - training.trainer - INFO - Epoch 9, Step 32646: Loss=5.8148, Acc=0.235, 
2025-10-04 19:13:39,748 - training.trainer - INFO - Epoch 9, Step 32746: Loss=5.4559, Acc=0.360, 
2025-10-04 19:13:47,104 - training.trainer - INFO - Epoch 9, Step 32846: Loss=5.7771, Acc=0.296, 
2025-10-04 19:13:54,572 - training.trainer - INFO - Epoch 9, Step 32946: Loss=5.0329, Acc=0.391, 
2025-10-04 19:14:02,087 - training.trainer - INFO - Epoch 9, Step 33046: Loss=5.3980, Acc=0.333, 
2025-10-04 19:14:09,475 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.3736, Acc=0.215, 
2025-10-04 19:14:17,038 - training.trainer - INFO - Epoch 9, Step 33246: Loss=5.7809, Acc=0.254, 
2025-10-04 19:14:24,383 - training.trainer - INFO - Epoch 9, Step 33346: Loss=5.2949, Acc=0.302, 
2025-10-04 19:14:31,809 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.2780, Acc=0.225, 
2025-10-04 19:14:39,447 - training.trainer - INFO - Epoch 9, Step 33546: Loss=5.7823, Acc=0.196, 
2025-10-04 19:14:46,829 - training.trainer - INFO - Epoch 9, Step 33646: Loss=5.6111, Acc=0.259, 
2025-10-04 19:14:54,300 - training.trainer - INFO - Epoch 9, Step 33746: Loss=5.4909, Acc=0.267, 
2025-10-04 19:15:14,228 - training.trainer - INFO - Epoch 10/100 completed in 267.34s - Train Loss: 5.4238, Train Acc: 0.292, Val Loss: 5.6724, Val Acc: 0.257
2025-10-04 19:15:14,602 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-04 19:15:15,384 - training.trainer - INFO - New best model saved with validation loss: 5.6724
2025-10-04 19:15:15,384 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-04 19:15:22,232 - training.trainer - INFO - Epoch 10, Step 33929: Loss=5.0477, Acc=0.364, 
2025-10-04 19:15:28,560 - training.trainer - INFO - Epoch 10, Step 34029: Loss=5.9147, Acc=0.250, 
2025-10-04 19:15:35,844 - training.trainer - INFO - Epoch 10, Step 34129: Loss=5.4536, Acc=0.269, 
2025-10-04 19:15:43,377 - training.trainer - INFO - Epoch 10, Step 34229: Loss=6.4432, Acc=0.164, 
2025-10-04 19:15:50,834 - training.trainer - INFO - Epoch 10, Step 34329: Loss=3.5368, Acc=0.538, 
2025-10-04 19:15:58,192 - training.trainer - INFO - Epoch 10, Step 34429: Loss=5.7460, Acc=0.238, 
2025-10-04 19:16:05,650 - training.trainer - INFO - Epoch 10, Step 34529: Loss=6.6046, Acc=0.133, 
2025-10-04 19:16:13,030 - training.trainer - INFO - Epoch 10, Step 34629: Loss=4.2652, Acc=0.312, 
2025-10-04 19:16:20,466 - training.trainer - INFO - Epoch 10, Step 34729: Loss=5.7634, Acc=0.261, 
2025-10-04 19:16:27,983 - training.trainer - INFO - Epoch 10, Step 34829: Loss=4.4472, Acc=0.481, 
2025-10-04 19:16:35,411 - training.trainer - INFO - Epoch 10, Step 34929: Loss=4.7146, Acc=0.368, 
2025-10-04 19:16:43,355 - training.trainer - INFO - Epoch 10, Step 35029: Loss=5.4203, Acc=0.261, 
2025-10-04 19:16:50,694 - training.trainer - INFO - Epoch 10, Step 35129: Loss=4.8744, Acc=0.400, 
2025-10-04 19:16:58,111 - training.trainer - INFO - Epoch 10, Step 35229: Loss=5.8078, Acc=0.273, 
2025-10-04 19:17:05,529 - training.trainer - INFO - Epoch 10, Step 35329: Loss=5.4099, Acc=0.224, 
2025-10-04 19:17:13,054 - training.trainer - INFO - Epoch 10, Step 35429: Loss=5.5193, Acc=0.405, 
2025-10-04 19:17:20,447 - training.trainer - INFO - Epoch 10, Step 35529: Loss=3.6510, Acc=0.550, 
2025-10-04 19:17:27,812 - training.trainer - INFO - Epoch 10, Step 35629: Loss=6.5181, Acc=0.146, 
2025-10-04 19:17:35,317 - training.trainer - INFO - Epoch 10, Step 35729: Loss=4.7226, Acc=0.409, 
2025-10-04 19:17:42,760 - training.trainer - INFO - Epoch 10, Step 35829: Loss=4.0986, Acc=0.400, 
2025-10-04 19:17:50,354 - training.trainer - INFO - Epoch 10, Step 35929: Loss=5.3593, Acc=0.268, 
2025-10-04 19:17:57,776 - training.trainer - INFO - Epoch 10, Step 36029: Loss=5.3290, Acc=0.339, 
2025-10-04 19:18:05,255 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.4407, Acc=0.271, 
2025-10-04 19:18:12,820 - training.trainer - INFO - Epoch 10, Step 36229: Loss=5.5061, Acc=0.314, 
2025-10-04 19:18:20,402 - training.trainer - INFO - Epoch 10, Step 36329: Loss=5.5595, Acc=0.302, 
2025-10-04 19:18:27,856 - training.trainer - INFO - Epoch 10, Step 36429: Loss=5.4198, Acc=0.423, 
2025-10-04 19:18:35,296 - training.trainer - INFO - Epoch 10, Step 36529: Loss=4.4913, Acc=0.414, 
2025-10-04 19:18:42,637 - training.trainer - INFO - Epoch 10, Step 36629: Loss=4.5227, Acc=0.474, 
2025-10-04 19:18:50,118 - training.trainer - INFO - Epoch 10, Step 36729: Loss=5.5796, Acc=0.302, 
2025-10-04 19:18:57,554 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.0942, Acc=0.312, 
2025-10-04 19:19:04,903 - training.trainer - INFO - Epoch 10, Step 36929: Loss=6.0945, Acc=0.348, 
2025-10-04 19:19:12,343 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.3370, Acc=0.400, 
2025-10-04 19:19:19,901 - training.trainer - INFO - Epoch 10, Step 37129: Loss=5.7935, Acc=0.253, 
2025-10-04 19:19:39,882 - training.trainer - INFO - Epoch 11/100 completed in 264.50s - Train Loss: 5.3651, Train Acc: 0.303, Val Loss: 5.6800, Val Acc: 0.259
2025-10-04 19:19:46,671 - training.trainer - INFO - Epoch 11, Step 37312: Loss=5.8815, Acc=0.273, 
2025-10-04 19:19:53,277 - training.trainer - INFO - Epoch 11, Step 37412: Loss=5.7680, Acc=0.246, 
2025-10-04 19:20:00,769 - training.trainer - INFO - Epoch 11, Step 37512: Loss=6.1184, Acc=0.239, 
2025-10-04 19:20:08,383 - training.trainer - INFO - Epoch 11, Step 37612: Loss=5.2864, Acc=0.286, 
2025-10-04 19:20:16,436 - training.trainer - INFO - Epoch 11, Step 37712: Loss=5.0407, Acc=0.333, 
2025-10-04 19:20:24,118 - training.trainer - INFO - Epoch 11, Step 37812: Loss=6.2155, Acc=0.302, 
2025-10-04 19:20:31,777 - training.trainer - INFO - Epoch 11, Step 37912: Loss=5.3763, Acc=0.222, 
2025-10-04 19:20:39,302 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.4886, Acc=0.215, 
2025-10-04 19:20:47,148 - training.trainer - INFO - Epoch 11, Step 38112: Loss=5.9767, Acc=0.279, 
2025-10-04 19:20:54,770 - training.trainer - INFO - Epoch 11, Step 38212: Loss=3.7147, Acc=0.462, 
2025-10-04 19:21:02,401 - training.trainer - INFO - Epoch 11, Step 38312: Loss=2.6058, Acc=0.600, 
2025-10-04 19:21:09,814 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.6152, Acc=0.324, 
2025-10-04 19:21:17,262 - training.trainer - INFO - Epoch 11, Step 38512: Loss=5.2395, Acc=0.323, 
2025-10-04 19:21:24,688 - training.trainer - INFO - Epoch 11, Step 38612: Loss=5.6804, Acc=0.212, 
2025-10-04 19:21:32,264 - training.trainer - INFO - Epoch 11, Step 38712: Loss=4.4656, Acc=0.451, 
2025-10-04 19:21:39,769 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.6336, Acc=0.241, 
2025-10-04 19:21:47,350 - training.trainer - INFO - Epoch 11, Step 38912: Loss=5.6153, Acc=0.333, 
2025-10-04 19:21:54,953 - training.trainer - INFO - Epoch 11, Step 39012: Loss=5.7189, Acc=0.278, 
2025-10-04 19:22:02,622 - training.trainer - INFO - Epoch 11, Step 39112: Loss=4.6219, Acc=0.375, 
2025-10-04 19:22:10,308 - training.trainer - INFO - Epoch 11, Step 39212: Loss=5.7912, Acc=0.241, 
2025-10-04 19:22:17,898 - training.trainer - INFO - Epoch 11, Step 39312: Loss=5.0708, Acc=0.379, 
2025-10-04 19:22:25,518 - training.trainer - INFO - Epoch 11, Step 39412: Loss=5.9008, Acc=0.250, 
2025-10-04 19:22:33,135 - training.trainer - INFO - Epoch 11, Step 39512: Loss=5.0913, Acc=0.367, 
2025-10-04 19:22:40,764 - training.trainer - INFO - Epoch 11, Step 39612: Loss=5.4206, Acc=0.171, 
2025-10-04 19:22:48,209 - training.trainer - INFO - Epoch 11, Step 39712: Loss=5.4911, Acc=0.268, 
2025-10-04 19:22:55,352 - training.trainer - INFO - Epoch 11, Step 39812: Loss=5.0707, Acc=0.250, 
2025-10-04 19:23:02,991 - training.trainer - INFO - Epoch 11, Step 39912: Loss=4.6427, Acc=0.333, 
2025-10-04 19:23:10,830 - training.trainer - INFO - Epoch 11, Step 40012: Loss=6.2976, Acc=0.237, 
2025-10-04 19:23:18,435 - training.trainer - INFO - Epoch 11, Step 40112: Loss=2.8416, Acc=0.667, 
2025-10-04 19:23:26,048 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.7060, Acc=0.208, 
2025-10-04 19:23:33,472 - training.trainer - INFO - Epoch 11, Step 40312: Loss=5.2990, Acc=0.227, 
2025-10-04 19:23:41,016 - training.trainer - INFO - Epoch 11, Step 40412: Loss=5.8233, Acc=0.281, 
2025-10-04 19:23:48,534 - training.trainer - INFO - Epoch 11, Step 40512: Loss=5.7446, Acc=0.208, 
2025-10-04 19:24:08,519 - training.trainer - INFO - Epoch 12/100 completed in 268.64s - Train Loss: 5.3074, Train Acc: 0.311, Val Loss: 5.6873, Val Acc: 0.258
2025-10-04 19:24:15,773 - training.trainer - INFO - Epoch 12, Step 40695: Loss=3.2710, Acc=0.562, 
2025-10-04 19:24:23,121 - training.trainer - INFO - Epoch 12, Step 40795: Loss=5.4593, Acc=0.310, 
2025-10-04 19:24:30,693 - training.trainer - INFO - Epoch 12, Step 40895: Loss=5.6731, Acc=0.281, 
2025-10-04 19:24:38,064 - training.trainer - INFO - Epoch 12, Step 40995: Loss=5.8930, Acc=0.302, 
2025-10-04 19:24:45,481 - training.trainer - INFO - Epoch 12, Step 41095: Loss=6.6960, Acc=0.242, 
2025-10-04 19:24:52,986 - training.trainer - INFO - Epoch 12, Step 41195: Loss=5.5191, Acc=0.314, 
2025-10-04 19:25:01,016 - training.trainer - INFO - Epoch 12, Step 41295: Loss=4.2052, Acc=0.463, 
2025-10-04 19:25:08,586 - training.trainer - INFO - Epoch 12, Step 41395: Loss=5.3561, Acc=0.346, 
2025-10-04 19:25:16,252 - training.trainer - INFO - Epoch 12, Step 41495: Loss=5.4055, Acc=0.290, 
2025-10-04 19:25:23,924 - training.trainer - INFO - Epoch 12, Step 41595: Loss=5.8426, Acc=0.292, 
2025-10-04 19:25:31,526 - training.trainer - INFO - Epoch 12, Step 41695: Loss=5.7058, Acc=0.211, 
2025-10-04 19:25:39,126 - training.trainer - INFO - Epoch 12, Step 41795: Loss=5.0127, Acc=0.378, 
2025-10-04 19:25:46,674 - training.trainer - INFO - Epoch 12, Step 41895: Loss=4.9009, Acc=0.424, 
2025-10-04 19:25:54,243 - training.trainer - INFO - Epoch 12, Step 41995: Loss=5.4894, Acc=0.340, 
2025-10-04 19:26:01,970 - training.trainer - INFO - Epoch 12, Step 42095: Loss=5.9028, Acc=0.279, 
2025-10-04 19:26:09,490 - training.trainer - INFO - Epoch 12, Step 42195: Loss=4.6112, Acc=0.438, 
2025-10-04 19:26:16,843 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.0603, Acc=0.303, 
2025-10-04 19:26:24,527 - training.trainer - INFO - Epoch 12, Step 42395: Loss=5.3133, Acc=0.312, 
2025-10-04 19:26:32,140 - training.trainer - INFO - Epoch 12, Step 42495: Loss=5.9207, Acc=0.259, 
2025-10-04 19:26:39,661 - training.trainer - INFO - Epoch 12, Step 42595: Loss=5.3033, Acc=0.222, 
2025-10-04 19:26:47,154 - training.trainer - INFO - Epoch 12, Step 42695: Loss=4.9292, Acc=0.442, 
2025-10-04 19:26:54,651 - training.trainer - INFO - Epoch 12, Step 42795: Loss=5.5011, Acc=0.358, 
2025-10-04 19:27:02,264 - training.trainer - INFO - Epoch 12, Step 42895: Loss=4.6807, Acc=0.361, 
2025-10-04 19:27:09,593 - training.trainer - INFO - Epoch 12, Step 42995: Loss=5.3978, Acc=0.304, 
2025-10-04 19:27:17,107 - training.trainer - INFO - Epoch 12, Step 43095: Loss=5.3333, Acc=0.314, 
2025-10-04 19:27:24,467 - training.trainer - INFO - Epoch 12, Step 43195: Loss=5.4547, Acc=0.310, 
2025-10-04 19:27:31,827 - training.trainer - INFO - Epoch 12, Step 43295: Loss=5.3416, Acc=0.375, 
2025-10-04 19:27:39,277 - training.trainer - INFO - Epoch 12, Step 43395: Loss=5.8949, Acc=0.283, 
2025-10-04 19:27:46,713 - training.trainer - INFO - Epoch 12, Step 43495: Loss=5.6636, Acc=0.233, 
2025-10-04 19:27:54,060 - training.trainer - INFO - Epoch 12, Step 43595: Loss=3.5224, Acc=0.667, 
2025-10-04 19:28:01,556 - training.trainer - INFO - Epoch 12, Step 43695: Loss=4.8639, Acc=0.421, 
2025-10-04 19:28:09,730 - training.trainer - INFO - Epoch 12, Step 43795: Loss=5.9410, Acc=0.279, 
2025-10-04 19:28:17,279 - training.trainer - INFO - Epoch 12, Step 43895: Loss=5.5383, Acc=0.269, 
2025-10-04 19:28:37,224 - training.trainer - INFO - Epoch 13/100 completed in 268.70s - Train Loss: 5.2558, Train Acc: 0.321, Val Loss: 5.6850, Val Acc: 0.258
2025-10-04 19:28:45,495 - training.trainer - INFO - Epoch 13, Step 44078: Loss=5.2775, Acc=0.338, 
2025-10-04 19:28:53,057 - training.trainer - INFO - Epoch 13, Step 44178: Loss=5.9096, Acc=0.238, 
2025-10-04 19:29:00,560 - training.trainer - INFO - Epoch 13, Step 44278: Loss=4.5770, Acc=0.359, 
2025-10-04 19:29:08,169 - training.trainer - INFO - Epoch 13, Step 44378: Loss=5.5013, Acc=0.200, 
2025-10-04 19:29:15,797 - training.trainer - INFO - Epoch 13, Step 44478: Loss=6.0718, Acc=0.258, 
2025-10-04 19:29:23,256 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.0186, Acc=0.357, 
2025-10-04 19:29:30,752 - training.trainer - INFO - Epoch 13, Step 44678: Loss=4.9100, Acc=0.333, 
2025-10-04 19:29:38,241 - training.trainer - INFO - Epoch 13, Step 44778: Loss=5.5975, Acc=0.216, 
2025-10-04 19:29:46,450 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.3553, Acc=0.286, 
2025-10-04 19:29:53,974 - training.trainer - INFO - Epoch 13, Step 44978: Loss=4.0590, Acc=0.444, 
2025-10-04 19:30:01,318 - training.trainer - INFO - Epoch 13, Step 45078: Loss=6.0793, Acc=0.206, 
2025-10-04 19:30:08,703 - training.trainer - INFO - Epoch 13, Step 45178: Loss=4.5925, Acc=0.500, 
2025-10-04 19:30:16,062 - training.trainer - INFO - Epoch 13, Step 45278: Loss=5.7007, Acc=0.283, 
2025-10-04 19:30:23,522 - training.trainer - INFO - Epoch 13, Step 45378: Loss=5.7689, Acc=0.286, 
2025-10-04 19:30:30,885 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.4923, Acc=0.256, 
2025-10-04 19:30:38,243 - training.trainer - INFO - Epoch 13, Step 45578: Loss=5.5607, Acc=0.311, 
2025-10-04 19:30:45,682 - training.trainer - INFO - Epoch 13, Step 45678: Loss=5.1711, Acc=0.189, 
2025-10-04 19:30:53,107 - training.trainer - INFO - Epoch 13, Step 45778: Loss=4.3536, Acc=0.467, 
2025-10-04 19:31:00,588 - training.trainer - INFO - Epoch 13, Step 45878: Loss=4.4605, Acc=0.353, 
2025-10-04 19:31:07,860 - training.trainer - INFO - Epoch 13, Step 45978: Loss=6.1057, Acc=0.194, 
2025-10-04 19:31:15,323 - training.trainer - INFO - Epoch 13, Step 46078: Loss=5.0905, Acc=0.356, 
2025-10-04 19:31:22,787 - training.trainer - INFO - Epoch 13, Step 46178: Loss=5.6962, Acc=0.257, 
2025-10-04 19:31:30,154 - training.trainer - INFO - Epoch 13, Step 46278: Loss=5.2657, Acc=0.300, 
2025-10-04 19:31:37,643 - training.trainer - INFO - Epoch 13, Step 46378: Loss=5.0908, Acc=0.322, 
2025-10-04 19:31:45,242 - training.trainer - INFO - Epoch 13, Step 46478: Loss=4.4819, Acc=0.486, 
2025-10-04 19:31:52,563 - training.trainer - INFO - Epoch 13, Step 46578: Loss=4.9248, Acc=0.367, 
2025-10-04 19:32:00,017 - training.trainer - INFO - Epoch 13, Step 46678: Loss=5.5492, Acc=0.186, 
2025-10-04 19:32:07,462 - training.trainer - INFO - Epoch 13, Step 46778: Loss=5.5619, Acc=0.310, 
2025-10-04 19:32:14,895 - training.trainer - INFO - Epoch 13, Step 46878: Loss=3.6871, Acc=0.591, 
2025-10-04 19:32:22,258 - training.trainer - INFO - Epoch 13, Step 46978: Loss=5.2075, Acc=0.367, 
2025-10-04 19:32:29,756 - training.trainer - INFO - Epoch 13, Step 47078: Loss=5.7248, Acc=0.318, 
2025-10-04 19:32:37,177 - training.trainer - INFO - Epoch 13, Step 47178: Loss=4.6574, Acc=0.403, 
2025-10-04 19:32:44,528 - training.trainer - INFO - Epoch 13, Step 47278: Loss=5.7148, Acc=0.280, 
2025-10-04 19:33:04,035 - training.trainer - INFO - Epoch 14/100 completed in 266.81s - Train Loss: 5.1874, Train Acc: 0.332, Val Loss: 5.7204, Val Acc: 0.262
2025-10-04 19:33:10,961 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.1462, Acc=0.308, 
2025-10-04 19:33:17,307 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.3224, Acc=0.222, 
2025-10-04 19:33:23,671 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.6744, Acc=0.194, 
2025-10-04 19:33:29,956 - training.trainer - INFO - Epoch 14, Step 47761: Loss=5.2385, Acc=0.361, 
2025-10-04 19:33:36,482 - training.trainer - INFO - Epoch 14, Step 47861: Loss=5.5943, Acc=0.184, 
2025-10-04 19:33:42,996 - training.trainer - INFO - Epoch 14, Step 47961: Loss=4.3337, Acc=0.388, 
2025-10-04 19:33:49,718 - training.trainer - INFO - Epoch 14, Step 48061: Loss=4.3587, Acc=0.385, 
2025-10-04 19:33:55,993 - training.trainer - INFO - Epoch 14, Step 48161: Loss=4.9488, Acc=0.255, 
2025-10-04 19:34:02,905 - training.trainer - INFO - Epoch 14, Step 48261: Loss=5.4657, Acc=0.346, 
2025-10-04 19:34:10,055 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.1201, Acc=0.364, 
2025-10-04 19:34:17,521 - training.trainer - INFO - Epoch 14, Step 48461: Loss=4.9380, Acc=0.257, 
2025-10-04 19:34:24,151 - training.trainer - INFO - Epoch 14, Step 48561: Loss=5.4452, Acc=0.289, 
2025-10-04 19:34:30,763 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.0638, Acc=0.341, 
2025-10-04 19:34:37,835 - training.trainer - INFO - Epoch 14, Step 48761: Loss=5.5287, Acc=0.323, 
2025-10-04 19:34:45,148 - training.trainer - INFO - Epoch 14, Step 48861: Loss=5.4173, Acc=0.296, 
2025-10-04 19:34:52,734 - training.trainer - INFO - Epoch 14, Step 48961: Loss=5.3097, Acc=0.410, 
2025-10-04 19:35:00,325 - training.trainer - INFO - Epoch 14, Step 49061: Loss=5.0023, Acc=0.306, 
2025-10-04 19:35:07,924 - training.trainer - INFO - Epoch 14, Step 49161: Loss=6.0540, Acc=0.216, 
2025-10-04 19:35:15,560 - training.trainer - INFO - Epoch 14, Step 49261: Loss=5.4068, Acc=0.294, 
2025-10-04 19:35:23,164 - training.trainer - INFO - Epoch 14, Step 49361: Loss=5.1417, Acc=0.417, 
2025-10-04 19:35:30,658 - training.trainer - INFO - Epoch 14, Step 49461: Loss=3.6322, Acc=0.600, 
2025-10-04 19:35:38,360 - training.trainer - INFO - Epoch 14, Step 49561: Loss=5.1138, Acc=0.350, 
2025-10-04 19:35:45,873 - training.trainer - INFO - Epoch 14, Step 49661: Loss=5.3835, Acc=0.323, 
2025-10-04 19:35:53,378 - training.trainer - INFO - Epoch 14, Step 49761: Loss=5.1016, Acc=0.339, 
2025-10-04 19:36:00,786 - training.trainer - INFO - Epoch 14, Step 49861: Loss=5.2033, Acc=0.375, 
2025-10-04 19:36:08,194 - training.trainer - INFO - Epoch 14, Step 49961: Loss=5.4146, Acc=0.321, 
2025-10-04 19:36:15,726 - training.trainer - INFO - Epoch 14, Step 50061: Loss=6.3641, Acc=0.250, 
2025-10-04 19:36:23,355 - training.trainer - INFO - Epoch 14, Step 50161: Loss=5.1157, Acc=0.259, 
2025-10-04 19:36:30,940 - training.trainer - INFO - Epoch 14, Step 50261: Loss=3.8281, Acc=0.409, 
2025-10-04 19:36:38,348 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.4083, Acc=0.375, 
2025-10-04 19:36:45,545 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.5179, Acc=0.320, 
2025-10-04 19:36:53,185 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.1600, Acc=0.306, 
2025-10-04 19:37:00,706 - training.trainer - INFO - Epoch 14, Step 50661: Loss=2.9437, Acc=0.673, 
2025-10-04 19:37:20,350 - training.trainer - INFO - Epoch 15/100 completed in 256.31s - Train Loss: 5.1338, Train Acc: 0.341, Val Loss: 5.7513, Val Acc: 0.261
2025-10-04 19:37:20,692 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-04 19:37:28,759 - training.trainer - INFO - Epoch 15, Step 50844: Loss=4.5221, Acc=0.333, 
2025-10-04 19:37:36,175 - training.trainer - INFO - Epoch 15, Step 50944: Loss=5.5571, Acc=0.286, 
2025-10-04 19:37:43,592 - training.trainer - INFO - Epoch 15, Step 51044: Loss=5.8981, Acc=0.214, 
2025-10-04 19:37:50,987 - training.trainer - INFO - Epoch 15, Step 51144: Loss=4.8699, Acc=0.259, 
2025-10-04 19:37:58,482 - training.trainer - INFO - Epoch 15, Step 51244: Loss=4.2793, Acc=0.474, 
2025-10-04 19:38:05,974 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.5717, Acc=0.303, 
2025-10-04 19:38:13,445 - training.trainer - INFO - Epoch 15, Step 51444: Loss=5.1982, Acc=0.381, 
2025-10-04 19:38:20,974 - training.trainer - INFO - Epoch 15, Step 51544: Loss=4.6610, Acc=0.433, 
2025-10-04 19:38:28,660 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.4462, Acc=0.209, 
2025-10-04 19:38:36,095 - training.trainer - INFO - Epoch 15, Step 51744: Loss=4.5339, Acc=0.447, 
2025-10-04 19:38:43,513 - training.trainer - INFO - Epoch 15, Step 51844: Loss=4.5498, Acc=0.515, 
2025-10-04 19:38:51,040 - training.trainer - INFO - Epoch 15, Step 51944: Loss=4.9766, Acc=0.419, 
2025-10-04 19:38:58,743 - training.trainer - INFO - Epoch 15, Step 52044: Loss=5.8732, Acc=0.278, 
2025-10-04 19:39:06,457 - training.trainer - INFO - Epoch 15, Step 52144: Loss=5.8957, Acc=0.255, 
2025-10-04 19:39:13,994 - training.trainer - INFO - Epoch 15, Step 52244: Loss=4.5184, Acc=0.367, 
2025-10-04 19:39:21,747 - training.trainer - INFO - Epoch 15, Step 52344: Loss=5.8170, Acc=0.241, 
2025-10-04 19:39:29,347 - training.trainer - INFO - Epoch 15, Step 52444: Loss=5.3184, Acc=0.342, 
2025-10-04 19:39:36,895 - training.trainer - INFO - Epoch 15, Step 52544: Loss=5.5417, Acc=0.286, 
2025-10-04 19:39:44,478 - training.trainer - INFO - Epoch 15, Step 52644: Loss=4.9761, Acc=0.308, 
2025-10-04 19:39:52,016 - training.trainer - INFO - Epoch 15, Step 52744: Loss=2.7978, Acc=0.750, 
2025-10-04 19:39:59,492 - training.trainer - INFO - Epoch 15, Step 52844: Loss=5.3870, Acc=0.296, 
2025-10-04 19:40:07,069 - training.trainer - INFO - Epoch 15, Step 52944: Loss=4.5428, Acc=0.432, 
2025-10-04 19:40:14,676 - training.trainer - INFO - Epoch 15, Step 53044: Loss=5.5130, Acc=0.342, 
2025-10-04 19:40:22,094 - training.trainer - INFO - Epoch 15, Step 53144: Loss=5.4412, Acc=0.300, 
2025-10-04 19:40:29,533 - training.trainer - INFO - Epoch 15, Step 53244: Loss=4.4356, Acc=0.400, 
2025-10-04 19:40:37,163 - training.trainer - INFO - Epoch 15, Step 53344: Loss=5.3234, Acc=0.433, 
2025-10-04 19:40:44,658 - training.trainer - INFO - Epoch 15, Step 53444: Loss=5.4979, Acc=0.273, 
2025-10-04 19:40:52,155 - training.trainer - INFO - Epoch 15, Step 53544: Loss=5.5898, Acc=0.344, 
2025-10-04 19:40:59,664 - training.trainer - INFO - Epoch 15, Step 53644: Loss=5.1528, Acc=0.222, 
2025-10-04 19:41:07,110 - training.trainer - INFO - Epoch 15, Step 53744: Loss=5.3659, Acc=0.329, 
2025-10-04 19:41:14,672 - training.trainer - INFO - Epoch 15, Step 53844: Loss=5.0271, Acc=0.364, 
2025-10-04 19:41:21,983 - training.trainer - INFO - Epoch 15, Step 53944: Loss=4.1827, Acc=0.364, 
2025-10-04 19:41:29,434 - training.trainer - INFO - Epoch 15, Step 54044: Loss=5.8223, Acc=0.286, 
2025-10-04 19:41:49,192 - training.trainer - INFO - Epoch 16/100 completed in 268.50s - Train Loss: 5.0832, Train Acc: 0.351, Val Loss: 5.7253, Val Acc: 0.262
2025-10-04 19:41:56,208 - training.trainer - INFO - Epoch 16, Step 54227: Loss=5.7210, Acc=0.312, 
2025-10-04 19:42:03,830 - training.trainer - INFO - Epoch 16, Step 54327: Loss=4.4605, Acc=0.393, 
2025-10-04 19:42:11,539 - training.trainer - INFO - Epoch 16, Step 54427: Loss=5.5538, Acc=0.318, 
2025-10-04 19:42:19,070 - training.trainer - INFO - Epoch 16, Step 54527: Loss=5.6388, Acc=0.357, 
2025-10-04 19:42:26,476 - training.trainer - INFO - Epoch 16, Step 54627: Loss=5.1689, Acc=0.333, 
2025-10-04 19:42:34,000 - training.trainer - INFO - Epoch 16, Step 54727: Loss=5.1949, Acc=0.314, 
2025-10-04 19:42:41,591 - training.trainer - INFO - Epoch 16, Step 54827: Loss=2.6935, Acc=0.682, 
2025-10-04 19:42:49,130 - training.trainer - INFO - Epoch 16, Step 54927: Loss=3.5876, Acc=0.486, 
2025-10-04 19:42:56,777 - training.trainer - INFO - Epoch 16, Step 55027: Loss=5.3097, Acc=0.294, 
2025-10-04 19:43:04,234 - training.trainer - INFO - Epoch 16, Step 55127: Loss=4.6078, Acc=0.388, 
2025-10-04 19:43:11,787 - training.trainer - INFO - Epoch 16, Step 55227: Loss=5.1468, Acc=0.297, 
2025-10-04 19:43:19,823 - training.trainer - INFO - Epoch 16, Step 55327: Loss=5.6252, Acc=0.333, 
2025-10-04 19:43:27,443 - training.trainer - INFO - Epoch 16, Step 55427: Loss=5.4108, Acc=0.462, 
2025-10-04 19:43:34,836 - training.trainer - INFO - Epoch 16, Step 55527: Loss=4.8201, Acc=0.417, 
2025-10-04 19:43:42,176 - training.trainer - INFO - Epoch 16, Step 55627: Loss=4.5641, Acc=0.500, 
2025-10-04 19:43:49,520 - training.trainer - INFO - Epoch 16, Step 55727: Loss=6.4615, Acc=0.191, 
2025-10-04 19:43:57,034 - training.trainer - INFO - Epoch 16, Step 55827: Loss=6.2247, Acc=0.275, 
2025-10-04 19:44:04,647 - training.trainer - INFO - Epoch 16, Step 55927: Loss=5.5412, Acc=0.281, 
2025-10-04 19:44:12,362 - training.trainer - INFO - Epoch 16, Step 56027: Loss=5.2947, Acc=0.297, 
2025-10-04 19:44:19,843 - training.trainer - INFO - Epoch 16, Step 56127: Loss=5.7751, Acc=0.230, 
2025-10-04 19:44:27,449 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.7037, Acc=0.231, 
2025-10-04 19:44:34,945 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.3853, Acc=0.310, 
2025-10-04 19:44:42,435 - training.trainer - INFO - Epoch 16, Step 56427: Loss=5.4630, Acc=0.225, 
2025-10-04 19:44:49,913 - training.trainer - INFO - Epoch 16, Step 56527: Loss=4.5635, Acc=0.304, 
2025-10-04 19:44:57,518 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.0915, Acc=0.383, 
2025-10-04 19:45:05,270 - training.trainer - INFO - Epoch 16, Step 56727: Loss=3.1742, Acc=0.618, 
2025-10-04 19:45:12,680 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.5068, Acc=0.295, 
2025-10-04 19:45:20,119 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.8033, Acc=0.281, 
2025-10-04 19:45:27,528 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.6165, Acc=0.375, 
2025-10-04 19:45:35,098 - training.trainer - INFO - Epoch 16, Step 57127: Loss=5.0907, Acc=0.379, 
2025-10-04 19:45:42,693 - training.trainer - INFO - Epoch 16, Step 57227: Loss=5.6022, Acc=0.368, 
2025-10-04 19:45:50,298 - training.trainer - INFO - Epoch 16, Step 57327: Loss=4.8947, Acc=0.400, 
2025-10-04 19:45:57,788 - training.trainer - INFO - Epoch 16, Step 57427: Loss=5.1907, Acc=0.375, 
2025-10-04 19:46:17,008 - training.trainer - INFO - Epoch 17/100 completed in 267.81s - Train Loss: 5.0310, Train Acc: 0.361, Val Loss: 5.7694, Val Acc: 0.263
2025-10-04 19:46:24,838 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.5918, Acc=0.289, 
2025-10-04 19:46:32,547 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.6009, Acc=0.377, 
2025-10-04 19:46:40,129 - training.trainer - INFO - Epoch 17, Step 57810: Loss=5.4778, Acc=0.275, 
2025-10-04 19:46:47,501 - training.trainer - INFO - Epoch 17, Step 57910: Loss=5.0834, Acc=0.316, 
2025-10-04 19:46:54,844 - training.trainer - INFO - Epoch 17, Step 58010: Loss=5.5055, Acc=0.318, 
2025-10-04 19:47:02,324 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.1550, Acc=0.313, 
2025-10-04 19:47:09,847 - training.trainer - INFO - Epoch 17, Step 58210: Loss=4.7593, Acc=0.364, 
2025-10-04 19:47:17,531 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.8306, Acc=0.319, 
2025-10-04 19:47:24,840 - training.trainer - INFO - Epoch 17, Step 58410: Loss=4.1111, Acc=0.424, 
2025-10-04 19:47:32,208 - training.trainer - INFO - Epoch 17, Step 58510: Loss=5.0023, Acc=0.318, 
2025-10-04 19:47:39,585 - training.trainer - INFO - Epoch 17, Step 58610: Loss=5.3930, Acc=0.306, 
2025-10-04 19:47:47,097 - training.trainer - INFO - Epoch 17, Step 58710: Loss=4.5378, Acc=0.353, 
2025-10-04 19:47:54,554 - training.trainer - INFO - Epoch 17, Step 58810: Loss=4.9691, Acc=0.348, 
2025-10-04 19:48:01,956 - training.trainer - INFO - Epoch 17, Step 58910: Loss=4.5693, Acc=0.467, 
2025-10-04 19:48:09,449 - training.trainer - INFO - Epoch 17, Step 59010: Loss=5.2166, Acc=0.333, 
2025-10-04 19:48:16,867 - training.trainer - INFO - Epoch 17, Step 59110: Loss=5.0306, Acc=0.357, 
2025-10-04 19:48:24,495 - training.trainer - INFO - Epoch 17, Step 59210: Loss=4.7570, Acc=0.414, 
2025-10-04 19:48:31,879 - training.trainer - INFO - Epoch 17, Step 59310: Loss=4.1308, Acc=0.500, 
2025-10-04 19:48:39,244 - training.trainer - INFO - Epoch 17, Step 59410: Loss=4.7064, Acc=0.433, 
2025-10-04 19:48:46,659 - training.trainer - INFO - Epoch 17, Step 59510: Loss=4.4681, Acc=0.443, 
2025-10-04 19:48:54,140 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.6919, Acc=0.328, 
2025-10-04 19:49:01,520 - training.trainer - INFO - Epoch 17, Step 59710: Loss=5.0425, Acc=0.359, 
2025-10-04 19:49:09,013 - training.trainer - INFO - Epoch 17, Step 59810: Loss=5.2035, Acc=0.365, 
2025-10-04 19:49:16,397 - training.trainer - INFO - Epoch 17, Step 59910: Loss=5.0488, Acc=0.282, 
2025-10-04 19:49:23,916 - training.trainer - INFO - Epoch 17, Step 60010: Loss=4.8107, Acc=0.375, 
2025-10-04 19:49:31,286 - training.trainer - INFO - Epoch 17, Step 60110: Loss=5.9380, Acc=0.265, 
2025-10-04 19:49:38,926 - training.trainer - INFO - Epoch 17, Step 60210: Loss=3.8199, Acc=0.568, 
2025-10-04 19:49:46,518 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.4095, Acc=0.323, 
2025-10-04 19:49:54,021 - training.trainer - INFO - Epoch 17, Step 60410: Loss=5.5604, Acc=0.344, 
2025-10-04 19:50:01,664 - training.trainer - INFO - Epoch 17, Step 60510: Loss=4.0072, Acc=0.524, 
2025-10-04 19:50:09,119 - training.trainer - INFO - Epoch 17, Step 60610: Loss=6.2954, Acc=0.278, 
2025-10-04 19:50:16,450 - training.trainer - INFO - Epoch 17, Step 60710: Loss=5.0528, Acc=0.318, 
2025-10-04 19:50:23,781 - training.trainer - INFO - Epoch 17, Step 60810: Loss=5.1487, Acc=0.343, 
2025-10-04 19:50:43,434 - training.trainer - INFO - Epoch 18/100 completed in 266.43s - Train Loss: 4.9697, Train Acc: 0.372, Val Loss: 5.8024, Val Acc: 0.264
2025-10-04 19:50:50,104 - training.trainer - INFO - Epoch 18, Step 60993: Loss=4.7873, Acc=0.318, 
2025-10-04 19:50:56,317 - training.trainer - INFO - Epoch 18, Step 61093: Loss=4.2052, Acc=0.500, 
2025-10-04 19:51:02,737 - training.trainer - INFO - Epoch 18, Step 61193: Loss=4.0690, Acc=0.526, 
2025-10-04 19:51:09,079 - training.trainer - INFO - Epoch 18, Step 61293: Loss=4.9918, Acc=0.423, 
2025-10-04 19:51:15,321 - training.trainer - INFO - Epoch 18, Step 61393: Loss=3.9099, Acc=0.438, 
2025-10-04 19:51:21,574 - training.trainer - INFO - Epoch 18, Step 61493: Loss=5.2746, Acc=0.385, 
2025-10-04 19:51:27,902 - training.trainer - INFO - Epoch 18, Step 61593: Loss=5.0152, Acc=0.368, 
2025-10-04 19:51:34,277 - training.trainer - INFO - Epoch 18, Step 61693: Loss=4.7215, Acc=0.345, 
2025-10-04 19:51:40,825 - training.trainer - INFO - Epoch 18, Step 61793: Loss=3.7953, Acc=0.455, 
2025-10-04 19:51:47,787 - training.trainer - INFO - Epoch 18, Step 61893: Loss=5.2723, Acc=0.286, 
2025-10-04 19:51:54,869 - training.trainer - INFO - Epoch 18, Step 61993: Loss=5.1718, Acc=0.381, 
2025-10-04 19:52:01,545 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.9929, Acc=0.303, 
2025-10-04 19:52:07,921 - training.trainer - INFO - Epoch 18, Step 62193: Loss=5.3393, Acc=0.281, 
2025-10-04 19:52:14,273 - training.trainer - INFO - Epoch 18, Step 62293: Loss=5.4923, Acc=0.366, 
2025-10-04 19:52:20,960 - training.trainer - INFO - Epoch 18, Step 62393: Loss=5.7460, Acc=0.267, 
2025-10-04 19:52:27,353 - training.trainer - INFO - Epoch 18, Step 62493: Loss=5.0591, Acc=0.302, 
2025-10-04 19:52:33,675 - training.trainer - INFO - Epoch 18, Step 62593: Loss=5.0656, Acc=0.382, 
2025-10-04 19:52:40,091 - training.trainer - INFO - Epoch 18, Step 62693: Loss=5.2845, Acc=0.296, 
2025-10-04 19:52:46,700 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.4080, Acc=0.283, 
2025-10-04 19:52:52,992 - training.trainer - INFO - Epoch 18, Step 62893: Loss=4.8574, Acc=0.412, 
2025-10-04 19:52:59,262 - training.trainer - INFO - Epoch 18, Step 62993: Loss=4.4027, Acc=0.368, 
2025-10-04 19:53:05,538 - training.trainer - INFO - Epoch 18, Step 63093: Loss=4.9556, Acc=0.318, 
2025-10-04 19:53:11,816 - training.trainer - INFO - Epoch 18, Step 63193: Loss=5.2417, Acc=0.370, 
2025-10-04 19:53:18,880 - training.trainer - INFO - Epoch 18, Step 63293: Loss=4.8744, Acc=0.268, 
2025-10-04 19:53:26,415 - training.trainer - INFO - Epoch 18, Step 63393: Loss=4.6279, Acc=0.405, 
2025-10-04 19:53:34,024 - training.trainer - INFO - Epoch 18, Step 63493: Loss=6.0174, Acc=0.302, 
2025-10-04 19:53:41,553 - training.trainer - INFO - Epoch 18, Step 63593: Loss=4.7041, Acc=0.353, 
2025-10-04 19:53:49,102 - training.trainer - INFO - Epoch 18, Step 63693: Loss=3.7220, Acc=0.556, 
2025-10-04 19:53:56,527 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.4443, Acc=0.381, 
2025-10-04 19:54:03,858 - training.trainer - INFO - Epoch 18, Step 63893: Loss=4.5963, Acc=0.469, 
2025-10-04 19:54:11,178 - training.trainer - INFO - Epoch 18, Step 63993: Loss=4.8532, Acc=0.375, 
2025-10-04 19:54:18,663 - training.trainer - INFO - Epoch 18, Step 64093: Loss=4.9104, Acc=0.370, 
2025-10-04 19:54:25,988 - training.trainer - INFO - Epoch 18, Step 64193: Loss=3.6752, Acc=0.559, 
2025-10-04 19:54:46,094 - training.trainer - INFO - Epoch 19/100 completed in 242.66s - Train Loss: 4.9236, Train Acc: 0.380, Val Loss: 5.8052, Val Acc: 0.264
2025-10-04 19:54:54,325 - training.trainer - INFO - Epoch 19, Step 64376: Loss=5.6013, Acc=0.324, 
2025-10-04 19:55:01,734 - training.trainer - INFO - Epoch 19, Step 64476: Loss=4.8278, Acc=0.400, 
2025-10-04 19:55:09,351 - training.trainer - INFO - Epoch 19, Step 64576: Loss=4.2521, Acc=0.448, 
2025-10-04 19:55:16,810 - training.trainer - INFO - Epoch 19, Step 64676: Loss=4.2809, Acc=0.526, 
2025-10-04 19:55:24,396 - training.trainer - INFO - Epoch 19, Step 64776: Loss=4.8103, Acc=0.362, 
2025-10-04 19:55:31,793 - training.trainer - INFO - Epoch 19, Step 64876: Loss=4.0140, Acc=0.536, 
2025-10-04 19:55:39,275 - training.trainer - INFO - Epoch 19, Step 64976: Loss=5.9722, Acc=0.281, 
2025-10-04 19:55:46,699 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.0603, Acc=0.361, 
2025-10-04 19:55:54,189 - training.trainer - INFO - Epoch 19, Step 65176: Loss=5.0926, Acc=0.404, 
2025-10-04 19:56:01,812 - training.trainer - INFO - Epoch 19, Step 65276: Loss=3.9374, Acc=0.438, 
2025-10-04 19:56:09,248 - training.trainer - INFO - Epoch 19, Step 65376: Loss=5.5338, Acc=0.355, 
2025-10-04 19:56:16,695 - training.trainer - INFO - Epoch 19, Step 65476: Loss=5.0171, Acc=0.429, 
2025-10-04 19:56:24,185 - training.trainer - INFO - Epoch 19, Step 65576: Loss=5.7090, Acc=0.346, 
2025-10-04 19:56:31,689 - training.trainer - INFO - Epoch 19, Step 65676: Loss=4.8983, Acc=0.349, 
2025-10-04 19:56:39,107 - training.trainer - INFO - Epoch 19, Step 65776: Loss=4.3628, Acc=0.382, 
2025-10-04 19:56:46,941 - training.trainer - INFO - Epoch 19, Step 65876: Loss=4.1187, Acc=0.520, 
2025-10-04 19:56:54,467 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.7961, Acc=0.292, 
2025-10-04 19:57:01,945 - training.trainer - INFO - Epoch 19, Step 66076: Loss=4.5690, Acc=0.474, 
2025-10-04 19:57:09,575 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.0204, Acc=0.375, 
2025-10-04 19:57:17,108 - training.trainer - INFO - Epoch 19, Step 66276: Loss=4.9680, Acc=0.395, 
2025-10-04 19:57:24,623 - training.trainer - INFO - Epoch 19, Step 66376: Loss=4.8527, Acc=0.400, 
2025-10-04 19:57:32,400 - training.trainer - INFO - Epoch 19, Step 66476: Loss=4.6894, Acc=0.444, 
2025-10-04 19:57:40,087 - training.trainer - INFO - Epoch 19, Step 66576: Loss=4.3052, Acc=0.483, 
2025-10-04 19:57:47,576 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.1527, Acc=0.340, 
2025-10-04 19:57:55,143 - training.trainer - INFO - Epoch 19, Step 66776: Loss=4.7766, Acc=0.477, 
2025-10-04 19:58:02,688 - training.trainer - INFO - Epoch 19, Step 66876: Loss=5.8911, Acc=0.244, 
2025-10-04 19:58:10,303 - training.trainer - INFO - Epoch 19, Step 66976: Loss=4.8849, Acc=0.400, 
2025-10-04 19:58:18,020 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.4603, Acc=0.333, 
2025-10-04 19:58:25,567 - training.trainer - INFO - Epoch 19, Step 67176: Loss=5.8853, Acc=0.238, 
2025-10-04 19:58:33,135 - training.trainer - INFO - Epoch 19, Step 67276: Loss=5.3154, Acc=0.261, 
2025-10-04 19:58:40,693 - training.trainer - INFO - Epoch 19, Step 67376: Loss=5.2386, Acc=0.316, 
2025-10-04 19:58:48,292 - training.trainer - INFO - Epoch 19, Step 67476: Loss=4.6048, Acc=0.351, 
2025-10-04 19:58:55,852 - training.trainer - INFO - Epoch 19, Step 67576: Loss=4.1065, Acc=0.500, 
2025-10-04 19:59:15,301 - training.trainer - INFO - Epoch 20/100 completed in 269.21s - Train Loss: 4.8720, Train Acc: 0.390, Val Loss: 5.8371, Val Acc: 0.261
2025-10-04 19:59:15,724 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-04 19:59:23,538 - training.trainer - INFO - Epoch 20, Step 67759: Loss=4.5974, Acc=0.500, 
2025-10-04 19:59:30,967 - training.trainer - INFO - Epoch 20, Step 67859: Loss=4.0255, Acc=0.545, 
2025-10-04 19:59:38,794 - training.trainer - INFO - Epoch 20, Step 67959: Loss=3.8039, Acc=0.565, 
2025-10-04 19:59:46,435 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.2275, Acc=0.231, 
2025-10-04 19:59:53,900 - training.trainer - INFO - Epoch 20, Step 68159: Loss=4.8204, Acc=0.406, 
2025-10-04 20:00:01,367 - training.trainer - INFO - Epoch 20, Step 68259: Loss=4.9340, Acc=0.378, 
2025-10-04 20:00:08,797 - training.trainer - INFO - Epoch 20, Step 68359: Loss=2.8444, Acc=0.692, 
2025-10-04 20:00:16,590 - training.trainer - INFO - Epoch 20, Step 68459: Loss=5.5457, Acc=0.247, 
2025-10-04 20:00:24,225 - training.trainer - INFO - Epoch 20, Step 68559: Loss=5.6307, Acc=0.281, 
2025-10-04 20:00:31,769 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.2662, Acc=0.364, 
2025-10-04 20:00:39,277 - training.trainer - INFO - Epoch 20, Step 68759: Loss=5.6286, Acc=0.387, 
2025-10-04 20:00:46,846 - training.trainer - INFO - Epoch 20, Step 68859: Loss=5.3646, Acc=0.324, 
2025-10-04 20:00:54,427 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.5446, Acc=0.324, 
2025-10-04 20:01:02,061 - training.trainer - INFO - Epoch 20, Step 69059: Loss=5.3087, Acc=0.353, 
2025-10-04 20:01:10,035 - training.trainer - INFO - Epoch 20, Step 69159: Loss=3.9620, Acc=0.556, 
2025-10-04 20:01:17,570 - training.trainer - INFO - Epoch 20, Step 69259: Loss=4.4539, Acc=0.280, 
2025-10-04 20:01:25,124 - training.trainer - INFO - Epoch 20, Step 69359: Loss=5.6085, Acc=0.309, 
2025-10-04 20:01:32,654 - training.trainer - INFO - Epoch 20, Step 69459: Loss=5.8384, Acc=0.321, 
2025-10-04 20:01:40,276 - training.trainer - INFO - Epoch 20, Step 69559: Loss=4.5979, Acc=0.348, 
2025-10-04 20:01:47,879 - training.trainer - INFO - Epoch 20, Step 69659: Loss=4.7897, Acc=0.188, 
2025-10-04 20:01:55,233 - training.trainer - INFO - Epoch 20, Step 69759: Loss=4.7710, Acc=0.404, 
2025-10-04 20:02:02,837 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.2642, Acc=0.312, 
2025-10-04 20:02:10,638 - training.trainer - INFO - Epoch 20, Step 69959: Loss=5.4680, Acc=0.294, 
2025-10-04 20:02:18,026 - training.trainer - INFO - Epoch 20, Step 70059: Loss=3.4531, Acc=0.621, 
2025-10-04 20:02:25,450 - training.trainer - INFO - Epoch 20, Step 70159: Loss=4.8476, Acc=0.441, 
2025-10-04 20:02:33,111 - training.trainer - INFO - Epoch 20, Step 70259: Loss=4.8255, Acc=0.429, 
2025-10-04 20:02:40,813 - training.trainer - INFO - Epoch 20, Step 70359: Loss=4.6259, Acc=0.424, 
2025-10-04 20:02:48,424 - training.trainer - INFO - Epoch 20, Step 70459: Loss=5.0221, Acc=0.267, 
2025-10-04 20:02:55,911 - training.trainer - INFO - Epoch 20, Step 70559: Loss=3.2166, Acc=0.682, 
2025-10-04 20:03:03,532 - training.trainer - INFO - Epoch 20, Step 70659: Loss=4.1885, Acc=0.429, 
2025-10-04 20:03:11,233 - training.trainer - INFO - Epoch 20, Step 70759: Loss=4.0527, Acc=0.440, 
2025-10-04 20:03:18,711 - training.trainer - INFO - Epoch 20, Step 70859: Loss=4.6501, Acc=0.455, 
2025-10-04 20:03:26,350 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.6246, Acc=0.316, 
2025-10-04 20:03:45,717 - training.trainer - INFO - Epoch 21/100 completed in 269.99s - Train Loss: 4.8222, Train Acc: 0.399, Val Loss: 5.8413, Val Acc: 0.268
2025-10-04 20:03:53,805 - training.trainer - INFO - Epoch 21, Step 71142: Loss=5.2728, Acc=0.400, 
2025-10-04 20:04:01,270 - training.trainer - INFO - Epoch 21, Step 71242: Loss=4.8972, Acc=0.387, 
2025-10-04 20:04:08,888 - training.trainer - INFO - Epoch 21, Step 71342: Loss=4.5158, Acc=0.378, 
2025-10-04 20:04:16,352 - training.trainer - INFO - Epoch 21, Step 71442: Loss=4.7648, Acc=0.381, 
2025-10-04 20:04:23,778 - training.trainer - INFO - Epoch 21, Step 71542: Loss=4.8997, Acc=0.520, 
2025-10-04 20:04:31,278 - training.trainer - INFO - Epoch 21, Step 71642: Loss=3.7372, Acc=0.611, 
2025-10-04 20:04:38,774 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.0046, Acc=0.405, 
2025-10-04 20:04:46,358 - training.trainer - INFO - Epoch 21, Step 71842: Loss=5.1565, Acc=0.320, 
2025-10-04 20:04:53,822 - training.trainer - INFO - Epoch 21, Step 71942: Loss=4.5580, Acc=0.365, 
2025-10-04 20:05:01,571 - training.trainer - INFO - Epoch 21, Step 72042: Loss=3.6946, Acc=0.583, 
2025-10-04 20:05:09,081 - training.trainer - INFO - Epoch 21, Step 72142: Loss=4.0310, Acc=0.500, 
2025-10-04 20:05:16,710 - training.trainer - INFO - Epoch 21, Step 72242: Loss=5.6796, Acc=0.301, 
2025-10-04 20:05:24,167 - training.trainer - INFO - Epoch 21, Step 72342: Loss=4.5598, Acc=0.378, 
2025-10-04 20:05:31,601 - training.trainer - INFO - Epoch 21, Step 72442: Loss=4.8127, Acc=0.403, 
2025-10-04 20:05:39,032 - training.trainer - INFO - Epoch 21, Step 72542: Loss=5.1905, Acc=0.344, 
2025-10-04 20:05:46,567 - training.trainer - INFO - Epoch 21, Step 72642: Loss=5.4044, Acc=0.240, 
2025-10-04 20:05:54,409 - training.trainer - INFO - Epoch 21, Step 72742: Loss=5.7609, Acc=0.306, 
2025-10-04 20:06:01,882 - training.trainer - INFO - Epoch 21, Step 72842: Loss=4.9171, Acc=0.263, 
2025-10-04 20:06:09,323 - training.trainer - INFO - Epoch 21, Step 72942: Loss=4.5211, Acc=0.370, 
2025-10-04 20:06:16,772 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.8757, Acc=0.312, 
2025-10-04 20:06:24,430 - training.trainer - INFO - Epoch 21, Step 73142: Loss=4.0038, Acc=0.474, 
2025-10-04 20:06:31,858 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.0014, Acc=0.357, 
2025-10-04 20:06:39,387 - training.trainer - INFO - Epoch 21, Step 73342: Loss=4.6282, Acc=0.378, 
2025-10-04 20:06:47,081 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.1379, Acc=0.324, 
2025-10-04 20:06:54,747 - training.trainer - INFO - Epoch 21, Step 73542: Loss=4.3963, Acc=0.525, 
2025-10-04 20:07:02,410 - training.trainer - INFO - Epoch 21, Step 73642: Loss=4.9306, Acc=0.345, 
2025-10-04 20:07:10,061 - training.trainer - INFO - Epoch 21, Step 73742: Loss=4.2922, Acc=0.536, 
2025-10-04 20:07:17,636 - training.trainer - INFO - Epoch 21, Step 73842: Loss=3.4306, Acc=0.568, 
2025-10-04 20:07:25,316 - training.trainer - INFO - Epoch 21, Step 73942: Loss=4.0682, Acc=0.514, 
2025-10-04 20:07:32,885 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.2150, Acc=0.297, 
2025-10-04 20:07:40,410 - training.trainer - INFO - Epoch 21, Step 74142: Loss=5.1442, Acc=0.300, 
2025-10-04 20:07:48,084 - training.trainer - INFO - Epoch 21, Step 74242: Loss=4.8476, Acc=0.406, 
2025-10-04 20:07:55,476 - training.trainer - INFO - Epoch 21, Step 74342: Loss=2.0193, Acc=0.886, 
2025-10-04 20:08:15,263 - training.trainer - INFO - Epoch 22/100 completed in 269.55s - Train Loss: 4.7830, Train Acc: 0.407, Val Loss: 5.8812, Val Acc: 0.263
2025-10-04 20:08:23,571 - training.trainer - INFO - Epoch 22, Step 74525: Loss=4.4803, Acc=0.477, 
2025-10-04 20:08:31,101 - training.trainer - INFO - Epoch 22, Step 74625: Loss=5.5295, Acc=0.312, 
2025-10-04 20:08:38,781 - training.trainer - INFO - Epoch 22, Step 74725: Loss=3.6951, Acc=0.459, 
2025-10-04 20:08:46,296 - training.trainer - INFO - Epoch 22, Step 74825: Loss=4.6084, Acc=0.467, 
2025-10-04 20:08:53,814 - training.trainer - INFO - Epoch 22, Step 74925: Loss=3.4364, Acc=0.580, 
2025-10-04 20:09:01,565 - training.trainer - INFO - Epoch 22, Step 75025: Loss=4.0706, Acc=0.474, 
2025-10-04 20:09:09,302 - training.trainer - INFO - Epoch 22, Step 75125: Loss=4.4361, Acc=0.424, 
2025-10-04 20:09:16,856 - training.trainer - INFO - Epoch 22, Step 75225: Loss=4.5040, Acc=0.460, 
2025-10-04 20:09:24,553 - training.trainer - INFO - Epoch 22, Step 75325: Loss=4.7082, Acc=0.400, 
2025-10-04 20:09:32,084 - training.trainer - INFO - Epoch 22, Step 75425: Loss=4.3437, Acc=0.435, 
2025-10-04 20:09:39,761 - training.trainer - INFO - Epoch 22, Step 75525: Loss=3.5614, Acc=0.551, 
2025-10-04 20:09:47,171 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.4729, Acc=0.295, 
2025-10-04 20:09:54,854 - training.trainer - INFO - Epoch 22, Step 75725: Loss=5.4413, Acc=0.389, 
2025-10-04 20:10:02,453 - training.trainer - INFO - Epoch 22, Step 75825: Loss=5.6586, Acc=0.308, 
2025-10-04 20:10:10,206 - training.trainer - INFO - Epoch 22, Step 75925: Loss=4.9732, Acc=0.333, 
2025-10-04 20:10:17,749 - training.trainer - INFO - Epoch 22, Step 76025: Loss=4.5945, Acc=0.448, 
2025-10-04 20:10:25,328 - training.trainer - INFO - Epoch 22, Step 76125: Loss=4.8208, Acc=0.360, 
2025-10-04 20:10:32,962 - training.trainer - INFO - Epoch 22, Step 76225: Loss=4.3675, Acc=0.406, 
2025-10-04 20:10:40,503 - training.trainer - INFO - Epoch 22, Step 76325: Loss=5.1111, Acc=0.412, 
2025-10-04 20:10:48,317 - training.trainer - INFO - Epoch 22, Step 76425: Loss=3.8832, Acc=0.577, 
2025-10-04 20:10:55,867 - training.trainer - INFO - Epoch 22, Step 76525: Loss=5.5896, Acc=0.267, 
2025-10-04 20:11:03,477 - training.trainer - INFO - Epoch 22, Step 76625: Loss=4.5456, Acc=0.429, 
2025-10-04 20:11:10,970 - training.trainer - INFO - Epoch 22, Step 76725: Loss=5.1316, Acc=0.383, 
2025-10-04 20:11:18,588 - training.trainer - INFO - Epoch 22, Step 76825: Loss=5.5840, Acc=0.412, 
2025-10-04 20:11:26,042 - training.trainer - INFO - Epoch 22, Step 76925: Loss=5.1926, Acc=0.343, 
2025-10-04 20:11:33,487 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.3828, Acc=0.315, 
2025-10-04 20:11:40,952 - training.trainer - INFO - Epoch 22, Step 77125: Loss=4.8184, Acc=0.389, 
2025-10-04 20:11:48,449 - training.trainer - INFO - Epoch 22, Step 77225: Loss=5.7331, Acc=0.308, 
2025-10-04 20:11:55,860 - training.trainer - INFO - Epoch 22, Step 77325: Loss=5.0495, Acc=0.407, 
2025-10-04 20:12:03,131 - training.trainer - INFO - Epoch 22, Step 77425: Loss=4.7582, Acc=0.310, 
2025-10-04 20:12:10,510 - training.trainer - INFO - Epoch 22, Step 77525: Loss=4.3953, Acc=0.482, 
2025-10-04 20:12:17,891 - training.trainer - INFO - Epoch 22, Step 77625: Loss=4.8215, Acc=0.406, 
2025-10-04 20:12:25,444 - training.trainer - INFO - Epoch 22, Step 77725: Loss=4.7600, Acc=0.429, 
2025-10-04 20:12:45,482 - training.trainer - INFO - Epoch 23/100 completed in 270.22s - Train Loss: 4.7465, Train Acc: 0.417, Val Loss: 5.8859, Val Acc: 0.269
2025-10-04 20:12:52,940 - training.trainer - INFO - Epoch 23, Step 77908: Loss=5.4334, Acc=0.400, 
2025-10-04 20:12:59,669 - training.trainer - INFO - Epoch 23, Step 78008: Loss=4.3310, Acc=0.346, 
2025-10-04 20:13:06,113 - training.trainer - INFO - Epoch 23, Step 78108: Loss=3.1987, Acc=0.583, 
2025-10-04 20:13:12,268 - training.trainer - INFO - Epoch 23, Step 78208: Loss=5.5160, Acc=0.344, 
2025-10-04 20:13:18,683 - training.trainer - INFO - Epoch 23, Step 78308: Loss=4.5711, Acc=0.514, 
2025-10-04 20:13:26,446 - training.trainer - INFO - Epoch 23, Step 78408: Loss=4.5567, Acc=0.486, 
2025-10-04 20:13:33,841 - training.trainer - INFO - Epoch 23, Step 78508: Loss=4.4412, Acc=0.405, 
2025-10-04 20:13:40,961 - training.trainer - INFO - Epoch 23, Step 78608: Loss=4.7079, Acc=0.324, 
2025-10-04 20:13:48,383 - training.trainer - INFO - Epoch 23, Step 78708: Loss=4.7657, Acc=0.343, 
2025-10-04 20:13:55,897 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.0517, Acc=0.412, 
2025-10-04 20:14:03,385 - training.trainer - INFO - Epoch 23, Step 78908: Loss=5.0805, Acc=0.314, 
2025-10-04 20:14:10,826 - training.trainer - INFO - Epoch 23, Step 79008: Loss=5.5068, Acc=0.412, 
2025-10-04 20:14:18,195 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.1686, Acc=0.329, 
2025-10-04 20:14:25,567 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.0907, Acc=0.389, 
2025-10-04 20:14:33,474 - training.trainer - INFO - Epoch 23, Step 79308: Loss=3.7658, Acc=0.581, 
2025-10-04 20:14:40,935 - training.trainer - INFO - Epoch 23, Step 79408: Loss=4.5333, Acc=0.471, 
2025-10-04 20:14:48,286 - training.trainer - INFO - Epoch 23, Step 79508: Loss=5.9720, Acc=0.328, 
2025-10-04 20:14:55,654 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.4240, Acc=0.341, 
2025-10-04 20:15:03,062 - training.trainer - INFO - Epoch 23, Step 79708: Loss=5.1952, Acc=0.300, 
2025-10-04 20:15:10,518 - training.trainer - INFO - Epoch 23, Step 79808: Loss=4.7291, Acc=0.356, 
2025-10-04 20:15:17,895 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.1119, Acc=0.302, 
2025-10-04 20:15:25,390 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.8441, Acc=0.267, 
2025-10-04 20:15:32,654 - training.trainer - INFO - Epoch 23, Step 80108: Loss=5.3506, Acc=0.400, 
2025-10-04 20:15:40,093 - training.trainer - INFO - Epoch 23, Step 80208: Loss=5.1508, Acc=0.417, 
2025-10-04 20:15:47,620 - training.trainer - INFO - Epoch 23, Step 80308: Loss=4.8846, Acc=0.475, 
2025-10-04 20:15:54,981 - training.trainer - INFO - Epoch 23, Step 80408: Loss=4.3853, Acc=0.500, 
2025-10-04 20:16:02,409 - training.trainer - INFO - Epoch 23, Step 80508: Loss=5.5111, Acc=0.370, 
2025-10-04 20:16:09,926 - training.trainer - INFO - Epoch 23, Step 80608: Loss=5.0314, Acc=0.400, 
2025-10-04 20:16:17,342 - training.trainer - INFO - Epoch 23, Step 80708: Loss=4.7917, Acc=0.435, 
2025-10-04 20:16:24,748 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.5311, Acc=0.375, 
2025-10-04 20:16:32,141 - training.trainer - INFO - Epoch 23, Step 80908: Loss=4.6810, Acc=0.400, 
2025-10-04 20:16:39,476 - training.trainer - INFO - Epoch 23, Step 81008: Loss=4.7608, Acc=0.382, 
2025-10-04 20:16:47,061 - training.trainer - INFO - Epoch 23, Step 81108: Loss=4.9499, Acc=0.391, 
2025-10-04 20:17:06,847 - training.trainer - INFO - Epoch 24/100 completed in 261.36s - Train Loss: 4.7042, Train Acc: 0.427, Val Loss: 5.9223, Val Acc: 0.261
2025-10-04 20:17:13,714 - training.trainer - INFO - Epoch 24, Step 81291: Loss=4.1559, Acc=0.483, 
2025-10-04 20:17:20,038 - training.trainer - INFO - Epoch 24, Step 81391: Loss=5.3163, Acc=0.367, 
2025-10-04 20:17:26,288 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.1467, Acc=0.429, 
2025-10-04 20:17:32,535 - training.trainer - INFO - Epoch 24, Step 81591: Loss=4.1361, Acc=0.522, 
2025-10-04 20:17:38,966 - training.trainer - INFO - Epoch 24, Step 81691: Loss=4.3475, Acc=0.483, 
2025-10-04 20:17:45,212 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.4773, Acc=0.333, 
2025-10-04 20:17:51,606 - training.trainer - INFO - Epoch 24, Step 81891: Loss=4.3461, Acc=0.452, 
2025-10-04 20:17:57,848 - training.trainer - INFO - Epoch 24, Step 81991: Loss=3.6843, Acc=0.667, 
2025-10-04 20:18:04,098 - training.trainer - INFO - Epoch 24, Step 82091: Loss=5.3557, Acc=0.394, 
2025-10-04 20:18:10,835 - training.trainer - INFO - Epoch 24, Step 82191: Loss=3.3357, Acc=0.700, 
2025-10-04 20:18:17,063 - training.trainer - INFO - Epoch 24, Step 82291: Loss=4.4086, Acc=0.455, 
2025-10-04 20:18:23,395 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.1750, Acc=0.351, 
2025-10-04 20:18:29,630 - training.trainer - INFO - Epoch 24, Step 82491: Loss=2.6989, Acc=0.760, 
2025-10-04 20:18:36,015 - training.trainer - INFO - Epoch 24, Step 82591: Loss=4.8881, Acc=0.390, 
2025-10-04 20:18:42,323 - training.trainer - INFO - Epoch 24, Step 82691: Loss=4.1779, Acc=0.419, 
2025-10-04 20:18:48,736 - training.trainer - INFO - Epoch 24, Step 82791: Loss=3.5303, Acc=0.645, 
2025-10-04 20:18:55,180 - training.trainer - INFO - Epoch 24, Step 82891: Loss=5.5420, Acc=0.411, 
2025-10-04 20:19:01,425 - training.trainer - INFO - Epoch 24, Step 82991: Loss=4.9771, Acc=0.357, 
2025-10-04 20:19:07,697 - training.trainer - INFO - Epoch 24, Step 83091: Loss=4.9032, Acc=0.295, 
2025-10-04 20:19:13,979 - training.trainer - INFO - Epoch 24, Step 83191: Loss=4.5811, Acc=0.367, 
2025-10-04 20:19:20,276 - training.trainer - INFO - Epoch 24, Step 83291: Loss=5.0374, Acc=0.351, 
2025-10-04 20:19:26,628 - training.trainer - INFO - Epoch 24, Step 83391: Loss=4.4768, Acc=0.459, 
2025-10-04 20:19:32,934 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.4187, Acc=0.340, 
2025-10-04 20:19:39,950 - training.trainer - INFO - Epoch 24, Step 83591: Loss=3.9097, Acc=0.519, 
2025-10-04 20:19:47,325 - training.trainer - INFO - Epoch 24, Step 83691: Loss=4.0559, Acc=0.486, 
2025-10-04 20:19:54,682 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.1262, Acc=0.344, 
2025-10-04 20:20:02,157 - training.trainer - INFO - Epoch 24, Step 83891: Loss=4.7954, Acc=0.449, 
2025-10-04 20:20:09,524 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.9003, Acc=0.310, 
2025-10-04 20:20:17,101 - training.trainer - INFO - Epoch 24, Step 84091: Loss=4.4996, Acc=0.579, 
2025-10-04 20:20:24,717 - training.trainer - INFO - Epoch 24, Step 84191: Loss=5.2193, Acc=0.303, 
2025-10-04 20:20:32,325 - training.trainer - INFO - Epoch 24, Step 84291: Loss=3.7451, Acc=0.625, 
2025-10-04 20:20:39,887 - training.trainer - INFO - Epoch 24, Step 84391: Loss=3.7758, Acc=0.667, 
2025-10-04 20:20:47,460 - training.trainer - INFO - Epoch 24, Step 84491: Loss=4.2768, Acc=0.400, 
2025-10-04 20:21:06,765 - training.trainer - INFO - Epoch 25/100 completed in 239.92s - Train Loss: 4.6774, Train Acc: 0.435, Val Loss: 5.9581, Val Acc: 0.267
2025-10-04 20:21:07,052 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-04 20:21:07,053 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-04 20:21:07,053 - training.trainer - INFO - Training completed!
2025-10-04 20:21:07,053 - __main__ - INFO - Training completed successfully!
2025-10-04 20:21:07,169 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-04 20:21:07,315 - __main__ - INFO - Process completed!
2025-10-04 20:21:21,635 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-04 20:21:21,636 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-04 20:21:21,636 - __main__ - INFO - Starting model evaluation
2025-10-04 20:21:22,383 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-04 20:26:59,032 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-04 20:26:59,048 - __main__ - INFO - Process completed!
2025-10-04 20:27:05,315 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-10-04 20:27:05,316 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-04 20:27:05,316 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-10-04 20:27:05,895 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-04 20:27:27,013 - __main__ - INFO - Inference completed successfully!
2025-10-04 20:27:27,024 - __main__ - INFO - Process completed!
2025-10-04 21:26:44,488 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-04 21:26:44,490 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-04 21:26:44,490 - __main__ - INFO - Starting model evaluation
2025-10-04 21:26:45,694 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-05 02:54:03,849 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-05 02:54:03,860 - __main__ - INFO - Process completed!
2025-10-05 13:16:10,742 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-05 13:16:10,743 - __main__ - INFO - Configuration: configs/baseline_lsa_t_config.yaml
2025-10-05 13:16:10,743 - __main__ - INFO - Starting training pipeline
2025-10-05 13:16:10,856 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-05 13:16:10,884 - __main__ - INFO - GPU: NVIDIA A30
2025-10-05 13:16:10,885 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-05 13:16:10,885 - __main__ - INFO - Loading training data...
2025-10-05 13:16:18,759 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-05 13:16:18,760 - __main__ - INFO - Processing train split...
2025-10-05 13:16:18,845 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-05 13:16:18,845 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-05 13:17:06,113 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-05 13:18:03,482 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-05 13:18:03,483 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-05 13:18:03,483 - __main__ - INFO - Starting training pipeline
2025-10-05 13:18:03,586 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-05 13:18:03,610 - __main__ - INFO - GPU: NVIDIA A30
2025-10-05 13:18:03,610 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-05 13:18:03,611 - __main__ - INFO - Loading training data...
2025-10-05 13:18:11,319 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-05 13:18:11,319 - __main__ - INFO - Processing train split...
2025-10-05 13:18:11,403 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-05 13:18:11,403 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-05 13:18:53,087 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-05 13:19:38,357 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-05 13:20:25,456 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-05 13:21:17,552 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-05 13:22:03,223 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-05 13:22:47,754 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-05 13:23:22,191 - __main__ - INFO - Processing val split...
2025-10-05 13:23:22,424 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-05 13:23:22,425 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-05 13:23:59,813 - __main__ - INFO - Processing test split...
2025-10-05 13:24:00,033 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-05 13:24:00,033 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-05 13:24:33,772 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-05 13:24:33,772 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-05 13:24:33,788 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-05 13:24:33,788 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-05 13:24:33,788 - __main__ - INFO - Creating model architecture...
2025-10-05 13:24:34,060 - __main__ - INFO - Model created successfully
2025-10-05 13:24:34,060 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-05 13:24:34,060 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-05 13:24:34,061 - __main__ - INFO - Using device: cuda
2025-10-05 13:24:34,061 - __main__ - INFO - Creating trainer...
2025-10-05 13:24:34,061 - __main__ - INFO - Moving model to cuda...
2025-10-05 13:24:34,357 - __main__ - INFO - Model moved to cuda
2025-10-05 13:24:34,358 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-05 13:24:36,369 - __main__ - INFO - Trainer created successfully
2025-10-05 13:24:36,370 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-05 13:24:36,370 - __main__ - INFO - Starting training...
2025-10-05 13:24:36,370 - __main__ - INFO - Training configuration:
2025-10-05 13:24:36,370 - __main__ - INFO -   - Epochs: 100
2025-10-05 13:24:36,370 - __main__ - INFO -   - Batch size: 2
2025-10-05 13:24:36,370 - __main__ - INFO -   - Learning rate: 3e-5
2025-10-05 13:24:36,370 - __main__ - INFO -   - Training samples: 6765
2025-10-05 13:24:36,370 - __main__ - INFO -   - Validation samples: 845
2025-10-05 13:24:36,370 - training.trainer - INFO - Starting training for 100 epochs
2025-10-05 13:24:36,371 - training.trainer - INFO - Model parameters: 16,680,032
2025-10-05 13:24:36,371 - training.trainer - INFO - Training on device: cuda
2025-10-05 13:24:46,956 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.6982, Acc=0.091, 
2025-10-05 13:24:54,406 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.3910, Acc=0.034, 
2025-10-05 13:25:01,326 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.7113, Acc=0.074, 
2025-10-05 13:25:08,277 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.5771, Acc=0.022, 
2025-10-05 13:25:15,253 - training.trainer - INFO - Epoch 0, Step 499: Loss=7.3655, Acc=0.059, 
2025-10-05 13:25:21,977 - training.trainer - INFO - Epoch 0, Step 599: Loss=6.6362, Acc=0.043, 
2025-10-05 13:25:29,450 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.4685, Acc=0.140, 
2025-10-05 13:25:37,148 - training.trainer - INFO - Epoch 0, Step 799: Loss=7.1515, Acc=0.130, 
2025-10-05 13:25:44,912 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.5482, Acc=0.103, 
2025-10-05 13:25:52,566 - training.trainer - INFO - Epoch 0, Step 999: Loss=6.4868, Acc=0.065, 
2025-10-05 13:26:00,165 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.6231, Acc=0.267, 
2025-10-05 13:26:08,163 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.5023, Acc=0.147, 
2025-10-05 13:26:16,049 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.4568, Acc=0.188, 
2025-10-05 13:26:23,926 - training.trainer - INFO - Epoch 0, Step 1399: Loss=7.3758, Acc=0.073, 
2025-10-05 13:26:31,857 - training.trainer - INFO - Epoch 0, Step 1499: Loss=5.8230, Acc=0.250, 
2025-10-05 13:26:39,497 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.1849, Acc=0.280, 
2025-10-05 13:26:47,332 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.7982, Acc=0.178, 
2025-10-05 13:26:55,198 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.8341, Acc=0.200, 
2025-10-05 13:27:02,948 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.3213, Acc=0.129, 
2025-10-05 13:27:10,518 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.1721, Acc=0.162, 
2025-10-05 13:27:18,086 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.6537, Acc=0.109, 
2025-10-05 13:27:25,664 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.7256, Acc=0.154, 
2025-10-05 13:27:33,229 - training.trainer - INFO - Epoch 0, Step 2299: Loss=7.3970, Acc=0.097, 
2025-10-05 13:27:41,145 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.7376, Acc=0.133, 
2025-10-05 13:27:48,889 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.7388, Acc=0.130, 
2025-10-05 13:27:56,507 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.2496, Acc=0.200, 
2025-10-05 13:28:04,251 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.6099, Acc=0.109, 
2025-10-05 13:28:11,902 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.9357, Acc=0.138, 
2025-10-05 13:28:19,672 - training.trainer - INFO - Epoch 0, Step 2899: Loss=7.0740, Acc=0.137, 
2025-10-05 13:28:27,266 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.0930, Acc=0.171, 
2025-10-05 13:28:34,966 - training.trainer - INFO - Epoch 0, Step 3099: Loss=7.1780, Acc=0.057, 
2025-10-05 13:28:42,606 - training.trainer - INFO - Epoch 0, Step 3199: Loss=5.4377, Acc=0.267, 
2025-10-05 13:28:50,333 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.8166, Acc=0.256, 
2025-10-05 13:29:09,923 - training.trainer - INFO - Epoch 1/100 completed in 273.55s - Train Loss: 6.8263, Train Acc: 0.130, Val Loss: 6.3840, Val Acc: 0.163
2025-10-05 13:29:10,509 - training.trainer - INFO - New best model saved with validation loss: 6.3840
2025-10-05 13:29:10,509 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-05 13:29:18,268 - training.trainer - INFO - Epoch 1, Step 3482: Loss=6.8283, Acc=0.133, 
2025-10-05 13:29:25,827 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.5129, Acc=0.167, 
2025-10-05 13:29:33,436 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.3738, Acc=0.137, 
2025-10-05 13:29:40,949 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.6791, Acc=0.103, 
2025-10-05 13:29:48,365 - training.trainer - INFO - Epoch 1, Step 3882: Loss=5.7637, Acc=0.214, 
2025-10-05 13:29:55,855 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.5852, Acc=0.087, 
2025-10-05 13:30:03,417 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.8462, Acc=0.100, 
2025-10-05 13:30:11,041 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.5889, Acc=0.139, 
2025-10-05 13:30:18,469 - training.trainer - INFO - Epoch 1, Step 4282: Loss=5.6846, Acc=0.241, 
2025-10-05 13:30:25,888 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.5482, Acc=0.103, 
2025-10-05 13:30:33,334 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.2420, Acc=0.250, 
2025-10-05 13:30:40,848 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.0608, Acc=0.208, 
2025-10-05 13:30:48,261 - training.trainer - INFO - Epoch 1, Step 4682: Loss=5.6618, Acc=0.087, 
2025-10-05 13:30:55,614 - training.trainer - INFO - Epoch 1, Step 4782: Loss=5.8861, Acc=0.182, 
2025-10-05 13:31:03,104 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.0753, Acc=0.156, 
2025-10-05 13:31:10,698 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.4719, Acc=0.250, 
2025-10-05 13:31:18,185 - training.trainer - INFO - Epoch 1, Step 5082: Loss=5.3547, Acc=0.217, 
2025-10-05 13:31:25,770 - training.trainer - INFO - Epoch 1, Step 5182: Loss=5.5882, Acc=0.212, 
2025-10-05 13:31:33,200 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.5646, Acc=0.109, 
2025-10-05 13:31:40,794 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.6164, Acc=0.180, 
2025-10-05 13:31:48,371 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.1610, Acc=0.255, 
2025-10-05 13:31:55,683 - training.trainer - INFO - Epoch 1, Step 5582: Loss=6.3573, Acc=0.250, 
2025-10-05 13:32:03,017 - training.trainer - INFO - Epoch 1, Step 5682: Loss=5.9600, Acc=0.194, 
2025-10-05 13:32:10,328 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.5359, Acc=0.140, 
2025-10-05 13:32:17,734 - training.trainer - INFO - Epoch 1, Step 5882: Loss=5.8393, Acc=0.261, 
2025-10-05 13:32:25,262 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.0438, Acc=0.100, 
2025-10-05 13:32:32,765 - training.trainer - INFO - Epoch 1, Step 6082: Loss=5.9503, Acc=0.227, 
2025-10-05 13:32:40,239 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.9151, Acc=0.130, 
2025-10-05 13:32:47,725 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.7885, Acc=0.121, 
2025-10-05 13:32:55,411 - training.trainer - INFO - Epoch 1, Step 6382: Loss=6.3098, Acc=0.184, 
2025-10-05 13:33:02,984 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.0617, Acc=0.122, 
2025-10-05 13:33:10,498 - training.trainer - INFO - Epoch 1, Step 6582: Loss=5.4985, Acc=0.286, 
2025-10-05 13:33:17,963 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.8104, Acc=0.082, 
2025-10-05 13:33:37,395 - training.trainer - INFO - Epoch 2/100 completed in 266.89s - Train Loss: 6.3193, Train Acc: 0.166, Val Loss: 6.1975, Val Acc: 0.172
2025-10-05 13:33:38,171 - training.trainer - INFO - New best model saved with validation loss: 6.1975
2025-10-05 13:33:38,171 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-05 13:33:46,096 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.7416, Acc=0.071, 
2025-10-05 13:33:53,840 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.3705, Acc=0.158, 
2025-10-05 13:34:01,442 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.2718, Acc=0.250, 
2025-10-05 13:34:08,999 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.8809, Acc=0.176, 
2025-10-05 13:34:16,347 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.5651, Acc=0.127, 
2025-10-05 13:34:23,594 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.6117, Acc=0.164, 
2025-10-05 13:34:30,886 - training.trainer - INFO - Epoch 2, Step 7465: Loss=5.7708, Acc=0.206, 
2025-10-05 13:34:38,290 - training.trainer - INFO - Epoch 2, Step 7565: Loss=5.5392, Acc=0.217, 
2025-10-05 13:34:45,497 - training.trainer - INFO - Epoch 2, Step 7665: Loss=5.9600, Acc=0.182, 
2025-10-05 13:34:52,977 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.5377, Acc=0.169, 
2025-10-05 13:35:00,512 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.3319, Acc=0.140, 
2025-10-05 13:35:07,855 - training.trainer - INFO - Epoch 2, Step 7965: Loss=6.4693, Acc=0.152, 
2025-10-05 13:35:15,297 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.4124, Acc=0.152, 
2025-10-05 13:35:22,507 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.3630, Acc=0.145, 
2025-10-05 13:35:29,721 - training.trainer - INFO - Epoch 2, Step 8265: Loss=6.0586, Acc=0.128, 
2025-10-05 13:35:37,192 - training.trainer - INFO - Epoch 2, Step 8365: Loss=6.2021, Acc=0.118, 
2025-10-05 13:35:44,783 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.4914, Acc=0.143, 
2025-10-05 13:35:52,125 - training.trainer - INFO - Epoch 2, Step 8565: Loss=5.0282, Acc=0.312, 
2025-10-05 13:35:59,492 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.0689, Acc=0.104, 
2025-10-05 13:36:06,844 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.9834, Acc=0.170, 
2025-10-05 13:36:14,241 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.3261, Acc=0.125, 
2025-10-05 13:36:21,685 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.6680, Acc=0.076, 
2025-10-05 13:36:28,959 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.6802, Acc=0.195, 
2025-10-05 13:36:36,219 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.0209, Acc=0.278, 
2025-10-05 13:36:43,496 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.3105, Acc=0.135, 
2025-10-05 13:36:50,882 - training.trainer - INFO - Epoch 2, Step 9365: Loss=7.1621, Acc=0.182, 
2025-10-05 13:36:58,143 - training.trainer - INFO - Epoch 2, Step 9465: Loss=5.7020, Acc=0.171, 
2025-10-05 13:37:05,323 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.9580, Acc=0.152, 
2025-10-05 13:37:12,567 - training.trainer - INFO - Epoch 2, Step 9665: Loss=6.2610, Acc=0.163, 
2025-10-05 13:37:19,858 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.6127, Acc=0.179, 
2025-10-05 13:37:27,379 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.6794, Acc=0.086, 
2025-10-05 13:37:34,868 - training.trainer - INFO - Epoch 2, Step 9965: Loss=6.8221, Acc=0.130, 
2025-10-05 13:37:42,160 - training.trainer - INFO - Epoch 2, Step 10065: Loss=6.2338, Acc=0.189, 
2025-10-05 13:38:02,215 - training.trainer - INFO - Epoch 3/100 completed in 264.04s - Train Loss: 6.1995, Train Acc: 0.177, Val Loss: 6.1167, Val Acc: 0.179
2025-10-05 13:38:02,938 - training.trainer - INFO - New best model saved with validation loss: 6.1167
2025-10-05 13:38:02,938 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-10-05 13:38:10,556 - training.trainer - INFO - Epoch 3, Step 10248: Loss=6.8427, Acc=0.108, 
2025-10-05 13:38:17,883 - training.trainer - INFO - Epoch 3, Step 10348: Loss=5.8940, Acc=0.217, 
2025-10-05 13:38:25,565 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.4649, Acc=0.113, 
2025-10-05 13:38:33,158 - training.trainer - INFO - Epoch 3, Step 10548: Loss=6.4365, Acc=0.143, 
2025-10-05 13:38:40,608 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.0678, Acc=0.111, 
2025-10-05 13:38:48,180 - training.trainer - INFO - Epoch 3, Step 10748: Loss=6.1252, Acc=0.286, 
2025-10-05 13:38:55,644 - training.trainer - INFO - Epoch 3, Step 10848: Loss=5.7170, Acc=0.217, 
2025-10-05 13:39:03,158 - training.trainer - INFO - Epoch 3, Step 10948: Loss=5.9334, Acc=0.146, 
2025-10-05 13:39:10,665 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.0189, Acc=0.233, 
2025-10-05 13:39:18,024 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.2738, Acc=0.200, 
2025-10-05 13:39:25,438 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.5720, Acc=0.145, 
2025-10-05 13:39:32,825 - training.trainer - INFO - Epoch 3, Step 11348: Loss=5.9312, Acc=0.250, 
2025-10-05 13:39:40,279 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.0171, Acc=0.167, 
2025-10-05 13:39:47,666 - training.trainer - INFO - Epoch 3, Step 11548: Loss=5.8056, Acc=0.200, 
2025-10-05 13:39:55,025 - training.trainer - INFO - Epoch 3, Step 11648: Loss=6.3671, Acc=0.129, 
2025-10-05 13:40:02,498 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.9349, Acc=0.212, 
2025-10-05 13:40:10,149 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.9981, Acc=0.194, 
2025-10-05 13:40:17,597 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.8268, Acc=0.104, 
2025-10-05 13:40:24,885 - training.trainer - INFO - Epoch 3, Step 12048: Loss=5.8339, Acc=0.316, 
2025-10-05 13:40:32,304 - training.trainer - INFO - Epoch 3, Step 12148: Loss=5.4660, Acc=0.375, 
2025-10-05 13:40:39,719 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.4599, Acc=0.111, 
2025-10-05 13:40:47,131 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.4292, Acc=0.122, 
2025-10-05 13:40:54,551 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.7066, Acc=0.114, 
2025-10-05 13:41:02,037 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.7036, Acc=0.118, 
2025-10-05 13:41:09,434 - training.trainer - INFO - Epoch 3, Step 12648: Loss=6.0533, Acc=0.250, 
2025-10-05 13:41:16,873 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.7076, Acc=0.167, 
2025-10-05 13:41:24,177 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.3921, Acc=0.094, 
2025-10-05 13:41:31,479 - training.trainer - INFO - Epoch 3, Step 12948: Loss=5.9680, Acc=0.200, 
2025-10-05 13:41:38,815 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.7597, Acc=0.162, 
2025-10-05 13:41:46,179 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.3284, Acc=0.178, 
2025-10-05 13:41:53,646 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.2412, Acc=0.123, 
2025-10-05 13:42:00,979 - training.trainer - INFO - Epoch 3, Step 13348: Loss=6.0010, Acc=0.148, 
2025-10-05 13:42:08,326 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.1822, Acc=0.217, 
2025-10-05 13:42:28,300 - training.trainer - INFO - Epoch 4/100 completed in 265.36s - Train Loss: 6.1353, Train Acc: 0.185, Val Loss: 6.0555, Val Acc: 0.191
2025-10-05 13:42:29,014 - training.trainer - INFO - New best model saved with validation loss: 6.0555
2025-10-05 13:42:29,014 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-10-05 13:42:36,930 - training.trainer - INFO - Epoch 4, Step 13631: Loss=5.1774, Acc=0.417, 
2025-10-05 13:42:44,439 - training.trainer - INFO - Epoch 4, Step 13731: Loss=5.8731, Acc=0.206, 
2025-10-05 13:42:51,979 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.3921, Acc=0.257, 
2025-10-05 13:42:59,387 - training.trainer - INFO - Epoch 4, Step 13931: Loss=6.1679, Acc=0.127, 
2025-10-05 13:43:06,878 - training.trainer - INFO - Epoch 4, Step 14031: Loss=6.3593, Acc=0.099, 
2025-10-05 13:43:14,269 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.4138, Acc=0.250, 
2025-10-05 13:43:21,635 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.4874, Acc=0.152, 
2025-10-05 13:43:29,036 - training.trainer - INFO - Epoch 4, Step 14331: Loss=5.6261, Acc=0.257, 
2025-10-05 13:43:36,674 - training.trainer - INFO - Epoch 4, Step 14431: Loss=5.4694, Acc=0.240, 
2025-10-05 13:43:44,172 - training.trainer - INFO - Epoch 4, Step 14531: Loss=6.2443, Acc=0.190, 
2025-10-05 13:43:51,575 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.1170, Acc=0.286, 
2025-10-05 13:43:58,971 - training.trainer - INFO - Epoch 4, Step 14731: Loss=5.9934, Acc=0.163, 
2025-10-05 13:44:06,323 - training.trainer - INFO - Epoch 4, Step 14831: Loss=6.5038, Acc=0.157, 
2025-10-05 13:44:13,646 - training.trainer - INFO - Epoch 4, Step 14931: Loss=6.1520, Acc=0.222, 
2025-10-05 13:44:21,049 - training.trainer - INFO - Epoch 4, Step 15031: Loss=6.4664, Acc=0.140, 
2025-10-05 13:44:28,399 - training.trainer - INFO - Epoch 4, Step 15131: Loss=6.5565, Acc=0.111, 
2025-10-05 13:44:35,685 - training.trainer - INFO - Epoch 4, Step 15231: Loss=6.8188, Acc=0.133, 
2025-10-05 13:44:42,905 - training.trainer - INFO - Epoch 4, Step 15331: Loss=4.8662, Acc=0.200, 
2025-10-05 13:44:50,151 - training.trainer - INFO - Epoch 4, Step 15431: Loss=5.2931, Acc=0.194, 
2025-10-05 13:44:57,449 - training.trainer - INFO - Epoch 4, Step 15531: Loss=7.0456, Acc=0.102, 
2025-10-05 13:45:04,806 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.6735, Acc=0.116, 
2025-10-05 13:45:12,268 - training.trainer - INFO - Epoch 4, Step 15731: Loss=5.7358, Acc=0.152, 
2025-10-05 13:45:19,646 - training.trainer - INFO - Epoch 4, Step 15831: Loss=5.8418, Acc=0.147, 
2025-10-05 13:45:27,041 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.4456, Acc=0.140, 
2025-10-05 13:45:34,419 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.7956, Acc=0.184, 
2025-10-05 13:45:41,785 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.6629, Acc=0.125, 
2025-10-05 13:45:49,138 - training.trainer - INFO - Epoch 4, Step 16231: Loss=5.2597, Acc=0.190, 
2025-10-05 13:45:56,499 - training.trainer - INFO - Epoch 4, Step 16331: Loss=5.7823, Acc=0.216, 
2025-10-05 13:46:04,059 - training.trainer - INFO - Epoch 4, Step 16431: Loss=5.9747, Acc=0.185, 
2025-10-05 13:46:11,449 - training.trainer - INFO - Epoch 4, Step 16531: Loss=6.1967, Acc=0.167, 
2025-10-05 13:46:18,822 - training.trainer - INFO - Epoch 4, Step 16631: Loss=6.5469, Acc=0.130, 
2025-10-05 13:46:26,196 - training.trainer - INFO - Epoch 4, Step 16731: Loss=6.3595, Acc=0.125, 
2025-10-05 13:46:33,519 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.2685, Acc=0.173, 
2025-10-05 13:46:52,436 - training.trainer - INFO - Epoch 5/100 completed in 263.42s - Train Loss: 6.0803, Train Acc: 0.194, Val Loss: 5.9897, Val Acc: 0.204
2025-10-05 13:46:52,778 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-05 13:46:53,471 - training.trainer - INFO - New best model saved with validation loss: 5.9897
2025-10-05 13:46:53,471 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-05 13:47:00,349 - training.trainer - INFO - Epoch 5, Step 17014: Loss=6.4954, Acc=0.188, 
2025-10-05 13:47:06,709 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.2858, Acc=0.125, 
2025-10-05 13:47:13,006 - training.trainer - INFO - Epoch 5, Step 17214: Loss=6.2401, Acc=0.100, 
2025-10-05 13:47:20,094 - training.trainer - INFO - Epoch 5, Step 17314: Loss=5.9429, Acc=0.211, 
2025-10-05 13:47:27,398 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.1783, Acc=0.200, 
2025-10-05 13:47:34,739 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.0099, Acc=0.167, 
2025-10-05 13:47:42,158 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.2890, Acc=0.171, 
2025-10-05 13:47:49,472 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.1398, Acc=0.125, 
2025-10-05 13:47:56,877 - training.trainer - INFO - Epoch 5, Step 17814: Loss=5.9511, Acc=0.216, 
2025-10-05 13:48:04,209 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.3848, Acc=0.200, 
2025-10-05 13:48:11,810 - training.trainer - INFO - Epoch 5, Step 18014: Loss=5.7558, Acc=0.300, 
2025-10-05 13:48:19,257 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.1349, Acc=0.167, 
2025-10-05 13:48:26,664 - training.trainer - INFO - Epoch 5, Step 18214: Loss=6.7869, Acc=0.161, 
2025-10-05 13:48:34,152 - training.trainer - INFO - Epoch 5, Step 18314: Loss=5.8348, Acc=0.269, 
2025-10-05 13:48:41,472 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.5782, Acc=0.211, 
2025-10-05 13:48:48,739 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.5423, Acc=0.141, 
2025-10-05 13:48:56,008 - training.trainer - INFO - Epoch 5, Step 18614: Loss=6.3481, Acc=0.157, 
2025-10-05 13:49:03,299 - training.trainer - INFO - Epoch 5, Step 18714: Loss=5.5788, Acc=0.172, 
2025-10-05 13:49:10,593 - training.trainer - INFO - Epoch 5, Step 18814: Loss=5.9924, Acc=0.128, 
2025-10-05 13:49:18,282 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.5602, Acc=0.192, 
2025-10-05 13:49:25,850 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.5343, Acc=0.146, 
2025-10-05 13:49:33,369 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.4906, Acc=0.182, 
2025-10-05 13:49:40,810 - training.trainer - INFO - Epoch 5, Step 19214: Loss=6.0941, Acc=0.176, 
2025-10-05 13:49:48,359 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.0511, Acc=0.200, 
2025-10-05 13:49:55,955 - training.trainer - INFO - Epoch 5, Step 19414: Loss=6.8568, Acc=0.176, 
2025-10-05 13:50:03,555 - training.trainer - INFO - Epoch 5, Step 19514: Loss=6.5924, Acc=0.184, 
2025-10-05 13:50:11,024 - training.trainer - INFO - Epoch 5, Step 19614: Loss=5.4504, Acc=0.238, 
2025-10-05 13:50:18,551 - training.trainer - INFO - Epoch 5, Step 19714: Loss=5.8559, Acc=0.136, 
2025-10-05 13:50:26,028 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.5458, Acc=0.250, 
2025-10-05 13:50:33,482 - training.trainer - INFO - Epoch 5, Step 19914: Loss=6.0178, Acc=0.200, 
2025-10-05 13:50:41,014 - training.trainer - INFO - Epoch 5, Step 20014: Loss=5.2273, Acc=0.289, 
2025-10-05 13:50:48,500 - training.trainer - INFO - Epoch 5, Step 20114: Loss=5.9427, Acc=0.211, 
2025-10-05 13:50:55,842 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.5635, Acc=0.214, 
2025-10-05 13:51:15,952 - training.trainer - INFO - Epoch 6/100 completed in 262.48s - Train Loss: 6.0310, Train Acc: 0.200, Val Loss: 5.9946, Val Acc: 0.206
2025-10-05 13:51:23,683 - training.trainer - INFO - Epoch 6, Step 20397: Loss=5.1942, Acc=0.286, 
2025-10-05 13:51:31,306 - training.trainer - INFO - Epoch 6, Step 20497: Loss=6.6108, Acc=0.172, 
2025-10-05 13:51:38,907 - training.trainer - INFO - Epoch 6, Step 20597: Loss=5.5321, Acc=0.250, 
2025-10-05 13:51:46,418 - training.trainer - INFO - Epoch 6, Step 20697: Loss=6.7745, Acc=0.161, 
2025-10-05 13:51:53,946 - training.trainer - INFO - Epoch 6, Step 20797: Loss=5.6192, Acc=0.219, 
2025-10-05 13:52:01,294 - training.trainer - INFO - Epoch 6, Step 20897: Loss=6.3231, Acc=0.200, 
2025-10-05 13:52:08,870 - training.trainer - INFO - Epoch 6, Step 20997: Loss=6.8413, Acc=0.170, 
2025-10-05 13:52:16,316 - training.trainer - INFO - Epoch 6, Step 21097: Loss=6.2960, Acc=0.157, 
2025-10-05 13:52:23,843 - training.trainer - INFO - Epoch 6, Step 21197: Loss=6.3036, Acc=0.154, 
2025-10-05 13:52:31,289 - training.trainer - INFO - Epoch 6, Step 21297: Loss=5.9832, Acc=0.308, 
2025-10-05 13:52:38,900 - training.trainer - INFO - Epoch 6, Step 21397: Loss=6.6714, Acc=0.121, 
2025-10-05 13:52:46,385 - training.trainer - INFO - Epoch 6, Step 21497: Loss=4.1354, Acc=0.481, 
2025-10-05 13:52:53,921 - training.trainer - INFO - Epoch 6, Step 21597: Loss=5.9110, Acc=0.206, 
2025-10-05 13:53:01,365 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.2942, Acc=0.115, 
2025-10-05 13:53:08,897 - training.trainer - INFO - Epoch 6, Step 21797: Loss=5.8007, Acc=0.280, 
2025-10-05 13:53:16,377 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.1087, Acc=0.158, 
2025-10-05 13:53:23,850 - training.trainer - INFO - Epoch 6, Step 21997: Loss=5.9448, Acc=0.143, 
2025-10-05 13:53:31,332 - training.trainer - INFO - Epoch 6, Step 22097: Loss=5.5190, Acc=0.333, 
2025-10-05 13:53:38,751 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.4327, Acc=0.133, 
2025-10-05 13:53:46,244 - training.trainer - INFO - Epoch 6, Step 22297: Loss=5.2731, Acc=0.273, 
2025-10-05 13:53:53,711 - training.trainer - INFO - Epoch 6, Step 22397: Loss=5.8896, Acc=0.250, 
2025-10-05 13:54:01,066 - training.trainer - INFO - Epoch 6, Step 22497: Loss=5.5794, Acc=0.231, 
2025-10-05 13:54:08,755 - training.trainer - INFO - Epoch 6, Step 22597: Loss=6.3069, Acc=0.189, 
2025-10-05 13:54:16,265 - training.trainer - INFO - Epoch 6, Step 22697: Loss=4.3555, Acc=0.500, 
2025-10-05 13:54:23,982 - training.trainer - INFO - Epoch 6, Step 22797: Loss=6.9265, Acc=0.105, 
2025-10-05 13:54:31,458 - training.trainer - INFO - Epoch 6, Step 22897: Loss=6.2210, Acc=0.200, 
2025-10-05 13:54:38,894 - training.trainer - INFO - Epoch 6, Step 22997: Loss=5.7608, Acc=0.308, 
2025-10-05 13:54:46,276 - training.trainer - INFO - Epoch 6, Step 23097: Loss=4.9844, Acc=0.300, 
2025-10-05 13:54:53,639 - training.trainer - INFO - Epoch 6, Step 23197: Loss=5.6278, Acc=0.270, 
2025-10-05 13:55:01,064 - training.trainer - INFO - Epoch 6, Step 23297: Loss=5.6770, Acc=0.267, 
2025-10-05 13:55:08,414 - training.trainer - INFO - Epoch 6, Step 23397: Loss=5.6923, Acc=0.238, 
2025-10-05 13:55:15,805 - training.trainer - INFO - Epoch 6, Step 23497: Loss=6.1471, Acc=0.158, 
2025-10-05 13:55:23,228 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.8953, Acc=0.150, 
2025-10-05 13:55:43,026 - training.trainer - INFO - Epoch 7/100 completed in 267.07s - Train Loss: 5.9823, Train Acc: 0.208, Val Loss: 5.9145, Val Acc: 0.214
2025-10-05 13:55:43,674 - training.trainer - INFO - New best model saved with validation loss: 5.9145
2025-10-05 13:55:43,675 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-10-05 13:55:50,959 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.1210, Acc=0.192, 
2025-10-05 13:55:57,489 - training.trainer - INFO - Epoch 7, Step 23880: Loss=5.5845, Acc=0.207, 
2025-10-05 13:56:04,090 - training.trainer - INFO - Epoch 7, Step 23980: Loss=4.5756, Acc=0.333, 
2025-10-05 13:56:10,765 - training.trainer - INFO - Epoch 7, Step 24080: Loss=5.4605, Acc=0.261, 
2025-10-05 13:56:17,794 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.8637, Acc=0.224, 
2025-10-05 13:56:25,020 - training.trainer - INFO - Epoch 7, Step 24280: Loss=6.3583, Acc=0.200, 
2025-10-05 13:56:32,469 - training.trainer - INFO - Epoch 7, Step 24380: Loss=5.4322, Acc=0.227, 
2025-10-05 13:56:40,363 - training.trainer - INFO - Epoch 7, Step 24480: Loss=3.3573, Acc=0.462, 
2025-10-05 13:56:47,733 - training.trainer - INFO - Epoch 7, Step 24580: Loss=6.2704, Acc=0.167, 
2025-10-05 13:56:55,037 - training.trainer - INFO - Epoch 7, Step 24680: Loss=5.8469, Acc=0.167, 
2025-10-05 13:57:02,531 - training.trainer - INFO - Epoch 7, Step 24780: Loss=5.5382, Acc=0.256, 
2025-10-05 13:57:09,799 - training.trainer - INFO - Epoch 7, Step 24880: Loss=6.5274, Acc=0.185, 
2025-10-05 13:57:17,038 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.8059, Acc=0.292, 
2025-10-05 13:57:24,317 - training.trainer - INFO - Epoch 7, Step 25080: Loss=6.5638, Acc=0.128, 
2025-10-05 13:57:31,639 - training.trainer - INFO - Epoch 7, Step 25180: Loss=6.4516, Acc=0.143, 
2025-10-05 13:57:39,070 - training.trainer - INFO - Epoch 7, Step 25280: Loss=5.7000, Acc=0.231, 
2025-10-05 13:57:46,355 - training.trainer - INFO - Epoch 7, Step 25380: Loss=6.0097, Acc=0.125, 
2025-10-05 13:57:53,599 - training.trainer - INFO - Epoch 7, Step 25480: Loss=6.3924, Acc=0.179, 
2025-10-05 13:58:00,895 - training.trainer - INFO - Epoch 7, Step 25580: Loss=5.4586, Acc=0.293, 
2025-10-05 13:58:08,569 - training.trainer - INFO - Epoch 7, Step 25680: Loss=6.4341, Acc=0.238, 
2025-10-05 13:58:15,866 - training.trainer - INFO - Epoch 7, Step 25780: Loss=5.3399, Acc=0.250, 
2025-10-05 13:58:23,351 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.3188, Acc=0.200, 
2025-10-05 13:58:30,865 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.6568, Acc=0.130, 
2025-10-05 13:58:38,383 - training.trainer - INFO - Epoch 7, Step 26080: Loss=4.8908, Acc=0.333, 
2025-10-05 13:58:45,996 - training.trainer - INFO - Epoch 7, Step 26180: Loss=5.1960, Acc=0.348, 
2025-10-05 13:58:53,432 - training.trainer - INFO - Epoch 7, Step 26280: Loss=6.5159, Acc=0.128, 
2025-10-05 13:59:00,930 - training.trainer - INFO - Epoch 7, Step 26380: Loss=6.9312, Acc=0.172, 
2025-10-05 13:59:08,310 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.5120, Acc=0.212, 
2025-10-05 13:59:15,659 - training.trainer - INFO - Epoch 7, Step 26580: Loss=6.6758, Acc=0.085, 
2025-10-05 13:59:23,010 - training.trainer - INFO - Epoch 7, Step 26680: Loss=5.7834, Acc=0.303, 
2025-10-05 13:59:30,544 - training.trainer - INFO - Epoch 7, Step 26780: Loss=5.9147, Acc=0.188, 
2025-10-05 13:59:38,042 - training.trainer - INFO - Epoch 7, Step 26880: Loss=5.9011, Acc=0.200, 
2025-10-05 13:59:45,670 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.7455, Acc=0.196, 
2025-10-05 14:00:05,009 - training.trainer - INFO - Epoch 8/100 completed in 261.33s - Train Loss: 5.9506, Train Acc: 0.212, Val Loss: 5.8835, Val Acc: 0.219
2025-10-05 14:00:05,815 - training.trainer - INFO - New best model saved with validation loss: 5.8835
2025-10-05 14:00:05,816 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-10-05 14:00:13,740 - training.trainer - INFO - Epoch 8, Step 27163: Loss=5.8996, Acc=0.203, 
2025-10-05 14:00:21,436 - training.trainer - INFO - Epoch 8, Step 27263: Loss=6.3321, Acc=0.200, 
2025-10-05 14:00:28,969 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.6807, Acc=0.250, 
2025-10-05 14:00:36,531 - training.trainer - INFO - Epoch 8, Step 27463: Loss=5.7809, Acc=0.156, 
2025-10-05 14:00:44,102 - training.trainer - INFO - Epoch 8, Step 27563: Loss=6.0032, Acc=0.211, 
2025-10-05 14:00:51,795 - training.trainer - INFO - Epoch 8, Step 27663: Loss=5.6299, Acc=0.283, 
2025-10-05 14:00:59,736 - training.trainer - INFO - Epoch 8, Step 27763: Loss=6.4476, Acc=0.164, 
2025-10-05 14:01:07,303 - training.trainer - INFO - Epoch 8, Step 27863: Loss=5.9220, Acc=0.200, 
2025-10-05 14:01:14,630 - training.trainer - INFO - Epoch 8, Step 27963: Loss=6.3712, Acc=0.182, 
2025-10-05 14:01:22,025 - training.trainer - INFO - Epoch 8, Step 28063: Loss=5.9025, Acc=0.184, 
2025-10-05 14:01:29,535 - training.trainer - INFO - Epoch 8, Step 28163: Loss=6.2284, Acc=0.200, 
2025-10-05 14:01:36,867 - training.trainer - INFO - Epoch 8, Step 28263: Loss=6.6012, Acc=0.133, 
2025-10-05 14:01:44,207 - training.trainer - INFO - Epoch 8, Step 28363: Loss=6.5710, Acc=0.060, 
2025-10-05 14:01:51,669 - training.trainer - INFO - Epoch 8, Step 28463: Loss=5.8155, Acc=0.275, 
2025-10-05 14:01:59,187 - training.trainer - INFO - Epoch 8, Step 28563: Loss=5.4751, Acc=0.261, 
2025-10-05 14:02:06,625 - training.trainer - INFO - Epoch 8, Step 28663: Loss=6.4203, Acc=0.171, 
2025-10-05 14:02:14,064 - training.trainer - INFO - Epoch 8, Step 28763: Loss=5.2871, Acc=0.348, 
2025-10-05 14:02:21,446 - training.trainer - INFO - Epoch 8, Step 28863: Loss=6.1328, Acc=0.286, 
2025-10-05 14:02:28,851 - training.trainer - INFO - Epoch 8, Step 28963: Loss=5.7637, Acc=0.172, 
2025-10-05 14:02:36,579 - training.trainer - INFO - Epoch 8, Step 29063: Loss=5.9832, Acc=0.200, 
2025-10-05 14:02:43,951 - training.trainer - INFO - Epoch 8, Step 29163: Loss=5.7326, Acc=0.200, 
2025-10-05 14:02:51,344 - training.trainer - INFO - Epoch 8, Step 29263: Loss=5.3725, Acc=0.286, 
2025-10-05 14:02:58,771 - training.trainer - INFO - Epoch 8, Step 29363: Loss=6.1386, Acc=0.156, 
2025-10-05 14:03:06,248 - training.trainer - INFO - Epoch 8, Step 29463: Loss=4.2035, Acc=0.467, 
2025-10-05 14:03:13,825 - training.trainer - INFO - Epoch 8, Step 29563: Loss=6.1832, Acc=0.200, 
2025-10-05 14:03:21,265 - training.trainer - INFO - Epoch 8, Step 29663: Loss=5.2404, Acc=0.286, 
2025-10-05 14:03:28,628 - training.trainer - INFO - Epoch 8, Step 29763: Loss=5.8756, Acc=0.316, 
2025-10-05 14:03:36,120 - training.trainer - INFO - Epoch 8, Step 29863: Loss=6.2407, Acc=0.195, 
2025-10-05 14:03:43,692 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.7490, Acc=0.133, 
2025-10-05 14:03:51,160 - training.trainer - INFO - Epoch 8, Step 30063: Loss=5.8100, Acc=0.211, 
2025-10-05 14:03:58,590 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.3900, Acc=0.167, 
2025-10-05 14:04:06,027 - training.trainer - INFO - Epoch 8, Step 30263: Loss=6.0656, Acc=0.205, 
2025-10-05 14:04:13,413 - training.trainer - INFO - Epoch 8, Step 30363: Loss=6.0306, Acc=0.118, 
2025-10-05 14:04:32,337 - training.trainer - INFO - Epoch 9/100 completed in 266.52s - Train Loss: 5.9147, Train Acc: 0.218, Val Loss: 5.8610, Val Acc: 0.220
2025-10-05 14:04:33,079 - training.trainer - INFO - New best model saved with validation loss: 5.8610
2025-10-05 14:04:33,079 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-10-05 14:04:41,100 - training.trainer - INFO - Epoch 9, Step 30546: Loss=5.9347, Acc=0.200, 
2025-10-05 14:04:48,553 - training.trainer - INFO - Epoch 9, Step 30646: Loss=6.7827, Acc=0.103, 
2025-10-05 14:04:56,095 - training.trainer - INFO - Epoch 9, Step 30746: Loss=5.3983, Acc=0.296, 
2025-10-05 14:05:03,475 - training.trainer - INFO - Epoch 9, Step 30846: Loss=5.9814, Acc=0.200, 
2025-10-05 14:05:10,902 - training.trainer - INFO - Epoch 9, Step 30946: Loss=6.1455, Acc=0.182, 
2025-10-05 14:05:18,406 - training.trainer - INFO - Epoch 9, Step 31046: Loss=6.8409, Acc=0.113, 
2025-10-05 14:05:25,818 - training.trainer - INFO - Epoch 9, Step 31146: Loss=5.5029, Acc=0.208, 
2025-10-05 14:05:33,167 - training.trainer - INFO - Epoch 9, Step 31246: Loss=6.1088, Acc=0.244, 
2025-10-05 14:05:40,568 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.2593, Acc=0.170, 
2025-10-05 14:05:47,913 - training.trainer - INFO - Epoch 9, Step 31446: Loss=6.2059, Acc=0.144, 
2025-10-05 14:05:55,291 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.8567, Acc=0.116, 
2025-10-05 14:06:02,634 - training.trainer - INFO - Epoch 9, Step 31646: Loss=6.5515, Acc=0.167, 
2025-10-05 14:06:09,953 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.6812, Acc=0.229, 
2025-10-05 14:06:17,320 - training.trainer - INFO - Epoch 9, Step 31846: Loss=5.4216, Acc=0.279, 
2025-10-05 14:06:24,842 - training.trainer - INFO - Epoch 9, Step 31946: Loss=5.6299, Acc=0.171, 
2025-10-05 14:06:32,354 - training.trainer - INFO - Epoch 9, Step 32046: Loss=6.0125, Acc=0.186, 
2025-10-05 14:06:39,791 - training.trainer - INFO - Epoch 9, Step 32146: Loss=6.2237, Acc=0.214, 
2025-10-05 14:06:47,181 - training.trainer - INFO - Epoch 9, Step 32246: Loss=5.5620, Acc=0.231, 
2025-10-05 14:06:54,713 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.0300, Acc=0.263, 
2025-10-05 14:07:02,062 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.4232, Acc=0.189, 
2025-10-05 14:07:09,414 - training.trainer - INFO - Epoch 9, Step 32546: Loss=6.7818, Acc=0.102, 
2025-10-05 14:07:16,750 - training.trainer - INFO - Epoch 9, Step 32646: Loss=5.8674, Acc=0.222, 
2025-10-05 14:07:24,261 - training.trainer - INFO - Epoch 9, Step 32746: Loss=5.1988, Acc=0.375, 
2025-10-05 14:07:31,718 - training.trainer - INFO - Epoch 9, Step 32846: Loss=6.2035, Acc=0.194, 
2025-10-05 14:07:39,086 - training.trainer - INFO - Epoch 9, Step 32946: Loss=6.3691, Acc=0.186, 
2025-10-05 14:07:46,410 - training.trainer - INFO - Epoch 9, Step 33046: Loss=4.5720, Acc=0.300, 
2025-10-05 14:07:53,748 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.0192, Acc=0.279, 
2025-10-05 14:08:01,166 - training.trainer - INFO - Epoch 9, Step 33246: Loss=6.3375, Acc=0.180, 
2025-10-05 14:08:08,517 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.7656, Acc=0.143, 
2025-10-05 14:08:15,851 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.1475, Acc=0.125, 
2025-10-05 14:08:23,418 - training.trainer - INFO - Epoch 9, Step 33546: Loss=5.0483, Acc=0.314, 
2025-10-05 14:08:30,975 - training.trainer - INFO - Epoch 9, Step 33646: Loss=5.4452, Acc=0.261, 
2025-10-05 14:08:38,517 - training.trainer - INFO - Epoch 9, Step 33746: Loss=5.3049, Acc=0.280, 
2025-10-05 14:08:58,354 - training.trainer - INFO - Epoch 10/100 completed in 265.27s - Train Loss: 5.8821, Train Acc: 0.223, Val Loss: 5.8350, Val Acc: 0.229
2025-10-05 14:08:58,718 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-05 14:08:59,449 - training.trainer - INFO - New best model saved with validation loss: 5.8350
2025-10-05 14:08:59,449 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-05 14:09:07,402 - training.trainer - INFO - Epoch 10, Step 33929: Loss=6.3801, Acc=0.189, 
2025-10-05 14:09:14,871 - training.trainer - INFO - Epoch 10, Step 34029: Loss=6.0304, Acc=0.182, 
2025-10-05 14:09:22,309 - training.trainer - INFO - Epoch 10, Step 34129: Loss=5.3896, Acc=0.233, 
2025-10-05 14:09:29,662 - training.trainer - INFO - Epoch 10, Step 34229: Loss=6.1760, Acc=0.179, 
2025-10-05 14:09:37,180 - training.trainer - INFO - Epoch 10, Step 34329: Loss=5.6260, Acc=0.350, 
2025-10-05 14:09:44,822 - training.trainer - INFO - Epoch 10, Step 34429: Loss=6.2351, Acc=0.243, 
2025-10-05 14:09:52,219 - training.trainer - INFO - Epoch 10, Step 34529: Loss=6.0837, Acc=0.180, 
2025-10-05 14:09:59,617 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.4695, Acc=0.391, 
2025-10-05 14:10:07,021 - training.trainer - INFO - Epoch 10, Step 34729: Loss=5.8620, Acc=0.186, 
2025-10-05 14:10:14,459 - training.trainer - INFO - Epoch 10, Step 34829: Loss=5.1156, Acc=0.269, 
2025-10-05 14:10:21,964 - training.trainer - INFO - Epoch 10, Step 34929: Loss=5.8072, Acc=0.206, 
2025-10-05 14:10:29,357 - training.trainer - INFO - Epoch 10, Step 35029: Loss=6.7656, Acc=0.132, 
2025-10-05 14:10:36,706 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.2487, Acc=0.185, 
2025-10-05 14:10:44,181 - training.trainer - INFO - Epoch 10, Step 35229: Loss=6.0422, Acc=0.167, 
2025-10-05 14:10:51,623 - training.trainer - INFO - Epoch 10, Step 35329: Loss=5.5979, Acc=0.312, 
2025-10-05 14:10:59,070 - training.trainer - INFO - Epoch 10, Step 35429: Loss=5.4074, Acc=0.294, 
2025-10-05 14:11:06,436 - training.trainer - INFO - Epoch 10, Step 35529: Loss=5.3251, Acc=0.239, 
2025-10-05 14:11:13,787 - training.trainer - INFO - Epoch 10, Step 35629: Loss=3.8291, Acc=0.231, 
2025-10-05 14:11:21,146 - training.trainer - INFO - Epoch 10, Step 35729: Loss=6.3232, Acc=0.175, 
2025-10-05 14:11:28,508 - training.trainer - INFO - Epoch 10, Step 35829: Loss=5.7690, Acc=0.213, 
2025-10-05 14:11:35,951 - training.trainer - INFO - Epoch 10, Step 35929: Loss=5.7825, Acc=0.258, 
2025-10-05 14:11:43,333 - training.trainer - INFO - Epoch 10, Step 36029: Loss=6.0242, Acc=0.227, 
2025-10-05 14:11:50,653 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.2757, Acc=0.360, 
2025-10-05 14:11:58,015 - training.trainer - INFO - Epoch 10, Step 36229: Loss=6.1303, Acc=0.154, 
2025-10-05 14:12:05,522 - training.trainer - INFO - Epoch 10, Step 36329: Loss=5.5686, Acc=0.300, 
2025-10-05 14:12:12,822 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.1480, Acc=0.154, 
2025-10-05 14:12:20,406 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.8041, Acc=0.212, 
2025-10-05 14:12:27,822 - training.trainer - INFO - Epoch 10, Step 36629: Loss=6.2620, Acc=0.145, 
2025-10-05 14:12:35,368 - training.trainer - INFO - Epoch 10, Step 36729: Loss=5.4165, Acc=0.286, 
2025-10-05 14:12:42,757 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.8051, Acc=0.275, 
2025-10-05 14:12:50,392 - training.trainer - INFO - Epoch 10, Step 36929: Loss=5.6719, Acc=0.297, 
2025-10-05 14:12:57,943 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.9024, Acc=0.229, 
2025-10-05 14:13:05,382 - training.trainer - INFO - Epoch 10, Step 37129: Loss=5.3546, Acc=0.294, 
2025-10-05 14:13:25,876 - training.trainer - INFO - Epoch 11/100 completed in 266.43s - Train Loss: 5.8510, Train Acc: 0.228, Val Loss: 5.8156, Val Acc: 0.229
2025-10-05 14:13:26,497 - training.trainer - INFO - New best model saved with validation loss: 5.8156
2025-10-05 14:13:26,497 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-10-05 14:13:34,338 - training.trainer - INFO - Epoch 11, Step 37312: Loss=6.0134, Acc=0.231, 
2025-10-05 14:13:41,839 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.1026, Acc=0.135, 
2025-10-05 14:13:49,333 - training.trainer - INFO - Epoch 11, Step 37512: Loss=5.2282, Acc=0.280, 
2025-10-05 14:13:56,846 - training.trainer - INFO - Epoch 11, Step 37612: Loss=6.0120, Acc=0.211, 
2025-10-05 14:14:04,361 - training.trainer - INFO - Epoch 11, Step 37712: Loss=5.9612, Acc=0.188, 
2025-10-05 14:14:11,820 - training.trainer - INFO - Epoch 11, Step 37812: Loss=5.8536, Acc=0.219, 
2025-10-05 14:14:19,282 - training.trainer - INFO - Epoch 11, Step 37912: Loss=5.3065, Acc=0.214, 
2025-10-05 14:14:26,756 - training.trainer - INFO - Epoch 11, Step 38012: Loss=6.1930, Acc=0.241, 
2025-10-05 14:14:34,323 - training.trainer - INFO - Epoch 11, Step 38112: Loss=6.3944, Acc=0.188, 
2025-10-05 14:14:41,783 - training.trainer - INFO - Epoch 11, Step 38212: Loss=4.4036, Acc=0.400, 
2025-10-05 14:14:49,206 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.7473, Acc=0.167, 
2025-10-05 14:14:56,780 - training.trainer - INFO - Epoch 11, Step 38412: Loss=6.4565, Acc=0.145, 
2025-10-05 14:15:04,744 - training.trainer - INFO - Epoch 11, Step 38512: Loss=6.3574, Acc=0.182, 
2025-10-05 14:15:12,119 - training.trainer - INFO - Epoch 11, Step 38612: Loss=6.6322, Acc=0.096, 
2025-10-05 14:15:19,606 - training.trainer - INFO - Epoch 11, Step 38712: Loss=6.1746, Acc=0.269, 
2025-10-05 14:15:26,991 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.1180, Acc=0.290, 
2025-10-05 14:15:34,462 - training.trainer - INFO - Epoch 11, Step 38912: Loss=6.5663, Acc=0.169, 
2025-10-05 14:15:42,042 - training.trainer - INFO - Epoch 11, Step 39012: Loss=5.1600, Acc=0.300, 
2025-10-05 14:15:49,390 - training.trainer - INFO - Epoch 11, Step 39112: Loss=6.2494, Acc=0.179, 
2025-10-05 14:15:56,761 - training.trainer - INFO - Epoch 11, Step 39212: Loss=6.3921, Acc=0.167, 
2025-10-05 14:16:04,318 - training.trainer - INFO - Epoch 11, Step 39312: Loss=5.8205, Acc=0.238, 
2025-10-05 14:16:11,965 - training.trainer - INFO - Epoch 11, Step 39412: Loss=5.2939, Acc=0.308, 
2025-10-05 14:16:19,447 - training.trainer - INFO - Epoch 11, Step 39512: Loss=5.5752, Acc=0.200, 
2025-10-05 14:16:26,992 - training.trainer - INFO - Epoch 11, Step 39612: Loss=5.9665, Acc=0.167, 
2025-10-05 14:16:34,523 - training.trainer - INFO - Epoch 11, Step 39712: Loss=6.2673, Acc=0.222, 
2025-10-05 14:16:41,961 - training.trainer - INFO - Epoch 11, Step 39812: Loss=6.3378, Acc=0.161, 
2025-10-05 14:16:49,295 - training.trainer - INFO - Epoch 11, Step 39912: Loss=6.5562, Acc=0.226, 
2025-10-05 14:16:56,791 - training.trainer - INFO - Epoch 11, Step 40012: Loss=5.3863, Acc=0.308, 
2025-10-05 14:17:04,503 - training.trainer - INFO - Epoch 11, Step 40112: Loss=6.1463, Acc=0.191, 
2025-10-05 14:17:12,099 - training.trainer - INFO - Epoch 11, Step 40212: Loss=6.5690, Acc=0.138, 
2025-10-05 14:17:19,666 - training.trainer - INFO - Epoch 11, Step 40312: Loss=6.3661, Acc=0.220, 
2025-10-05 14:17:27,137 - training.trainer - INFO - Epoch 11, Step 40412: Loss=5.7278, Acc=0.280, 
2025-10-05 14:17:34,634 - training.trainer - INFO - Epoch 11, Step 40512: Loss=6.3316, Acc=0.194, 
2025-10-05 14:17:54,340 - training.trainer - INFO - Epoch 12/100 completed in 267.84s - Train Loss: 5.8327, Train Acc: 0.231, Val Loss: 5.8052, Val Acc: 0.233
2025-10-05 14:17:55,009 - training.trainer - INFO - New best model saved with validation loss: 5.8052
2025-10-05 14:17:55,009 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-10-05 14:18:02,586 - training.trainer - INFO - Epoch 12, Step 40695: Loss=5.8039, Acc=0.308, 
2025-10-05 14:18:09,957 - training.trainer - INFO - Epoch 12, Step 40795: Loss=5.5358, Acc=0.237, 
2025-10-05 14:18:17,368 - training.trainer - INFO - Epoch 12, Step 40895: Loss=4.7728, Acc=0.270, 
2025-10-05 14:18:24,958 - training.trainer - INFO - Epoch 12, Step 40995: Loss=5.1638, Acc=0.250, 
2025-10-05 14:18:32,520 - training.trainer - INFO - Epoch 12, Step 41095: Loss=5.7105, Acc=0.250, 
2025-10-05 14:18:40,165 - training.trainer - INFO - Epoch 12, Step 41195: Loss=6.0073, Acc=0.167, 
2025-10-05 14:18:47,701 - training.trainer - INFO - Epoch 12, Step 41295: Loss=5.3834, Acc=0.318, 
2025-10-05 14:18:55,192 - training.trainer - INFO - Epoch 12, Step 41395: Loss=6.3002, Acc=0.169, 
2025-10-05 14:19:02,632 - training.trainer - INFO - Epoch 12, Step 41495: Loss=5.4006, Acc=0.324, 
2025-10-05 14:19:09,970 - training.trainer - INFO - Epoch 12, Step 41595: Loss=6.0088, Acc=0.194, 
2025-10-05 14:19:17,438 - training.trainer - INFO - Epoch 12, Step 41695: Loss=6.5859, Acc=0.200, 
2025-10-05 14:19:24,968 - training.trainer - INFO - Epoch 12, Step 41795: Loss=5.9403, Acc=0.214, 
2025-10-05 14:19:32,380 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.7251, Acc=0.123, 
2025-10-05 14:19:39,887 - training.trainer - INFO - Epoch 12, Step 41995: Loss=6.0840, Acc=0.290, 
2025-10-05 14:19:47,400 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.1710, Acc=0.214, 
2025-10-05 14:19:55,028 - training.trainer - INFO - Epoch 12, Step 42195: Loss=6.2536, Acc=0.125, 
2025-10-05 14:20:02,599 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.7471, Acc=0.226, 
2025-10-05 14:20:10,475 - training.trainer - INFO - Epoch 12, Step 42395: Loss=6.3906, Acc=0.214, 
2025-10-05 14:20:17,993 - training.trainer - INFO - Epoch 12, Step 42495: Loss=6.7655, Acc=0.231, 
2025-10-05 14:20:25,559 - training.trainer - INFO - Epoch 12, Step 42595: Loss=6.8355, Acc=0.175, 
2025-10-05 14:20:33,128 - training.trainer - INFO - Epoch 12, Step 42695: Loss=6.0004, Acc=0.259, 
2025-10-05 14:20:40,516 - training.trainer - INFO - Epoch 12, Step 42795: Loss=5.1711, Acc=0.275, 
2025-10-05 14:20:47,947 - training.trainer - INFO - Epoch 12, Step 42895: Loss=5.4942, Acc=0.242, 
2025-10-05 14:20:55,427 - training.trainer - INFO - Epoch 12, Step 42995: Loss=5.7986, Acc=0.224, 
2025-10-05 14:21:03,225 - training.trainer - INFO - Epoch 12, Step 43095: Loss=5.5447, Acc=0.222, 
2025-10-05 14:21:10,622 - training.trainer - INFO - Epoch 12, Step 43195: Loss=4.8890, Acc=0.467, 
2025-10-05 14:21:18,187 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.2104, Acc=0.167, 
2025-10-05 14:21:25,663 - training.trainer - INFO - Epoch 12, Step 43395: Loss=4.6325, Acc=0.333, 
2025-10-05 14:21:33,036 - training.trainer - INFO - Epoch 12, Step 43495: Loss=6.0117, Acc=0.292, 
2025-10-05 14:21:40,592 - training.trainer - INFO - Epoch 12, Step 43595: Loss=5.9635, Acc=0.220, 
2025-10-05 14:21:48,130 - training.trainer - INFO - Epoch 12, Step 43695: Loss=5.3593, Acc=0.356, 
2025-10-05 14:21:55,734 - training.trainer - INFO - Epoch 12, Step 43795: Loss=6.2665, Acc=0.214, 
2025-10-05 14:22:03,217 - training.trainer - INFO - Epoch 12, Step 43895: Loss=5.5147, Acc=0.250, 
2025-10-05 14:22:22,504 - training.trainer - INFO - Epoch 13/100 completed in 267.49s - Train Loss: 5.8058, Train Acc: 0.234, Val Loss: 5.7679, Val Acc: 0.236
2025-10-05 14:22:23,271 - training.trainer - INFO - New best model saved with validation loss: 5.7679
2025-10-05 14:22:23,272 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-10-05 14:22:31,401 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.0710, Acc=0.136, 
2025-10-05 14:22:38,978 - training.trainer - INFO - Epoch 13, Step 44178: Loss=5.5394, Acc=0.260, 
2025-10-05 14:22:46,459 - training.trainer - INFO - Epoch 13, Step 44278: Loss=6.2475, Acc=0.238, 
2025-10-05 14:22:53,976 - training.trainer - INFO - Epoch 13, Step 44378: Loss=5.6474, Acc=0.241, 
2025-10-05 14:23:01,563 - training.trainer - INFO - Epoch 13, Step 44478: Loss=5.2740, Acc=0.333, 
2025-10-05 14:23:09,028 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.9077, Acc=0.188, 
2025-10-05 14:23:16,416 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.7274, Acc=0.300, 
2025-10-05 14:23:23,942 - training.trainer - INFO - Epoch 13, Step 44778: Loss=5.4807, Acc=0.304, 
2025-10-05 14:23:31,410 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.4905, Acc=0.250, 
2025-10-05 14:23:38,844 - training.trainer - INFO - Epoch 13, Step 44978: Loss=6.2679, Acc=0.149, 
2025-10-05 14:23:46,170 - training.trainer - INFO - Epoch 13, Step 45078: Loss=4.7258, Acc=0.381, 
2025-10-05 14:23:53,627 - training.trainer - INFO - Epoch 13, Step 45178: Loss=4.9584, Acc=0.321, 
2025-10-05 14:24:01,052 - training.trainer - INFO - Epoch 13, Step 45278: Loss=5.6073, Acc=0.224, 
2025-10-05 14:24:08,622 - training.trainer - INFO - Epoch 13, Step 45378: Loss=5.7029, Acc=0.229, 
2025-10-05 14:24:16,411 - training.trainer - INFO - Epoch 13, Step 45478: Loss=6.3586, Acc=0.167, 
2025-10-05 14:24:24,075 - training.trainer - INFO - Epoch 13, Step 45578: Loss=5.9082, Acc=0.250, 
2025-10-05 14:24:31,534 - training.trainer - INFO - Epoch 13, Step 45678: Loss=6.4510, Acc=0.221, 
2025-10-05 14:24:39,119 - training.trainer - INFO - Epoch 13, Step 45778: Loss=6.4493, Acc=0.128, 
2025-10-05 14:24:46,547 - training.trainer - INFO - Epoch 13, Step 45878: Loss=5.9078, Acc=0.242, 
2025-10-05 14:24:54,112 - training.trainer - INFO - Epoch 13, Step 45978: Loss=6.1487, Acc=0.239, 
2025-10-05 14:25:01,702 - training.trainer - INFO - Epoch 13, Step 46078: Loss=4.9113, Acc=0.500, 
2025-10-05 14:25:09,046 - training.trainer - INFO - Epoch 13, Step 46178: Loss=5.6682, Acc=0.230, 
2025-10-05 14:25:16,507 - training.trainer - INFO - Epoch 13, Step 46278: Loss=6.2676, Acc=0.156, 
2025-10-05 14:25:23,967 - training.trainer - INFO - Epoch 13, Step 46378: Loss=5.0700, Acc=0.364, 
2025-10-05 14:25:31,456 - training.trainer - INFO - Epoch 13, Step 46478: Loss=6.1436, Acc=0.180, 
2025-10-05 14:25:38,932 - training.trainer - INFO - Epoch 13, Step 46578: Loss=6.3310, Acc=0.191, 
2025-10-05 14:25:46,427 - training.trainer - INFO - Epoch 13, Step 46678: Loss=6.4273, Acc=0.182, 
2025-10-05 14:25:53,842 - training.trainer - INFO - Epoch 13, Step 46778: Loss=4.6783, Acc=0.281, 
2025-10-05 14:26:01,272 - training.trainer - INFO - Epoch 13, Step 46878: Loss=6.0533, Acc=0.224, 
2025-10-05 14:26:08,610 - training.trainer - INFO - Epoch 13, Step 46978: Loss=4.7980, Acc=0.368, 
2025-10-05 14:26:16,108 - training.trainer - INFO - Epoch 13, Step 47078: Loss=6.3704, Acc=0.143, 
2025-10-05 14:26:23,541 - training.trainer - INFO - Epoch 13, Step 47178: Loss=5.9012, Acc=0.125, 
2025-10-05 14:26:31,024 - training.trainer - INFO - Epoch 13, Step 47278: Loss=5.1651, Acc=0.304, 
2025-10-05 14:26:50,530 - training.trainer - INFO - Epoch 14/100 completed in 267.26s - Train Loss: 5.7765, Train Acc: 0.237, Val Loss: 5.7634, Val Acc: 0.238
2025-10-05 14:26:51,311 - training.trainer - INFO - New best model saved with validation loss: 5.7634
2025-10-05 14:26:51,312 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-10-05 14:26:59,290 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.7491, Acc=0.174, 
2025-10-05 14:27:06,842 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.4952, Acc=0.167, 
2025-10-05 14:27:14,249 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.0877, Acc=0.222, 
2025-10-05 14:27:21,758 - training.trainer - INFO - Epoch 14, Step 47761: Loss=5.9234, Acc=0.190, 
2025-10-05 14:27:29,120 - training.trainer - INFO - Epoch 14, Step 47861: Loss=5.6603, Acc=0.276, 
2025-10-05 14:27:36,651 - training.trainer - INFO - Epoch 14, Step 47961: Loss=5.7587, Acc=0.300, 
2025-10-05 14:27:44,270 - training.trainer - INFO - Epoch 14, Step 48061: Loss=5.7519, Acc=0.224, 
2025-10-05 14:27:51,772 - training.trainer - INFO - Epoch 14, Step 48161: Loss=6.1459, Acc=0.167, 
2025-10-05 14:27:59,297 - training.trainer - INFO - Epoch 14, Step 48261: Loss=6.1951, Acc=0.185, 
2025-10-05 14:28:06,913 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.5007, Acc=0.237, 
2025-10-05 14:28:14,227 - training.trainer - INFO - Epoch 14, Step 48461: Loss=6.0008, Acc=0.237, 
2025-10-05 14:28:21,578 - training.trainer - INFO - Epoch 14, Step 48561: Loss=6.3460, Acc=0.286, 
2025-10-05 14:28:28,973 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.3912, Acc=0.207, 
2025-10-05 14:28:36,413 - training.trainer - INFO - Epoch 14, Step 48761: Loss=6.2027, Acc=0.192, 
2025-10-05 14:28:44,016 - training.trainer - INFO - Epoch 14, Step 48861: Loss=6.2191, Acc=0.140, 
2025-10-05 14:28:51,420 - training.trainer - INFO - Epoch 14, Step 48961: Loss=5.4325, Acc=0.143, 
2025-10-05 14:28:58,788 - training.trainer - INFO - Epoch 14, Step 49061: Loss=5.7571, Acc=0.368, 
2025-10-05 14:29:06,143 - training.trainer - INFO - Epoch 14, Step 49161: Loss=4.3722, Acc=0.407, 
2025-10-05 14:29:13,605 - training.trainer - INFO - Epoch 14, Step 49261: Loss=4.6015, Acc=0.395, 
2025-10-05 14:29:21,309 - training.trainer - INFO - Epoch 14, Step 49361: Loss=6.3222, Acc=0.296, 
2025-10-05 14:29:28,936 - training.trainer - INFO - Epoch 14, Step 49461: Loss=5.5328, Acc=0.289, 
2025-10-05 14:29:36,212 - training.trainer - INFO - Epoch 14, Step 49561: Loss=5.4030, Acc=0.189, 
2025-10-05 14:29:43,520 - training.trainer - INFO - Epoch 14, Step 49661: Loss=5.1156, Acc=0.343, 
2025-10-05 14:29:51,042 - training.trainer - INFO - Epoch 14, Step 49761: Loss=5.8655, Acc=0.194, 
2025-10-05 14:29:58,830 - training.trainer - INFO - Epoch 14, Step 49861: Loss=6.7266, Acc=0.224, 
2025-10-05 14:30:06,219 - training.trainer - INFO - Epoch 14, Step 49961: Loss=6.3403, Acc=0.188, 
2025-10-05 14:30:13,716 - training.trainer - INFO - Epoch 14, Step 50061: Loss=5.3428, Acc=0.294, 
2025-10-05 14:30:21,295 - training.trainer - INFO - Epoch 14, Step 50161: Loss=5.7488, Acc=0.243, 
2025-10-05 14:30:28,784 - training.trainer - INFO - Epoch 14, Step 50261: Loss=6.2357, Acc=0.148, 
2025-10-05 14:30:36,208 - training.trainer - INFO - Epoch 14, Step 50361: Loss=6.2164, Acc=0.156, 
2025-10-05 14:30:43,645 - training.trainer - INFO - Epoch 14, Step 50461: Loss=4.8306, Acc=0.345, 
2025-10-05 14:30:51,072 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.5896, Acc=0.389, 
2025-10-05 14:30:58,644 - training.trainer - INFO - Epoch 14, Step 50661: Loss=6.2328, Acc=0.152, 
2025-10-05 14:31:17,961 - training.trainer - INFO - Epoch 15/100 completed in 266.65s - Train Loss: 5.7544, Train Acc: 0.241, Val Loss: 5.7349, Val Acc: 0.241
2025-10-05 14:31:18,353 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-05 14:31:19,135 - training.trainer - INFO - New best model saved with validation loss: 5.7349
2025-10-05 14:31:19,135 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-05 14:31:27,115 - training.trainer - INFO - Epoch 15, Step 50844: Loss=5.9746, Acc=0.200, 
2025-10-05 14:31:34,560 - training.trainer - INFO - Epoch 15, Step 50944: Loss=5.7678, Acc=0.314, 
2025-10-05 14:31:41,956 - training.trainer - INFO - Epoch 15, Step 51044: Loss=6.0811, Acc=0.083, 
2025-10-05 14:31:49,529 - training.trainer - INFO - Epoch 15, Step 51144: Loss=5.4404, Acc=0.286, 
2025-10-05 14:31:56,999 - training.trainer - INFO - Epoch 15, Step 51244: Loss=5.1571, Acc=0.227, 
2025-10-05 14:32:04,420 - training.trainer - INFO - Epoch 15, Step 51344: Loss=6.0119, Acc=0.262, 
2025-10-05 14:32:11,819 - training.trainer - INFO - Epoch 15, Step 51444: Loss=6.4049, Acc=0.176, 
2025-10-05 14:32:19,518 - training.trainer - INFO - Epoch 15, Step 51544: Loss=4.7562, Acc=0.250, 
2025-10-05 14:32:26,914 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.8420, Acc=0.200, 
2025-10-05 14:32:34,280 - training.trainer - INFO - Epoch 15, Step 51744: Loss=5.9073, Acc=0.133, 
2025-10-05 14:32:41,734 - training.trainer - INFO - Epoch 15, Step 51844: Loss=5.8994, Acc=0.191, 
2025-10-05 14:32:49,250 - training.trainer - INFO - Epoch 15, Step 51944: Loss=5.2645, Acc=0.294, 
2025-10-05 14:32:56,610 - training.trainer - INFO - Epoch 15, Step 52044: Loss=5.7818, Acc=0.269, 
2025-10-05 14:33:04,422 - training.trainer - INFO - Epoch 15, Step 52144: Loss=6.0049, Acc=0.271, 
2025-10-05 14:33:11,773 - training.trainer - INFO - Epoch 15, Step 52244: Loss=4.9899, Acc=0.308, 
2025-10-05 14:33:19,115 - training.trainer - INFO - Epoch 15, Step 52344: Loss=6.2177, Acc=0.213, 
2025-10-05 14:33:26,593 - training.trainer - INFO - Epoch 15, Step 52444: Loss=6.5309, Acc=0.194, 
2025-10-05 14:33:33,996 - training.trainer - INFO - Epoch 15, Step 52544: Loss=5.1858, Acc=0.316, 
2025-10-05 14:33:41,386 - training.trainer - INFO - Epoch 15, Step 52644: Loss=6.3408, Acc=0.133, 
2025-10-05 14:33:48,757 - training.trainer - INFO - Epoch 15, Step 52744: Loss=6.6128, Acc=0.231, 
2025-10-05 14:33:56,118 - training.trainer - INFO - Epoch 15, Step 52844: Loss=6.4268, Acc=0.238, 
2025-10-05 14:34:03,469 - training.trainer - INFO - Epoch 15, Step 52944: Loss=3.0909, Acc=0.625, 
2025-10-05 14:34:10,841 - training.trainer - INFO - Epoch 15, Step 53044: Loss=6.1189, Acc=0.172, 
2025-10-05 14:34:18,174 - training.trainer - INFO - Epoch 15, Step 53144: Loss=5.1798, Acc=0.333, 
2025-10-05 14:34:25,540 - training.trainer - INFO - Epoch 15, Step 53244: Loss=4.1122, Acc=0.524, 
2025-10-05 14:34:32,929 - training.trainer - INFO - Epoch 15, Step 53344: Loss=5.9038, Acc=0.268, 
2025-10-05 14:34:40,350 - training.trainer - INFO - Epoch 15, Step 53444: Loss=5.0417, Acc=0.400, 
2025-10-05 14:34:47,789 - training.trainer - INFO - Epoch 15, Step 53544: Loss=5.5676, Acc=0.292, 
2025-10-05 14:34:55,219 - training.trainer - INFO - Epoch 15, Step 53644: Loss=5.1651, Acc=0.263, 
2025-10-05 14:35:02,633 - training.trainer - INFO - Epoch 15, Step 53744: Loss=5.8628, Acc=0.188, 
2025-10-05 14:35:09,981 - training.trainer - INFO - Epoch 15, Step 53844: Loss=6.3223, Acc=0.175, 
2025-10-05 14:35:17,360 - training.trainer - INFO - Epoch 15, Step 53944: Loss=5.6672, Acc=0.227, 
2025-10-05 14:35:24,720 - training.trainer - INFO - Epoch 15, Step 54044: Loss=4.1832, Acc=0.421, 
2025-10-05 14:35:45,105 - training.trainer - INFO - Epoch 16/100 completed in 265.97s - Train Loss: 5.7341, Train Acc: 0.244, Val Loss: 5.7413, Val Acc: 0.244
2025-10-05 14:35:52,814 - training.trainer - INFO - Epoch 16, Step 54227: Loss=6.3082, Acc=0.187, 
2025-10-05 14:36:00,170 - training.trainer - INFO - Epoch 16, Step 54327: Loss=5.3617, Acc=0.340, 
2025-10-05 14:36:07,530 - training.trainer - INFO - Epoch 16, Step 54427: Loss=4.8263, Acc=0.370, 
2025-10-05 14:36:14,886 - training.trainer - INFO - Epoch 16, Step 54527: Loss=4.5811, Acc=0.333, 
2025-10-05 14:36:22,276 - training.trainer - INFO - Epoch 16, Step 54627: Loss=4.5245, Acc=0.400, 
2025-10-05 14:36:29,597 - training.trainer - INFO - Epoch 16, Step 54727: Loss=6.3791, Acc=0.205, 
2025-10-05 14:36:37,008 - training.trainer - INFO - Epoch 16, Step 54827: Loss=6.1893, Acc=0.226, 
2025-10-05 14:36:44,365 - training.trainer - INFO - Epoch 16, Step 54927: Loss=5.7111, Acc=0.205, 
2025-10-05 14:36:51,751 - training.trainer - INFO - Epoch 16, Step 55027: Loss=6.2234, Acc=0.174, 
2025-10-05 14:36:59,117 - training.trainer - INFO - Epoch 16, Step 55127: Loss=6.1583, Acc=0.154, 
2025-10-05 14:37:06,498 - training.trainer - INFO - Epoch 16, Step 55227: Loss=6.0217, Acc=0.216, 
2025-10-05 14:37:13,894 - training.trainer - INFO - Epoch 16, Step 55327: Loss=5.5668, Acc=0.200, 
2025-10-05 14:37:21,264 - training.trainer - INFO - Epoch 16, Step 55427: Loss=5.4026, Acc=0.344, 
2025-10-05 14:37:28,724 - training.trainer - INFO - Epoch 16, Step 55527: Loss=6.0353, Acc=0.323, 
2025-10-05 14:37:36,107 - training.trainer - INFO - Epoch 16, Step 55627: Loss=5.7824, Acc=0.308, 
2025-10-05 14:37:43,491 - training.trainer - INFO - Epoch 16, Step 55727: Loss=5.7892, Acc=0.158, 
2025-10-05 14:37:50,922 - training.trainer - INFO - Epoch 16, Step 55827: Loss=5.2895, Acc=0.267, 
2025-10-05 14:37:58,295 - training.trainer - INFO - Epoch 16, Step 55927: Loss=6.0116, Acc=0.273, 
2025-10-05 14:38:05,673 - training.trainer - INFO - Epoch 16, Step 56027: Loss=5.5239, Acc=0.250, 
2025-10-05 14:38:12,997 - training.trainer - INFO - Epoch 16, Step 56127: Loss=6.1024, Acc=0.145, 
2025-10-05 14:38:20,425 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.2635, Acc=0.300, 
2025-10-05 14:38:27,789 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.6925, Acc=0.207, 
2025-10-05 14:38:35,198 - training.trainer - INFO - Epoch 16, Step 56427: Loss=6.0447, Acc=0.190, 
2025-10-05 14:38:42,642 - training.trainer - INFO - Epoch 16, Step 56527: Loss=5.0177, Acc=0.333, 
2025-10-05 14:38:50,088 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.7371, Acc=0.324, 
2025-10-05 14:38:57,442 - training.trainer - INFO - Epoch 16, Step 56727: Loss=4.6928, Acc=0.367, 
2025-10-05 14:39:04,791 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.8842, Acc=0.300, 
2025-10-05 14:39:12,200 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.6820, Acc=0.231, 
2025-10-05 14:39:19,546 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.9511, Acc=0.250, 
2025-10-05 14:39:26,991 - training.trainer - INFO - Epoch 16, Step 57127: Loss=6.1528, Acc=0.194, 
2025-10-05 14:39:34,466 - training.trainer - INFO - Epoch 16, Step 57227: Loss=6.1395, Acc=0.220, 
2025-10-05 14:39:41,813 - training.trainer - INFO - Epoch 16, Step 57327: Loss=6.2738, Acc=0.250, 
2025-10-05 14:39:49,181 - training.trainer - INFO - Epoch 16, Step 57427: Loss=6.1841, Acc=0.184, 
2025-10-05 14:40:08,897 - training.trainer - INFO - Epoch 17/100 completed in 263.79s - Train Loss: 5.7079, Train Acc: 0.248, Val Loss: 5.7224, Val Acc: 0.246
2025-10-05 14:40:09,486 - training.trainer - INFO - New best model saved with validation loss: 5.7224
2025-10-05 14:40:09,487 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-10-05 14:40:17,277 - training.trainer - INFO - Epoch 17, Step 57610: Loss=6.2936, Acc=0.233, 
2025-10-05 14:40:24,694 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.2624, Acc=0.316, 
2025-10-05 14:40:32,158 - training.trainer - INFO - Epoch 17, Step 57810: Loss=6.1104, Acc=0.246, 
2025-10-05 14:40:39,646 - training.trainer - INFO - Epoch 17, Step 57910: Loss=5.2264, Acc=0.227, 
2025-10-05 14:40:47,060 - training.trainer - INFO - Epoch 17, Step 58010: Loss=5.9511, Acc=0.205, 
2025-10-05 14:40:54,496 - training.trainer - INFO - Epoch 17, Step 58110: Loss=3.9465, Acc=0.500, 
2025-10-05 14:41:01,889 - training.trainer - INFO - Epoch 17, Step 58210: Loss=6.2481, Acc=0.170, 
2025-10-05 14:41:09,547 - training.trainer - INFO - Epoch 17, Step 58310: Loss=6.0781, Acc=0.250, 
2025-10-05 14:41:17,259 - training.trainer - INFO - Epoch 17, Step 58410: Loss=6.0918, Acc=0.169, 
2025-10-05 14:41:24,716 - training.trainer - INFO - Epoch 17, Step 58510: Loss=6.5198, Acc=0.097, 
2025-10-05 14:41:32,109 - training.trainer - INFO - Epoch 17, Step 58610: Loss=5.4337, Acc=0.292, 
2025-10-05 14:41:39,523 - training.trainer - INFO - Epoch 17, Step 58710: Loss=6.7551, Acc=0.158, 
2025-10-05 14:41:46,954 - training.trainer - INFO - Epoch 17, Step 58810: Loss=5.4158, Acc=0.281, 
2025-10-05 14:41:54,290 - training.trainer - INFO - Epoch 17, Step 58910: Loss=6.0603, Acc=0.167, 
2025-10-05 14:42:01,867 - training.trainer - INFO - Epoch 17, Step 59010: Loss=6.6877, Acc=0.161, 
2025-10-05 14:42:09,306 - training.trainer - INFO - Epoch 17, Step 59110: Loss=4.9814, Acc=0.478, 
2025-10-05 14:42:16,764 - training.trainer - INFO - Epoch 17, Step 59210: Loss=5.3871, Acc=0.194, 
2025-10-05 14:42:24,328 - training.trainer - INFO - Epoch 17, Step 59310: Loss=6.3951, Acc=0.172, 
2025-10-05 14:42:31,724 - training.trainer - INFO - Epoch 17, Step 59410: Loss=6.4493, Acc=0.167, 
2025-10-05 14:42:39,325 - training.trainer - INFO - Epoch 17, Step 59510: Loss=5.7683, Acc=0.150, 
2025-10-05 14:42:46,717 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.6391, Acc=0.250, 
2025-10-05 14:42:54,269 - training.trainer - INFO - Epoch 17, Step 59710: Loss=7.0159, Acc=0.119, 
2025-10-05 14:43:01,711 - training.trainer - INFO - Epoch 17, Step 59810: Loss=6.4791, Acc=0.164, 
2025-10-05 14:43:09,115 - training.trainer - INFO - Epoch 17, Step 59910: Loss=6.3491, Acc=0.145, 
2025-10-05 14:43:16,463 - training.trainer - INFO - Epoch 17, Step 60010: Loss=6.7372, Acc=0.138, 
2025-10-05 14:43:23,837 - training.trainer - INFO - Epoch 17, Step 60110: Loss=3.9933, Acc=0.412, 
2025-10-05 14:43:31,235 - training.trainer - INFO - Epoch 17, Step 60210: Loss=5.4245, Acc=0.300, 
2025-10-05 14:43:38,573 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.4195, Acc=0.341, 
2025-10-05 14:43:45,936 - training.trainer - INFO - Epoch 17, Step 60410: Loss=6.2661, Acc=0.296, 
2025-10-05 14:43:53,276 - training.trainer - INFO - Epoch 17, Step 60510: Loss=5.8488, Acc=0.279, 
2025-10-05 14:44:00,740 - training.trainer - INFO - Epoch 17, Step 60610: Loss=5.8767, Acc=0.306, 
2025-10-05 14:44:08,179 - training.trainer - INFO - Epoch 17, Step 60710: Loss=6.0807, Acc=0.191, 
2025-10-05 14:44:15,524 - training.trainer - INFO - Epoch 17, Step 60810: Loss=6.2543, Acc=0.154, 
2025-10-05 14:44:34,658 - training.trainer - INFO - Epoch 18/100 completed in 265.17s - Train Loss: 5.6859, Train Acc: 0.250, Val Loss: 5.7150, Val Acc: 0.248
2025-10-05 14:44:35,325 - training.trainer - INFO - New best model saved with validation loss: 5.7150
2025-10-05 14:44:35,325 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-10-05 14:44:43,289 - training.trainer - INFO - Epoch 18, Step 60993: Loss=5.8847, Acc=0.250, 
2025-10-05 14:44:50,743 - training.trainer - INFO - Epoch 18, Step 61093: Loss=5.8041, Acc=0.278, 
2025-10-05 14:44:58,085 - training.trainer - INFO - Epoch 18, Step 61193: Loss=5.8579, Acc=0.300, 
2025-10-05 14:45:05,453 - training.trainer - INFO - Epoch 18, Step 61293: Loss=4.9520, Acc=0.350, 
2025-10-05 14:45:12,950 - training.trainer - INFO - Epoch 18, Step 61393: Loss=5.9386, Acc=0.206, 
2025-10-05 14:45:20,329 - training.trainer - INFO - Epoch 18, Step 61493: Loss=5.7022, Acc=0.133, 
2025-10-05 14:45:27,754 - training.trainer - INFO - Epoch 18, Step 61593: Loss=5.6783, Acc=0.298, 
2025-10-05 14:45:35,230 - training.trainer - INFO - Epoch 18, Step 61693: Loss=4.8774, Acc=0.385, 
2025-10-05 14:45:42,659 - training.trainer - INFO - Epoch 18, Step 61793: Loss=6.3423, Acc=0.231, 
2025-10-05 14:45:50,071 - training.trainer - INFO - Epoch 18, Step 61893: Loss=6.0921, Acc=0.143, 
2025-10-05 14:45:57,503 - training.trainer - INFO - Epoch 18, Step 61993: Loss=6.0514, Acc=0.333, 
2025-10-05 14:46:05,028 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.4934, Acc=0.273, 
2025-10-05 14:46:12,436 - training.trainer - INFO - Epoch 18, Step 62193: Loss=4.8078, Acc=0.375, 
2025-10-05 14:46:19,831 - training.trainer - INFO - Epoch 18, Step 62293: Loss=6.3077, Acc=0.224, 
2025-10-05 14:46:27,207 - training.trainer - INFO - Epoch 18, Step 62393: Loss=5.9633, Acc=0.125, 
2025-10-05 14:46:34,701 - training.trainer - INFO - Epoch 18, Step 62493: Loss=5.4359, Acc=0.291, 
2025-10-05 14:46:42,105 - training.trainer - INFO - Epoch 18, Step 62593: Loss=6.7970, Acc=0.155, 
2025-10-05 14:46:49,448 - training.trainer - INFO - Epoch 18, Step 62693: Loss=5.9595, Acc=0.234, 
2025-10-05 14:46:57,023 - training.trainer - INFO - Epoch 18, Step 62793: Loss=6.0870, Acc=0.200, 
2025-10-05 14:47:04,541 - training.trainer - INFO - Epoch 18, Step 62893: Loss=5.8957, Acc=0.186, 
2025-10-05 14:47:11,990 - training.trainer - INFO - Epoch 18, Step 62993: Loss=5.9165, Acc=0.250, 
2025-10-05 14:47:19,592 - training.trainer - INFO - Epoch 18, Step 63093: Loss=5.8595, Acc=0.308, 
2025-10-05 14:47:26,998 - training.trainer - INFO - Epoch 18, Step 63193: Loss=4.3989, Acc=0.478, 
2025-10-05 14:47:34,553 - training.trainer - INFO - Epoch 18, Step 63293: Loss=6.3530, Acc=0.189, 
2025-10-05 14:47:42,116 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.9540, Acc=0.288, 
2025-10-05 14:47:49,677 - training.trainer - INFO - Epoch 18, Step 63493: Loss=6.3661, Acc=0.194, 
2025-10-05 14:47:57,075 - training.trainer - INFO - Epoch 18, Step 63593: Loss=5.6611, Acc=0.263, 
2025-10-05 14:48:04,533 - training.trainer - INFO - Epoch 18, Step 63693: Loss=6.0633, Acc=0.222, 
2025-10-05 14:48:12,146 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.5828, Acc=0.270, 
2025-10-05 14:48:19,592 - training.trainer - INFO - Epoch 18, Step 63893: Loss=5.6051, Acc=0.273, 
2025-10-05 14:48:27,030 - training.trainer - INFO - Epoch 18, Step 63993: Loss=5.8531, Acc=0.175, 
2025-10-05 14:48:34,814 - training.trainer - INFO - Epoch 18, Step 64093: Loss=6.4036, Acc=0.098, 
2025-10-05 14:48:42,398 - training.trainer - INFO - Epoch 18, Step 64193: Loss=4.6218, Acc=0.341, 
2025-10-05 14:49:01,803 - training.trainer - INFO - Epoch 19/100 completed in 266.48s - Train Loss: 5.6696, Train Acc: 0.254, Val Loss: 5.7142, Val Acc: 0.247
2025-10-05 14:49:02,548 - training.trainer - INFO - New best model saved with validation loss: 5.7142
2025-10-05 14:49:02,549 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-10-05 14:49:10,592 - training.trainer - INFO - Epoch 19, Step 64376: Loss=5.6701, Acc=0.219, 
2025-10-05 14:49:17,923 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.1522, Acc=0.344, 
2025-10-05 14:49:25,069 - training.trainer - INFO - Epoch 19, Step 64576: Loss=3.5408, Acc=0.571, 
2025-10-05 14:49:32,497 - training.trainer - INFO - Epoch 19, Step 64676: Loss=6.0140, Acc=0.227, 
2025-10-05 14:49:39,876 - training.trainer - INFO - Epoch 19, Step 64776: Loss=6.1564, Acc=0.280, 
2025-10-05 14:49:47,555 - training.trainer - INFO - Epoch 19, Step 64876: Loss=5.2257, Acc=0.238, 
2025-10-05 14:49:55,140 - training.trainer - INFO - Epoch 19, Step 64976: Loss=5.4956, Acc=0.298, 
2025-10-05 14:50:02,550 - training.trainer - INFO - Epoch 19, Step 65076: Loss=6.1224, Acc=0.176, 
2025-10-05 14:50:09,981 - training.trainer - INFO - Epoch 19, Step 65176: Loss=6.3875, Acc=0.218, 
2025-10-05 14:50:17,387 - training.trainer - INFO - Epoch 19, Step 65276: Loss=5.8303, Acc=0.136, 
2025-10-05 14:50:24,974 - training.trainer - INFO - Epoch 19, Step 65376: Loss=5.8754, Acc=0.171, 
2025-10-05 14:50:32,394 - training.trainer - INFO - Epoch 19, Step 65476: Loss=4.6789, Acc=0.333, 
2025-10-05 14:50:40,010 - training.trainer - INFO - Epoch 19, Step 65576: Loss=5.1451, Acc=0.333, 
2025-10-05 14:50:47,816 - training.trainer - INFO - Epoch 19, Step 65676: Loss=4.6333, Acc=0.414, 
2025-10-05 14:50:55,458 - training.trainer - INFO - Epoch 19, Step 65776: Loss=5.5053, Acc=0.271, 
2025-10-05 14:51:02,847 - training.trainer - INFO - Epoch 19, Step 65876: Loss=6.1369, Acc=0.216, 
2025-10-05 14:51:10,327 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.4633, Acc=0.200, 
2025-10-05 14:51:17,908 - training.trainer - INFO - Epoch 19, Step 66076: Loss=5.0592, Acc=0.364, 
2025-10-05 14:51:25,375 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.5802, Acc=0.200, 
2025-10-05 14:51:33,098 - training.trainer - INFO - Epoch 19, Step 66276: Loss=6.1317, Acc=0.222, 
2025-10-05 14:51:40,673 - training.trainer - INFO - Epoch 19, Step 66376: Loss=6.2107, Acc=0.250, 
2025-10-05 14:51:48,039 - training.trainer - INFO - Epoch 19, Step 66476: Loss=5.1724, Acc=0.294, 
2025-10-05 14:51:55,428 - training.trainer - INFO - Epoch 19, Step 66576: Loss=5.2200, Acc=0.240, 
2025-10-05 14:52:02,971 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.9467, Acc=0.179, 
2025-10-05 14:52:10,418 - training.trainer - INFO - Epoch 19, Step 66776: Loss=5.7148, Acc=0.355, 
2025-10-05 14:52:17,786 - training.trainer - INFO - Epoch 19, Step 66876: Loss=5.9281, Acc=0.209, 
2025-10-05 14:52:25,150 - training.trainer - INFO - Epoch 19, Step 66976: Loss=5.7078, Acc=0.205, 
2025-10-05 14:52:32,584 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.9308, Acc=0.222, 
2025-10-05 14:52:40,261 - training.trainer - INFO - Epoch 19, Step 67176: Loss=5.8807, Acc=0.191, 
2025-10-05 14:52:47,745 - training.trainer - INFO - Epoch 19, Step 67276: Loss=6.2317, Acc=0.222, 
2025-10-05 14:52:55,156 - training.trainer - INFO - Epoch 19, Step 67376: Loss=4.7925, Acc=0.333, 
2025-10-05 14:53:02,547 - training.trainer - INFO - Epoch 19, Step 67476: Loss=4.7782, Acc=0.407, 
2025-10-05 14:53:10,036 - training.trainer - INFO - Epoch 19, Step 67576: Loss=6.2554, Acc=0.200, 
2025-10-05 14:53:29,202 - training.trainer - INFO - Epoch 20/100 completed in 266.65s - Train Loss: 5.6472, Train Acc: 0.256, Val Loss: 5.7114, Val Acc: 0.249
2025-10-05 14:53:29,509 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-05 14:53:30,156 - training.trainer - INFO - New best model saved with validation loss: 5.7114
2025-10-05 14:53:30,156 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-05 14:53:37,346 - training.trainer - INFO - Epoch 20, Step 67759: Loss=6.1287, Acc=0.258, 
2025-10-05 14:53:44,830 - training.trainer - INFO - Epoch 20, Step 67859: Loss=5.9694, Acc=0.238, 
2025-10-05 14:53:52,378 - training.trainer - INFO - Epoch 20, Step 67959: Loss=6.1569, Acc=0.189, 
2025-10-05 14:53:59,806 - training.trainer - INFO - Epoch 20, Step 68059: Loss=4.5934, Acc=0.258, 
2025-10-05 14:54:07,209 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.6681, Acc=0.263, 
2025-10-05 14:54:14,880 - training.trainer - INFO - Epoch 20, Step 68259: Loss=5.5549, Acc=0.222, 
2025-10-05 14:54:22,311 - training.trainer - INFO - Epoch 20, Step 68359: Loss=5.9446, Acc=0.219, 
2025-10-05 14:54:29,661 - training.trainer - INFO - Epoch 20, Step 68459: Loss=5.6139, Acc=0.250, 
2025-10-05 14:54:37,087 - training.trainer - INFO - Epoch 20, Step 68559: Loss=4.0623, Acc=0.444, 
2025-10-05 14:54:44,477 - training.trainer - INFO - Epoch 20, Step 68659: Loss=6.4715, Acc=0.152, 
2025-10-05 14:54:51,843 - training.trainer - INFO - Epoch 20, Step 68759: Loss=5.6498, Acc=0.240, 
2025-10-05 14:54:59,283 - training.trainer - INFO - Epoch 20, Step 68859: Loss=5.6927, Acc=0.214, 
2025-10-05 14:55:06,757 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.1853, Acc=0.250, 
2025-10-05 14:55:14,121 - training.trainer - INFO - Epoch 20, Step 69059: Loss=6.0301, Acc=0.280, 
2025-10-05 14:55:21,594 - training.trainer - INFO - Epoch 20, Step 69159: Loss=5.0128, Acc=0.300, 
2025-10-05 14:55:29,223 - training.trainer - INFO - Epoch 20, Step 69259: Loss=4.3799, Acc=0.393, 
2025-10-05 14:55:37,148 - training.trainer - INFO - Epoch 20, Step 69359: Loss=4.6841, Acc=0.478, 
2025-10-05 14:55:44,669 - training.trainer - INFO - Epoch 20, Step 69459: Loss=6.3146, Acc=0.210, 
2025-10-05 14:55:52,146 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.9914, Acc=0.194, 
2025-10-05 14:55:59,615 - training.trainer - INFO - Epoch 20, Step 69659: Loss=5.3918, Acc=0.271, 
2025-10-05 14:56:07,086 - training.trainer - INFO - Epoch 20, Step 69759: Loss=6.0181, Acc=0.200, 
2025-10-05 14:56:14,563 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.5649, Acc=0.258, 
2025-10-05 14:56:21,944 - training.trainer - INFO - Epoch 20, Step 69959: Loss=6.0725, Acc=0.286, 
2025-10-05 14:56:29,495 - training.trainer - INFO - Epoch 20, Step 70059: Loss=5.8413, Acc=0.304, 
2025-10-05 14:56:37,089 - training.trainer - INFO - Epoch 20, Step 70159: Loss=5.6747, Acc=0.267, 
2025-10-05 14:56:44,722 - training.trainer - INFO - Epoch 20, Step 70259: Loss=5.7379, Acc=0.233, 
2025-10-05 14:56:52,407 - training.trainer - INFO - Epoch 20, Step 70359: Loss=6.1231, Acc=0.170, 
2025-10-05 14:56:59,964 - training.trainer - INFO - Epoch 20, Step 70459: Loss=5.9970, Acc=0.179, 
2025-10-05 14:57:07,441 - training.trainer - INFO - Epoch 20, Step 70559: Loss=6.4496, Acc=0.178, 
2025-10-05 14:57:14,896 - training.trainer - INFO - Epoch 20, Step 70659: Loss=5.6411, Acc=0.250, 
2025-10-05 14:57:22,531 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.2622, Acc=0.261, 
2025-10-05 14:57:30,093 - training.trainer - INFO - Epoch 20, Step 70859: Loss=5.4301, Acc=0.269, 
2025-10-05 14:57:37,630 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.8364, Acc=0.304, 
2025-10-05 14:57:57,092 - training.trainer - INFO - Epoch 21/100 completed in 266.94s - Train Loss: 5.6264, Train Acc: 0.260, Val Loss: 5.6794, Val Acc: 0.253
2025-10-05 14:57:57,775 - training.trainer - INFO - New best model saved with validation loss: 5.6794
2025-10-05 14:57:57,775 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-10-05 14:58:04,765 - training.trainer - INFO - Epoch 21, Step 71142: Loss=4.9747, Acc=0.214, 
2025-10-05 14:58:11,230 - training.trainer - INFO - Epoch 21, Step 71242: Loss=6.3562, Acc=0.225, 
2025-10-05 14:58:18,444 - training.trainer - INFO - Epoch 21, Step 71342: Loss=5.2995, Acc=0.325, 
2025-10-05 14:58:26,013 - training.trainer - INFO - Epoch 21, Step 71442: Loss=6.4819, Acc=0.158, 
2025-10-05 14:58:33,483 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.8014, Acc=0.234, 
2025-10-05 14:58:40,853 - training.trainer - INFO - Epoch 21, Step 71642: Loss=5.6685, Acc=0.278, 
2025-10-05 14:58:48,252 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.5984, Acc=0.273, 
2025-10-05 14:58:55,703 - training.trainer - INFO - Epoch 21, Step 71842: Loss=5.5338, Acc=0.226, 
2025-10-05 14:59:03,095 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.6411, Acc=0.257, 
2025-10-05 14:59:10,912 - training.trainer - INFO - Epoch 21, Step 72042: Loss=5.7172, Acc=0.339, 
2025-10-05 14:59:18,334 - training.trainer - INFO - Epoch 21, Step 72142: Loss=5.2062, Acc=0.312, 
2025-10-05 14:59:25,751 - training.trainer - INFO - Epoch 21, Step 72242: Loss=5.0770, Acc=0.281, 
2025-10-05 14:59:33,207 - training.trainer - INFO - Epoch 21, Step 72342: Loss=5.9153, Acc=0.267, 
2025-10-05 14:59:40,624 - training.trainer - INFO - Epoch 21, Step 72442: Loss=6.5088, Acc=0.182, 
2025-10-05 14:59:48,072 - training.trainer - INFO - Epoch 21, Step 72542: Loss=5.8675, Acc=0.211, 
2025-10-05 14:59:55,479 - training.trainer - INFO - Epoch 21, Step 72642: Loss=5.4863, Acc=0.167, 
2025-10-05 15:00:02,962 - training.trainer - INFO - Epoch 21, Step 72742: Loss=5.2022, Acc=0.241, 
2025-10-05 15:00:10,307 - training.trainer - INFO - Epoch 21, Step 72842: Loss=4.5995, Acc=0.407, 
2025-10-05 15:00:17,772 - training.trainer - INFO - Epoch 21, Step 72942: Loss=5.5804, Acc=0.250, 
2025-10-05 15:00:25,195 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.5272, Acc=0.312, 
2025-10-05 15:00:32,606 - training.trainer - INFO - Epoch 21, Step 73142: Loss=5.2027, Acc=0.378, 
2025-10-05 15:00:40,045 - training.trainer - INFO - Epoch 21, Step 73242: Loss=6.1352, Acc=0.208, 
2025-10-05 15:00:47,416 - training.trainer - INFO - Epoch 21, Step 73342: Loss=6.4668, Acc=0.188, 
2025-10-05 15:00:54,845 - training.trainer - INFO - Epoch 21, Step 73442: Loss=4.9627, Acc=0.333, 
2025-10-05 15:01:02,201 - training.trainer - INFO - Epoch 21, Step 73542: Loss=5.2011, Acc=0.250, 
2025-10-05 15:01:09,568 - training.trainer - INFO - Epoch 21, Step 73642: Loss=5.1261, Acc=0.333, 
2025-10-05 15:01:16,899 - training.trainer - INFO - Epoch 21, Step 73742: Loss=4.2139, Acc=0.483, 
2025-10-05 15:01:24,228 - training.trainer - INFO - Epoch 21, Step 73842: Loss=6.1630, Acc=0.217, 
2025-10-05 15:01:31,603 - training.trainer - INFO - Epoch 21, Step 73942: Loss=6.2798, Acc=0.238, 
2025-10-05 15:01:39,299 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.9208, Acc=0.226, 
2025-10-05 15:01:46,707 - training.trainer - INFO - Epoch 21, Step 74142: Loss=5.9314, Acc=0.191, 
2025-10-05 15:01:54,203 - training.trainer - INFO - Epoch 21, Step 74242: Loss=5.7614, Acc=0.269, 
2025-10-05 15:02:01,732 - training.trainer - INFO - Epoch 21, Step 74342: Loss=5.8094, Acc=0.194, 
2025-10-05 15:02:20,656 - training.trainer - INFO - Epoch 22/100 completed in 262.88s - Train Loss: 5.6097, Train Acc: 0.263, Val Loss: 5.6877, Val Acc: 0.252
2025-10-05 15:02:27,612 - training.trainer - INFO - Epoch 22, Step 74525: Loss=5.0791, Acc=0.254, 
2025-10-05 15:02:33,923 - training.trainer - INFO - Epoch 22, Step 74625: Loss=6.4022, Acc=0.256, 
2025-10-05 15:02:40,221 - training.trainer - INFO - Epoch 22, Step 74725: Loss=4.9904, Acc=0.312, 
2025-10-05 15:02:46,785 - training.trainer - INFO - Epoch 22, Step 74825: Loss=5.3929, Acc=0.278, 
2025-10-05 15:02:53,084 - training.trainer - INFO - Epoch 22, Step 74925: Loss=5.4492, Acc=0.250, 
2025-10-05 15:02:59,402 - training.trainer - INFO - Epoch 22, Step 75025: Loss=4.0155, Acc=0.413, 
2025-10-05 15:03:05,746 - training.trainer - INFO - Epoch 22, Step 75125: Loss=5.8754, Acc=0.235, 
2025-10-05 15:03:12,161 - training.trainer - INFO - Epoch 22, Step 75225: Loss=6.1218, Acc=0.167, 
2025-10-05 15:03:18,612 - training.trainer - INFO - Epoch 22, Step 75325: Loss=5.3744, Acc=0.306, 
2025-10-05 15:03:24,941 - training.trainer - INFO - Epoch 22, Step 75425: Loss=5.8477, Acc=0.244, 
2025-10-05 15:03:31,303 - training.trainer - INFO - Epoch 22, Step 75525: Loss=5.1644, Acc=0.238, 
2025-10-05 15:03:37,622 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.8262, Acc=0.258, 
2025-10-05 15:03:43,994 - training.trainer - INFO - Epoch 22, Step 75725: Loss=5.4095, Acc=0.254, 
2025-10-05 15:03:50,389 - training.trainer - INFO - Epoch 22, Step 75825: Loss=5.2097, Acc=0.391, 
2025-10-05 15:03:56,768 - training.trainer - INFO - Epoch 22, Step 75925: Loss=3.9705, Acc=0.294, 
2025-10-05 15:04:03,213 - training.trainer - INFO - Epoch 22, Step 76025: Loss=4.7251, Acc=0.359, 
2025-10-05 15:04:10,575 - training.trainer - INFO - Epoch 22, Step 76125: Loss=5.5964, Acc=0.238, 
2025-10-05 15:04:17,927 - training.trainer - INFO - Epoch 22, Step 76225: Loss=6.1240, Acc=0.241, 
2025-10-05 15:04:25,357 - training.trainer - INFO - Epoch 22, Step 76325: Loss=5.6972, Acc=0.255, 
2025-10-05 15:04:32,948 - training.trainer - INFO - Epoch 22, Step 76425: Loss=5.1970, Acc=0.213, 
2025-10-05 15:04:40,330 - training.trainer - INFO - Epoch 22, Step 76525: Loss=4.6717, Acc=0.302, 
2025-10-05 15:04:47,718 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.9760, Acc=0.261, 
2025-10-05 15:04:55,271 - training.trainer - INFO - Epoch 22, Step 76725: Loss=6.4218, Acc=0.167, 
2025-10-05 15:05:02,779 - training.trainer - INFO - Epoch 22, Step 76825: Loss=5.7525, Acc=0.222, 
2025-10-05 15:05:10,369 - training.trainer - INFO - Epoch 22, Step 76925: Loss=5.8053, Acc=0.320, 
2025-10-05 15:05:17,912 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.6787, Acc=0.316, 
2025-10-05 15:05:25,585 - training.trainer - INFO - Epoch 22, Step 77125: Loss=5.2003, Acc=0.321, 
2025-10-05 15:05:33,290 - training.trainer - INFO - Epoch 22, Step 77225: Loss=5.8643, Acc=0.222, 
2025-10-05 15:05:40,736 - training.trainer - INFO - Epoch 22, Step 77325: Loss=5.1051, Acc=0.258, 
2025-10-05 15:05:48,285 - training.trainer - INFO - Epoch 22, Step 77425: Loss=5.7440, Acc=0.145, 
2025-10-05 15:05:55,960 - training.trainer - INFO - Epoch 22, Step 77525: Loss=4.8933, Acc=0.389, 
2025-10-05 15:06:03,319 - training.trainer - INFO - Epoch 22, Step 77625: Loss=5.3508, Acc=0.324, 
2025-10-05 15:06:10,828 - training.trainer - INFO - Epoch 22, Step 77725: Loss=4.8233, Acc=0.333, 
2025-10-05 15:06:30,508 - training.trainer - INFO - Epoch 23/100 completed in 249.85s - Train Loss: 5.5819, Train Acc: 0.267, Val Loss: 5.6774, Val Acc: 0.255
2025-10-05 15:06:31,329 - training.trainer - INFO - New best model saved with validation loss: 5.6774
2025-10-05 15:06:31,329 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-10-05 15:06:39,318 - training.trainer - INFO - Epoch 23, Step 77908: Loss=4.7050, Acc=0.375, 
2025-10-05 15:06:47,016 - training.trainer - INFO - Epoch 23, Step 78008: Loss=5.5149, Acc=0.143, 
2025-10-05 15:06:54,397 - training.trainer - INFO - Epoch 23, Step 78108: Loss=5.3303, Acc=0.269, 
2025-10-05 15:07:01,948 - training.trainer - INFO - Epoch 23, Step 78208: Loss=5.6766, Acc=0.269, 
2025-10-05 15:07:09,506 - training.trainer - INFO - Epoch 23, Step 78308: Loss=6.0531, Acc=0.275, 
2025-10-05 15:07:16,981 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.6692, Acc=0.250, 
2025-10-05 15:07:24,444 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.6952, Acc=0.233, 
2025-10-05 15:07:31,915 - training.trainer - INFO - Epoch 23, Step 78608: Loss=5.5373, Acc=0.292, 
2025-10-05 15:07:39,321 - training.trainer - INFO - Epoch 23, Step 78708: Loss=5.0513, Acc=0.226, 
2025-10-05 15:07:46,783 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.0069, Acc=0.379, 
2025-10-05 15:07:54,321 - training.trainer - INFO - Epoch 23, Step 78908: Loss=3.0248, Acc=0.560, 
2025-10-05 15:08:01,722 - training.trainer - INFO - Epoch 23, Step 79008: Loss=5.2154, Acc=0.227, 
2025-10-05 15:08:09,182 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.7756, Acc=0.229, 
2025-10-05 15:08:16,609 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.4952, Acc=0.346, 
2025-10-05 15:08:24,094 - training.trainer - INFO - Epoch 23, Step 79308: Loss=5.9911, Acc=0.235, 
2025-10-05 15:08:31,515 - training.trainer - INFO - Epoch 23, Step 79408: Loss=5.6991, Acc=0.218, 
2025-10-05 15:08:39,186 - training.trainer - INFO - Epoch 23, Step 79508: Loss=6.8567, Acc=0.194, 
2025-10-05 15:08:46,762 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.5486, Acc=0.303, 
2025-10-05 15:08:54,520 - training.trainer - INFO - Epoch 23, Step 79708: Loss=5.8742, Acc=0.276, 
2025-10-05 15:09:02,083 - training.trainer - INFO - Epoch 23, Step 79808: Loss=6.3250, Acc=0.217, 
2025-10-05 15:09:09,451 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.8531, Acc=0.278, 
2025-10-05 15:09:16,775 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.8076, Acc=0.237, 
2025-10-05 15:09:24,153 - training.trainer - INFO - Epoch 23, Step 80108: Loss=4.4367, Acc=0.409, 
2025-10-05 15:09:31,690 - training.trainer - INFO - Epoch 23, Step 80208: Loss=5.9366, Acc=0.200, 
2025-10-05 15:09:39,072 - training.trainer - INFO - Epoch 23, Step 80308: Loss=4.0561, Acc=0.583, 
2025-10-05 15:09:46,545 - training.trainer - INFO - Epoch 23, Step 80408: Loss=5.6741, Acc=0.207, 
2025-10-05 15:09:54,094 - training.trainer - INFO - Epoch 23, Step 80508: Loss=5.1703, Acc=0.179, 
2025-10-05 15:10:01,728 - training.trainer - INFO - Epoch 23, Step 80608: Loss=4.0712, Acc=0.462, 
2025-10-05 15:10:09,296 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.7657, Acc=0.261, 
2025-10-05 15:10:16,670 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.9668, Acc=0.312, 
2025-10-05 15:10:24,036 - training.trainer - INFO - Epoch 23, Step 80908: Loss=4.6525, Acc=0.350, 
2025-10-05 15:10:31,532 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.2123, Acc=0.182, 
2025-10-05 15:10:38,846 - training.trainer - INFO - Epoch 23, Step 81108: Loss=2.7031, Acc=0.533, 
2025-10-05 15:10:58,245 - training.trainer - INFO - Epoch 24/100 completed in 266.91s - Train Loss: 5.5616, Train Acc: 0.269, Val Loss: 5.6722, Val Acc: 0.252
2025-10-05 15:10:58,972 - training.trainer - INFO - New best model saved with validation loss: 5.6722
2025-10-05 15:10:58,972 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-10-05 15:11:06,398 - training.trainer - INFO - Epoch 24, Step 81291: Loss=6.1517, Acc=0.200, 
2025-10-05 15:11:13,862 - training.trainer - INFO - Epoch 24, Step 81391: Loss=5.0594, Acc=0.300, 
2025-10-05 15:11:21,541 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.4092, Acc=0.351, 
2025-10-05 15:11:29,091 - training.trainer - INFO - Epoch 24, Step 81591: Loss=5.6615, Acc=0.162, 
2025-10-05 15:11:36,577 - training.trainer - INFO - Epoch 24, Step 81691: Loss=5.9807, Acc=0.250, 
2025-10-05 15:11:44,078 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.7312, Acc=0.167, 
2025-10-05 15:11:51,532 - training.trainer - INFO - Epoch 24, Step 81891: Loss=5.1691, Acc=0.245, 
2025-10-05 15:11:59,091 - training.trainer - INFO - Epoch 24, Step 81991: Loss=4.7668, Acc=0.263, 
2025-10-05 15:12:06,546 - training.trainer - INFO - Epoch 24, Step 82091: Loss=4.1434, Acc=0.480, 
2025-10-05 15:12:13,922 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.3231, Acc=0.480, 
2025-10-05 15:12:21,409 - training.trainer - INFO - Epoch 24, Step 82291: Loss=5.4790, Acc=0.163, 
2025-10-05 15:12:28,901 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.0886, Acc=0.400, 
2025-10-05 15:12:36,386 - training.trainer - INFO - Epoch 24, Step 82491: Loss=5.6242, Acc=0.226, 
2025-10-05 15:12:43,773 - training.trainer - INFO - Epoch 24, Step 82591: Loss=5.8905, Acc=0.217, 
2025-10-05 15:12:51,155 - training.trainer - INFO - Epoch 24, Step 82691: Loss=6.6163, Acc=0.114, 
2025-10-05 15:12:58,613 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.5387, Acc=0.350, 
2025-10-05 15:13:05,982 - training.trainer - INFO - Epoch 24, Step 82891: Loss=5.1895, Acc=0.259, 
2025-10-05 15:13:13,387 - training.trainer - INFO - Epoch 24, Step 82991: Loss=6.1348, Acc=0.250, 
2025-10-05 15:13:20,946 - training.trainer - INFO - Epoch 24, Step 83091: Loss=4.3457, Acc=0.415, 
2025-10-05 15:13:28,308 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.7705, Acc=0.303, 
2025-10-05 15:13:35,772 - training.trainer - INFO - Epoch 24, Step 83291: Loss=5.9907, Acc=0.310, 
2025-10-05 15:13:43,194 - training.trainer - INFO - Epoch 24, Step 83391: Loss=5.3150, Acc=0.405, 
2025-10-05 15:13:50,624 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.4180, Acc=0.268, 
2025-10-05 15:13:58,049 - training.trainer - INFO - Epoch 24, Step 83591: Loss=6.5908, Acc=0.157, 
2025-10-05 15:14:05,400 - training.trainer - INFO - Epoch 24, Step 83691: Loss=6.3391, Acc=0.278, 
2025-10-05 15:14:12,809 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.7324, Acc=0.262, 
2025-10-05 15:14:20,290 - training.trainer - INFO - Epoch 24, Step 83891: Loss=5.7897, Acc=0.270, 
2025-10-05 15:14:27,645 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.1404, Acc=0.268, 
2025-10-05 15:14:35,213 - training.trainer - INFO - Epoch 24, Step 84091: Loss=5.2733, Acc=0.283, 
2025-10-05 15:14:42,834 - training.trainer - INFO - Epoch 24, Step 84191: Loss=6.1883, Acc=0.220, 
2025-10-05 15:14:50,320 - training.trainer - INFO - Epoch 24, Step 84291: Loss=5.7597, Acc=0.225, 
2025-10-05 15:14:57,704 - training.trainer - INFO - Epoch 24, Step 84391: Loss=6.6990, Acc=0.147, 
2025-10-05 15:15:05,228 - training.trainer - INFO - Epoch 24, Step 84491: Loss=4.9699, Acc=0.391, 
2025-10-05 15:15:24,844 - training.trainer - INFO - Epoch 25/100 completed in 265.87s - Train Loss: 5.5447, Train Acc: 0.271, Val Loss: 5.6625, Val Acc: 0.255
2025-10-05 15:15:25,221 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-05 15:15:25,991 - training.trainer - INFO - New best model saved with validation loss: 5.6625
2025-10-05 15:15:25,992 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-05 15:15:32,831 - training.trainer - INFO - Epoch 25, Step 84674: Loss=5.8450, Acc=0.203, 
2025-10-05 15:15:39,086 - training.trainer - INFO - Epoch 25, Step 84774: Loss=5.3871, Acc=0.318, 
2025-10-05 15:15:45,463 - training.trainer - INFO - Epoch 25, Step 84874: Loss=6.3761, Acc=0.245, 
2025-10-05 15:15:51,790 - training.trainer - INFO - Epoch 25, Step 84974: Loss=6.4709, Acc=0.149, 
2025-10-05 15:15:58,118 - training.trainer - INFO - Epoch 25, Step 85074: Loss=5.8238, Acc=0.179, 
2025-10-05 15:16:04,437 - training.trainer - INFO - Epoch 25, Step 85174: Loss=4.3583, Acc=0.389, 
2025-10-05 15:16:10,777 - training.trainer - INFO - Epoch 25, Step 85274: Loss=4.6732, Acc=0.310, 
2025-10-05 15:16:17,104 - training.trainer - INFO - Epoch 25, Step 85374: Loss=5.2163, Acc=0.217, 
2025-10-05 15:16:23,399 - training.trainer - INFO - Epoch 25, Step 85474: Loss=5.3839, Acc=0.214, 
2025-10-05 15:16:29,670 - training.trainer - INFO - Epoch 25, Step 85574: Loss=5.7792, Acc=0.271, 
2025-10-05 15:16:36,003 - training.trainer - INFO - Epoch 25, Step 85674: Loss=5.7338, Acc=0.273, 
2025-10-05 15:16:42,331 - training.trainer - INFO - Epoch 25, Step 85774: Loss=4.7422, Acc=0.222, 
2025-10-05 15:16:49,467 - training.trainer - INFO - Epoch 25, Step 85874: Loss=5.7119, Acc=0.333, 
2025-10-05 15:16:56,799 - training.trainer - INFO - Epoch 25, Step 85974: Loss=4.7679, Acc=0.444, 
2025-10-05 15:17:04,197 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.7828, Acc=0.255, 
2025-10-05 15:17:11,765 - training.trainer - INFO - Epoch 25, Step 86174: Loss=5.9737, Acc=0.243, 
2025-10-05 15:17:19,279 - training.trainer - INFO - Epoch 25, Step 86274: Loss=5.7086, Acc=0.267, 
2025-10-05 15:17:26,718 - training.trainer - INFO - Epoch 25, Step 86374: Loss=6.3040, Acc=0.143, 
2025-10-05 15:17:34,183 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.7612, Acc=0.286, 
2025-10-05 15:17:41,617 - training.trainer - INFO - Epoch 25, Step 86574: Loss=5.2237, Acc=0.250, 
2025-10-05 15:17:49,029 - training.trainer - INFO - Epoch 25, Step 86674: Loss=5.1928, Acc=0.276, 
2025-10-05 15:17:56,468 - training.trainer - INFO - Epoch 25, Step 86774: Loss=5.7803, Acc=0.267, 
2025-10-05 15:18:03,890 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.9464, Acc=0.180, 
2025-10-05 15:18:11,205 - training.trainer - INFO - Epoch 25, Step 86974: Loss=4.7857, Acc=0.400, 
2025-10-05 15:18:18,532 - training.trainer - INFO - Epoch 25, Step 87074: Loss=5.5081, Acc=0.250, 
2025-10-05 15:18:25,898 - training.trainer - INFO - Epoch 25, Step 87174: Loss=5.5240, Acc=0.182, 
2025-10-05 15:18:33,202 - training.trainer - INFO - Epoch 25, Step 87274: Loss=5.7828, Acc=0.333, 
2025-10-05 15:18:40,681 - training.trainer - INFO - Epoch 25, Step 87374: Loss=5.2103, Acc=0.292, 
2025-10-05 15:18:48,439 - training.trainer - INFO - Epoch 25, Step 87474: Loss=4.0144, Acc=0.467, 
2025-10-05 15:18:55,934 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.7357, Acc=0.241, 
2025-10-05 15:19:03,359 - training.trainer - INFO - Epoch 25, Step 87674: Loss=4.3124, Acc=0.520, 
2025-10-05 15:19:10,728 - training.trainer - INFO - Epoch 25, Step 87774: Loss=5.5395, Acc=0.267, 
2025-10-05 15:19:18,125 - training.trainer - INFO - Epoch 25, Step 87874: Loss=4.3490, Acc=0.472, 
2025-10-05 15:19:37,537 - training.trainer - INFO - Epoch 26/100 completed in 251.54s - Train Loss: 5.5252, Train Acc: 0.276, Val Loss: 5.6538, Val Acc: 0.256
2025-10-05 15:19:38,355 - training.trainer - INFO - New best model saved with validation loss: 5.6538
2025-10-05 15:19:38,355 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_26.pt
2025-10-05 15:19:46,339 - training.trainer - INFO - Epoch 26, Step 88057: Loss=5.3386, Acc=0.308, 
2025-10-05 15:19:53,953 - training.trainer - INFO - Epoch 26, Step 88157: Loss=5.3355, Acc=0.368, 
2025-10-05 15:20:01,305 - training.trainer - INFO - Epoch 26, Step 88257: Loss=5.9413, Acc=0.250, 
2025-10-05 15:20:08,708 - training.trainer - INFO - Epoch 26, Step 88357: Loss=5.2071, Acc=0.303, 
2025-10-05 15:20:16,117 - training.trainer - INFO - Epoch 26, Step 88457: Loss=6.0231, Acc=0.225, 
2025-10-05 15:20:23,486 - training.trainer - INFO - Epoch 26, Step 88557: Loss=6.0386, Acc=0.194, 
2025-10-05 15:20:30,878 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.2932, Acc=0.286, 
2025-10-05 15:20:38,269 - training.trainer - INFO - Epoch 26, Step 88757: Loss=2.9117, Acc=0.762, 
2025-10-05 15:20:45,668 - training.trainer - INFO - Epoch 26, Step 88857: Loss=6.2413, Acc=0.178, 
2025-10-05 15:20:53,252 - training.trainer - INFO - Epoch 26, Step 88957: Loss=6.0590, Acc=0.211, 
2025-10-05 15:21:00,766 - training.trainer - INFO - Epoch 26, Step 89057: Loss=6.5942, Acc=0.364, 
2025-10-05 15:21:08,282 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.8446, Acc=0.208, 
2025-10-05 15:21:15,749 - training.trainer - INFO - Epoch 26, Step 89257: Loss=5.1751, Acc=0.286, 
2025-10-05 15:21:23,150 - training.trainer - INFO - Epoch 26, Step 89357: Loss=5.9648, Acc=0.268, 
2025-10-05 15:21:30,833 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.1832, Acc=0.333, 
2025-10-05 15:21:38,390 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.8801, Acc=0.206, 
2025-10-05 15:21:46,004 - training.trainer - INFO - Epoch 26, Step 89657: Loss=4.7682, Acc=0.346, 
2025-10-05 15:21:53,652 - training.trainer - INFO - Epoch 26, Step 89757: Loss=5.2960, Acc=0.407, 
2025-10-05 15:22:01,346 - training.trainer - INFO - Epoch 26, Step 89857: Loss=5.5913, Acc=0.302, 
2025-10-05 15:22:08,879 - training.trainer - INFO - Epoch 26, Step 89957: Loss=4.6723, Acc=0.370, 
2025-10-05 15:22:16,695 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.5187, Acc=0.267, 
2025-10-05 15:22:24,445 - training.trainer - INFO - Epoch 26, Step 90157: Loss=5.7493, Acc=0.257, 
2025-10-05 15:22:31,912 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.8420, Acc=0.211, 
2025-10-05 15:22:39,414 - training.trainer - INFO - Epoch 26, Step 90357: Loss=5.5147, Acc=0.236, 
2025-10-05 15:22:46,810 - training.trainer - INFO - Epoch 26, Step 90457: Loss=5.3068, Acc=0.269, 
2025-10-05 15:22:54,212 - training.trainer - INFO - Epoch 26, Step 90557: Loss=6.0833, Acc=0.170, 
2025-10-05 15:23:01,754 - training.trainer - INFO - Epoch 26, Step 90657: Loss=5.3897, Acc=0.273, 
2025-10-05 15:23:09,316 - training.trainer - INFO - Epoch 26, Step 90757: Loss=5.1788, Acc=0.368, 
2025-10-05 15:23:16,833 - training.trainer - INFO - Epoch 26, Step 90857: Loss=6.5028, Acc=0.157, 
2025-10-05 15:23:24,175 - training.trainer - INFO - Epoch 26, Step 90957: Loss=5.3634, Acc=0.360, 
2025-10-05 15:23:31,615 - training.trainer - INFO - Epoch 26, Step 91057: Loss=5.5440, Acc=0.268, 
2025-10-05 15:23:39,145 - training.trainer - INFO - Epoch 26, Step 91157: Loss=5.5934, Acc=0.320, 
2025-10-05 15:23:46,636 - training.trainer - INFO - Epoch 26, Step 91257: Loss=6.4540, Acc=0.161, 
2025-10-05 15:24:06,675 - training.trainer - INFO - Epoch 27/100 completed in 268.32s - Train Loss: 5.5095, Train Acc: 0.277, Val Loss: 5.6634, Val Acc: 0.252
2025-10-05 15:24:14,515 - training.trainer - INFO - Epoch 27, Step 91440: Loss=5.9259, Acc=0.194, 
2025-10-05 15:24:22,000 - training.trainer - INFO - Epoch 27, Step 91540: Loss=5.8840, Acc=0.213, 
2025-10-05 15:24:29,458 - training.trainer - INFO - Epoch 27, Step 91640: Loss=5.4231, Acc=0.333, 
2025-10-05 15:24:36,838 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.6635, Acc=0.243, 
2025-10-05 15:24:44,161 - training.trainer - INFO - Epoch 27, Step 91840: Loss=6.0237, Acc=0.250, 
2025-10-05 15:24:51,807 - training.trainer - INFO - Epoch 27, Step 91940: Loss=6.3634, Acc=0.182, 
2025-10-05 15:24:59,146 - training.trainer - INFO - Epoch 27, Step 92040: Loss=5.0893, Acc=0.429, 
2025-10-05 15:25:06,603 - training.trainer - INFO - Epoch 27, Step 92140: Loss=5.0538, Acc=0.318, 
2025-10-05 15:25:13,974 - training.trainer - INFO - Epoch 27, Step 92240: Loss=4.2898, Acc=0.444, 
2025-10-05 15:25:21,409 - training.trainer - INFO - Epoch 27, Step 92340: Loss=5.0285, Acc=0.379, 
2025-10-05 15:25:28,846 - training.trainer - INFO - Epoch 27, Step 92440: Loss=4.8362, Acc=0.281, 
2025-10-05 15:25:36,215 - training.trainer - INFO - Epoch 27, Step 92540: Loss=5.1430, Acc=0.238, 
2025-10-05 15:25:43,529 - training.trainer - INFO - Epoch 27, Step 92640: Loss=5.4320, Acc=0.385, 
2025-10-05 15:25:50,866 - training.trainer - INFO - Epoch 27, Step 92740: Loss=6.0314, Acc=0.196, 
2025-10-05 15:25:58,175 - training.trainer - INFO - Epoch 27, Step 92840: Loss=6.7588, Acc=0.195, 
2025-10-05 15:26:05,550 - training.trainer - INFO - Epoch 27, Step 92940: Loss=5.6130, Acc=0.261, 
2025-10-05 15:26:12,979 - training.trainer - INFO - Epoch 27, Step 93040: Loss=5.6932, Acc=0.333, 
2025-10-05 15:26:20,313 - training.trainer - INFO - Epoch 27, Step 93140: Loss=6.0187, Acc=0.208, 
2025-10-05 15:26:27,690 - training.trainer - INFO - Epoch 27, Step 93240: Loss=5.9048, Acc=0.231, 
2025-10-05 15:26:35,203 - training.trainer - INFO - Epoch 27, Step 93340: Loss=5.6003, Acc=0.326, 
2025-10-05 15:26:42,727 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.4114, Acc=0.258, 
2025-10-05 15:26:50,146 - training.trainer - INFO - Epoch 27, Step 93540: Loss=5.5081, Acc=0.250, 
2025-10-05 15:26:57,708 - training.trainer - INFO - Epoch 27, Step 93640: Loss=5.3745, Acc=0.297, 
2025-10-05 15:27:05,176 - training.trainer - INFO - Epoch 27, Step 93740: Loss=5.5661, Acc=0.286, 
2025-10-05 15:27:12,753 - training.trainer - INFO - Epoch 27, Step 93840: Loss=6.0904, Acc=0.281, 
2025-10-05 15:27:20,156 - training.trainer - INFO - Epoch 27, Step 93940: Loss=5.9742, Acc=0.224, 
2025-10-05 15:27:27,648 - training.trainer - INFO - Epoch 27, Step 94040: Loss=6.4018, Acc=0.260, 
2025-10-05 15:27:35,121 - training.trainer - INFO - Epoch 27, Step 94140: Loss=6.0513, Acc=0.211, 
2025-10-05 15:27:42,642 - training.trainer - INFO - Epoch 27, Step 94240: Loss=5.5230, Acc=0.273, 
2025-10-05 15:27:50,133 - training.trainer - INFO - Epoch 27, Step 94340: Loss=6.2299, Acc=0.234, 
2025-10-05 15:27:57,514 - training.trainer - INFO - Epoch 27, Step 94440: Loss=5.7808, Acc=0.273, 
2025-10-05 15:28:04,836 - training.trainer - INFO - Epoch 27, Step 94540: Loss=5.6606, Acc=0.333, 
2025-10-05 15:28:12,414 - training.trainer - INFO - Epoch 27, Step 94640: Loss=6.1020, Acc=0.224, 
2025-10-05 15:28:32,331 - training.trainer - INFO - Epoch 28/100 completed in 265.66s - Train Loss: 5.4980, Train Acc: 0.279, Val Loss: 5.6586, Val Acc: 0.259
2025-10-05 15:28:40,352 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.8606, Acc=0.303, 
2025-10-05 15:28:47,895 - training.trainer - INFO - Epoch 28, Step 94923: Loss=5.5704, Acc=0.222, 
2025-10-05 15:28:55,586 - training.trainer - INFO - Epoch 28, Step 95023: Loss=4.9083, Acc=0.423, 
2025-10-05 15:29:03,147 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.5678, Acc=0.250, 
2025-10-05 15:29:10,683 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.9005, Acc=0.185, 
2025-10-05 15:29:18,622 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.6822, Acc=0.267, 
2025-10-05 15:29:26,146 - training.trainer - INFO - Epoch 28, Step 95423: Loss=5.9641, Acc=0.174, 
2025-10-05 15:29:33,696 - training.trainer - INFO - Epoch 28, Step 95523: Loss=4.9146, Acc=0.343, 
2025-10-05 15:29:41,245 - training.trainer - INFO - Epoch 28, Step 95623: Loss=5.8136, Acc=0.190, 
2025-10-05 15:29:48,841 - training.trainer - INFO - Epoch 28, Step 95723: Loss=5.0757, Acc=0.386, 
2025-10-05 15:29:56,273 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.9294, Acc=0.310, 
2025-10-05 15:30:03,700 - training.trainer - INFO - Epoch 28, Step 95923: Loss=5.2504, Acc=0.156, 
2025-10-05 15:30:10,972 - training.trainer - INFO - Epoch 28, Step 96023: Loss=5.5086, Acc=0.211, 
2025-10-05 15:30:18,260 - training.trainer - INFO - Epoch 28, Step 96123: Loss=4.1582, Acc=0.333, 
2025-10-05 15:30:25,517 - training.trainer - INFO - Epoch 28, Step 96223: Loss=6.3364, Acc=0.100, 
2025-10-05 15:30:33,278 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.8504, Acc=0.333, 
2025-10-05 15:30:40,825 - training.trainer - INFO - Epoch 28, Step 96423: Loss=6.6550, Acc=0.200, 
2025-10-05 15:30:48,102 - training.trainer - INFO - Epoch 28, Step 96523: Loss=4.8716, Acc=0.346, 
2025-10-05 15:30:55,412 - training.trainer - INFO - Epoch 28, Step 96623: Loss=5.9368, Acc=0.188, 
2025-10-05 15:31:02,979 - training.trainer - INFO - Epoch 28, Step 96723: Loss=5.4086, Acc=0.321, 
2025-10-05 15:31:10,508 - training.trainer - INFO - Epoch 28, Step 96823: Loss=5.6052, Acc=0.343, 
2025-10-05 15:31:17,957 - training.trainer - INFO - Epoch 28, Step 96923: Loss=6.3357, Acc=0.210, 
2025-10-05 15:31:25,444 - training.trainer - INFO - Epoch 28, Step 97023: Loss=4.9427, Acc=0.286, 
2025-10-05 15:31:32,984 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.3940, Acc=0.254, 
2025-10-05 15:31:40,994 - training.trainer - INFO - Epoch 28, Step 97223: Loss=2.9713, Acc=0.700, 
2025-10-05 15:31:48,523 - training.trainer - INFO - Epoch 28, Step 97323: Loss=6.1946, Acc=0.179, 
2025-10-05 15:31:55,855 - training.trainer - INFO - Epoch 28, Step 97423: Loss=5.2688, Acc=0.300, 
2025-10-05 15:32:03,123 - training.trainer - INFO - Epoch 28, Step 97523: Loss=4.5794, Acc=0.417, 
2025-10-05 15:32:10,636 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.3126, Acc=0.364, 
2025-10-05 15:32:17,924 - training.trainer - INFO - Epoch 28, Step 97723: Loss=4.1620, Acc=0.500, 
2025-10-05 15:32:25,178 - training.trainer - INFO - Epoch 28, Step 97823: Loss=6.1598, Acc=0.230, 
2025-10-05 15:32:32,494 - training.trainer - INFO - Epoch 28, Step 97923: Loss=5.6745, Acc=0.222, 
2025-10-05 15:32:39,739 - training.trainer - INFO - Epoch 28, Step 98023: Loss=5.3467, Acc=0.200, 
2025-10-05 15:32:59,714 - training.trainer - INFO - Epoch 29/100 completed in 267.38s - Train Loss: 5.4756, Train Acc: 0.281, Val Loss: 5.6643, Val Acc: 0.257
2025-10-05 15:33:07,422 - training.trainer - INFO - Epoch 29, Step 98206: Loss=4.6792, Acc=0.348, 
2025-10-05 15:33:15,010 - training.trainer - INFO - Epoch 29, Step 98306: Loss=6.1937, Acc=0.241, 
2025-10-05 15:33:22,763 - training.trainer - INFO - Epoch 29, Step 98406: Loss=6.0775, Acc=0.258, 
2025-10-05 15:33:30,165 - training.trainer - INFO - Epoch 29, Step 98506: Loss=5.1799, Acc=0.320, 
2025-10-05 15:33:37,575 - training.trainer - INFO - Epoch 29, Step 98606: Loss=6.1926, Acc=0.100, 
2025-10-05 15:33:45,126 - training.trainer - INFO - Epoch 29, Step 98706: Loss=5.4821, Acc=0.317, 
2025-10-05 15:33:52,501 - training.trainer - INFO - Epoch 29, Step 98806: Loss=6.1362, Acc=0.219, 
2025-10-05 15:34:00,086 - training.trainer - INFO - Epoch 29, Step 98906: Loss=4.7571, Acc=0.375, 
2025-10-05 15:34:07,626 - training.trainer - INFO - Epoch 29, Step 99006: Loss=3.3058, Acc=0.579, 
2025-10-05 15:34:15,190 - training.trainer - INFO - Epoch 29, Step 99106: Loss=5.4882, Acc=0.333, 
2025-10-05 15:34:22,815 - training.trainer - INFO - Epoch 29, Step 99206: Loss=3.6240, Acc=0.500, 
2025-10-05 15:34:30,287 - training.trainer - INFO - Epoch 29, Step 99306: Loss=5.8419, Acc=0.254, 
2025-10-05 15:34:37,653 - training.trainer - INFO - Epoch 29, Step 99406: Loss=5.5610, Acc=0.229, 
2025-10-05 15:34:45,025 - training.trainer - INFO - Epoch 29, Step 99506: Loss=5.3778, Acc=0.300, 
2025-10-05 15:34:52,593 - training.trainer - INFO - Epoch 29, Step 99606: Loss=5.5456, Acc=0.233, 
2025-10-05 15:35:00,468 - training.trainer - INFO - Epoch 29, Step 99706: Loss=5.8161, Acc=0.163, 
2025-10-05 15:35:07,984 - training.trainer - INFO - Epoch 29, Step 99806: Loss=4.8139, Acc=0.152, 
2025-10-05 15:35:15,444 - training.trainer - INFO - Epoch 29, Step 99906: Loss=5.7422, Acc=0.400, 
2025-10-05 15:35:23,151 - training.trainer - INFO - Epoch 29, Step 100006: Loss=5.2602, Acc=0.304, 
2025-10-05 15:35:30,496 - training.trainer - INFO - Epoch 29, Step 100106: Loss=5.0801, Acc=0.167, 
2025-10-05 15:35:37,898 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.7212, Acc=0.324, 
2025-10-05 15:35:45,239 - training.trainer - INFO - Epoch 29, Step 100306: Loss=6.2762, Acc=0.300, 
2025-10-05 15:35:52,533 - training.trainer - INFO - Epoch 29, Step 100406: Loss=6.0455, Acc=0.202, 
2025-10-05 15:35:59,954 - training.trainer - INFO - Epoch 29, Step 100506: Loss=5.0336, Acc=0.333, 
2025-10-05 15:36:07,336 - training.trainer - INFO - Epoch 29, Step 100606: Loss=4.3448, Acc=0.484, 
2025-10-05 15:36:14,767 - training.trainer - INFO - Epoch 29, Step 100706: Loss=5.9098, Acc=0.262, 
2025-10-05 15:36:22,160 - training.trainer - INFO - Epoch 29, Step 100806: Loss=5.7654, Acc=0.260, 
2025-10-05 15:36:29,563 - training.trainer - INFO - Epoch 29, Step 100906: Loss=5.6907, Acc=0.143, 
2025-10-05 15:36:36,803 - training.trainer - INFO - Epoch 29, Step 101006: Loss=4.8268, Acc=0.326, 
2025-10-05 15:36:44,026 - training.trainer - INFO - Epoch 29, Step 101106: Loss=6.0140, Acc=0.190, 
2025-10-05 15:36:51,272 - training.trainer - INFO - Epoch 29, Step 101206: Loss=4.9565, Acc=0.344, 
2025-10-05 15:36:58,502 - training.trainer - INFO - Epoch 29, Step 101306: Loss=6.0134, Acc=0.304, 
2025-10-05 15:37:05,862 - training.trainer - INFO - Epoch 29, Step 101406: Loss=4.7701, Acc=0.296, 
2025-10-05 15:37:24,645 - training.trainer - INFO - Epoch 30/100 completed in 264.93s - Train Loss: 5.4620, Train Acc: 0.283, Val Loss: 5.6627, Val Acc: 0.256
2025-10-05 15:37:24,973 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-10-05 15:37:31,689 - training.trainer - INFO - Epoch 30, Step 101589: Loss=6.0344, Acc=0.240, 
2025-10-05 15:37:39,230 - training.trainer - INFO - Epoch 30, Step 101689: Loss=6.3326, Acc=0.225, 
2025-10-05 15:37:46,911 - training.trainer - INFO - Epoch 30, Step 101789: Loss=5.3446, Acc=0.323, 
2025-10-05 15:37:54,512 - training.trainer - INFO - Epoch 30, Step 101889: Loss=5.8025, Acc=0.300, 
2025-10-05 15:38:02,134 - training.trainer - INFO - Epoch 30, Step 101989: Loss=5.4882, Acc=0.256, 
2025-10-05 15:38:09,840 - training.trainer - INFO - Epoch 30, Step 102089: Loss=5.3292, Acc=0.346, 
2025-10-05 15:38:17,330 - training.trainer - INFO - Epoch 30, Step 102189: Loss=5.3031, Acc=0.325, 
2025-10-05 15:38:24,765 - training.trainer - INFO - Epoch 30, Step 102289: Loss=5.9073, Acc=0.245, 
2025-10-05 15:38:32,237 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.8679, Acc=0.211, 
2025-10-05 15:38:39,685 - training.trainer - INFO - Epoch 30, Step 102489: Loss=6.0299, Acc=0.228, 
2025-10-05 15:38:46,978 - training.trainer - INFO - Epoch 30, Step 102589: Loss=6.0212, Acc=0.184, 
2025-10-05 15:38:54,218 - training.trainer - INFO - Epoch 30, Step 102689: Loss=5.4673, Acc=0.206, 
2025-10-05 15:39:01,614 - training.trainer - INFO - Epoch 30, Step 102789: Loss=6.1654, Acc=0.167, 
2025-10-05 15:39:09,159 - training.trainer - INFO - Epoch 30, Step 102889: Loss=5.8813, Acc=0.222, 
2025-10-05 15:39:16,741 - training.trainer - INFO - Epoch 30, Step 102989: Loss=5.1767, Acc=0.259, 
2025-10-05 15:39:24,258 - training.trainer - INFO - Epoch 30, Step 103089: Loss=4.4817, Acc=0.357, 
2025-10-05 15:39:31,590 - training.trainer - INFO - Epoch 30, Step 103189: Loss=5.8319, Acc=0.208, 
2025-10-05 15:39:38,873 - training.trainer - INFO - Epoch 30, Step 103289: Loss=6.0080, Acc=0.189, 
2025-10-05 15:39:46,388 - training.trainer - INFO - Epoch 30, Step 103389: Loss=5.3869, Acc=0.269, 
2025-10-05 15:39:53,696 - training.trainer - INFO - Epoch 30, Step 103489: Loss=3.8695, Acc=0.412, 
2025-10-05 15:40:01,032 - training.trainer - INFO - Epoch 30, Step 103589: Loss=4.7155, Acc=0.375, 
2025-10-05 15:40:08,668 - training.trainer - INFO - Epoch 30, Step 103689: Loss=4.8022, Acc=0.293, 
2025-10-05 15:40:16,216 - training.trainer - INFO - Epoch 30, Step 103789: Loss=6.0054, Acc=0.286, 
2025-10-05 15:40:23,801 - training.trainer - INFO - Epoch 30, Step 103889: Loss=6.0572, Acc=0.273, 
2025-10-05 15:40:31,427 - training.trainer - INFO - Epoch 30, Step 103989: Loss=5.1152, Acc=0.360, 
2025-10-05 15:40:38,852 - training.trainer - INFO - Epoch 30, Step 104089: Loss=5.8476, Acc=0.300, 
2025-10-05 15:40:46,548 - training.trainer - INFO - Epoch 30, Step 104189: Loss=4.9612, Acc=0.278, 
2025-10-05 15:40:53,933 - training.trainer - INFO - Epoch 30, Step 104289: Loss=5.8606, Acc=0.189, 
2025-10-05 15:41:01,348 - training.trainer - INFO - Epoch 30, Step 104389: Loss=5.1730, Acc=0.353, 
2025-10-05 15:41:08,903 - training.trainer - INFO - Epoch 30, Step 104489: Loss=5.5535, Acc=0.217, 
2025-10-05 15:41:16,422 - training.trainer - INFO - Epoch 30, Step 104589: Loss=4.7519, Acc=0.286, 
2025-10-05 15:41:24,002 - training.trainer - INFO - Epoch 30, Step 104689: Loss=5.4657, Acc=0.282, 
2025-10-05 15:41:31,429 - training.trainer - INFO - Epoch 30, Step 104789: Loss=4.5918, Acc=0.412, 
2025-10-05 15:41:50,712 - training.trainer - INFO - Epoch 31/100 completed in 265.74s - Train Loss: 5.4435, Train Acc: 0.287, Val Loss: 5.6639, Val Acc: 0.255
2025-10-05 15:41:58,818 - training.trainer - INFO - Epoch 31, Step 104972: Loss=4.8719, Acc=0.320, 
2025-10-05 15:42:06,231 - training.trainer - INFO - Epoch 31, Step 105072: Loss=6.2935, Acc=0.205, 
2025-10-05 15:42:13,598 - training.trainer - INFO - Epoch 31, Step 105172: Loss=5.1586, Acc=0.296, 
2025-10-05 15:42:20,976 - training.trainer - INFO - Epoch 31, Step 105272: Loss=4.9917, Acc=0.364, 
2025-10-05 15:42:28,328 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.0290, Acc=0.292, 
2025-10-05 15:42:35,774 - training.trainer - INFO - Epoch 31, Step 105472: Loss=5.2573, Acc=0.333, 
2025-10-05 15:42:43,270 - training.trainer - INFO - Epoch 31, Step 105572: Loss=5.7288, Acc=0.261, 
2025-10-05 15:42:50,657 - training.trainer - INFO - Epoch 31, Step 105672: Loss=5.5278, Acc=0.278, 
2025-10-05 15:42:58,006 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.2147, Acc=0.367, 
2025-10-05 15:43:05,837 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.1432, Acc=0.328, 
2025-10-05 15:43:13,129 - training.trainer - INFO - Epoch 31, Step 105972: Loss=5.0806, Acc=0.276, 
2025-10-05 15:43:20,440 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.4060, Acc=0.286, 
2025-10-05 15:43:27,887 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.4522, Acc=0.412, 
2025-10-05 15:43:35,287 - training.trainer - INFO - Epoch 31, Step 106272: Loss=4.6838, Acc=0.421, 
2025-10-05 15:43:42,636 - training.trainer - INFO - Epoch 31, Step 106372: Loss=5.1424, Acc=0.286, 
2025-10-05 15:43:49,975 - training.trainer - INFO - Epoch 31, Step 106472: Loss=6.1633, Acc=0.182, 
2025-10-05 15:43:57,309 - training.trainer - INFO - Epoch 31, Step 106572: Loss=4.7459, Acc=0.450, 
2025-10-05 15:44:04,843 - training.trainer - INFO - Epoch 31, Step 106672: Loss=4.2304, Acc=0.333, 
2025-10-05 15:44:12,472 - training.trainer - INFO - Epoch 31, Step 106772: Loss=5.2261, Acc=0.361, 
2025-10-05 15:44:20,171 - training.trainer - INFO - Epoch 31, Step 106872: Loss=5.8407, Acc=0.185, 
2025-10-05 15:44:27,456 - training.trainer - INFO - Epoch 31, Step 106972: Loss=6.0346, Acc=0.286, 
2025-10-05 15:44:34,757 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.1270, Acc=0.375, 
2025-10-05 15:44:42,145 - training.trainer - INFO - Epoch 31, Step 107172: Loss=5.5742, Acc=0.318, 
2025-10-05 15:44:49,494 - training.trainer - INFO - Epoch 31, Step 107272: Loss=5.0465, Acc=0.265, 
2025-10-05 15:44:56,953 - training.trainer - INFO - Epoch 31, Step 107372: Loss=5.6909, Acc=0.295, 
2025-10-05 15:45:04,315 - training.trainer - INFO - Epoch 31, Step 107472: Loss=5.8322, Acc=0.269, 
2025-10-05 15:45:11,669 - training.trainer - INFO - Epoch 31, Step 107572: Loss=5.7365, Acc=0.308, 
2025-10-05 15:45:19,074 - training.trainer - INFO - Epoch 31, Step 107672: Loss=5.3692, Acc=0.360, 
2025-10-05 15:45:26,554 - training.trainer - INFO - Epoch 31, Step 107772: Loss=6.2994, Acc=0.209, 
2025-10-05 15:45:33,978 - training.trainer - INFO - Epoch 31, Step 107872: Loss=4.9444, Acc=0.310, 
2025-10-05 15:45:41,452 - training.trainer - INFO - Epoch 31, Step 107972: Loss=4.9718, Acc=0.387, 
2025-10-05 15:45:49,017 - training.trainer - INFO - Epoch 31, Step 108072: Loss=5.2866, Acc=0.269, 
2025-10-05 15:45:56,713 - training.trainer - INFO - Epoch 31, Step 108172: Loss=5.5981, Acc=0.217, 
2025-10-05 15:46:15,797 - training.trainer - INFO - Epoch 32/100 completed in 265.08s - Train Loss: 5.4280, Train Acc: 0.290, Val Loss: 5.6583, Val Acc: 0.255
2025-10-05 15:46:23,954 - training.trainer - INFO - Epoch 32, Step 108355: Loss=5.0987, Acc=0.286, 
2025-10-05 15:46:31,507 - training.trainer - INFO - Epoch 32, Step 108455: Loss=5.2367, Acc=0.318, 
2025-10-05 15:46:38,901 - training.trainer - INFO - Epoch 32, Step 108555: Loss=5.1362, Acc=0.286, 
2025-10-05 15:46:46,249 - training.trainer - INFO - Epoch 32, Step 108655: Loss=5.3495, Acc=0.279, 
2025-10-05 15:46:53,642 - training.trainer - INFO - Epoch 32, Step 108755: Loss=6.0117, Acc=0.305, 
2025-10-05 15:47:01,134 - training.trainer - INFO - Epoch 32, Step 108855: Loss=5.6943, Acc=0.231, 
2025-10-05 15:47:08,744 - training.trainer - INFO - Epoch 32, Step 108955: Loss=5.6044, Acc=0.244, 
2025-10-05 15:47:16,234 - training.trainer - INFO - Epoch 32, Step 109055: Loss=5.2978, Acc=0.269, 
2025-10-05 15:47:23,636 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.2584, Acc=0.295, 
2025-10-05 15:47:31,048 - training.trainer - INFO - Epoch 32, Step 109255: Loss=5.2482, Acc=0.286, 
2025-10-05 15:47:38,487 - training.trainer - INFO - Epoch 32, Step 109355: Loss=5.6070, Acc=0.391, 
2025-10-05 15:47:46,113 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.4137, Acc=0.389, 
2025-10-05 15:47:53,598 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.3541, Acc=0.327, 
2025-10-05 15:48:01,112 - training.trainer - INFO - Epoch 32, Step 109655: Loss=4.0378, Acc=0.459, 
2025-10-05 15:48:09,170 - training.trainer - INFO - Epoch 32, Step 109755: Loss=6.0587, Acc=0.220, 
2025-10-05 15:48:16,737 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.4147, Acc=0.333, 
2025-10-05 15:48:24,212 - training.trainer - INFO - Epoch 32, Step 109955: Loss=5.6251, Acc=0.273, 
2025-10-05 15:48:31,766 - training.trainer - INFO - Epoch 32, Step 110055: Loss=6.4946, Acc=0.153, 
2025-10-05 15:48:39,234 - training.trainer - INFO - Epoch 32, Step 110155: Loss=5.4698, Acc=0.233, 
2025-10-05 15:48:46,725 - training.trainer - INFO - Epoch 32, Step 110255: Loss=4.3663, Acc=0.480, 
2025-10-05 15:48:54,195 - training.trainer - INFO - Epoch 32, Step 110355: Loss=5.8196, Acc=0.339, 
2025-10-05 15:49:01,731 - training.trainer - INFO - Epoch 32, Step 110455: Loss=5.6364, Acc=0.300, 
2025-10-05 15:49:09,296 - training.trainer - INFO - Epoch 32, Step 110555: Loss=5.0535, Acc=0.391, 
2025-10-05 15:49:16,782 - training.trainer - INFO - Epoch 32, Step 110655: Loss=5.6706, Acc=0.270, 
2025-10-05 15:49:24,160 - training.trainer - INFO - Epoch 32, Step 110755: Loss=6.5690, Acc=0.204, 
2025-10-05 15:49:31,426 - training.trainer - INFO - Epoch 32, Step 110855: Loss=6.7136, Acc=0.184, 
2025-10-05 15:49:38,718 - training.trainer - INFO - Epoch 32, Step 110955: Loss=4.3532, Acc=0.333, 
2025-10-05 15:49:46,255 - training.trainer - INFO - Epoch 32, Step 111055: Loss=6.0352, Acc=0.230, 
2025-10-05 15:49:53,973 - training.trainer - INFO - Epoch 32, Step 111155: Loss=6.2442, Acc=0.231, 
2025-10-05 15:50:01,528 - training.trainer - INFO - Epoch 32, Step 111255: Loss=5.9583, Acc=0.179, 
2025-10-05 15:50:09,092 - training.trainer - INFO - Epoch 32, Step 111355: Loss=5.8453, Acc=0.280, 
2025-10-05 15:50:16,624 - training.trainer - INFO - Epoch 32, Step 111455: Loss=5.1966, Acc=0.310, 
2025-10-05 15:50:24,015 - training.trainer - INFO - Epoch 32, Step 111555: Loss=6.2162, Acc=0.333, 
2025-10-05 15:50:43,298 - training.trainer - INFO - Epoch 33/100 completed in 267.50s - Train Loss: 5.4133, Train Acc: 0.293, Val Loss: 5.6526, Val Acc: 0.259
2025-10-05 15:50:44,032 - training.trainer - INFO - New best model saved with validation loss: 5.6526
2025-10-05 15:50:44,033 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_33.pt
2025-10-05 15:50:52,062 - training.trainer - INFO - Epoch 33, Step 111738: Loss=5.4707, Acc=0.286, 
2025-10-05 15:50:59,623 - training.trainer - INFO - Epoch 33, Step 111838: Loss=6.2605, Acc=0.185, 
2025-10-05 15:51:07,055 - training.trainer - INFO - Epoch 33, Step 111938: Loss=5.3620, Acc=0.273, 
2025-10-05 15:51:14,517 - training.trainer - INFO - Epoch 33, Step 112038: Loss=5.9614, Acc=0.242, 
2025-10-05 15:51:21,845 - training.trainer - INFO - Epoch 33, Step 112138: Loss=5.5123, Acc=0.277, 
2025-10-05 15:51:29,149 - training.trainer - INFO - Epoch 33, Step 112238: Loss=5.7177, Acc=0.289, 
2025-10-05 15:51:36,539 - training.trainer - INFO - Epoch 33, Step 112338: Loss=6.0038, Acc=0.423, 
2025-10-05 15:51:44,166 - training.trainer - INFO - Epoch 33, Step 112438: Loss=5.6704, Acc=0.395, 
2025-10-05 15:51:51,507 - training.trainer - INFO - Epoch 33, Step 112538: Loss=6.0548, Acc=0.220, 
2025-10-05 15:51:58,924 - training.trainer - INFO - Epoch 33, Step 112638: Loss=5.5941, Acc=0.217, 
2025-10-05 15:52:06,379 - training.trainer - INFO - Epoch 33, Step 112738: Loss=5.5272, Acc=0.250, 
2025-10-05 15:52:13,720 - training.trainer - INFO - Epoch 33, Step 112838: Loss=4.6863, Acc=0.302, 
2025-10-05 15:52:21,264 - training.trainer - INFO - Epoch 33, Step 112938: Loss=6.2112, Acc=0.224, 
2025-10-05 15:52:28,728 - training.trainer - INFO - Epoch 33, Step 113038: Loss=6.0013, Acc=0.143, 
2025-10-05 15:52:36,128 - training.trainer - INFO - Epoch 33, Step 113138: Loss=5.8120, Acc=0.222, 
2025-10-05 15:52:43,418 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.5497, Acc=0.179, 
2025-10-05 15:52:50,673 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.3009, Acc=0.276, 
2025-10-05 15:52:57,994 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.3549, Acc=0.346, 
2025-10-05 15:53:05,754 - training.trainer - INFO - Epoch 33, Step 113538: Loss=5.6624, Acc=0.276, 
2025-10-05 15:53:13,199 - training.trainer - INFO - Epoch 33, Step 113638: Loss=6.1633, Acc=0.191, 
2025-10-05 15:53:20,641 - training.trainer - INFO - Epoch 33, Step 113738: Loss=5.7113, Acc=0.273, 
2025-10-05 15:53:28,084 - training.trainer - INFO - Epoch 33, Step 113838: Loss=6.1413, Acc=0.250, 
2025-10-05 15:53:35,491 - training.trainer - INFO - Epoch 33, Step 113938: Loss=5.2157, Acc=0.300, 
2025-10-05 15:53:42,891 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.5117, Acc=0.319, 
2025-10-05 15:53:50,308 - training.trainer - INFO - Epoch 33, Step 114138: Loss=5.9265, Acc=0.271, 
2025-10-05 15:53:57,605 - training.trainer - INFO - Epoch 33, Step 114238: Loss=5.2121, Acc=0.400, 
2025-10-05 15:54:04,914 - training.trainer - INFO - Epoch 33, Step 114338: Loss=6.0872, Acc=0.176, 
2025-10-05 15:54:12,203 - training.trainer - INFO - Epoch 33, Step 114438: Loss=6.3626, Acc=0.211, 
2025-10-05 15:54:19,537 - training.trainer - INFO - Epoch 33, Step 114538: Loss=6.1829, Acc=0.292, 
2025-10-05 15:54:26,983 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.1830, Acc=0.300, 
2025-10-05 15:54:34,302 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.3117, Acc=0.370, 
2025-10-05 15:54:41,649 - training.trainer - INFO - Epoch 33, Step 114838: Loss=5.9684, Acc=0.317, 
2025-10-05 15:54:49,091 - training.trainer - INFO - Epoch 33, Step 114938: Loss=5.6068, Acc=0.208, 
2025-10-05 15:55:08,897 - training.trainer - INFO - Epoch 34/100 completed in 264.86s - Train Loss: 5.3963, Train Acc: 0.295, Val Loss: 5.6538, Val Acc: 0.261
2025-10-05 15:55:15,596 - training.trainer - INFO - Epoch 34, Step 115121: Loss=5.3275, Acc=0.321, 
2025-10-05 15:55:22,479 - training.trainer - INFO - Epoch 34, Step 115221: Loss=6.1121, Acc=0.150, 
2025-10-05 15:55:29,792 - training.trainer - INFO - Epoch 34, Step 115321: Loss=2.5495, Acc=0.696, 
2025-10-05 15:55:37,038 - training.trainer - INFO - Epoch 34, Step 115421: Loss=4.1279, Acc=0.417, 
2025-10-05 15:55:44,374 - training.trainer - INFO - Epoch 34, Step 115521: Loss=5.8524, Acc=0.273, 
2025-10-05 15:55:51,683 - training.trainer - INFO - Epoch 34, Step 115621: Loss=5.3564, Acc=0.404, 
2025-10-05 15:55:58,965 - training.trainer - INFO - Epoch 34, Step 115721: Loss=4.9198, Acc=0.353, 
2025-10-05 15:56:06,208 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.8039, Acc=0.360, 
2025-10-05 15:56:13,467 - training.trainer - INFO - Epoch 34, Step 115921: Loss=4.8832, Acc=0.324, 
2025-10-05 15:56:20,875 - training.trainer - INFO - Epoch 34, Step 116021: Loss=5.2215, Acc=0.296, 
2025-10-05 15:56:28,258 - training.trainer - INFO - Epoch 34, Step 116121: Loss=5.9193, Acc=0.222, 
2025-10-05 15:56:35,624 - training.trainer - INFO - Epoch 34, Step 116221: Loss=5.7698, Acc=0.375, 
2025-10-05 15:56:43,005 - training.trainer - INFO - Epoch 34, Step 116321: Loss=5.7763, Acc=0.333, 
2025-10-05 15:56:50,520 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.9077, Acc=0.204, 
2025-10-05 15:56:57,810 - training.trainer - INFO - Epoch 34, Step 116521: Loss=5.0908, Acc=0.250, 
2025-10-05 15:57:05,098 - training.trainer - INFO - Epoch 34, Step 116621: Loss=5.5770, Acc=0.286, 
2025-10-05 15:57:12,344 - training.trainer - INFO - Epoch 34, Step 116721: Loss=5.1730, Acc=0.268, 
2025-10-05 15:57:20,145 - training.trainer - INFO - Epoch 34, Step 116821: Loss=5.5345, Acc=0.256, 
2025-10-05 15:57:27,455 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.0626, Acc=0.321, 
2025-10-05 15:57:34,768 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.2172, Acc=0.275, 
2025-10-05 15:57:42,050 - training.trainer - INFO - Epoch 34, Step 117121: Loss=5.2581, Acc=0.286, 
2025-10-05 15:57:49,484 - training.trainer - INFO - Epoch 34, Step 117221: Loss=6.0896, Acc=0.211, 
2025-10-05 15:57:57,098 - training.trainer - INFO - Epoch 34, Step 117321: Loss=5.0192, Acc=0.302, 
2025-10-05 15:58:04,635 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.5586, Acc=0.259, 
2025-10-05 15:58:12,131 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.5689, Acc=0.231, 
2025-10-05 15:58:19,542 - training.trainer - INFO - Epoch 34, Step 117621: Loss=5.8765, Acc=0.435, 
2025-10-05 15:58:26,963 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.4679, Acc=0.301, 
2025-10-05 15:58:34,239 - training.trainer - INFO - Epoch 34, Step 117821: Loss=5.6404, Acc=0.254, 
2025-10-05 15:58:41,549 - training.trainer - INFO - Epoch 34, Step 117921: Loss=5.8680, Acc=0.345, 
2025-10-05 15:58:48,849 - training.trainer - INFO - Epoch 34, Step 118021: Loss=4.5157, Acc=0.342, 
2025-10-05 15:58:56,236 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.7271, Acc=0.297, 
2025-10-05 15:59:03,841 - training.trainer - INFO - Epoch 34, Step 118221: Loss=5.3157, Acc=0.222, 
2025-10-05 15:59:11,155 - training.trainer - INFO - Epoch 34, Step 118321: Loss=5.7951, Acc=0.169, 
2025-10-05 15:59:30,457 - training.trainer - INFO - Epoch 35/100 completed in 261.56s - Train Loss: 5.3750, Train Acc: 0.297, Val Loss: 5.6578, Val Acc: 0.257
2025-10-05 15:59:30,826 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-10-05 15:59:39,008 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.3125, Acc=0.318, 
2025-10-05 15:59:46,626 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.3621, Acc=0.440, 
2025-10-05 15:59:53,954 - training.trainer - INFO - Epoch 35, Step 118704: Loss=4.9813, Acc=0.300, 
2025-10-05 16:00:01,331 - training.trainer - INFO - Epoch 35, Step 118804: Loss=6.5735, Acc=0.192, 
2025-10-05 16:00:08,789 - training.trainer - INFO - Epoch 35, Step 118904: Loss=5.1016, Acc=0.308, 
2025-10-05 16:00:16,357 - training.trainer - INFO - Epoch 35, Step 119004: Loss=6.5803, Acc=0.146, 
2025-10-05 16:00:23,704 - training.trainer - INFO - Epoch 35, Step 119104: Loss=5.5198, Acc=0.300, 
2025-10-05 16:00:31,045 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.8394, Acc=0.288, 
2025-10-05 16:00:38,338 - training.trainer - INFO - Epoch 35, Step 119304: Loss=5.5877, Acc=0.233, 
2025-10-05 16:00:46,006 - training.trainer - INFO - Epoch 35, Step 119404: Loss=6.3925, Acc=0.233, 
2025-10-05 16:00:53,740 - training.trainer - INFO - Epoch 35, Step 119504: Loss=5.9236, Acc=0.184, 
2025-10-05 16:01:01,211 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.6416, Acc=0.300, 
2025-10-05 16:01:08,651 - training.trainer - INFO - Epoch 35, Step 119704: Loss=5.8808, Acc=0.296, 
2025-10-05 16:01:16,156 - training.trainer - INFO - Epoch 35, Step 119804: Loss=4.3121, Acc=0.450, 
2025-10-05 16:01:23,700 - training.trainer - INFO - Epoch 35, Step 119904: Loss=4.8347, Acc=0.308, 
2025-10-05 16:01:31,326 - training.trainer - INFO - Epoch 35, Step 120004: Loss=6.0920, Acc=0.209, 
2025-10-05 16:01:38,780 - training.trainer - INFO - Epoch 35, Step 120104: Loss=5.1057, Acc=0.314, 
2025-10-05 16:01:46,395 - training.trainer - INFO - Epoch 35, Step 120204: Loss=4.0091, Acc=0.462, 
2025-10-05 16:01:53,967 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.9436, Acc=0.360, 
2025-10-05 16:02:01,445 - training.trainer - INFO - Epoch 35, Step 120404: Loss=5.9987, Acc=0.171, 
2025-10-05 16:02:08,907 - training.trainer - INFO - Epoch 35, Step 120504: Loss=6.4279, Acc=0.269, 
2025-10-05 16:02:16,285 - training.trainer - INFO - Epoch 35, Step 120604: Loss=5.6208, Acc=0.360, 
2025-10-05 16:02:23,708 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.3374, Acc=0.303, 
2025-10-05 16:02:31,453 - training.trainer - INFO - Epoch 35, Step 120804: Loss=5.6603, Acc=0.289, 
2025-10-05 16:02:39,014 - training.trainer - INFO - Epoch 35, Step 120904: Loss=4.5215, Acc=0.278, 
2025-10-05 16:02:46,575 - training.trainer - INFO - Epoch 35, Step 121004: Loss=6.1774, Acc=0.233, 
2025-10-05 16:02:54,093 - training.trainer - INFO - Epoch 35, Step 121104: Loss=5.9247, Acc=0.260, 
2025-10-05 16:03:01,702 - training.trainer - INFO - Epoch 35, Step 121204: Loss=5.5418, Acc=0.333, 
2025-10-05 16:03:09,108 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.6352, Acc=0.237, 
2025-10-05 16:03:16,497 - training.trainer - INFO - Epoch 35, Step 121404: Loss=5.3086, Acc=0.356, 
2025-10-05 16:03:24,035 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.6567, Acc=0.241, 
2025-10-05 16:03:31,554 - training.trainer - INFO - Epoch 35, Step 121604: Loss=4.4009, Acc=0.414, 
2025-10-05 16:03:39,108 - training.trainer - INFO - Epoch 35, Step 121704: Loss=5.4121, Acc=0.279, 
2025-10-05 16:03:59,019 - training.trainer - INFO - Epoch 36/100 completed in 268.19s - Train Loss: 5.3626, Train Acc: 0.300, Val Loss: 5.6506, Val Acc: 0.259
2025-10-05 16:03:59,714 - training.trainer - INFO - New best model saved with validation loss: 5.6506
2025-10-05 16:03:59,714 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_36.pt
2025-10-05 16:04:07,892 - training.trainer - INFO - Epoch 36, Step 121887: Loss=5.9606, Acc=0.312, 
2025-10-05 16:04:15,647 - training.trainer - INFO - Epoch 36, Step 121987: Loss=6.2151, Acc=0.250, 
2025-10-05 16:04:23,218 - training.trainer - INFO - Epoch 36, Step 122087: Loss=5.6802, Acc=0.294, 
2025-10-05 16:04:30,834 - training.trainer - INFO - Epoch 36, Step 122187: Loss=6.0738, Acc=0.188, 
2025-10-05 16:04:38,389 - training.trainer - INFO - Epoch 36, Step 122287: Loss=5.6250, Acc=0.273, 
2025-10-05 16:04:45,933 - training.trainer - INFO - Epoch 36, Step 122387: Loss=5.8168, Acc=0.297, 
2025-10-05 16:04:53,413 - training.trainer - INFO - Epoch 36, Step 122487: Loss=6.0086, Acc=0.220, 
2025-10-05 16:05:00,873 - training.trainer - INFO - Epoch 36, Step 122587: Loss=6.1743, Acc=0.185, 
2025-10-05 16:05:08,257 - training.trainer - INFO - Epoch 36, Step 122687: Loss=5.0236, Acc=0.238, 
2025-10-05 16:05:15,697 - training.trainer - INFO - Epoch 36, Step 122787: Loss=5.7791, Acc=0.262, 
2025-10-05 16:05:23,073 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.8031, Acc=0.268, 
2025-10-05 16:05:30,617 - training.trainer - INFO - Epoch 36, Step 122987: Loss=6.2213, Acc=0.300, 
2025-10-05 16:05:38,068 - training.trainer - INFO - Epoch 36, Step 123087: Loss=5.2899, Acc=0.286, 
2025-10-05 16:05:45,437 - training.trainer - INFO - Epoch 36, Step 123187: Loss=5.6777, Acc=0.264, 
2025-10-05 16:05:52,803 - training.trainer - INFO - Epoch 36, Step 123287: Loss=5.2633, Acc=0.276, 
2025-10-05 16:06:00,123 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.4717, Acc=0.217, 
2025-10-05 16:06:07,511 - training.trainer - INFO - Epoch 36, Step 123487: Loss=5.2960, Acc=0.310, 
2025-10-05 16:06:15,286 - training.trainer - INFO - Epoch 36, Step 123587: Loss=5.4063, Acc=0.309, 
2025-10-05 16:06:22,676 - training.trainer - INFO - Epoch 36, Step 123687: Loss=5.3760, Acc=0.273, 
2025-10-05 16:06:30,086 - training.trainer - INFO - Epoch 36, Step 123787: Loss=4.4902, Acc=0.442, 
2025-10-05 16:06:37,392 - training.trainer - INFO - Epoch 36, Step 123887: Loss=5.5082, Acc=0.239, 
2025-10-05 16:06:44,752 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.2761, Acc=0.242, 
2025-10-05 16:06:52,083 - training.trainer - INFO - Epoch 36, Step 124087: Loss=4.4145, Acc=0.393, 
2025-10-05 16:06:59,426 - training.trainer - INFO - Epoch 36, Step 124187: Loss=4.1745, Acc=0.429, 
2025-10-05 16:07:06,812 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.4800, Acc=0.254, 
2025-10-05 16:07:14,204 - training.trainer - INFO - Epoch 36, Step 124387: Loss=5.9853, Acc=0.174, 
2025-10-05 16:07:21,520 - training.trainer - INFO - Epoch 36, Step 124487: Loss=6.0111, Acc=0.263, 
2025-10-05 16:07:28,858 - training.trainer - INFO - Epoch 36, Step 124587: Loss=6.2616, Acc=0.232, 
2025-10-05 16:07:36,148 - training.trainer - INFO - Epoch 36, Step 124687: Loss=5.2917, Acc=0.273, 
2025-10-05 16:07:43,525 - training.trainer - INFO - Epoch 36, Step 124787: Loss=5.7501, Acc=0.286, 
2025-10-05 16:07:50,948 - training.trainer - INFO - Epoch 36, Step 124887: Loss=6.0270, Acc=0.246, 
2025-10-05 16:07:58,338 - training.trainer - INFO - Epoch 36, Step 124987: Loss=5.1173, Acc=0.294, 
2025-10-05 16:08:05,672 - training.trainer - INFO - Epoch 36, Step 125087: Loss=5.9984, Acc=0.290, 
2025-10-05 16:08:24,398 - training.trainer - INFO - Epoch 37/100 completed in 264.68s - Train Loss: 5.3471, Train Acc: 0.303, Val Loss: 5.6506, Val Acc: 0.261
2025-10-05 16:08:31,014 - training.trainer - INFO - Epoch 37, Step 125270: Loss=5.9623, Acc=0.250, 
2025-10-05 16:08:37,366 - training.trainer - INFO - Epoch 37, Step 125370: Loss=6.4586, Acc=0.238, 
2025-10-05 16:08:43,676 - training.trainer - INFO - Epoch 37, Step 125470: Loss=5.8520, Acc=0.326, 
2025-10-05 16:08:49,986 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.6472, Acc=0.184, 
2025-10-05 16:08:56,461 - training.trainer - INFO - Epoch 37, Step 125670: Loss=3.7851, Acc=0.630, 
2025-10-05 16:09:02,834 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.8448, Acc=0.270, 
2025-10-05 16:09:09,225 - training.trainer - INFO - Epoch 37, Step 125870: Loss=5.9102, Acc=0.186, 
2025-10-05 16:09:15,480 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.1908, Acc=0.278, 
2025-10-05 16:09:21,767 - training.trainer - INFO - Epoch 37, Step 126070: Loss=5.5971, Acc=0.229, 
2025-10-05 16:09:28,098 - training.trainer - INFO - Epoch 37, Step 126170: Loss=6.0716, Acc=0.157, 
2025-10-05 16:09:34,413 - training.trainer - INFO - Epoch 37, Step 126270: Loss=4.2539, Acc=0.333, 
2025-10-05 16:09:40,684 - training.trainer - INFO - Epoch 37, Step 126370: Loss=5.2206, Acc=0.312, 
2025-10-05 16:09:46,998 - training.trainer - INFO - Epoch 37, Step 126470: Loss=5.7133, Acc=0.317, 
2025-10-05 16:09:53,322 - training.trainer - INFO - Epoch 37, Step 126570: Loss=6.0466, Acc=0.250, 
2025-10-05 16:09:59,653 - training.trainer - INFO - Epoch 37, Step 126670: Loss=6.3754, Acc=0.176, 
2025-10-05 16:10:06,429 - training.trainer - INFO - Epoch 37, Step 126770: Loss=5.9290, Acc=0.211, 
2025-10-05 16:10:13,814 - training.trainer - INFO - Epoch 37, Step 126870: Loss=5.6706, Acc=0.326, 
2025-10-05 16:10:21,237 - training.trainer - INFO - Epoch 37, Step 126970: Loss=4.8364, Acc=0.308, 
2025-10-05 16:10:28,656 - training.trainer - INFO - Epoch 37, Step 127070: Loss=5.8054, Acc=0.235, 
2025-10-05 16:10:36,150 - training.trainer - INFO - Epoch 37, Step 127170: Loss=5.9631, Acc=0.297, 
2025-10-05 16:10:43,514 - training.trainer - INFO - Epoch 37, Step 127270: Loss=6.0595, Acc=0.158, 
2025-10-05 16:10:50,990 - training.trainer - INFO - Epoch 37, Step 127370: Loss=5.8185, Acc=0.298, 
2025-10-05 16:10:58,533 - training.trainer - INFO - Epoch 37, Step 127470: Loss=5.4954, Acc=0.290, 
2025-10-05 16:11:06,039 - training.trainer - INFO - Epoch 37, Step 127570: Loss=5.8456, Acc=0.205, 
2025-10-05 16:11:13,454 - training.trainer - INFO - Epoch 37, Step 127670: Loss=4.1339, Acc=0.359, 
2025-10-05 16:11:20,799 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.6571, Acc=0.190, 
2025-10-05 16:11:28,140 - training.trainer - INFO - Epoch 37, Step 127870: Loss=3.6288, Acc=0.636, 
2025-10-05 16:11:35,417 - training.trainer - INFO - Epoch 37, Step 127970: Loss=5.3538, Acc=0.294, 
2025-10-05 16:11:42,795 - training.trainer - INFO - Epoch 37, Step 128070: Loss=5.3444, Acc=0.208, 
2025-10-05 16:11:50,249 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.4416, Acc=0.310, 
2025-10-05 16:11:57,686 - training.trainer - INFO - Epoch 37, Step 128270: Loss=5.4615, Acc=0.289, 
2025-10-05 16:12:05,061 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.0795, Acc=0.267, 
2025-10-05 16:12:12,537 - training.trainer - INFO - Epoch 37, Step 128470: Loss=4.9924, Acc=0.444, 
2025-10-05 16:12:31,902 - training.trainer - INFO - Epoch 38/100 completed in 247.50s - Train Loss: 5.3293, Train Acc: 0.306, Val Loss: 5.6524, Val Acc: 0.264
2025-10-05 16:12:38,653 - training.trainer - INFO - Epoch 38, Step 128653: Loss=5.6360, Acc=0.264, 
2025-10-05 16:12:44,980 - training.trainer - INFO - Epoch 38, Step 128753: Loss=6.1167, Acc=0.250, 
2025-10-05 16:12:51,347 - training.trainer - INFO - Epoch 38, Step 128853: Loss=4.8673, Acc=0.519, 
2025-10-05 16:12:57,635 - training.trainer - INFO - Epoch 38, Step 128953: Loss=5.9407, Acc=0.324, 
2025-10-05 16:13:04,001 - training.trainer - INFO - Epoch 38, Step 129053: Loss=5.3258, Acc=0.279, 
2025-10-05 16:13:10,379 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.2307, Acc=0.300, 
2025-10-05 16:13:16,787 - training.trainer - INFO - Epoch 38, Step 129253: Loss=3.1529, Acc=0.613, 
2025-10-05 16:13:23,208 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.4150, Acc=0.256, 
2025-10-05 16:13:29,576 - training.trainer - INFO - Epoch 38, Step 129453: Loss=5.6503, Acc=0.275, 
2025-10-05 16:13:36,818 - training.trainer - INFO - Epoch 38, Step 129553: Loss=4.9761, Acc=0.321, 
2025-10-05 16:13:44,188 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.4674, Acc=0.393, 
2025-10-05 16:13:51,637 - training.trainer - INFO - Epoch 38, Step 129753: Loss=5.3211, Acc=0.341, 
2025-10-05 16:13:59,079 - training.trainer - INFO - Epoch 38, Step 129853: Loss=5.4838, Acc=0.220, 
2025-10-05 16:14:06,577 - training.trainer - INFO - Epoch 38, Step 129953: Loss=5.7198, Acc=0.294, 
2025-10-05 16:14:14,099 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.7625, Acc=0.296, 
2025-10-05 16:14:21,551 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.3403, Acc=0.205, 
2025-10-05 16:14:29,058 - training.trainer - INFO - Epoch 38, Step 130253: Loss=4.5393, Acc=0.333, 
2025-10-05 16:14:36,420 - training.trainer - INFO - Epoch 38, Step 130353: Loss=2.7676, Acc=0.760, 
2025-10-05 16:14:43,771 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.2674, Acc=0.371, 
2025-10-05 16:14:51,116 - training.trainer - INFO - Epoch 38, Step 130553: Loss=5.6100, Acc=0.286, 
2025-10-05 16:14:58,508 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.9858, Acc=0.250, 
2025-10-05 16:15:05,854 - training.trainer - INFO - Epoch 38, Step 130753: Loss=5.0223, Acc=0.410, 
2025-10-05 16:15:13,543 - training.trainer - INFO - Epoch 38, Step 130853: Loss=4.6318, Acc=0.303, 
2025-10-05 16:15:20,911 - training.trainer - INFO - Epoch 38, Step 130953: Loss=5.9723, Acc=0.222, 
2025-10-05 16:15:28,326 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.7979, Acc=0.349, 
2025-10-05 16:15:35,722 - training.trainer - INFO - Epoch 38, Step 131153: Loss=5.6003, Acc=0.320, 
2025-10-05 16:15:43,088 - training.trainer - INFO - Epoch 38, Step 131253: Loss=5.0035, Acc=0.345, 
2025-10-05 16:15:50,421 - training.trainer - INFO - Epoch 38, Step 131353: Loss=5.8323, Acc=0.286, 
2025-10-05 16:15:57,795 - training.trainer - INFO - Epoch 38, Step 131453: Loss=4.8054, Acc=0.318, 
2025-10-05 16:16:05,246 - training.trainer - INFO - Epoch 38, Step 131553: Loss=6.1426, Acc=0.233, 
2025-10-05 16:16:12,633 - training.trainer - INFO - Epoch 38, Step 131653: Loss=4.6630, Acc=0.471, 
2025-10-05 16:16:20,022 - training.trainer - INFO - Epoch 38, Step 131753: Loss=5.8164, Acc=0.207, 
2025-10-05 16:16:27,367 - training.trainer - INFO - Epoch 38, Step 131853: Loss=5.3662, Acc=0.242, 
2025-10-05 16:16:46,652 - training.trainer - INFO - Epoch 39/100 completed in 254.75s - Train Loss: 5.3152, Train Acc: 0.308, Val Loss: 5.6482, Val Acc: 0.263
2025-10-05 16:16:47,384 - training.trainer - INFO - New best model saved with validation loss: 5.6482
2025-10-05 16:16:47,384 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_39.pt
2025-10-05 16:16:55,169 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.3056, Acc=0.221, 
2025-10-05 16:17:02,614 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.7203, Acc=0.293, 
2025-10-05 16:17:10,042 - training.trainer - INFO - Epoch 39, Step 132236: Loss=5.9255, Acc=0.276, 
2025-10-05 16:17:17,341 - training.trainer - INFO - Epoch 39, Step 132336: Loss=4.9516, Acc=0.419, 
2025-10-05 16:17:24,725 - training.trainer - INFO - Epoch 39, Step 132436: Loss=5.3410, Acc=0.324, 
2025-10-05 16:17:32,090 - training.trainer - INFO - Epoch 39, Step 132536: Loss=5.9928, Acc=0.190, 
2025-10-05 16:17:39,553 - training.trainer - INFO - Epoch 39, Step 132636: Loss=4.9115, Acc=0.433, 
2025-10-05 16:17:47,137 - training.trainer - INFO - Epoch 39, Step 132736: Loss=5.9236, Acc=0.255, 
2025-10-05 16:17:54,583 - training.trainer - INFO - Epoch 39, Step 132836: Loss=5.1072, Acc=0.360, 
2025-10-05 16:18:01,996 - training.trainer - INFO - Epoch 39, Step 132936: Loss=4.8389, Acc=0.250, 
2025-10-05 16:18:09,474 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.7391, Acc=0.368, 
2025-10-05 16:18:17,057 - training.trainer - INFO - Epoch 39, Step 133136: Loss=5.2960, Acc=0.375, 
2025-10-05 16:18:24,665 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.0680, Acc=0.333, 
2025-10-05 16:18:32,324 - training.trainer - INFO - Epoch 39, Step 133336: Loss=4.5262, Acc=0.286, 
2025-10-05 16:18:39,768 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.4486, Acc=0.333, 
2025-10-05 16:18:47,168 - training.trainer - INFO - Epoch 39, Step 133536: Loss=5.6470, Acc=0.304, 
2025-10-05 16:18:54,631 - training.trainer - INFO - Epoch 39, Step 133636: Loss=6.5008, Acc=0.310, 
2025-10-05 16:19:02,010 - training.trainer - INFO - Epoch 39, Step 133736: Loss=5.2388, Acc=0.400, 
2025-10-05 16:19:09,592 - training.trainer - INFO - Epoch 39, Step 133836: Loss=3.3241, Acc=0.500, 
2025-10-05 16:19:17,188 - training.trainer - INFO - Epoch 39, Step 133936: Loss=5.4543, Acc=0.286, 
2025-10-05 16:19:24,655 - training.trainer - INFO - Epoch 39, Step 134036: Loss=6.4667, Acc=0.176, 
2025-10-05 16:19:32,198 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.3673, Acc=0.260, 
2025-10-05 16:19:39,732 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.9147, Acc=0.286, 
2025-10-05 16:19:47,355 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.4140, Acc=0.370, 
2025-10-05 16:19:54,946 - training.trainer - INFO - Epoch 39, Step 134436: Loss=5.1544, Acc=0.385, 
2025-10-05 16:20:02,597 - training.trainer - INFO - Epoch 39, Step 134536: Loss=6.1018, Acc=0.219, 
2025-10-05 16:20:09,957 - training.trainer - INFO - Epoch 39, Step 134636: Loss=3.9208, Acc=0.605, 
2025-10-05 16:20:17,338 - training.trainer - INFO - Epoch 39, Step 134736: Loss=4.6291, Acc=0.444, 
2025-10-05 16:20:24,790 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.4660, Acc=0.290, 
2025-10-05 16:20:32,211 - training.trainer - INFO - Epoch 39, Step 134936: Loss=5.3649, Acc=0.244, 
2025-10-05 16:20:39,692 - training.trainer - INFO - Epoch 39, Step 135036: Loss=6.1105, Acc=0.169, 
2025-10-05 16:20:47,328 - training.trainer - INFO - Epoch 39, Step 135136: Loss=3.4584, Acc=0.452, 
2025-10-05 16:20:54,930 - training.trainer - INFO - Epoch 39, Step 135236: Loss=4.0763, Acc=0.542, 
2025-10-05 16:21:14,411 - training.trainer - INFO - Epoch 40/100 completed in 267.03s - Train Loss: 5.2935, Train Acc: 0.311, Val Loss: 5.6606, Val Acc: 0.262
2025-10-05 16:21:14,789 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-10-05 16:21:22,584 - training.trainer - INFO - Epoch 40, Step 135419: Loss=5.5105, Acc=0.190, 
2025-10-05 16:21:29,920 - training.trainer - INFO - Epoch 40, Step 135519: Loss=5.4059, Acc=0.269, 
2025-10-05 16:21:37,260 - training.trainer - INFO - Epoch 40, Step 135619: Loss=5.4197, Acc=0.359, 
2025-10-05 16:21:45,229 - training.trainer - INFO - Epoch 40, Step 135719: Loss=4.8510, Acc=0.357, 
2025-10-05 16:21:52,533 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.6689, Acc=0.300, 
2025-10-05 16:21:59,835 - training.trainer - INFO - Epoch 40, Step 135919: Loss=5.5633, Acc=0.250, 
2025-10-05 16:22:07,189 - training.trainer - INFO - Epoch 40, Step 136019: Loss=4.4341, Acc=0.333, 
2025-10-05 16:22:14,547 - training.trainer - INFO - Epoch 40, Step 136119: Loss=5.8708, Acc=0.250, 
2025-10-05 16:22:22,040 - training.trainer - INFO - Epoch 40, Step 136219: Loss=5.9875, Acc=0.238, 
2025-10-05 16:22:29,390 - training.trainer - INFO - Epoch 40, Step 136319: Loss=6.4532, Acc=0.152, 
2025-10-05 16:22:36,689 - training.trainer - INFO - Epoch 40, Step 136419: Loss=5.8038, Acc=0.265, 
2025-10-05 16:22:43,995 - training.trainer - INFO - Epoch 40, Step 136519: Loss=5.7758, Acc=0.256, 
2025-10-05 16:22:51,309 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.6416, Acc=0.240, 
2025-10-05 16:22:58,653 - training.trainer - INFO - Epoch 40, Step 136719: Loss=5.6320, Acc=0.257, 
2025-10-05 16:23:05,978 - training.trainer - INFO - Epoch 40, Step 136819: Loss=4.8384, Acc=0.438, 
2025-10-05 16:23:13,356 - training.trainer - INFO - Epoch 40, Step 136919: Loss=5.6390, Acc=0.281, 
2025-10-05 16:23:20,822 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.9513, Acc=0.229, 
2025-10-05 16:23:28,075 - training.trainer - INFO - Epoch 40, Step 137119: Loss=5.6356, Acc=0.282, 
2025-10-05 16:23:35,324 - training.trainer - INFO - Epoch 40, Step 137219: Loss=5.8068, Acc=0.302, 
2025-10-05 16:23:42,662 - training.trainer - INFO - Epoch 40, Step 137319: Loss=6.2273, Acc=0.189, 
2025-10-05 16:23:50,111 - training.trainer - INFO - Epoch 40, Step 137419: Loss=4.7837, Acc=0.350, 
2025-10-05 16:23:57,573 - training.trainer - INFO - Epoch 40, Step 137519: Loss=5.2095, Acc=0.282, 
2025-10-05 16:24:04,932 - training.trainer - INFO - Epoch 40, Step 137619: Loss=5.8928, Acc=0.188, 
2025-10-05 16:24:12,345 - training.trainer - INFO - Epoch 40, Step 137719: Loss=5.5209, Acc=0.257, 
2025-10-05 16:24:19,653 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.6349, Acc=0.300, 
2025-10-05 16:24:27,181 - training.trainer - INFO - Epoch 40, Step 137919: Loss=4.7799, Acc=0.280, 
2025-10-05 16:24:34,777 - training.trainer - INFO - Epoch 40, Step 138019: Loss=4.9548, Acc=0.238, 
2025-10-05 16:24:42,287 - training.trainer - INFO - Epoch 40, Step 138119: Loss=5.1958, Acc=0.268, 
2025-10-05 16:24:49,644 - training.trainer - INFO - Epoch 40, Step 138219: Loss=4.2384, Acc=0.455, 
2025-10-05 16:24:57,045 - training.trainer - INFO - Epoch 40, Step 138319: Loss=5.6271, Acc=0.280, 
2025-10-05 16:25:04,656 - training.trainer - INFO - Epoch 40, Step 138419: Loss=5.7798, Acc=0.194, 
2025-10-05 16:25:12,274 - training.trainer - INFO - Epoch 40, Step 138519: Loss=5.3894, Acc=0.314, 
2025-10-05 16:25:19,747 - training.trainer - INFO - Epoch 40, Step 138619: Loss=5.6069, Acc=0.286, 
2025-10-05 16:25:39,758 - training.trainer - INFO - Epoch 41/100 completed in 264.97s - Train Loss: 5.2803, Train Acc: 0.314, Val Loss: 5.6554, Val Acc: 0.263
2025-10-05 16:25:47,438 - training.trainer - INFO - Epoch 41, Step 138802: Loss=5.3617, Acc=0.216, 
2025-10-05 16:25:54,873 - training.trainer - INFO - Epoch 41, Step 138902: Loss=6.0594, Acc=0.212, 
2025-10-05 16:26:02,386 - training.trainer - INFO - Epoch 41, Step 139002: Loss=6.7375, Acc=0.231, 
2025-10-05 16:26:09,833 - training.trainer - INFO - Epoch 41, Step 139102: Loss=5.7406, Acc=0.234, 
2025-10-05 16:26:17,253 - training.trainer - INFO - Epoch 41, Step 139202: Loss=5.6485, Acc=0.226, 
2025-10-05 16:26:24,615 - training.trainer - INFO - Epoch 41, Step 139302: Loss=4.7679, Acc=0.364, 
2025-10-05 16:26:31,883 - training.trainer - INFO - Epoch 41, Step 139402: Loss=5.7494, Acc=0.200, 
2025-10-05 16:26:39,181 - training.trainer - INFO - Epoch 41, Step 139502: Loss=4.0142, Acc=0.682, 
2025-10-05 16:26:46,483 - training.trainer - INFO - Epoch 41, Step 139602: Loss=5.4410, Acc=0.432, 
2025-10-05 16:26:53,952 - training.trainer - INFO - Epoch 41, Step 139702: Loss=4.0236, Acc=0.444, 
2025-10-05 16:27:01,201 - training.trainer - INFO - Epoch 41, Step 139802: Loss=5.0988, Acc=0.302, 
2025-10-05 16:27:08,543 - training.trainer - INFO - Epoch 41, Step 139902: Loss=4.7416, Acc=0.400, 
2025-10-05 16:27:15,812 - training.trainer - INFO - Epoch 41, Step 140002: Loss=5.8024, Acc=0.208, 
2025-10-05 16:27:23,084 - training.trainer - INFO - Epoch 41, Step 140102: Loss=6.4119, Acc=0.257, 
2025-10-05 16:27:31,020 - training.trainer - INFO - Epoch 41, Step 140202: Loss=5.0195, Acc=0.333, 
2025-10-05 16:27:38,483 - training.trainer - INFO - Epoch 41, Step 140302: Loss=3.5824, Acc=0.500, 
2025-10-05 16:27:45,819 - training.trainer - INFO - Epoch 41, Step 140402: Loss=5.7211, Acc=0.226, 
2025-10-05 16:27:53,099 - training.trainer - INFO - Epoch 41, Step 140502: Loss=5.8707, Acc=0.191, 
2025-10-05 16:28:00,463 - training.trainer - INFO - Epoch 41, Step 140602: Loss=5.1173, Acc=0.395, 
2025-10-05 16:28:07,772 - training.trainer - INFO - Epoch 41, Step 140702: Loss=5.6103, Acc=0.297, 
2025-10-05 16:28:15,033 - training.trainer - INFO - Epoch 41, Step 140802: Loss=5.3033, Acc=0.328, 
2025-10-05 16:28:22,274 - training.trainer - INFO - Epoch 41, Step 140902: Loss=5.0033, Acc=0.300, 
2025-10-05 16:28:29,510 - training.trainer - INFO - Epoch 41, Step 141002: Loss=5.3258, Acc=0.438, 
2025-10-05 16:28:36,920 - training.trainer - INFO - Epoch 41, Step 141102: Loss=4.0535, Acc=0.389, 
2025-10-05 16:28:44,148 - training.trainer - INFO - Epoch 41, Step 141202: Loss=5.6213, Acc=0.234, 
2025-10-05 16:28:51,488 - training.trainer - INFO - Epoch 41, Step 141302: Loss=5.1399, Acc=0.273, 
2025-10-05 16:28:58,766 - training.trainer - INFO - Epoch 41, Step 141402: Loss=4.9138, Acc=0.343, 
2025-10-05 16:29:06,428 - training.trainer - INFO - Epoch 41, Step 141502: Loss=4.1532, Acc=0.545, 
2025-10-05 16:29:13,826 - training.trainer - INFO - Epoch 41, Step 141602: Loss=5.8208, Acc=0.234, 
2025-10-05 16:29:21,187 - training.trainer - INFO - Epoch 41, Step 141702: Loss=4.3832, Acc=0.385, 
2025-10-05 16:29:28,692 - training.trainer - INFO - Epoch 41, Step 141802: Loss=5.4235, Acc=0.327, 
2025-10-05 16:29:36,146 - training.trainer - INFO - Epoch 41, Step 141902: Loss=4.0353, Acc=0.429, 
2025-10-05 16:29:43,470 - training.trainer - INFO - Epoch 41, Step 142002: Loss=5.4828, Acc=0.300, 
2025-10-05 16:30:03,261 - training.trainer - INFO - Epoch 42/100 completed in 263.50s - Train Loss: 5.2609, Train Acc: 0.316, Val Loss: 5.6697, Val Acc: 0.259
2025-10-05 16:30:10,231 - training.trainer - INFO - Epoch 42, Step 142185: Loss=5.6196, Acc=0.324, 
2025-10-05 16:30:16,670 - training.trainer - INFO - Epoch 42, Step 142285: Loss=5.5072, Acc=0.245, 
2025-10-05 16:30:23,370 - training.trainer - INFO - Epoch 42, Step 142385: Loss=5.6611, Acc=0.281, 
2025-10-05 16:30:31,035 - training.trainer - INFO - Epoch 42, Step 142485: Loss=5.4631, Acc=0.167, 
2025-10-05 16:30:38,595 - training.trainer - INFO - Epoch 42, Step 142585: Loss=5.6976, Acc=0.250, 
2025-10-05 16:30:46,354 - training.trainer - INFO - Epoch 42, Step 142685: Loss=5.2615, Acc=0.385, 
2025-10-05 16:30:53,796 - training.trainer - INFO - Epoch 42, Step 142785: Loss=5.8045, Acc=0.174, 
2025-10-05 16:31:01,233 - training.trainer - INFO - Epoch 42, Step 142885: Loss=4.4487, Acc=0.381, 
2025-10-05 16:31:08,764 - training.trainer - INFO - Epoch 42, Step 142985: Loss=5.6311, Acc=0.238, 
2025-10-05 16:31:16,287 - training.trainer - INFO - Epoch 42, Step 143085: Loss=5.4930, Acc=0.214, 
2025-10-05 16:31:23,741 - training.trainer - INFO - Epoch 42, Step 143185: Loss=5.7226, Acc=0.243, 
2025-10-05 16:31:31,311 - training.trainer - INFO - Epoch 42, Step 143285: Loss=5.7014, Acc=0.267, 
2025-10-05 16:31:38,825 - training.trainer - INFO - Epoch 42, Step 143385: Loss=5.6014, Acc=0.239, 
2025-10-05 16:31:46,177 - training.trainer - INFO - Epoch 42, Step 143485: Loss=5.0690, Acc=0.300, 
2025-10-05 16:31:53,524 - training.trainer - INFO - Epoch 42, Step 143585: Loss=4.9613, Acc=0.258, 
2025-10-05 16:32:00,884 - training.trainer - INFO - Epoch 42, Step 143685: Loss=4.3549, Acc=0.417, 
2025-10-05 16:32:08,311 - training.trainer - INFO - Epoch 42, Step 143785: Loss=4.7081, Acc=0.323, 
2025-10-05 16:32:15,720 - training.trainer - INFO - Epoch 42, Step 143885: Loss=4.5004, Acc=0.333, 
2025-10-05 16:32:23,202 - training.trainer - INFO - Epoch 42, Step 143985: Loss=6.1209, Acc=0.239, 
2025-10-05 16:32:30,760 - training.trainer - INFO - Epoch 42, Step 144085: Loss=5.4496, Acc=0.200, 
2025-10-05 16:32:38,361 - training.trainer - INFO - Epoch 42, Step 144185: Loss=4.2834, Acc=0.346, 
2025-10-05 16:32:45,889 - training.trainer - INFO - Epoch 42, Step 144285: Loss=4.7329, Acc=0.259, 
2025-10-05 16:32:53,479 - training.trainer - INFO - Epoch 42, Step 144385: Loss=4.7554, Acc=0.500, 
2025-10-05 16:33:01,204 - training.trainer - INFO - Epoch 42, Step 144485: Loss=5.1319, Acc=0.364, 
2025-10-05 16:33:08,793 - training.trainer - INFO - Epoch 42, Step 144585: Loss=5.4397, Acc=0.291, 
2025-10-05 16:33:16,371 - training.trainer - INFO - Epoch 42, Step 144685: Loss=4.4836, Acc=0.471, 
2025-10-05 16:33:23,847 - training.trainer - INFO - Epoch 42, Step 144785: Loss=4.0969, Acc=0.419, 
2025-10-05 16:33:31,669 - training.trainer - INFO - Epoch 42, Step 144885: Loss=4.5499, Acc=0.350, 
2025-10-05 16:33:39,151 - training.trainer - INFO - Epoch 42, Step 144985: Loss=5.1787, Acc=0.296, 
2025-10-05 16:33:46,572 - training.trainer - INFO - Epoch 42, Step 145085: Loss=5.8085, Acc=0.227, 
2025-10-05 16:33:53,910 - training.trainer - INFO - Epoch 42, Step 145185: Loss=5.7990, Acc=0.314, 
2025-10-05 16:34:01,306 - training.trainer - INFO - Epoch 42, Step 145285: Loss=5.6148, Acc=0.286, 
2025-10-05 16:34:08,659 - training.trainer - INFO - Epoch 42, Step 145385: Loss=6.0641, Acc=0.242, 
2025-10-05 16:34:28,091 - training.trainer - INFO - Epoch 43/100 completed in 264.83s - Train Loss: 5.2541, Train Acc: 0.318, Val Loss: 5.6769, Val Acc: 0.261
2025-10-05 16:34:36,091 - training.trainer - INFO - Epoch 43, Step 145568: Loss=5.7440, Acc=0.279, 
2025-10-05 16:34:43,624 - training.trainer - INFO - Epoch 43, Step 145668: Loss=5.6204, Acc=0.231, 
2025-10-05 16:34:51,183 - training.trainer - INFO - Epoch 43, Step 145768: Loss=6.1815, Acc=0.167, 
2025-10-05 16:34:58,802 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.2830, Acc=0.286, 
2025-10-05 16:35:06,533 - training.trainer - INFO - Epoch 43, Step 145968: Loss=5.2624, Acc=0.389, 
2025-10-05 16:35:14,071 - training.trainer - INFO - Epoch 43, Step 146068: Loss=5.1469, Acc=0.273, 
2025-10-05 16:35:21,579 - training.trainer - INFO - Epoch 43, Step 146168: Loss=6.2646, Acc=0.200, 
2025-10-05 16:35:29,141 - training.trainer - INFO - Epoch 43, Step 146268: Loss=5.3710, Acc=0.221, 
2025-10-05 16:35:36,850 - training.trainer - INFO - Epoch 43, Step 146368: Loss=5.3131, Acc=0.325, 
2025-10-05 16:35:44,268 - training.trainer - INFO - Epoch 43, Step 146468: Loss=5.9998, Acc=0.200, 
2025-10-05 16:35:51,682 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.0230, Acc=0.333, 
2025-10-05 16:35:59,043 - training.trainer - INFO - Epoch 43, Step 146668: Loss=4.1778, Acc=0.458, 
2025-10-05 16:36:06,365 - training.trainer - INFO - Epoch 43, Step 146768: Loss=5.1677, Acc=0.311, 
2025-10-05 16:36:13,856 - training.trainer - INFO - Epoch 43, Step 146868: Loss=6.3809, Acc=0.215, 
2025-10-05 16:36:21,172 - training.trainer - INFO - Epoch 43, Step 146968: Loss=6.2684, Acc=0.194, 
2025-10-05 16:36:28,493 - training.trainer - INFO - Epoch 43, Step 147068: Loss=5.0367, Acc=0.242, 
2025-10-05 16:36:35,962 - training.trainer - INFO - Epoch 43, Step 147168: Loss=4.9734, Acc=0.324, 
2025-10-05 16:36:43,562 - training.trainer - INFO - Epoch 43, Step 147268: Loss=5.2304, Acc=0.412, 
2025-10-05 16:36:50,974 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.1980, Acc=0.235, 
2025-10-05 16:36:58,255 - training.trainer - INFO - Epoch 43, Step 147468: Loss=6.2470, Acc=0.237, 
2025-10-05 16:37:05,628 - training.trainer - INFO - Epoch 43, Step 147568: Loss=5.6443, Acc=0.278, 
2025-10-05 16:37:13,025 - training.trainer - INFO - Epoch 43, Step 147668: Loss=5.9160, Acc=0.234, 
2025-10-05 16:37:20,667 - training.trainer - INFO - Epoch 43, Step 147768: Loss=5.2197, Acc=0.289, 
2025-10-05 16:37:28,109 - training.trainer - INFO - Epoch 43, Step 147868: Loss=4.7638, Acc=0.364, 
2025-10-05 16:37:35,380 - training.trainer - INFO - Epoch 43, Step 147968: Loss=5.9381, Acc=0.244, 
2025-10-05 16:37:42,891 - training.trainer - INFO - Epoch 43, Step 148068: Loss=5.7761, Acc=0.233, 
2025-10-05 16:37:50,334 - training.trainer - INFO - Epoch 43, Step 148168: Loss=5.6259, Acc=0.208, 
2025-10-05 16:37:58,022 - training.trainer - INFO - Epoch 43, Step 148268: Loss=4.2592, Acc=0.562, 
2025-10-05 16:38:05,387 - training.trainer - INFO - Epoch 43, Step 148368: Loss=3.9058, Acc=0.412, 
2025-10-05 16:38:12,717 - training.trainer - INFO - Epoch 43, Step 148468: Loss=5.3841, Acc=0.255, 
2025-10-05 16:38:20,223 - training.trainer - INFO - Epoch 43, Step 148568: Loss=5.7045, Acc=0.350, 
2025-10-05 16:38:28,060 - training.trainer - INFO - Epoch 43, Step 148668: Loss=6.6707, Acc=0.200, 
2025-10-05 16:38:35,505 - training.trainer - INFO - Epoch 43, Step 148768: Loss=6.0743, Acc=0.135, 
2025-10-05 16:38:54,862 - training.trainer - INFO - Epoch 44/100 completed in 266.77s - Train Loss: 5.2393, Train Acc: 0.321, Val Loss: 5.6746, Val Acc: 0.264
2025-10-05 16:39:01,777 - training.trainer - INFO - Epoch 44, Step 148951: Loss=4.5164, Acc=0.474, 
2025-10-05 16:39:08,946 - training.trainer - INFO - Epoch 44, Step 149051: Loss=5.1741, Acc=0.260, 
2025-10-05 16:39:16,478 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.3534, Acc=0.271, 
2025-10-05 16:39:24,069 - training.trainer - INFO - Epoch 44, Step 149251: Loss=4.6025, Acc=0.435, 
2025-10-05 16:39:31,635 - training.trainer - INFO - Epoch 44, Step 149351: Loss=5.6193, Acc=0.268, 
2025-10-05 16:39:39,030 - training.trainer - INFO - Epoch 44, Step 149451: Loss=5.8508, Acc=0.368, 
2025-10-05 16:39:46,421 - training.trainer - INFO - Epoch 44, Step 149551: Loss=5.2845, Acc=0.244, 
2025-10-05 16:39:53,971 - training.trainer - INFO - Epoch 44, Step 149651: Loss=5.0176, Acc=0.270, 
2025-10-05 16:40:01,628 - training.trainer - INFO - Epoch 44, Step 149751: Loss=5.2998, Acc=0.353, 
2025-10-05 16:40:09,446 - training.trainer - INFO - Epoch 44, Step 149851: Loss=5.5818, Acc=0.211, 
2025-10-05 16:40:16,946 - training.trainer - INFO - Epoch 44, Step 149951: Loss=4.5462, Acc=0.321, 
2025-10-05 16:40:24,509 - training.trainer - INFO - Epoch 44, Step 150051: Loss=5.0296, Acc=0.364, 
2025-10-05 16:40:32,071 - training.trainer - INFO - Epoch 44, Step 150151: Loss=5.8273, Acc=0.267, 
2025-10-05 16:40:39,524 - training.trainer - INFO - Epoch 44, Step 150251: Loss=5.3040, Acc=0.262, 
2025-10-05 16:40:46,956 - training.trainer - INFO - Epoch 44, Step 150351: Loss=5.8841, Acc=0.324, 
2025-10-05 16:40:54,464 - training.trainer - INFO - Epoch 44, Step 150451: Loss=4.0464, Acc=0.611, 
2025-10-05 16:41:01,975 - training.trainer - INFO - Epoch 44, Step 150551: Loss=5.0273, Acc=0.352, 
2025-10-05 16:41:09,713 - training.trainer - INFO - Epoch 44, Step 150651: Loss=5.6055, Acc=0.280, 
2025-10-05 16:41:17,179 - training.trainer - INFO - Epoch 44, Step 150751: Loss=5.2552, Acc=0.370, 
2025-10-05 16:41:24,624 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.5049, Acc=0.308, 
2025-10-05 16:41:32,107 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.6556, Acc=0.276, 
2025-10-05 16:41:39,641 - training.trainer - INFO - Epoch 44, Step 151051: Loss=5.9330, Acc=0.268, 
2025-10-05 16:41:46,996 - training.trainer - INFO - Epoch 44, Step 151151: Loss=5.3633, Acc=0.321, 
2025-10-05 16:41:54,412 - training.trainer - INFO - Epoch 44, Step 151251: Loss=4.7162, Acc=0.455, 
2025-10-05 16:42:01,832 - training.trainer - INFO - Epoch 44, Step 151351: Loss=3.7493, Acc=0.475, 
2025-10-05 16:42:09,362 - training.trainer - INFO - Epoch 44, Step 151451: Loss=5.4348, Acc=0.250, 
2025-10-05 16:42:16,886 - training.trainer - INFO - Epoch 44, Step 151551: Loss=4.5907, Acc=0.367, 
2025-10-05 16:42:24,349 - training.trainer - INFO - Epoch 44, Step 151651: Loss=5.9970, Acc=0.217, 
2025-10-05 16:42:32,013 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.5184, Acc=0.261, 
2025-10-05 16:42:39,386 - training.trainer - INFO - Epoch 44, Step 151851: Loss=5.2310, Acc=0.333, 
2025-10-05 16:42:47,056 - training.trainer - INFO - Epoch 44, Step 151951: Loss=5.1435, Acc=0.312, 
2025-10-05 16:42:54,487 - training.trainer - INFO - Epoch 44, Step 152051: Loss=4.9764, Acc=0.222, 
2025-10-05 16:43:02,065 - training.trainer - INFO - Epoch 44, Step 152151: Loss=5.2423, Acc=0.306, 
2025-10-05 16:43:21,128 - training.trainer - INFO - Epoch 45/100 completed in 266.27s - Train Loss: 5.2207, Train Acc: 0.323, Val Loss: 5.6707, Val Acc: 0.265
2025-10-05 16:43:21,493 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-10-05 16:43:28,616 - training.trainer - INFO - Epoch 45, Step 152334: Loss=5.6966, Acc=0.188, 
2025-10-05 16:43:35,062 - training.trainer - INFO - Epoch 45, Step 152434: Loss=4.6803, Acc=0.382, 
2025-10-05 16:43:41,540 - training.trainer - INFO - Epoch 45, Step 152534: Loss=6.1323, Acc=0.286, 
2025-10-05 16:43:48,005 - training.trainer - INFO - Epoch 45, Step 152634: Loss=5.4839, Acc=0.250, 
2025-10-05 16:43:54,482 - training.trainer - INFO - Epoch 45, Step 152734: Loss=5.9957, Acc=0.208, 
2025-10-05 16:44:01,021 - training.trainer - INFO - Epoch 45, Step 152834: Loss=5.9235, Acc=0.167, 
2025-10-05 16:44:07,481 - training.trainer - INFO - Epoch 45, Step 152934: Loss=5.2879, Acc=0.452, 
2025-10-05 16:44:13,855 - training.trainer - INFO - Epoch 45, Step 153034: Loss=5.4564, Acc=0.312, 
2025-10-05 16:44:20,255 - training.trainer - INFO - Epoch 45, Step 153134: Loss=2.7800, Acc=0.760, 
2025-10-05 16:44:26,666 - training.trainer - INFO - Epoch 45, Step 153234: Loss=5.6446, Acc=0.259, 
2025-10-05 16:44:32,986 - training.trainer - INFO - Epoch 45, Step 153334: Loss=6.2665, Acc=0.304, 
2025-10-05 16:44:39,371 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.0943, Acc=0.333, 
2025-10-05 16:44:45,753 - training.trainer - INFO - Epoch 45, Step 153534: Loss=4.9403, Acc=0.325, 
2025-10-05 16:44:52,471 - training.trainer - INFO - Epoch 45, Step 153634: Loss=5.0197, Acc=0.321, 
2025-10-05 16:44:59,522 - training.trainer - INFO - Epoch 45, Step 153734: Loss=3.7626, Acc=0.575, 
2025-10-05 16:45:06,907 - training.trainer - INFO - Epoch 45, Step 153834: Loss=5.7488, Acc=0.242, 
2025-10-05 16:45:14,466 - training.trainer - INFO - Epoch 45, Step 153934: Loss=5.8644, Acc=0.310, 
2025-10-05 16:45:21,851 - training.trainer - INFO - Epoch 45, Step 154034: Loss=5.3689, Acc=0.245, 
2025-10-05 16:45:29,305 - training.trainer - INFO - Epoch 45, Step 154134: Loss=5.9888, Acc=0.255, 
2025-10-05 16:45:36,676 - training.trainer - INFO - Epoch 45, Step 154234: Loss=4.3043, Acc=0.435, 
2025-10-05 16:45:44,111 - training.trainer - INFO - Epoch 45, Step 154334: Loss=5.8929, Acc=0.229, 
2025-10-05 16:45:51,472 - training.trainer - INFO - Epoch 45, Step 154434: Loss=5.6862, Acc=0.214, 
2025-10-05 16:45:58,888 - training.trainer - INFO - Epoch 45, Step 154534: Loss=4.8213, Acc=0.364, 
2025-10-05 16:46:06,330 - training.trainer - INFO - Epoch 45, Step 154634: Loss=4.7258, Acc=0.367, 
2025-10-05 16:46:13,805 - training.trainer - INFO - Epoch 45, Step 154734: Loss=3.9706, Acc=0.500, 
2025-10-05 16:46:21,503 - training.trainer - INFO - Epoch 45, Step 154834: Loss=5.5560, Acc=0.294, 
2025-10-05 16:46:29,084 - training.trainer - INFO - Epoch 45, Step 154934: Loss=4.8182, Acc=0.286, 
2025-10-05 16:46:36,673 - training.trainer - INFO - Epoch 45, Step 155034: Loss=5.5449, Acc=0.325, 
2025-10-05 16:46:44,315 - training.trainer - INFO - Epoch 45, Step 155134: Loss=5.7815, Acc=0.226, 
2025-10-05 16:46:51,747 - training.trainer - INFO - Epoch 45, Step 155234: Loss=5.5193, Acc=0.333, 
2025-10-05 16:46:59,270 - training.trainer - INFO - Epoch 45, Step 155334: Loss=5.7889, Acc=0.182, 
2025-10-05 16:47:06,798 - training.trainer - INFO - Epoch 45, Step 155434: Loss=5.4647, Acc=0.291, 
2025-10-05 16:47:14,272 - training.trainer - INFO - Epoch 45, Step 155534: Loss=5.1405, Acc=0.395, 
2025-10-05 16:47:33,546 - training.trainer - INFO - Epoch 46/100 completed in 252.05s - Train Loss: 5.2069, Train Acc: 0.327, Val Loss: 5.6713, Val Acc: 0.261
2025-10-05 16:47:40,365 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.4864, Acc=0.233, 
2025-10-05 16:47:46,763 - training.trainer - INFO - Epoch 46, Step 155817: Loss=4.6691, Acc=0.310, 
2025-10-05 16:47:54,336 - training.trainer - INFO - Epoch 46, Step 155917: Loss=5.7281, Acc=0.271, 
2025-10-05 16:48:01,870 - training.trainer - INFO - Epoch 46, Step 156017: Loss=5.1919, Acc=0.303, 
2025-10-05 16:48:09,293 - training.trainer - INFO - Epoch 46, Step 156117: Loss=5.4823, Acc=0.231, 
2025-10-05 16:48:16,983 - training.trainer - INFO - Epoch 46, Step 156217: Loss=5.4816, Acc=0.268, 
2025-10-05 16:48:24,552 - training.trainer - INFO - Epoch 46, Step 156317: Loss=3.8110, Acc=0.514, 
2025-10-05 16:48:32,074 - training.trainer - INFO - Epoch 46, Step 156417: Loss=5.3749, Acc=0.333, 
2025-10-05 16:48:39,522 - training.trainer - INFO - Epoch 46, Step 156517: Loss=5.7650, Acc=0.200, 
2025-10-05 16:48:47,077 - training.trainer - INFO - Epoch 46, Step 156617: Loss=4.6472, Acc=0.321, 
2025-10-05 16:48:54,563 - training.trainer - INFO - Epoch 46, Step 156717: Loss=3.7559, Acc=0.636, 
2025-10-05 16:49:02,079 - training.trainer - INFO - Epoch 46, Step 156817: Loss=5.3923, Acc=0.400, 
2025-10-05 16:49:09,692 - training.trainer - INFO - Epoch 46, Step 156917: Loss=5.5373, Acc=0.276, 
2025-10-05 16:49:17,209 - training.trainer - INFO - Epoch 46, Step 157017: Loss=5.0166, Acc=0.310, 
2025-10-05 16:49:24,606 - training.trainer - INFO - Epoch 46, Step 157117: Loss=5.3858, Acc=0.250, 
2025-10-05 16:49:31,989 - training.trainer - INFO - Epoch 46, Step 157217: Loss=4.2526, Acc=0.483, 
2025-10-05 16:49:39,548 - training.trainer - INFO - Epoch 46, Step 157317: Loss=4.9210, Acc=0.308, 
2025-10-05 16:49:46,943 - training.trainer - INFO - Epoch 46, Step 157417: Loss=4.7279, Acc=0.452, 
2025-10-05 16:49:54,506 - training.trainer - INFO - Epoch 46, Step 157517: Loss=5.5933, Acc=0.326, 
2025-10-05 16:50:02,087 - training.trainer - INFO - Epoch 46, Step 157617: Loss=5.0148, Acc=0.325, 
2025-10-05 16:50:09,692 - training.trainer - INFO - Epoch 46, Step 157717: Loss=6.1196, Acc=0.182, 
2025-10-05 16:50:17,185 - training.trainer - INFO - Epoch 46, Step 157817: Loss=5.8353, Acc=0.173, 
2025-10-05 16:50:24,602 - training.trainer - INFO - Epoch 46, Step 157917: Loss=5.8036, Acc=0.400, 
2025-10-05 16:50:32,108 - training.trainer - INFO - Epoch 46, Step 158017: Loss=5.2288, Acc=0.400, 
2025-10-05 16:50:39,551 - training.trainer - INFO - Epoch 46, Step 158117: Loss=5.3732, Acc=0.333, 
2025-10-05 16:50:47,059 - training.trainer - INFO - Epoch 46, Step 158217: Loss=5.2124, Acc=0.234, 
2025-10-05 16:50:54,587 - training.trainer - INFO - Epoch 46, Step 158317: Loss=3.1100, Acc=0.667, 
2025-10-05 16:51:02,075 - training.trainer - INFO - Epoch 46, Step 158417: Loss=5.0239, Acc=0.323, 
2025-10-05 16:51:09,621 - training.trainer - INFO - Epoch 46, Step 158517: Loss=5.7297, Acc=0.176, 
2025-10-05 16:51:17,098 - training.trainer - INFO - Epoch 46, Step 158617: Loss=5.7013, Acc=0.378, 
2025-10-05 16:51:24,559 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.9637, Acc=0.235, 
2025-10-05 16:51:32,135 - training.trainer - INFO - Epoch 46, Step 158817: Loss=5.3968, Acc=0.343, 
2025-10-05 16:51:39,704 - training.trainer - INFO - Epoch 46, Step 158917: Loss=5.8369, Acc=0.176, 
2025-10-05 16:51:59,232 - training.trainer - INFO - Epoch 47/100 completed in 265.69s - Train Loss: 5.1927, Train Acc: 0.328, Val Loss: 5.6852, Val Acc: 0.262
2025-10-05 16:52:07,404 - training.trainer - INFO - Epoch 47, Step 159100: Loss=5.5284, Acc=0.293, 
2025-10-05 16:52:14,893 - training.trainer - INFO - Epoch 47, Step 159200: Loss=3.6000, Acc=0.567, 
2025-10-05 16:52:22,356 - training.trainer - INFO - Epoch 47, Step 159300: Loss=5.3682, Acc=0.241, 
2025-10-05 16:52:30,024 - training.trainer - INFO - Epoch 47, Step 159400: Loss=5.2118, Acc=0.308, 
2025-10-05 16:52:37,684 - training.trainer - INFO - Epoch 47, Step 159500: Loss=4.7223, Acc=0.316, 
2025-10-05 16:52:45,251 - training.trainer - INFO - Epoch 47, Step 159600: Loss=4.6845, Acc=0.379, 
2025-10-05 16:52:52,702 - training.trainer - INFO - Epoch 47, Step 159700: Loss=5.0686, Acc=0.312, 
2025-10-05 16:53:00,136 - training.trainer - INFO - Epoch 47, Step 159800: Loss=5.6020, Acc=0.174, 
2025-10-05 16:53:07,636 - training.trainer - INFO - Epoch 47, Step 159900: Loss=5.3096, Acc=0.323, 
2025-10-05 16:53:15,335 - training.trainer - INFO - Epoch 47, Step 160000: Loss=5.0493, Acc=0.321, 
2025-10-05 16:53:22,795 - training.trainer - INFO - Epoch 47, Step 160100: Loss=4.5365, Acc=0.318, 
2025-10-05 16:53:30,710 - training.trainer - INFO - Epoch 47, Step 160200: Loss=5.3790, Acc=0.244, 
2025-10-05 16:53:38,460 - training.trainer - INFO - Epoch 47, Step 160300: Loss=3.4568, Acc=0.605, 
2025-10-05 16:53:45,953 - training.trainer - INFO - Epoch 47, Step 160400: Loss=4.5675, Acc=0.379, 
2025-10-05 16:53:53,491 - training.trainer - INFO - Epoch 47, Step 160500: Loss=3.4002, Acc=0.682, 
2025-10-05 16:54:00,906 - training.trainer - INFO - Epoch 47, Step 160600: Loss=5.9282, Acc=0.288, 
2025-10-05 16:54:08,510 - training.trainer - INFO - Epoch 47, Step 160700: Loss=4.7365, Acc=0.393, 
2025-10-05 16:54:15,905 - training.trainer - INFO - Epoch 47, Step 160800: Loss=4.8904, Acc=0.345, 
2025-10-05 16:54:23,554 - training.trainer - INFO - Epoch 47, Step 160900: Loss=5.8550, Acc=0.300, 
2025-10-05 16:54:30,978 - training.trainer - INFO - Epoch 47, Step 161000: Loss=5.6644, Acc=0.230, 
2025-10-05 16:54:38,536 - training.trainer - INFO - Epoch 47, Step 161100: Loss=4.7042, Acc=0.425, 
2025-10-05 16:54:46,009 - training.trainer - INFO - Epoch 47, Step 161200: Loss=5.7014, Acc=0.310, 
2025-10-05 16:54:53,483 - training.trainer - INFO - Epoch 47, Step 161300: Loss=6.0072, Acc=0.241, 
2025-10-05 16:55:01,163 - training.trainer - INFO - Epoch 47, Step 161400: Loss=5.7162, Acc=0.295, 
2025-10-05 16:55:09,138 - training.trainer - INFO - Epoch 47, Step 161500: Loss=5.0527, Acc=0.351, 
2025-10-05 16:55:16,837 - training.trainer - INFO - Epoch 47, Step 161600: Loss=4.6662, Acc=0.407, 
2025-10-05 16:55:24,323 - training.trainer - INFO - Epoch 47, Step 161700: Loss=5.4270, Acc=0.281, 
2025-10-05 16:55:31,766 - training.trainer - INFO - Epoch 47, Step 161800: Loss=5.7771, Acc=0.289, 
2025-10-05 16:55:39,267 - training.trainer - INFO - Epoch 47, Step 161900: Loss=5.8816, Acc=0.255, 
2025-10-05 16:55:46,714 - training.trainer - INFO - Epoch 47, Step 162000: Loss=4.9808, Acc=0.329, 
2025-10-05 16:55:54,235 - training.trainer - INFO - Epoch 47, Step 162100: Loss=5.0577, Acc=0.333, 
2025-10-05 16:56:01,708 - training.trainer - INFO - Epoch 47, Step 162200: Loss=5.6189, Acc=0.333, 
2025-10-05 16:56:09,121 - training.trainer - INFO - Epoch 47, Step 162300: Loss=5.3011, Acc=0.357, 
2025-10-05 16:56:28,374 - training.trainer - INFO - Epoch 48/100 completed in 269.14s - Train Loss: 5.1769, Train Acc: 0.331, Val Loss: 5.6955, Val Acc: 0.260
2025-10-05 16:56:36,498 - training.trainer - INFO - Epoch 48, Step 162483: Loss=5.7039, Acc=0.260, 
2025-10-05 16:56:44,048 - training.trainer - INFO - Epoch 48, Step 162583: Loss=4.6016, Acc=0.375, 
2025-10-05 16:56:51,537 - training.trainer - INFO - Epoch 48, Step 162683: Loss=3.5174, Acc=0.596, 
2025-10-05 16:56:59,320 - training.trainer - INFO - Epoch 48, Step 162783: Loss=5.0383, Acc=0.467, 
2025-10-05 16:57:06,906 - training.trainer - INFO - Epoch 48, Step 162883: Loss=4.9018, Acc=0.364, 
2025-10-05 16:57:14,374 - training.trainer - INFO - Epoch 48, Step 162983: Loss=5.7541, Acc=0.219, 
2025-10-05 16:57:21,860 - training.trainer - INFO - Epoch 48, Step 163083: Loss=6.1931, Acc=0.250, 
2025-10-05 16:57:29,320 - training.trainer - INFO - Epoch 48, Step 163183: Loss=5.7209, Acc=0.277, 
2025-10-05 16:57:36,764 - training.trainer - INFO - Epoch 48, Step 163283: Loss=5.6958, Acc=0.279, 
2025-10-05 16:57:44,193 - training.trainer - INFO - Epoch 48, Step 163383: Loss=5.5769, Acc=0.292, 
2025-10-05 16:57:51,772 - training.trainer - INFO - Epoch 48, Step 163483: Loss=4.9508, Acc=0.349, 
2025-10-05 16:57:59,262 - training.trainer - INFO - Epoch 48, Step 163583: Loss=5.3279, Acc=0.333, 
2025-10-05 16:58:06,773 - training.trainer - INFO - Epoch 48, Step 163683: Loss=5.4917, Acc=0.256, 
2025-10-05 16:58:14,248 - training.trainer - INFO - Epoch 48, Step 163783: Loss=5.6337, Acc=0.245, 
2025-10-05 16:58:21,669 - training.trainer - INFO - Epoch 48, Step 163883: Loss=5.9516, Acc=0.240, 
2025-10-05 16:58:29,036 - training.trainer - INFO - Epoch 48, Step 163983: Loss=4.7629, Acc=0.400, 
2025-10-05 16:58:36,519 - training.trainer - INFO - Epoch 48, Step 164083: Loss=5.7783, Acc=0.235, 
2025-10-05 16:58:43,974 - training.trainer - INFO - Epoch 48, Step 164183: Loss=5.4063, Acc=0.286, 
2025-10-05 16:58:51,505 - training.trainer - INFO - Epoch 48, Step 164283: Loss=5.4108, Acc=0.290, 
2025-10-05 16:58:59,209 - training.trainer - INFO - Epoch 48, Step 164383: Loss=5.8024, Acc=0.317, 
2025-10-05 16:59:06,700 - training.trainer - INFO - Epoch 48, Step 164483: Loss=5.7917, Acc=0.314, 
2025-10-05 16:59:14,262 - training.trainer - INFO - Epoch 48, Step 164583: Loss=4.5518, Acc=0.412, 
2025-10-05 16:59:21,841 - training.trainer - INFO - Epoch 48, Step 164683: Loss=6.0260, Acc=0.286, 
2025-10-05 16:59:29,590 - training.trainer - INFO - Epoch 48, Step 164783: Loss=4.1514, Acc=0.556, 
2025-10-05 16:59:37,281 - training.trainer - INFO - Epoch 48, Step 164883: Loss=4.5710, Acc=0.375, 
2025-10-05 16:59:44,851 - training.trainer - INFO - Epoch 48, Step 164983: Loss=5.5091, Acc=0.159, 
2025-10-05 16:59:52,425 - training.trainer - INFO - Epoch 48, Step 165083: Loss=4.4633, Acc=0.368, 
2025-10-05 16:59:59,989 - training.trainer - INFO - Epoch 48, Step 165183: Loss=5.8223, Acc=0.182, 
2025-10-05 17:00:07,666 - training.trainer - INFO - Epoch 48, Step 165283: Loss=6.3756, Acc=0.206, 
2025-10-05 17:00:15,122 - training.trainer - INFO - Epoch 48, Step 165383: Loss=6.0178, Acc=0.224, 
2025-10-05 17:00:22,963 - training.trainer - INFO - Epoch 48, Step 165483: Loss=4.9704, Acc=0.281, 
2025-10-05 17:00:30,369 - training.trainer - INFO - Epoch 48, Step 165583: Loss=5.3468, Acc=0.367, 
2025-10-05 17:00:37,902 - training.trainer - INFO - Epoch 48, Step 165683: Loss=4.4486, Acc=0.435, 
2025-10-05 17:00:58,036 - training.trainer - INFO - Epoch 49/100 completed in 269.66s - Train Loss: 5.1706, Train Acc: 0.334, Val Loss: 5.7050, Val Acc: 0.262
2025-10-05 17:01:05,916 - training.trainer - INFO - Epoch 49, Step 165866: Loss=4.1934, Acc=0.526, 
2025-10-05 17:01:13,303 - training.trainer - INFO - Epoch 49, Step 165966: Loss=4.9380, Acc=0.370, 
2025-10-05 17:01:20,789 - training.trainer - INFO - Epoch 49, Step 166066: Loss=5.6903, Acc=0.275, 
2025-10-05 17:01:28,141 - training.trainer - INFO - Epoch 49, Step 166166: Loss=4.4883, Acc=0.409, 
2025-10-05 17:01:35,508 - training.trainer - INFO - Epoch 49, Step 166266: Loss=4.2063, Acc=0.353, 
2025-10-05 17:01:42,865 - training.trainer - INFO - Epoch 49, Step 166366: Loss=5.4089, Acc=0.312, 
2025-10-05 17:01:50,694 - training.trainer - INFO - Epoch 49, Step 166466: Loss=4.2485, Acc=0.464, 
2025-10-05 17:01:58,273 - training.trainer - INFO - Epoch 49, Step 166566: Loss=5.4399, Acc=0.250, 
2025-10-05 17:02:06,016 - training.trainer - INFO - Epoch 49, Step 166666: Loss=5.9613, Acc=0.264, 
2025-10-05 17:02:13,796 - training.trainer - INFO - Epoch 49, Step 166766: Loss=5.4520, Acc=0.339, 
2025-10-05 17:02:21,721 - training.trainer - INFO - Epoch 49, Step 166866: Loss=5.6548, Acc=0.257, 
2025-10-05 17:02:29,247 - training.trainer - INFO - Epoch 49, Step 166966: Loss=4.4346, Acc=0.562, 
2025-10-05 17:02:36,654 - training.trainer - INFO - Epoch 49, Step 167066: Loss=5.5093, Acc=0.271, 
2025-10-05 17:02:44,187 - training.trainer - INFO - Epoch 49, Step 167166: Loss=5.3315, Acc=0.313, 
2025-10-05 17:02:51,779 - training.trainer - INFO - Epoch 49, Step 167266: Loss=5.9827, Acc=0.296, 
2025-10-05 17:02:59,403 - training.trainer - INFO - Epoch 49, Step 167366: Loss=5.5392, Acc=0.250, 
2025-10-05 17:03:06,834 - training.trainer - INFO - Epoch 49, Step 167466: Loss=5.4857, Acc=0.234, 
2025-10-05 17:03:14,191 - training.trainer - INFO - Epoch 49, Step 167566: Loss=4.6241, Acc=0.355, 
2025-10-05 17:03:21,736 - training.trainer - INFO - Epoch 49, Step 167666: Loss=5.4723, Acc=0.255, 
2025-10-05 17:03:29,408 - training.trainer - INFO - Epoch 49, Step 167766: Loss=6.4669, Acc=0.150, 
2025-10-05 17:03:37,042 - training.trainer - INFO - Epoch 49, Step 167866: Loss=5.5424, Acc=0.186, 
2025-10-05 17:03:44,609 - training.trainer - INFO - Epoch 49, Step 167966: Loss=4.8413, Acc=0.269, 
2025-10-05 17:03:52,146 - training.trainer - INFO - Epoch 49, Step 168066: Loss=5.8400, Acc=0.224, 
2025-10-05 17:03:59,743 - training.trainer - INFO - Epoch 49, Step 168166: Loss=6.2005, Acc=0.175, 
2025-10-05 17:04:07,255 - training.trainer - INFO - Epoch 49, Step 168266: Loss=5.8367, Acc=0.190, 
2025-10-05 17:04:14,924 - training.trainer - INFO - Epoch 49, Step 168366: Loss=5.5034, Acc=0.264, 
2025-10-05 17:04:22,548 - training.trainer - INFO - Epoch 49, Step 168466: Loss=5.3027, Acc=0.234, 
2025-10-05 17:04:30,062 - training.trainer - INFO - Epoch 49, Step 168566: Loss=6.0250, Acc=0.250, 
2025-10-05 17:04:37,575 - training.trainer - INFO - Epoch 49, Step 168666: Loss=4.9061, Acc=0.326, 
2025-10-05 17:04:44,963 - training.trainer - INFO - Epoch 49, Step 168766: Loss=4.4017, Acc=0.444, 
2025-10-05 17:04:52,473 - training.trainer - INFO - Epoch 49, Step 168866: Loss=5.1676, Acc=0.294, 
2025-10-05 17:04:59,981 - training.trainer - INFO - Epoch 49, Step 168966: Loss=5.3911, Acc=0.292, 
2025-10-05 17:05:07,645 - training.trainer - INFO - Epoch 49, Step 169066: Loss=5.4084, Acc=0.368, 
2025-10-05 17:05:26,850 - training.trainer - INFO - Epoch 50/100 completed in 268.81s - Train Loss: 5.1572, Train Acc: 0.334, Val Loss: 5.6913, Val Acc: 0.259
2025-10-05 17:05:27,190 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-10-05 17:05:35,167 - training.trainer - INFO - Epoch 50, Step 169249: Loss=4.9289, Acc=0.357, 
2025-10-05 17:05:43,131 - training.trainer - INFO - Epoch 50, Step 169349: Loss=4.9681, Acc=0.320, 
2025-10-05 17:05:50,697 - training.trainer - INFO - Epoch 50, Step 169449: Loss=5.4448, Acc=0.309, 
2025-10-05 17:05:58,311 - training.trainer - INFO - Epoch 50, Step 169549: Loss=4.0452, Acc=0.559, 
2025-10-05 17:06:05,644 - training.trainer - INFO - Epoch 50, Step 169649: Loss=5.3810, Acc=0.310, 
2025-10-05 17:06:13,006 - training.trainer - INFO - Epoch 50, Step 169749: Loss=5.3486, Acc=0.250, 
2025-10-05 17:06:20,463 - training.trainer - INFO - Epoch 50, Step 169849: Loss=4.8177, Acc=0.364, 
2025-10-05 17:06:27,939 - training.trainer - INFO - Epoch 50, Step 169949: Loss=4.2882, Acc=0.444, 
2025-10-05 17:06:35,438 - training.trainer - INFO - Epoch 50, Step 170049: Loss=5.2256, Acc=0.304, 
2025-10-05 17:06:42,863 - training.trainer - INFO - Epoch 50, Step 170149: Loss=4.8541, Acc=0.382, 
2025-10-05 17:06:50,202 - training.trainer - INFO - Epoch 50, Step 170249: Loss=5.6887, Acc=0.242, 
2025-10-05 17:06:57,836 - training.trainer - INFO - Epoch 50, Step 170349: Loss=5.6314, Acc=0.276, 
2025-10-05 17:07:05,483 - training.trainer - INFO - Epoch 50, Step 170449: Loss=5.0101, Acc=0.333, 
2025-10-05 17:07:12,862 - training.trainer - INFO - Epoch 50, Step 170549: Loss=5.5273, Acc=0.333, 
2025-10-05 17:07:20,410 - training.trainer - INFO - Epoch 50, Step 170649: Loss=4.5503, Acc=0.333, 
2025-10-05 17:07:28,048 - training.trainer - INFO - Epoch 50, Step 170749: Loss=4.1337, Acc=0.429, 
2025-10-05 17:07:35,629 - training.trainer - INFO - Epoch 50, Step 170849: Loss=5.5859, Acc=0.250, 
2025-10-05 17:07:43,165 - training.trainer - INFO - Epoch 50, Step 170949: Loss=3.7413, Acc=0.556, 
2025-10-05 17:07:50,550 - training.trainer - INFO - Epoch 50, Step 171049: Loss=4.8124, Acc=0.393, 
2025-10-05 17:07:58,044 - training.trainer - INFO - Epoch 50, Step 171149: Loss=5.4136, Acc=0.379, 
2025-10-05 17:08:05,672 - training.trainer - INFO - Epoch 50, Step 171249: Loss=6.1709, Acc=0.268, 
2025-10-05 17:08:13,171 - training.trainer - INFO - Epoch 50, Step 171349: Loss=5.6517, Acc=0.250, 
2025-10-05 17:08:20,547 - training.trainer - INFO - Epoch 50, Step 171449: Loss=5.7952, Acc=0.300, 
2025-10-05 17:08:28,154 - training.trainer - INFO - Epoch 50, Step 171549: Loss=5.8883, Acc=0.300, 
2025-10-05 17:08:35,710 - training.trainer - INFO - Epoch 50, Step 171649: Loss=5.8368, Acc=0.220, 
2025-10-05 17:08:43,161 - training.trainer - INFO - Epoch 50, Step 171749: Loss=4.5053, Acc=0.450, 
2025-10-05 17:08:50,576 - training.trainer - INFO - Epoch 50, Step 171849: Loss=3.3428, Acc=0.655, 
2025-10-05 17:08:57,927 - training.trainer - INFO - Epoch 50, Step 171949: Loss=5.2292, Acc=0.233, 
2025-10-05 17:09:05,547 - training.trainer - INFO - Epoch 50, Step 172049: Loss=5.4631, Acc=0.256, 
2025-10-05 17:09:12,986 - training.trainer - INFO - Epoch 50, Step 172149: Loss=6.2049, Acc=0.280, 
2025-10-05 17:09:20,389 - training.trainer - INFO - Epoch 50, Step 172249: Loss=5.1012, Acc=0.311, 
2025-10-05 17:09:27,836 - training.trainer - INFO - Epoch 50, Step 172349: Loss=5.1588, Acc=0.381, 
2025-10-05 17:09:35,110 - training.trainer - INFO - Epoch 50, Step 172449: Loss=4.4382, Acc=0.488, 
2025-10-05 17:09:54,204 - training.trainer - INFO - Epoch 51/100 completed in 267.01s - Train Loss: 5.1522, Train Acc: 0.337, Val Loss: 5.7148, Val Acc: 0.262
2025-10-05 17:10:01,607 - training.trainer - INFO - Epoch 51, Step 172632: Loss=5.1446, Acc=0.217, 
2025-10-05 17:10:08,884 - training.trainer - INFO - Epoch 51, Step 172732: Loss=4.8066, Acc=0.412, 
2025-10-05 17:10:16,487 - training.trainer - INFO - Epoch 51, Step 172832: Loss=5.2865, Acc=0.278, 
2025-10-05 17:10:24,120 - training.trainer - INFO - Epoch 51, Step 172932: Loss=5.1968, Acc=0.348, 
2025-10-05 17:10:31,669 - training.trainer - INFO - Epoch 51, Step 173032: Loss=4.7562, Acc=0.364, 
2025-10-05 17:10:39,174 - training.trainer - INFO - Epoch 51, Step 173132: Loss=4.8082, Acc=0.355, 
2025-10-05 17:10:46,658 - training.trainer - INFO - Epoch 51, Step 173232: Loss=4.9990, Acc=0.286, 
2025-10-05 17:10:54,460 - training.trainer - INFO - Epoch 51, Step 173332: Loss=5.5444, Acc=0.333, 
2025-10-05 17:11:01,968 - training.trainer - INFO - Epoch 51, Step 173432: Loss=5.6157, Acc=0.256, 
2025-10-05 17:11:09,495 - training.trainer - INFO - Epoch 51, Step 173532: Loss=4.8073, Acc=0.333, 
2025-10-05 17:11:16,982 - training.trainer - INFO - Epoch 51, Step 173632: Loss=5.4320, Acc=0.283, 
2025-10-05 17:11:24,542 - training.trainer - INFO - Epoch 51, Step 173732: Loss=5.3795, Acc=0.321, 
2025-10-05 17:11:31,991 - training.trainer - INFO - Epoch 51, Step 173832: Loss=5.6505, Acc=0.340, 
2025-10-05 17:11:39,624 - training.trainer - INFO - Epoch 51, Step 173932: Loss=4.1481, Acc=0.588, 
2025-10-05 17:11:47,211 - training.trainer - INFO - Epoch 51, Step 174032: Loss=5.6054, Acc=0.273, 
2025-10-05 17:11:54,622 - training.trainer - INFO - Epoch 51, Step 174132: Loss=5.6846, Acc=0.205, 
2025-10-05 17:12:02,131 - training.trainer - INFO - Epoch 51, Step 174232: Loss=4.8308, Acc=0.407, 
2025-10-05 17:12:09,669 - training.trainer - INFO - Epoch 51, Step 174332: Loss=5.4280, Acc=0.293, 
2025-10-05 17:12:17,130 - training.trainer - INFO - Epoch 51, Step 174432: Loss=5.3232, Acc=0.286, 
2025-10-05 17:12:24,609 - training.trainer - INFO - Epoch 51, Step 174532: Loss=5.7890, Acc=0.250, 
2025-10-05 17:12:32,113 - training.trainer - INFO - Epoch 51, Step 174632: Loss=5.8651, Acc=0.240, 
2025-10-05 17:12:39,624 - training.trainer - INFO - Epoch 51, Step 174732: Loss=5.5686, Acc=0.324, 
2025-10-05 17:12:47,019 - training.trainer - INFO - Epoch 51, Step 174832: Loss=6.0926, Acc=0.233, 
2025-10-05 17:12:54,459 - training.trainer - INFO - Epoch 51, Step 174932: Loss=5.9292, Acc=0.268, 
2025-10-05 17:13:01,981 - training.trainer - INFO - Epoch 51, Step 175032: Loss=4.0092, Acc=0.562, 
2025-10-05 17:13:09,425 - training.trainer - INFO - Epoch 51, Step 175132: Loss=4.3048, Acc=0.391, 
2025-10-05 17:13:16,816 - training.trainer - INFO - Epoch 51, Step 175232: Loss=4.8296, Acc=0.342, 
2025-10-05 17:13:24,327 - training.trainer - INFO - Epoch 51, Step 175332: Loss=3.9380, Acc=0.524, 
2025-10-05 17:13:31,747 - training.trainer - INFO - Epoch 51, Step 175432: Loss=5.8615, Acc=0.308, 
2025-10-05 17:13:39,175 - training.trainer - INFO - Epoch 51, Step 175532: Loss=3.5746, Acc=0.565, 
2025-10-05 17:13:46,623 - training.trainer - INFO - Epoch 51, Step 175632: Loss=5.7631, Acc=0.324, 
2025-10-05 17:13:54,025 - training.trainer - INFO - Epoch 51, Step 175732: Loss=5.0216, Acc=0.317, 
2025-10-05 17:14:01,468 - training.trainer - INFO - Epoch 51, Step 175832: Loss=5.5156, Acc=0.300, 
2025-10-05 17:14:21,379 - training.trainer - INFO - Epoch 52/100 completed in 267.17s - Train Loss: 5.1298, Train Acc: 0.340, Val Loss: 5.7057, Val Acc: 0.263
2025-10-05 17:14:29,399 - training.trainer - INFO - Epoch 52, Step 176015: Loss=4.6598, Acc=0.364, 
2025-10-05 17:14:36,827 - training.trainer - INFO - Epoch 52, Step 176115: Loss=5.3346, Acc=0.355, 
2025-10-05 17:14:44,569 - training.trainer - INFO - Epoch 52, Step 176215: Loss=4.3564, Acc=0.419, 
2025-10-05 17:14:52,050 - training.trainer - INFO - Epoch 52, Step 176315: Loss=5.2617, Acc=0.450, 
2025-10-05 17:14:59,599 - training.trainer - INFO - Epoch 52, Step 176415: Loss=5.0029, Acc=0.455, 
2025-10-05 17:15:07,146 - training.trainer - INFO - Epoch 52, Step 176515: Loss=4.7801, Acc=0.429, 
2025-10-05 17:15:14,917 - training.trainer - INFO - Epoch 52, Step 176615: Loss=5.0984, Acc=0.354, 
2025-10-05 17:15:22,264 - training.trainer - INFO - Epoch 52, Step 176715: Loss=4.4761, Acc=0.387, 
2025-10-05 17:15:29,873 - training.trainer - INFO - Epoch 52, Step 176815: Loss=5.5450, Acc=0.273, 
2025-10-05 17:15:37,321 - training.trainer - INFO - Epoch 52, Step 176915: Loss=5.9340, Acc=0.242, 
2025-10-05 17:15:44,724 - training.trainer - INFO - Epoch 52, Step 177015: Loss=4.8015, Acc=0.407, 
2025-10-05 17:15:52,136 - training.trainer - INFO - Epoch 52, Step 177115: Loss=5.2080, Acc=0.268, 
2025-10-05 17:15:59,454 - training.trainer - INFO - Epoch 52, Step 177215: Loss=4.7140, Acc=0.310, 
2025-10-05 17:16:06,854 - training.trainer - INFO - Epoch 52, Step 177315: Loss=4.8171, Acc=0.343, 
2025-10-05 17:16:14,256 - training.trainer - INFO - Epoch 52, Step 177415: Loss=5.3125, Acc=0.278, 
2025-10-05 17:16:21,710 - training.trainer - INFO - Epoch 52, Step 177515: Loss=5.6401, Acc=0.288, 
2025-10-05 17:16:29,236 - training.trainer - INFO - Epoch 52, Step 177615: Loss=6.0788, Acc=0.194, 
2025-10-05 17:16:36,769 - training.trainer - INFO - Epoch 52, Step 177715: Loss=6.0121, Acc=0.259, 
2025-10-05 17:16:44,291 - training.trainer - INFO - Epoch 52, Step 177815: Loss=5.9641, Acc=0.282, 
2025-10-05 17:16:51,696 - training.trainer - INFO - Epoch 52, Step 177915: Loss=5.2530, Acc=0.328, 
2025-10-05 17:16:59,105 - training.trainer - INFO - Epoch 52, Step 178015: Loss=5.7929, Acc=0.233, 
2025-10-05 17:17:06,595 - training.trainer - INFO - Epoch 52, Step 178115: Loss=5.5746, Acc=0.246, 
2025-10-05 17:17:14,038 - training.trainer - INFO - Epoch 52, Step 178215: Loss=5.1763, Acc=0.395, 
2025-10-05 17:17:21,379 - training.trainer - INFO - Epoch 52, Step 178315: Loss=4.0112, Acc=0.516, 
2025-10-05 17:17:28,773 - training.trainer - INFO - Epoch 52, Step 178415: Loss=5.7336, Acc=0.310, 
2025-10-05 17:17:36,296 - training.trainer - INFO - Epoch 52, Step 178515: Loss=6.0262, Acc=0.224, 
2025-10-05 17:17:43,643 - training.trainer - INFO - Epoch 52, Step 178615: Loss=5.1464, Acc=0.286, 
2025-10-05 17:17:50,975 - training.trainer - INFO - Epoch 52, Step 178715: Loss=5.4678, Acc=0.341, 
2025-10-05 17:17:58,408 - training.trainer - INFO - Epoch 52, Step 178815: Loss=5.4774, Acc=0.222, 
2025-10-05 17:18:05,913 - training.trainer - INFO - Epoch 52, Step 178915: Loss=4.8257, Acc=0.419, 
2025-10-05 17:18:13,509 - training.trainer - INFO - Epoch 52, Step 179015: Loss=2.3148, Acc=0.714, 
2025-10-05 17:18:20,922 - training.trainer - INFO - Epoch 52, Step 179115: Loss=5.4960, Acc=0.255, 
2025-10-05 17:18:28,374 - training.trainer - INFO - Epoch 52, Step 179215: Loss=4.4437, Acc=0.485, 
2025-10-05 17:18:47,497 - training.trainer - INFO - Epoch 53/100 completed in 266.12s - Train Loss: 5.1185, Train Acc: 0.342, Val Loss: 5.7075, Val Acc: 0.263
2025-10-05 17:18:55,123 - training.trainer - INFO - Epoch 53, Step 179398: Loss=5.7189, Acc=0.161, 
2025-10-05 17:19:02,318 - training.trainer - INFO - Epoch 53, Step 179498: Loss=5.7264, Acc=0.224, 
2025-10-05 17:19:09,795 - training.trainer - INFO - Epoch 53, Step 179598: Loss=5.6520, Acc=0.250, 
2025-10-05 17:19:17,204 - training.trainer - INFO - Epoch 53, Step 179698: Loss=5.4800, Acc=0.316, 
2025-10-05 17:19:24,582 - training.trainer - INFO - Epoch 53, Step 179798: Loss=3.8886, Acc=0.400, 
2025-10-05 17:19:32,163 - training.trainer - INFO - Epoch 53, Step 179898: Loss=6.5420, Acc=0.231, 
2025-10-05 17:19:39,584 - training.trainer - INFO - Epoch 53, Step 179998: Loss=5.1373, Acc=0.360, 
2025-10-05 17:19:46,985 - training.trainer - INFO - Epoch 53, Step 180098: Loss=5.0929, Acc=0.347, 
2025-10-05 17:19:54,393 - training.trainer - INFO - Epoch 53, Step 180198: Loss=4.0806, Acc=0.407, 
2025-10-05 17:20:01,774 - training.trainer - INFO - Epoch 53, Step 180298: Loss=5.8566, Acc=0.281, 
2025-10-05 17:20:09,204 - training.trainer - INFO - Epoch 53, Step 180398: Loss=4.5561, Acc=0.407, 
2025-10-05 17:20:16,602 - training.trainer - INFO - Epoch 53, Step 180498: Loss=5.3518, Acc=0.324, 
2025-10-05 17:20:24,004 - training.trainer - INFO - Epoch 53, Step 180598: Loss=6.0407, Acc=0.258, 
2025-10-05 17:20:31,469 - training.trainer - INFO - Epoch 53, Step 180698: Loss=4.7753, Acc=0.615, 
2025-10-05 17:20:38,878 - training.trainer - INFO - Epoch 53, Step 180798: Loss=4.6854, Acc=0.391, 
2025-10-05 17:20:46,293 - training.trainer - INFO - Epoch 53, Step 180898: Loss=4.9165, Acc=0.341, 
2025-10-05 17:20:53,797 - training.trainer - INFO - Epoch 53, Step 180998: Loss=4.8311, Acc=0.294, 
2025-10-05 17:21:01,305 - training.trainer - INFO - Epoch 53, Step 181098: Loss=5.0163, Acc=0.364, 
2025-10-05 17:21:09,081 - training.trainer - INFO - Epoch 53, Step 181198: Loss=4.2917, Acc=0.462, 
2025-10-05 17:21:16,617 - training.trainer - INFO - Epoch 53, Step 181298: Loss=5.7046, Acc=0.175, 
2025-10-05 17:21:23,973 - training.trainer - INFO - Epoch 53, Step 181398: Loss=4.9654, Acc=0.224, 
2025-10-05 17:21:31,409 - training.trainer - INFO - Epoch 53, Step 181498: Loss=4.7446, Acc=0.444, 
2025-10-05 17:21:39,062 - training.trainer - INFO - Epoch 53, Step 181598: Loss=4.3369, Acc=0.286, 
2025-10-05 17:21:46,613 - training.trainer - INFO - Epoch 53, Step 181698: Loss=5.7804, Acc=0.222, 
2025-10-05 17:21:54,213 - training.trainer - INFO - Epoch 53, Step 181798: Loss=5.2142, Acc=0.304, 
2025-10-05 17:22:01,729 - training.trainer - INFO - Epoch 53, Step 181898: Loss=4.3061, Acc=0.562, 
2025-10-05 17:22:09,343 - training.trainer - INFO - Epoch 53, Step 181998: Loss=5.3957, Acc=0.317, 
2025-10-05 17:22:16,938 - training.trainer - INFO - Epoch 53, Step 182098: Loss=4.8931, Acc=0.333, 
2025-10-05 17:22:24,375 - training.trainer - INFO - Epoch 53, Step 182198: Loss=4.8417, Acc=0.429, 
2025-10-05 17:22:31,806 - training.trainer - INFO - Epoch 53, Step 182298: Loss=5.3827, Acc=0.314, 
2025-10-05 17:22:39,305 - training.trainer - INFO - Epoch 53, Step 182398: Loss=5.9181, Acc=0.216, 
2025-10-05 17:22:46,671 - training.trainer - INFO - Epoch 53, Step 182498: Loss=5.2896, Acc=0.250, 
2025-10-05 17:22:54,172 - training.trainer - INFO - Epoch 53, Step 182598: Loss=5.7676, Acc=0.289, 
2025-10-05 17:23:13,448 - training.trainer - INFO - Epoch 54/100 completed in 265.95s - Train Loss: 5.0985, Train Acc: 0.347, Val Loss: 5.7007, Val Acc: 0.261
2025-10-05 17:23:13,448 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-05 17:23:13,448 - training.trainer - INFO - Training completed!
2025-10-05 17:23:13,449 - __main__ - INFO - Training completed successfully!
2025-10-05 17:23:13,571 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-05 17:23:13,602 - __main__ - INFO - Process completed!
2025-10-05 17:23:22,263 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-05 17:23:22,263 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-05 17:23:22,264 - __main__ - INFO - Starting model evaluation
2025-10-05 17:23:22,999 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-05 18:08:24,591 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-05 18:08:24,608 - __main__ - INFO - Process completed!
2025-10-05 18:08:31,150 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-10-05 18:08:31,150 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-05 18:08:31,150 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-10-05 18:08:31,770 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-05 18:08:36,190 - __main__ - INFO - Inference completed successfully!
2025-10-05 18:08:36,200 - __main__ - INFO - Process completed!
2025-10-05 22:51:16,384 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-05 22:51:16,385 - __main__ - INFO - Configuration: configs/lsa_t_config_8.yaml
2025-10-05 22:51:16,385 - __main__ - INFO - Starting model evaluation
2025-10-05 22:51:16,802 - __main__ - ERROR - No trained model found at checkpoints/lsa_t/best_model.pt
2025-10-05 22:51:16,809 - __main__ - INFO - Process completed!
2025-10-05 22:54:34,357 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-05 22:54:34,357 - __main__ - INFO - Configuration: configs/lsa_t_config_8.yaml
2025-10-05 22:54:34,357 - __main__ - INFO - Starting model evaluation
2025-10-05 22:54:35,093 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-06 00:08:46,822 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-06 00:08:46,836 - __main__ - INFO - Process completed!
2025-10-06 00:08:51,193 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-06 00:08:51,193 - __main__ - INFO - Configuration: configs/lsa_t_config_16.yaml
2025-10-06 00:08:51,193 - __main__ - INFO - Starting model evaluation
2025-10-06 00:08:51,867 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-06 02:43:41,418 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-06 02:43:41,433 - __main__ - INFO - Process completed!
2025-10-06 02:43:46,177 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-06 02:43:46,177 - __main__ - INFO - Configuration: configs/lsa_t_config_24.yaml
2025-10-06 02:43:46,177 - __main__ - INFO - Starting model evaluation
2025-10-06 02:43:46,818 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-06 05:20:04,422 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-06 05:20:04,569 - __main__ - INFO - Process completed!
2025-10-06 20:37:45,275 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-06 20:37:45,277 - __main__ - INFO - Configuration: configs/lsa_t_config_24.yaml
2025-10-06 20:37:45,277 - __main__ - INFO - Starting model evaluation
2025-10-06 20:37:46,560 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-07 00:48:04,605 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-07 00:48:04,629 - __main__ - INFO - Process completed!
2025-10-07 09:19:20,256 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-07 09:19:20,256 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-07 09:19:20,256 - __main__ - INFO - Starting training pipeline
2025-10-07 09:19:20,288 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-07 09:19:20,317 - __main__ - INFO - GPU: NVIDIA A30
2025-10-07 09:19:20,317 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-07 09:19:20,317 - __main__ - INFO - Loading training data...
2025-10-07 09:19:52,594 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-07 09:19:52,595 - __main__ - INFO - Processing train split...
2025-10-07 09:19:52,702 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-07 09:19:52,702 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-07 09:21:56,162 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-07 09:21:56,162 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-07 09:21:56,162 - __main__ - INFO - Starting training pipeline
2025-10-07 09:21:56,194 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-07 09:21:56,222 - __main__ - INFO - GPU: NVIDIA A30
2025-10-07 09:21:56,222 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-07 09:21:56,222 - __main__ - INFO - Loading training data...
2025-10-07 09:22:04,060 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-07 09:22:04,060 - __main__ - INFO - Processing train split...
2025-10-07 09:22:04,146 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-07 09:22:04,146 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-07 09:22:47,982 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-07 09:23:32,926 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-07 09:24:18,295 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-07 09:25:02,035 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-07 09:25:53,349 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-07 09:26:45,696 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-07 09:27:26,399 - __main__ - INFO - Processing val split...
2025-10-07 09:27:26,676 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-07 09:27:26,676 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-07 09:28:10,913 - __main__ - INFO - Processing test split...
2025-10-07 09:28:11,169 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-07 09:28:11,169 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-07 09:28:56,287 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-07 09:28:56,288 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-07 09:28:56,306 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-07 09:28:56,307 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-07 09:28:56,307 - __main__ - INFO - Creating model architecture...
2025-10-07 09:28:56,676 - __main__ - INFO - Model created successfully
2025-10-07 09:28:56,677 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-07 09:28:56,677 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-07 09:28:56,677 - __main__ - INFO - Using device: cuda
2025-10-07 09:28:56,677 - __main__ - INFO - Creating trainer...
2025-10-07 09:28:56,677 - __main__ - INFO - Moving model to cuda...
2025-10-07 09:28:57,149 - __main__ - INFO - Model moved to cuda
2025-10-07 09:28:57,150 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-07 09:28:59,783 - __main__ - INFO - Trainer created successfully
2025-10-07 09:28:59,783 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-07 09:28:59,783 - __main__ - INFO - Starting training...
2025-10-07 09:28:59,783 - __main__ - INFO - Training configuration:
2025-10-07 09:28:59,783 - __main__ - INFO -   - Epochs: 100
2025-10-07 09:28:59,783 - __main__ - INFO -   - Batch size: 2
2025-10-07 09:28:59,783 - __main__ - INFO -   - Learning rate: 3e-5
2025-10-07 09:28:59,784 - __main__ - INFO -   - Training samples: 6765
2025-10-07 09:28:59,784 - __main__ - INFO -   - Validation samples: 845
2025-10-07 09:28:59,784 - training.trainer - INFO - Starting training for 100 epochs
2025-10-07 09:28:59,784 - training.trainer - INFO - Model parameters: 18,259,552
2025-10-07 09:28:59,784 - training.trainer - INFO - Training on device: cuda
2025-10-07 09:29:11,421 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.8760, Acc=0.032, 
2025-10-07 09:29:20,895 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.4575, Acc=0.087, 
2025-10-07 09:29:30,363 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.9652, Acc=0.042, 
2025-10-07 09:29:39,607 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.6055, Acc=0.000, 
2025-10-07 09:29:48,725 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.7449, Acc=0.026, 
2025-10-07 09:29:57,811 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.3717, Acc=0.043, 
2025-10-07 09:30:06,754 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.9042, Acc=0.089, 
2025-10-07 09:30:15,680 - training.trainer - INFO - Epoch 0, Step 799: Loss=7.1502, Acc=0.109, 
2025-10-07 09:30:24,538 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.4094, Acc=0.000, 
2025-10-07 09:30:33,376 - training.trainer - INFO - Epoch 0, Step 999: Loss=7.0457, Acc=0.118, 
2025-10-07 09:30:42,153 - training.trainer - INFO - Epoch 0, Step 1099: Loss=7.0383, Acc=0.125, 
2025-10-07 09:30:50,898 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.2059, Acc=0.136, 
2025-10-07 09:30:59,606 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.1685, Acc=0.316, 
2025-10-07 09:31:08,261 - training.trainer - INFO - Epoch 0, Step 1399: Loss=6.5063, Acc=0.082, 
2025-10-07 09:31:16,928 - training.trainer - INFO - Epoch 0, Step 1499: Loss=6.9708, Acc=0.136, 
2025-10-07 09:31:25,424 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.5413, Acc=0.135, 
2025-10-07 09:31:33,946 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.3834, Acc=0.143, 
2025-10-07 09:31:42,559 - training.trainer - INFO - Epoch 0, Step 1799: Loss=5.8491, Acc=0.190, 
2025-10-07 09:31:51,121 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.7099, Acc=0.194, 
2025-10-07 09:31:59,781 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.4440, Acc=0.191, 
2025-10-07 09:32:08,545 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.1509, Acc=0.308, 
2025-10-07 09:32:17,158 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.5981, Acc=0.091, 
2025-10-07 09:32:25,700 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.3672, Acc=0.208, 
2025-10-07 09:32:34,172 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.4647, Acc=0.128, 
2025-10-07 09:32:42,635 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.9085, Acc=0.122, 
2025-10-07 09:32:51,207 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.8046, Acc=0.250, 
2025-10-07 09:32:59,741 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.6909, Acc=0.113, 
2025-10-07 09:33:08,143 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.2989, Acc=0.152, 
2025-10-07 09:33:16,491 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.9427, Acc=0.114, 
2025-10-07 09:33:24,874 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.8264, Acc=0.118, 
2025-10-07 09:33:33,424 - training.trainer - INFO - Epoch 0, Step 3099: Loss=5.5400, Acc=0.111, 
2025-10-07 09:33:41,995 - training.trainer - INFO - Epoch 0, Step 3199: Loss=6.5997, Acc=0.211, 
2025-10-07 09:33:50,559 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.6396, Acc=0.092, 
2025-10-07 09:34:10,291 - training.trainer - INFO - Epoch 1/100 completed in 310.51s - Train Loss: 6.8319, Train Acc: 0.128, Val Loss: 6.3568, Val Acc: 0.164
2025-10-07 09:34:11,141 - training.trainer - INFO - New best model saved with validation loss: 6.3568
2025-10-07 09:34:11,142 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-07 09:34:18,592 - training.trainer - INFO - Epoch 1, Step 3482: Loss=5.5076, Acc=0.214, 
2025-10-07 09:34:25,591 - training.trainer - INFO - Epoch 1, Step 3582: Loss=7.0416, Acc=0.159, 
2025-10-07 09:34:32,620 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.2622, Acc=0.115, 
2025-10-07 09:34:39,696 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.9800, Acc=0.073, 
2025-10-07 09:34:46,914 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.3237, Acc=0.158, 
2025-10-07 09:34:53,989 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.3818, Acc=0.250, 
2025-10-07 09:35:01,732 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.3939, Acc=0.136, 
2025-10-07 09:35:10,209 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.6969, Acc=0.190, 
2025-10-07 09:35:18,554 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.9805, Acc=0.114, 
2025-10-07 09:35:26,830 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.7586, Acc=0.167, 
2025-10-07 09:35:35,156 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.9530, Acc=0.148, 
2025-10-07 09:35:43,722 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.2376, Acc=0.182, 
2025-10-07 09:35:52,119 - training.trainer - INFO - Epoch 1, Step 4682: Loss=5.8962, Acc=0.136, 
2025-10-07 09:36:00,305 - training.trainer - INFO - Epoch 1, Step 4782: Loss=5.9058, Acc=0.163, 
2025-10-07 09:36:08,485 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.5648, Acc=0.200, 
2025-10-07 09:36:16,835 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.4060, Acc=0.196, 
2025-10-07 09:36:25,123 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.8034, Acc=0.220, 
2025-10-07 09:36:33,354 - training.trainer - INFO - Epoch 1, Step 5182: Loss=4.9392, Acc=0.308, 
2025-10-07 09:36:41,647 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.6356, Acc=0.132, 
2025-10-07 09:36:49,977 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.3272, Acc=0.170, 
2025-10-07 09:36:58,210 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.5967, Acc=0.129, 
2025-10-07 09:37:06,446 - training.trainer - INFO - Epoch 1, Step 5582: Loss=5.5393, Acc=0.222, 
2025-10-07 09:37:14,634 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.4368, Acc=0.186, 
2025-10-07 09:37:22,890 - training.trainer - INFO - Epoch 1, Step 5782: Loss=6.0512, Acc=0.125, 
2025-10-07 09:37:31,090 - training.trainer - INFO - Epoch 1, Step 5882: Loss=7.0657, Acc=0.125, 
2025-10-07 09:37:39,313 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.4263, Acc=0.171, 
2025-10-07 09:37:47,508 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.7502, Acc=0.156, 
2025-10-07 09:37:55,825 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.2432, Acc=0.214, 
2025-10-07 09:38:04,064 - training.trainer - INFO - Epoch 1, Step 6282: Loss=6.1501, Acc=0.227, 
2025-10-07 09:38:12,414 - training.trainer - INFO - Epoch 1, Step 6382: Loss=6.2641, Acc=0.134, 
2025-10-07 09:38:20,466 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.1431, Acc=0.333, 
2025-10-07 09:38:27,946 - training.trainer - INFO - Epoch 1, Step 6582: Loss=5.9119, Acc=0.180, 
2025-10-07 09:38:34,987 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.5888, Acc=0.089, 
2025-10-07 09:38:53,418 - training.trainer - INFO - Epoch 2/100 completed in 282.28s - Train Loss: 6.3245, Train Acc: 0.166, Val Loss: 6.2063, Val Acc: 0.174
2025-10-07 09:38:54,331 - training.trainer - INFO - New best model saved with validation loss: 6.2063
2025-10-07 09:38:54,332 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-07 09:39:02,012 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.4534, Acc=0.105, 
2025-10-07 09:39:09,201 - training.trainer - INFO - Epoch 2, Step 6965: Loss=5.8303, Acc=0.211, 
2025-10-07 09:39:16,654 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.2687, Acc=0.091, 
2025-10-07 09:39:24,987 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.0146, Acc=0.200, 
2025-10-07 09:39:33,269 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.1863, Acc=0.161, 
2025-10-07 09:39:41,542 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.7013, Acc=0.250, 
2025-10-07 09:39:49,919 - training.trainer - INFO - Epoch 2, Step 7465: Loss=7.1940, Acc=0.104, 
2025-10-07 09:39:58,374 - training.trainer - INFO - Epoch 2, Step 7565: Loss=5.5268, Acc=0.208, 
2025-10-07 09:40:06,519 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.6265, Acc=0.171, 
2025-10-07 09:40:14,799 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.1706, Acc=0.170, 
2025-10-07 09:40:23,189 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.1975, Acc=0.143, 
2025-10-07 09:40:31,669 - training.trainer - INFO - Epoch 2, Step 7965: Loss=5.7406, Acc=0.216, 
2025-10-07 09:40:40,189 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.1961, Acc=0.181, 
2025-10-07 09:40:48,672 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.6029, Acc=0.136, 
2025-10-07 09:40:57,119 - training.trainer - INFO - Epoch 2, Step 8265: Loss=7.0075, Acc=0.092, 
2025-10-07 09:41:05,610 - training.trainer - INFO - Epoch 2, Step 8365: Loss=4.8730, Acc=0.353, 
2025-10-07 09:41:14,061 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.3700, Acc=0.103, 
2025-10-07 09:41:22,567 - training.trainer - INFO - Epoch 2, Step 8565: Loss=6.8828, Acc=0.130, 
2025-10-07 09:41:30,960 - training.trainer - INFO - Epoch 2, Step 8665: Loss=5.9868, Acc=0.200, 
2025-10-07 09:41:39,315 - training.trainer - INFO - Epoch 2, Step 8765: Loss=5.4368, Acc=0.238, 
2025-10-07 09:41:47,599 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.1925, Acc=0.192, 
2025-10-07 09:41:56,009 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.3586, Acc=0.121, 
2025-10-07 09:42:04,405 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.2097, Acc=0.222, 
2025-10-07 09:42:12,815 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.4134, Acc=0.122, 
2025-10-07 09:42:21,205 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.7842, Acc=0.109, 
2025-10-07 09:42:29,431 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.7221, Acc=0.155, 
2025-10-07 09:42:37,741 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.2810, Acc=0.207, 
2025-10-07 09:42:46,097 - training.trainer - INFO - Epoch 2, Step 9565: Loss=5.2312, Acc=0.421, 
2025-10-07 09:42:54,539 - training.trainer - INFO - Epoch 2, Step 9665: Loss=7.1492, Acc=0.116, 
2025-10-07 09:43:02,864 - training.trainer - INFO - Epoch 2, Step 9765: Loss=5.7502, Acc=0.174, 
2025-10-07 09:43:11,165 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.1250, Acc=0.174, 
2025-10-07 09:43:19,475 - training.trainer - INFO - Epoch 2, Step 9965: Loss=4.7842, Acc=0.357, 
2025-10-07 09:43:27,751 - training.trainer - INFO - Epoch 2, Step 10065: Loss=5.5654, Acc=0.182, 
2025-10-07 09:43:47,855 - training.trainer - INFO - Epoch 3/100 completed in 293.52s - Train Loss: 6.1990, Train Acc: 0.176, Val Loss: 6.1038, Val Acc: 0.188
2025-10-07 09:43:48,537 - training.trainer - INFO - New best model saved with validation loss: 6.1038
2025-10-07 09:43:48,538 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-10-07 09:43:56,304 - training.trainer - INFO - Epoch 3, Step 10248: Loss=6.3531, Acc=0.194, 
2025-10-07 09:44:03,506 - training.trainer - INFO - Epoch 3, Step 10348: Loss=5.6462, Acc=0.158, 
2025-10-07 09:44:10,590 - training.trainer - INFO - Epoch 3, Step 10448: Loss=5.8994, Acc=0.125, 
2025-10-07 09:44:17,679 - training.trainer - INFO - Epoch 3, Step 10548: Loss=6.6376, Acc=0.155, 
2025-10-07 09:44:24,801 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.7748, Acc=0.102, 
2025-10-07 09:44:31,910 - training.trainer - INFO - Epoch 3, Step 10748: Loss=6.2712, Acc=0.200, 
2025-10-07 09:44:39,057 - training.trainer - INFO - Epoch 3, Step 10848: Loss=5.2747, Acc=0.200, 
2025-10-07 09:44:46,234 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.2666, Acc=0.171, 
2025-10-07 09:44:53,473 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.0403, Acc=0.286, 
2025-10-07 09:45:00,584 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.7658, Acc=0.125, 
2025-10-07 09:45:07,704 - training.trainer - INFO - Epoch 3, Step 11248: Loss=5.1152, Acc=0.208, 
2025-10-07 09:45:14,809 - training.trainer - INFO - Epoch 3, Step 11348: Loss=5.6446, Acc=0.224, 
2025-10-07 09:45:21,894 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.9343, Acc=0.122, 
2025-10-07 09:45:29,039 - training.trainer - INFO - Epoch 3, Step 11548: Loss=5.3541, Acc=0.190, 
2025-10-07 09:45:36,097 - training.trainer - INFO - Epoch 3, Step 11648: Loss=6.6165, Acc=0.151, 
2025-10-07 09:45:43,260 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.8523, Acc=0.243, 
2025-10-07 09:45:50,827 - training.trainer - INFO - Epoch 3, Step 11848: Loss=6.0811, Acc=0.174, 
2025-10-07 09:45:57,878 - training.trainer - INFO - Epoch 3, Step 11948: Loss=5.6619, Acc=0.143, 
2025-10-07 09:46:04,893 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.2921, Acc=0.182, 
2025-10-07 09:46:12,042 - training.trainer - INFO - Epoch 3, Step 12148: Loss=5.4096, Acc=0.233, 
2025-10-07 09:46:19,113 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.8394, Acc=0.152, 
2025-10-07 09:46:26,170 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.5065, Acc=0.167, 
2025-10-07 09:46:33,272 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.5559, Acc=0.143, 
2025-10-07 09:46:40,295 - training.trainer - INFO - Epoch 3, Step 12548: Loss=5.8504, Acc=0.152, 
2025-10-07 09:46:47,394 - training.trainer - INFO - Epoch 3, Step 12648: Loss=4.9524, Acc=0.231, 
2025-10-07 09:46:54,493 - training.trainer - INFO - Epoch 3, Step 12748: Loss=5.5371, Acc=0.300, 
2025-10-07 09:47:01,845 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.2309, Acc=0.211, 
2025-10-07 09:47:08,972 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.6174, Acc=0.117, 
2025-10-07 09:47:16,038 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.1560, Acc=0.111, 
2025-10-07 09:47:23,077 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.1069, Acc=0.095, 
2025-10-07 09:47:31,043 - training.trainer - INFO - Epoch 3, Step 13248: Loss=5.9637, Acc=0.171, 
2025-10-07 09:47:38,843 - training.trainer - INFO - Epoch 3, Step 13348: Loss=5.7378, Acc=0.194, 
2025-10-07 09:47:46,790 - training.trainer - INFO - Epoch 3, Step 13448: Loss=5.5336, Acc=0.154, 
2025-10-07 09:48:06,330 - training.trainer - INFO - Epoch 4/100 completed in 257.79s - Train Loss: 6.1353, Train Acc: 0.185, Val Loss: 6.0402, Val Acc: 0.196
2025-10-07 09:48:07,112 - training.trainer - INFO - New best model saved with validation loss: 6.0402
2025-10-07 09:48:07,112 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-10-07 09:48:15,669 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.2516, Acc=0.246, 
2025-10-07 09:48:24,075 - training.trainer - INFO - Epoch 4, Step 13731: Loss=5.7285, Acc=0.179, 
2025-10-07 09:48:32,579 - training.trainer - INFO - Epoch 4, Step 13831: Loss=5.6383, Acc=0.190, 
2025-10-07 09:48:40,907 - training.trainer - INFO - Epoch 4, Step 13931: Loss=5.7776, Acc=0.258, 
2025-10-07 09:48:49,256 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.2867, Acc=0.267, 
2025-10-07 09:48:57,584 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.2032, Acc=0.140, 
2025-10-07 09:49:05,939 - training.trainer - INFO - Epoch 4, Step 14231: Loss=5.8916, Acc=0.242, 
2025-10-07 09:49:14,332 - training.trainer - INFO - Epoch 4, Step 14331: Loss=5.8800, Acc=0.267, 
2025-10-07 09:49:22,660 - training.trainer - INFO - Epoch 4, Step 14431: Loss=6.4708, Acc=0.250, 
2025-10-07 09:49:30,998 - training.trainer - INFO - Epoch 4, Step 14531: Loss=6.5649, Acc=0.189, 
2025-10-07 09:49:39,231 - training.trainer - INFO - Epoch 4, Step 14631: Loss=5.9178, Acc=0.158, 
2025-10-07 09:49:47,493 - training.trainer - INFO - Epoch 4, Step 14731: Loss=7.1442, Acc=0.111, 
2025-10-07 09:49:55,816 - training.trainer - INFO - Epoch 4, Step 14831: Loss=5.0952, Acc=0.316, 
2025-10-07 09:50:04,134 - training.trainer - INFO - Epoch 4, Step 14931: Loss=6.2897, Acc=0.149, 
2025-10-07 09:50:12,359 - training.trainer - INFO - Epoch 4, Step 15031: Loss=5.4708, Acc=0.282, 
2025-10-07 09:50:20,622 - training.trainer - INFO - Epoch 4, Step 15131: Loss=5.6586, Acc=0.267, 
2025-10-07 09:50:28,966 - training.trainer - INFO - Epoch 4, Step 15231: Loss=6.0178, Acc=0.238, 
2025-10-07 09:50:37,441 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.1222, Acc=0.083, 
2025-10-07 09:50:45,925 - training.trainer - INFO - Epoch 4, Step 15431: Loss=5.8352, Acc=0.136, 
2025-10-07 09:50:54,342 - training.trainer - INFO - Epoch 4, Step 15531: Loss=6.6696, Acc=0.137, 
2025-10-07 09:51:02,758 - training.trainer - INFO - Epoch 4, Step 15631: Loss=5.9356, Acc=0.162, 
2025-10-07 09:51:11,221 - training.trainer - INFO - Epoch 4, Step 15731: Loss=5.6360, Acc=0.158, 
2025-10-07 09:51:19,615 - training.trainer - INFO - Epoch 4, Step 15831: Loss=5.0511, Acc=0.316, 
2025-10-07 09:51:28,291 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.3187, Acc=0.167, 
2025-10-07 09:51:36,650 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.0622, Acc=0.148, 
2025-10-07 09:51:45,121 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.7992, Acc=0.188, 
2025-10-07 09:51:53,501 - training.trainer - INFO - Epoch 4, Step 16231: Loss=6.0988, Acc=0.217, 
2025-10-07 09:52:01,879 - training.trainer - INFO - Epoch 4, Step 16331: Loss=6.4939, Acc=0.147, 
2025-10-07 09:52:10,233 - training.trainer - INFO - Epoch 4, Step 16431: Loss=5.3525, Acc=0.308, 
2025-10-07 09:52:18,540 - training.trainer - INFO - Epoch 4, Step 16531: Loss=5.9252, Acc=0.233, 
2025-10-07 09:52:26,779 - training.trainer - INFO - Epoch 4, Step 16631: Loss=6.3185, Acc=0.120, 
2025-10-07 09:52:35,036 - training.trainer - INFO - Epoch 4, Step 16731: Loss=6.2135, Acc=0.159, 
2025-10-07 09:52:43,301 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.3524, Acc=0.083, 
2025-10-07 09:53:03,163 - training.trainer - INFO - Epoch 5/100 completed in 296.05s - Train Loss: 6.0786, Train Acc: 0.193, Val Loss: 5.9896, Val Acc: 0.203
2025-10-07 09:53:03,578 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-07 09:53:04,426 - training.trainer - INFO - New best model saved with validation loss: 5.9896
2025-10-07 09:53:04,426 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-07 09:53:13,399 - training.trainer - INFO - Epoch 5, Step 17014: Loss=4.6638, Acc=0.250, 
2025-10-07 09:53:21,765 - training.trainer - INFO - Epoch 5, Step 17114: Loss=5.4732, Acc=0.304, 
2025-10-07 09:53:30,181 - training.trainer - INFO - Epoch 5, Step 17214: Loss=5.4121, Acc=0.333, 
2025-10-07 09:53:38,551 - training.trainer - INFO - Epoch 5, Step 17314: Loss=6.9287, Acc=0.111, 
2025-10-07 09:53:46,941 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.3700, Acc=0.133, 
2025-10-07 09:53:55,443 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.2906, Acc=0.241, 
2025-10-07 09:54:03,902 - training.trainer - INFO - Epoch 5, Step 17614: Loss=5.8030, Acc=0.184, 
2025-10-07 09:54:12,367 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.0644, Acc=0.161, 
2025-10-07 09:54:20,745 - training.trainer - INFO - Epoch 5, Step 17814: Loss=6.1445, Acc=0.171, 
2025-10-07 09:54:29,099 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.2151, Acc=0.263, 
2025-10-07 09:54:37,415 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.2838, Acc=0.152, 
2025-10-07 09:54:45,697 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.6149, Acc=0.159, 
2025-10-07 09:54:53,995 - training.trainer - INFO - Epoch 5, Step 18214: Loss=6.3827, Acc=0.153, 
2025-10-07 09:55:02,403 - training.trainer - INFO - Epoch 5, Step 18314: Loss=6.1431, Acc=0.219, 
2025-10-07 09:55:10,806 - training.trainer - INFO - Epoch 5, Step 18414: Loss=6.3965, Acc=0.111, 
2025-10-07 09:55:19,072 - training.trainer - INFO - Epoch 5, Step 18514: Loss=5.6299, Acc=0.238, 
2025-10-07 09:55:27,277 - training.trainer - INFO - Epoch 5, Step 18614: Loss=5.4993, Acc=0.154, 
2025-10-07 09:55:35,594 - training.trainer - INFO - Epoch 5, Step 18714: Loss=4.9217, Acc=0.444, 
2025-10-07 09:55:43,836 - training.trainer - INFO - Epoch 5, Step 18814: Loss=6.0331, Acc=0.214, 
2025-10-07 09:55:52,089 - training.trainer - INFO - Epoch 5, Step 18914: Loss=5.9522, Acc=0.196, 
2025-10-07 09:56:00,462 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.7808, Acc=0.113, 
2025-10-07 09:56:08,730 - training.trainer - INFO - Epoch 5, Step 19114: Loss=5.7761, Acc=0.179, 
2025-10-07 09:56:17,080 - training.trainer - INFO - Epoch 5, Step 19214: Loss=5.8522, Acc=0.143, 
2025-10-07 09:56:25,386 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.2514, Acc=0.250, 
2025-10-07 09:56:33,667 - training.trainer - INFO - Epoch 5, Step 19414: Loss=6.2077, Acc=0.273, 
2025-10-07 09:56:42,016 - training.trainer - INFO - Epoch 5, Step 19514: Loss=5.9366, Acc=0.154, 
2025-10-07 09:56:50,415 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.3931, Acc=0.155, 
2025-10-07 09:56:58,786 - training.trainer - INFO - Epoch 5, Step 19714: Loss=5.3367, Acc=0.231, 
2025-10-07 09:57:07,111 - training.trainer - INFO - Epoch 5, Step 19814: Loss=5.6626, Acc=0.312, 
2025-10-07 09:57:15,374 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.8038, Acc=0.162, 
2025-10-07 09:57:23,653 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.3082, Acc=0.195, 
2025-10-07 09:57:31,925 - training.trainer - INFO - Epoch 5, Step 20114: Loss=5.9638, Acc=0.216, 
2025-10-07 09:57:40,222 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.3456, Acc=0.138, 
2025-10-07 09:57:59,983 - training.trainer - INFO - Epoch 6/100 completed in 295.56s - Train Loss: 6.0320, Train Acc: 0.201, Val Loss: 5.9524, Val Acc: 0.207
2025-10-07 09:58:00,765 - training.trainer - INFO - New best model saved with validation loss: 5.9524
2025-10-07 09:58:00,766 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-10-07 09:58:09,498 - training.trainer - INFO - Epoch 6, Step 20397: Loss=5.9909, Acc=0.129, 
2025-10-07 09:58:17,896 - training.trainer - INFO - Epoch 6, Step 20497: Loss=5.9242, Acc=0.278, 
2025-10-07 09:58:26,401 - training.trainer - INFO - Epoch 6, Step 20597: Loss=5.7776, Acc=0.245, 
2025-10-07 09:58:34,974 - training.trainer - INFO - Epoch 6, Step 20697: Loss=5.7018, Acc=0.237, 
2025-10-07 09:58:43,458 - training.trainer - INFO - Epoch 6, Step 20797: Loss=6.2308, Acc=0.182, 
2025-10-07 09:58:52,037 - training.trainer - INFO - Epoch 6, Step 20897: Loss=6.2283, Acc=0.191, 
2025-10-07 09:59:00,566 - training.trainer - INFO - Epoch 6, Step 20997: Loss=5.8037, Acc=0.250, 
2025-10-07 09:59:08,987 - training.trainer - INFO - Epoch 6, Step 21097: Loss=6.2730, Acc=0.167, 
2025-10-07 09:59:17,351 - training.trainer - INFO - Epoch 6, Step 21197: Loss=5.7170, Acc=0.235, 
2025-10-07 09:59:25,825 - training.trainer - INFO - Epoch 6, Step 21297: Loss=5.5586, Acc=0.192, 
2025-10-07 09:59:34,201 - training.trainer - INFO - Epoch 6, Step 21397: Loss=4.7946, Acc=0.387, 
2025-10-07 09:59:42,564 - training.trainer - INFO - Epoch 6, Step 21497: Loss=6.9535, Acc=0.054, 
2025-10-07 09:59:50,981 - training.trainer - INFO - Epoch 6, Step 21597: Loss=7.2054, Acc=0.207, 
2025-10-07 09:59:59,247 - training.trainer - INFO - Epoch 6, Step 21697: Loss=5.8480, Acc=0.538, 
2025-10-07 10:00:07,511 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.1749, Acc=0.216, 
2025-10-07 10:00:15,771 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.5878, Acc=0.067, 
2025-10-07 10:00:24,176 - training.trainer - INFO - Epoch 6, Step 21997: Loss=4.8535, Acc=0.269, 
2025-10-07 10:00:32,515 - training.trainer - INFO - Epoch 6, Step 22097: Loss=6.2701, Acc=0.138, 
2025-10-07 10:00:40,760 - training.trainer - INFO - Epoch 6, Step 22197: Loss=5.1591, Acc=0.208, 
2025-10-07 10:00:49,003 - training.trainer - INFO - Epoch 6, Step 22297: Loss=6.3821, Acc=0.182, 
2025-10-07 10:00:57,299 - training.trainer - INFO - Epoch 6, Step 22397: Loss=6.3117, Acc=0.321, 
2025-10-07 10:01:05,586 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.7407, Acc=0.133, 
2025-10-07 10:01:13,839 - training.trainer - INFO - Epoch 6, Step 22597: Loss=6.0574, Acc=0.190, 
2025-10-07 10:01:22,142 - training.trainer - INFO - Epoch 6, Step 22697: Loss=4.6533, Acc=0.318, 
2025-10-07 10:01:30,457 - training.trainer - INFO - Epoch 6, Step 22797: Loss=5.5609, Acc=0.273, 
2025-10-07 10:01:38,840 - training.trainer - INFO - Epoch 6, Step 22897: Loss=6.3283, Acc=0.136, 
2025-10-07 10:01:47,223 - training.trainer - INFO - Epoch 6, Step 22997: Loss=4.4869, Acc=0.238, 
2025-10-07 10:01:55,550 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.3761, Acc=0.108, 
2025-10-07 10:02:03,939 - training.trainer - INFO - Epoch 6, Step 23197: Loss=5.5215, Acc=0.192, 
2025-10-07 10:02:12,117 - training.trainer - INFO - Epoch 6, Step 23297: Loss=6.5448, Acc=0.167, 
2025-10-07 10:02:20,381 - training.trainer - INFO - Epoch 6, Step 23397: Loss=5.6926, Acc=0.280, 
2025-10-07 10:02:28,649 - training.trainer - INFO - Epoch 6, Step 23497: Loss=5.6141, Acc=0.150, 
2025-10-07 10:02:36,995 - training.trainer - INFO - Epoch 6, Step 23597: Loss=5.9000, Acc=0.179, 
2025-10-07 10:02:56,808 - training.trainer - INFO - Epoch 7/100 completed in 296.04s - Train Loss: 5.9881, Train Acc: 0.207, Val Loss: 5.9179, Val Acc: 0.217
2025-10-07 10:02:57,501 - training.trainer - INFO - New best model saved with validation loss: 5.9179
2025-10-07 10:02:57,503 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-10-07 10:03:06,280 - training.trainer - INFO - Epoch 7, Step 23780: Loss=5.6436, Acc=0.280, 
2025-10-07 10:03:14,848 - training.trainer - INFO - Epoch 7, Step 23880: Loss=5.5564, Acc=0.348, 
2025-10-07 10:03:23,312 - training.trainer - INFO - Epoch 7, Step 23980: Loss=5.9156, Acc=0.208, 
2025-10-07 10:03:31,798 - training.trainer - INFO - Epoch 7, Step 24080: Loss=6.6392, Acc=0.170, 
2025-10-07 10:03:40,402 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.5411, Acc=0.171, 
2025-10-07 10:03:48,791 - training.trainer - INFO - Epoch 7, Step 24280: Loss=6.1891, Acc=0.214, 
2025-10-07 10:03:57,127 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.2850, Acc=0.130, 
2025-10-07 10:04:05,600 - training.trainer - INFO - Epoch 7, Step 24480: Loss=5.7361, Acc=0.226, 
2025-10-07 10:04:14,092 - training.trainer - INFO - Epoch 7, Step 24580: Loss=6.0864, Acc=0.152, 
2025-10-07 10:04:22,040 - training.trainer - INFO - Epoch 7, Step 24680: Loss=6.4049, Acc=0.250, 
2025-10-07 10:04:30,103 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.1990, Acc=0.149, 
2025-10-07 10:04:38,399 - training.trainer - INFO - Epoch 7, Step 24880: Loss=5.2495, Acc=0.368, 
2025-10-07 10:04:46,571 - training.trainer - INFO - Epoch 7, Step 24980: Loss=6.1045, Acc=0.093, 
2025-10-07 10:04:54,785 - training.trainer - INFO - Epoch 7, Step 25080: Loss=5.4484, Acc=0.257, 
2025-10-07 10:05:03,037 - training.trainer - INFO - Epoch 7, Step 25180: Loss=6.0453, Acc=0.182, 
2025-10-07 10:05:11,386 - training.trainer - INFO - Epoch 7, Step 25280: Loss=5.6367, Acc=0.240, 
2025-10-07 10:05:19,751 - training.trainer - INFO - Epoch 7, Step 25380: Loss=6.3212, Acc=0.194, 
2025-10-07 10:05:28,162 - training.trainer - INFO - Epoch 7, Step 25480: Loss=5.2844, Acc=0.333, 
2025-10-07 10:05:36,526 - training.trainer - INFO - Epoch 7, Step 25580: Loss=6.1019, Acc=0.145, 
2025-10-07 10:05:44,802 - training.trainer - INFO - Epoch 7, Step 25680: Loss=6.6272, Acc=0.189, 
2025-10-07 10:05:53,256 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.3095, Acc=0.162, 
2025-10-07 10:06:01,652 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.2639, Acc=0.194, 
2025-10-07 10:06:10,065 - training.trainer - INFO - Epoch 7, Step 25980: Loss=5.9888, Acc=0.156, 
2025-10-07 10:06:18,476 - training.trainer - INFO - Epoch 7, Step 26080: Loss=5.7250, Acc=0.273, 
2025-10-07 10:06:26,879 - training.trainer - INFO - Epoch 7, Step 26180: Loss=5.0407, Acc=0.214, 
2025-10-07 10:06:34,991 - training.trainer - INFO - Epoch 7, Step 26280: Loss=5.7828, Acc=0.296, 
2025-10-07 10:06:43,267 - training.trainer - INFO - Epoch 7, Step 26380: Loss=6.2230, Acc=0.159, 
2025-10-07 10:06:51,653 - training.trainer - INFO - Epoch 7, Step 26480: Loss=5.3430, Acc=0.235, 
2025-10-07 10:06:59,959 - training.trainer - INFO - Epoch 7, Step 26580: Loss=6.0402, Acc=0.188, 
2025-10-07 10:07:08,165 - training.trainer - INFO - Epoch 7, Step 26680: Loss=6.9391, Acc=0.133, 
2025-10-07 10:07:16,274 - training.trainer - INFO - Epoch 7, Step 26780: Loss=5.9599, Acc=0.250, 
2025-10-07 10:07:24,584 - training.trainer - INFO - Epoch 7, Step 26880: Loss=6.6949, Acc=0.133, 
2025-10-07 10:07:33,068 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.8033, Acc=0.235, 
2025-10-07 10:07:52,636 - training.trainer - INFO - Epoch 8/100 completed in 295.13s - Train Loss: 5.9437, Train Acc: 0.214, Val Loss: 5.8806, Val Acc: 0.215
2025-10-07 10:07:53,528 - training.trainer - INFO - New best model saved with validation loss: 5.8806
2025-10-07 10:07:53,528 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-10-07 10:08:02,398 - training.trainer - INFO - Epoch 8, Step 27163: Loss=6.3453, Acc=0.125, 
2025-10-07 10:08:10,911 - training.trainer - INFO - Epoch 8, Step 27263: Loss=5.8798, Acc=0.245, 
2025-10-07 10:08:19,269 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.9794, Acc=0.227, 
2025-10-07 10:08:27,532 - training.trainer - INFO - Epoch 8, Step 27463: Loss=5.6606, Acc=0.267, 
2025-10-07 10:08:35,830 - training.trainer - INFO - Epoch 8, Step 27563: Loss=5.2200, Acc=0.400, 
2025-10-07 10:08:44,110 - training.trainer - INFO - Epoch 8, Step 27663: Loss=6.2285, Acc=0.143, 
2025-10-07 10:08:52,488 - training.trainer - INFO - Epoch 8, Step 27763: Loss=5.7102, Acc=0.211, 
2025-10-07 10:09:00,979 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.0174, Acc=0.174, 
2025-10-07 10:09:09,494 - training.trainer - INFO - Epoch 8, Step 27963: Loss=5.1799, Acc=0.353, 
2025-10-07 10:09:18,141 - training.trainer - INFO - Epoch 8, Step 28063: Loss=6.5144, Acc=0.156, 
2025-10-07 10:09:26,564 - training.trainer - INFO - Epoch 8, Step 28163: Loss=6.0627, Acc=0.169, 
2025-10-07 10:09:35,015 - training.trainer - INFO - Epoch 8, Step 28263: Loss=6.1760, Acc=0.121, 
2025-10-07 10:09:43,489 - training.trainer - INFO - Epoch 8, Step 28363: Loss=5.8466, Acc=0.244, 
2025-10-07 10:09:51,756 - training.trainer - INFO - Epoch 8, Step 28463: Loss=5.6180, Acc=0.229, 
2025-10-07 10:10:00,139 - training.trainer - INFO - Epoch 8, Step 28563: Loss=5.7137, Acc=0.261, 
2025-10-07 10:10:08,402 - training.trainer - INFO - Epoch 8, Step 28663: Loss=5.5954, Acc=0.273, 
2025-10-07 10:10:16,667 - training.trainer - INFO - Epoch 8, Step 28763: Loss=5.7263, Acc=0.212, 
2025-10-07 10:10:24,995 - training.trainer - INFO - Epoch 8, Step 28863: Loss=6.4335, Acc=0.182, 
2025-10-07 10:10:33,264 - training.trainer - INFO - Epoch 8, Step 28963: Loss=6.8434, Acc=0.118, 
2025-10-07 10:10:41,636 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.5255, Acc=0.097, 
2025-10-07 10:10:49,989 - training.trainer - INFO - Epoch 8, Step 29163: Loss=5.0245, Acc=0.308, 
2025-10-07 10:10:58,336 - training.trainer - INFO - Epoch 8, Step 29263: Loss=5.5158, Acc=0.286, 
2025-10-07 10:11:06,728 - training.trainer - INFO - Epoch 8, Step 29363: Loss=6.0859, Acc=0.208, 
2025-10-07 10:11:15,128 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.3638, Acc=0.212, 
2025-10-07 10:11:23,534 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.9610, Acc=0.310, 
2025-10-07 10:11:31,900 - training.trainer - INFO - Epoch 8, Step 29663: Loss=5.6094, Acc=0.269, 
2025-10-07 10:11:40,352 - training.trainer - INFO - Epoch 8, Step 29763: Loss=6.7554, Acc=0.130, 
2025-10-07 10:11:48,683 - training.trainer - INFO - Epoch 8, Step 29863: Loss=5.9787, Acc=0.217, 
2025-10-07 10:11:57,173 - training.trainer - INFO - Epoch 8, Step 29963: Loss=5.4236, Acc=0.192, 
2025-10-07 10:12:05,553 - training.trainer - INFO - Epoch 8, Step 30063: Loss=5.5376, Acc=0.250, 
2025-10-07 10:12:13,984 - training.trainer - INFO - Epoch 8, Step 30163: Loss=6.5946, Acc=0.152, 
2025-10-07 10:12:22,417 - training.trainer - INFO - Epoch 8, Step 30263: Loss=6.1379, Acc=0.169, 
2025-10-07 10:12:30,775 - training.trainer - INFO - Epoch 8, Step 30363: Loss=7.1158, Acc=0.098, 
2025-10-07 10:12:51,044 - training.trainer - INFO - Epoch 9/100 completed in 297.52s - Train Loss: 5.9030, Train Acc: 0.219, Val Loss: 5.8479, Val Acc: 0.225
2025-10-07 10:12:51,910 - training.trainer - INFO - New best model saved with validation loss: 5.8479
2025-10-07 10:12:51,911 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-10-07 10:13:00,772 - training.trainer - INFO - Epoch 9, Step 30546: Loss=5.0066, Acc=0.231, 
2025-10-07 10:13:09,003 - training.trainer - INFO - Epoch 9, Step 30646: Loss=6.5367, Acc=0.180, 
2025-10-07 10:13:17,463 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.7119, Acc=0.128, 
2025-10-07 10:13:26,180 - training.trainer - INFO - Epoch 9, Step 30846: Loss=5.4858, Acc=0.320, 
2025-10-07 10:13:34,614 - training.trainer - INFO - Epoch 9, Step 30946: Loss=6.1240, Acc=0.250, 
2025-10-07 10:13:43,004 - training.trainer - INFO - Epoch 9, Step 31046: Loss=6.5136, Acc=0.130, 
2025-10-07 10:13:51,388 - training.trainer - INFO - Epoch 9, Step 31146: Loss=5.8910, Acc=0.300, 
2025-10-07 10:13:59,756 - training.trainer - INFO - Epoch 9, Step 31246: Loss=4.5010, Acc=0.250, 
2025-10-07 10:14:08,366 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.0156, Acc=0.185, 
2025-10-07 10:14:16,772 - training.trainer - INFO - Epoch 9, Step 31446: Loss=5.7382, Acc=0.227, 
2025-10-07 10:14:25,188 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.9673, Acc=0.182, 
2025-10-07 10:14:33,464 - training.trainer - INFO - Epoch 9, Step 31646: Loss=4.0082, Acc=0.385, 
2025-10-07 10:14:41,785 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.8550, Acc=0.229, 
2025-10-07 10:14:50,104 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.2372, Acc=0.196, 
2025-10-07 10:14:58,470 - training.trainer - INFO - Epoch 9, Step 31946: Loss=6.8420, Acc=0.200, 
2025-10-07 10:15:06,824 - training.trainer - INFO - Epoch 9, Step 32046: Loss=5.2057, Acc=0.250, 
2025-10-07 10:15:15,015 - training.trainer - INFO - Epoch 9, Step 32146: Loss=5.4770, Acc=0.197, 
2025-10-07 10:15:23,316 - training.trainer - INFO - Epoch 9, Step 32246: Loss=5.4797, Acc=0.353, 
2025-10-07 10:15:31,697 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.0848, Acc=0.220, 
2025-10-07 10:15:40,022 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.8772, Acc=0.143, 
2025-10-07 10:15:48,335 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.2692, Acc=0.192, 
2025-10-07 10:15:56,640 - training.trainer - INFO - Epoch 9, Step 32646: Loss=6.5951, Acc=0.204, 
2025-10-07 10:16:04,893 - training.trainer - INFO - Epoch 9, Step 32746: Loss=3.2894, Acc=0.417, 
2025-10-07 10:16:13,204 - training.trainer - INFO - Epoch 9, Step 32846: Loss=4.9015, Acc=0.333, 
2025-10-07 10:16:21,661 - training.trainer - INFO - Epoch 9, Step 32946: Loss=6.1287, Acc=0.125, 
2025-10-07 10:16:29,980 - training.trainer - INFO - Epoch 9, Step 33046: Loss=5.3543, Acc=0.250, 
2025-10-07 10:16:38,398 - training.trainer - INFO - Epoch 9, Step 33146: Loss=5.2610, Acc=0.298, 
2025-10-07 10:16:46,873 - training.trainer - INFO - Epoch 9, Step 33246: Loss=6.9338, Acc=0.120, 
2025-10-07 10:16:55,254 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.6580, Acc=0.169, 
2025-10-07 10:17:03,607 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.3337, Acc=0.200, 
2025-10-07 10:17:11,848 - training.trainer - INFO - Epoch 9, Step 33546: Loss=6.0750, Acc=0.212, 
2025-10-07 10:17:20,204 - training.trainer - INFO - Epoch 9, Step 33646: Loss=5.5487, Acc=0.182, 
2025-10-07 10:17:28,523 - training.trainer - INFO - Epoch 9, Step 33746: Loss=6.7238, Acc=0.159, 
2025-10-07 10:17:48,954 - training.trainer - INFO - Epoch 10/100 completed in 297.04s - Train Loss: 5.8806, Train Acc: 0.222, Val Loss: 5.8326, Val Acc: 0.229
2025-10-07 10:17:49,307 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-07 10:17:50,101 - training.trainer - INFO - New best model saved with validation loss: 5.8326
2025-10-07 10:17:50,101 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-07 10:17:58,712 - training.trainer - INFO - Epoch 10, Step 33929: Loss=6.1640, Acc=0.221, 
2025-10-07 10:18:07,029 - training.trainer - INFO - Epoch 10, Step 34029: Loss=4.9947, Acc=0.391, 
2025-10-07 10:18:15,287 - training.trainer - INFO - Epoch 10, Step 34129: Loss=5.6525, Acc=0.244, 
2025-10-07 10:18:23,543 - training.trainer - INFO - Epoch 10, Step 34229: Loss=6.1049, Acc=0.271, 
2025-10-07 10:18:31,826 - training.trainer - INFO - Epoch 10, Step 34329: Loss=5.7257, Acc=0.250, 
2025-10-07 10:18:40,139 - training.trainer - INFO - Epoch 10, Step 34429: Loss=5.2025, Acc=0.267, 
2025-10-07 10:18:48,496 - training.trainer - INFO - Epoch 10, Step 34529: Loss=4.3361, Acc=0.333, 
2025-10-07 10:18:56,965 - training.trainer - INFO - Epoch 10, Step 34629: Loss=6.0253, Acc=0.200, 
2025-10-07 10:19:05,411 - training.trainer - INFO - Epoch 10, Step 34729: Loss=6.3300, Acc=0.226, 
2025-10-07 10:19:13,823 - training.trainer - INFO - Epoch 10, Step 34829: Loss=6.2748, Acc=0.258, 
2025-10-07 10:19:22,258 - training.trainer - INFO - Epoch 10, Step 34929: Loss=6.6312, Acc=0.119, 
2025-10-07 10:19:30,713 - training.trainer - INFO - Epoch 10, Step 35029: Loss=6.2681, Acc=0.141, 
2025-10-07 10:19:39,081 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.6067, Acc=0.125, 
2025-10-07 10:19:47,433 - training.trainer - INFO - Epoch 10, Step 35229: Loss=5.8440, Acc=0.193, 
2025-10-07 10:19:55,741 - training.trainer - INFO - Epoch 10, Step 35329: Loss=4.6531, Acc=0.333, 
2025-10-07 10:20:04,146 - training.trainer - INFO - Epoch 10, Step 35429: Loss=5.6222, Acc=0.174, 
2025-10-07 10:20:12,318 - training.trainer - INFO - Epoch 10, Step 35529: Loss=4.4069, Acc=0.235, 
2025-10-07 10:20:20,676 - training.trainer - INFO - Epoch 10, Step 35629: Loss=5.8491, Acc=0.178, 
2025-10-07 10:20:29,162 - training.trainer - INFO - Epoch 10, Step 35729: Loss=6.4811, Acc=0.198, 
2025-10-07 10:20:37,468 - training.trainer - INFO - Epoch 10, Step 35829: Loss=5.8603, Acc=0.200, 
2025-10-07 10:20:45,663 - training.trainer - INFO - Epoch 10, Step 35929: Loss=6.0367, Acc=0.250, 
2025-10-07 10:20:54,004 - training.trainer - INFO - Epoch 10, Step 36029: Loss=5.6874, Acc=0.216, 
2025-10-07 10:21:02,244 - training.trainer - INFO - Epoch 10, Step 36129: Loss=7.0716, Acc=0.250, 
2025-10-07 10:21:10,574 - training.trainer - INFO - Epoch 10, Step 36229: Loss=5.6692, Acc=0.233, 
2025-10-07 10:21:18,794 - training.trainer - INFO - Epoch 10, Step 36329: Loss=5.6471, Acc=0.294, 
2025-10-07 10:21:26,996 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.0473, Acc=0.176, 
2025-10-07 10:21:35,614 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.3398, Acc=0.205, 
2025-10-07 10:21:43,910 - training.trainer - INFO - Epoch 10, Step 36629: Loss=6.2992, Acc=0.175, 
2025-10-07 10:21:52,265 - training.trainer - INFO - Epoch 10, Step 36729: Loss=5.9139, Acc=0.185, 
2025-10-07 10:22:00,475 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.4760, Acc=0.189, 
2025-10-07 10:22:08,739 - training.trainer - INFO - Epoch 10, Step 36929: Loss=6.4148, Acc=0.217, 
2025-10-07 10:22:17,306 - training.trainer - INFO - Epoch 10, Step 37029: Loss=6.2981, Acc=0.174, 
2025-10-07 10:22:25,559 - training.trainer - INFO - Epoch 10, Step 37129: Loss=5.5698, Acc=0.250, 
2025-10-07 10:22:46,404 - training.trainer - INFO - Epoch 11/100 completed in 296.30s - Train Loss: 5.8519, Train Acc: 0.226, Val Loss: 5.8083, Val Acc: 0.233
2025-10-07 10:22:47,280 - training.trainer - INFO - New best model saved with validation loss: 5.8083
2025-10-07 10:22:47,281 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-10-07 10:22:56,089 - training.trainer - INFO - Epoch 11, Step 37312: Loss=6.1496, Acc=0.190, 
2025-10-07 10:23:04,582 - training.trainer - INFO - Epoch 11, Step 37412: Loss=5.4470, Acc=0.268, 
2025-10-07 10:23:12,940 - training.trainer - INFO - Epoch 11, Step 37512: Loss=5.0095, Acc=0.304, 
2025-10-07 10:23:21,266 - training.trainer - INFO - Epoch 11, Step 37612: Loss=5.8425, Acc=0.224, 
2025-10-07 10:23:29,621 - training.trainer - INFO - Epoch 11, Step 37712: Loss=5.2670, Acc=0.343, 
2025-10-07 10:23:38,187 - training.trainer - INFO - Epoch 11, Step 37812: Loss=6.0337, Acc=0.233, 
2025-10-07 10:23:46,829 - training.trainer - INFO - Epoch 11, Step 37912: Loss=5.6647, Acc=0.229, 
2025-10-07 10:23:55,178 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.9848, Acc=0.125, 
2025-10-07 10:24:03,480 - training.trainer - INFO - Epoch 11, Step 38112: Loss=5.6339, Acc=0.350, 
2025-10-07 10:24:11,849 - training.trainer - INFO - Epoch 11, Step 38212: Loss=6.2169, Acc=0.100, 
2025-10-07 10:24:20,137 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.2503, Acc=0.102, 
2025-10-07 10:24:28,354 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.6738, Acc=0.282, 
2025-10-07 10:24:36,659 - training.trainer - INFO - Epoch 11, Step 38512: Loss=6.5245, Acc=0.217, 
2025-10-07 10:24:45,026 - training.trainer - INFO - Epoch 11, Step 38612: Loss=5.2143, Acc=0.273, 
2025-10-07 10:24:53,265 - training.trainer - INFO - Epoch 11, Step 38712: Loss=5.7453, Acc=0.182, 
2025-10-07 10:25:01,486 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.3274, Acc=0.286, 
2025-10-07 10:25:09,749 - training.trainer - INFO - Epoch 11, Step 38912: Loss=4.9238, Acc=0.321, 
2025-10-07 10:25:18,163 - training.trainer - INFO - Epoch 11, Step 39012: Loss=5.5904, Acc=0.256, 
2025-10-07 10:25:26,409 - training.trainer - INFO - Epoch 11, Step 39112: Loss=5.2829, Acc=0.286, 
2025-10-07 10:25:34,690 - training.trainer - INFO - Epoch 11, Step 39212: Loss=6.4519, Acc=0.161, 
2025-10-07 10:25:42,942 - training.trainer - INFO - Epoch 11, Step 39312: Loss=6.1000, Acc=0.189, 
2025-10-07 10:25:51,268 - training.trainer - INFO - Epoch 11, Step 39412: Loss=5.3542, Acc=0.286, 
2025-10-07 10:25:59,583 - training.trainer - INFO - Epoch 11, Step 39512: Loss=6.0338, Acc=0.214, 
2025-10-07 10:26:08,091 - training.trainer - INFO - Epoch 11, Step 39612: Loss=5.6326, Acc=0.240, 
2025-10-07 10:26:16,406 - training.trainer - INFO - Epoch 11, Step 39712: Loss=4.5137, Acc=0.333, 
2025-10-07 10:26:24,719 - training.trainer - INFO - Epoch 11, Step 39812: Loss=5.4073, Acc=0.276, 
2025-10-07 10:26:32,991 - training.trainer - INFO - Epoch 11, Step 39912: Loss=5.3202, Acc=0.243, 
2025-10-07 10:26:41,274 - training.trainer - INFO - Epoch 11, Step 40012: Loss=5.6883, Acc=0.128, 
2025-10-07 10:26:49,616 - training.trainer - INFO - Epoch 11, Step 40112: Loss=5.8980, Acc=0.152, 
2025-10-07 10:26:57,847 - training.trainer - INFO - Epoch 11, Step 40212: Loss=6.5568, Acc=0.292, 
2025-10-07 10:27:06,198 - training.trainer - INFO - Epoch 11, Step 40312: Loss=6.0625, Acc=0.167, 
2025-10-07 10:27:14,589 - training.trainer - INFO - Epoch 11, Step 40412: Loss=6.3092, Acc=0.179, 
2025-10-07 10:27:22,972 - training.trainer - INFO - Epoch 11, Step 40512: Loss=6.1951, Acc=0.190, 
2025-10-07 10:27:42,792 - training.trainer - INFO - Epoch 12/100 completed in 295.51s - Train Loss: 5.8296, Train Acc: 0.230, Val Loss: 5.7949, Val Acc: 0.236
2025-10-07 10:27:43,615 - training.trainer - INFO - New best model saved with validation loss: 5.7949
2025-10-07 10:27:43,615 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-10-07 10:27:51,180 - training.trainer - INFO - Epoch 12, Step 40695: Loss=6.0357, Acc=0.200, 
2025-10-07 10:27:58,348 - training.trainer - INFO - Epoch 12, Step 40795: Loss=6.0637, Acc=0.200, 
2025-10-07 10:28:05,401 - training.trainer - INFO - Epoch 12, Step 40895: Loss=6.2783, Acc=0.159, 
2025-10-07 10:28:12,586 - training.trainer - INFO - Epoch 12, Step 40995: Loss=6.4989, Acc=0.217, 
2025-10-07 10:28:19,674 - training.trainer - INFO - Epoch 12, Step 41095: Loss=7.4949, Acc=0.161, 
2025-10-07 10:28:26,741 - training.trainer - INFO - Epoch 12, Step 41195: Loss=5.3762, Acc=0.269, 
2025-10-07 10:28:34,114 - training.trainer - INFO - Epoch 12, Step 41295: Loss=6.2649, Acc=0.173, 
2025-10-07 10:28:41,223 - training.trainer - INFO - Epoch 12, Step 41395: Loss=6.6287, Acc=0.188, 
2025-10-07 10:28:48,478 - training.trainer - INFO - Epoch 12, Step 41495: Loss=6.4623, Acc=0.104, 
2025-10-07 10:28:55,487 - training.trainer - INFO - Epoch 12, Step 41595: Loss=5.2858, Acc=0.278, 
2025-10-07 10:29:02,926 - training.trainer - INFO - Epoch 12, Step 41695: Loss=5.1500, Acc=0.300, 
2025-10-07 10:29:10,101 - training.trainer - INFO - Epoch 12, Step 41795: Loss=5.9108, Acc=0.250, 
2025-10-07 10:29:18,006 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.4981, Acc=0.357, 
2025-10-07 10:29:25,633 - training.trainer - INFO - Epoch 12, Step 41995: Loss=5.7251, Acc=0.318, 
2025-10-07 10:29:32,729 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.3426, Acc=0.163, 
2025-10-07 10:29:40,181 - training.trainer - INFO - Epoch 12, Step 42195: Loss=5.7496, Acc=0.208, 
2025-10-07 10:29:47,464 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.8288, Acc=0.217, 
2025-10-07 10:29:55,379 - training.trainer - INFO - Epoch 12, Step 42395: Loss=5.5554, Acc=0.160, 
2025-10-07 10:30:02,895 - training.trainer - INFO - Epoch 12, Step 42495: Loss=5.5408, Acc=0.195, 
2025-10-07 10:30:10,677 - training.trainer - INFO - Epoch 12, Step 42595: Loss=5.7325, Acc=0.207, 
2025-10-07 10:30:18,130 - training.trainer - INFO - Epoch 12, Step 42695: Loss=6.0797, Acc=0.154, 
2025-10-07 10:30:26,005 - training.trainer - INFO - Epoch 12, Step 42795: Loss=6.3360, Acc=0.182, 
2025-10-07 10:30:33,318 - training.trainer - INFO - Epoch 12, Step 42895: Loss=5.8944, Acc=0.214, 
2025-10-07 10:30:41,387 - training.trainer - INFO - Epoch 12, Step 42995: Loss=6.2688, Acc=0.231, 
2025-10-07 10:30:49,862 - training.trainer - INFO - Epoch 12, Step 43095: Loss=6.3114, Acc=0.254, 
2025-10-07 10:30:58,302 - training.trainer - INFO - Epoch 12, Step 43195: Loss=6.1876, Acc=0.261, 
2025-10-07 10:31:06,695 - training.trainer - INFO - Epoch 12, Step 43295: Loss=5.9386, Acc=0.170, 
2025-10-07 10:31:15,207 - training.trainer - INFO - Epoch 12, Step 43395: Loss=4.8658, Acc=0.471, 
2025-10-07 10:31:23,546 - training.trainer - INFO - Epoch 12, Step 43495: Loss=6.1724, Acc=0.182, 
2025-10-07 10:31:31,921 - training.trainer - INFO - Epoch 12, Step 43595: Loss=5.5115, Acc=0.231, 
2025-10-07 10:31:40,449 - training.trainer - INFO - Epoch 12, Step 43695: Loss=6.4868, Acc=0.167, 
2025-10-07 10:31:48,842 - training.trainer - INFO - Epoch 12, Step 43795: Loss=6.2801, Acc=0.171, 
2025-10-07 10:31:57,243 - training.trainer - INFO - Epoch 12, Step 43895: Loss=6.0532, Acc=0.245, 
2025-10-07 10:32:17,370 - training.trainer - INFO - Epoch 13/100 completed in 273.75s - Train Loss: 5.8008, Train Acc: 0.235, Val Loss: 5.7783, Val Acc: 0.235
2025-10-07 10:32:18,123 - training.trainer - INFO - New best model saved with validation loss: 5.7783
2025-10-07 10:32:18,124 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-10-07 10:32:25,684 - training.trainer - INFO - Epoch 13, Step 44078: Loss=5.5955, Acc=0.286, 
2025-10-07 10:32:32,929 - training.trainer - INFO - Epoch 13, Step 44178: Loss=6.2242, Acc=0.127, 
2025-10-07 10:32:40,625 - training.trainer - INFO - Epoch 13, Step 44278: Loss=4.8704, Acc=0.364, 
2025-10-07 10:32:48,491 - training.trainer - INFO - Epoch 13, Step 44378: Loss=4.2479, Acc=0.409, 
2025-10-07 10:32:55,795 - training.trainer - INFO - Epoch 13, Step 44478: Loss=6.0122, Acc=0.227, 
2025-10-07 10:33:03,001 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.5202, Acc=0.258, 
2025-10-07 10:33:10,198 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.7460, Acc=0.230, 
2025-10-07 10:33:17,928 - training.trainer - INFO - Epoch 13, Step 44778: Loss=4.9920, Acc=0.250, 
2025-10-07 10:33:26,208 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.6592, Acc=0.222, 
2025-10-07 10:33:34,475 - training.trainer - INFO - Epoch 13, Step 44978: Loss=6.4278, Acc=0.103, 
2025-10-07 10:33:42,804 - training.trainer - INFO - Epoch 13, Step 45078: Loss=5.2397, Acc=0.364, 
2025-10-07 10:33:51,245 - training.trainer - INFO - Epoch 13, Step 45178: Loss=6.2651, Acc=0.222, 
2025-10-07 10:33:59,735 - training.trainer - INFO - Epoch 13, Step 45278: Loss=6.1432, Acc=0.255, 
2025-10-07 10:34:08,009 - training.trainer - INFO - Epoch 13, Step 45378: Loss=5.5742, Acc=0.333, 
2025-10-07 10:34:16,512 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.9594, Acc=0.250, 
2025-10-07 10:34:24,918 - training.trainer - INFO - Epoch 13, Step 45578: Loss=6.0466, Acc=0.184, 
2025-10-07 10:34:33,226 - training.trainer - INFO - Epoch 13, Step 45678: Loss=5.7944, Acc=0.190, 
2025-10-07 10:34:41,435 - training.trainer - INFO - Epoch 13, Step 45778: Loss=5.4732, Acc=0.215, 
2025-10-07 10:34:49,827 - training.trainer - INFO - Epoch 13, Step 45878: Loss=6.2250, Acc=0.227, 
2025-10-07 10:34:58,374 - training.trainer - INFO - Epoch 13, Step 45978: Loss=5.7492, Acc=0.227, 
2025-10-07 10:35:06,798 - training.trainer - INFO - Epoch 13, Step 46078: Loss=6.6767, Acc=0.176, 
2025-10-07 10:35:15,128 - training.trainer - INFO - Epoch 13, Step 46178: Loss=5.8342, Acc=0.255, 
2025-10-07 10:35:23,584 - training.trainer - INFO - Epoch 13, Step 46278: Loss=4.8009, Acc=0.333, 
2025-10-07 10:35:31,801 - training.trainer - INFO - Epoch 13, Step 46378: Loss=3.8301, Acc=0.476, 
2025-10-07 10:35:40,306 - training.trainer - INFO - Epoch 13, Step 46478: Loss=5.1927, Acc=0.211, 
2025-10-07 10:35:48,750 - training.trainer - INFO - Epoch 13, Step 46578: Loss=4.5117, Acc=0.400, 
2025-10-07 10:35:57,151 - training.trainer - INFO - Epoch 13, Step 46678: Loss=5.4623, Acc=0.161, 
2025-10-07 10:36:05,760 - training.trainer - INFO - Epoch 13, Step 46778: Loss=4.4714, Acc=0.350, 
2025-10-07 10:36:14,164 - training.trainer - INFO - Epoch 13, Step 46878: Loss=4.6898, Acc=0.308, 
2025-10-07 10:36:22,555 - training.trainer - INFO - Epoch 13, Step 46978: Loss=4.6828, Acc=0.294, 
2025-10-07 10:36:30,998 - training.trainer - INFO - Epoch 13, Step 47078: Loss=5.3551, Acc=0.348, 
2025-10-07 10:36:39,269 - training.trainer - INFO - Epoch 13, Step 47178: Loss=5.8291, Acc=0.235, 
2025-10-07 10:36:47,809 - training.trainer - INFO - Epoch 13, Step 47278: Loss=6.2571, Acc=0.209, 
2025-10-07 10:37:07,271 - training.trainer - INFO - Epoch 14/100 completed in 289.15s - Train Loss: 5.7820, Train Acc: 0.238, Val Loss: 5.7744, Val Acc: 0.241
2025-10-07 10:37:08,155 - training.trainer - INFO - New best model saved with validation loss: 5.7744
2025-10-07 10:37:08,155 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-10-07 10:37:15,880 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.6909, Acc=0.246, 
2025-10-07 10:37:23,078 - training.trainer - INFO - Epoch 14, Step 47561: Loss=6.0208, Acc=0.162, 
2025-10-07 10:37:31,381 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.5533, Acc=0.243, 
2025-10-07 10:37:39,862 - training.trainer - INFO - Epoch 14, Step 47761: Loss=6.3136, Acc=0.167, 
2025-10-07 10:37:48,384 - training.trainer - INFO - Epoch 14, Step 47861: Loss=5.6238, Acc=0.262, 
2025-10-07 10:37:56,674 - training.trainer - INFO - Epoch 14, Step 47961: Loss=5.5270, Acc=0.222, 
2025-10-07 10:38:04,933 - training.trainer - INFO - Epoch 14, Step 48061: Loss=5.6505, Acc=0.233, 
2025-10-07 10:38:13,276 - training.trainer - INFO - Epoch 14, Step 48161: Loss=5.8951, Acc=0.152, 
2025-10-07 10:38:21,940 - training.trainer - INFO - Epoch 14, Step 48261: Loss=5.9238, Acc=0.279, 
2025-10-07 10:38:30,489 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.4660, Acc=0.200, 
2025-10-07 10:38:38,972 - training.trainer - INFO - Epoch 14, Step 48461: Loss=6.4081, Acc=0.197, 
2025-10-07 10:38:47,398 - training.trainer - INFO - Epoch 14, Step 48561: Loss=5.2774, Acc=0.250, 
2025-10-07 10:38:55,892 - training.trainer - INFO - Epoch 14, Step 48661: Loss=6.6753, Acc=0.258, 
2025-10-07 10:39:04,420 - training.trainer - INFO - Epoch 14, Step 48761: Loss=5.2856, Acc=0.267, 
2025-10-07 10:39:12,968 - training.trainer - INFO - Epoch 14, Step 48861: Loss=6.2939, Acc=0.153, 
2025-10-07 10:39:21,432 - training.trainer - INFO - Epoch 14, Step 48961: Loss=6.6911, Acc=0.190, 
2025-10-07 10:39:29,659 - training.trainer - INFO - Epoch 14, Step 49061: Loss=4.8739, Acc=0.312, 
2025-10-07 10:39:38,107 - training.trainer - INFO - Epoch 14, Step 49161: Loss=4.8272, Acc=0.241, 
2025-10-07 10:39:46,413 - training.trainer - INFO - Epoch 14, Step 49261: Loss=5.9063, Acc=0.222, 
2025-10-07 10:39:54,624 - training.trainer - INFO - Epoch 14, Step 49361: Loss=6.3648, Acc=0.258, 
2025-10-07 10:40:03,026 - training.trainer - INFO - Epoch 14, Step 49461: Loss=5.9551, Acc=0.205, 
2025-10-07 10:40:11,530 - training.trainer - INFO - Epoch 14, Step 49561: Loss=6.1912, Acc=0.170, 
2025-10-07 10:40:19,900 - training.trainer - INFO - Epoch 14, Step 49661: Loss=6.7707, Acc=0.123, 
2025-10-07 10:40:28,144 - training.trainer - INFO - Epoch 14, Step 49761: Loss=5.5085, Acc=0.211, 
2025-10-07 10:40:36,527 - training.trainer - INFO - Epoch 14, Step 49861: Loss=5.8933, Acc=0.294, 
2025-10-07 10:40:44,830 - training.trainer - INFO - Epoch 14, Step 49961: Loss=5.9278, Acc=0.170, 
2025-10-07 10:40:53,096 - training.trainer - INFO - Epoch 14, Step 50061: Loss=6.1570, Acc=0.161, 
2025-10-07 10:41:01,291 - training.trainer - INFO - Epoch 14, Step 50161: Loss=5.4306, Acc=0.158, 
2025-10-07 10:41:09,517 - training.trainer - INFO - Epoch 14, Step 50261: Loss=6.7643, Acc=0.138, 
2025-10-07 10:41:17,723 - training.trainer - INFO - Epoch 14, Step 50361: Loss=4.8996, Acc=0.429, 
2025-10-07 10:41:25,936 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.9516, Acc=0.314, 
2025-10-07 10:41:34,214 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.2221, Acc=0.233, 
2025-10-07 10:41:42,426 - training.trainer - INFO - Epoch 14, Step 50661: Loss=5.8436, Acc=0.229, 
2025-10-07 10:42:02,074 - training.trainer - INFO - Epoch 15/100 completed in 293.92s - Train Loss: 5.7608, Train Acc: 0.239, Val Loss: 5.7623, Val Acc: 0.236
2025-10-07 10:42:02,534 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-07 10:42:03,313 - training.trainer - INFO - New best model saved with validation loss: 5.7623
2025-10-07 10:42:03,314 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-07 10:42:12,311 - training.trainer - INFO - Epoch 15, Step 50844: Loss=6.5779, Acc=0.185, 
2025-10-07 10:42:20,590 - training.trainer - INFO - Epoch 15, Step 50944: Loss=4.9619, Acc=0.263, 
2025-10-07 10:42:27,707 - training.trainer - INFO - Epoch 15, Step 51044: Loss=5.6463, Acc=0.242, 
2025-10-07 10:42:34,818 - training.trainer - INFO - Epoch 15, Step 51144: Loss=6.4789, Acc=0.169, 
2025-10-07 10:42:41,948 - training.trainer - INFO - Epoch 15, Step 51244: Loss=5.6567, Acc=0.233, 
2025-10-07 10:42:49,584 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.3725, Acc=0.245, 
2025-10-07 10:42:57,955 - training.trainer - INFO - Epoch 15, Step 51444: Loss=5.9072, Acc=0.196, 
2025-10-07 10:43:06,453 - training.trainer - INFO - Epoch 15, Step 51544: Loss=5.2836, Acc=0.414, 
2025-10-07 10:43:14,838 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.9765, Acc=0.292, 
2025-10-07 10:43:23,256 - training.trainer - INFO - Epoch 15, Step 51744: Loss=5.4113, Acc=0.312, 
2025-10-07 10:43:31,701 - training.trainer - INFO - Epoch 15, Step 51844: Loss=6.1061, Acc=0.224, 
2025-10-07 10:43:40,102 - training.trainer - INFO - Epoch 15, Step 51944: Loss=5.9312, Acc=0.179, 
2025-10-07 10:43:48,571 - training.trainer - INFO - Epoch 15, Step 52044: Loss=6.0032, Acc=0.255, 
2025-10-07 10:43:57,019 - training.trainer - INFO - Epoch 15, Step 52144: Loss=5.6114, Acc=0.167, 
2025-10-07 10:44:05,409 - training.trainer - INFO - Epoch 15, Step 52244: Loss=6.1166, Acc=0.162, 
2025-10-07 10:44:13,733 - training.trainer - INFO - Epoch 15, Step 52344: Loss=5.1964, Acc=0.312, 
2025-10-07 10:44:22,189 - training.trainer - INFO - Epoch 15, Step 52444: Loss=6.3310, Acc=0.146, 
2025-10-07 10:44:30,528 - training.trainer - INFO - Epoch 15, Step 52544: Loss=5.3060, Acc=0.286, 
2025-10-07 10:44:38,943 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.3209, Acc=0.326, 
2025-10-07 10:44:47,337 - training.trainer - INFO - Epoch 15, Step 52744: Loss=6.5308, Acc=0.176, 
2025-10-07 10:44:55,802 - training.trainer - INFO - Epoch 15, Step 52844: Loss=5.1932, Acc=0.333, 
2025-10-07 10:45:04,221 - training.trainer - INFO - Epoch 15, Step 52944: Loss=4.7908, Acc=0.250, 
2025-10-07 10:45:12,668 - training.trainer - INFO - Epoch 15, Step 53044: Loss=5.1237, Acc=0.407, 
2025-10-07 10:45:21,122 - training.trainer - INFO - Epoch 15, Step 53144: Loss=5.7982, Acc=0.286, 
2025-10-07 10:45:29,439 - training.trainer - INFO - Epoch 15, Step 53244: Loss=6.0215, Acc=0.175, 
2025-10-07 10:45:37,737 - training.trainer - INFO - Epoch 15, Step 53344: Loss=5.7688, Acc=0.310, 
2025-10-07 10:45:46,196 - training.trainer - INFO - Epoch 15, Step 53444: Loss=6.5125, Acc=0.208, 
2025-10-07 10:45:54,662 - training.trainer - INFO - Epoch 15, Step 53544: Loss=4.7700, Acc=0.406, 
2025-10-07 10:46:02,960 - training.trainer - INFO - Epoch 15, Step 53644: Loss=6.3619, Acc=0.185, 
2025-10-07 10:46:11,179 - training.trainer - INFO - Epoch 15, Step 53744: Loss=6.0469, Acc=0.304, 
2025-10-07 10:46:19,372 - training.trainer - INFO - Epoch 15, Step 53844: Loss=4.9714, Acc=0.375, 
2025-10-07 10:46:27,602 - training.trainer - INFO - Epoch 15, Step 53944: Loss=6.0450, Acc=0.231, 
2025-10-07 10:46:35,904 - training.trainer - INFO - Epoch 15, Step 54044: Loss=5.8040, Acc=0.207, 
2025-10-07 10:46:56,355 - training.trainer - INFO - Epoch 16/100 completed in 293.04s - Train Loss: 5.7395, Train Acc: 0.244, Val Loss: 5.7477, Val Acc: 0.245
2025-10-07 10:46:57,146 - training.trainer - INFO - New best model saved with validation loss: 5.7477
2025-10-07 10:46:57,146 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-10-07 10:47:06,112 - training.trainer - INFO - Epoch 16, Step 54227: Loss=6.7527, Acc=0.158, 
2025-10-07 10:47:14,440 - training.trainer - INFO - Epoch 16, Step 54327: Loss=6.1141, Acc=0.176, 
2025-10-07 10:47:22,735 - training.trainer - INFO - Epoch 16, Step 54427: Loss=6.3904, Acc=0.200, 
2025-10-07 10:47:31,026 - training.trainer - INFO - Epoch 16, Step 54527: Loss=6.3401, Acc=0.135, 
2025-10-07 10:47:39,370 - training.trainer - INFO - Epoch 16, Step 54627: Loss=5.4064, Acc=0.270, 
2025-10-07 10:47:47,676 - training.trainer - INFO - Epoch 16, Step 54727: Loss=5.8423, Acc=0.208, 
2025-10-07 10:47:55,932 - training.trainer - INFO - Epoch 16, Step 54827: Loss=5.9906, Acc=0.171, 
2025-10-07 10:48:04,206 - training.trainer - INFO - Epoch 16, Step 54927: Loss=5.3880, Acc=0.233, 
2025-10-07 10:48:12,530 - training.trainer - INFO - Epoch 16, Step 55027: Loss=5.5466, Acc=0.333, 
2025-10-07 10:48:20,917 - training.trainer - INFO - Epoch 16, Step 55127: Loss=5.3134, Acc=0.182, 
2025-10-07 10:48:29,226 - training.trainer - INFO - Epoch 16, Step 55227: Loss=6.4714, Acc=0.194, 
2025-10-07 10:48:37,527 - training.trainer - INFO - Epoch 16, Step 55327: Loss=5.4039, Acc=0.324, 
2025-10-07 10:48:45,936 - training.trainer - INFO - Epoch 16, Step 55427: Loss=4.6167, Acc=0.222, 
2025-10-07 10:48:54,236 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.0500, Acc=0.235, 
2025-10-07 10:49:02,540 - training.trainer - INFO - Epoch 16, Step 55627: Loss=6.6221, Acc=0.224, 
2025-10-07 10:49:10,771 - training.trainer - INFO - Epoch 16, Step 55727: Loss=5.7686, Acc=0.154, 
2025-10-07 10:49:19,117 - training.trainer - INFO - Epoch 16, Step 55827: Loss=6.4927, Acc=0.250, 
2025-10-07 10:49:27,527 - training.trainer - INFO - Epoch 16, Step 55927: Loss=5.6373, Acc=0.241, 
2025-10-07 10:49:35,882 - training.trainer - INFO - Epoch 16, Step 56027: Loss=6.4729, Acc=0.173, 
2025-10-07 10:49:44,184 - training.trainer - INFO - Epoch 16, Step 56127: Loss=5.6834, Acc=0.232, 
2025-10-07 10:49:52,539 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.0978, Acc=0.242, 
2025-10-07 10:50:00,916 - training.trainer - INFO - Epoch 16, Step 56327: Loss=6.3275, Acc=0.137, 
2025-10-07 10:50:09,222 - training.trainer - INFO - Epoch 16, Step 56427: Loss=4.7354, Acc=0.378, 
2025-10-07 10:50:17,505 - training.trainer - INFO - Epoch 16, Step 56527: Loss=5.6273, Acc=0.286, 
2025-10-07 10:50:25,956 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.7751, Acc=0.227, 
2025-10-07 10:50:34,209 - training.trainer - INFO - Epoch 16, Step 56727: Loss=3.8324, Acc=0.394, 
2025-10-07 10:50:42,697 - training.trainer - INFO - Epoch 16, Step 56827: Loss=4.8904, Acc=0.352, 
2025-10-07 10:50:51,043 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.4096, Acc=0.222, 
2025-10-07 10:50:59,320 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.2555, Acc=0.333, 
2025-10-07 10:51:07,587 - training.trainer - INFO - Epoch 16, Step 57127: Loss=5.9551, Acc=0.300, 
2025-10-07 10:51:15,792 - training.trainer - INFO - Epoch 16, Step 57227: Loss=6.1488, Acc=0.190, 
2025-10-07 10:51:24,066 - training.trainer - INFO - Epoch 16, Step 57327: Loss=4.2031, Acc=0.457, 
2025-10-07 10:51:32,312 - training.trainer - INFO - Epoch 16, Step 57427: Loss=6.2147, Acc=0.231, 
2025-10-07 10:51:52,109 - training.trainer - INFO - Epoch 17/100 completed in 294.96s - Train Loss: 5.7191, Train Acc: 0.246, Val Loss: 5.7299, Val Acc: 0.247
2025-10-07 10:51:52,864 - training.trainer - INFO - New best model saved with validation loss: 5.7299
2025-10-07 10:51:52,864 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-10-07 10:52:00,500 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.0431, Acc=0.281, 
2025-10-07 10:52:08,384 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.7409, Acc=0.286, 
2025-10-07 10:52:16,590 - training.trainer - INFO - Epoch 17, Step 57810: Loss=5.6459, Acc=0.182, 
2025-10-07 10:52:24,965 - training.trainer - INFO - Epoch 17, Step 57910: Loss=5.2363, Acc=0.208, 
2025-10-07 10:52:33,311 - training.trainer - INFO - Epoch 17, Step 58010: Loss=5.2793, Acc=0.286, 
2025-10-07 10:52:41,643 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.4728, Acc=0.222, 
2025-10-07 10:52:49,990 - training.trainer - INFO - Epoch 17, Step 58210: Loss=6.0008, Acc=0.219, 
2025-10-07 10:52:58,359 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.2221, Acc=0.370, 
2025-10-07 10:53:06,689 - training.trainer - INFO - Epoch 17, Step 58410: Loss=5.0787, Acc=0.306, 
2025-10-07 10:53:14,909 - training.trainer - INFO - Epoch 17, Step 58510: Loss=6.4909, Acc=0.182, 
2025-10-07 10:53:23,262 - training.trainer - INFO - Epoch 17, Step 58610: Loss=5.6655, Acc=0.267, 
2025-10-07 10:53:31,554 - training.trainer - INFO - Epoch 17, Step 58710: Loss=5.6173, Acc=0.200, 
2025-10-07 10:53:39,909 - training.trainer - INFO - Epoch 17, Step 58810: Loss=5.5533, Acc=0.250, 
2025-10-07 10:53:48,512 - training.trainer - INFO - Epoch 17, Step 58910: Loss=5.7814, Acc=0.250, 
2025-10-07 10:53:56,998 - training.trainer - INFO - Epoch 17, Step 59010: Loss=6.0236, Acc=0.214, 
2025-10-07 10:54:05,536 - training.trainer - INFO - Epoch 17, Step 59110: Loss=5.3502, Acc=0.241, 
2025-10-07 10:54:14,056 - training.trainer - INFO - Epoch 17, Step 59210: Loss=5.5971, Acc=0.217, 
2025-10-07 10:54:22,572 - training.trainer - INFO - Epoch 17, Step 59310: Loss=4.8360, Acc=0.286, 
2025-10-07 10:54:31,061 - training.trainer - INFO - Epoch 17, Step 59410: Loss=4.8676, Acc=0.389, 
2025-10-07 10:54:39,482 - training.trainer - INFO - Epoch 17, Step 59510: Loss=5.2574, Acc=0.262, 
2025-10-07 10:54:47,870 - training.trainer - INFO - Epoch 17, Step 59610: Loss=5.5902, Acc=0.222, 
2025-10-07 10:54:56,341 - training.trainer - INFO - Epoch 17, Step 59710: Loss=4.9790, Acc=0.222, 
2025-10-07 10:55:04,746 - training.trainer - INFO - Epoch 17, Step 59810: Loss=3.8769, Acc=0.519, 
2025-10-07 10:55:13,174 - training.trainer - INFO - Epoch 17, Step 59910: Loss=5.3728, Acc=0.300, 
2025-10-07 10:55:21,423 - training.trainer - INFO - Epoch 17, Step 60010: Loss=5.1641, Acc=0.238, 
2025-10-07 10:55:29,776 - training.trainer - INFO - Epoch 17, Step 60110: Loss=6.0498, Acc=0.224, 
2025-10-07 10:55:38,116 - training.trainer - INFO - Epoch 17, Step 60210: Loss=4.7977, Acc=0.346, 
2025-10-07 10:55:46,520 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.6069, Acc=0.200, 
2025-10-07 10:55:54,839 - training.trainer - INFO - Epoch 17, Step 60410: Loss=6.6636, Acc=0.208, 
2025-10-07 10:56:03,178 - training.trainer - INFO - Epoch 17, Step 60510: Loss=5.9362, Acc=0.318, 
2025-10-07 10:56:11,489 - training.trainer - INFO - Epoch 17, Step 60610: Loss=6.6624, Acc=0.179, 
2025-10-07 10:56:19,860 - training.trainer - INFO - Epoch 17, Step 60710: Loss=6.4474, Acc=0.132, 
2025-10-07 10:56:28,080 - training.trainer - INFO - Epoch 17, Step 60810: Loss=5.7938, Acc=0.207, 
2025-10-07 10:56:47,322 - training.trainer - INFO - Epoch 18/100 completed in 294.46s - Train Loss: 5.6994, Train Acc: 0.247, Val Loss: 5.7274, Val Acc: 0.249
2025-10-07 10:56:48,209 - training.trainer - INFO - New best model saved with validation loss: 5.7274
2025-10-07 10:56:48,209 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-10-07 10:56:55,706 - training.trainer - INFO - Epoch 18, Step 60993: Loss=6.0741, Acc=0.217, 
2025-10-07 10:57:02,799 - training.trainer - INFO - Epoch 18, Step 61093: Loss=6.4312, Acc=0.127, 
2025-10-07 10:57:09,953 - training.trainer - INFO - Epoch 18, Step 61193: Loss=6.2986, Acc=0.174, 
2025-10-07 10:57:17,668 - training.trainer - INFO - Epoch 18, Step 61293: Loss=5.7477, Acc=0.265, 
2025-10-07 10:57:25,508 - training.trainer - INFO - Epoch 18, Step 61393: Loss=3.1741, Acc=0.579, 
2025-10-07 10:57:33,351 - training.trainer - INFO - Epoch 18, Step 61493: Loss=6.2827, Acc=0.194, 
2025-10-07 10:57:41,674 - training.trainer - INFO - Epoch 18, Step 61593: Loss=7.0333, Acc=0.143, 
2025-10-07 10:57:50,058 - training.trainer - INFO - Epoch 18, Step 61693: Loss=5.4018, Acc=0.243, 
2025-10-07 10:57:58,384 - training.trainer - INFO - Epoch 18, Step 61793: Loss=6.0093, Acc=0.241, 
2025-10-07 10:58:06,718 - training.trainer - INFO - Epoch 18, Step 61893: Loss=6.1731, Acc=0.205, 
2025-10-07 10:58:15,026 - training.trainer - INFO - Epoch 18, Step 61993: Loss=5.2362, Acc=0.382, 
2025-10-07 10:58:23,421 - training.trainer - INFO - Epoch 18, Step 62093: Loss=4.7094, Acc=0.439, 
2025-10-07 10:58:31,969 - training.trainer - INFO - Epoch 18, Step 62193: Loss=5.6750, Acc=0.204, 
2025-10-07 10:58:40,297 - training.trainer - INFO - Epoch 18, Step 62293: Loss=4.3930, Acc=0.471, 
2025-10-07 10:58:48,681 - training.trainer - INFO - Epoch 18, Step 62393: Loss=5.9560, Acc=0.275, 
2025-10-07 10:58:57,131 - training.trainer - INFO - Epoch 18, Step 62493: Loss=6.3710, Acc=0.244, 
2025-10-07 10:59:05,562 - training.trainer - INFO - Epoch 18, Step 62593: Loss=3.6604, Acc=0.545, 
2025-10-07 10:59:13,890 - training.trainer - INFO - Epoch 18, Step 62693: Loss=5.8164, Acc=0.350, 
2025-10-07 10:59:22,303 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.7056, Acc=0.303, 
2025-10-07 10:59:30,646 - training.trainer - INFO - Epoch 18, Step 62893: Loss=5.2779, Acc=0.290, 
2025-10-07 10:59:38,935 - training.trainer - INFO - Epoch 18, Step 62993: Loss=5.7527, Acc=0.290, 
2025-10-07 10:59:47,131 - training.trainer - INFO - Epoch 18, Step 63093: Loss=5.0430, Acc=0.324, 
2025-10-07 10:59:55,355 - training.trainer - INFO - Epoch 18, Step 63193: Loss=5.7834, Acc=0.310, 
2025-10-07 11:00:03,581 - training.trainer - INFO - Epoch 18, Step 63293: Loss=5.7649, Acc=0.250, 
2025-10-07 11:00:11,895 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.0145, Acc=0.320, 
2025-10-07 11:00:20,150 - training.trainer - INFO - Epoch 18, Step 63493: Loss=5.7682, Acc=0.262, 
2025-10-07 11:00:28,657 - training.trainer - INFO - Epoch 18, Step 63593: Loss=6.6777, Acc=0.160, 
2025-10-07 11:00:37,203 - training.trainer - INFO - Epoch 18, Step 63693: Loss=4.8388, Acc=0.244, 
2025-10-07 11:00:45,671 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.2101, Acc=0.318, 
2025-10-07 11:00:53,839 - training.trainer - INFO - Epoch 18, Step 63893: Loss=5.0311, Acc=0.389, 
2025-10-07 11:01:02,014 - training.trainer - INFO - Epoch 18, Step 63993: Loss=5.2780, Acc=0.414, 
2025-10-07 11:01:10,176 - training.trainer - INFO - Epoch 18, Step 64093: Loss=6.3643, Acc=0.137, 
2025-10-07 11:01:18,469 - training.trainer - INFO - Epoch 18, Step 64193: Loss=6.6508, Acc=0.192, 
2025-10-07 11:01:38,168 - training.trainer - INFO - Epoch 19/100 completed in 289.96s - Train Loss: 5.6811, Train Acc: 0.252, Val Loss: 5.7255, Val Acc: 0.249
2025-10-07 11:01:39,164 - training.trainer - INFO - New best model saved with validation loss: 5.7255
2025-10-07 11:01:39,164 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_19.pt
2025-10-07 11:01:48,055 - training.trainer - INFO - Epoch 19, Step 64376: Loss=5.5545, Acc=0.162, 
2025-10-07 11:01:56,484 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.7204, Acc=0.207, 
2025-10-07 11:02:04,879 - training.trainer - INFO - Epoch 19, Step 64576: Loss=6.1688, Acc=0.211, 
2025-10-07 11:02:13,291 - training.trainer - INFO - Epoch 19, Step 64676: Loss=5.4282, Acc=0.167, 
2025-10-07 11:02:21,823 - training.trainer - INFO - Epoch 19, Step 64776: Loss=5.4275, Acc=0.156, 
2025-10-07 11:02:30,256 - training.trainer - INFO - Epoch 19, Step 64876: Loss=5.7990, Acc=0.220, 
2025-10-07 11:02:38,667 - training.trainer - INFO - Epoch 19, Step 64976: Loss=5.1922, Acc=0.289, 
2025-10-07 11:02:46,926 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.0840, Acc=0.296, 
2025-10-07 11:02:55,154 - training.trainer - INFO - Epoch 19, Step 65176: Loss=4.8216, Acc=0.409, 
2025-10-07 11:03:03,422 - training.trainer - INFO - Epoch 19, Step 65276: Loss=5.8390, Acc=0.232, 
2025-10-07 11:03:11,738 - training.trainer - INFO - Epoch 19, Step 65376: Loss=5.2715, Acc=0.222, 
2025-10-07 11:03:19,952 - training.trainer - INFO - Epoch 19, Step 65476: Loss=5.8098, Acc=0.211, 
2025-10-07 11:03:28,231 - training.trainer - INFO - Epoch 19, Step 65576: Loss=5.1089, Acc=0.289, 
2025-10-07 11:03:36,408 - training.trainer - INFO - Epoch 19, Step 65676: Loss=5.5822, Acc=0.200, 
2025-10-07 11:03:44,592 - training.trainer - INFO - Epoch 19, Step 65776: Loss=6.2822, Acc=0.333, 
2025-10-07 11:03:52,756 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.6996, Acc=0.214, 
2025-10-07 11:04:00,992 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.8942, Acc=0.186, 
2025-10-07 11:04:09,115 - training.trainer - INFO - Epoch 19, Step 66076: Loss=4.4674, Acc=0.353, 
2025-10-07 11:04:17,248 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.8644, Acc=0.217, 
2025-10-07 11:04:25,411 - training.trainer - INFO - Epoch 19, Step 66276: Loss=5.8137, Acc=0.261, 
2025-10-07 11:04:33,683 - training.trainer - INFO - Epoch 19, Step 66376: Loss=6.0691, Acc=0.234, 
2025-10-07 11:04:41,872 - training.trainer - INFO - Epoch 19, Step 66476: Loss=5.5379, Acc=0.194, 
2025-10-07 11:04:50,119 - training.trainer - INFO - Epoch 19, Step 66576: Loss=5.1568, Acc=0.276, 
2025-10-07 11:04:58,289 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.6836, Acc=0.175, 
2025-10-07 11:05:06,656 - training.trainer - INFO - Epoch 19, Step 66776: Loss=6.1518, Acc=0.194, 
2025-10-07 11:05:15,058 - training.trainer - INFO - Epoch 19, Step 66876: Loss=6.4120, Acc=0.175, 
2025-10-07 11:05:23,553 - training.trainer - INFO - Epoch 19, Step 66976: Loss=5.5824, Acc=0.164, 
2025-10-07 11:05:31,985 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.2143, Acc=0.222, 
2025-10-07 11:05:40,538 - training.trainer - INFO - Epoch 19, Step 67176: Loss=5.5759, Acc=0.345, 
2025-10-07 11:05:48,817 - training.trainer - INFO - Epoch 19, Step 67276: Loss=6.3576, Acc=0.190, 
2025-10-07 11:05:57,088 - training.trainer - INFO - Epoch 19, Step 67376: Loss=6.0262, Acc=0.191, 
2025-10-07 11:06:05,387 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.2737, Acc=0.227, 
2025-10-07 11:06:13,820 - training.trainer - INFO - Epoch 19, Step 67576: Loss=3.1926, Acc=0.545, 
2025-10-07 11:06:33,743 - training.trainer - INFO - Epoch 20/100 completed in 294.58s - Train Loss: 5.6584, Train Acc: 0.254, Val Loss: 5.7496, Val Acc: 0.251
2025-10-07 11:06:34,125 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-07 11:06:42,838 - training.trainer - INFO - Epoch 20, Step 67759: Loss=5.3756, Acc=0.174, 
2025-10-07 11:06:50,977 - training.trainer - INFO - Epoch 20, Step 67859: Loss=5.8737, Acc=0.256, 
2025-10-07 11:06:59,123 - training.trainer - INFO - Epoch 20, Step 67959: Loss=5.8268, Acc=0.200, 
2025-10-07 11:07:07,377 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.8506, Acc=0.188, 
2025-10-07 11:07:15,700 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.0568, Acc=0.344, 
2025-10-07 11:07:23,996 - training.trainer - INFO - Epoch 20, Step 68259: Loss=6.4775, Acc=0.116, 
2025-10-07 11:07:32,397 - training.trainer - INFO - Epoch 20, Step 68359: Loss=5.7941, Acc=0.297, 
2025-10-07 11:07:40,751 - training.trainer - INFO - Epoch 20, Step 68459: Loss=6.0609, Acc=0.186, 
2025-10-07 11:07:49,056 - training.trainer - INFO - Epoch 20, Step 68559: Loss=5.6328, Acc=0.233, 
2025-10-07 11:07:57,422 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.4188, Acc=0.250, 
2025-10-07 11:08:05,793 - training.trainer - INFO - Epoch 20, Step 68759: Loss=5.5985, Acc=0.305, 
2025-10-07 11:08:14,132 - training.trainer - INFO - Epoch 20, Step 68859: Loss=6.2144, Acc=0.206, 
2025-10-07 11:08:22,527 - training.trainer - INFO - Epoch 20, Step 68959: Loss=4.6620, Acc=0.302, 
2025-10-07 11:08:30,806 - training.trainer - INFO - Epoch 20, Step 69059: Loss=4.5230, Acc=0.395, 
2025-10-07 11:08:39,057 - training.trainer - INFO - Epoch 20, Step 69159: Loss=6.0761, Acc=0.197, 
2025-10-07 11:08:47,407 - training.trainer - INFO - Epoch 20, Step 69259: Loss=5.5142, Acc=0.176, 
2025-10-07 11:08:55,948 - training.trainer - INFO - Epoch 20, Step 69359: Loss=5.3831, Acc=0.250, 
2025-10-07 11:09:04,249 - training.trainer - INFO - Epoch 20, Step 69459: Loss=3.5428, Acc=0.467, 
2025-10-07 11:09:12,548 - training.trainer - INFO - Epoch 20, Step 69559: Loss=4.9046, Acc=0.375, 
2025-10-07 11:09:20,773 - training.trainer - INFO - Epoch 20, Step 69659: Loss=5.7207, Acc=0.277, 
2025-10-07 11:09:29,344 - training.trainer - INFO - Epoch 20, Step 69759: Loss=5.8526, Acc=0.323, 
2025-10-07 11:09:37,681 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.5541, Acc=0.286, 
2025-10-07 11:09:45,865 - training.trainer - INFO - Epoch 20, Step 69959: Loss=5.5502, Acc=0.258, 
2025-10-07 11:09:54,184 - training.trainer - INFO - Epoch 20, Step 70059: Loss=6.0699, Acc=0.214, 
2025-10-07 11:10:02,807 - training.trainer - INFO - Epoch 20, Step 70159: Loss=5.0509, Acc=0.345, 
2025-10-07 11:10:11,262 - training.trainer - INFO - Epoch 20, Step 70259: Loss=5.5499, Acc=0.163, 
2025-10-07 11:10:19,659 - training.trainer - INFO - Epoch 20, Step 70359: Loss=5.0544, Acc=0.154, 
2025-10-07 11:10:28,023 - training.trainer - INFO - Epoch 20, Step 70459: Loss=5.6064, Acc=0.261, 
2025-10-07 11:10:36,404 - training.trainer - INFO - Epoch 20, Step 70559: Loss=6.2391, Acc=0.179, 
2025-10-07 11:10:44,756 - training.trainer - INFO - Epoch 20, Step 70659: Loss=6.1309, Acc=0.156, 
2025-10-07 11:10:53,091 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.7183, Acc=0.240, 
2025-10-07 11:11:01,450 - training.trainer - INFO - Epoch 20, Step 70859: Loss=4.6555, Acc=0.429, 
2025-10-07 11:11:10,029 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.9849, Acc=0.263, 
2025-10-07 11:11:29,384 - training.trainer - INFO - Epoch 21/100 completed in 295.26s - Train Loss: 5.6439, Train Acc: 0.255, Val Loss: 5.7167, Val Acc: 0.250
2025-10-07 11:11:30,304 - training.trainer - INFO - New best model saved with validation loss: 5.7167
2025-10-07 11:11:30,304 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-10-07 11:11:39,482 - training.trainer - INFO - Epoch 21, Step 71142: Loss=6.6689, Acc=0.151, 
2025-10-07 11:11:47,917 - training.trainer - INFO - Epoch 21, Step 71242: Loss=5.6187, Acc=0.250, 
2025-10-07 11:11:56,111 - training.trainer - INFO - Epoch 21, Step 71342: Loss=6.6707, Acc=0.205, 
2025-10-07 11:12:04,504 - training.trainer - INFO - Epoch 21, Step 71442: Loss=4.0659, Acc=0.548, 
2025-10-07 11:12:13,004 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.4196, Acc=0.276, 
2025-10-07 11:12:21,287 - training.trainer - INFO - Epoch 21, Step 71642: Loss=6.3577, Acc=0.187, 
2025-10-07 11:12:29,601 - training.trainer - INFO - Epoch 21, Step 71742: Loss=6.2994, Acc=0.213, 
2025-10-07 11:12:37,971 - training.trainer - INFO - Epoch 21, Step 71842: Loss=6.1894, Acc=0.182, 
2025-10-07 11:12:46,549 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.1891, Acc=0.222, 
2025-10-07 11:12:55,074 - training.trainer - INFO - Epoch 21, Step 72042: Loss=5.9957, Acc=0.250, 
2025-10-07 11:13:03,790 - training.trainer - INFO - Epoch 21, Step 72142: Loss=4.7053, Acc=0.438, 
2025-10-07 11:13:12,174 - training.trainer - INFO - Epoch 21, Step 72242: Loss=5.7254, Acc=0.267, 
2025-10-07 11:13:20,577 - training.trainer - INFO - Epoch 21, Step 72342: Loss=5.5921, Acc=0.259, 
2025-10-07 11:13:28,974 - training.trainer - INFO - Epoch 21, Step 72442: Loss=5.2341, Acc=0.275, 
2025-10-07 11:13:37,388 - training.trainer - INFO - Epoch 21, Step 72542: Loss=4.8201, Acc=0.366, 
2025-10-07 11:13:45,942 - training.trainer - INFO - Epoch 21, Step 72642: Loss=5.6338, Acc=0.381, 
2025-10-07 11:13:54,557 - training.trainer - INFO - Epoch 21, Step 72742: Loss=6.2590, Acc=0.254, 
2025-10-07 11:14:03,074 - training.trainer - INFO - Epoch 21, Step 72842: Loss=5.9251, Acc=0.219, 
2025-10-07 11:14:11,614 - training.trainer - INFO - Epoch 21, Step 72942: Loss=5.4615, Acc=0.263, 
2025-10-07 11:14:20,138 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.6217, Acc=0.226, 
2025-10-07 11:14:28,594 - training.trainer - INFO - Epoch 21, Step 73142: Loss=5.9677, Acc=0.197, 
2025-10-07 11:14:37,004 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.2198, Acc=0.200, 
2025-10-07 11:14:45,281 - training.trainer - INFO - Epoch 21, Step 73342: Loss=6.3953, Acc=0.261, 
2025-10-07 11:14:53,624 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.8666, Acc=0.176, 
2025-10-07 11:15:01,878 - training.trainer - INFO - Epoch 21, Step 73542: Loss=5.2701, Acc=0.256, 
2025-10-07 11:15:10,081 - training.trainer - INFO - Epoch 21, Step 73642: Loss=5.4762, Acc=0.231, 
2025-10-07 11:15:18,429 - training.trainer - INFO - Epoch 21, Step 73742: Loss=5.2675, Acc=0.294, 
2025-10-07 11:15:26,787 - training.trainer - INFO - Epoch 21, Step 73842: Loss=5.3125, Acc=0.391, 
2025-10-07 11:15:35,104 - training.trainer - INFO - Epoch 21, Step 73942: Loss=5.4670, Acc=0.259, 
2025-10-07 11:15:43,467 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.2861, Acc=0.240, 
2025-10-07 11:15:51,806 - training.trainer - INFO - Epoch 21, Step 74142: Loss=5.4029, Acc=0.391, 
2025-10-07 11:16:00,200 - training.trainer - INFO - Epoch 21, Step 74242: Loss=5.7615, Acc=0.310, 
2025-10-07 11:16:08,612 - training.trainer - INFO - Epoch 21, Step 74342: Loss=5.1869, Acc=0.231, 
2025-10-07 11:16:29,877 - training.trainer - INFO - Epoch 22/100 completed in 299.57s - Train Loss: 5.6255, Train Acc: 0.259, Val Loss: 5.7270, Val Acc: 0.253
2025-10-07 11:16:38,702 - training.trainer - INFO - Epoch 22, Step 74525: Loss=5.8149, Acc=0.237, 
2025-10-07 11:16:46,963 - training.trainer - INFO - Epoch 22, Step 74625: Loss=6.6420, Acc=0.179, 
2025-10-07 11:16:55,091 - training.trainer - INFO - Epoch 22, Step 74725: Loss=5.7673, Acc=0.136, 
2025-10-07 11:17:03,437 - training.trainer - INFO - Epoch 22, Step 74825: Loss=5.9293, Acc=0.242, 
2025-10-07 11:17:11,702 - training.trainer - INFO - Epoch 22, Step 74925: Loss=5.7766, Acc=0.242, 
2025-10-07 11:17:20,030 - training.trainer - INFO - Epoch 22, Step 75025: Loss=5.1439, Acc=0.333, 
2025-10-07 11:17:28,301 - training.trainer - INFO - Epoch 22, Step 75125: Loss=5.5428, Acc=0.260, 
2025-10-07 11:17:36,576 - training.trainer - INFO - Epoch 22, Step 75225: Loss=6.1401, Acc=0.276, 
2025-10-07 11:17:44,939 - training.trainer - INFO - Epoch 22, Step 75325: Loss=5.9808, Acc=0.130, 
2025-10-07 11:17:53,218 - training.trainer - INFO - Epoch 22, Step 75425: Loss=5.5704, Acc=0.239, 
2025-10-07 11:18:01,472 - training.trainer - INFO - Epoch 22, Step 75525: Loss=5.7227, Acc=0.220, 
2025-10-07 11:18:09,709 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.1452, Acc=0.310, 
2025-10-07 11:18:17,964 - training.trainer - INFO - Epoch 22, Step 75725: Loss=6.3395, Acc=0.292, 
2025-10-07 11:18:26,304 - training.trainer - INFO - Epoch 22, Step 75825: Loss=5.5030, Acc=0.182, 
2025-10-07 11:18:34,585 - training.trainer - INFO - Epoch 22, Step 75925: Loss=5.2998, Acc=0.280, 
2025-10-07 11:18:42,780 - training.trainer - INFO - Epoch 22, Step 76025: Loss=5.8121, Acc=0.174, 
2025-10-07 11:18:51,039 - training.trainer - INFO - Epoch 22, Step 76125: Loss=5.8419, Acc=0.231, 
2025-10-07 11:18:59,280 - training.trainer - INFO - Epoch 22, Step 76225: Loss=5.4336, Acc=0.273, 
2025-10-07 11:19:07,558 - training.trainer - INFO - Epoch 22, Step 76325: Loss=5.3620, Acc=0.261, 
2025-10-07 11:19:15,986 - training.trainer - INFO - Epoch 22, Step 76425: Loss=5.7484, Acc=0.299, 
2025-10-07 11:19:24,459 - training.trainer - INFO - Epoch 22, Step 76525: Loss=5.9609, Acc=0.226, 
2025-10-07 11:19:32,915 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.6426, Acc=0.222, 
2025-10-07 11:19:41,226 - training.trainer - INFO - Epoch 22, Step 76725: Loss=6.9090, Acc=0.231, 
2025-10-07 11:19:49,672 - training.trainer - INFO - Epoch 22, Step 76825: Loss=6.0738, Acc=0.185, 
2025-10-07 11:19:57,919 - training.trainer - INFO - Epoch 22, Step 76925: Loss=6.0110, Acc=0.224, 
2025-10-07 11:20:06,425 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.4339, Acc=0.262, 
2025-10-07 11:20:15,046 - training.trainer - INFO - Epoch 22, Step 77125: Loss=5.6888, Acc=0.220, 
2025-10-07 11:20:23,551 - training.trainer - INFO - Epoch 22, Step 77225: Loss=6.0555, Acc=0.207, 
2025-10-07 11:20:32,131 - training.trainer - INFO - Epoch 22, Step 77325: Loss=5.0598, Acc=0.350, 
2025-10-07 11:20:40,720 - training.trainer - INFO - Epoch 22, Step 77425: Loss=5.6228, Acc=0.184, 
2025-10-07 11:20:49,346 - training.trainer - INFO - Epoch 22, Step 77525: Loss=5.4605, Acc=0.280, 
2025-10-07 11:20:58,103 - training.trainer - INFO - Epoch 22, Step 77625: Loss=5.8022, Acc=0.163, 
2025-10-07 11:21:06,592 - training.trainer - INFO - Epoch 22, Step 77725: Loss=6.3692, Acc=0.100, 
2025-10-07 11:21:28,267 - training.trainer - INFO - Epoch 23/100 completed in 298.39s - Train Loss: 5.6110, Train Acc: 0.262, Val Loss: 5.7015, Val Acc: 0.255
2025-10-07 11:21:29,143 - training.trainer - INFO - New best model saved with validation loss: 5.7015
2025-10-07 11:21:29,143 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_23.pt
2025-10-07 11:21:38,380 - training.trainer - INFO - Epoch 23, Step 77908: Loss=6.0083, Acc=0.265, 
2025-10-07 11:21:46,942 - training.trainer - INFO - Epoch 23, Step 78008: Loss=5.4896, Acc=0.269, 
2025-10-07 11:21:55,353 - training.trainer - INFO - Epoch 23, Step 78108: Loss=5.3777, Acc=0.273, 
2025-10-07 11:22:03,889 - training.trainer - INFO - Epoch 23, Step 78208: Loss=6.6415, Acc=0.176, 
2025-10-07 11:22:12,373 - training.trainer - INFO - Epoch 23, Step 78308: Loss=4.8546, Acc=0.409, 
2025-10-07 11:22:20,812 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.7809, Acc=0.115, 
2025-10-07 11:22:29,274 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.4449, Acc=0.268, 
2025-10-07 11:22:37,870 - training.trainer - INFO - Epoch 23, Step 78608: Loss=6.1888, Acc=0.214, 
2025-10-07 11:22:46,587 - training.trainer - INFO - Epoch 23, Step 78708: Loss=5.7400, Acc=0.265, 
2025-10-07 11:22:55,038 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.4123, Acc=0.283, 
2025-10-07 11:23:03,572 - training.trainer - INFO - Epoch 23, Step 78908: Loss=5.9712, Acc=0.233, 
2025-10-07 11:23:11,982 - training.trainer - INFO - Epoch 23, Step 79008: Loss=5.3974, Acc=0.323, 
2025-10-07 11:23:20,379 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.9481, Acc=0.206, 
2025-10-07 11:23:28,774 - training.trainer - INFO - Epoch 23, Step 79208: Loss=6.2996, Acc=0.233, 
2025-10-07 11:23:37,257 - training.trainer - INFO - Epoch 23, Step 79308: Loss=5.2910, Acc=0.217, 
2025-10-07 11:23:45,771 - training.trainer - INFO - Epoch 23, Step 79408: Loss=5.5199, Acc=0.231, 
2025-10-07 11:23:54,187 - training.trainer - INFO - Epoch 23, Step 79508: Loss=5.4065, Acc=0.231, 
2025-10-07 11:24:02,576 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.0709, Acc=0.250, 
2025-10-07 11:24:10,992 - training.trainer - INFO - Epoch 23, Step 79708: Loss=5.9098, Acc=0.242, 
2025-10-07 11:24:19,441 - training.trainer - INFO - Epoch 23, Step 79808: Loss=4.8618, Acc=0.325, 
2025-10-07 11:24:27,868 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.8648, Acc=0.333, 
2025-10-07 11:24:36,236 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.8097, Acc=0.296, 
2025-10-07 11:24:44,679 - training.trainer - INFO - Epoch 23, Step 80108: Loss=6.1808, Acc=0.119, 
2025-10-07 11:24:53,098 - training.trainer - INFO - Epoch 23, Step 80208: Loss=6.8619, Acc=0.194, 
2025-10-07 11:25:01,617 - training.trainer - INFO - Epoch 23, Step 80308: Loss=4.5500, Acc=0.481, 
2025-10-07 11:25:10,058 - training.trainer - INFO - Epoch 23, Step 80408: Loss=5.7692, Acc=0.303, 
2025-10-07 11:25:18,592 - training.trainer - INFO - Epoch 23, Step 80508: Loss=6.2857, Acc=0.168, 
2025-10-07 11:25:27,037 - training.trainer - INFO - Epoch 23, Step 80608: Loss=6.1755, Acc=0.188, 
2025-10-07 11:25:35,465 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.6628, Acc=0.208, 
2025-10-07 11:25:43,812 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.1185, Acc=0.303, 
2025-10-07 11:25:52,179 - training.trainer - INFO - Epoch 23, Step 80908: Loss=5.4276, Acc=0.250, 
2025-10-07 11:26:00,629 - training.trainer - INFO - Epoch 23, Step 81008: Loss=6.1743, Acc=0.261, 
2025-10-07 11:26:09,017 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.5325, Acc=0.269, 
2025-10-07 11:26:30,151 - training.trainer - INFO - Epoch 24/100 completed in 301.01s - Train Loss: 5.5904, Train Acc: 0.266, Val Loss: 5.7172, Val Acc: 0.256
2025-10-07 11:26:39,036 - training.trainer - INFO - Epoch 24, Step 81291: Loss=5.7982, Acc=0.368, 
2025-10-07 11:26:47,588 - training.trainer - INFO - Epoch 24, Step 81391: Loss=5.0471, Acc=0.296, 
2025-10-07 11:26:55,931 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.8810, Acc=0.318, 
2025-10-07 11:27:04,249 - training.trainer - INFO - Epoch 24, Step 81591: Loss=5.5505, Acc=0.273, 
2025-10-07 11:27:12,444 - training.trainer - INFO - Epoch 24, Step 81691: Loss=4.8712, Acc=0.419, 
2025-10-07 11:27:20,595 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.3181, Acc=0.300, 
2025-10-07 11:27:28,942 - training.trainer - INFO - Epoch 24, Step 81891: Loss=6.0426, Acc=0.267, 
2025-10-07 11:27:37,356 - training.trainer - INFO - Epoch 24, Step 81991: Loss=5.9103, Acc=0.178, 
2025-10-07 11:27:45,669 - training.trainer - INFO - Epoch 24, Step 82091: Loss=6.3555, Acc=0.157, 
2025-10-07 11:27:53,942 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.1146, Acc=0.214, 
2025-10-07 11:28:02,307 - training.trainer - INFO - Epoch 24, Step 82291: Loss=5.2100, Acc=0.244, 
2025-10-07 11:28:10,643 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.8306, Acc=0.269, 
2025-10-07 11:28:18,968 - training.trainer - INFO - Epoch 24, Step 82491: Loss=6.2460, Acc=0.167, 
2025-10-07 11:28:27,341 - training.trainer - INFO - Epoch 24, Step 82591: Loss=5.6489, Acc=0.220, 
2025-10-07 11:28:35,767 - training.trainer - INFO - Epoch 24, Step 82691: Loss=5.2161, Acc=0.326, 
2025-10-07 11:28:44,055 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.6115, Acc=0.409, 
2025-10-07 11:28:52,389 - training.trainer - INFO - Epoch 24, Step 82891: Loss=6.1131, Acc=0.396, 
2025-10-07 11:29:00,843 - training.trainer - INFO - Epoch 24, Step 82991: Loss=5.4733, Acc=0.160, 
2025-10-07 11:29:09,233 - training.trainer - INFO - Epoch 24, Step 83091: Loss=5.5158, Acc=0.224, 
2025-10-07 11:29:17,575 - training.trainer - INFO - Epoch 24, Step 83191: Loss=6.1145, Acc=0.234, 
2025-10-07 11:29:25,921 - training.trainer - INFO - Epoch 24, Step 83291: Loss=6.4472, Acc=0.104, 
2025-10-07 11:29:34,283 - training.trainer - INFO - Epoch 24, Step 83391: Loss=6.1489, Acc=0.170, 
2025-10-07 11:29:42,667 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.7252, Acc=0.244, 
2025-10-07 11:29:51,019 - training.trainer - INFO - Epoch 24, Step 83591: Loss=5.1108, Acc=0.360, 
2025-10-07 11:29:59,367 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.6875, Acc=0.188, 
2025-10-07 11:30:07,729 - training.trainer - INFO - Epoch 24, Step 83791: Loss=4.3721, Acc=0.424, 
2025-10-07 11:30:16,200 - training.trainer - INFO - Epoch 24, Step 83891: Loss=6.1068, Acc=0.281, 
2025-10-07 11:30:24,570 - training.trainer - INFO - Epoch 24, Step 83991: Loss=6.3636, Acc=0.209, 
2025-10-07 11:30:33,195 - training.trainer - INFO - Epoch 24, Step 84091: Loss=5.5174, Acc=0.182, 
2025-10-07 11:30:41,627 - training.trainer - INFO - Epoch 24, Step 84191: Loss=4.8247, Acc=0.400, 
2025-10-07 11:30:50,103 - training.trainer - INFO - Epoch 24, Step 84291: Loss=4.8165, Acc=0.300, 
2025-10-07 11:30:58,478 - training.trainer - INFO - Epoch 24, Step 84391: Loss=6.2163, Acc=0.273, 
2025-10-07 11:31:06,813 - training.trainer - INFO - Epoch 24, Step 84491: Loss=5.3119, Acc=0.250, 
2025-10-07 11:31:26,866 - training.trainer - INFO - Epoch 25/100 completed in 296.72s - Train Loss: 5.5805, Train Acc: 0.267, Val Loss: 5.7227, Val Acc: 0.258
2025-10-07 11:31:27,208 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-07 11:31:34,728 - training.trainer - INFO - Epoch 25, Step 84674: Loss=5.8051, Acc=0.349, 
2025-10-07 11:31:41,790 - training.trainer - INFO - Epoch 25, Step 84774: Loss=4.0448, Acc=0.500, 
2025-10-07 11:31:48,959 - training.trainer - INFO - Epoch 25, Step 84874: Loss=6.2042, Acc=0.262, 
2025-10-07 11:31:56,202 - training.trainer - INFO - Epoch 25, Step 84974: Loss=5.5924, Acc=0.267, 
2025-10-07 11:32:03,724 - training.trainer - INFO - Epoch 25, Step 85074: Loss=5.1771, Acc=0.333, 
2025-10-07 11:32:11,735 - training.trainer - INFO - Epoch 25, Step 85174: Loss=4.7496, Acc=0.292, 
2025-10-07 11:32:20,258 - training.trainer - INFO - Epoch 25, Step 85274: Loss=5.2146, Acc=0.368, 
2025-10-07 11:32:28,711 - training.trainer - INFO - Epoch 25, Step 85374: Loss=5.8369, Acc=0.156, 
2025-10-07 11:32:37,055 - training.trainer - INFO - Epoch 25, Step 85474: Loss=6.0189, Acc=0.256, 
2025-10-07 11:32:45,403 - training.trainer - INFO - Epoch 25, Step 85574: Loss=4.5974, Acc=0.450, 
2025-10-07 11:32:53,770 - training.trainer - INFO - Epoch 25, Step 85674: Loss=5.6587, Acc=0.196, 
2025-10-07 11:33:02,193 - training.trainer - INFO - Epoch 25, Step 85774: Loss=5.7572, Acc=0.283, 
2025-10-07 11:33:10,549 - training.trainer - INFO - Epoch 25, Step 85874: Loss=5.6514, Acc=0.286, 
2025-10-07 11:33:18,852 - training.trainer - INFO - Epoch 25, Step 85974: Loss=5.3702, Acc=0.250, 
2025-10-07 11:33:27,338 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.4580, Acc=0.278, 
2025-10-07 11:33:35,638 - training.trainer - INFO - Epoch 25, Step 86174: Loss=5.6292, Acc=0.286, 
2025-10-07 11:33:44,002 - training.trainer - INFO - Epoch 25, Step 86274: Loss=5.7957, Acc=0.222, 
2025-10-07 11:33:52,298 - training.trainer - INFO - Epoch 25, Step 86374: Loss=5.5078, Acc=0.381, 
2025-10-07 11:34:00,718 - training.trainer - INFO - Epoch 25, Step 86474: Loss=6.3355, Acc=0.179, 
2025-10-07 11:34:09,052 - training.trainer - INFO - Epoch 25, Step 86574: Loss=5.7930, Acc=0.194, 
2025-10-07 11:34:17,409 - training.trainer - INFO - Epoch 25, Step 86674: Loss=5.6254, Acc=0.297, 
2025-10-07 11:34:25,700 - training.trainer - INFO - Epoch 25, Step 86774: Loss=3.9330, Acc=0.417, 
2025-10-07 11:34:34,096 - training.trainer - INFO - Epoch 25, Step 86874: Loss=5.7444, Acc=0.250, 
2025-10-07 11:34:42,507 - training.trainer - INFO - Epoch 25, Step 86974: Loss=4.6214, Acc=0.500, 
2025-10-07 11:34:50,925 - training.trainer - INFO - Epoch 25, Step 87074: Loss=5.6365, Acc=0.333, 
2025-10-07 11:34:59,365 - training.trainer - INFO - Epoch 25, Step 87174: Loss=5.9498, Acc=0.222, 
2025-10-07 11:35:07,842 - training.trainer - INFO - Epoch 25, Step 87274: Loss=5.6316, Acc=0.231, 
2025-10-07 11:35:16,267 - training.trainer - INFO - Epoch 25, Step 87374: Loss=4.5970, Acc=0.417, 
2025-10-07 11:35:24,624 - training.trainer - INFO - Epoch 25, Step 87474: Loss=6.0422, Acc=0.231, 
2025-10-07 11:35:32,837 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.7319, Acc=0.194, 
2025-10-07 11:35:41,058 - training.trainer - INFO - Epoch 25, Step 87674: Loss=5.4863, Acc=0.231, 
2025-10-07 11:35:49,240 - training.trainer - INFO - Epoch 25, Step 87774: Loss=5.7553, Acc=0.364, 
2025-10-07 11:35:57,427 - training.trainer - INFO - Epoch 25, Step 87874: Loss=6.3537, Acc=0.100, 
2025-10-07 11:36:17,431 - training.trainer - INFO - Epoch 26/100 completed in 290.22s - Train Loss: 5.5621, Train Acc: 0.270, Val Loss: 5.7177, Val Acc: 0.255
2025-10-07 11:36:26,456 - training.trainer - INFO - Epoch 26, Step 88057: Loss=5.7753, Acc=0.300, 
2025-10-07 11:36:34,896 - training.trainer - INFO - Epoch 26, Step 88157: Loss=4.9457, Acc=0.357, 
2025-10-07 11:36:43,210 - training.trainer - INFO - Epoch 26, Step 88257: Loss=5.4192, Acc=0.264, 
2025-10-07 11:36:51,620 - training.trainer - INFO - Epoch 26, Step 88357: Loss=5.1281, Acc=0.308, 
2025-10-07 11:36:59,986 - training.trainer - INFO - Epoch 26, Step 88457: Loss=5.8242, Acc=0.167, 
2025-10-07 11:37:08,265 - training.trainer - INFO - Epoch 26, Step 88557: Loss=4.8046, Acc=0.323, 
2025-10-07 11:37:16,570 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.6898, Acc=0.182, 
2025-10-07 11:37:24,918 - training.trainer - INFO - Epoch 26, Step 88757: Loss=5.3626, Acc=0.303, 
2025-10-07 11:37:33,218 - training.trainer - INFO - Epoch 26, Step 88857: Loss=5.0969, Acc=0.433, 
2025-10-07 11:37:41,503 - training.trainer - INFO - Epoch 26, Step 88957: Loss=5.1871, Acc=0.333, 
2025-10-07 11:37:49,808 - training.trainer - INFO - Epoch 26, Step 89057: Loss=6.7516, Acc=0.194, 
2025-10-07 11:37:58,320 - training.trainer - INFO - Epoch 26, Step 89157: Loss=4.4277, Acc=0.303, 
2025-10-07 11:38:06,721 - training.trainer - INFO - Epoch 26, Step 89257: Loss=5.1511, Acc=0.368, 
2025-10-07 11:38:15,104 - training.trainer - INFO - Epoch 26, Step 89357: Loss=6.2343, Acc=0.258, 
2025-10-07 11:38:23,500 - training.trainer - INFO - Epoch 26, Step 89457: Loss=6.0286, Acc=0.300, 
2025-10-07 11:38:32,032 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.5301, Acc=0.318, 
2025-10-07 11:38:40,381 - training.trainer - INFO - Epoch 26, Step 89657: Loss=5.1182, Acc=0.271, 
2025-10-07 11:38:48,722 - training.trainer - INFO - Epoch 26, Step 89757: Loss=6.0786, Acc=0.241, 
2025-10-07 11:38:57,144 - training.trainer - INFO - Epoch 26, Step 89857: Loss=5.8676, Acc=0.194, 
2025-10-07 11:39:05,478 - training.trainer - INFO - Epoch 26, Step 89957: Loss=5.8198, Acc=0.171, 
2025-10-07 11:39:13,946 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.6924, Acc=0.235, 
2025-10-07 11:39:22,530 - training.trainer - INFO - Epoch 26, Step 90157: Loss=5.0502, Acc=0.286, 
2025-10-07 11:39:31,087 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.9200, Acc=0.244, 
2025-10-07 11:39:39,435 - training.trainer - INFO - Epoch 26, Step 90357: Loss=4.9436, Acc=0.344, 
2025-10-07 11:39:47,788 - training.trainer - INFO - Epoch 26, Step 90457: Loss=6.0892, Acc=0.178, 
2025-10-07 11:39:56,269 - training.trainer - INFO - Epoch 26, Step 90557: Loss=5.7318, Acc=0.265, 
2025-10-07 11:40:04,653 - training.trainer - INFO - Epoch 26, Step 90657: Loss=4.3919, Acc=0.400, 
2025-10-07 11:40:12,995 - training.trainer - INFO - Epoch 26, Step 90757: Loss=5.7230, Acc=0.205, 
2025-10-07 11:40:21,570 - training.trainer - INFO - Epoch 26, Step 90857: Loss=4.4414, Acc=0.250, 
2025-10-07 11:40:29,924 - training.trainer - INFO - Epoch 26, Step 90957: Loss=6.3491, Acc=0.149, 
2025-10-07 11:40:38,436 - training.trainer - INFO - Epoch 26, Step 91057: Loss=6.6108, Acc=0.263, 
2025-10-07 11:40:46,891 - training.trainer - INFO - Epoch 26, Step 91157: Loss=6.0680, Acc=0.231, 
2025-10-07 11:40:55,351 - training.trainer - INFO - Epoch 26, Step 91257: Loss=6.0114, Acc=0.194, 
2025-10-07 11:41:15,098 - training.trainer - INFO - Epoch 27/100 completed in 297.67s - Train Loss: 5.5468, Train Acc: 0.272, Val Loss: 5.7195, Val Acc: 0.257
2025-10-07 11:41:23,752 - training.trainer - INFO - Epoch 27, Step 91440: Loss=5.7806, Acc=0.200, 
2025-10-07 11:41:32,262 - training.trainer - INFO - Epoch 27, Step 91540: Loss=5.5842, Acc=0.271, 
2025-10-07 11:41:40,507 - training.trainer - INFO - Epoch 27, Step 91640: Loss=4.5381, Acc=0.333, 
2025-10-07 11:41:48,814 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.8499, Acc=0.241, 
2025-10-07 11:41:57,236 - training.trainer - INFO - Epoch 27, Step 91840: Loss=6.0101, Acc=0.250, 
2025-10-07 11:42:05,688 - training.trainer - INFO - Epoch 27, Step 91940: Loss=5.4403, Acc=0.296, 
2025-10-07 11:42:14,234 - training.trainer - INFO - Epoch 27, Step 92040: Loss=4.1364, Acc=0.429, 
2025-10-07 11:42:22,751 - training.trainer - INFO - Epoch 27, Step 92140: Loss=5.9246, Acc=0.212, 
2025-10-07 11:42:31,145 - training.trainer - INFO - Epoch 27, Step 92240: Loss=4.0186, Acc=0.361, 
2025-10-07 11:42:39,719 - training.trainer - INFO - Epoch 27, Step 92340: Loss=5.9295, Acc=0.257, 
2025-10-07 11:42:48,106 - training.trainer - INFO - Epoch 27, Step 92440: Loss=5.8679, Acc=0.170, 
2025-10-07 11:42:56,585 - training.trainer - INFO - Epoch 27, Step 92540: Loss=6.4262, Acc=0.232, 
2025-10-07 11:43:05,148 - training.trainer - INFO - Epoch 27, Step 92640: Loss=6.6492, Acc=0.191, 
2025-10-07 11:43:13,640 - training.trainer - INFO - Epoch 27, Step 92740: Loss=6.0667, Acc=0.242, 
2025-10-07 11:43:21,897 - training.trainer - INFO - Epoch 27, Step 92840: Loss=6.3553, Acc=0.220, 
2025-10-07 11:43:30,303 - training.trainer - INFO - Epoch 27, Step 92940: Loss=6.5464, Acc=0.093, 
2025-10-07 11:43:38,706 - training.trainer - INFO - Epoch 27, Step 93040: Loss=6.2960, Acc=0.169, 
2025-10-07 11:43:46,545 - training.trainer - INFO - Epoch 27, Step 93140: Loss=5.8539, Acc=0.241, 
2025-10-07 11:43:54,755 - training.trainer - INFO - Epoch 27, Step 93240: Loss=4.6979, Acc=0.406, 
2025-10-07 11:44:02,950 - training.trainer - INFO - Epoch 27, Step 93340: Loss=5.5072, Acc=0.176, 
2025-10-07 11:44:11,323 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.9502, Acc=0.189, 
2025-10-07 11:44:19,858 - training.trainer - INFO - Epoch 27, Step 93540: Loss=6.1774, Acc=0.220, 
2025-10-07 11:44:28,353 - training.trainer - INFO - Epoch 27, Step 93640: Loss=5.8643, Acc=0.200, 
2025-10-07 11:44:36,518 - training.trainer - INFO - Epoch 27, Step 93740: Loss=4.8900, Acc=0.375, 
2025-10-07 11:44:44,923 - training.trainer - INFO - Epoch 27, Step 93840: Loss=5.8345, Acc=0.200, 
2025-10-07 11:44:53,324 - training.trainer - INFO - Epoch 27, Step 93940: Loss=5.3331, Acc=0.323, 
2025-10-07 11:45:01,701 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.6038, Acc=0.205, 
2025-10-07 11:45:10,165 - training.trainer - INFO - Epoch 27, Step 94140: Loss=5.3736, Acc=0.125, 
2025-10-07 11:45:18,524 - training.trainer - INFO - Epoch 27, Step 94240: Loss=5.7363, Acc=0.375, 
2025-10-07 11:45:26,963 - training.trainer - INFO - Epoch 27, Step 94340: Loss=6.1833, Acc=0.123, 
2025-10-07 11:45:35,370 - training.trainer - INFO - Epoch 27, Step 94440: Loss=5.5129, Acc=0.260, 
2025-10-07 11:45:43,803 - training.trainer - INFO - Epoch 27, Step 94540: Loss=6.2968, Acc=0.186, 
2025-10-07 11:45:52,210 - training.trainer - INFO - Epoch 27, Step 94640: Loss=4.6846, Acc=0.373, 
2025-10-07 11:46:12,376 - training.trainer - INFO - Epoch 28/100 completed in 297.28s - Train Loss: 5.5305, Train Acc: 0.275, Val Loss: 5.7262, Val Acc: 0.259
2025-10-07 11:46:20,694 - training.trainer - INFO - Epoch 28, Step 94823: Loss=4.7355, Acc=0.400, 
2025-10-07 11:46:28,898 - training.trainer - INFO - Epoch 28, Step 94923: Loss=5.1765, Acc=0.237, 
2025-10-07 11:46:37,061 - training.trainer - INFO - Epoch 28, Step 95023: Loss=5.8672, Acc=0.290, 
2025-10-07 11:46:45,126 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.8203, Acc=0.152, 
2025-10-07 11:46:53,388 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.1166, Acc=0.333, 
2025-10-07 11:47:01,687 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.3184, Acc=0.191, 
2025-10-07 11:47:10,016 - training.trainer - INFO - Epoch 28, Step 95423: Loss=6.7295, Acc=0.179, 
2025-10-07 11:47:18,503 - training.trainer - INFO - Epoch 28, Step 95523: Loss=5.7815, Acc=0.129, 
2025-10-07 11:47:26,903 - training.trainer - INFO - Epoch 28, Step 95623: Loss=4.6558, Acc=0.273, 
2025-10-07 11:47:35,301 - training.trainer - INFO - Epoch 28, Step 95723: Loss=4.9471, Acc=0.440, 
2025-10-07 11:47:43,688 - training.trainer - INFO - Epoch 28, Step 95823: Loss=6.0697, Acc=0.230, 
2025-10-07 11:47:52,052 - training.trainer - INFO - Epoch 28, Step 95923: Loss=4.9904, Acc=0.320, 
2025-10-07 11:48:00,390 - training.trainer - INFO - Epoch 28, Step 96023: Loss=5.3811, Acc=0.346, 
2025-10-07 11:48:08,640 - training.trainer - INFO - Epoch 28, Step 96123: Loss=6.1803, Acc=0.221, 
2025-10-07 11:48:17,110 - training.trainer - INFO - Epoch 28, Step 96223: Loss=4.2391, Acc=0.373, 
2025-10-07 11:48:25,391 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.2959, Acc=0.327, 
2025-10-07 11:48:33,670 - training.trainer - INFO - Epoch 28, Step 96423: Loss=6.2019, Acc=0.154, 
2025-10-07 11:48:42,050 - training.trainer - INFO - Epoch 28, Step 96523: Loss=5.9440, Acc=0.277, 
2025-10-07 11:48:50,456 - training.trainer - INFO - Epoch 28, Step 96623: Loss=6.1836, Acc=0.250, 
2025-10-07 11:48:58,800 - training.trainer - INFO - Epoch 28, Step 96723: Loss=5.9209, Acc=0.200, 
2025-10-07 11:49:07,207 - training.trainer - INFO - Epoch 28, Step 96823: Loss=6.4244, Acc=0.237, 
2025-10-07 11:49:15,606 - training.trainer - INFO - Epoch 28, Step 96923: Loss=5.1548, Acc=0.308, 
2025-10-07 11:49:24,056 - training.trainer - INFO - Epoch 28, Step 97023: Loss=6.2170, Acc=0.121, 
2025-10-07 11:49:32,466 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.6945, Acc=0.245, 
2025-10-07 11:49:40,907 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.8489, Acc=0.207, 
2025-10-07 11:49:49,321 - training.trainer - INFO - Epoch 28, Step 97323: Loss=3.8551, Acc=0.514, 
2025-10-07 11:49:57,718 - training.trainer - INFO - Epoch 28, Step 97423: Loss=5.6918, Acc=0.304, 
2025-10-07 11:50:06,100 - training.trainer - INFO - Epoch 28, Step 97523: Loss=6.2969, Acc=0.181, 
2025-10-07 11:50:14,412 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.3946, Acc=0.225, 
2025-10-07 11:50:22,684 - training.trainer - INFO - Epoch 28, Step 97723: Loss=5.6917, Acc=0.326, 
2025-10-07 11:50:31,303 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.2665, Acc=0.299, 
2025-10-07 11:50:39,784 - training.trainer - INFO - Epoch 28, Step 97923: Loss=5.3118, Acc=0.250, 
2025-10-07 11:50:48,096 - training.trainer - INFO - Epoch 28, Step 98023: Loss=5.2712, Acc=0.304, 
2025-10-07 11:51:07,400 - training.trainer - INFO - Epoch 29/100 completed in 295.02s - Train Loss: 5.5142, Train Acc: 0.277, Val Loss: 5.7195, Val Acc: 0.259
2025-10-07 11:51:16,118 - training.trainer - INFO - Epoch 29, Step 98206: Loss=5.3211, Acc=0.323, 
2025-10-07 11:51:24,468 - training.trainer - INFO - Epoch 29, Step 98306: Loss=4.7191, Acc=0.389, 
2025-10-07 11:51:32,926 - training.trainer - INFO - Epoch 29, Step 98406: Loss=5.7814, Acc=0.237, 
2025-10-07 11:51:41,152 - training.trainer - INFO - Epoch 29, Step 98506: Loss=3.7351, Acc=0.452, 
2025-10-07 11:51:49,350 - training.trainer - INFO - Epoch 29, Step 98606: Loss=5.2470, Acc=0.302, 
2025-10-07 11:51:57,587 - training.trainer - INFO - Epoch 29, Step 98706: Loss=4.9064, Acc=0.222, 
2025-10-07 11:52:05,983 - training.trainer - INFO - Epoch 29, Step 98806: Loss=5.2695, Acc=0.250, 
2025-10-07 11:52:14,170 - training.trainer - INFO - Epoch 29, Step 98906: Loss=4.7905, Acc=0.387, 
2025-10-07 11:52:22,374 - training.trainer - INFO - Epoch 29, Step 99006: Loss=4.7951, Acc=0.310, 
2025-10-07 11:52:30,623 - training.trainer - INFO - Epoch 29, Step 99106: Loss=5.6562, Acc=0.175, 
2025-10-07 11:52:38,952 - training.trainer - INFO - Epoch 29, Step 99206: Loss=3.7632, Acc=0.500, 
2025-10-07 11:52:47,181 - training.trainer - INFO - Epoch 29, Step 99306: Loss=5.6208, Acc=0.265, 
2025-10-07 11:52:55,431 - training.trainer - INFO - Epoch 29, Step 99406: Loss=6.1998, Acc=0.195, 
2025-10-07 11:53:03,693 - training.trainer - INFO - Epoch 29, Step 99506: Loss=6.2041, Acc=0.375, 
2025-10-07 11:53:12,000 - training.trainer - INFO - Epoch 29, Step 99606: Loss=5.4673, Acc=0.280, 
2025-10-07 11:53:20,448 - training.trainer - INFO - Epoch 29, Step 99706: Loss=4.4718, Acc=0.387, 
2025-10-07 11:53:28,617 - training.trainer - INFO - Epoch 29, Step 99806: Loss=5.1636, Acc=0.364, 
2025-10-07 11:53:36,905 - training.trainer - INFO - Epoch 29, Step 99906: Loss=5.6030, Acc=0.238, 
2025-10-07 11:53:45,356 - training.trainer - INFO - Epoch 29, Step 100006: Loss=5.7416, Acc=0.225, 
2025-10-07 11:53:53,646 - training.trainer - INFO - Epoch 29, Step 100106: Loss=5.4193, Acc=0.289, 
2025-10-07 11:54:01,988 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.7039, Acc=0.393, 
2025-10-07 11:54:10,318 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.8591, Acc=0.241, 
2025-10-07 11:54:18,715 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.9674, Acc=0.280, 
2025-10-07 11:54:27,032 - training.trainer - INFO - Epoch 29, Step 100506: Loss=4.8545, Acc=0.286, 
2025-10-07 11:54:35,347 - training.trainer - INFO - Epoch 29, Step 100606: Loss=6.4997, Acc=0.143, 
2025-10-07 11:54:43,609 - training.trainer - INFO - Epoch 29, Step 100706: Loss=5.7244, Acc=0.290, 
2025-10-07 11:54:51,945 - training.trainer - INFO - Epoch 29, Step 100806: Loss=6.2946, Acc=0.133, 
2025-10-07 11:55:00,271 - training.trainer - INFO - Epoch 29, Step 100906: Loss=6.0792, Acc=0.333, 
2025-10-07 11:55:08,534 - training.trainer - INFO - Epoch 29, Step 101006: Loss=6.0487, Acc=0.222, 
2025-10-07 11:55:16,830 - training.trainer - INFO - Epoch 29, Step 101106: Loss=5.9353, Acc=0.268, 
2025-10-07 11:55:25,193 - training.trainer - INFO - Epoch 29, Step 101206: Loss=5.4714, Acc=0.303, 
2025-10-07 11:55:33,450 - training.trainer - INFO - Epoch 29, Step 101306: Loss=6.2619, Acc=0.250, 
2025-10-07 11:55:41,703 - training.trainer - INFO - Epoch 29, Step 101406: Loss=6.1869, Acc=0.216, 
2025-10-07 11:56:01,437 - training.trainer - INFO - Epoch 30/100 completed in 294.04s - Train Loss: 5.4973, Train Acc: 0.280, Val Loss: 5.6972, Val Acc: 0.261
2025-10-07 11:56:01,778 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-10-07 11:56:02,471 - training.trainer - INFO - New best model saved with validation loss: 5.6972
2025-10-07 11:56:02,471 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-10-07 11:56:11,277 - training.trainer - INFO - Epoch 30, Step 101589: Loss=5.6750, Acc=0.205, 
2025-10-07 11:56:19,592 - training.trainer - INFO - Epoch 30, Step 101689: Loss=6.4152, Acc=0.222, 
2025-10-07 11:56:28,000 - training.trainer - INFO - Epoch 30, Step 101789: Loss=4.6450, Acc=0.364, 
2025-10-07 11:56:36,495 - training.trainer - INFO - Epoch 30, Step 101889: Loss=5.1371, Acc=0.347, 
2025-10-07 11:56:45,056 - training.trainer - INFO - Epoch 30, Step 101989: Loss=5.2368, Acc=0.291, 
2025-10-07 11:56:55,002 - training.trainer - INFO - Epoch 30, Step 102089: Loss=4.0566, Acc=0.324, 
2025-10-07 11:57:03,351 - training.trainer - INFO - Epoch 30, Step 102189: Loss=6.3671, Acc=0.259, 
2025-10-07 11:57:11,703 - training.trainer - INFO - Epoch 30, Step 102289: Loss=5.7495, Acc=0.190, 
2025-10-07 11:57:20,074 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.7542, Acc=0.256, 
2025-10-07 11:57:28,460 - training.trainer - INFO - Epoch 30, Step 102489: Loss=6.1392, Acc=0.190, 
2025-10-07 11:57:37,082 - training.trainer - INFO - Epoch 30, Step 102589: Loss=5.2127, Acc=0.235, 
2025-10-07 11:57:45,729 - training.trainer - INFO - Epoch 30, Step 102689: Loss=5.4920, Acc=0.256, 
2025-10-07 11:57:53,237 - training.trainer - INFO - Epoch 30, Step 102789: Loss=6.0617, Acc=0.244, 
2025-10-07 11:58:01,307 - training.trainer - INFO - Epoch 30, Step 102889: Loss=5.1148, Acc=0.444, 
2025-10-07 11:58:09,679 - training.trainer - INFO - Epoch 30, Step 102989: Loss=5.8761, Acc=0.200, 
2025-10-07 11:58:18,068 - training.trainer - INFO - Epoch 30, Step 103089: Loss=5.7976, Acc=0.280, 
2025-10-07 11:58:26,474 - training.trainer - INFO - Epoch 30, Step 103189: Loss=6.1486, Acc=0.182, 
2025-10-07 11:58:34,995 - training.trainer - INFO - Epoch 30, Step 103289: Loss=5.9935, Acc=0.192, 
2025-10-07 11:58:43,441 - training.trainer - INFO - Epoch 30, Step 103389: Loss=5.1032, Acc=0.250, 
2025-10-07 11:58:51,686 - training.trainer - INFO - Epoch 30, Step 103489: Loss=5.8820, Acc=0.314, 
2025-10-07 11:59:00,036 - training.trainer - INFO - Epoch 30, Step 103589: Loss=4.2986, Acc=0.357, 
2025-10-07 11:59:08,478 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.1101, Acc=0.316, 
2025-10-07 11:59:17,051 - training.trainer - INFO - Epoch 30, Step 103789: Loss=6.2578, Acc=0.190, 
2025-10-07 11:59:25,481 - training.trainer - INFO - Epoch 30, Step 103889: Loss=4.8994, Acc=0.407, 
2025-10-07 11:59:33,974 - training.trainer - INFO - Epoch 30, Step 103989: Loss=5.0748, Acc=0.419, 
2025-10-07 11:59:42,272 - training.trainer - INFO - Epoch 30, Step 104089: Loss=5.2158, Acc=0.263, 
2025-10-07 11:59:50,788 - training.trainer - INFO - Epoch 30, Step 104189: Loss=5.9525, Acc=0.219, 
2025-10-07 11:59:59,205 - training.trainer - INFO - Epoch 30, Step 104289: Loss=5.7407, Acc=0.204, 
2025-10-07 12:00:07,507 - training.trainer - INFO - Epoch 30, Step 104389: Loss=5.4925, Acc=0.263, 
2025-10-07 12:00:15,872 - training.trainer - INFO - Epoch 30, Step 104489: Loss=4.6906, Acc=0.222, 
2025-10-07 12:00:24,429 - training.trainer - INFO - Epoch 30, Step 104589: Loss=5.4458, Acc=0.280, 
2025-10-07 12:00:32,906 - training.trainer - INFO - Epoch 30, Step 104689: Loss=5.3273, Acc=0.280, 
2025-10-07 12:00:41,387 - training.trainer - INFO - Epoch 30, Step 104789: Loss=6.2282, Acc=0.208, 
2025-10-07 12:01:01,077 - training.trainer - INFO - Epoch 31/100 completed in 298.61s - Train Loss: 5.4867, Train Acc: 0.280, Val Loss: 5.6993, Val Acc: 0.258
2025-10-07 12:01:09,967 - training.trainer - INFO - Epoch 31, Step 104972: Loss=5.8896, Acc=0.226, 
2025-10-07 12:01:18,244 - training.trainer - INFO - Epoch 31, Step 105072: Loss=5.4038, Acc=0.292, 
2025-10-07 12:01:26,600 - training.trainer - INFO - Epoch 31, Step 105172: Loss=6.1685, Acc=0.182, 
2025-10-07 12:01:34,947 - training.trainer - INFO - Epoch 31, Step 105272: Loss=5.4616, Acc=0.260, 
2025-10-07 12:01:43,275 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.9108, Acc=0.286, 
2025-10-07 12:01:51,789 - training.trainer - INFO - Epoch 31, Step 105472: Loss=5.2481, Acc=0.296, 
2025-10-07 12:02:00,194 - training.trainer - INFO - Epoch 31, Step 105572: Loss=4.6430, Acc=0.348, 
2025-10-07 12:02:08,370 - training.trainer - INFO - Epoch 31, Step 105672: Loss=5.0956, Acc=0.391, 
2025-10-07 12:02:16,612 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.2332, Acc=0.222, 
2025-10-07 12:02:24,952 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.3117, Acc=0.261, 
2025-10-07 12:02:33,371 - training.trainer - INFO - Epoch 31, Step 105972: Loss=5.6460, Acc=0.156, 
2025-10-07 12:02:41,566 - training.trainer - INFO - Epoch 31, Step 106072: Loss=6.2705, Acc=0.169, 
2025-10-07 12:02:49,898 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.7747, Acc=0.263, 
2025-10-07 12:02:58,358 - training.trainer - INFO - Epoch 31, Step 106272: Loss=4.3185, Acc=0.450, 
2025-10-07 12:03:06,661 - training.trainer - INFO - Epoch 31, Step 106372: Loss=6.4539, Acc=0.208, 
2025-10-07 12:03:15,008 - training.trainer - INFO - Epoch 31, Step 106472: Loss=4.7715, Acc=0.381, 
2025-10-07 12:03:23,432 - training.trainer - INFO - Epoch 31, Step 106572: Loss=6.0758, Acc=0.192, 
2025-10-07 12:03:31,641 - training.trainer - INFO - Epoch 31, Step 106672: Loss=5.9440, Acc=0.206, 
2025-10-07 12:03:39,972 - training.trainer - INFO - Epoch 31, Step 106772: Loss=5.7472, Acc=0.211, 
2025-10-07 12:03:48,444 - training.trainer - INFO - Epoch 31, Step 106872: Loss=5.8727, Acc=0.200, 
2025-10-07 12:03:56,820 - training.trainer - INFO - Epoch 31, Step 106972: Loss=5.2974, Acc=0.320, 
2025-10-07 12:04:05,092 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.4516, Acc=0.320, 
2025-10-07 12:04:13,434 - training.trainer - INFO - Epoch 31, Step 107172: Loss=6.0477, Acc=0.265, 
2025-10-07 12:04:21,986 - training.trainer - INFO - Epoch 31, Step 107272: Loss=5.6761, Acc=0.185, 
2025-10-07 12:04:30,310 - training.trainer - INFO - Epoch 31, Step 107372: Loss=6.2399, Acc=0.122, 
2025-10-07 12:04:38,784 - training.trainer - INFO - Epoch 31, Step 107472: Loss=4.9269, Acc=0.222, 
2025-10-07 12:04:47,154 - training.trainer - INFO - Epoch 31, Step 107572: Loss=6.0608, Acc=0.256, 
2025-10-07 12:04:55,789 - training.trainer - INFO - Epoch 31, Step 107672: Loss=5.3376, Acc=0.320, 
2025-10-07 12:05:04,244 - training.trainer - INFO - Epoch 31, Step 107772: Loss=5.8991, Acc=0.256, 
2025-10-07 12:05:12,686 - training.trainer - INFO - Epoch 31, Step 107872: Loss=5.8615, Acc=0.220, 
2025-10-07 12:05:21,226 - training.trainer - INFO - Epoch 31, Step 107972: Loss=5.5321, Acc=0.250, 
2025-10-07 12:05:29,695 - training.trainer - INFO - Epoch 31, Step 108072: Loss=4.9757, Acc=0.476, 
2025-10-07 12:05:38,131 - training.trainer - INFO - Epoch 31, Step 108172: Loss=5.8465, Acc=0.176, 
2025-10-07 12:05:58,099 - training.trainer - INFO - Epoch 32/100 completed in 297.02s - Train Loss: 5.4718, Train Acc: 0.283, Val Loss: 5.6980, Val Acc: 0.263
2025-10-07 12:06:06,206 - training.trainer - INFO - Epoch 32, Step 108355: Loss=5.4625, Acc=0.400, 
2025-10-07 12:06:13,910 - training.trainer - INFO - Epoch 32, Step 108455: Loss=6.0286, Acc=0.206, 
2025-10-07 12:06:21,659 - training.trainer - INFO - Epoch 32, Step 108555: Loss=4.3846, Acc=0.355, 
2025-10-07 12:06:29,766 - training.trainer - INFO - Epoch 32, Step 108655: Loss=4.9039, Acc=0.462, 
2025-10-07 12:06:38,079 - training.trainer - INFO - Epoch 32, Step 108755: Loss=5.4413, Acc=0.257, 
2025-10-07 12:06:46,369 - training.trainer - INFO - Epoch 32, Step 108855: Loss=6.4898, Acc=0.238, 
2025-10-07 12:06:54,585 - training.trainer - INFO - Epoch 32, Step 108955: Loss=6.1636, Acc=0.286, 
2025-10-07 12:07:02,867 - training.trainer - INFO - Epoch 32, Step 109055: Loss=5.2559, Acc=0.310, 
2025-10-07 12:07:11,153 - training.trainer - INFO - Epoch 32, Step 109155: Loss=6.0713, Acc=0.255, 
2025-10-07 12:07:19,558 - training.trainer - INFO - Epoch 32, Step 109255: Loss=6.0544, Acc=0.196, 
2025-10-07 12:07:28,049 - training.trainer - INFO - Epoch 32, Step 109355: Loss=6.1240, Acc=0.192, 
2025-10-07 12:07:36,237 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.8960, Acc=0.238, 
2025-10-07 12:07:44,493 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.5296, Acc=0.171, 
2025-10-07 12:07:52,846 - training.trainer - INFO - Epoch 32, Step 109655: Loss=4.6371, Acc=0.438, 
2025-10-07 12:08:01,369 - training.trainer - INFO - Epoch 32, Step 109755: Loss=5.9085, Acc=0.185, 
2025-10-07 12:08:09,642 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.7766, Acc=0.278, 
2025-10-07 12:08:17,967 - training.trainer - INFO - Epoch 32, Step 109955: Loss=5.8283, Acc=0.267, 
2025-10-07 12:08:26,371 - training.trainer - INFO - Epoch 32, Step 110055: Loss=6.4912, Acc=0.123, 
2025-10-07 12:08:34,760 - training.trainer - INFO - Epoch 32, Step 110155: Loss=5.4615, Acc=0.263, 
2025-10-07 12:08:43,250 - training.trainer - INFO - Epoch 32, Step 110255: Loss=6.0860, Acc=0.348, 
2025-10-07 12:08:51,573 - training.trainer - INFO - Epoch 32, Step 110355: Loss=5.3765, Acc=0.239, 
2025-10-07 12:08:59,855 - training.trainer - INFO - Epoch 32, Step 110455: Loss=5.4917, Acc=0.389, 
2025-10-07 12:09:08,273 - training.trainer - INFO - Epoch 32, Step 110555: Loss=5.6663, Acc=0.286, 
2025-10-07 12:09:16,609 - training.trainer - INFO - Epoch 32, Step 110655: Loss=4.8121, Acc=0.357, 
2025-10-07 12:09:24,931 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.7169, Acc=0.226, 
2025-10-07 12:09:33,293 - training.trainer - INFO - Epoch 32, Step 110855: Loss=5.5653, Acc=0.280, 
2025-10-07 12:09:41,728 - training.trainer - INFO - Epoch 32, Step 110955: Loss=5.5390, Acc=0.265, 
2025-10-07 12:09:49,999 - training.trainer - INFO - Epoch 32, Step 111055: Loss=6.4618, Acc=0.146, 
2025-10-07 12:09:58,269 - training.trainer - INFO - Epoch 32, Step 111155: Loss=5.3927, Acc=0.462, 
2025-10-07 12:10:06,563 - training.trainer - INFO - Epoch 32, Step 111255: Loss=4.3565, Acc=0.429, 
2025-10-07 12:10:14,993 - training.trainer - INFO - Epoch 32, Step 111355: Loss=4.6922, Acc=0.308, 
2025-10-07 12:10:23,417 - training.trainer - INFO - Epoch 32, Step 111455: Loss=5.9097, Acc=0.230, 
2025-10-07 12:10:31,601 - training.trainer - INFO - Epoch 32, Step 111555: Loss=6.1396, Acc=0.157, 
2025-10-07 12:10:51,320 - training.trainer - INFO - Epoch 33/100 completed in 293.22s - Train Loss: 5.4587, Train Acc: 0.284, Val Loss: 5.7114, Val Acc: 0.263
2025-10-07 12:10:59,396 - training.trainer - INFO - Epoch 33, Step 111738: Loss=6.1228, Acc=0.137, 
2025-10-07 12:11:07,274 - training.trainer - INFO - Epoch 33, Step 111838: Loss=5.1119, Acc=0.372, 
2025-10-07 12:11:15,060 - training.trainer - INFO - Epoch 33, Step 111938: Loss=4.5708, Acc=0.391, 
2025-10-07 12:11:23,041 - training.trainer - INFO - Epoch 33, Step 112038: Loss=5.6535, Acc=0.259, 
2025-10-07 12:11:30,850 - training.trainer - INFO - Epoch 33, Step 112138: Loss=6.2334, Acc=0.135, 
2025-10-07 12:11:38,693 - training.trainer - INFO - Epoch 33, Step 112238: Loss=5.6093, Acc=0.180, 
2025-10-07 12:11:46,747 - training.trainer - INFO - Epoch 33, Step 112338: Loss=4.6669, Acc=0.333, 
2025-10-07 12:11:54,720 - training.trainer - INFO - Epoch 33, Step 112438: Loss=5.5681, Acc=0.257, 
2025-10-07 12:12:02,871 - training.trainer - INFO - Epoch 33, Step 112538: Loss=6.1949, Acc=0.139, 
2025-10-07 12:12:11,124 - training.trainer - INFO - Epoch 33, Step 112638: Loss=5.7573, Acc=0.208, 
2025-10-07 12:12:19,311 - training.trainer - INFO - Epoch 33, Step 112738: Loss=5.4652, Acc=0.235, 
2025-10-07 12:12:27,752 - training.trainer - INFO - Epoch 33, Step 112838: Loss=3.7703, Acc=0.476, 
2025-10-07 12:12:36,049 - training.trainer - INFO - Epoch 33, Step 112938: Loss=4.9895, Acc=0.238, 
2025-10-07 12:12:44,360 - training.trainer - INFO - Epoch 33, Step 113038: Loss=5.7275, Acc=0.244, 
2025-10-07 12:12:52,535 - training.trainer - INFO - Epoch 33, Step 113138: Loss=4.2240, Acc=0.484, 
2025-10-07 12:13:00,971 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.8388, Acc=0.222, 
2025-10-07 12:13:09,717 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.5512, Acc=0.280, 
2025-10-07 12:13:18,312 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.3111, Acc=0.381, 
2025-10-07 12:13:26,745 - training.trainer - INFO - Epoch 33, Step 113538: Loss=5.5150, Acc=0.300, 
2025-10-07 12:13:35,059 - training.trainer - INFO - Epoch 33, Step 113638: Loss=5.1331, Acc=0.280, 
2025-10-07 12:13:43,362 - training.trainer - INFO - Epoch 33, Step 113738: Loss=5.1436, Acc=0.286, 
2025-10-07 12:13:51,627 - training.trainer - INFO - Epoch 33, Step 113838: Loss=4.0708, Acc=0.476, 
2025-10-07 12:13:59,848 - training.trainer - INFO - Epoch 33, Step 113938: Loss=3.8749, Acc=0.581, 
2025-10-07 12:14:08,090 - training.trainer - INFO - Epoch 33, Step 114038: Loss=6.4863, Acc=0.170, 
2025-10-07 12:14:16,451 - training.trainer - INFO - Epoch 33, Step 114138: Loss=5.3092, Acc=0.279, 
2025-10-07 12:14:24,690 - training.trainer - INFO - Epoch 33, Step 114238: Loss=5.9527, Acc=0.215, 
2025-10-07 12:14:32,899 - training.trainer - INFO - Epoch 33, Step 114338: Loss=5.5730, Acc=0.323, 
2025-10-07 12:14:41,252 - training.trainer - INFO - Epoch 33, Step 114438: Loss=4.5535, Acc=0.348, 
2025-10-07 12:14:49,893 - training.trainer - INFO - Epoch 33, Step 114538: Loss=5.4372, Acc=0.275, 
2025-10-07 12:14:58,317 - training.trainer - INFO - Epoch 33, Step 114638: Loss=6.1645, Acc=0.220, 
2025-10-07 12:15:06,545 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.7652, Acc=0.241, 
2025-10-07 12:15:14,901 - training.trainer - INFO - Epoch 33, Step 114838: Loss=6.1054, Acc=0.197, 
2025-10-07 12:15:23,362 - training.trainer - INFO - Epoch 33, Step 114938: Loss=5.8188, Acc=0.318, 
2025-10-07 12:15:42,877 - training.trainer - INFO - Epoch 34/100 completed in 291.56s - Train Loss: 5.4460, Train Acc: 0.287, Val Loss: 5.7005, Val Acc: 0.264
2025-10-07 12:15:51,517 - training.trainer - INFO - Epoch 34, Step 115121: Loss=5.8997, Acc=0.250, 
2025-10-07 12:15:59,634 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.4129, Acc=0.194, 
2025-10-07 12:16:08,102 - training.trainer - INFO - Epoch 34, Step 115321: Loss=5.3381, Acc=0.263, 
2025-10-07 12:16:16,382 - training.trainer - INFO - Epoch 34, Step 115421: Loss=4.9499, Acc=0.260, 
2025-10-07 12:16:24,471 - training.trainer - INFO - Epoch 34, Step 115521: Loss=6.7688, Acc=0.197, 
2025-10-07 12:16:32,474 - training.trainer - INFO - Epoch 34, Step 115621: Loss=5.3333, Acc=0.291, 
2025-10-07 12:16:40,926 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.8226, Acc=0.219, 
2025-10-07 12:16:49,336 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.5047, Acc=0.298, 
2025-10-07 12:16:57,752 - training.trainer - INFO - Epoch 34, Step 115921: Loss=5.7893, Acc=0.286, 
2025-10-07 12:17:06,073 - training.trainer - INFO - Epoch 34, Step 116021: Loss=5.1948, Acc=0.209, 
2025-10-07 12:17:14,450 - training.trainer - INFO - Epoch 34, Step 116121: Loss=5.8575, Acc=0.244, 
2025-10-07 12:17:22,901 - training.trainer - INFO - Epoch 34, Step 116221: Loss=6.2495, Acc=0.304, 
2025-10-07 12:17:31,343 - training.trainer - INFO - Epoch 34, Step 116321: Loss=5.0836, Acc=0.250, 
2025-10-07 12:17:39,783 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.4669, Acc=0.250, 
2025-10-07 12:17:48,145 - training.trainer - INFO - Epoch 34, Step 116521: Loss=5.2001, Acc=0.458, 
2025-10-07 12:17:56,658 - training.trainer - INFO - Epoch 34, Step 116621: Loss=5.1974, Acc=0.286, 
2025-10-07 12:18:05,065 - training.trainer - INFO - Epoch 34, Step 116721: Loss=4.9110, Acc=0.304, 
2025-10-07 12:18:13,448 - training.trainer - INFO - Epoch 34, Step 116821: Loss=4.8946, Acc=0.267, 
2025-10-07 12:18:21,895 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.9771, Acc=0.267, 
2025-10-07 12:18:30,355 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.6951, Acc=0.265, 
2025-10-07 12:18:38,768 - training.trainer - INFO - Epoch 34, Step 117121: Loss=5.5880, Acc=0.211, 
2025-10-07 12:18:47,501 - training.trainer - INFO - Epoch 34, Step 117221: Loss=5.2796, Acc=0.348, 
2025-10-07 12:18:55,967 - training.trainer - INFO - Epoch 34, Step 117321: Loss=5.7266, Acc=0.312, 
2025-10-07 12:19:04,452 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.4786, Acc=0.320, 
2025-10-07 12:19:12,770 - training.trainer - INFO - Epoch 34, Step 117521: Loss=3.7429, Acc=0.514, 
2025-10-07 12:19:21,137 - training.trainer - INFO - Epoch 34, Step 117621: Loss=4.0938, Acc=0.500, 
2025-10-07 12:19:29,869 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.8438, Acc=0.181, 
2025-10-07 12:19:39,188 - training.trainer - INFO - Epoch 34, Step 117821: Loss=5.2740, Acc=0.400, 
2025-10-07 12:19:48,550 - training.trainer - INFO - Epoch 34, Step 117921: Loss=5.2456, Acc=0.200, 
2025-10-07 12:19:57,978 - training.trainer - INFO - Epoch 34, Step 118021: Loss=4.1815, Acc=0.318, 
2025-10-07 12:20:07,506 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.2714, Acc=0.393, 
2025-10-07 12:20:17,277 - training.trainer - INFO - Epoch 34, Step 118221: Loss=5.2538, Acc=0.189, 
2025-10-07 12:20:26,778 - training.trainer - INFO - Epoch 34, Step 118321: Loss=6.0757, Acc=0.229, 
2025-10-07 12:20:48,616 - training.trainer - INFO - Epoch 35/100 completed in 305.74s - Train Loss: 5.4283, Train Acc: 0.290, Val Loss: 5.6956, Val Acc: 0.263
2025-10-07 12:20:49,024 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-10-07 12:20:49,677 - training.trainer - INFO - New best model saved with validation loss: 5.6956
2025-10-07 12:20:49,677 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-10-07 12:20:58,249 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.4552, Acc=0.278, 
2025-10-07 12:21:06,512 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.7271, Acc=0.194, 
2025-10-07 12:21:15,875 - training.trainer - INFO - Epoch 35, Step 118704: Loss=4.0082, Acc=0.476, 
2025-10-07 12:21:25,288 - training.trainer - INFO - Epoch 35, Step 118804: Loss=5.2643, Acc=0.317, 
2025-10-07 12:21:33,754 - training.trainer - INFO - Epoch 35, Step 118904: Loss=4.9284, Acc=0.375, 
2025-10-07 12:21:42,240 - training.trainer - INFO - Epoch 35, Step 119004: Loss=5.6713, Acc=0.235, 
2025-10-07 12:21:50,521 - training.trainer - INFO - Epoch 35, Step 119104: Loss=4.9523, Acc=0.351, 
2025-10-07 12:21:58,889 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.1423, Acc=0.300, 
2025-10-07 12:22:07,086 - training.trainer - INFO - Epoch 35, Step 119304: Loss=5.6803, Acc=0.242, 
2025-10-07 12:22:15,394 - training.trainer - INFO - Epoch 35, Step 119404: Loss=5.1900, Acc=0.278, 
2025-10-07 12:22:23,718 - training.trainer - INFO - Epoch 35, Step 119504: Loss=4.4316, Acc=0.423, 
2025-10-07 12:22:32,022 - training.trainer - INFO - Epoch 35, Step 119604: Loss=4.6684, Acc=0.423, 
2025-10-07 12:22:40,320 - training.trainer - INFO - Epoch 35, Step 119704: Loss=5.3475, Acc=0.143, 
2025-10-07 12:22:48,623 - training.trainer - INFO - Epoch 35, Step 119804: Loss=4.7784, Acc=0.321, 
2025-10-07 12:22:56,964 - training.trainer - INFO - Epoch 35, Step 119904: Loss=6.1485, Acc=0.222, 
2025-10-07 12:23:05,391 - training.trainer - INFO - Epoch 35, Step 120004: Loss=5.8764, Acc=0.167, 
2025-10-07 12:23:13,876 - training.trainer - INFO - Epoch 35, Step 120104: Loss=6.3879, Acc=0.200, 
2025-10-07 12:23:22,394 - training.trainer - INFO - Epoch 35, Step 120204: Loss=5.8992, Acc=0.240, 
2025-10-07 12:23:30,674 - training.trainer - INFO - Epoch 35, Step 120304: Loss=3.6547, Acc=0.556, 
2025-10-07 12:23:39,112 - training.trainer - INFO - Epoch 35, Step 120404: Loss=5.8394, Acc=0.423, 
2025-10-07 12:23:47,425 - training.trainer - INFO - Epoch 35, Step 120504: Loss=6.0381, Acc=0.238, 
2025-10-07 12:23:56,083 - training.trainer - INFO - Epoch 35, Step 120604: Loss=5.9414, Acc=0.138, 
2025-10-07 12:24:04,470 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.1703, Acc=0.375, 
2025-10-07 12:24:12,837 - training.trainer - INFO - Epoch 35, Step 120804: Loss=5.4713, Acc=0.333, 
2025-10-07 12:24:21,224 - training.trainer - INFO - Epoch 35, Step 120904: Loss=5.1254, Acc=0.300, 
2025-10-07 12:24:29,647 - training.trainer - INFO - Epoch 35, Step 121004: Loss=5.8248, Acc=0.192, 
2025-10-07 12:24:37,971 - training.trainer - INFO - Epoch 35, Step 121104: Loss=6.1836, Acc=0.206, 
2025-10-07 12:24:46,287 - training.trainer - INFO - Epoch 35, Step 121204: Loss=6.1275, Acc=0.190, 
2025-10-07 12:24:54,594 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.9786, Acc=0.222, 
2025-10-07 12:25:02,982 - training.trainer - INFO - Epoch 35, Step 121404: Loss=5.6989, Acc=0.324, 
2025-10-07 12:25:11,332 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.2946, Acc=0.352, 
2025-10-07 12:25:19,695 - training.trainer - INFO - Epoch 35, Step 121604: Loss=5.9541, Acc=0.171, 
2025-10-07 12:25:27,996 - training.trainer - INFO - Epoch 35, Step 121704: Loss=6.4444, Acc=0.175, 
2025-10-07 12:25:48,122 - training.trainer - INFO - Epoch 36/100 completed in 298.44s - Train Loss: 5.4225, Train Acc: 0.291, Val Loss: 5.6927, Val Acc: 0.265
2025-10-07 12:25:48,962 - training.trainer - INFO - New best model saved with validation loss: 5.6927
2025-10-07 12:25:48,963 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_36.pt
2025-10-07 12:25:57,779 - training.trainer - INFO - Epoch 36, Step 121887: Loss=4.6783, Acc=0.333, 
2025-10-07 12:26:06,345 - training.trainer - INFO - Epoch 36, Step 121987: Loss=4.7621, Acc=0.407, 
2025-10-07 12:26:14,810 - training.trainer - INFO - Epoch 36, Step 122087: Loss=6.1216, Acc=0.243, 
2025-10-07 12:26:23,097 - training.trainer - INFO - Epoch 36, Step 122187: Loss=5.0014, Acc=0.325, 
2025-10-07 12:26:31,332 - training.trainer - INFO - Epoch 36, Step 122287: Loss=4.3307, Acc=0.333, 
2025-10-07 12:26:39,833 - training.trainer - INFO - Epoch 36, Step 122387: Loss=4.8503, Acc=0.341, 
2025-10-07 12:26:48,142 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.8217, Acc=0.293, 
2025-10-07 12:26:56,611 - training.trainer - INFO - Epoch 36, Step 122587: Loss=5.3831, Acc=0.231, 
2025-10-07 12:27:05,122 - training.trainer - INFO - Epoch 36, Step 122687: Loss=6.0619, Acc=0.220, 
2025-10-07 12:27:13,583 - training.trainer - INFO - Epoch 36, Step 122787: Loss=5.5038, Acc=0.302, 
2025-10-07 12:27:22,009 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.4852, Acc=0.328, 
2025-10-07 12:27:30,024 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.8160, Acc=0.262, 
2025-10-07 12:27:37,906 - training.trainer - INFO - Epoch 36, Step 123087: Loss=4.7460, Acc=0.348, 
2025-10-07 12:27:46,203 - training.trainer - INFO - Epoch 36, Step 123187: Loss=4.8557, Acc=0.450, 
2025-10-07 12:27:54,617 - training.trainer - INFO - Epoch 36, Step 123287: Loss=3.5358, Acc=0.407, 
2025-10-07 12:28:03,092 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.2994, Acc=0.263, 
2025-10-07 12:28:11,373 - training.trainer - INFO - Epoch 36, Step 123487: Loss=5.6414, Acc=0.265, 
2025-10-07 12:28:20,737 - training.trainer - INFO - Epoch 36, Step 123587: Loss=5.7615, Acc=0.200, 
2025-10-07 12:28:28,957 - training.trainer - INFO - Epoch 36, Step 123687: Loss=5.9957, Acc=0.176, 
2025-10-07 12:28:37,563 - training.trainer - INFO - Epoch 36, Step 123787: Loss=6.1675, Acc=0.188, 
2025-10-07 12:28:45,968 - training.trainer - INFO - Epoch 36, Step 123887: Loss=4.7789, Acc=0.438, 
2025-10-07 12:28:54,525 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.8387, Acc=0.264, 
2025-10-07 12:29:03,179 - training.trainer - INFO - Epoch 36, Step 124087: Loss=6.2493, Acc=0.197, 
2025-10-07 12:29:11,702 - training.trainer - INFO - Epoch 36, Step 124187: Loss=5.4083, Acc=0.243, 
2025-10-07 12:29:20,130 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.8419, Acc=0.250, 
2025-10-07 12:29:28,428 - training.trainer - INFO - Epoch 36, Step 124387: Loss=5.1418, Acc=0.277, 
2025-10-07 12:29:36,863 - training.trainer - INFO - Epoch 36, Step 124487: Loss=5.8521, Acc=0.232, 
2025-10-07 12:29:45,471 - training.trainer - INFO - Epoch 36, Step 124587: Loss=5.5405, Acc=0.297, 
2025-10-07 12:29:53,947 - training.trainer - INFO - Epoch 36, Step 124687: Loss=5.7427, Acc=0.189, 
2025-10-07 12:30:02,531 - training.trainer - INFO - Epoch 36, Step 124787: Loss=4.1534, Acc=0.425, 
2025-10-07 12:30:10,913 - training.trainer - INFO - Epoch 36, Step 124887: Loss=5.6872, Acc=0.345, 
2025-10-07 12:30:19,293 - training.trainer - INFO - Epoch 36, Step 124987: Loss=4.1408, Acc=0.542, 
2025-10-07 12:30:27,001 - training.trainer - INFO - Epoch 36, Step 125087: Loss=4.7314, Acc=0.154, 
2025-10-07 12:30:47,117 - training.trainer - INFO - Epoch 37/100 completed in 298.15s - Train Loss: 5.4087, Train Acc: 0.294, Val Loss: 5.6937, Val Acc: 0.266
2025-10-07 12:30:55,907 - training.trainer - INFO - Epoch 37, Step 125270: Loss=4.8908, Acc=0.281, 
2025-10-07 12:31:04,338 - training.trainer - INFO - Epoch 37, Step 125370: Loss=5.0248, Acc=0.235, 
2025-10-07 12:31:12,846 - training.trainer - INFO - Epoch 37, Step 125470: Loss=5.2239, Acc=0.244, 
2025-10-07 12:31:21,331 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.7726, Acc=0.333, 
2025-10-07 12:31:29,724 - training.trainer - INFO - Epoch 37, Step 125670: Loss=5.4313, Acc=0.250, 
2025-10-07 12:31:38,047 - training.trainer - INFO - Epoch 37, Step 125770: Loss=4.2268, Acc=0.364, 
2025-10-07 12:31:46,383 - training.trainer - INFO - Epoch 37, Step 125870: Loss=4.7027, Acc=0.310, 
2025-10-07 12:31:54,809 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.2691, Acc=0.290, 
2025-10-07 12:32:03,216 - training.trainer - INFO - Epoch 37, Step 126070: Loss=5.8629, Acc=0.262, 
2025-10-07 12:32:11,544 - training.trainer - INFO - Epoch 37, Step 126170: Loss=5.2623, Acc=0.325, 
2025-10-07 12:32:19,791 - training.trainer - INFO - Epoch 37, Step 126270: Loss=4.6339, Acc=0.444, 
2025-10-07 12:32:28,032 - training.trainer - INFO - Epoch 37, Step 126370: Loss=5.3443, Acc=0.267, 
2025-10-07 12:32:36,551 - training.trainer - INFO - Epoch 37, Step 126470: Loss=5.2425, Acc=0.324, 
2025-10-07 12:32:45,123 - training.trainer - INFO - Epoch 37, Step 126570: Loss=5.6440, Acc=0.174, 
2025-10-07 12:32:53,468 - training.trainer - INFO - Epoch 37, Step 126670: Loss=5.8819, Acc=0.197, 
2025-10-07 12:33:01,950 - training.trainer - INFO - Epoch 37, Step 126770: Loss=5.2835, Acc=0.292, 
2025-10-07 12:33:10,244 - training.trainer - INFO - Epoch 37, Step 126870: Loss=5.0288, Acc=0.308, 
2025-10-07 12:33:18,676 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.5890, Acc=0.297, 
2025-10-07 12:33:27,105 - training.trainer - INFO - Epoch 37, Step 127070: Loss=5.2413, Acc=0.417, 
2025-10-07 12:33:35,566 - training.trainer - INFO - Epoch 37, Step 127170: Loss=5.5624, Acc=0.231, 
2025-10-07 12:33:44,021 - training.trainer - INFO - Epoch 37, Step 127270: Loss=5.4036, Acc=0.297, 
2025-10-07 12:33:52,335 - training.trainer - INFO - Epoch 37, Step 127370: Loss=5.9122, Acc=0.267, 
2025-10-07 12:34:00,705 - training.trainer - INFO - Epoch 37, Step 127470: Loss=6.1003, Acc=0.292, 
2025-10-07 12:34:09,171 - training.trainer - INFO - Epoch 37, Step 127570: Loss=4.1039, Acc=0.417, 
2025-10-07 12:34:17,667 - training.trainer - INFO - Epoch 37, Step 127670: Loss=4.3911, Acc=0.438, 
2025-10-07 12:34:25,986 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.1294, Acc=0.417, 
2025-10-07 12:34:34,325 - training.trainer - INFO - Epoch 37, Step 127870: Loss=5.5184, Acc=0.280, 
2025-10-07 12:34:42,695 - training.trainer - INFO - Epoch 37, Step 127970: Loss=4.6620, Acc=0.333, 
2025-10-07 12:34:51,165 - training.trainer - INFO - Epoch 37, Step 128070: Loss=6.2780, Acc=0.250, 
2025-10-07 12:34:59,585 - training.trainer - INFO - Epoch 37, Step 128170: Loss=4.9183, Acc=0.317, 
2025-10-07 12:35:08,035 - training.trainer - INFO - Epoch 37, Step 128270: Loss=6.1790, Acc=0.213, 
2025-10-07 12:35:16,401 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.3233, Acc=0.259, 
2025-10-07 12:35:24,848 - training.trainer - INFO - Epoch 37, Step 128470: Loss=5.6873, Acc=0.200, 
2025-10-07 12:35:44,727 - training.trainer - INFO - Epoch 38/100 completed in 297.61s - Train Loss: 5.3990, Train Acc: 0.295, Val Loss: 5.6920, Val Acc: 0.262
2025-10-07 12:35:45,422 - training.trainer - INFO - New best model saved with validation loss: 5.6920
2025-10-07 12:35:45,422 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_38.pt
2025-10-07 12:35:53,808 - training.trainer - INFO - Epoch 38, Step 128653: Loss=6.2561, Acc=0.200, 
2025-10-07 12:36:02,290 - training.trainer - INFO - Epoch 38, Step 128753: Loss=5.5967, Acc=0.269, 
2025-10-07 12:36:10,610 - training.trainer - INFO - Epoch 38, Step 128853: Loss=5.7524, Acc=0.276, 
2025-10-07 12:36:19,014 - training.trainer - INFO - Epoch 38, Step 128953: Loss=5.6964, Acc=0.344, 
2025-10-07 12:36:27,365 - training.trainer - INFO - Epoch 38, Step 129053: Loss=3.6707, Acc=0.550, 
2025-10-07 12:36:35,846 - training.trainer - INFO - Epoch 38, Step 129153: Loss=4.4729, Acc=0.359, 
2025-10-07 12:36:44,221 - training.trainer - INFO - Epoch 38, Step 129253: Loss=5.6432, Acc=0.324, 
2025-10-07 12:36:52,641 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.1964, Acc=0.213, 
2025-10-07 12:37:01,103 - training.trainer - INFO - Epoch 38, Step 129453: Loss=5.1298, Acc=0.267, 
2025-10-07 12:37:09,404 - training.trainer - INFO - Epoch 38, Step 129553: Loss=5.1303, Acc=0.176, 
2025-10-07 12:37:17,737 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.1158, Acc=0.333, 
2025-10-07 12:37:26,121 - training.trainer - INFO - Epoch 38, Step 129753: Loss=4.5584, Acc=0.277, 
2025-10-07 12:37:34,615 - training.trainer - INFO - Epoch 38, Step 129853: Loss=5.6824, Acc=0.276, 
2025-10-07 12:37:42,934 - training.trainer - INFO - Epoch 38, Step 129953: Loss=5.7409, Acc=0.286, 
2025-10-07 12:37:51,356 - training.trainer - INFO - Epoch 38, Step 130053: Loss=3.5415, Acc=0.500, 
2025-10-07 12:37:59,715 - training.trainer - INFO - Epoch 38, Step 130153: Loss=3.7752, Acc=0.600, 
2025-10-07 12:38:08,281 - training.trainer - INFO - Epoch 38, Step 130253: Loss=6.3469, Acc=0.241, 
2025-10-07 12:38:16,614 - training.trainer - INFO - Epoch 38, Step 130353: Loss=5.7094, Acc=0.265, 
2025-10-07 12:38:25,023 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.8915, Acc=0.150, 
2025-10-07 12:38:33,596 - training.trainer - INFO - Epoch 38, Step 130553: Loss=4.1300, Acc=0.429, 
2025-10-07 12:38:42,146 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.5754, Acc=0.297, 
2025-10-07 12:38:50,568 - training.trainer - INFO - Epoch 38, Step 130753: Loss=5.9706, Acc=0.229, 
2025-10-07 12:38:59,162 - training.trainer - INFO - Epoch 38, Step 130853: Loss=5.0977, Acc=0.286, 
2025-10-07 12:39:07,466 - training.trainer - INFO - Epoch 38, Step 130953: Loss=6.3060, Acc=0.257, 
2025-10-07 12:39:15,843 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.7846, Acc=0.278, 
2025-10-07 12:39:24,187 - training.trainer - INFO - Epoch 38, Step 131153: Loss=5.5505, Acc=0.242, 
2025-10-07 12:39:32,498 - training.trainer - INFO - Epoch 38, Step 131253: Loss=6.2885, Acc=0.216, 
2025-10-07 12:39:40,850 - training.trainer - INFO - Epoch 38, Step 131353: Loss=6.5069, Acc=0.186, 
2025-10-07 12:39:49,365 - training.trainer - INFO - Epoch 38, Step 131453: Loss=5.2457, Acc=0.240, 
2025-10-07 12:39:57,653 - training.trainer - INFO - Epoch 38, Step 131553: Loss=5.1176, Acc=0.240, 
2025-10-07 12:40:05,895 - training.trainer - INFO - Epoch 38, Step 131653: Loss=6.3027, Acc=0.242, 
2025-10-07 12:40:14,064 - training.trainer - INFO - Epoch 38, Step 131753: Loss=4.7968, Acc=0.303, 
2025-10-07 12:40:22,606 - training.trainer - INFO - Epoch 38, Step 131853: Loss=6.4142, Acc=0.233, 
2025-10-07 12:40:41,737 - training.trainer - INFO - Epoch 39/100 completed in 296.31s - Train Loss: 5.3759, Train Acc: 0.297, Val Loss: 5.6908, Val Acc: 0.268
2025-10-07 12:40:42,567 - training.trainer - INFO - New best model saved with validation loss: 5.6908
2025-10-07 12:40:42,567 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_39.pt
2025-10-07 12:40:51,356 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.7107, Acc=0.180, 
2025-10-07 12:40:59,751 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.8914, Acc=0.250, 
2025-10-07 12:41:08,111 - training.trainer - INFO - Epoch 39, Step 132236: Loss=4.6097, Acc=0.375, 
2025-10-07 12:41:16,540 - training.trainer - INFO - Epoch 39, Step 132336: Loss=6.7777, Acc=0.194, 
2025-10-07 12:41:25,084 - training.trainer - INFO - Epoch 39, Step 132436: Loss=5.8897, Acc=0.250, 
2025-10-07 12:41:33,717 - training.trainer - INFO - Epoch 39, Step 132536: Loss=5.8408, Acc=0.182, 
2025-10-07 12:41:42,157 - training.trainer - INFO - Epoch 39, Step 132636: Loss=5.9035, Acc=0.213, 
2025-10-07 12:41:50,511 - training.trainer - INFO - Epoch 39, Step 132736: Loss=6.1924, Acc=0.206, 
2025-10-07 12:41:58,954 - training.trainer - INFO - Epoch 39, Step 132836: Loss=5.9663, Acc=0.272, 
2025-10-07 12:42:07,353 - training.trainer - INFO - Epoch 39, Step 132936: Loss=6.0855, Acc=0.243, 
2025-10-07 12:42:15,685 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.0639, Acc=0.312, 
2025-10-07 12:42:24,014 - training.trainer - INFO - Epoch 39, Step 133136: Loss=5.2178, Acc=0.217, 
2025-10-07 12:42:32,497 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.2291, Acc=0.231, 
2025-10-07 12:42:40,793 - training.trainer - INFO - Epoch 39, Step 133336: Loss=5.7508, Acc=0.250, 
2025-10-07 12:42:49,136 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.8688, Acc=0.250, 
2025-10-07 12:42:57,447 - training.trainer - INFO - Epoch 39, Step 133536: Loss=6.1564, Acc=0.264, 
2025-10-07 12:43:05,999 - training.trainer - INFO - Epoch 39, Step 133636: Loss=6.1528, Acc=0.206, 
2025-10-07 12:43:14,291 - training.trainer - INFO - Epoch 39, Step 133736: Loss=6.0682, Acc=0.178, 
2025-10-07 12:43:22,663 - training.trainer - INFO - Epoch 39, Step 133836: Loss=5.9804, Acc=0.221, 
2025-10-07 12:43:31,017 - training.trainer - INFO - Epoch 39, Step 133936: Loss=6.0137, Acc=0.304, 
2025-10-07 12:43:39,531 - training.trainer - INFO - Epoch 39, Step 134036: Loss=5.3320, Acc=0.400, 
2025-10-07 12:43:47,870 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.6156, Acc=0.281, 
2025-10-07 12:43:56,196 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.1451, Acc=0.188, 
2025-10-07 12:44:04,215 - training.trainer - INFO - Epoch 39, Step 134336: Loss=6.3426, Acc=0.200, 
2025-10-07 12:44:12,374 - training.trainer - INFO - Epoch 39, Step 134436: Loss=5.2777, Acc=0.311, 
2025-10-07 12:44:20,483 - training.trainer - INFO - Epoch 39, Step 134536: Loss=6.7280, Acc=0.171, 
2025-10-07 12:44:28,677 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.8808, Acc=0.190, 
2025-10-07 12:44:37,116 - training.trainer - INFO - Epoch 39, Step 134736: Loss=5.5661, Acc=0.250, 
2025-10-07 12:44:45,691 - training.trainer - INFO - Epoch 39, Step 134836: Loss=5.7860, Acc=0.288, 
2025-10-07 12:44:53,923 - training.trainer - INFO - Epoch 39, Step 134936: Loss=4.3769, Acc=0.435, 
2025-10-07 12:45:02,195 - training.trainer - INFO - Epoch 39, Step 135036: Loss=6.0413, Acc=0.216, 
2025-10-07 12:45:10,352 - training.trainer - INFO - Epoch 39, Step 135136: Loss=5.9380, Acc=0.300, 
2025-10-07 12:45:18,409 - training.trainer - INFO - Epoch 39, Step 135236: Loss=6.1852, Acc=0.150, 
2025-10-07 12:45:37,966 - training.trainer - INFO - Epoch 40/100 completed in 295.40s - Train Loss: 5.3708, Train Acc: 0.298, Val Loss: 5.7073, Val Acc: 0.266
2025-10-07 12:45:38,322 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-10-07 12:45:47,213 - training.trainer - INFO - Epoch 40, Step 135419: Loss=5.7154, Acc=0.291, 
2025-10-07 12:45:55,545 - training.trainer - INFO - Epoch 40, Step 135519: Loss=6.7071, Acc=0.226, 
2025-10-07 12:46:03,913 - training.trainer - INFO - Epoch 40, Step 135619: Loss=6.0584, Acc=0.176, 
2025-10-07 12:46:12,102 - training.trainer - INFO - Epoch 40, Step 135719: Loss=5.7060, Acc=0.303, 
2025-10-07 12:46:20,437 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.4000, Acc=0.275, 
2025-10-07 12:46:28,893 - training.trainer - INFO - Epoch 40, Step 135919: Loss=6.0281, Acc=0.291, 
2025-10-07 12:46:37,204 - training.trainer - INFO - Epoch 40, Step 136019: Loss=6.0503, Acc=0.100, 
2025-10-07 12:46:45,712 - training.trainer - INFO - Epoch 40, Step 136119: Loss=5.9364, Acc=0.300, 
2025-10-07 12:46:53,971 - training.trainer - INFO - Epoch 40, Step 136219: Loss=5.5602, Acc=0.214, 
2025-10-07 12:47:02,000 - training.trainer - INFO - Epoch 40, Step 136319: Loss=5.8421, Acc=0.268, 
2025-10-07 12:47:10,433 - training.trainer - INFO - Epoch 40, Step 136419: Loss=5.1429, Acc=0.369, 
2025-10-07 12:47:18,805 - training.trainer - INFO - Epoch 40, Step 136519: Loss=5.6412, Acc=0.233, 
2025-10-07 12:47:27,319 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.9550, Acc=0.213, 
2025-10-07 12:47:35,931 - training.trainer - INFO - Epoch 40, Step 136719: Loss=6.0730, Acc=0.167, 
2025-10-07 12:47:44,486 - training.trainer - INFO - Epoch 40, Step 136819: Loss=6.3476, Acc=0.167, 
2025-10-07 12:47:53,024 - training.trainer - INFO - Epoch 40, Step 136919: Loss=6.3113, Acc=0.318, 
2025-10-07 12:48:01,343 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.7448, Acc=0.222, 
2025-10-07 12:48:09,950 - training.trainer - INFO - Epoch 40, Step 137119: Loss=4.9981, Acc=0.257, 
2025-10-07 12:48:18,397 - training.trainer - INFO - Epoch 40, Step 137219: Loss=6.1470, Acc=0.217, 
2025-10-07 12:48:26,731 - training.trainer - INFO - Epoch 40, Step 137319: Loss=6.0615, Acc=0.255, 
2025-10-07 12:48:34,920 - training.trainer - INFO - Epoch 40, Step 137419: Loss=4.7830, Acc=0.381, 
2025-10-07 12:48:43,321 - training.trainer - INFO - Epoch 40, Step 137519: Loss=5.6400, Acc=0.273, 
2025-10-07 12:48:51,760 - training.trainer - INFO - Epoch 40, Step 137619: Loss=5.4727, Acc=0.306, 
2025-10-07 12:49:00,211 - training.trainer - INFO - Epoch 40, Step 137719: Loss=6.0079, Acc=0.200, 
2025-10-07 12:49:08,705 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.6386, Acc=0.274, 
2025-10-07 12:49:17,215 - training.trainer - INFO - Epoch 40, Step 137919: Loss=5.1869, Acc=0.268, 
2025-10-07 12:49:25,597 - training.trainer - INFO - Epoch 40, Step 138019: Loss=5.3671, Acc=0.242, 
2025-10-07 12:49:33,936 - training.trainer - INFO - Epoch 40, Step 138119: Loss=6.2046, Acc=0.208, 
2025-10-07 12:49:42,390 - training.trainer - INFO - Epoch 40, Step 138219: Loss=5.9931, Acc=0.234, 
2025-10-07 12:49:50,701 - training.trainer - INFO - Epoch 40, Step 138319: Loss=5.9477, Acc=0.256, 
2025-10-07 12:49:58,958 - training.trainer - INFO - Epoch 40, Step 138419: Loss=6.2354, Acc=0.182, 
2025-10-07 12:50:07,270 - training.trainer - INFO - Epoch 40, Step 138519: Loss=4.2269, Acc=0.474, 
2025-10-07 12:50:15,669 - training.trainer - INFO - Epoch 40, Step 138619: Loss=5.2244, Acc=0.298, 
2025-10-07 12:50:36,054 - training.trainer - INFO - Epoch 41/100 completed in 297.73s - Train Loss: 5.3510, Train Acc: 0.302, Val Loss: 5.7041, Val Acc: 0.265
2025-10-07 12:50:43,747 - training.trainer - INFO - Epoch 41, Step 138802: Loss=5.2657, Acc=0.206, 
2025-10-07 12:50:51,024 - training.trainer - INFO - Epoch 41, Step 138902: Loss=5.3048, Acc=0.286, 
2025-10-07 12:50:58,202 - training.trainer - INFO - Epoch 41, Step 139002: Loss=4.6726, Acc=0.286, 
2025-10-07 12:51:05,334 - training.trainer - INFO - Epoch 41, Step 139102: Loss=5.3575, Acc=0.250, 
2025-10-07 12:51:12,463 - training.trainer - INFO - Epoch 41, Step 139202: Loss=5.8628, Acc=0.286, 
2025-10-07 12:51:19,919 - training.trainer - INFO - Epoch 41, Step 139302: Loss=6.1927, Acc=0.160, 
2025-10-07 12:51:27,091 - training.trainer - INFO - Epoch 41, Step 139402: Loss=4.0980, Acc=0.478, 
2025-10-07 12:51:35,049 - training.trainer - INFO - Epoch 41, Step 139502: Loss=6.2201, Acc=0.161, 
2025-10-07 12:51:43,345 - training.trainer - INFO - Epoch 41, Step 139602: Loss=5.0945, Acc=0.222, 
2025-10-07 12:51:51,679 - training.trainer - INFO - Epoch 41, Step 139702: Loss=5.3779, Acc=0.250, 
2025-10-07 12:52:00,133 - training.trainer - INFO - Epoch 41, Step 139802: Loss=5.4330, Acc=0.192, 
2025-10-07 12:52:08,473 - training.trainer - INFO - Epoch 41, Step 139902: Loss=5.9891, Acc=0.203, 
2025-10-07 12:52:16,782 - training.trainer - INFO - Epoch 41, Step 140002: Loss=3.9369, Acc=0.368, 
2025-10-07 12:52:25,100 - training.trainer - INFO - Epoch 41, Step 140102: Loss=5.6479, Acc=0.352, 
2025-10-07 12:52:33,507 - training.trainer - INFO - Epoch 41, Step 140202: Loss=5.3953, Acc=0.346, 
2025-10-07 12:52:42,006 - training.trainer - INFO - Epoch 41, Step 140302: Loss=5.6186, Acc=0.296, 
2025-10-07 12:52:50,398 - training.trainer - INFO - Epoch 41, Step 140402: Loss=4.6192, Acc=0.500, 
2025-10-07 12:52:58,701 - training.trainer - INFO - Epoch 41, Step 140502: Loss=4.6757, Acc=0.344, 
2025-10-07 12:53:07,227 - training.trainer - INFO - Epoch 41, Step 140602: Loss=5.2546, Acc=0.304, 
2025-10-07 12:53:15,538 - training.trainer - INFO - Epoch 41, Step 140702: Loss=4.8796, Acc=0.370, 
2025-10-07 12:53:23,988 - training.trainer - INFO - Epoch 41, Step 140802: Loss=5.3162, Acc=0.375, 
2025-10-07 12:53:32,315 - training.trainer - INFO - Epoch 41, Step 140902: Loss=5.5114, Acc=0.255, 
2025-10-07 12:53:40,453 - training.trainer - INFO - Epoch 41, Step 141002: Loss=4.8799, Acc=0.350, 
2025-10-07 12:53:48,762 - training.trainer - INFO - Epoch 41, Step 141102: Loss=4.5531, Acc=0.417, 
2025-10-07 12:53:56,992 - training.trainer - INFO - Epoch 41, Step 141202: Loss=5.9614, Acc=0.296, 
2025-10-07 12:54:05,357 - training.trainer - INFO - Epoch 41, Step 141302: Loss=5.0264, Acc=0.278, 
2025-10-07 12:54:13,717 - training.trainer - INFO - Epoch 41, Step 141402: Loss=5.8596, Acc=0.254, 
2025-10-07 12:54:22,414 - training.trainer - INFO - Epoch 41, Step 141502: Loss=5.6508, Acc=0.291, 
2025-10-07 12:54:30,643 - training.trainer - INFO - Epoch 41, Step 141602: Loss=5.3697, Acc=0.200, 
2025-10-07 12:54:38,979 - training.trainer - INFO - Epoch 41, Step 141702: Loss=4.6806, Acc=0.429, 
2025-10-07 12:54:47,099 - training.trainer - INFO - Epoch 41, Step 141802: Loss=5.5314, Acc=0.310, 
2025-10-07 12:54:55,282 - training.trainer - INFO - Epoch 41, Step 141902: Loss=5.5624, Acc=0.360, 
2025-10-07 12:55:03,585 - training.trainer - INFO - Epoch 41, Step 142002: Loss=4.8694, Acc=0.405, 
2025-10-07 12:55:23,744 - training.trainer - INFO - Epoch 42/100 completed in 287.69s - Train Loss: 5.3405, Train Acc: 0.304, Val Loss: 5.7100, Val Acc: 0.268
2025-10-07 12:55:31,115 - training.trainer - INFO - Epoch 42, Step 142185: Loss=4.8411, Acc=0.256, 
2025-10-07 12:55:38,290 - training.trainer - INFO - Epoch 42, Step 142285: Loss=5.7806, Acc=0.239, 
2025-10-07 12:55:46,011 - training.trainer - INFO - Epoch 42, Step 142385: Loss=5.7633, Acc=0.224, 
2025-10-07 12:55:55,075 - training.trainer - INFO - Epoch 42, Step 142485: Loss=5.0516, Acc=0.320, 
2025-10-07 12:56:03,401 - training.trainer - INFO - Epoch 42, Step 142585: Loss=6.1328, Acc=0.224, 
2025-10-07 12:56:11,899 - training.trainer - INFO - Epoch 42, Step 142685: Loss=5.6614, Acc=0.248, 
2025-10-07 12:56:20,385 - training.trainer - INFO - Epoch 42, Step 142785: Loss=6.0521, Acc=0.159, 
2025-10-07 12:56:28,913 - training.trainer - INFO - Epoch 42, Step 142885: Loss=4.6380, Acc=0.318, 
2025-10-07 12:56:37,324 - training.trainer - INFO - Epoch 42, Step 142985: Loss=3.9776, Acc=0.500, 
2025-10-07 12:56:45,803 - training.trainer - INFO - Epoch 42, Step 143085: Loss=5.3863, Acc=0.256, 
2025-10-07 12:56:54,305 - training.trainer - INFO - Epoch 42, Step 143185: Loss=6.4187, Acc=0.220, 
2025-10-07 12:57:02,737 - training.trainer - INFO - Epoch 42, Step 143285: Loss=5.5945, Acc=0.211, 
2025-10-07 12:57:11,119 - training.trainer - INFO - Epoch 42, Step 143385: Loss=5.8878, Acc=0.297, 
2025-10-07 12:57:19,432 - training.trainer - INFO - Epoch 42, Step 143485: Loss=5.7572, Acc=0.158, 
2025-10-07 12:57:27,914 - training.trainer - INFO - Epoch 42, Step 143585: Loss=4.7033, Acc=0.324, 
2025-10-07 12:57:36,150 - training.trainer - INFO - Epoch 42, Step 143685: Loss=6.4998, Acc=0.189, 
2025-10-07 12:57:44,434 - training.trainer - INFO - Epoch 42, Step 143785: Loss=5.3406, Acc=0.353, 
2025-10-07 12:57:53,192 - training.trainer - INFO - Epoch 42, Step 143885: Loss=5.8191, Acc=0.214, 
2025-10-07 12:58:02,009 - training.trainer - INFO - Epoch 42, Step 143985: Loss=5.1608, Acc=0.371, 
2025-10-07 12:58:08,953 - training.trainer - INFO - Epoch 42, Step 144085: Loss=5.6917, Acc=0.304, 
2025-10-07 12:58:16,843 - training.trainer - INFO - Epoch 42, Step 144185: Loss=5.7478, Acc=0.203, 
2025-10-07 12:58:24,673 - training.trainer - INFO - Epoch 42, Step 144285: Loss=5.9915, Acc=0.157, 
2025-10-07 12:58:32,505 - training.trainer - INFO - Epoch 42, Step 144385: Loss=5.7171, Acc=0.240, 
2025-10-07 12:58:40,913 - training.trainer - INFO - Epoch 42, Step 144485: Loss=6.4215, Acc=0.220, 
2025-10-07 12:58:49,303 - training.trainer - INFO - Epoch 42, Step 144585: Loss=6.4662, Acc=0.286, 
2025-10-07 12:58:57,619 - training.trainer - INFO - Epoch 42, Step 144685: Loss=5.7405, Acc=0.256, 
2025-10-07 12:59:06,047 - training.trainer - INFO - Epoch 42, Step 144785: Loss=5.5766, Acc=0.294, 
2025-10-07 12:59:14,220 - training.trainer - INFO - Epoch 42, Step 144885: Loss=4.5583, Acc=0.462, 
2025-10-07 12:59:22,464 - training.trainer - INFO - Epoch 42, Step 144985: Loss=3.8846, Acc=0.316, 
2025-10-07 12:59:30,650 - training.trainer - INFO - Epoch 42, Step 145085: Loss=5.1672, Acc=0.333, 
2025-10-07 12:59:39,040 - training.trainer - INFO - Epoch 42, Step 145185: Loss=6.0964, Acc=0.225, 
2025-10-07 12:59:47,471 - training.trainer - INFO - Epoch 42, Step 145285: Loss=4.8098, Acc=0.312, 
2025-10-07 12:59:55,812 - training.trainer - INFO - Epoch 42, Step 145385: Loss=4.7782, Acc=0.429, 
2025-10-07 13:00:15,429 - training.trainer - INFO - Epoch 43/100 completed in 291.68s - Train Loss: 5.3322, Train Acc: 0.306, Val Loss: 5.7129, Val Acc: 0.268
2025-10-07 13:00:23,827 - training.trainer - INFO - Epoch 43, Step 145568: Loss=5.4682, Acc=0.244, 
2025-10-07 13:00:32,198 - training.trainer - INFO - Epoch 43, Step 145668: Loss=6.0433, Acc=0.222, 
2025-10-07 13:00:40,634 - training.trainer - INFO - Epoch 43, Step 145768: Loss=5.4054, Acc=0.261, 
2025-10-07 13:00:49,091 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.1006, Acc=0.279, 
2025-10-07 13:00:57,485 - training.trainer - INFO - Epoch 43, Step 145968: Loss=5.1254, Acc=0.308, 
2025-10-07 13:01:05,750 - training.trainer - INFO - Epoch 43, Step 146068: Loss=6.0649, Acc=0.194, 
2025-10-07 13:01:14,227 - training.trainer - INFO - Epoch 43, Step 146168: Loss=5.7761, Acc=0.243, 
2025-10-07 13:01:22,868 - training.trainer - INFO - Epoch 43, Step 146268: Loss=5.2048, Acc=0.351, 
2025-10-07 13:01:31,268 - training.trainer - INFO - Epoch 43, Step 146368: Loss=4.5318, Acc=0.343, 
2025-10-07 13:01:39,656 - training.trainer - INFO - Epoch 43, Step 146468: Loss=5.6610, Acc=0.250, 
2025-10-07 13:01:47,952 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.8430, Acc=0.236, 
2025-10-07 13:01:56,458 - training.trainer - INFO - Epoch 43, Step 146668: Loss=4.3543, Acc=0.318, 
2025-10-07 13:02:04,939 - training.trainer - INFO - Epoch 43, Step 146768: Loss=6.1709, Acc=0.189, 
2025-10-07 13:02:13,365 - training.trainer - INFO - Epoch 43, Step 146868: Loss=4.0882, Acc=0.429, 
2025-10-07 13:02:22,310 - training.trainer - INFO - Epoch 43, Step 146968: Loss=4.7942, Acc=0.324, 
2025-10-07 13:02:30,623 - training.trainer - INFO - Epoch 43, Step 147068: Loss=6.1643, Acc=0.235, 
2025-10-07 13:02:38,927 - training.trainer - INFO - Epoch 43, Step 147168: Loss=5.7552, Acc=0.215, 
2025-10-07 13:02:47,177 - training.trainer - INFO - Epoch 43, Step 147268: Loss=5.1402, Acc=0.320, 
2025-10-07 13:02:55,524 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.4505, Acc=0.263, 
2025-10-07 13:03:03,952 - training.trainer - INFO - Epoch 43, Step 147468: Loss=5.5637, Acc=0.300, 
2025-10-07 13:03:12,227 - training.trainer - INFO - Epoch 43, Step 147568: Loss=6.6109, Acc=0.136, 
2025-10-07 13:03:20,548 - training.trainer - INFO - Epoch 43, Step 147668: Loss=5.7120, Acc=0.203, 
2025-10-07 13:03:29,146 - training.trainer - INFO - Epoch 43, Step 147768: Loss=4.8751, Acc=0.345, 
2025-10-07 13:03:37,614 - training.trainer - INFO - Epoch 43, Step 147868: Loss=6.0533, Acc=0.204, 
2025-10-07 13:03:46,062 - training.trainer - INFO - Epoch 43, Step 147968: Loss=4.5297, Acc=0.368, 
2025-10-07 13:03:54,694 - training.trainer - INFO - Epoch 43, Step 148068: Loss=4.7323, Acc=0.410, 
2025-10-07 13:04:03,105 - training.trainer - INFO - Epoch 43, Step 148168: Loss=5.8785, Acc=0.323, 
2025-10-07 13:04:11,374 - training.trainer - INFO - Epoch 43, Step 148268: Loss=6.0597, Acc=0.192, 
2025-10-07 13:04:19,077 - training.trainer - INFO - Epoch 43, Step 148368: Loss=5.7266, Acc=0.170, 
2025-10-07 13:04:27,629 - training.trainer - INFO - Epoch 43, Step 148468: Loss=5.9230, Acc=0.226, 
2025-10-07 13:04:36,090 - training.trainer - INFO - Epoch 43, Step 148568: Loss=5.4571, Acc=0.245, 
2025-10-07 13:04:44,467 - training.trainer - INFO - Epoch 43, Step 148668: Loss=6.8028, Acc=0.217, 
2025-10-07 13:04:52,938 - training.trainer - INFO - Epoch 43, Step 148768: Loss=4.5840, Acc=0.394, 
2025-10-07 13:05:13,087 - training.trainer - INFO - Epoch 44/100 completed in 297.66s - Train Loss: 5.3187, Train Acc: 0.308, Val Loss: 5.7071, Val Acc: 0.266
2025-10-07 13:05:21,857 - training.trainer - INFO - Epoch 44, Step 148951: Loss=5.9444, Acc=0.243, 
2025-10-07 13:05:30,225 - training.trainer - INFO - Epoch 44, Step 149051: Loss=5.7011, Acc=0.189, 
2025-10-07 13:05:38,680 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.6842, Acc=0.167, 
2025-10-07 13:05:46,988 - training.trainer - INFO - Epoch 44, Step 149251: Loss=6.0221, Acc=0.258, 
2025-10-07 13:05:55,323 - training.trainer - INFO - Epoch 44, Step 149351: Loss=4.7186, Acc=0.286, 
2025-10-07 13:06:03,628 - training.trainer - INFO - Epoch 44, Step 149451: Loss=6.1337, Acc=0.188, 
2025-10-07 13:06:12,096 - training.trainer - INFO - Epoch 44, Step 149551: Loss=6.5921, Acc=0.186, 
2025-10-07 13:06:20,524 - training.trainer - INFO - Epoch 44, Step 149651: Loss=5.1823, Acc=0.354, 
2025-10-07 13:06:28,773 - training.trainer - INFO - Epoch 44, Step 149751: Loss=5.4168, Acc=0.261, 
2025-10-07 13:06:37,024 - training.trainer - INFO - Epoch 44, Step 149851: Loss=6.1803, Acc=0.250, 
2025-10-07 13:06:45,329 - training.trainer - INFO - Epoch 44, Step 149951: Loss=5.2397, Acc=0.333, 
2025-10-07 13:06:53,570 - training.trainer - INFO - Epoch 44, Step 150051: Loss=5.2459, Acc=0.279, 
2025-10-07 13:07:02,468 - training.trainer - INFO - Epoch 44, Step 150151: Loss=5.4467, Acc=0.290, 
2025-10-07 13:07:11,025 - training.trainer - INFO - Epoch 44, Step 150251: Loss=4.5891, Acc=0.442, 
2025-10-07 13:07:19,491 - training.trainer - INFO - Epoch 44, Step 150351: Loss=5.8232, Acc=0.266, 
2025-10-07 13:07:27,849 - training.trainer - INFO - Epoch 44, Step 150451: Loss=5.5317, Acc=0.327, 
2025-10-07 13:07:36,144 - training.trainer - INFO - Epoch 44, Step 150551: Loss=5.0632, Acc=0.292, 
2025-10-07 13:07:44,796 - training.trainer - INFO - Epoch 44, Step 150651: Loss=5.0097, Acc=0.267, 
2025-10-07 13:07:53,351 - training.trainer - INFO - Epoch 44, Step 150751: Loss=5.5305, Acc=0.314, 
2025-10-07 13:08:01,790 - training.trainer - INFO - Epoch 44, Step 150851: Loss=5.0250, Acc=0.250, 
2025-10-07 13:08:10,115 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.2836, Acc=0.308, 
2025-10-07 13:08:18,443 - training.trainer - INFO - Epoch 44, Step 151051: Loss=5.1939, Acc=0.200, 
2025-10-07 13:08:26,882 - training.trainer - INFO - Epoch 44, Step 151151: Loss=4.6605, Acc=0.297, 
2025-10-07 13:08:35,308 - training.trainer - INFO - Epoch 44, Step 151251: Loss=4.0391, Acc=0.562, 
2025-10-07 13:08:43,687 - training.trainer - INFO - Epoch 44, Step 151351: Loss=6.1179, Acc=0.175, 
2025-10-07 13:08:52,106 - training.trainer - INFO - Epoch 44, Step 151451: Loss=3.5358, Acc=0.500, 
2025-10-07 13:09:00,505 - training.trainer - INFO - Epoch 44, Step 151551: Loss=5.8879, Acc=0.302, 
2025-10-07 13:09:08,901 - training.trainer - INFO - Epoch 44, Step 151651: Loss=4.3187, Acc=0.429, 
2025-10-07 13:09:17,276 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.1947, Acc=0.355, 
2025-10-07 13:09:25,810 - training.trainer - INFO - Epoch 44, Step 151851: Loss=5.2519, Acc=0.333, 
2025-10-07 13:09:34,045 - training.trainer - INFO - Epoch 44, Step 151951: Loss=4.0634, Acc=0.538, 
2025-10-07 13:09:42,296 - training.trainer - INFO - Epoch 44, Step 152051: Loss=5.5577, Acc=0.250, 
2025-10-07 13:09:50,593 - training.trainer - INFO - Epoch 44, Step 152151: Loss=5.3958, Acc=0.283, 
2025-10-07 13:10:10,610 - training.trainer - INFO - Epoch 45/100 completed in 297.52s - Train Loss: 5.3086, Train Acc: 0.309, Val Loss: 5.7291, Val Acc: 0.266
2025-10-07 13:10:10,951 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-10-07 13:10:18,664 - training.trainer - INFO - Epoch 45, Step 152334: Loss=6.1626, Acc=0.303, 
2025-10-07 13:10:26,537 - training.trainer - INFO - Epoch 45, Step 152434: Loss=5.7540, Acc=0.278, 
2025-10-07 13:10:33,783 - training.trainer - INFO - Epoch 45, Step 152534: Loss=6.2578, Acc=0.209, 
2025-10-07 13:10:40,957 - training.trainer - INFO - Epoch 45, Step 152634: Loss=5.7443, Acc=0.256, 
2025-10-07 13:10:48,850 - training.trainer - INFO - Epoch 45, Step 152734: Loss=5.2834, Acc=0.364, 
2025-10-07 13:10:56,199 - training.trainer - INFO - Epoch 45, Step 152834: Loss=4.9422, Acc=0.333, 
2025-10-07 13:11:04,490 - training.trainer - INFO - Epoch 45, Step 152934: Loss=5.1430, Acc=0.333, 
2025-10-07 13:11:12,785 - training.trainer - INFO - Epoch 45, Step 153034: Loss=5.2814, Acc=0.353, 
2025-10-07 13:11:21,175 - training.trainer - INFO - Epoch 45, Step 153134: Loss=4.9293, Acc=0.300, 
2025-10-07 13:11:29,489 - training.trainer - INFO - Epoch 45, Step 153234: Loss=5.7159, Acc=0.286, 
2025-10-07 13:11:37,974 - training.trainer - INFO - Epoch 45, Step 153334: Loss=5.0666, Acc=0.345, 
2025-10-07 13:11:46,311 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.2266, Acc=0.348, 
2025-10-07 13:11:54,617 - training.trainer - INFO - Epoch 45, Step 153534: Loss=4.2630, Acc=0.312, 
2025-10-07 13:12:02,873 - training.trainer - INFO - Epoch 45, Step 153634: Loss=5.4103, Acc=0.299, 
2025-10-07 13:12:11,284 - training.trainer - INFO - Epoch 45, Step 153734: Loss=5.8229, Acc=0.246, 
2025-10-07 13:12:19,640 - training.trainer - INFO - Epoch 45, Step 153834: Loss=5.4031, Acc=0.395, 
2025-10-07 13:12:28,073 - training.trainer - INFO - Epoch 45, Step 153934: Loss=5.2301, Acc=0.276, 
2025-10-07 13:12:36,406 - training.trainer - INFO - Epoch 45, Step 154034: Loss=6.1988, Acc=0.137, 
2025-10-07 13:12:44,902 - training.trainer - INFO - Epoch 45, Step 154134: Loss=5.4353, Acc=0.352, 
2025-10-07 13:12:53,272 - training.trainer - INFO - Epoch 45, Step 154234: Loss=6.3471, Acc=0.239, 
2025-10-07 13:13:01,627 - training.trainer - INFO - Epoch 45, Step 154334: Loss=5.9702, Acc=0.188, 
2025-10-07 13:13:09,950 - training.trainer - INFO - Epoch 45, Step 154434: Loss=5.4823, Acc=0.333, 
2025-10-07 13:13:18,424 - training.trainer - INFO - Epoch 45, Step 154534: Loss=4.8218, Acc=0.263, 
2025-10-07 13:13:26,719 - training.trainer - INFO - Epoch 45, Step 154634: Loss=4.9139, Acc=0.341, 
2025-10-07 13:13:35,014 - training.trainer - INFO - Epoch 45, Step 154734: Loss=5.2095, Acc=0.346, 
2025-10-07 13:13:43,298 - training.trainer - INFO - Epoch 45, Step 154834: Loss=3.6758, Acc=0.600, 
2025-10-07 13:13:51,727 - training.trainer - INFO - Epoch 45, Step 154934: Loss=5.0849, Acc=0.333, 
2025-10-07 13:14:00,045 - training.trainer - INFO - Epoch 45, Step 155034: Loss=5.5164, Acc=0.280, 
2025-10-07 13:14:08,395 - training.trainer - INFO - Epoch 45, Step 155134: Loss=4.2953, Acc=0.350, 
2025-10-07 13:14:16,817 - training.trainer - INFO - Epoch 45, Step 155234: Loss=4.4325, Acc=0.345, 
2025-10-07 13:14:25,111 - training.trainer - INFO - Epoch 45, Step 155334: Loss=5.2088, Acc=0.346, 
2025-10-07 13:14:33,463 - training.trainer - INFO - Epoch 45, Step 155434: Loss=5.0569, Acc=0.347, 
2025-10-07 13:14:41,717 - training.trainer - INFO - Epoch 45, Step 155534: Loss=5.5212, Acc=0.280, 
2025-10-07 13:15:01,656 - training.trainer - INFO - Epoch 46/100 completed in 290.70s - Train Loss: 5.3006, Train Acc: 0.312, Val Loss: 5.7256, Val Acc: 0.267
2025-10-07 13:15:09,189 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.4284, Acc=0.264, 
2025-10-07 13:15:16,206 - training.trainer - INFO - Epoch 46, Step 155817: Loss=4.1413, Acc=0.515, 
2025-10-07 13:15:23,384 - training.trainer - INFO - Epoch 46, Step 155917: Loss=4.6848, Acc=0.562, 
2025-10-07 13:15:30,469 - training.trainer - INFO - Epoch 46, Step 156017: Loss=5.6486, Acc=0.275, 
2025-10-07 13:15:37,580 - training.trainer - INFO - Epoch 46, Step 156117: Loss=4.4260, Acc=0.429, 
2025-10-07 13:15:45,409 - training.trainer - INFO - Epoch 46, Step 156217: Loss=5.7941, Acc=0.310, 
2025-10-07 13:15:53,614 - training.trainer - INFO - Epoch 46, Step 156317: Loss=5.6374, Acc=0.333, 
2025-10-07 13:16:02,163 - training.trainer - INFO - Epoch 46, Step 156417: Loss=6.0100, Acc=0.182, 
2025-10-07 13:16:10,576 - training.trainer - INFO - Epoch 46, Step 156517: Loss=5.2367, Acc=0.310, 
2025-10-07 13:16:19,131 - training.trainer - INFO - Epoch 46, Step 156617: Loss=4.2722, Acc=0.485, 
2025-10-07 13:16:27,374 - training.trainer - INFO - Epoch 46, Step 156717: Loss=5.9108, Acc=0.258, 
2025-10-07 13:16:35,768 - training.trainer - INFO - Epoch 46, Step 156817: Loss=5.2434, Acc=0.290, 
2025-10-07 13:16:44,268 - training.trainer - INFO - Epoch 46, Step 156917: Loss=5.2630, Acc=0.333, 
2025-10-07 13:16:52,647 - training.trainer - INFO - Epoch 46, Step 157017: Loss=5.0621, Acc=0.282, 
2025-10-07 13:17:01,116 - training.trainer - INFO - Epoch 46, Step 157117: Loss=4.8508, Acc=0.371, 
2025-10-07 13:17:09,466 - training.trainer - INFO - Epoch 46, Step 157217: Loss=5.1739, Acc=0.250, 
2025-10-07 13:17:17,755 - training.trainer - INFO - Epoch 46, Step 157317: Loss=4.0872, Acc=0.455, 
2025-10-07 13:17:26,208 - training.trainer - INFO - Epoch 46, Step 157417: Loss=5.7911, Acc=0.333, 
2025-10-07 13:17:34,670 - training.trainer - INFO - Epoch 46, Step 157517: Loss=5.4332, Acc=0.250, 
2025-10-07 13:17:43,023 - training.trainer - INFO - Epoch 46, Step 157617: Loss=6.0745, Acc=0.129, 
2025-10-07 13:17:51,385 - training.trainer - INFO - Epoch 46, Step 157717: Loss=5.1673, Acc=0.362, 
2025-10-07 13:18:00,085 - training.trainer - INFO - Epoch 46, Step 157817: Loss=5.6532, Acc=0.276, 
2025-10-07 13:18:08,605 - training.trainer - INFO - Epoch 46, Step 157917: Loss=5.6712, Acc=0.296, 
2025-10-07 13:18:17,126 - training.trainer - INFO - Epoch 46, Step 158017: Loss=4.5038, Acc=0.406, 
2025-10-07 13:18:25,642 - training.trainer - INFO - Epoch 46, Step 158117: Loss=5.7727, Acc=0.316, 
2025-10-07 13:18:34,037 - training.trainer - INFO - Epoch 46, Step 158217: Loss=5.1831, Acc=0.312, 
2025-10-07 13:18:42,646 - training.trainer - INFO - Epoch 46, Step 158317: Loss=5.9995, Acc=0.243, 
2025-10-07 13:18:51,096 - training.trainer - INFO - Epoch 46, Step 158417: Loss=5.3394, Acc=0.278, 
2025-10-07 13:18:59,382 - training.trainer - INFO - Epoch 46, Step 158517: Loss=4.1859, Acc=0.450, 
2025-10-07 13:19:07,632 - training.trainer - INFO - Epoch 46, Step 158617: Loss=5.3072, Acc=0.295, 
2025-10-07 13:19:16,029 - training.trainer - INFO - Epoch 46, Step 158717: Loss=4.7252, Acc=0.312, 
2025-10-07 13:19:24,248 - training.trainer - INFO - Epoch 46, Step 158817: Loss=5.8607, Acc=0.213, 
2025-10-07 13:19:32,719 - training.trainer - INFO - Epoch 46, Step 158917: Loss=5.5022, Acc=0.304, 
2025-10-07 13:19:52,679 - training.trainer - INFO - Epoch 47/100 completed in 291.02s - Train Loss: 5.2919, Train Acc: 0.313, Val Loss: 5.7001, Val Acc: 0.269
2025-10-07 13:20:02,109 - training.trainer - INFO - Epoch 47, Step 159100: Loss=5.6033, Acc=0.333, 
2025-10-07 13:20:10,524 - training.trainer - INFO - Epoch 47, Step 159200: Loss=5.5889, Acc=0.212, 
2025-10-07 13:20:18,844 - training.trainer - INFO - Epoch 47, Step 159300: Loss=5.1669, Acc=0.242, 
2025-10-07 13:20:27,101 - training.trainer - INFO - Epoch 47, Step 159400: Loss=5.0626, Acc=0.308, 
2025-10-07 13:20:35,553 - training.trainer - INFO - Epoch 47, Step 159500: Loss=5.3355, Acc=0.244, 
2025-10-07 13:20:44,019 - training.trainer - INFO - Epoch 47, Step 159600: Loss=5.6515, Acc=0.269, 
2025-10-07 13:20:52,477 - training.trainer - INFO - Epoch 47, Step 159700: Loss=5.8431, Acc=0.280, 
2025-10-07 13:21:00,895 - training.trainer - INFO - Epoch 47, Step 159800: Loss=5.0757, Acc=0.349, 
2025-10-07 13:21:09,265 - training.trainer - INFO - Epoch 47, Step 159900: Loss=5.1228, Acc=0.400, 
2025-10-07 13:21:17,669 - training.trainer - INFO - Epoch 47, Step 160000: Loss=6.3210, Acc=0.154, 
2025-10-07 13:21:26,014 - training.trainer - INFO - Epoch 47, Step 160100: Loss=5.8118, Acc=0.326, 
2025-10-07 13:21:34,251 - training.trainer - INFO - Epoch 47, Step 160200: Loss=4.2186, Acc=0.524, 
2025-10-07 13:21:42,456 - training.trainer - INFO - Epoch 47, Step 160300: Loss=6.2524, Acc=0.232, 
2025-10-07 13:21:50,659 - training.trainer - INFO - Epoch 47, Step 160400: Loss=5.5628, Acc=0.250, 
2025-10-07 13:21:59,166 - training.trainer - INFO - Epoch 47, Step 160500: Loss=5.4051, Acc=0.319, 
2025-10-07 13:22:07,522 - training.trainer - INFO - Epoch 47, Step 160600: Loss=5.4478, Acc=0.357, 
2025-10-07 13:22:15,812 - training.trainer - INFO - Epoch 47, Step 160700: Loss=6.0206, Acc=0.250, 
2025-10-07 13:22:24,289 - training.trainer - INFO - Epoch 47, Step 160800: Loss=4.3086, Acc=0.444, 
2025-10-07 13:22:32,727 - training.trainer - INFO - Epoch 47, Step 160900: Loss=6.0191, Acc=0.247, 
2025-10-07 13:22:41,044 - training.trainer - INFO - Epoch 47, Step 161000: Loss=4.9335, Acc=0.304, 
2025-10-07 13:22:49,290 - training.trainer - INFO - Epoch 47, Step 161100: Loss=5.9168, Acc=0.308, 
2025-10-07 13:22:57,595 - training.trainer - INFO - Epoch 47, Step 161200: Loss=5.2879, Acc=0.342, 
2025-10-07 13:23:05,898 - training.trainer - INFO - Epoch 47, Step 161300: Loss=4.8904, Acc=0.333, 
2025-10-07 13:23:14,081 - training.trainer - INFO - Epoch 47, Step 161400: Loss=6.2348, Acc=0.273, 
2025-10-07 13:23:22,347 - training.trainer - INFO - Epoch 47, Step 161500: Loss=6.1437, Acc=0.235, 
2025-10-07 13:23:30,704 - training.trainer - INFO - Epoch 47, Step 161600: Loss=5.3998, Acc=0.317, 
2025-10-07 13:23:39,005 - training.trainer - INFO - Epoch 47, Step 161700: Loss=5.0940, Acc=0.350, 
2025-10-07 13:23:47,231 - training.trainer - INFO - Epoch 47, Step 161800: Loss=5.1620, Acc=0.370, 
2025-10-07 13:23:55,469 - training.trainer - INFO - Epoch 47, Step 161900: Loss=5.5949, Acc=0.296, 
2025-10-07 13:24:03,749 - training.trainer - INFO - Epoch 47, Step 162000: Loss=5.5327, Acc=0.269, 
2025-10-07 13:24:12,130 - training.trainer - INFO - Epoch 47, Step 162100: Loss=5.4875, Acc=0.371, 
2025-10-07 13:24:20,431 - training.trainer - INFO - Epoch 47, Step 162200: Loss=5.9309, Acc=0.224, 
2025-10-07 13:24:28,733 - training.trainer - INFO - Epoch 47, Step 162300: Loss=5.7657, Acc=0.327, 
2025-10-07 13:24:49,371 - training.trainer - INFO - Epoch 48/100 completed in 296.69s - Train Loss: 5.2757, Train Acc: 0.315, Val Loss: 5.7272, Val Acc: 0.267
2025-10-07 13:24:56,800 - training.trainer - INFO - Epoch 48, Step 162483: Loss=6.1373, Acc=0.179, 
2025-10-07 13:25:03,859 - training.trainer - INFO - Epoch 48, Step 162583: Loss=5.2660, Acc=0.273, 
2025-10-07 13:25:10,919 - training.trainer - INFO - Epoch 48, Step 162683: Loss=4.8021, Acc=0.385, 
2025-10-07 13:25:18,099 - training.trainer - INFO - Epoch 48, Step 162783: Loss=5.0511, Acc=0.359, 
2025-10-07 13:25:25,188 - training.trainer - INFO - Epoch 48, Step 162883: Loss=6.2152, Acc=0.243, 
2025-10-07 13:25:32,271 - training.trainer - INFO - Epoch 48, Step 162983: Loss=4.7110, Acc=0.393, 
2025-10-07 13:25:39,359 - training.trainer - INFO - Epoch 48, Step 163083: Loss=5.9788, Acc=0.302, 
2025-10-07 13:25:46,504 - training.trainer - INFO - Epoch 48, Step 163183: Loss=6.0822, Acc=0.241, 
2025-10-07 13:25:53,575 - training.trainer - INFO - Epoch 48, Step 163283: Loss=4.7360, Acc=0.333, 
2025-10-07 13:26:00,612 - training.trainer - INFO - Epoch 48, Step 163383: Loss=5.5954, Acc=0.267, 
2025-10-07 13:26:07,889 - training.trainer - INFO - Epoch 48, Step 163483: Loss=4.1772, Acc=0.227, 
2025-10-07 13:26:15,700 - training.trainer - INFO - Epoch 48, Step 163583: Loss=5.5464, Acc=0.324, 
2025-10-07 13:26:24,257 - training.trainer - INFO - Epoch 48, Step 163683: Loss=3.6544, Acc=0.524, 
2025-10-07 13:26:32,826 - training.trainer - INFO - Epoch 48, Step 163783: Loss=5.3550, Acc=0.262, 
2025-10-07 13:26:41,338 - training.trainer - INFO - Epoch 48, Step 163883: Loss=5.2982, Acc=0.310, 
2025-10-07 13:26:49,866 - training.trainer - INFO - Epoch 48, Step 163983: Loss=5.1800, Acc=0.269, 
2025-10-07 13:26:58,451 - training.trainer - INFO - Epoch 48, Step 164083: Loss=5.4211, Acc=0.262, 
2025-10-07 13:27:06,974 - training.trainer - INFO - Epoch 48, Step 164183: Loss=4.4468, Acc=0.357, 
2025-10-07 13:27:15,499 - training.trainer - INFO - Epoch 48, Step 164283: Loss=5.6844, Acc=0.347, 
2025-10-07 13:27:23,841 - training.trainer - INFO - Epoch 48, Step 164383: Loss=5.9581, Acc=0.281, 
2025-10-07 13:27:32,226 - training.trainer - INFO - Epoch 48, Step 164483: Loss=4.7461, Acc=0.393, 
2025-10-07 13:27:40,617 - training.trainer - INFO - Epoch 48, Step 164583: Loss=5.2677, Acc=0.309, 
2025-10-07 13:27:49,091 - training.trainer - INFO - Epoch 48, Step 164683: Loss=4.4923, Acc=0.412, 
2025-10-07 13:27:57,532 - training.trainer - INFO - Epoch 48, Step 164783: Loss=6.0391, Acc=0.267, 
2025-10-07 13:28:05,957 - training.trainer - INFO - Epoch 48, Step 164883: Loss=6.2072, Acc=0.241, 
2025-10-07 13:28:14,408 - training.trainer - INFO - Epoch 48, Step 164983: Loss=3.7082, Acc=0.467, 
2025-10-07 13:28:23,212 - training.trainer - INFO - Epoch 48, Step 165083: Loss=6.2317, Acc=0.184, 
2025-10-07 13:28:31,672 - training.trainer - INFO - Epoch 48, Step 165183: Loss=5.7451, Acc=0.235, 
2025-10-07 13:28:39,949 - training.trainer - INFO - Epoch 48, Step 165283: Loss=6.4458, Acc=0.211, 
2025-10-07 13:28:48,404 - training.trainer - INFO - Epoch 48, Step 165383: Loss=5.4896, Acc=0.300, 
2025-10-07 13:28:57,022 - training.trainer - INFO - Epoch 48, Step 165483: Loss=4.2830, Acc=0.406, 
2025-10-07 13:29:05,577 - training.trainer - INFO - Epoch 48, Step 165583: Loss=5.1264, Acc=0.256, 
2025-10-07 13:29:13,868 - training.trainer - INFO - Epoch 48, Step 165683: Loss=5.6344, Acc=0.205, 
2025-10-07 13:29:33,094 - training.trainer - INFO - Epoch 49/100 completed in 283.72s - Train Loss: 5.2704, Train Acc: 0.316, Val Loss: 5.7321, Val Acc: 0.267
2025-10-07 13:29:41,423 - training.trainer - INFO - Epoch 49, Step 165866: Loss=5.9851, Acc=0.229, 
2025-10-07 13:29:49,801 - training.trainer - INFO - Epoch 49, Step 165966: Loss=5.8285, Acc=0.254, 
2025-10-07 13:29:58,139 - training.trainer - INFO - Epoch 49, Step 166066: Loss=4.3887, Acc=0.409, 
2025-10-07 13:30:06,517 - training.trainer - INFO - Epoch 49, Step 166166: Loss=4.7932, Acc=0.340, 
2025-10-07 13:30:14,851 - training.trainer - INFO - Epoch 49, Step 166266: Loss=5.7908, Acc=0.279, 
2025-10-07 13:30:23,036 - training.trainer - INFO - Epoch 49, Step 166366: Loss=5.2849, Acc=0.276, 
2025-10-07 13:30:31,267 - training.trainer - INFO - Epoch 49, Step 166466: Loss=5.6146, Acc=0.316, 
2025-10-07 13:30:39,668 - training.trainer - INFO - Epoch 49, Step 166566: Loss=4.7873, Acc=0.444, 
2025-10-07 13:30:47,941 - training.trainer - INFO - Epoch 49, Step 166666: Loss=6.1695, Acc=0.344, 
2025-10-07 13:30:56,201 - training.trainer - INFO - Epoch 49, Step 166766: Loss=4.7481, Acc=0.275, 
2025-10-07 13:31:04,412 - training.trainer - INFO - Epoch 49, Step 166866: Loss=5.8082, Acc=0.257, 
2025-10-07 13:31:12,687 - training.trainer - INFO - Epoch 49, Step 166966: Loss=5.0590, Acc=0.344, 
2025-10-07 13:31:20,982 - training.trainer - INFO - Epoch 49, Step 167066: Loss=4.9664, Acc=0.367, 
2025-10-07 13:31:29,284 - training.trainer - INFO - Epoch 49, Step 167166: Loss=5.6411, Acc=0.209, 
2025-10-07 13:31:37,702 - training.trainer - INFO - Epoch 49, Step 167266: Loss=4.7886, Acc=0.333, 
2025-10-07 13:31:46,156 - training.trainer - INFO - Epoch 49, Step 167366: Loss=5.4543, Acc=0.250, 
2025-10-07 13:31:54,516 - training.trainer - INFO - Epoch 49, Step 167466: Loss=5.6591, Acc=0.286, 
2025-10-07 13:32:02,924 - training.trainer - INFO - Epoch 49, Step 167566: Loss=5.7562, Acc=0.262, 
2025-10-07 13:32:11,265 - training.trainer - INFO - Epoch 49, Step 167666: Loss=5.1219, Acc=0.292, 
2025-10-07 13:32:19,824 - training.trainer - INFO - Epoch 49, Step 167766: Loss=4.7660, Acc=0.407, 
2025-10-07 13:32:28,131 - training.trainer - INFO - Epoch 49, Step 167866: Loss=5.0673, Acc=0.345, 
2025-10-07 13:32:36,497 - training.trainer - INFO - Epoch 49, Step 167966: Loss=5.4422, Acc=0.297, 
2025-10-07 13:32:44,971 - training.trainer - INFO - Epoch 49, Step 168066: Loss=5.7713, Acc=0.288, 
2025-10-07 13:32:53,530 - training.trainer - INFO - Epoch 49, Step 168166: Loss=4.5404, Acc=0.346, 
2025-10-07 13:33:01,869 - training.trainer - INFO - Epoch 49, Step 168266: Loss=6.1502, Acc=0.232, 
2025-10-07 13:33:10,261 - training.trainer - INFO - Epoch 49, Step 168366: Loss=4.0484, Acc=0.478, 
2025-10-07 13:33:18,336 - training.trainer - INFO - Epoch 49, Step 168466: Loss=4.7098, Acc=0.300, 
2025-10-07 13:33:26,831 - training.trainer - INFO - Epoch 49, Step 168566: Loss=4.2351, Acc=0.412, 
2025-10-07 13:33:35,076 - training.trainer - INFO - Epoch 49, Step 168666: Loss=4.9011, Acc=0.298, 
2025-10-07 13:33:43,566 - training.trainer - INFO - Epoch 49, Step 168766: Loss=4.4254, Acc=0.412, 
2025-10-07 13:33:52,038 - training.trainer - INFO - Epoch 49, Step 168866: Loss=4.9224, Acc=0.342, 
2025-10-07 13:34:00,367 - training.trainer - INFO - Epoch 49, Step 168966: Loss=5.8055, Acc=0.235, 
2025-10-07 13:34:08,823 - training.trainer - INFO - Epoch 49, Step 169066: Loss=5.2816, Acc=0.250, 
2025-10-07 13:34:28,248 - training.trainer - INFO - Epoch 50/100 completed in 295.15s - Train Loss: 5.2553, Train Acc: 0.320, Val Loss: 5.7267, Val Acc: 0.270
2025-10-07 13:34:28,715 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_50.pt
2025-10-07 13:34:37,608 - training.trainer - INFO - Epoch 50, Step 169249: Loss=4.7399, Acc=0.296, 
2025-10-07 13:34:45,931 - training.trainer - INFO - Epoch 50, Step 169349: Loss=5.0227, Acc=0.320, 
2025-10-07 13:34:54,233 - training.trainer - INFO - Epoch 50, Step 169449: Loss=5.7915, Acc=0.295, 
2025-10-07 13:35:02,589 - training.trainer - INFO - Epoch 50, Step 169549: Loss=3.1833, Acc=0.778, 
2025-10-07 13:35:10,931 - training.trainer - INFO - Epoch 50, Step 169649: Loss=5.2916, Acc=0.200, 
2025-10-07 13:35:19,235 - training.trainer - INFO - Epoch 50, Step 169749: Loss=5.2930, Acc=0.235, 
2025-10-07 13:35:27,576 - training.trainer - INFO - Epoch 50, Step 169849: Loss=5.6789, Acc=0.234, 
2025-10-07 13:35:36,127 - training.trainer - INFO - Epoch 50, Step 169949: Loss=2.3302, Acc=0.750, 
2025-10-07 13:35:44,436 - training.trainer - INFO - Epoch 50, Step 170049: Loss=5.7482, Acc=0.435, 
2025-10-07 13:35:52,797 - training.trainer - INFO - Epoch 50, Step 170149: Loss=5.7730, Acc=0.263, 
2025-10-07 13:36:01,137 - training.trainer - INFO - Epoch 50, Step 170249: Loss=6.0399, Acc=0.188, 
2025-10-07 13:36:09,657 - training.trainer - INFO - Epoch 50, Step 170349: Loss=4.6241, Acc=0.400, 
2025-10-07 13:36:18,155 - training.trainer - INFO - Epoch 50, Step 170449: Loss=5.8888, Acc=0.189, 
2025-10-07 13:36:26,642 - training.trainer - INFO - Epoch 50, Step 170549: Loss=5.6339, Acc=0.260, 
2025-10-07 13:36:35,027 - training.trainer - INFO - Epoch 50, Step 170649: Loss=5.6212, Acc=0.290, 
2025-10-07 13:36:43,518 - training.trainer - INFO - Epoch 50, Step 170749: Loss=6.0538, Acc=0.179, 
2025-10-07 13:36:51,867 - training.trainer - INFO - Epoch 50, Step 170849: Loss=6.1113, Acc=0.184, 
2025-10-07 13:37:00,263 - training.trainer - INFO - Epoch 50, Step 170949: Loss=5.2935, Acc=0.304, 
2025-10-07 13:37:08,767 - training.trainer - INFO - Epoch 50, Step 171049: Loss=4.7586, Acc=0.411, 
2025-10-07 13:37:17,230 - training.trainer - INFO - Epoch 50, Step 171149: Loss=5.3215, Acc=0.224, 
2025-10-07 13:37:25,771 - training.trainer - INFO - Epoch 50, Step 171249: Loss=5.6072, Acc=0.262, 
2025-10-07 13:37:34,111 - training.trainer - INFO - Epoch 50, Step 171349: Loss=5.1001, Acc=0.385, 
2025-10-07 13:37:42,520 - training.trainer - INFO - Epoch 50, Step 171449: Loss=3.5063, Acc=0.500, 
2025-10-07 13:37:51,047 - training.trainer - INFO - Epoch 50, Step 171549: Loss=3.4824, Acc=0.676, 
2025-10-07 13:37:59,440 - training.trainer - INFO - Epoch 50, Step 171649: Loss=6.0813, Acc=0.202, 
2025-10-07 13:38:07,764 - training.trainer - INFO - Epoch 50, Step 171749: Loss=3.7239, Acc=0.417, 
2025-10-07 13:38:16,083 - training.trainer - INFO - Epoch 50, Step 171849: Loss=3.5401, Acc=0.619, 
2025-10-07 13:38:24,510 - training.trainer - INFO - Epoch 50, Step 171949: Loss=6.1300, Acc=0.290, 
2025-10-07 13:38:32,830 - training.trainer - INFO - Epoch 50, Step 172049: Loss=3.9111, Acc=0.512, 
2025-10-07 13:38:41,175 - training.trainer - INFO - Epoch 50, Step 172149: Loss=5.6437, Acc=0.286, 
2025-10-07 13:38:49,497 - training.trainer - INFO - Epoch 50, Step 172249: Loss=6.0388, Acc=0.298, 
2025-10-07 13:38:57,960 - training.trainer - INFO - Epoch 50, Step 172349: Loss=5.1388, Acc=0.367, 
2025-10-07 13:39:06,309 - training.trainer - INFO - Epoch 50, Step 172449: Loss=5.2328, Acc=0.450, 
2025-10-07 13:39:26,159 - training.trainer - INFO - Epoch 51/100 completed in 297.44s - Train Loss: 5.2418, Train Acc: 0.320, Val Loss: 5.7469, Val Acc: 0.268
2025-10-07 13:39:33,862 - training.trainer - INFO - Epoch 51, Step 172632: Loss=5.6698, Acc=0.313, 
2025-10-07 13:39:41,094 - training.trainer - INFO - Epoch 51, Step 172732: Loss=6.1239, Acc=0.146, 
2025-10-07 13:39:48,204 - training.trainer - INFO - Epoch 51, Step 172832: Loss=4.2664, Acc=0.409, 
2025-10-07 13:39:55,360 - training.trainer - INFO - Epoch 51, Step 172932: Loss=5.7073, Acc=0.286, 
2025-10-07 13:40:02,442 - training.trainer - INFO - Epoch 51, Step 173032: Loss=5.8148, Acc=0.190, 
2025-10-07 13:40:09,618 - training.trainer - INFO - Epoch 51, Step 173132: Loss=5.2422, Acc=0.333, 
2025-10-07 13:40:16,743 - training.trainer - INFO - Epoch 51, Step 173232: Loss=5.5299, Acc=0.256, 
2025-10-07 13:40:23,795 - training.trainer - INFO - Epoch 51, Step 173332: Loss=4.2783, Acc=0.509, 
2025-10-07 13:40:30,840 - training.trainer - INFO - Epoch 51, Step 173432: Loss=5.4999, Acc=0.258, 
2025-10-07 13:40:37,985 - training.trainer - INFO - Epoch 51, Step 173532: Loss=5.1902, Acc=0.325, 
2025-10-07 13:40:45,044 - training.trainer - INFO - Epoch 51, Step 173632: Loss=5.7785, Acc=0.255, 
2025-10-07 13:40:52,078 - training.trainer - INFO - Epoch 51, Step 173732: Loss=4.8951, Acc=0.333, 
2025-10-07 13:40:59,139 - training.trainer - INFO - Epoch 51, Step 173832: Loss=5.2685, Acc=0.324, 
2025-10-07 13:41:06,229 - training.trainer - INFO - Epoch 51, Step 173932: Loss=5.6734, Acc=0.298, 
2025-10-07 13:41:13,513 - training.trainer - INFO - Epoch 51, Step 174032: Loss=5.2062, Acc=0.407, 
2025-10-07 13:41:20,572 - training.trainer - INFO - Epoch 51, Step 174132: Loss=5.1878, Acc=0.333, 
2025-10-07 13:41:27,668 - training.trainer - INFO - Epoch 51, Step 174232: Loss=3.8714, Acc=0.357, 
2025-10-07 13:41:34,786 - training.trainer - INFO - Epoch 51, Step 174332: Loss=5.2141, Acc=0.286, 
2025-10-07 13:41:42,097 - training.trainer - INFO - Epoch 51, Step 174432: Loss=4.4726, Acc=0.391, 
2025-10-07 13:41:49,114 - training.trainer - INFO - Epoch 51, Step 174532: Loss=5.6743, Acc=0.241, 
2025-10-07 13:41:56,140 - training.trainer - INFO - Epoch 51, Step 174632: Loss=5.5687, Acc=0.300, 
2025-10-07 13:42:03,224 - training.trainer - INFO - Epoch 51, Step 174732: Loss=3.5804, Acc=0.474, 
2025-10-07 13:42:10,355 - training.trainer - INFO - Epoch 51, Step 174832: Loss=5.1461, Acc=0.245, 
2025-10-07 13:42:17,573 - training.trainer - INFO - Epoch 51, Step 174932: Loss=5.0688, Acc=0.278, 
2025-10-07 13:42:24,808 - training.trainer - INFO - Epoch 51, Step 175032: Loss=5.1951, Acc=0.325, 
2025-10-07 13:42:31,955 - training.trainer - INFO - Epoch 51, Step 175132: Loss=3.1612, Acc=0.600, 
2025-10-07 13:42:38,969 - training.trainer - INFO - Epoch 51, Step 175232: Loss=5.5938, Acc=0.357, 
2025-10-07 13:42:46,046 - training.trainer - INFO - Epoch 51, Step 175332: Loss=5.5998, Acc=0.200, 
2025-10-07 13:42:53,375 - training.trainer - INFO - Epoch 51, Step 175432: Loss=4.8097, Acc=0.316, 
2025-10-07 13:43:01,153 - training.trainer - INFO - Epoch 51, Step 175532: Loss=4.5005, Acc=0.333, 
2025-10-07 13:43:09,193 - training.trainer - INFO - Epoch 51, Step 175632: Loss=5.5625, Acc=0.268, 
2025-10-07 13:43:16,767 - training.trainer - INFO - Epoch 51, Step 175732: Loss=5.8055, Acc=0.216, 
2025-10-07 13:43:25,101 - training.trainer - INFO - Epoch 51, Step 175832: Loss=5.3127, Acc=0.262, 
2025-10-07 13:43:44,516 - training.trainer - INFO - Epoch 52/100 completed in 258.36s - Train Loss: 5.2383, Train Acc: 0.321, Val Loss: 5.7315, Val Acc: 0.269
2025-10-07 13:43:52,054 - training.trainer - INFO - Epoch 52, Step 176015: Loss=5.6233, Acc=0.308, 
2025-10-07 13:43:59,243 - training.trainer - INFO - Epoch 52, Step 176115: Loss=5.8180, Acc=0.235, 
2025-10-07 13:44:06,954 - training.trainer - INFO - Epoch 52, Step 176215: Loss=5.9799, Acc=0.302, 
2025-10-07 13:44:14,770 - training.trainer - INFO - Epoch 52, Step 176315: Loss=5.5049, Acc=0.246, 
2025-10-07 13:44:21,919 - training.trainer - INFO - Epoch 52, Step 176415: Loss=5.0641, Acc=0.271, 
2025-10-07 13:44:29,598 - training.trainer - INFO - Epoch 52, Step 176515: Loss=6.3483, Acc=0.176, 
2025-10-07 13:44:37,392 - training.trainer - INFO - Epoch 52, Step 176615: Loss=4.9620, Acc=0.310, 
2025-10-07 13:44:45,320 - training.trainer - INFO - Epoch 52, Step 176715: Loss=4.2882, Acc=0.375, 
2025-10-07 13:44:52,514 - training.trainer - INFO - Epoch 52, Step 176815: Loss=4.7903, Acc=0.282, 
2025-10-07 13:45:00,642 - training.trainer - INFO - Epoch 52, Step 176915: Loss=5.5280, Acc=0.244, 
2025-10-07 13:45:08,937 - training.trainer - INFO - Epoch 52, Step 177015: Loss=5.7541, Acc=0.350, 
2025-10-07 13:45:17,174 - training.trainer - INFO - Epoch 52, Step 177115: Loss=6.1589, Acc=0.226, 
2025-10-07 13:45:25,562 - training.trainer - INFO - Epoch 52, Step 177215: Loss=4.8791, Acc=0.286, 
2025-10-07 13:45:33,944 - training.trainer - INFO - Epoch 52, Step 177315: Loss=5.4952, Acc=0.308, 
2025-10-07 13:45:42,532 - training.trainer - INFO - Epoch 52, Step 177415: Loss=5.4302, Acc=0.212, 
2025-10-07 13:45:50,934 - training.trainer - INFO - Epoch 52, Step 177515: Loss=5.0488, Acc=0.391, 
2025-10-07 13:45:59,307 - training.trainer - INFO - Epoch 52, Step 177615: Loss=5.7734, Acc=0.237, 
2025-10-07 13:46:07,544 - training.trainer - INFO - Epoch 52, Step 177715: Loss=5.2738, Acc=0.316, 
2025-10-07 13:46:15,668 - training.trainer - INFO - Epoch 52, Step 177815: Loss=5.0873, Acc=0.265, 
2025-10-07 13:46:24,031 - training.trainer - INFO - Epoch 52, Step 177915: Loss=5.7160, Acc=0.206, 
2025-10-07 13:46:32,469 - training.trainer - INFO - Epoch 52, Step 178015: Loss=5.5038, Acc=0.271, 
2025-10-07 13:46:40,951 - training.trainer - INFO - Epoch 52, Step 178115: Loss=5.2674, Acc=0.238, 
2025-10-07 13:46:49,414 - training.trainer - INFO - Epoch 52, Step 178215: Loss=4.9429, Acc=0.306, 
2025-10-07 13:46:57,595 - training.trainer - INFO - Epoch 52, Step 178315: Loss=5.8996, Acc=0.286, 
2025-10-07 13:47:05,888 - training.trainer - INFO - Epoch 52, Step 178415: Loss=4.9013, Acc=0.370, 
2025-10-07 13:47:14,134 - training.trainer - INFO - Epoch 52, Step 178515: Loss=4.3748, Acc=0.526, 
2025-10-07 13:47:22,388 - training.trainer - INFO - Epoch 52, Step 178615: Loss=5.2706, Acc=0.306, 
2025-10-07 13:47:30,716 - training.trainer - INFO - Epoch 52, Step 178715: Loss=5.3824, Acc=0.302, 
2025-10-07 13:47:38,944 - training.trainer - INFO - Epoch 52, Step 178815: Loss=5.6548, Acc=0.242, 
2025-10-07 13:47:47,399 - training.trainer - INFO - Epoch 52, Step 178915: Loss=5.3339, Acc=0.286, 
2025-10-07 13:47:55,679 - training.trainer - INFO - Epoch 52, Step 179015: Loss=5.9533, Acc=0.231, 
2025-10-07 13:48:03,907 - training.trainer - INFO - Epoch 52, Step 179115: Loss=5.3832, Acc=0.273, 
2025-10-07 13:48:12,186 - training.trainer - INFO - Epoch 52, Step 179215: Loss=4.2816, Acc=0.429, 
2025-10-07 13:48:31,533 - training.trainer - INFO - Epoch 53/100 completed in 287.02s - Train Loss: 5.2288, Train Acc: 0.323, Val Loss: 5.7611, Val Acc: 0.269
2025-10-07 13:48:39,096 - training.trainer - INFO - Epoch 53, Step 179398: Loss=5.1588, Acc=0.375, 
2025-10-07 13:48:46,083 - training.trainer - INFO - Epoch 53, Step 179498: Loss=4.4925, Acc=0.367, 
2025-10-07 13:48:53,837 - training.trainer - INFO - Epoch 53, Step 179598: Loss=5.7178, Acc=0.283, 
2025-10-07 13:49:02,043 - training.trainer - INFO - Epoch 53, Step 179698: Loss=4.7626, Acc=0.480, 
2025-10-07 13:49:10,273 - training.trainer - INFO - Epoch 53, Step 179798: Loss=5.2761, Acc=0.280, 
2025-10-07 13:49:18,635 - training.trainer - INFO - Epoch 53, Step 179898: Loss=5.7502, Acc=0.275, 
2025-10-07 13:49:26,979 - training.trainer - INFO - Epoch 53, Step 179998: Loss=5.5633, Acc=0.243, 
2025-10-07 13:49:35,209 - training.trainer - INFO - Epoch 53, Step 180098: Loss=5.1536, Acc=0.351, 
2025-10-07 13:49:43,466 - training.trainer - INFO - Epoch 53, Step 180198: Loss=5.9689, Acc=0.237, 
2025-10-07 13:49:51,731 - training.trainer - INFO - Epoch 53, Step 180298: Loss=4.4845, Acc=0.400, 
2025-10-07 13:50:00,102 - training.trainer - INFO - Epoch 53, Step 180398: Loss=4.6415, Acc=0.364, 
2025-10-07 13:50:08,427 - training.trainer - INFO - Epoch 53, Step 180498: Loss=4.4918, Acc=0.414, 
2025-10-07 13:50:16,712 - training.trainer - INFO - Epoch 53, Step 180598: Loss=4.4825, Acc=0.393, 
2025-10-07 13:50:25,030 - training.trainer - INFO - Epoch 53, Step 180698: Loss=5.3287, Acc=0.267, 
2025-10-07 13:50:33,423 - training.trainer - INFO - Epoch 53, Step 180798: Loss=5.5765, Acc=0.318, 
2025-10-07 13:50:41,858 - training.trainer - INFO - Epoch 53, Step 180898: Loss=6.1206, Acc=0.360, 
2025-10-07 13:50:50,334 - training.trainer - INFO - Epoch 53, Step 180998: Loss=5.2042, Acc=0.391, 
2025-10-07 13:50:58,792 - training.trainer - INFO - Epoch 53, Step 181098: Loss=5.4224, Acc=0.419, 
2025-10-07 13:51:07,316 - training.trainer - INFO - Epoch 53, Step 181198: Loss=4.6177, Acc=0.474, 
2025-10-07 13:51:15,714 - training.trainer - INFO - Epoch 53, Step 181298: Loss=3.1037, Acc=0.622, 
2025-10-07 13:51:24,284 - training.trainer - INFO - Epoch 53, Step 181398: Loss=5.0543, Acc=0.259, 
2025-10-07 13:51:32,705 - training.trainer - INFO - Epoch 53, Step 181498: Loss=5.0704, Acc=0.311, 
2025-10-07 13:51:41,133 - training.trainer - INFO - Epoch 53, Step 181598: Loss=4.4866, Acc=0.412, 
2025-10-07 13:51:49,578 - training.trainer - INFO - Epoch 53, Step 181698: Loss=5.0272, Acc=0.333, 
2025-10-07 13:51:58,084 - training.trainer - INFO - Epoch 53, Step 181798: Loss=5.1506, Acc=0.333, 
2025-10-07 13:52:06,611 - training.trainer - INFO - Epoch 53, Step 181898: Loss=5.2123, Acc=0.344, 
2025-10-07 13:52:15,044 - training.trainer - INFO - Epoch 53, Step 181998: Loss=4.7848, Acc=0.412, 
2025-10-07 13:52:23,438 - training.trainer - INFO - Epoch 53, Step 182098: Loss=4.7020, Acc=0.333, 
2025-10-07 13:52:32,006 - training.trainer - INFO - Epoch 53, Step 182198: Loss=5.9160, Acc=0.234, 
2025-10-07 13:52:40,377 - training.trainer - INFO - Epoch 53, Step 182298: Loss=4.6657, Acc=0.500, 
2025-10-07 13:52:48,802 - training.trainer - INFO - Epoch 53, Step 182398: Loss=6.1911, Acc=0.239, 
2025-10-07 13:52:57,232 - training.trainer - INFO - Epoch 53, Step 182498: Loss=5.6227, Acc=0.262, 
2025-10-07 13:53:05,704 - training.trainer - INFO - Epoch 53, Step 182598: Loss=4.8293, Acc=0.389, 
2025-10-07 13:53:25,451 - training.trainer - INFO - Epoch 54/100 completed in 293.92s - Train Loss: 5.2217, Train Acc: 0.324, Val Loss: 5.7339, Val Acc: 0.270
2025-10-07 13:53:25,452 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-07 13:53:25,452 - training.trainer - INFO - Training completed!
2025-10-07 13:53:25,457 - __main__ - INFO - Training completed successfully!
2025-10-07 13:53:25,598 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-07 13:53:25,711 - __main__ - INFO - Process completed!
2025-10-07 13:53:41,561 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-07 13:53:41,562 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-07 13:53:41,562 - __main__ - INFO - Starting model evaluation
2025-10-07 13:53:42,890 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-07 13:59:01,677 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-07 13:59:01,692 - __main__ - INFO - Process completed!
2025-10-07 13:59:08,244 - __main__ - INFO - Starting Sign Language Translation - Mode: inference
2025-10-07 13:59:08,244 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-07 13:59:08,244 - __main__ - INFO - Running inference on demo_keypoints.npy
2025-10-07 13:59:08,850 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-07 13:59:13,145 - __main__ - INFO - Inference completed successfully!
2025-10-07 13:59:13,152 - __main__ - INFO - Process completed!
2025-10-07 23:38:26,804 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-07 23:38:26,805 - __main__ - INFO - Configuration: configs/lsa_t_config_5.yaml
2025-10-07 23:38:26,805 - __main__ - INFO - Starting model evaluation
2025-10-07 23:38:27,566 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-08 00:28:38,735 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-08 00:28:38,749 - __main__ - INFO - Process completed!
2025-10-08 00:28:43,337 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-08 00:28:43,337 - __main__ - INFO - Configuration: configs/lsa_t_config_8.yaml
2025-10-08 00:28:43,337 - __main__ - INFO - Starting model evaluation
2025-10-08 00:28:44,146 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-08 01:48:16,454 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-08 01:48:16,469 - __main__ - INFO - Process completed!
2025-10-08 01:48:20,556 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-08 01:48:20,556 - __main__ - INFO - Configuration: configs/lsa_t_config_16.yaml
2025-10-08 01:48:20,556 - __main__ - INFO - Starting model evaluation
2025-10-08 01:48:21,302 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-08 04:34:46,703 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-08 04:34:46,720 - __main__ - INFO - Process completed!
2025-10-08 04:34:50,896 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-08 04:34:50,896 - __main__ - INFO - Configuration: configs/lsa_t_config_24.yaml
2025-10-08 04:34:50,896 - __main__ - INFO - Starting model evaluation
2025-10-08 04:34:51,508 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-08 08:52:49,142 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-08 08:52:49,157 - __main__ - INFO - Process completed!
2025-10-08 08:52:53,647 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-08 08:52:53,647 - __main__ - INFO - Configuration: configs/lsa_t_config_32.yaml
2025-10-08 08:52:53,647 - __main__ - INFO - Starting model evaluation
2025-10-08 08:52:54,283 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-08 19:49:58,830 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-08 19:49:59,403 - __main__ - INFO - Process completed!
2025-10-10 22:12:52,425 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-10 22:12:52,426 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-10 22:12:52,427 - __main__ - INFO - Starting training pipeline
2025-10-10 22:12:52,454 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-10 22:12:52,478 - __main__ - INFO - GPU: NVIDIA A30
2025-10-10 22:12:52,478 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-10 22:12:52,478 - __main__ - INFO - Loading training data...
2025-10-10 22:13:36,716 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-10 22:13:36,717 - __main__ - INFO - Processing train split...
2025-10-10 22:13:36,824 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-10 22:13:36,824 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-10 22:14:34,039 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-10 22:15:31,812 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-10 22:16:29,810 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-10 22:17:26,377 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-10 22:18:22,570 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-10 22:19:17,282 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-10 22:19:59,907 - __main__ - INFO - Processing val split...
2025-10-10 22:20:00,176 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-10 22:20:00,176 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-10 22:20:46,409 - __main__ - INFO - Processing test split...
2025-10-10 22:20:46,679 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-10 22:20:46,679 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-10 22:21:33,534 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-10 22:21:33,534 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-10 22:21:33,554 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-10 22:21:33,554 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-10 22:21:33,554 - __main__ - INFO - Creating model architecture...
2025-10-10 22:21:34,068 - __main__ - INFO - Model created successfully
2025-10-10 22:21:34,069 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-10 22:21:34,069 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-10 22:21:34,069 - __main__ - INFO - Using device: cuda
2025-10-10 22:21:34,069 - __main__ - INFO - Creating trainer...
2025-10-10 22:21:34,069 - __main__ - INFO - Moving model to cuda...
2025-10-10 22:21:34,477 - __main__ - INFO - Model moved to cuda
2025-10-10 22:21:34,478 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-10 22:21:36,969 - __main__ - INFO - Trainer created successfully
2025-10-10 22:21:36,969 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-10 22:21:36,969 - __main__ - INFO - Starting training...
2025-10-10 22:21:36,969 - __main__ - INFO - Training configuration:
2025-10-10 22:21:36,970 - __main__ - INFO -   - Epochs: 100
2025-10-10 22:21:36,970 - __main__ - INFO -   - Batch size: 2
2025-10-10 22:21:36,970 - __main__ - INFO -   - Learning rate: 3e-5
2025-10-10 22:21:36,970 - __main__ - INFO -   - Training samples: 6765
2025-10-10 22:21:36,970 - __main__ - INFO -   - Validation samples: 845
2025-10-10 22:21:36,970 - training.trainer - INFO - Starting training for 100 epochs
2025-10-10 22:21:36,971 - training.trainer - INFO - Model parameters: 19,839,072
2025-10-10 22:21:36,971 - training.trainer - INFO - Training on device: cuda
2025-10-10 22:21:50,628 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.8216, Acc=0.070, 
2025-10-10 22:22:00,790 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.1062, Acc=0.074, 
2025-10-10 22:22:11,173 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.7060, Acc=0.077, 
2025-10-10 22:22:21,332 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.4913, Acc=0.083, 
2025-10-10 22:22:31,148 - training.trainer - INFO - Epoch 0, Step 499: Loss=7.5222, Acc=0.040, 
2025-10-10 22:22:41,166 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.0180, Acc=0.050, 
2025-10-10 22:22:51,027 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.3226, Acc=0.211, 
2025-10-10 22:23:00,852 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.7103, Acc=0.154, 
2025-10-10 22:23:10,339 - training.trainer - INFO - Epoch 0, Step 899: Loss=7.0826, Acc=0.044, 
2025-10-10 22:23:20,029 - training.trainer - INFO - Epoch 0, Step 999: Loss=7.1083, Acc=0.132, 
2025-10-10 22:23:29,471 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.8446, Acc=0.070, 
2025-10-10 22:23:39,080 - training.trainer - INFO - Epoch 0, Step 1199: Loss=7.2911, Acc=0.041, 
2025-10-10 22:23:48,713 - training.trainer - INFO - Epoch 0, Step 1299: Loss=7.0319, Acc=0.111, 
2025-10-10 22:23:58,271 - training.trainer - INFO - Epoch 0, Step 1399: Loss=6.9225, Acc=0.167, 
2025-10-11 17:11:00,782 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-11 17:11:00,783 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-11 17:11:00,783 - __main__ - INFO - Starting training pipeline
2025-10-11 17:11:00,809 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-11 17:11:00,835 - __main__ - INFO - GPU: NVIDIA A30
2025-10-11 17:11:00,835 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-11 17:11:00,836 - __main__ - INFO - Loading training data...
2025-10-11 17:11:44,500 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-11 17:11:44,500 - __main__ - INFO - Processing train split...
2025-10-11 17:11:44,608 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-11 17:11:44,608 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-11 17:12:41,919 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-11 17:13:39,468 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-11 17:14:37,209 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-11 17:15:33,134 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-11 17:16:29,030 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-11 17:17:23,411 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-11 17:18:05,408 - __main__ - INFO - Processing val split...
2025-10-11 17:18:05,672 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-11 17:18:05,673 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-11 17:18:51,446 - __main__ - INFO - Processing test split...
2025-10-11 17:18:51,711 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-11 17:18:51,712 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-11 17:19:38,115 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-11 17:19:38,116 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-11 17:19:38,134 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-11 17:19:38,135 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-11 17:19:38,135 - __main__ - INFO - Creating model architecture...
2025-10-11 17:19:38,541 - __main__ - INFO - Model created successfully
2025-10-11 17:19:38,542 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-11 17:19:38,542 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-11 17:19:38,542 - __main__ - INFO - Using device: cuda
2025-10-11 17:19:38,542 - __main__ - INFO - Creating trainer...
2025-10-11 17:19:38,543 - __main__ - INFO - Moving model to cuda...
2025-10-11 17:19:38,928 - __main__ - INFO - Model moved to cuda
2025-10-11 17:19:38,929 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-11 17:19:40,729 - __main__ - INFO - Trainer created successfully
2025-10-11 17:19:40,730 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-11 17:19:40,730 - __main__ - INFO - Starting training...
2025-10-11 17:19:40,730 - __main__ - INFO - Training configuration:
2025-10-11 17:19:40,730 - __main__ - INFO -   - Epochs: 100
2025-10-11 17:19:40,730 - __main__ - INFO -   - Batch size: 2
2025-10-11 17:19:40,730 - __main__ - INFO -   - Learning rate: 3e-5
2025-10-11 17:19:40,730 - __main__ - INFO -   - Training samples: 6765
2025-10-11 17:19:40,731 - __main__ - INFO -   - Validation samples: 845
2025-10-11 17:19:40,731 - training.trainer - INFO - Starting training for 100 epochs
2025-10-11 17:19:40,731 - training.trainer - INFO - Model parameters: 19,839,072
2025-10-11 17:19:40,731 - training.trainer - INFO - Training on device: cuda
2025-10-11 17:19:52,972 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.9725, Acc=0.056, 
2025-10-11 17:20:03,588 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.1815, Acc=0.000, 
2025-10-11 17:20:14,005 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.8693, Acc=0.036, 
2025-10-11 17:20:24,430 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.2570, Acc=0.079, 
2025-10-11 17:20:34,519 - training.trainer - INFO - Epoch 0, Step 499: Loss=7.2074, Acc=0.049, 
2025-10-11 17:20:44,525 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.3787, Acc=0.172, 
2025-10-11 17:20:54,592 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.6466, Acc=0.056, 
2025-10-11 17:21:04,416 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.8713, Acc=0.077, 
2025-10-11 17:21:14,351 - training.trainer - INFO - Epoch 0, Step 899: Loss=6.8147, Acc=0.056, 
2025-10-11 17:21:24,052 - training.trainer - INFO - Epoch 0, Step 999: Loss=6.5592, Acc=0.125, 
2025-10-11 17:21:33,659 - training.trainer - INFO - Epoch 0, Step 1099: Loss=6.3006, Acc=0.111, 
2025-10-11 17:21:43,235 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.6584, Acc=0.071, 
2025-10-11 17:21:52,851 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.7722, Acc=0.111, 
2025-10-11 17:22:02,579 - training.trainer - INFO - Epoch 0, Step 1399: Loss=6.3669, Acc=0.121, 
2025-10-11 17:22:12,085 - training.trainer - INFO - Epoch 0, Step 1499: Loss=6.6386, Acc=0.111, 
2025-10-11 17:22:21,636 - training.trainer - INFO - Epoch 0, Step 1599: Loss=7.0321, Acc=0.094, 
2025-10-11 17:22:31,346 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.5184, Acc=0.190, 
2025-10-11 17:22:40,858 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.2970, Acc=0.188, 
2025-10-11 17:22:50,607 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.9261, Acc=0.182, 
2025-10-11 17:23:00,171 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.1970, Acc=0.179, 
2025-10-11 17:23:09,881 - training.trainer - INFO - Epoch 0, Step 2099: Loss=5.8649, Acc=0.143, 
2025-10-11 17:23:19,409 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.5004, Acc=0.061, 
2025-10-11 17:23:28,908 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.1991, Acc=0.174, 
2025-10-11 17:23:38,320 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.7710, Acc=0.069, 
2025-10-11 17:23:47,615 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.5752, Acc=0.086, 
2025-10-11 17:23:56,865 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.3729, Acc=0.152, 
2025-10-11 17:24:06,450 - training.trainer - INFO - Epoch 0, Step 2699: Loss=5.9024, Acc=0.214, 
2025-10-11 17:24:15,863 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.5967, Acc=0.151, 
2025-10-11 17:24:25,369 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.7647, Acc=0.143, 
2025-10-11 17:24:35,078 - training.trainer - INFO - Epoch 0, Step 2999: Loss=7.4099, Acc=0.103, 
2025-10-11 17:24:44,512 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.2859, Acc=0.211, 
2025-10-11 17:24:53,918 - training.trainer - INFO - Epoch 0, Step 3199: Loss=6.2802, Acc=0.312, 
2025-10-11 17:25:03,379 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.8672, Acc=0.294, 
2025-10-11 17:25:25,485 - training.trainer - INFO - Epoch 1/100 completed in 344.75s - Train Loss: 6.8265, Train Acc: 0.129, Val Loss: 6.4035, Val Acc: 0.169
2025-10-11 17:25:26,271 - training.trainer - INFO - New best model saved with validation loss: 6.4035
2025-10-11 17:25:26,272 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-11 17:25:35,927 - training.trainer - INFO - Epoch 1, Step 3482: Loss=6.5890, Acc=0.126, 
2025-10-11 17:25:45,337 - training.trainer - INFO - Epoch 1, Step 3582: Loss=5.8861, Acc=0.171, 
2025-10-11 17:25:54,760 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.6007, Acc=0.171, 
2025-10-11 17:26:04,104 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.9068, Acc=0.176, 
2025-10-11 17:26:13,457 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.4668, Acc=0.135, 
2025-10-11 17:26:22,774 - training.trainer - INFO - Epoch 1, Step 3982: Loss=5.8598, Acc=0.250, 
2025-10-11 17:26:32,118 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.7875, Acc=0.241, 
2025-10-11 17:26:41,516 - training.trainer - INFO - Epoch 1, Step 4182: Loss=7.0026, Acc=0.143, 
2025-10-11 17:26:50,701 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.4542, Acc=0.182, 
2025-10-11 17:26:59,951 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.5415, Acc=0.188, 
2025-10-11 17:27:09,345 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.1928, Acc=0.139, 
2025-10-11 17:27:18,697 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.5090, Acc=0.156, 
2025-10-11 17:27:27,945 - training.trainer - INFO - Epoch 1, Step 4682: Loss=6.6572, Acc=0.182, 
2025-10-11 17:27:37,178 - training.trainer - INFO - Epoch 1, Step 4782: Loss=5.7927, Acc=0.133, 
2025-10-11 17:27:46,541 - training.trainer - INFO - Epoch 1, Step 4882: Loss=5.3742, Acc=0.217, 
2025-10-11 17:27:55,981 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.4351, Acc=0.167, 
2025-10-11 17:28:05,499 - training.trainer - INFO - Epoch 1, Step 5082: Loss=5.8839, Acc=0.148, 
2025-10-11 17:28:14,790 - training.trainer - INFO - Epoch 1, Step 5182: Loss=5.6136, Acc=0.286, 
2025-10-11 17:28:24,235 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.2186, Acc=0.167, 
2025-10-11 17:28:33,643 - training.trainer - INFO - Epoch 1, Step 5382: Loss=5.1185, Acc=0.208, 
2025-10-11 17:28:43,121 - training.trainer - INFO - Epoch 1, Step 5482: Loss=5.9618, Acc=0.214, 
2025-10-11 17:28:52,511 - training.trainer - INFO - Epoch 1, Step 5582: Loss=6.5857, Acc=0.111, 
2025-10-11 17:29:01,787 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.0460, Acc=0.128, 
2025-10-11 17:29:11,167 - training.trainer - INFO - Epoch 1, Step 5782: Loss=5.6440, Acc=0.231, 
2025-10-11 17:29:20,651 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.8716, Acc=0.174, 
2025-10-11 17:29:30,187 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.1503, Acc=0.273, 
2025-10-11 17:29:39,647 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.1235, Acc=0.149, 
2025-10-11 17:29:48,886 - training.trainer - INFO - Epoch 1, Step 6182: Loss=7.0430, Acc=0.137, 
2025-10-11 17:29:58,193 - training.trainer - INFO - Epoch 1, Step 6282: Loss=5.9350, Acc=0.171, 
2025-10-11 17:30:07,486 - training.trainer - INFO - Epoch 1, Step 6382: Loss=5.1860, Acc=0.278, 
2025-10-11 17:30:16,657 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.6294, Acc=0.139, 
2025-10-11 17:30:25,868 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.2044, Acc=0.083, 
2025-10-11 17:30:35,201 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.9413, Acc=0.107, 
2025-10-11 17:30:56,475 - training.trainer - INFO - Epoch 2/100 completed in 330.20s - Train Loss: 6.3264, Train Acc: 0.166, Val Loss: 6.2047, Val Acc: 0.175
2025-10-11 17:30:57,228 - training.trainer - INFO - New best model saved with validation loss: 6.2047
2025-10-11 17:30:57,228 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-11 17:31:06,164 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.6495, Acc=0.273, 
2025-10-11 17:31:14,415 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.9872, Acc=0.125, 
2025-10-11 17:31:23,614 - training.trainer - INFO - Epoch 2, Step 7065: Loss=5.9844, Acc=0.152, 
2025-10-11 17:31:33,017 - training.trainer - INFO - Epoch 2, Step 7165: Loss=7.1704, Acc=0.074, 
2025-10-11 17:31:42,455 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.5572, Acc=0.134, 
2025-10-11 17:31:51,739 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.4313, Acc=0.185, 
2025-10-11 17:32:01,065 - training.trainer - INFO - Epoch 2, Step 7465: Loss=5.9397, Acc=0.156, 
2025-10-11 17:32:10,502 - training.trainer - INFO - Epoch 2, Step 7565: Loss=6.6725, Acc=0.139, 
2025-10-11 17:32:20,049 - training.trainer - INFO - Epoch 2, Step 7665: Loss=5.9408, Acc=0.250, 
2025-10-11 17:32:29,239 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.2309, Acc=0.127, 
2025-10-11 17:32:38,444 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.4743, Acc=0.148, 
2025-10-11 17:32:47,647 - training.trainer - INFO - Epoch 2, Step 7965: Loss=6.1364, Acc=0.146, 
2025-10-11 17:32:56,814 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.4562, Acc=0.212, 
2025-10-11 17:33:05,952 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.1458, Acc=0.128, 
2025-10-11 17:33:15,112 - training.trainer - INFO - Epoch 2, Step 8265: Loss=5.8437, Acc=0.217, 
2025-10-11 17:33:24,280 - training.trainer - INFO - Epoch 2, Step 8365: Loss=6.4105, Acc=0.123, 
2025-10-11 17:33:33,496 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.0685, Acc=0.172, 
2025-10-11 17:33:42,649 - training.trainer - INFO - Epoch 2, Step 8565: Loss=7.3213, Acc=0.083, 
2025-10-11 17:33:51,960 - training.trainer - INFO - Epoch 2, Step 8665: Loss=7.1362, Acc=0.193, 
2025-10-11 17:34:01,253 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.1645, Acc=0.222, 
2025-10-11 17:34:10,279 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.0695, Acc=0.263, 
2025-10-11 17:34:19,395 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.5641, Acc=0.180, 
2025-10-11 17:34:28,634 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.1162, Acc=0.154, 
2025-10-11 17:34:37,884 - training.trainer - INFO - Epoch 2, Step 9165: Loss=5.3873, Acc=0.174, 
2025-10-11 17:34:47,063 - training.trainer - INFO - Epoch 2, Step 9265: Loss=5.2693, Acc=0.312, 
2025-10-11 17:34:56,248 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.2794, Acc=0.167, 
2025-10-11 17:35:05,595 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.3618, Acc=0.136, 
2025-10-11 17:35:14,862 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.5420, Acc=0.122, 
2025-10-11 17:35:24,084 - training.trainer - INFO - Epoch 2, Step 9665: Loss=5.5892, Acc=0.212, 
2025-10-11 17:35:33,257 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.8816, Acc=0.261, 
2025-10-11 17:35:42,551 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.0093, Acc=0.143, 
2025-10-11 17:35:52,013 - training.trainer - INFO - Epoch 2, Step 9965: Loss=6.5545, Acc=0.161, 
2025-10-11 17:36:01,177 - training.trainer - INFO - Epoch 2, Step 10065: Loss=5.5068, Acc=0.200, 
2025-10-11 17:36:22,141 - training.trainer - INFO - Epoch 3/100 completed in 324.91s - Train Loss: 6.2133, Train Acc: 0.175, Val Loss: 6.1145, Val Acc: 0.181
2025-10-11 17:36:22,871 - training.trainer - INFO - New best model saved with validation loss: 6.1145
2025-10-11 17:36:22,871 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-10-11 17:36:32,448 - training.trainer - INFO - Epoch 3, Step 10248: Loss=6.0128, Acc=0.177, 
2025-10-11 17:36:41,748 - training.trainer - INFO - Epoch 3, Step 10348: Loss=6.6507, Acc=0.123, 
2025-10-11 17:36:51,058 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.1979, Acc=0.256, 
2025-10-11 17:37:00,406 - training.trainer - INFO - Epoch 3, Step 10548: Loss=6.4131, Acc=0.200, 
2025-10-11 17:37:09,788 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.1843, Acc=0.145, 
2025-10-11 17:37:19,287 - training.trainer - INFO - Epoch 3, Step 10748: Loss=6.3486, Acc=0.240, 
2025-10-11 17:37:28,884 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.3637, Acc=0.203, 
2025-10-11 17:37:38,371 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.3789, Acc=0.123, 
2025-10-11 17:37:47,729 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.2724, Acc=0.167, 
2025-10-11 17:37:57,173 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.6401, Acc=0.171, 
2025-10-11 17:38:06,697 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.2290, Acc=0.293, 
2025-10-11 17:38:15,960 - training.trainer - INFO - Epoch 3, Step 11348: Loss=6.3998, Acc=0.136, 
2025-10-11 17:38:25,327 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.1889, Acc=0.140, 
2025-10-11 17:38:34,772 - training.trainer - INFO - Epoch 3, Step 11548: Loss=6.2458, Acc=0.122, 
2025-10-11 17:38:44,299 - training.trainer - INFO - Epoch 3, Step 11648: Loss=6.8036, Acc=0.193, 
2025-10-11 17:38:53,671 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.9372, Acc=0.191, 
2025-10-11 17:39:03,069 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.6271, Acc=0.214, 
2025-10-11 17:39:12,201 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.2130, Acc=0.115, 
2025-10-11 17:39:21,426 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.2120, Acc=0.235, 
2025-10-11 17:39:30,575 - training.trainer - INFO - Epoch 3, Step 12148: Loss=5.6643, Acc=0.254, 
2025-10-11 17:39:39,687 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.0638, Acc=0.167, 
2025-10-11 17:39:48,864 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.3621, Acc=0.138, 
2025-10-11 17:39:58,082 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.9215, Acc=0.136, 
2025-10-11 17:40:07,228 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.4131, Acc=0.167, 
2025-10-11 17:40:16,420 - training.trainer - INFO - Epoch 3, Step 12648: Loss=6.2677, Acc=0.122, 
2025-10-11 17:40:25,619 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.7177, Acc=0.156, 
2025-10-11 17:40:34,803 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.1798, Acc=0.190, 
2025-10-11 17:40:44,124 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.3744, Acc=0.111, 
2025-10-11 17:40:53,289 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.1187, Acc=0.222, 
2025-10-11 17:41:02,677 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.1159, Acc=0.227, 
2025-10-11 17:41:11,902 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.2478, Acc=0.156, 
2025-10-11 17:41:21,198 - training.trainer - INFO - Epoch 3, Step 13348: Loss=5.3741, Acc=0.250, 
2025-10-11 17:41:30,405 - training.trainer - INFO - Epoch 3, Step 13448: Loss=5.5775, Acc=0.240, 
2025-10-11 17:41:51,650 - training.trainer - INFO - Epoch 4/100 completed in 328.78s - Train Loss: 6.1435, Train Acc: 0.183, Val Loss: 6.0589, Val Acc: 0.192
2025-10-11 17:41:52,577 - training.trainer - INFO - New best model saved with validation loss: 6.0589
2025-10-11 17:41:52,577 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-10-11 17:42:02,162 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.2558, Acc=0.172, 
2025-10-11 17:42:11,483 - training.trainer - INFO - Epoch 4, Step 13731: Loss=6.4219, Acc=0.188, 
2025-10-11 17:42:20,746 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.4072, Acc=0.188, 
2025-10-11 17:42:29,931 - training.trainer - INFO - Epoch 4, Step 13931: Loss=5.7331, Acc=0.172, 
2025-10-11 17:42:39,201 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.9676, Acc=0.225, 
2025-10-11 17:42:48,426 - training.trainer - INFO - Epoch 4, Step 14131: Loss=5.0353, Acc=0.190, 
2025-10-11 17:42:57,868 - training.trainer - INFO - Epoch 4, Step 14231: Loss=5.9702, Acc=0.156, 
2025-10-11 17:43:07,281 - training.trainer - INFO - Epoch 4, Step 14331: Loss=6.0207, Acc=0.194, 
2025-10-11 17:43:16,646 - training.trainer - INFO - Epoch 4, Step 14431: Loss=5.7634, Acc=0.235, 
2025-10-11 17:43:25,939 - training.trainer - INFO - Epoch 4, Step 14531: Loss=5.6996, Acc=0.233, 
2025-10-11 17:43:35,238 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.2854, Acc=0.241, 
2025-10-11 17:43:44,498 - training.trainer - INFO - Epoch 4, Step 14731: Loss=5.5722, Acc=0.190, 
2025-10-11 17:43:53,867 - training.trainer - INFO - Epoch 4, Step 14831: Loss=5.6056, Acc=0.257, 
2025-10-11 17:44:03,467 - training.trainer - INFO - Epoch 4, Step 14931: Loss=5.8609, Acc=0.200, 
2025-10-11 17:44:12,931 - training.trainer - INFO - Epoch 4, Step 15031: Loss=6.0026, Acc=0.115, 
2025-10-11 17:44:22,304 - training.trainer - INFO - Epoch 4, Step 15131: Loss=5.8984, Acc=0.182, 
2025-10-11 17:44:31,699 - training.trainer - INFO - Epoch 4, Step 15231: Loss=6.3590, Acc=0.139, 
2025-10-11 17:44:40,919 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.2261, Acc=0.238, 
2025-10-11 17:44:50,185 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.0075, Acc=0.184, 
2025-10-11 17:44:59,439 - training.trainer - INFO - Epoch 4, Step 15531: Loss=6.5488, Acc=0.173, 
2025-10-11 17:45:08,846 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.0405, Acc=0.148, 
2025-10-11 17:45:18,133 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.4819, Acc=0.146, 
2025-10-11 17:45:27,531 - training.trainer - INFO - Epoch 4, Step 15831: Loss=5.1056, Acc=0.280, 
2025-10-11 17:45:36,984 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.6373, Acc=0.154, 
2025-10-11 17:45:46,367 - training.trainer - INFO - Epoch 4, Step 16031: Loss=5.6858, Acc=0.204, 
2025-10-11 17:45:55,543 - training.trainer - INFO - Epoch 4, Step 16131: Loss=5.9318, Acc=0.159, 
2025-10-11 17:46:05,034 - training.trainer - INFO - Epoch 4, Step 16231: Loss=5.8484, Acc=0.129, 
2025-10-11 17:46:14,350 - training.trainer - INFO - Epoch 4, Step 16331: Loss=4.9981, Acc=0.260, 
2025-10-11 17:46:23,693 - training.trainer - INFO - Epoch 4, Step 16431: Loss=6.0518, Acc=0.308, 
2025-10-11 17:46:33,227 - training.trainer - INFO - Epoch 4, Step 16531: Loss=5.6617, Acc=0.219, 
2025-10-11 17:46:42,709 - training.trainer - INFO - Epoch 4, Step 16631: Loss=5.8311, Acc=0.241, 
2025-10-11 17:46:52,169 - training.trainer - INFO - Epoch 4, Step 16731: Loss=6.2510, Acc=0.189, 
2025-10-11 17:47:01,453 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.1156, Acc=0.162, 
2025-10-11 17:47:22,931 - training.trainer - INFO - Epoch 5/100 completed in 330.35s - Train Loss: 6.0936, Train Acc: 0.191, Val Loss: 5.9937, Val Acc: 0.203
2025-10-11 17:47:23,435 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-11 17:47:24,384 - training.trainer - INFO - New best model saved with validation loss: 5.9937
2025-10-11 17:47:24,384 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-11 17:47:34,341 - training.trainer - INFO - Epoch 5, Step 17014: Loss=5.8291, Acc=0.123, 
2025-10-11 17:47:43,516 - training.trainer - INFO - Epoch 5, Step 17114: Loss=5.6528, Acc=0.200, 
2025-10-11 17:47:52,630 - training.trainer - INFO - Epoch 5, Step 17214: Loss=5.8800, Acc=0.220, 
2025-10-11 17:48:01,835 - training.trainer - INFO - Epoch 5, Step 17314: Loss=5.3825, Acc=0.258, 
2025-10-11 17:48:11,033 - training.trainer - INFO - Epoch 5, Step 17414: Loss=5.8959, Acc=0.184, 
2025-10-11 17:48:20,497 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.3837, Acc=0.091, 
2025-10-11 17:48:29,764 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.0321, Acc=0.146, 
2025-10-11 17:48:39,217 - training.trainer - INFO - Epoch 5, Step 17714: Loss=5.3598, Acc=0.194, 
2025-10-11 17:48:48,516 - training.trainer - INFO - Epoch 5, Step 17814: Loss=5.9575, Acc=0.267, 
2025-10-11 17:48:57,829 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.5477, Acc=0.220, 
2025-10-11 17:49:07,028 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.2444, Acc=0.220, 
2025-10-11 17:49:16,335 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.6722, Acc=0.113, 
2025-10-11 17:49:25,645 - training.trainer - INFO - Epoch 5, Step 18214: Loss=5.7765, Acc=0.179, 
2025-10-11 17:49:35,017 - training.trainer - INFO - Epoch 5, Step 18314: Loss=5.6323, Acc=0.235, 
2025-10-11 17:49:44,357 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.7537, Acc=0.219, 
2025-10-11 17:49:53,646 - training.trainer - INFO - Epoch 5, Step 18514: Loss=5.9488, Acc=0.212, 
2025-10-11 17:50:02,882 - training.trainer - INFO - Epoch 5, Step 18614: Loss=6.9836, Acc=0.179, 
2025-10-11 17:50:12,096 - training.trainer - INFO - Epoch 5, Step 18714: Loss=5.4190, Acc=0.237, 
2025-10-11 17:50:21,376 - training.trainer - INFO - Epoch 5, Step 18814: Loss=6.3235, Acc=0.080, 
2025-10-11 17:50:30,629 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.1321, Acc=0.217, 
2025-10-11 17:50:39,870 - training.trainer - INFO - Epoch 5, Step 19014: Loss=5.1852, Acc=0.267, 
2025-10-11 17:50:49,096 - training.trainer - INFO - Epoch 5, Step 19114: Loss=5.3822, Acc=0.300, 
2025-10-11 17:50:58,452 - training.trainer - INFO - Epoch 5, Step 19214: Loss=6.6786, Acc=0.159, 
2025-10-11 17:51:07,872 - training.trainer - INFO - Epoch 5, Step 19314: Loss=5.4290, Acc=0.240, 
2025-10-11 17:51:17,126 - training.trainer - INFO - Epoch 5, Step 19414: Loss=5.7287, Acc=0.167, 
2025-10-11 17:51:26,433 - training.trainer - INFO - Epoch 5, Step 19514: Loss=5.4201, Acc=0.269, 
2025-10-11 17:51:35,856 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.6296, Acc=0.143, 
2025-10-11 17:51:45,196 - training.trainer - INFO - Epoch 5, Step 19714: Loss=6.8146, Acc=0.182, 
2025-10-11 17:51:54,479 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.4562, Acc=0.154, 
2025-10-11 17:52:03,801 - training.trainer - INFO - Epoch 5, Step 19914: Loss=6.2703, Acc=0.113, 
2025-10-11 17:52:13,203 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.5554, Acc=0.146, 
2025-10-11 17:52:22,464 - training.trainer - INFO - Epoch 5, Step 20114: Loss=4.7521, Acc=0.263, 
2025-10-11 17:52:31,927 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.7753, Acc=0.226, 
2025-10-11 17:52:52,843 - training.trainer - INFO - Epoch 6/100 completed in 328.46s - Train Loss: 6.0423, Train Acc: 0.199, Val Loss: 5.9649, Val Acc: 0.207
2025-10-11 17:52:53,757 - training.trainer - INFO - New best model saved with validation loss: 5.9649
2025-10-11 17:52:53,757 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-10-11 17:53:03,544 - training.trainer - INFO - Epoch 6, Step 20397: Loss=6.4728, Acc=0.152, 
2025-10-11 17:53:12,965 - training.trainer - INFO - Epoch 6, Step 20497: Loss=6.4648, Acc=0.240, 
2025-10-11 17:53:22,352 - training.trainer - INFO - Epoch 6, Step 20597: Loss=4.9834, Acc=0.263, 
2025-10-11 17:53:31,713 - training.trainer - INFO - Epoch 6, Step 20697: Loss=6.4631, Acc=0.173, 
2025-10-11 17:53:40,989 - training.trainer - INFO - Epoch 6, Step 20797: Loss=6.5413, Acc=0.167, 
2025-10-11 17:53:50,414 - training.trainer - INFO - Epoch 6, Step 20897: Loss=6.3085, Acc=0.200, 
2025-10-11 17:53:59,890 - training.trainer - INFO - Epoch 6, Step 20997: Loss=5.7900, Acc=0.261, 
2025-10-11 17:54:09,241 - training.trainer - INFO - Epoch 6, Step 21097: Loss=6.2470, Acc=0.153, 
2025-10-11 17:54:18,531 - training.trainer - INFO - Epoch 6, Step 21197: Loss=5.5487, Acc=0.333, 
2025-10-11 17:54:27,854 - training.trainer - INFO - Epoch 6, Step 21297: Loss=6.8955, Acc=0.114, 
2025-10-11 17:54:37,215 - training.trainer - INFO - Epoch 6, Step 21397: Loss=4.6975, Acc=0.300, 
2025-10-11 17:54:46,556 - training.trainer - INFO - Epoch 6, Step 21497: Loss=6.3396, Acc=0.174, 
2025-10-11 17:54:56,080 - training.trainer - INFO - Epoch 6, Step 21597: Loss=5.9011, Acc=0.168, 
2025-10-11 17:55:05,405 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.6013, Acc=0.097, 
2025-10-11 17:55:14,783 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.2990, Acc=0.195, 
2025-10-11 17:55:24,119 - training.trainer - INFO - Epoch 6, Step 21897: Loss=5.4771, Acc=0.222, 
2025-10-11 17:55:33,405 - training.trainer - INFO - Epoch 6, Step 21997: Loss=5.6824, Acc=0.231, 
2025-10-11 17:55:42,778 - training.trainer - INFO - Epoch 6, Step 22097: Loss=6.4436, Acc=0.139, 
2025-10-11 17:55:52,240 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.1825, Acc=0.151, 
2025-10-11 17:56:01,790 - training.trainer - INFO - Epoch 6, Step 22297: Loss=3.5131, Acc=0.571, 
2025-10-11 17:56:11,197 - training.trainer - INFO - Epoch 6, Step 22397: Loss=4.8268, Acc=0.269, 
2025-10-11 17:56:20,611 - training.trainer - INFO - Epoch 6, Step 22497: Loss=5.6108, Acc=0.274, 
2025-10-11 17:56:29,893 - training.trainer - INFO - Epoch 6, Step 22597: Loss=5.8510, Acc=0.304, 
2025-10-11 17:56:39,177 - training.trainer - INFO - Epoch 6, Step 22697: Loss=5.7123, Acc=0.222, 
2025-10-11 17:56:48,404 - training.trainer - INFO - Epoch 6, Step 22797: Loss=6.4906, Acc=0.148, 
2025-10-11 17:56:57,613 - training.trainer - INFO - Epoch 6, Step 22897: Loss=6.1045, Acc=0.125, 
2025-10-11 17:57:06,970 - training.trainer - INFO - Epoch 6, Step 22997: Loss=5.7450, Acc=0.200, 
2025-10-11 17:57:16,423 - training.trainer - INFO - Epoch 6, Step 23097: Loss=5.7099, Acc=0.324, 
2025-10-11 17:57:25,792 - training.trainer - INFO - Epoch 6, Step 23197: Loss=6.1772, Acc=0.188, 
2025-10-11 17:57:35,282 - training.trainer - INFO - Epoch 6, Step 23297: Loss=6.3331, Acc=0.167, 
2025-10-11 17:57:44,677 - training.trainer - INFO - Epoch 6, Step 23397: Loss=6.2805, Acc=0.221, 
2025-10-11 17:57:54,177 - training.trainer - INFO - Epoch 6, Step 23497: Loss=4.1447, Acc=0.400, 
2025-10-11 17:58:03,593 - training.trainer - INFO - Epoch 6, Step 23597: Loss=5.5971, Acc=0.240, 
2025-10-11 17:58:24,590 - training.trainer - INFO - Epoch 7/100 completed in 330.83s - Train Loss: 5.9996, Train Acc: 0.207, Val Loss: 5.9147, Val Acc: 0.216
2025-10-11 17:58:25,542 - training.trainer - INFO - New best model saved with validation loss: 5.9147
2025-10-11 17:58:25,542 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-10-11 17:58:35,406 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.6070, Acc=0.150, 
2025-10-11 17:58:44,609 - training.trainer - INFO - Epoch 7, Step 23880: Loss=5.8469, Acc=0.196, 
2025-10-11 17:58:53,916 - training.trainer - INFO - Epoch 7, Step 23980: Loss=6.7607, Acc=0.071, 
2025-10-11 17:59:03,287 - training.trainer - INFO - Epoch 7, Step 24080: Loss=6.2847, Acc=0.250, 
2025-10-11 17:59:12,766 - training.trainer - INFO - Epoch 7, Step 24180: Loss=6.0719, Acc=0.217, 
2025-10-11 17:59:22,237 - training.trainer - INFO - Epoch 7, Step 24280: Loss=6.0556, Acc=0.231, 
2025-10-11 17:59:31,711 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.5716, Acc=0.093, 
2025-10-11 17:59:41,162 - training.trainer - INFO - Epoch 7, Step 24480: Loss=6.2442, Acc=0.133, 
2025-10-11 17:59:50,553 - training.trainer - INFO - Epoch 7, Step 24580: Loss=5.1253, Acc=0.359, 
2025-10-11 17:59:59,925 - training.trainer - INFO - Epoch 7, Step 24680: Loss=6.0618, Acc=0.231, 
2025-10-11 18:00:09,295 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.0523, Acc=0.192, 
2025-10-11 18:00:18,723 - training.trainer - INFO - Epoch 7, Step 24880: Loss=6.0881, Acc=0.171, 
2025-10-11 18:00:28,014 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.2052, Acc=0.333, 
2025-10-11 18:00:37,366 - training.trainer - INFO - Epoch 7, Step 25080: Loss=6.5217, Acc=0.079, 
2025-10-11 18:00:46,622 - training.trainer - INFO - Epoch 7, Step 25180: Loss=5.6402, Acc=0.241, 
2025-10-11 18:00:55,928 - training.trainer - INFO - Epoch 7, Step 25280: Loss=7.1276, Acc=0.075, 
2025-10-11 18:01:05,149 - training.trainer - INFO - Epoch 7, Step 25380: Loss=6.3812, Acc=0.172, 
2025-10-11 18:01:14,433 - training.trainer - INFO - Epoch 7, Step 25480: Loss=5.3049, Acc=0.233, 
2025-10-11 18:01:23,659 - training.trainer - INFO - Epoch 7, Step 25580: Loss=6.0110, Acc=0.171, 
2025-10-11 18:01:32,908 - training.trainer - INFO - Epoch 7, Step 25680: Loss=7.0765, Acc=0.105, 
2025-10-11 18:01:42,208 - training.trainer - INFO - Epoch 7, Step 25780: Loss=5.6385, Acc=0.241, 
2025-10-11 18:01:51,461 - training.trainer - INFO - Epoch 7, Step 25880: Loss=5.9663, Acc=0.180, 
2025-10-11 18:02:00,803 - training.trainer - INFO - Epoch 7, Step 25980: Loss=5.2964, Acc=0.143, 
2025-10-11 18:02:10,484 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.1875, Acc=0.217, 
2025-10-11 18:02:20,069 - training.trainer - INFO - Epoch 7, Step 26180: Loss=5.0820, Acc=0.333, 
2025-10-11 18:02:29,442 - training.trainer - INFO - Epoch 7, Step 26280: Loss=5.4792, Acc=0.306, 
2025-10-11 18:02:38,988 - training.trainer - INFO - Epoch 7, Step 26380: Loss=5.3735, Acc=0.333, 
2025-10-11 18:02:48,335 - training.trainer - INFO - Epoch 7, Step 26480: Loss=5.3051, Acc=0.231, 
2025-10-11 18:02:57,697 - training.trainer - INFO - Epoch 7, Step 26580: Loss=5.1021, Acc=0.302, 
2025-10-11 18:03:07,046 - training.trainer - INFO - Epoch 7, Step 26680: Loss=5.5583, Acc=0.211, 
2025-10-11 18:03:16,598 - training.trainer - INFO - Epoch 7, Step 26780: Loss=6.1262, Acc=0.217, 
2025-10-11 18:03:25,940 - training.trainer - INFO - Epoch 7, Step 26880: Loss=6.2435, Acc=0.224, 
2025-10-11 18:03:35,316 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.8658, Acc=0.250, 
2025-10-11 18:03:56,886 - training.trainer - INFO - Epoch 8/100 completed in 331.34s - Train Loss: 5.9588, Train Acc: 0.213, Val Loss: 5.9063, Val Acc: 0.218
2025-10-11 18:03:57,873 - training.trainer - INFO - New best model saved with validation loss: 5.9063
2025-10-11 18:03:57,874 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-10-11 18:04:07,680 - training.trainer - INFO - Epoch 8, Step 27163: Loss=5.7615, Acc=0.211, 
2025-10-11 18:04:17,119 - training.trainer - INFO - Epoch 8, Step 27263: Loss=6.1243, Acc=0.140, 
2025-10-11 18:04:26,444 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.2695, Acc=0.235, 
2025-10-11 18:04:35,581 - training.trainer - INFO - Epoch 8, Step 27463: Loss=6.0652, Acc=0.158, 
2025-10-11 18:04:44,815 - training.trainer - INFO - Epoch 8, Step 27563: Loss=6.0131, Acc=0.226, 
2025-10-11 18:04:54,055 - training.trainer - INFO - Epoch 8, Step 27663: Loss=6.2939, Acc=0.255, 
2025-10-11 18:05:03,361 - training.trainer - INFO - Epoch 8, Step 27763: Loss=6.2417, Acc=0.175, 
2025-10-11 18:05:12,714 - training.trainer - INFO - Epoch 8, Step 27863: Loss=4.8240, Acc=0.280, 
2025-10-11 18:05:22,042 - training.trainer - INFO - Epoch 8, Step 27963: Loss=5.6243, Acc=0.161, 
2025-10-11 18:05:31,334 - training.trainer - INFO - Epoch 8, Step 28063: Loss=6.8169, Acc=0.175, 
2025-10-11 18:05:40,668 - training.trainer - INFO - Epoch 8, Step 28163: Loss=6.4363, Acc=0.222, 
2025-10-11 18:05:49,967 - training.trainer - INFO - Epoch 8, Step 28263: Loss=4.3449, Acc=0.400, 
2025-10-11 18:05:59,390 - training.trainer - INFO - Epoch 8, Step 28363: Loss=4.9972, Acc=0.208, 
2025-10-11 18:06:08,765 - training.trainer - INFO - Epoch 8, Step 28463: Loss=5.8627, Acc=0.219, 
2025-10-11 18:06:18,080 - training.trainer - INFO - Epoch 8, Step 28563: Loss=5.3329, Acc=0.238, 
2025-10-11 18:06:27,249 - training.trainer - INFO - Epoch 8, Step 28663: Loss=6.6104, Acc=0.117, 
2025-10-11 18:06:36,467 - training.trainer - INFO - Epoch 8, Step 28763: Loss=5.4163, Acc=0.308, 
2025-10-11 18:06:45,711 - training.trainer - INFO - Epoch 8, Step 28863: Loss=5.4255, Acc=0.261, 
2025-10-11 18:06:55,033 - training.trainer - INFO - Epoch 8, Step 28963: Loss=6.3791, Acc=0.155, 
2025-10-11 18:07:04,400 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.3589, Acc=0.143, 
2025-10-11 18:07:13,598 - training.trainer - INFO - Epoch 8, Step 29163: Loss=6.3045, Acc=0.238, 
2025-10-11 18:07:22,819 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.2746, Acc=0.225, 
2025-10-11 18:07:32,090 - training.trainer - INFO - Epoch 8, Step 29363: Loss=5.3136, Acc=0.280, 
2025-10-11 18:07:41,406 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.0032, Acc=0.204, 
2025-10-11 18:07:50,621 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.6836, Acc=0.186, 
2025-10-11 18:07:59,873 - training.trainer - INFO - Epoch 8, Step 29663: Loss=3.8703, Acc=0.375, 
2025-10-11 18:08:09,138 - training.trainer - INFO - Epoch 8, Step 29763: Loss=4.9241, Acc=0.263, 
2025-10-11 18:08:18,404 - training.trainer - INFO - Epoch 8, Step 29863: Loss=6.1508, Acc=0.182, 
2025-10-11 18:08:27,664 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.3488, Acc=0.179, 
2025-10-11 18:08:36,963 - training.trainer - INFO - Epoch 8, Step 30063: Loss=6.3306, Acc=0.148, 
2025-10-11 18:08:46,355 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.9844, Acc=0.229, 
2025-10-11 18:08:55,693 - training.trainer - INFO - Epoch 8, Step 30263: Loss=5.6618, Acc=0.368, 
2025-10-11 18:09:04,941 - training.trainer - INFO - Epoch 8, Step 30363: Loss=5.9286, Acc=0.259, 
2025-10-11 18:09:26,409 - training.trainer - INFO - Epoch 9/100 completed in 328.54s - Train Loss: 5.9220, Train Acc: 0.217, Val Loss: 5.8643, Val Acc: 0.224
2025-10-11 18:09:27,316 - training.trainer - INFO - New best model saved with validation loss: 5.8643
2025-10-11 18:09:27,317 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-10-11 18:09:37,382 - training.trainer - INFO - Epoch 9, Step 30546: Loss=4.9328, Acc=0.385, 
2025-10-11 18:09:46,873 - training.trainer - INFO - Epoch 9, Step 30646: Loss=6.4229, Acc=0.220, 
2025-10-11 18:09:56,228 - training.trainer - INFO - Epoch 9, Step 30746: Loss=5.8429, Acc=0.097, 
2025-10-11 18:10:05,674 - training.trainer - INFO - Epoch 9, Step 30846: Loss=6.4377, Acc=0.114, 
2025-10-11 18:10:14,980 - training.trainer - INFO - Epoch 9, Step 30946: Loss=5.5667, Acc=0.231, 
2025-10-11 18:10:24,266 - training.trainer - INFO - Epoch 9, Step 31046: Loss=6.4362, Acc=0.217, 
2025-10-11 18:10:33,604 - training.trainer - INFO - Epoch 9, Step 31146: Loss=5.1950, Acc=0.333, 
2025-10-11 18:10:42,825 - training.trainer - INFO - Epoch 9, Step 31246: Loss=5.4689, Acc=0.275, 
2025-10-11 18:10:52,088 - training.trainer - INFO - Epoch 9, Step 31346: Loss=5.5600, Acc=0.200, 
2025-10-11 18:11:01,381 - training.trainer - INFO - Epoch 9, Step 31446: Loss=4.9157, Acc=0.333, 
2025-10-11 18:11:10,694 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.9818, Acc=0.211, 
2025-10-11 18:11:19,998 - training.trainer - INFO - Epoch 9, Step 31646: Loss=6.2194, Acc=0.190, 
2025-10-11 18:11:29,263 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.5648, Acc=0.243, 
2025-10-11 18:11:38,722 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.0628, Acc=0.207, 
2025-10-11 18:11:48,037 - training.trainer - INFO - Epoch 9, Step 31946: Loss=6.1512, Acc=0.258, 
2025-10-11 18:11:57,210 - training.trainer - INFO - Epoch 9, Step 32046: Loss=5.6232, Acc=0.212, 
2025-10-11 18:12:06,509 - training.trainer - INFO - Epoch 9, Step 32146: Loss=6.3722, Acc=0.143, 
2025-10-11 18:12:15,736 - training.trainer - INFO - Epoch 9, Step 32246: Loss=6.5778, Acc=0.167, 
2025-10-11 18:12:24,954 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.7125, Acc=0.204, 
2025-10-11 18:12:34,227 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.7144, Acc=0.241, 
2025-10-11 18:12:43,559 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.4719, Acc=0.282, 
2025-10-11 18:12:52,841 - training.trainer - INFO - Epoch 9, Step 32646: Loss=5.6242, Acc=0.237, 
2025-10-11 18:13:02,328 - training.trainer - INFO - Epoch 9, Step 32746: Loss=4.8443, Acc=0.348, 
2025-10-11 18:13:11,692 - training.trainer - INFO - Epoch 9, Step 32846: Loss=5.3490, Acc=0.206, 
2025-10-11 18:13:21,021 - training.trainer - INFO - Epoch 9, Step 32946: Loss=5.0278, Acc=0.312, 
2025-10-11 18:13:30,494 - training.trainer - INFO - Epoch 9, Step 33046: Loss=5.5541, Acc=0.286, 
2025-10-11 18:13:39,783 - training.trainer - INFO - Epoch 9, Step 33146: Loss=6.2405, Acc=0.200, 
2025-10-11 18:13:49,093 - training.trainer - INFO - Epoch 9, Step 33246: Loss=5.8584, Acc=0.182, 
2025-10-11 18:13:58,522 - training.trainer - INFO - Epoch 9, Step 33346: Loss=6.6435, Acc=0.282, 
2025-10-11 18:14:07,811 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.3071, Acc=0.212, 
2025-10-11 18:14:17,132 - training.trainer - INFO - Epoch 9, Step 33546: Loss=6.8347, Acc=0.114, 
2025-10-11 18:14:26,406 - training.trainer - INFO - Epoch 9, Step 33646: Loss=6.3111, Acc=0.182, 
2025-10-11 18:14:35,862 - training.trainer - INFO - Epoch 9, Step 33746: Loss=5.2709, Acc=0.320, 
2025-10-11 18:14:57,471 - training.trainer - INFO - Epoch 10/100 completed in 330.15s - Train Loss: 5.8960, Train Acc: 0.222, Val Loss: 5.8515, Val Acc: 0.227
2025-10-11 18:14:57,965 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-11 18:14:58,919 - training.trainer - INFO - New best model saved with validation loss: 5.8515
2025-10-11 18:14:58,919 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-11 18:15:07,431 - training.trainer - INFO - Epoch 10, Step 33929: Loss=5.3008, Acc=0.250, 
2025-10-11 18:15:15,442 - training.trainer - INFO - Epoch 10, Step 34029: Loss=6.1176, Acc=0.167, 
2025-10-11 18:15:23,546 - training.trainer - INFO - Epoch 10, Step 34129: Loss=5.8254, Acc=0.158, 
2025-10-11 18:15:31,558 - training.trainer - INFO - Epoch 10, Step 34229: Loss=6.2462, Acc=0.219, 
2025-10-11 18:15:39,740 - training.trainer - INFO - Epoch 10, Step 34329: Loss=6.5698, Acc=0.120, 
2025-10-11 18:15:47,948 - training.trainer - INFO - Epoch 10, Step 34429: Loss=5.0444, Acc=0.304, 
2025-10-11 18:15:55,974 - training.trainer - INFO - Epoch 10, Step 34529: Loss=5.3273, Acc=0.240, 
2025-10-11 18:16:03,998 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.5805, Acc=0.342, 
2025-10-11 18:16:12,004 - training.trainer - INFO - Epoch 10, Step 34729: Loss=5.2027, Acc=0.429, 
2025-10-11 18:16:20,075 - training.trainer - INFO - Epoch 10, Step 34829: Loss=6.0137, Acc=0.357, 
2025-10-11 18:16:28,049 - training.trainer - INFO - Epoch 10, Step 34929: Loss=5.7747, Acc=0.261, 
2025-10-11 18:16:36,067 - training.trainer - INFO - Epoch 10, Step 35029: Loss=5.8606, Acc=0.188, 
2025-10-11 18:16:44,003 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.4758, Acc=0.146, 
2025-10-11 18:16:51,952 - training.trainer - INFO - Epoch 10, Step 35229: Loss=6.4425, Acc=0.273, 
2025-10-11 18:16:59,948 - training.trainer - INFO - Epoch 10, Step 35329: Loss=5.3588, Acc=0.263, 
2025-10-11 18:17:08,513 - training.trainer - INFO - Epoch 10, Step 35429: Loss=6.2191, Acc=0.167, 
2025-10-11 18:17:16,585 - training.trainer - INFO - Epoch 10, Step 35529: Loss=6.2122, Acc=0.171, 
2025-10-11 18:17:24,625 - training.trainer - INFO - Epoch 10, Step 35629: Loss=6.2062, Acc=0.225, 
2025-10-11 18:17:32,631 - training.trainer - INFO - Epoch 10, Step 35729: Loss=5.9044, Acc=0.176, 
2025-10-11 18:17:40,599 - training.trainer - INFO - Epoch 10, Step 35829: Loss=5.7902, Acc=0.118, 
2025-10-11 18:17:49,254 - training.trainer - INFO - Epoch 10, Step 35929: Loss=5.5425, Acc=0.296, 
2025-10-11 18:17:57,791 - training.trainer - INFO - Epoch 10, Step 36029: Loss=5.6151, Acc=0.269, 
2025-10-11 18:18:06,587 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.9094, Acc=0.139, 
2025-10-11 18:18:15,191 - training.trainer - INFO - Epoch 10, Step 36229: Loss=4.9796, Acc=0.333, 
2025-10-11 18:18:23,278 - training.trainer - INFO - Epoch 10, Step 36329: Loss=4.7683, Acc=0.329, 
2025-10-11 18:18:31,481 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.0911, Acc=0.151, 
2025-10-11 18:18:39,861 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.6672, Acc=0.333, 
2025-10-11 18:18:48,618 - training.trainer - INFO - Epoch 10, Step 36629: Loss=5.2102, Acc=0.286, 
2025-10-11 18:18:57,431 - training.trainer - INFO - Epoch 10, Step 36729: Loss=5.6575, Acc=0.240, 
2025-10-11 18:19:05,989 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.8317, Acc=0.280, 
2025-10-11 18:19:14,213 - training.trainer - INFO - Epoch 10, Step 36929: Loss=6.1472, Acc=0.200, 
2025-10-11 18:19:22,929 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.9182, Acc=0.245, 
2025-10-11 18:19:31,613 - training.trainer - INFO - Epoch 10, Step 37129: Loss=6.2218, Acc=0.263, 
2025-10-11 18:19:52,330 - training.trainer - INFO - Epoch 11/100 completed in 293.41s - Train Loss: 5.8712, Train Acc: 0.227, Val Loss: 5.8462, Val Acc: 0.233
2025-10-11 18:19:53,272 - training.trainer - INFO - New best model saved with validation loss: 5.8462
2025-10-11 18:19:53,273 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-10-11 18:20:03,091 - training.trainer - INFO - Epoch 11, Step 37312: Loss=6.4524, Acc=0.160, 
2025-10-11 18:20:12,784 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.4089, Acc=0.222, 
2025-10-11 18:20:22,371 - training.trainer - INFO - Epoch 11, Step 37512: Loss=5.3192, Acc=0.167, 
2025-10-11 18:20:31,912 - training.trainer - INFO - Epoch 11, Step 37612: Loss=6.0923, Acc=0.175, 
2025-10-11 18:20:41,289 - training.trainer - INFO - Epoch 11, Step 37712: Loss=6.4725, Acc=0.265, 
2025-10-11 18:20:50,590 - training.trainer - INFO - Epoch 11, Step 37812: Loss=5.1490, Acc=0.184, 
2025-10-11 18:20:59,865 - training.trainer - INFO - Epoch 11, Step 37912: Loss=4.9125, Acc=0.345, 
2025-10-11 18:21:09,182 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.9376, Acc=0.135, 
2025-10-11 18:21:18,539 - training.trainer - INFO - Epoch 11, Step 38112: Loss=6.4184, Acc=0.172, 
2025-10-11 18:21:27,967 - training.trainer - INFO - Epoch 11, Step 38212: Loss=6.4500, Acc=0.117, 
2025-10-11 18:21:37,331 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.2076, Acc=0.295, 
2025-10-11 18:21:46,658 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.9360, Acc=0.211, 
2025-10-11 18:21:55,923 - training.trainer - INFO - Epoch 11, Step 38512: Loss=4.8826, Acc=0.417, 
2025-10-11 18:22:05,340 - training.trainer - INFO - Epoch 11, Step 38612: Loss=7.0354, Acc=0.129, 
2025-10-11 18:22:14,609 - training.trainer - INFO - Epoch 11, Step 38712: Loss=6.0340, Acc=0.122, 
2025-10-11 18:22:23,826 - training.trainer - INFO - Epoch 11, Step 38812: Loss=6.5448, Acc=0.212, 
2025-10-11 18:22:33,119 - training.trainer - INFO - Epoch 11, Step 38912: Loss=6.6700, Acc=0.220, 
2025-10-11 18:22:42,505 - training.trainer - INFO - Epoch 11, Step 39012: Loss=6.1412, Acc=0.222, 
2025-10-11 18:22:51,680 - training.trainer - INFO - Epoch 11, Step 39112: Loss=5.7608, Acc=0.273, 
2025-10-11 18:23:00,898 - training.trainer - INFO - Epoch 11, Step 39212: Loss=5.0538, Acc=0.364, 
2025-10-11 18:23:10,280 - training.trainer - INFO - Epoch 11, Step 39312: Loss=6.1379, Acc=0.250, 
2025-10-11 18:23:19,625 - training.trainer - INFO - Epoch 11, Step 39412: Loss=6.7252, Acc=0.159, 
2025-10-11 18:23:28,963 - training.trainer - INFO - Epoch 11, Step 39512: Loss=6.2817, Acc=0.269, 
2025-10-11 18:23:38,284 - training.trainer - INFO - Epoch 11, Step 39612: Loss=5.4894, Acc=0.385, 
2025-10-11 18:23:47,618 - training.trainer - INFO - Epoch 11, Step 39712: Loss=6.4772, Acc=0.167, 
2025-10-11 18:23:56,879 - training.trainer - INFO - Epoch 11, Step 39812: Loss=5.9610, Acc=0.229, 
2025-10-11 18:24:06,184 - training.trainer - INFO - Epoch 11, Step 39912: Loss=6.2970, Acc=0.149, 
2025-10-11 18:24:15,580 - training.trainer - INFO - Epoch 11, Step 40012: Loss=6.8385, Acc=0.116, 
2025-10-11 18:24:24,953 - training.trainer - INFO - Epoch 11, Step 40112: Loss=6.4901, Acc=0.127, 
2025-10-11 18:24:34,468 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.2715, Acc=0.269, 
2025-10-11 18:24:43,930 - training.trainer - INFO - Epoch 11, Step 40312: Loss=5.7793, Acc=0.163, 
2025-10-11 18:24:53,226 - training.trainer - INFO - Epoch 11, Step 40412: Loss=5.9713, Acc=0.290, 
2025-10-11 18:25:02,655 - training.trainer - INFO - Epoch 11, Step 40512: Loss=5.5098, Acc=0.226, 
2025-10-11 18:25:23,828 - training.trainer - INFO - Epoch 12/100 completed in 330.56s - Train Loss: 5.8474, Train Acc: 0.229, Val Loss: 5.8161, Val Acc: 0.236
2025-10-11 18:25:24,687 - training.trainer - INFO - New best model saved with validation loss: 5.8161
2025-10-11 18:25:24,688 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-10-11 18:25:34,467 - training.trainer - INFO - Epoch 12, Step 40695: Loss=5.5982, Acc=0.286, 
2025-10-11 18:25:44,056 - training.trainer - INFO - Epoch 12, Step 40795: Loss=6.4517, Acc=0.110, 
2025-10-11 18:25:53,438 - training.trainer - INFO - Epoch 12, Step 40895: Loss=6.3669, Acc=0.096, 
2025-10-11 18:26:02,901 - training.trainer - INFO - Epoch 12, Step 40995: Loss=5.7840, Acc=0.158, 
2025-10-11 18:26:12,238 - training.trainer - INFO - Epoch 12, Step 41095: Loss=5.8339, Acc=0.182, 
2025-10-11 18:26:21,876 - training.trainer - INFO - Epoch 12, Step 41195: Loss=6.2501, Acc=0.162, 
2025-10-11 18:26:31,305 - training.trainer - INFO - Epoch 12, Step 41295: Loss=5.2390, Acc=0.387, 
2025-10-11 18:26:40,641 - training.trainer - INFO - Epoch 12, Step 41395: Loss=5.9145, Acc=0.212, 
2025-10-11 18:26:49,778 - training.trainer - INFO - Epoch 12, Step 41495: Loss=6.4934, Acc=0.125, 
2025-10-11 18:26:59,413 - training.trainer - INFO - Epoch 12, Step 41595: Loss=5.8767, Acc=0.210, 
2025-10-11 18:27:08,791 - training.trainer - INFO - Epoch 12, Step 41695: Loss=5.6181, Acc=0.214, 
2025-10-11 18:27:18,110 - training.trainer - INFO - Epoch 12, Step 41795: Loss=6.5140, Acc=0.130, 
2025-10-11 18:27:27,418 - training.trainer - INFO - Epoch 12, Step 41895: Loss=6.2711, Acc=0.233, 
2025-10-11 18:27:36,685 - training.trainer - INFO - Epoch 12, Step 41995: Loss=5.3951, Acc=0.265, 
2025-10-11 18:27:46,030 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.0846, Acc=0.321, 
2025-10-11 18:27:55,312 - training.trainer - INFO - Epoch 12, Step 42195: Loss=5.6123, Acc=0.231, 
2025-10-11 18:28:04,437 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.4745, Acc=0.200, 
2025-10-11 18:28:13,579 - training.trainer - INFO - Epoch 12, Step 42395: Loss=4.6632, Acc=0.471, 
2025-10-11 18:28:22,986 - training.trainer - INFO - Epoch 12, Step 42495: Loss=6.0447, Acc=0.161, 
2025-10-11 18:28:32,359 - training.trainer - INFO - Epoch 12, Step 42595: Loss=6.6200, Acc=0.134, 
2025-10-11 18:28:41,812 - training.trainer - INFO - Epoch 12, Step 42695: Loss=6.5583, Acc=0.155, 
2025-10-11 18:28:51,254 - training.trainer - INFO - Epoch 12, Step 42795: Loss=5.8072, Acc=0.282, 
2025-10-11 18:29:00,711 - training.trainer - INFO - Epoch 12, Step 42895: Loss=6.1043, Acc=0.150, 
2025-10-11 18:29:10,183 - training.trainer - INFO - Epoch 12, Step 42995: Loss=6.1422, Acc=0.167, 
2025-10-11 18:29:19,615 - training.trainer - INFO - Epoch 12, Step 43095: Loss=5.0409, Acc=0.333, 
2025-10-11 18:29:29,113 - training.trainer - INFO - Epoch 12, Step 43195: Loss=6.2208, Acc=0.169, 
2025-10-11 18:29:38,437 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.3363, Acc=0.179, 
2025-10-11 18:29:48,036 - training.trainer - INFO - Epoch 12, Step 43395: Loss=5.7435, Acc=0.200, 
2025-10-11 18:29:57,336 - training.trainer - INFO - Epoch 12, Step 43495: Loss=5.2727, Acc=0.438, 
2025-10-11 18:30:06,605 - training.trainer - INFO - Epoch 12, Step 43595: Loss=5.4632, Acc=0.217, 
2025-10-11 18:30:16,023 - training.trainer - INFO - Epoch 12, Step 43695: Loss=6.1067, Acc=0.189, 
2025-10-11 18:30:25,432 - training.trainer - INFO - Epoch 12, Step 43795: Loss=5.7323, Acc=0.207, 
2025-10-11 18:30:34,650 - training.trainer - INFO - Epoch 12, Step 43895: Loss=7.2319, Acc=0.154, 
2025-10-11 18:30:55,957 - training.trainer - INFO - Epoch 13/100 completed in 331.27s - Train Loss: 5.8203, Train Acc: 0.233, Val Loss: 5.8127, Val Acc: 0.236
2025-10-11 18:30:56,835 - training.trainer - INFO - New best model saved with validation loss: 5.8127
2025-10-11 18:30:56,835 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-10-11 18:31:06,534 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.1314, Acc=0.259, 
2025-10-11 18:31:15,821 - training.trainer - INFO - Epoch 13, Step 44178: Loss=6.0862, Acc=0.258, 
2025-10-11 18:31:25,281 - training.trainer - INFO - Epoch 13, Step 44278: Loss=5.3204, Acc=0.214, 
2025-10-11 18:31:34,653 - training.trainer - INFO - Epoch 13, Step 44378: Loss=5.5168, Acc=0.128, 
2025-10-11 18:31:44,167 - training.trainer - INFO - Epoch 13, Step 44478: Loss=5.2867, Acc=0.276, 
2025-10-11 18:31:53,476 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.9506, Acc=0.205, 
2025-10-11 18:32:03,049 - training.trainer - INFO - Epoch 13, Step 44678: Loss=7.2684, Acc=0.162, 
2025-10-11 18:32:12,549 - training.trainer - INFO - Epoch 13, Step 44778: Loss=5.4638, Acc=0.353, 
2025-10-11 18:32:21,906 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.7379, Acc=0.185, 
2025-10-11 18:32:31,070 - training.trainer - INFO - Epoch 13, Step 44978: Loss=6.1483, Acc=0.196, 
2025-10-11 18:32:40,487 - training.trainer - INFO - Epoch 13, Step 45078: Loss=5.1976, Acc=0.328, 
2025-10-11 18:32:49,992 - training.trainer - INFO - Epoch 13, Step 45178: Loss=6.5434, Acc=0.238, 
2025-10-11 18:32:59,726 - training.trainer - INFO - Epoch 13, Step 45278: Loss=4.4376, Acc=0.320, 
2025-10-11 18:33:08,943 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.3220, Acc=0.091, 
2025-10-11 18:33:18,149 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.9161, Acc=0.118, 
2025-10-11 18:33:27,468 - training.trainer - INFO - Epoch 13, Step 45578: Loss=6.1037, Acc=0.176, 
2025-10-11 18:33:36,691 - training.trainer - INFO - Epoch 13, Step 45678: Loss=6.3349, Acc=0.250, 
2025-10-11 18:33:46,110 - training.trainer - INFO - Epoch 13, Step 45778: Loss=6.9132, Acc=0.175, 
2025-10-11 18:33:55,563 - training.trainer - INFO - Epoch 13, Step 45878: Loss=5.9032, Acc=0.308, 
2025-10-11 18:34:04,869 - training.trainer - INFO - Epoch 13, Step 45978: Loss=5.6216, Acc=0.256, 
2025-10-11 18:34:14,172 - training.trainer - INFO - Epoch 13, Step 46078: Loss=5.8359, Acc=0.192, 
2025-10-11 18:34:23,519 - training.trainer - INFO - Epoch 13, Step 46178: Loss=3.2674, Acc=0.591, 
2025-10-11 18:34:32,757 - training.trainer - INFO - Epoch 13, Step 46278: Loss=5.5592, Acc=0.250, 
2025-10-11 18:34:42,062 - training.trainer - INFO - Epoch 13, Step 46378: Loss=6.4845, Acc=0.333, 
2025-10-11 18:34:51,497 - training.trainer - INFO - Epoch 13, Step 46478: Loss=6.2250, Acc=0.231, 
2025-10-11 18:35:00,898 - training.trainer - INFO - Epoch 13, Step 46578: Loss=6.2243, Acc=0.143, 
2025-10-11 18:35:10,303 - training.trainer - INFO - Epoch 13, Step 46678: Loss=6.1708, Acc=0.200, 
2025-10-11 18:35:19,743 - training.trainer - INFO - Epoch 13, Step 46778: Loss=5.7036, Acc=0.250, 
2025-10-11 18:35:29,080 - training.trainer - INFO - Epoch 13, Step 46878: Loss=7.1346, Acc=0.215, 
2025-10-11 18:35:38,344 - training.trainer - INFO - Epoch 13, Step 46978: Loss=6.4235, Acc=0.115, 
2025-10-11 18:35:47,585 - training.trainer - INFO - Epoch 13, Step 47078: Loss=6.1878, Acc=0.192, 
2025-10-11 18:35:56,809 - training.trainer - INFO - Epoch 13, Step 47178: Loss=5.7807, Acc=0.153, 
2025-10-11 18:36:06,151 - training.trainer - INFO - Epoch 13, Step 47278: Loss=6.3731, Acc=0.180, 
2025-10-11 18:36:27,038 - training.trainer - INFO - Epoch 14/100 completed in 330.20s - Train Loss: 5.7977, Train Acc: 0.236, Val Loss: 5.8421, Val Acc: 0.234
2025-10-11 18:36:35,364 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.9378, Acc=0.179, 
2025-10-11 18:36:43,305 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.6008, Acc=0.349, 
2025-10-11 18:36:51,392 - training.trainer - INFO - Epoch 14, Step 47661: Loss=4.7404, Acc=0.346, 
2025-10-11 18:36:59,328 - training.trainer - INFO - Epoch 14, Step 47761: Loss=5.8859, Acc=0.219, 
2025-10-11 18:37:07,424 - training.trainer - INFO - Epoch 14, Step 47861: Loss=6.2902, Acc=0.187, 
2025-10-11 18:37:15,537 - training.trainer - INFO - Epoch 14, Step 47961: Loss=6.4235, Acc=0.122, 
2025-10-11 18:37:23,526 - training.trainer - INFO - Epoch 14, Step 48061: Loss=5.0276, Acc=0.214, 
2025-10-11 18:37:32,168 - training.trainer - INFO - Epoch 14, Step 48161: Loss=4.9733, Acc=0.320, 
2025-10-11 18:37:40,924 - training.trainer - INFO - Epoch 14, Step 48261: Loss=5.5817, Acc=0.171, 
2025-10-11 18:37:49,456 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.7360, Acc=0.226, 
2025-10-11 18:37:57,513 - training.trainer - INFO - Epoch 14, Step 48461: Loss=5.7782, Acc=0.364, 
2025-10-11 18:38:05,733 - training.trainer - INFO - Epoch 14, Step 48561: Loss=6.1240, Acc=0.152, 
2025-10-11 18:38:14,076 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.8539, Acc=0.312, 
2025-10-11 18:38:22,806 - training.trainer - INFO - Epoch 14, Step 48761: Loss=5.6343, Acc=0.167, 
2025-10-11 18:38:32,251 - training.trainer - INFO - Epoch 14, Step 48861: Loss=5.0991, Acc=0.333, 
2025-10-11 18:38:41,612 - training.trainer - INFO - Epoch 14, Step 48961: Loss=6.2084, Acc=0.225, 
2025-10-11 18:38:51,124 - training.trainer - INFO - Epoch 14, Step 49061: Loss=4.4120, Acc=0.360, 
2025-10-11 18:39:00,580 - training.trainer - INFO - Epoch 14, Step 49161: Loss=5.4463, Acc=0.140, 
2025-10-11 18:39:09,823 - training.trainer - INFO - Epoch 14, Step 49261: Loss=4.5531, Acc=0.316, 
2025-10-11 18:39:19,077 - training.trainer - INFO - Epoch 14, Step 49361: Loss=4.8385, Acc=0.364, 
2025-10-11 18:39:28,393 - training.trainer - INFO - Epoch 14, Step 49461: Loss=4.7761, Acc=0.290, 
2025-10-11 18:39:37,641 - training.trainer - INFO - Epoch 14, Step 49561: Loss=5.9143, Acc=0.162, 
2025-10-11 18:39:46,903 - training.trainer - INFO - Epoch 14, Step 49661: Loss=5.7759, Acc=0.265, 
2025-10-11 18:39:56,071 - training.trainer - INFO - Epoch 14, Step 49761: Loss=6.4205, Acc=0.200, 
2025-10-11 18:40:05,323 - training.trainer - INFO - Epoch 14, Step 49861: Loss=6.4933, Acc=0.195, 
2025-10-11 18:40:14,800 - training.trainer - INFO - Epoch 14, Step 49961: Loss=6.0707, Acc=0.204, 
2025-10-11 18:40:24,047 - training.trainer - INFO - Epoch 14, Step 50061: Loss=6.2520, Acc=0.190, 
2025-10-11 18:40:33,182 - training.trainer - INFO - Epoch 14, Step 50161: Loss=5.4289, Acc=0.222, 
2025-10-11 18:40:42,370 - training.trainer - INFO - Epoch 14, Step 50261: Loss=6.9888, Acc=0.119, 
2025-10-11 18:40:51,513 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.0422, Acc=0.348, 
2025-10-11 18:41:00,759 - training.trainer - INFO - Epoch 14, Step 50461: Loss=5.4858, Acc=0.294, 
2025-10-11 18:41:09,979 - training.trainer - INFO - Epoch 14, Step 50561: Loss=6.5542, Acc=0.207, 
2025-10-11 18:41:19,135 - training.trainer - INFO - Epoch 14, Step 50661: Loss=6.2182, Acc=0.176, 
2025-10-11 18:41:41,143 - training.trainer - INFO - Epoch 15/100 completed in 314.10s - Train Loss: 5.7739, Train Acc: 0.239, Val Loss: 5.8349, Val Acc: 0.241
2025-10-11 18:41:41,584 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-11 18:41:51,141 - training.trainer - INFO - Epoch 15, Step 50844: Loss=5.5476, Acc=0.255, 
2025-10-11 18:42:00,382 - training.trainer - INFO - Epoch 15, Step 50944: Loss=5.4565, Acc=0.345, 
2025-10-11 18:42:09,563 - training.trainer - INFO - Epoch 15, Step 51044: Loss=6.6685, Acc=0.237, 
2025-10-11 18:42:18,771 - training.trainer - INFO - Epoch 15, Step 51144: Loss=6.4107, Acc=0.151, 
2025-10-11 18:42:28,079 - training.trainer - INFO - Epoch 15, Step 51244: Loss=5.0058, Acc=0.286, 
2025-10-11 18:42:37,521 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.4896, Acc=0.321, 
2025-10-11 18:42:46,896 - training.trainer - INFO - Epoch 15, Step 51444: Loss=6.2178, Acc=0.208, 
2025-10-11 18:42:56,228 - training.trainer - INFO - Epoch 15, Step 51544: Loss=5.9806, Acc=0.182, 
2025-10-11 18:43:05,572 - training.trainer - INFO - Epoch 15, Step 51644: Loss=4.9960, Acc=0.400, 
2025-10-11 18:43:15,091 - training.trainer - INFO - Epoch 15, Step 51744: Loss=5.5730, Acc=0.150, 
2025-10-11 18:43:24,509 - training.trainer - INFO - Epoch 15, Step 51844: Loss=6.3446, Acc=0.191, 
2025-10-11 18:43:33,699 - training.trainer - INFO - Epoch 15, Step 51944: Loss=5.2106, Acc=0.200, 
2025-10-11 18:43:42,895 - training.trainer - INFO - Epoch 15, Step 52044: Loss=4.6663, Acc=0.238, 
2025-10-11 18:43:52,171 - training.trainer - INFO - Epoch 15, Step 52144: Loss=5.9385, Acc=0.218, 
2025-10-11 18:44:01,383 - training.trainer - INFO - Epoch 15, Step 52244: Loss=5.8108, Acc=0.276, 
2025-10-11 18:44:10,591 - training.trainer - INFO - Epoch 15, Step 52344: Loss=6.2967, Acc=0.279, 
2025-10-11 18:44:19,755 - training.trainer - INFO - Epoch 15, Step 52444: Loss=6.1010, Acc=0.214, 
2025-10-11 18:44:29,098 - training.trainer - INFO - Epoch 15, Step 52544: Loss=5.8581, Acc=0.200, 
2025-10-11 18:44:38,383 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.5940, Acc=0.273, 
2025-10-11 18:44:47,898 - training.trainer - INFO - Epoch 15, Step 52744: Loss=6.2453, Acc=0.196, 
2025-10-11 18:44:57,337 - training.trainer - INFO - Epoch 15, Step 52844: Loss=6.6360, Acc=0.238, 
2025-10-11 18:45:06,636 - training.trainer - INFO - Epoch 15, Step 52944: Loss=5.5189, Acc=0.200, 
2025-10-11 18:45:15,908 - training.trainer - INFO - Epoch 15, Step 53044: Loss=5.9662, Acc=0.269, 
2025-10-11 18:45:25,229 - training.trainer - INFO - Epoch 15, Step 53144: Loss=6.0796, Acc=0.143, 
2025-10-11 18:45:34,422 - training.trainer - INFO - Epoch 15, Step 53244: Loss=5.5063, Acc=0.385, 
2025-10-11 18:45:43,651 - training.trainer - INFO - Epoch 15, Step 53344: Loss=6.1407, Acc=0.170, 
2025-10-11 18:45:53,121 - training.trainer - INFO - Epoch 15, Step 53444: Loss=6.3389, Acc=0.186, 
2025-10-11 18:46:02,296 - training.trainer - INFO - Epoch 15, Step 53544: Loss=6.6203, Acc=0.130, 
2025-10-11 18:46:11,587 - training.trainer - INFO - Epoch 15, Step 53644: Loss=4.7503, Acc=0.312, 
2025-10-11 18:46:20,805 - training.trainer - INFO - Epoch 15, Step 53744: Loss=6.1270, Acc=0.255, 
2025-10-11 18:46:30,158 - training.trainer - INFO - Epoch 15, Step 53844: Loss=5.6250, Acc=0.203, 
2025-10-11 18:46:39,538 - training.trainer - INFO - Epoch 15, Step 53944: Loss=5.5638, Acc=0.265, 
2025-10-11 18:46:48,980 - training.trainer - INFO - Epoch 15, Step 54044: Loss=5.3753, Acc=0.333, 
2025-10-11 18:47:10,198 - training.trainer - INFO - Epoch 16/100 completed in 328.61s - Train Loss: 5.7469, Train Acc: 0.242, Val Loss: 5.8207, Val Acc: 0.242
2025-10-11 18:47:19,829 - training.trainer - INFO - Epoch 16, Step 54227: Loss=6.3531, Acc=0.132, 
2025-10-11 18:47:29,210 - training.trainer - INFO - Epoch 16, Step 54327: Loss=6.3346, Acc=0.250, 
2025-10-11 18:47:38,455 - training.trainer - INFO - Epoch 16, Step 54427: Loss=6.0023, Acc=0.211, 
2025-10-11 18:47:47,787 - training.trainer - INFO - Epoch 16, Step 54527: Loss=4.6289, Acc=0.351, 
2025-10-11 18:47:57,158 - training.trainer - INFO - Epoch 16, Step 54627: Loss=5.1426, Acc=0.222, 
2025-10-11 18:48:06,863 - training.trainer - INFO - Epoch 16, Step 54727: Loss=6.1718, Acc=0.270, 
2025-10-11 18:48:16,283 - training.trainer - INFO - Epoch 16, Step 54827: Loss=5.8768, Acc=0.250, 
2025-10-11 18:48:25,658 - training.trainer - INFO - Epoch 16, Step 54927: Loss=4.8633, Acc=0.394, 
2025-10-11 18:48:35,172 - training.trainer - INFO - Epoch 16, Step 55027: Loss=4.9718, Acc=0.304, 
2025-10-11 18:48:44,666 - training.trainer - INFO - Epoch 16, Step 55127: Loss=5.7644, Acc=0.242, 
2025-10-11 18:48:54,204 - training.trainer - INFO - Epoch 16, Step 55227: Loss=5.2389, Acc=0.258, 
2025-10-11 18:49:03,435 - training.trainer - INFO - Epoch 16, Step 55327: Loss=4.6344, Acc=0.375, 
2025-10-11 18:49:12,728 - training.trainer - INFO - Epoch 16, Step 55427: Loss=4.9842, Acc=0.385, 
2025-10-11 18:49:22,089 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.3596, Acc=0.294, 
2025-10-11 18:49:31,534 - training.trainer - INFO - Epoch 16, Step 55627: Loss=6.1773, Acc=0.273, 
2025-10-11 18:49:40,855 - training.trainer - INFO - Epoch 16, Step 55727: Loss=6.5208, Acc=0.255, 
2025-10-11 18:49:50,336 - training.trainer - INFO - Epoch 16, Step 55827: Loss=5.5917, Acc=0.286, 
2025-10-11 18:49:59,909 - training.trainer - INFO - Epoch 16, Step 55927: Loss=6.3295, Acc=0.235, 
2025-10-11 18:50:09,330 - training.trainer - INFO - Epoch 16, Step 56027: Loss=5.9866, Acc=0.174, 
2025-10-11 18:50:18,843 - training.trainer - INFO - Epoch 16, Step 56127: Loss=6.0622, Acc=0.104, 
2025-10-11 18:50:28,286 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.9145, Acc=0.205, 
2025-10-11 18:50:37,641 - training.trainer - INFO - Epoch 16, Step 56327: Loss=6.1750, Acc=0.157, 
2025-10-11 18:50:46,924 - training.trainer - INFO - Epoch 16, Step 56427: Loss=6.2454, Acc=0.242, 
2025-10-11 18:50:56,331 - training.trainer - INFO - Epoch 16, Step 56527: Loss=4.8654, Acc=0.231, 
2025-10-11 18:51:05,526 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.2844, Acc=0.296, 
2025-10-11 18:51:14,892 - training.trainer - INFO - Epoch 16, Step 56727: Loss=6.1229, Acc=0.229, 
2025-10-11 18:51:24,339 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.2199, Acc=0.297, 
2025-10-11 18:51:33,788 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.4440, Acc=0.280, 
2025-10-11 18:51:43,342 - training.trainer - INFO - Epoch 16, Step 57027: Loss=6.4966, Acc=0.175, 
2025-10-11 18:51:52,816 - training.trainer - INFO - Epoch 16, Step 57127: Loss=6.3298, Acc=0.132, 
2025-10-11 18:52:02,225 - training.trainer - INFO - Epoch 16, Step 57227: Loss=5.0211, Acc=0.333, 
2025-10-11 18:52:11,814 - training.trainer - INFO - Epoch 16, Step 57327: Loss=5.5105, Acc=0.220, 
2025-10-11 18:52:21,353 - training.trainer - INFO - Epoch 16, Step 57427: Loss=5.4955, Acc=0.306, 
2025-10-11 18:52:43,516 - training.trainer - INFO - Epoch 17/100 completed in 333.32s - Train Loss: 5.7274, Train Acc: 0.246, Val Loss: 5.8150, Val Acc: 0.244
2025-10-11 18:52:53,455 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.2989, Acc=0.360, 
2025-10-11 18:53:02,843 - training.trainer - INFO - Epoch 17, Step 57710: Loss=5.3940, Acc=0.320, 
2025-10-11 18:53:12,352 - training.trainer - INFO - Epoch 17, Step 57810: Loss=6.0398, Acc=0.203, 
2025-10-11 18:53:21,830 - training.trainer - INFO - Epoch 17, Step 57910: Loss=6.1050, Acc=0.275, 
2025-10-11 18:53:31,319 - training.trainer - INFO - Epoch 17, Step 58010: Loss=4.8330, Acc=0.333, 
2025-10-11 18:53:40,751 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.2196, Acc=0.269, 
2025-10-11 18:53:50,122 - training.trainer - INFO - Epoch 17, Step 58210: Loss=5.4747, Acc=0.182, 
2025-10-11 18:53:59,436 - training.trainer - INFO - Epoch 17, Step 58310: Loss=6.1580, Acc=0.286, 
2025-10-11 18:54:08,915 - training.trainer - INFO - Epoch 17, Step 58410: Loss=5.8856, Acc=0.195, 
2025-10-11 18:54:18,324 - training.trainer - INFO - Epoch 17, Step 58510: Loss=6.1505, Acc=0.265, 
2025-10-11 18:54:27,734 - training.trainer - INFO - Epoch 17, Step 58610: Loss=6.0701, Acc=0.156, 
2025-10-11 18:54:36,982 - training.trainer - INFO - Epoch 17, Step 58710: Loss=6.1037, Acc=0.172, 
2025-10-11 18:54:46,282 - training.trainer - INFO - Epoch 17, Step 58810: Loss=6.0190, Acc=0.216, 
2025-10-11 18:54:55,605 - training.trainer - INFO - Epoch 17, Step 58910: Loss=6.3061, Acc=0.118, 
2025-10-11 18:55:04,938 - training.trainer - INFO - Epoch 17, Step 59010: Loss=5.6014, Acc=0.208, 
2025-10-11 18:55:14,219 - training.trainer - INFO - Epoch 17, Step 59110: Loss=4.6232, Acc=0.438, 
2025-10-11 18:55:23,557 - training.trainer - INFO - Epoch 17, Step 59210: Loss=5.7106, Acc=0.227, 
2025-10-11 18:55:33,000 - training.trainer - INFO - Epoch 17, Step 59310: Loss=6.1348, Acc=0.196, 
2025-10-11 18:55:42,379 - training.trainer - INFO - Epoch 17, Step 59410: Loss=4.0267, Acc=0.417, 
2025-10-11 18:55:51,824 - training.trainer - INFO - Epoch 17, Step 59510: Loss=6.4796, Acc=0.279, 
2025-10-11 18:56:01,244 - training.trainer - INFO - Epoch 17, Step 59610: Loss=6.2347, Acc=0.214, 
2025-10-11 18:56:10,819 - training.trainer - INFO - Epoch 17, Step 59710: Loss=6.7131, Acc=0.115, 
2025-10-11 18:56:20,209 - training.trainer - INFO - Epoch 17, Step 59810: Loss=5.9141, Acc=0.216, 
2025-10-11 18:56:29,456 - training.trainer - INFO - Epoch 17, Step 59910: Loss=5.1548, Acc=0.250, 
2025-10-11 18:56:38,759 - training.trainer - INFO - Epoch 17, Step 60010: Loss=5.8430, Acc=0.263, 
2025-10-11 18:56:48,259 - training.trainer - INFO - Epoch 17, Step 60110: Loss=6.1730, Acc=0.237, 
2025-10-11 18:56:57,576 - training.trainer - INFO - Epoch 17, Step 60210: Loss=5.4596, Acc=0.276, 
2025-10-11 18:57:07,088 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.8822, Acc=0.259, 
2025-10-11 18:57:16,591 - training.trainer - INFO - Epoch 17, Step 60410: Loss=4.9052, Acc=0.444, 
2025-10-11 18:57:26,118 - training.trainer - INFO - Epoch 17, Step 60510: Loss=5.1507, Acc=0.185, 
2025-10-11 18:57:35,569 - training.trainer - INFO - Epoch 17, Step 60610: Loss=6.5691, Acc=0.191, 
2025-10-11 18:57:44,966 - training.trainer - INFO - Epoch 17, Step 60710: Loss=6.1376, Acc=0.241, 
2025-10-11 18:57:54,512 - training.trainer - INFO - Epoch 17, Step 60810: Loss=5.1219, Acc=0.333, 
2025-10-11 18:58:15,867 - training.trainer - INFO - Epoch 18/100 completed in 332.35s - Train Loss: 5.7053, Train Acc: 0.248, Val Loss: 5.7972, Val Acc: 0.247
2025-10-11 18:58:16,992 - training.trainer - INFO - New best model saved with validation loss: 5.7972
2025-10-11 18:58:16,993 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-10-11 18:58:26,560 - training.trainer - INFO - Epoch 18, Step 60993: Loss=5.5882, Acc=0.200, 
2025-10-11 18:58:35,621 - training.trainer - INFO - Epoch 18, Step 61093: Loss=4.5832, Acc=0.238, 
2025-10-11 18:58:44,929 - training.trainer - INFO - Epoch 18, Step 61193: Loss=5.3137, Acc=0.273, 
2025-10-11 18:58:54,332 - training.trainer - INFO - Epoch 18, Step 61293: Loss=4.6151, Acc=0.286, 
2025-10-11 18:59:03,531 - training.trainer - INFO - Epoch 18, Step 61393: Loss=6.4175, Acc=0.175, 
2025-10-11 18:59:13,113 - training.trainer - INFO - Epoch 18, Step 61493: Loss=4.5891, Acc=0.565, 
2025-10-11 18:59:22,463 - training.trainer - INFO - Epoch 18, Step 61593: Loss=5.4320, Acc=0.308, 
2025-10-11 18:59:31,914 - training.trainer - INFO - Epoch 18, Step 61693: Loss=6.2142, Acc=0.137, 
2025-10-11 18:59:41,203 - training.trainer - INFO - Epoch 18, Step 61793: Loss=5.3264, Acc=0.263, 
2025-10-11 18:59:50,458 - training.trainer - INFO - Epoch 18, Step 61893: Loss=6.3024, Acc=0.204, 
2025-10-11 18:59:59,697 - training.trainer - INFO - Epoch 18, Step 61993: Loss=5.5327, Acc=0.286, 
2025-10-11 19:00:08,952 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.6520, Acc=0.162, 
2025-10-11 19:00:18,331 - training.trainer - INFO - Epoch 18, Step 62193: Loss=5.8752, Acc=0.375, 
2025-10-11 19:00:27,674 - training.trainer - INFO - Epoch 18, Step 62293: Loss=5.9213, Acc=0.267, 
2025-10-11 19:00:37,025 - training.trainer - INFO - Epoch 18, Step 62393: Loss=6.0230, Acc=0.188, 
2025-10-11 19:00:46,188 - training.trainer - INFO - Epoch 18, Step 62493: Loss=6.1540, Acc=0.237, 
2025-10-11 19:00:55,335 - training.trainer - INFO - Epoch 18, Step 62593: Loss=5.5327, Acc=0.234, 
2025-10-11 19:01:04,494 - training.trainer - INFO - Epoch 18, Step 62693: Loss=5.7959, Acc=0.200, 
2025-10-11 19:01:13,820 - training.trainer - INFO - Epoch 18, Step 62793: Loss=6.1957, Acc=0.160, 
2025-10-11 19:01:23,075 - training.trainer - INFO - Epoch 18, Step 62893: Loss=5.5448, Acc=0.125, 
2025-10-11 19:01:32,345 - training.trainer - INFO - Epoch 18, Step 62993: Loss=6.0683, Acc=0.179, 
2025-10-11 19:01:41,533 - training.trainer - INFO - Epoch 18, Step 63093: Loss=5.8282, Acc=0.261, 
2025-10-11 19:01:50,965 - training.trainer - INFO - Epoch 18, Step 63193: Loss=6.0784, Acc=0.245, 
2025-10-11 19:02:00,307 - training.trainer - INFO - Epoch 18, Step 63293: Loss=5.9185, Acc=0.234, 
2025-10-11 19:02:09,672 - training.trainer - INFO - Epoch 18, Step 63393: Loss=6.2946, Acc=0.206, 
2025-10-11 19:02:18,919 - training.trainer - INFO - Epoch 18, Step 63493: Loss=6.2233, Acc=0.353, 
2025-10-11 19:02:28,328 - training.trainer - INFO - Epoch 18, Step 63593: Loss=5.7475, Acc=0.281, 
2025-10-11 19:02:37,560 - training.trainer - INFO - Epoch 18, Step 63693: Loss=4.5547, Acc=0.381, 
2025-10-11 19:02:46,736 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.6691, Acc=0.217, 
2025-10-11 19:02:55,932 - training.trainer - INFO - Epoch 18, Step 63893: Loss=6.1804, Acc=0.149, 
2025-10-11 19:03:05,227 - training.trainer - INFO - Epoch 18, Step 63993: Loss=4.9337, Acc=0.385, 
2025-10-11 19:03:14,471 - training.trainer - INFO - Epoch 18, Step 64093: Loss=5.6292, Acc=0.214, 
2025-10-11 19:03:23,708 - training.trainer - INFO - Epoch 18, Step 64193: Loss=5.8935, Acc=0.140, 
2025-10-11 19:03:45,465 - training.trainer - INFO - Epoch 19/100 completed in 328.47s - Train Loss: 5.6899, Train Acc: 0.250, Val Loss: 5.8373, Val Acc: 0.250
2025-10-11 19:03:55,031 - training.trainer - INFO - Epoch 19, Step 64376: Loss=6.0864, Acc=0.205, 
2025-10-11 19:04:04,403 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.0952, Acc=0.250, 
2025-10-11 19:04:13,675 - training.trainer - INFO - Epoch 19, Step 64576: Loss=5.2551, Acc=0.267, 
2025-10-11 19:04:23,005 - training.trainer - INFO - Epoch 19, Step 64676: Loss=5.5329, Acc=0.281, 
2025-10-11 19:04:32,528 - training.trainer - INFO - Epoch 19, Step 64776: Loss=5.8420, Acc=0.189, 
2025-10-11 19:04:42,161 - training.trainer - INFO - Epoch 19, Step 64876: Loss=5.8597, Acc=0.231, 
2025-10-11 19:04:51,775 - training.trainer - INFO - Epoch 19, Step 64976: Loss=6.1088, Acc=0.238, 
2025-10-11 19:05:01,110 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.9607, Acc=0.235, 
2025-10-11 19:05:10,358 - training.trainer - INFO - Epoch 19, Step 65176: Loss=6.0850, Acc=0.208, 
2025-10-11 19:05:19,771 - training.trainer - INFO - Epoch 19, Step 65276: Loss=5.8984, Acc=0.214, 
2025-10-11 19:05:29,289 - training.trainer - INFO - Epoch 19, Step 65376: Loss=5.2699, Acc=0.297, 
2025-10-11 19:05:38,488 - training.trainer - INFO - Epoch 19, Step 65476: Loss=5.3583, Acc=0.281, 
2025-10-11 19:05:47,680 - training.trainer - INFO - Epoch 19, Step 65576: Loss=6.6211, Acc=0.188, 
2025-10-11 19:05:56,987 - training.trainer - INFO - Epoch 19, Step 65676: Loss=5.2385, Acc=0.259, 
2025-10-11 19:06:06,393 - training.trainer - INFO - Epoch 19, Step 65776: Loss=5.9279, Acc=0.326, 
2025-10-11 19:06:15,722 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.4087, Acc=0.214, 
2025-10-11 19:06:25,115 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.8953, Acc=0.238, 
2025-10-11 19:06:34,512 - training.trainer - INFO - Epoch 19, Step 66076: Loss=5.1801, Acc=0.238, 
2025-10-11 19:06:44,018 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.1924, Acc=0.318, 
2025-10-11 19:06:53,315 - training.trainer - INFO - Epoch 19, Step 66276: Loss=6.8729, Acc=0.162, 
2025-10-11 19:07:02,661 - training.trainer - INFO - Epoch 19, Step 66376: Loss=6.3041, Acc=0.185, 
2025-10-11 19:07:12,037 - training.trainer - INFO - Epoch 19, Step 66476: Loss=6.2067, Acc=0.280, 
2025-10-11 19:07:21,289 - training.trainer - INFO - Epoch 19, Step 66576: Loss=6.1472, Acc=0.255, 
2025-10-11 19:07:30,517 - training.trainer - INFO - Epoch 19, Step 66676: Loss=6.0957, Acc=0.177, 
2025-10-11 19:07:39,947 - training.trainer - INFO - Epoch 19, Step 66776: Loss=6.7405, Acc=0.194, 
2025-10-11 19:07:49,311 - training.trainer - INFO - Epoch 19, Step 66876: Loss=6.2225, Acc=0.182, 
2025-10-11 19:07:58,651 - training.trainer - INFO - Epoch 19, Step 66976: Loss=6.3493, Acc=0.143, 
2025-10-11 19:08:07,946 - training.trainer - INFO - Epoch 19, Step 67076: Loss=6.0463, Acc=0.229, 
2025-10-11 19:08:17,224 - training.trainer - INFO - Epoch 19, Step 67176: Loss=3.9022, Acc=0.400, 
2025-10-11 19:08:26,506 - training.trainer - INFO - Epoch 19, Step 67276: Loss=6.7602, Acc=0.182, 
2025-10-11 19:08:35,919 - training.trainer - INFO - Epoch 19, Step 67376: Loss=5.8199, Acc=0.205, 
2025-10-11 19:08:45,091 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.0698, Acc=0.280, 
2025-10-11 19:08:54,568 - training.trainer - INFO - Epoch 19, Step 67576: Loss=5.4748, Acc=0.385, 
2025-10-11 19:09:15,705 - training.trainer - INFO - Epoch 20/100 completed in 330.24s - Train Loss: 5.6722, Train Acc: 0.253, Val Loss: 5.7753, Val Acc: 0.250
2025-10-11 19:09:16,134 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-11 19:09:16,952 - training.trainer - INFO - New best model saved with validation loss: 5.7753
2025-10-11 19:09:16,952 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-11 19:09:26,380 - training.trainer - INFO - Epoch 20, Step 67759: Loss=5.9544, Acc=0.247, 
2025-10-11 19:09:35,560 - training.trainer - INFO - Epoch 20, Step 67859: Loss=3.7093, Acc=0.471, 
2025-10-11 19:09:44,883 - training.trainer - INFO - Epoch 20, Step 67959: Loss=5.3539, Acc=0.238, 
2025-10-11 19:09:54,308 - training.trainer - INFO - Epoch 20, Step 68059: Loss=6.4649, Acc=0.220, 
2025-10-11 19:10:03,875 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.4724, Acc=0.300, 
2025-10-11 19:10:13,033 - training.trainer - INFO - Epoch 20, Step 68259: Loss=6.1098, Acc=0.192, 
2025-10-11 19:10:22,412 - training.trainer - INFO - Epoch 20, Step 68359: Loss=5.8100, Acc=0.222, 
2025-10-11 19:10:31,777 - training.trainer - INFO - Epoch 20, Step 68459: Loss=6.5507, Acc=0.213, 
2025-10-11 19:10:40,940 - training.trainer - INFO - Epoch 20, Step 68559: Loss=6.4351, Acc=0.157, 
2025-10-11 19:10:50,107 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.2448, Acc=0.349, 
2025-10-11 19:10:59,288 - training.trainer - INFO - Epoch 20, Step 68759: Loss=6.5072, Acc=0.229, 
2025-10-11 19:11:08,495 - training.trainer - INFO - Epoch 20, Step 68859: Loss=6.0873, Acc=0.150, 
2025-10-11 19:11:17,678 - training.trainer - INFO - Epoch 20, Step 68959: Loss=6.1039, Acc=0.234, 
2025-10-11 19:11:26,821 - training.trainer - INFO - Epoch 20, Step 69059: Loss=6.2901, Acc=0.196, 
2025-10-11 19:11:36,120 - training.trainer - INFO - Epoch 20, Step 69159: Loss=4.8893, Acc=0.421, 
2025-10-11 19:11:45,276 - training.trainer - INFO - Epoch 20, Step 69259: Loss=5.9885, Acc=0.167, 
2025-10-11 19:11:54,437 - training.trainer - INFO - Epoch 20, Step 69359: Loss=6.5181, Acc=0.161, 
2025-10-11 19:12:03,903 - training.trainer - INFO - Epoch 20, Step 69459: Loss=6.5835, Acc=0.196, 
2025-10-11 19:12:13,221 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.7595, Acc=0.300, 
2025-10-11 19:12:22,380 - training.trainer - INFO - Epoch 20, Step 69659: Loss=6.2801, Acc=0.136, 
2025-10-11 19:12:31,537 - training.trainer - INFO - Epoch 20, Step 69759: Loss=5.1328, Acc=0.385, 
2025-10-11 19:12:40,730 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.1955, Acc=0.217, 
2025-10-11 19:12:49,944 - training.trainer - INFO - Epoch 20, Step 69959: Loss=6.2293, Acc=0.250, 
2025-10-11 19:12:59,121 - training.trainer - INFO - Epoch 20, Step 70059: Loss=6.2922, Acc=0.111, 
2025-10-11 19:13:08,353 - training.trainer - INFO - Epoch 20, Step 70159: Loss=6.7008, Acc=0.227, 
2025-10-11 19:13:17,577 - training.trainer - INFO - Epoch 20, Step 70259: Loss=5.9322, Acc=0.193, 
2025-10-11 19:13:26,769 - training.trainer - INFO - Epoch 20, Step 70359: Loss=4.5564, Acc=0.444, 
2025-10-11 19:13:35,972 - training.trainer - INFO - Epoch 20, Step 70459: Loss=6.2575, Acc=0.184, 
2025-10-11 19:13:45,201 - training.trainer - INFO - Epoch 20, Step 70559: Loss=4.8023, Acc=0.364, 
2025-10-11 19:13:54,416 - training.trainer - INFO - Epoch 20, Step 70659: Loss=5.2635, Acc=0.444, 
2025-10-11 19:14:03,602 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.5677, Acc=0.209, 
2025-10-11 19:14:12,843 - training.trainer - INFO - Epoch 20, Step 70859: Loss=4.3656, Acc=0.429, 
2025-10-11 19:14:22,172 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.6217, Acc=0.259, 
2025-10-11 19:14:43,722 - training.trainer - INFO - Epoch 21/100 completed in 326.77s - Train Loss: 5.6563, Train Acc: 0.255, Val Loss: 5.7736, Val Acc: 0.252
2025-10-11 19:14:44,631 - training.trainer - INFO - New best model saved with validation loss: 5.7736
2025-10-11 19:14:44,631 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_21.pt
2025-10-11 19:14:53,226 - training.trainer - INFO - Epoch 21, Step 71142: Loss=4.9307, Acc=0.353, 
2025-10-11 19:15:01,127 - training.trainer - INFO - Epoch 21, Step 71242: Loss=4.0884, Acc=0.583, 
2025-10-11 19:15:09,984 - training.trainer - INFO - Epoch 21, Step 71342: Loss=2.3932, Acc=0.864, 
2025-10-11 19:15:19,083 - training.trainer - INFO - Epoch 21, Step 71442: Loss=4.6740, Acc=0.375, 
2025-10-11 19:15:27,397 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.0196, Acc=0.238, 
2025-10-11 19:15:35,340 - training.trainer - INFO - Epoch 21, Step 71642: Loss=5.8714, Acc=0.172, 
2025-10-11 19:15:43,954 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.7063, Acc=0.239, 
2025-10-11 19:15:53,110 - training.trainer - INFO - Epoch 21, Step 71842: Loss=5.3700, Acc=0.282, 
2025-10-11 19:16:01,802 - training.trainer - INFO - Epoch 21, Step 71942: Loss=6.2971, Acc=0.333, 
2025-10-11 19:16:10,661 - training.trainer - INFO - Epoch 21, Step 72042: Loss=5.9373, Acc=0.281, 
2025-10-11 19:16:20,233 - training.trainer - INFO - Epoch 21, Step 72142: Loss=5.1510, Acc=0.382, 
2025-10-11 19:16:29,590 - training.trainer - INFO - Epoch 21, Step 72242: Loss=6.2637, Acc=0.167, 
2025-10-11 19:16:38,966 - training.trainer - INFO - Epoch 21, Step 72342: Loss=4.8967, Acc=0.379, 
2025-10-11 19:16:48,493 - training.trainer - INFO - Epoch 21, Step 72442: Loss=6.4039, Acc=0.144, 
2025-10-11 19:16:58,241 - training.trainer - INFO - Epoch 21, Step 72542: Loss=5.5043, Acc=0.186, 
2025-10-11 19:17:07,500 - training.trainer - INFO - Epoch 21, Step 72642: Loss=5.3383, Acc=0.349, 
2025-10-11 19:17:17,024 - training.trainer - INFO - Epoch 21, Step 72742: Loss=5.8434, Acc=0.200, 
2025-10-11 19:17:26,597 - training.trainer - INFO - Epoch 21, Step 72842: Loss=5.6459, Acc=0.279, 
2025-10-11 19:17:35,913 - training.trainer - INFO - Epoch 21, Step 72942: Loss=5.0442, Acc=0.370, 
2025-10-11 19:17:45,192 - training.trainer - INFO - Epoch 21, Step 73042: Loss=3.7266, Acc=0.450, 
2025-10-11 19:17:54,502 - training.trainer - INFO - Epoch 21, Step 73142: Loss=5.8029, Acc=0.208, 
2025-10-11 19:18:03,854 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.6885, Acc=0.263, 
2025-10-11 19:18:13,134 - training.trainer - INFO - Epoch 21, Step 73342: Loss=6.2948, Acc=0.146, 
2025-10-11 19:18:22,423 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.6498, Acc=0.250, 
2025-10-11 19:18:31,930 - training.trainer - INFO - Epoch 21, Step 73542: Loss=6.2788, Acc=0.188, 
2025-10-11 19:18:41,315 - training.trainer - INFO - Epoch 21, Step 73642: Loss=5.7505, Acc=0.211, 
2025-10-11 19:18:50,510 - training.trainer - INFO - Epoch 21, Step 73742: Loss=6.3365, Acc=0.119, 
2025-10-11 19:18:59,695 - training.trainer - INFO - Epoch 21, Step 73842: Loss=5.2199, Acc=0.250, 
2025-10-11 19:19:08,878 - training.trainer - INFO - Epoch 21, Step 73942: Loss=5.2498, Acc=0.248, 
2025-10-11 19:19:18,356 - training.trainer - INFO - Epoch 21, Step 74042: Loss=6.1348, Acc=0.261, 
2025-10-11 19:19:27,851 - training.trainer - INFO - Epoch 21, Step 74142: Loss=6.4837, Acc=0.157, 
2025-10-11 19:19:37,422 - training.trainer - INFO - Epoch 21, Step 74242: Loss=4.4545, Acc=0.385, 
2025-10-11 19:19:46,905 - training.trainer - INFO - Epoch 21, Step 74342: Loss=5.9923, Acc=0.205, 
2025-10-11 19:20:07,624 - training.trainer - INFO - Epoch 22/100 completed in 322.99s - Train Loss: 5.6360, Train Acc: 0.257, Val Loss: 5.7479, Val Acc: 0.253
2025-10-11 19:20:08,444 - training.trainer - INFO - New best model saved with validation loss: 5.7479
2025-10-11 19:20:08,444 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_22.pt
2025-10-11 19:20:17,793 - training.trainer - INFO - Epoch 22, Step 74525: Loss=5.4347, Acc=0.172, 
2025-10-11 19:20:26,699 - training.trainer - INFO - Epoch 22, Step 74625: Loss=6.9979, Acc=0.179, 
2025-10-11 19:20:35,546 - training.trainer - INFO - Epoch 22, Step 74725: Loss=5.7129, Acc=0.200, 
2025-10-11 19:20:44,749 - training.trainer - INFO - Epoch 22, Step 74825: Loss=5.3002, Acc=0.276, 
2025-10-11 19:20:54,031 - training.trainer - INFO - Epoch 22, Step 74925: Loss=3.6449, Acc=0.556, 
2025-10-11 19:21:03,298 - training.trainer - INFO - Epoch 22, Step 75025: Loss=4.5058, Acc=0.391, 
2025-10-11 19:21:12,556 - training.trainer - INFO - Epoch 22, Step 75125: Loss=5.9448, Acc=0.200, 
2025-10-11 19:21:22,124 - training.trainer - INFO - Epoch 22, Step 75225: Loss=5.4797, Acc=0.242, 
2025-10-11 19:21:31,672 - training.trainer - INFO - Epoch 22, Step 75325: Loss=5.5524, Acc=0.224, 
2025-10-11 19:21:40,965 - training.trainer - INFO - Epoch 22, Step 75425: Loss=5.2384, Acc=0.190, 
2025-10-11 19:21:50,418 - training.trainer - INFO - Epoch 22, Step 75525: Loss=5.6595, Acc=0.147, 
2025-10-11 19:21:59,711 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.5116, Acc=0.215, 
2025-10-11 19:22:08,926 - training.trainer - INFO - Epoch 22, Step 75725: Loss=6.1944, Acc=0.239, 
2025-10-11 19:22:18,127 - training.trainer - INFO - Epoch 22, Step 75825: Loss=5.4250, Acc=0.318, 
2025-10-11 19:22:27,427 - training.trainer - INFO - Epoch 22, Step 75925: Loss=5.5278, Acc=0.276, 
2025-10-11 19:22:36,788 - training.trainer - INFO - Epoch 22, Step 76025: Loss=6.1761, Acc=0.154, 
2025-10-11 19:22:46,087 - training.trainer - INFO - Epoch 22, Step 76125: Loss=4.7708, Acc=0.333, 
2025-10-11 19:22:55,283 - training.trainer - INFO - Epoch 22, Step 76225: Loss=5.5715, Acc=0.324, 
2025-10-11 19:23:04,515 - training.trainer - INFO - Epoch 22, Step 76325: Loss=5.5901, Acc=0.200, 
2025-10-11 19:23:13,644 - training.trainer - INFO - Epoch 22, Step 76425: Loss=5.9766, Acc=0.156, 
2025-10-11 19:23:22,776 - training.trainer - INFO - Epoch 22, Step 76525: Loss=5.1313, Acc=0.343, 
2025-10-11 19:23:31,882 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.0566, Acc=0.172, 
2025-10-11 19:23:40,928 - training.trainer - INFO - Epoch 22, Step 76725: Loss=5.6683, Acc=0.192, 
2025-10-11 19:23:50,151 - training.trainer - INFO - Epoch 22, Step 76825: Loss=6.4461, Acc=0.179, 
2025-10-11 19:23:59,244 - training.trainer - INFO - Epoch 22, Step 76925: Loss=5.9073, Acc=0.208, 
2025-10-11 19:24:08,480 - training.trainer - INFO - Epoch 22, Step 77025: Loss=6.0207, Acc=0.205, 
2025-10-11 19:24:17,747 - training.trainer - INFO - Epoch 22, Step 77125: Loss=5.0969, Acc=0.455, 
2025-10-11 19:24:26,969 - training.trainer - INFO - Epoch 22, Step 77225: Loss=5.3072, Acc=0.220, 
2025-10-11 19:24:36,127 - training.trainer - INFO - Epoch 22, Step 77325: Loss=6.0354, Acc=0.220, 
2025-10-11 19:24:45,271 - training.trainer - INFO - Epoch 22, Step 77425: Loss=5.3723, Acc=0.379, 
2025-10-11 19:24:54,355 - training.trainer - INFO - Epoch 22, Step 77525: Loss=5.7813, Acc=0.208, 
2025-10-11 19:25:03,538 - training.trainer - INFO - Epoch 22, Step 77625: Loss=5.9852, Acc=0.235, 
2025-10-11 19:25:12,816 - training.trainer - INFO - Epoch 22, Step 77725: Loss=5.9787, Acc=0.182, 
2025-10-11 19:25:33,870 - training.trainer - INFO - Epoch 23/100 completed in 325.43s - Train Loss: 5.6197, Train Acc: 0.261, Val Loss: 5.7573, Val Acc: 0.254
2025-10-11 19:25:43,354 - training.trainer - INFO - Epoch 23, Step 77908: Loss=5.9414, Acc=0.120, 
2025-10-11 19:25:52,566 - training.trainer - INFO - Epoch 23, Step 78008: Loss=5.9455, Acc=0.182, 
2025-10-11 19:26:01,722 - training.trainer - INFO - Epoch 23, Step 78108: Loss=6.5012, Acc=0.156, 
2025-10-11 19:26:10,920 - training.trainer - INFO - Epoch 23, Step 78208: Loss=5.2026, Acc=0.240, 
2025-10-11 19:26:20,067 - training.trainer - INFO - Epoch 23, Step 78308: Loss=4.0590, Acc=0.412, 
2025-10-11 19:26:29,256 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.7717, Acc=0.238, 
2025-10-11 19:26:38,410 - training.trainer - INFO - Epoch 23, Step 78508: Loss=6.1476, Acc=0.175, 
2025-10-11 19:26:47,537 - training.trainer - INFO - Epoch 23, Step 78608: Loss=5.5808, Acc=0.212, 
2025-10-11 19:26:56,667 - training.trainer - INFO - Epoch 23, Step 78708: Loss=6.0754, Acc=0.207, 
2025-10-11 19:27:05,984 - training.trainer - INFO - Epoch 23, Step 78808: Loss=5.8812, Acc=0.308, 
2025-10-11 19:27:15,139 - training.trainer - INFO - Epoch 23, Step 78908: Loss=6.1506, Acc=0.176, 
2025-10-11 19:27:24,295 - training.trainer - INFO - Epoch 23, Step 79008: Loss=6.1924, Acc=0.208, 
2025-10-11 19:27:33,679 - training.trainer - INFO - Epoch 23, Step 79108: Loss=6.5062, Acc=0.143, 
2025-10-11 19:27:43,195 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.7188, Acc=0.250, 
2025-10-11 19:27:52,622 - training.trainer - INFO - Epoch 23, Step 79308: Loss=2.6317, Acc=0.750, 
2025-10-11 19:28:01,844 - training.trainer - INFO - Epoch 23, Step 79408: Loss=5.9646, Acc=0.278, 
2025-10-11 19:28:11,047 - training.trainer - INFO - Epoch 23, Step 79508: Loss=5.8269, Acc=0.265, 
2025-10-11 19:28:20,532 - training.trainer - INFO - Epoch 23, Step 79608: Loss=4.6261, Acc=0.425, 
2025-10-11 19:28:29,758 - training.trainer - INFO - Epoch 23, Step 79708: Loss=6.1804, Acc=0.156, 
2025-10-11 19:28:38,934 - training.trainer - INFO - Epoch 23, Step 79808: Loss=5.5716, Acc=0.286, 
2025-10-11 19:28:48,210 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.4521, Acc=0.308, 
2025-10-11 19:28:57,424 - training.trainer - INFO - Epoch 23, Step 80008: Loss=6.2373, Acc=0.212, 
2025-10-11 19:29:06,751 - training.trainer - INFO - Epoch 23, Step 80108: Loss=5.7468, Acc=0.279, 
2025-10-11 19:29:16,232 - training.trainer - INFO - Epoch 23, Step 80208: Loss=3.3372, Acc=0.417, 
2025-10-11 19:29:25,706 - training.trainer - INFO - Epoch 23, Step 80308: Loss=5.2761, Acc=0.238, 
2025-10-11 19:29:35,102 - training.trainer - INFO - Epoch 23, Step 80408: Loss=5.6093, Acc=0.274, 
2025-10-11 19:29:44,493 - training.trainer - INFO - Epoch 23, Step 80508: Loss=6.4040, Acc=0.157, 
2025-10-11 19:29:53,986 - training.trainer - INFO - Epoch 23, Step 80608: Loss=5.0120, Acc=0.286, 
2025-10-11 19:30:03,442 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.2933, Acc=0.368, 
2025-10-11 19:30:12,955 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.7726, Acc=0.232, 
2025-10-11 19:30:22,519 - training.trainer - INFO - Epoch 23, Step 80908: Loss=5.9889, Acc=0.182, 
2025-10-11 19:30:31,972 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.7868, Acc=0.262, 
2025-10-11 19:30:41,331 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.4567, Acc=0.316, 
2025-10-11 19:31:02,446 - training.trainer - INFO - Epoch 24/100 completed in 328.58s - Train Loss: 5.5990, Train Acc: 0.264, Val Loss: 5.7313, Val Acc: 0.254
2025-10-11 19:31:03,188 - training.trainer - INFO - New best model saved with validation loss: 5.7313
2025-10-11 19:31:03,188 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-10-11 19:31:12,386 - training.trainer - INFO - Epoch 24, Step 81291: Loss=5.9141, Acc=0.240, 
2025-10-11 19:31:21,399 - training.trainer - INFO - Epoch 24, Step 81391: Loss=6.3021, Acc=0.167, 
2025-10-11 19:31:30,720 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.9515, Acc=0.148, 
2025-10-11 19:31:40,286 - training.trainer - INFO - Epoch 24, Step 81591: Loss=6.7358, Acc=0.114, 
2025-10-11 19:31:49,732 - training.trainer - INFO - Epoch 24, Step 81691: Loss=4.6267, Acc=0.400, 
2025-10-11 19:31:59,066 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.4126, Acc=0.276, 
2025-10-11 19:32:08,487 - training.trainer - INFO - Epoch 24, Step 81891: Loss=5.6633, Acc=0.308, 
2025-10-11 19:32:17,821 - training.trainer - INFO - Epoch 24, Step 81991: Loss=6.3103, Acc=0.129, 
2025-10-11 19:32:27,054 - training.trainer - INFO - Epoch 24, Step 82091: Loss=6.0070, Acc=0.235, 
2025-10-11 19:32:36,385 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.7897, Acc=0.268, 
2025-10-11 19:32:45,553 - training.trainer - INFO - Epoch 24, Step 82291: Loss=4.7432, Acc=0.417, 
2025-10-11 19:32:54,845 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.8937, Acc=0.245, 
2025-10-11 19:33:04,307 - training.trainer - INFO - Epoch 24, Step 82491: Loss=4.8272, Acc=0.293, 
2025-10-11 19:33:13,613 - training.trainer - INFO - Epoch 24, Step 82591: Loss=6.1319, Acc=0.182, 
2025-10-11 19:33:22,807 - training.trainer - INFO - Epoch 24, Step 82691: Loss=6.1728, Acc=0.250, 
2025-10-11 19:33:31,969 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.3551, Acc=0.333, 
2025-10-11 19:33:41,150 - training.trainer - INFO - Epoch 24, Step 82891: Loss=6.0591, Acc=0.273, 
2025-10-11 19:33:50,443 - training.trainer - INFO - Epoch 24, Step 82991: Loss=5.1635, Acc=0.326, 
2025-10-11 19:33:59,866 - training.trainer - INFO - Epoch 24, Step 83091: Loss=5.2402, Acc=0.281, 
2025-10-11 19:34:09,082 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.1085, Acc=0.375, 
2025-10-11 19:34:18,466 - training.trainer - INFO - Epoch 24, Step 83291: Loss=4.9543, Acc=0.205, 
2025-10-11 19:34:27,892 - training.trainer - INFO - Epoch 24, Step 83391: Loss=5.6213, Acc=0.262, 
2025-10-11 19:34:37,006 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.7439, Acc=0.238, 
2025-10-11 19:34:46,153 - training.trainer - INFO - Epoch 24, Step 83591: Loss=4.7308, Acc=0.280, 
2025-10-11 19:34:55,350 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.9683, Acc=0.183, 
2025-10-11 19:35:04,530 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.4896, Acc=0.240, 
2025-10-11 19:35:13,671 - training.trainer - INFO - Epoch 24, Step 83891: Loss=5.4131, Acc=0.314, 
2025-10-11 19:35:22,788 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.1268, Acc=0.297, 
2025-10-11 19:35:32,018 - training.trainer - INFO - Epoch 24, Step 84091: Loss=5.8504, Acc=0.139, 
2025-10-11 19:35:41,245 - training.trainer - INFO - Epoch 24, Step 84191: Loss=5.8134, Acc=0.280, 
2025-10-11 19:35:50,558 - training.trainer - INFO - Epoch 24, Step 84291: Loss=5.5914, Acc=0.200, 
2025-10-11 19:36:00,039 - training.trainer - INFO - Epoch 24, Step 84391: Loss=6.6990, Acc=0.400, 
2025-10-11 19:36:09,493 - training.trainer - INFO - Epoch 24, Step 84491: Loss=5.9450, Acc=0.243, 
2025-10-11 19:36:30,770 - training.trainer - INFO - Epoch 25/100 completed in 327.58s - Train Loss: 5.5933, Train Acc: 0.265, Val Loss: 5.7510, Val Acc: 0.253
2025-10-11 19:36:31,224 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-11 19:36:40,923 - training.trainer - INFO - Epoch 25, Step 84674: Loss=4.9519, Acc=0.367, 
2025-10-11 19:36:50,268 - training.trainer - INFO - Epoch 25, Step 84774: Loss=5.1291, Acc=0.333, 
2025-10-11 19:36:59,550 - training.trainer - INFO - Epoch 25, Step 84874: Loss=5.7989, Acc=0.300, 
2025-10-11 19:37:08,801 - training.trainer - INFO - Epoch 25, Step 84974: Loss=5.7559, Acc=0.281, 
2025-10-11 19:37:18,180 - training.trainer - INFO - Epoch 25, Step 85074: Loss=6.2162, Acc=0.240, 
2025-10-11 19:37:27,372 - training.trainer - INFO - Epoch 25, Step 85174: Loss=5.6159, Acc=0.269, 
2025-10-11 19:37:36,904 - training.trainer - INFO - Epoch 25, Step 85274: Loss=5.3903, Acc=0.286, 
2025-10-11 19:37:46,498 - training.trainer - INFO - Epoch 25, Step 85374: Loss=5.3483, Acc=0.212, 
2025-10-11 19:37:55,933 - training.trainer - INFO - Epoch 25, Step 85474: Loss=6.0464, Acc=0.208, 
2025-10-11 19:38:05,349 - training.trainer - INFO - Epoch 25, Step 85574: Loss=4.5822, Acc=0.364, 
2025-10-11 19:38:14,683 - training.trainer - INFO - Epoch 25, Step 85674: Loss=6.0677, Acc=0.193, 
2025-10-11 19:38:24,018 - training.trainer - INFO - Epoch 25, Step 85774: Loss=5.0867, Acc=0.327, 
2025-10-11 19:38:33,452 - training.trainer - INFO - Epoch 25, Step 85874: Loss=5.3397, Acc=0.241, 
2025-10-11 19:38:42,916 - training.trainer - INFO - Epoch 25, Step 85974: Loss=6.0307, Acc=0.190, 
2025-10-11 19:38:52,401 - training.trainer - INFO - Epoch 25, Step 86074: Loss=4.6685, Acc=0.382, 
2025-10-11 19:39:01,857 - training.trainer - INFO - Epoch 25, Step 86174: Loss=5.4655, Acc=0.189, 
2025-10-11 19:39:11,352 - training.trainer - INFO - Epoch 25, Step 86274: Loss=4.6250, Acc=0.348, 
2025-10-11 19:39:20,881 - training.trainer - INFO - Epoch 25, Step 86374: Loss=5.4090, Acc=0.341, 
2025-10-11 19:39:30,325 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.0048, Acc=0.357, 
2025-10-11 19:39:39,717 - training.trainer - INFO - Epoch 25, Step 86574: Loss=6.7163, Acc=0.259, 
2025-10-11 19:39:49,220 - training.trainer - INFO - Epoch 25, Step 86674: Loss=6.0921, Acc=0.217, 
2025-10-11 19:39:58,367 - training.trainer - INFO - Epoch 25, Step 86774: Loss=6.1084, Acc=0.149, 
2025-10-11 19:40:07,519 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.0925, Acc=0.255, 
2025-10-11 19:40:16,627 - training.trainer - INFO - Epoch 25, Step 86974: Loss=5.9631, Acc=0.255, 
2025-10-11 19:40:25,834 - training.trainer - INFO - Epoch 25, Step 87074: Loss=6.0263, Acc=0.152, 
2025-10-11 19:40:35,023 - training.trainer - INFO - Epoch 25, Step 87174: Loss=6.1653, Acc=0.190, 
2025-10-11 19:40:44,369 - training.trainer - INFO - Epoch 25, Step 87274: Loss=3.9577, Acc=0.375, 
2025-10-11 19:40:53,596 - training.trainer - INFO - Epoch 25, Step 87374: Loss=5.6240, Acc=0.235, 
2025-10-11 19:41:02,853 - training.trainer - INFO - Epoch 25, Step 87474: Loss=5.2835, Acc=0.257, 
2025-10-11 19:41:12,066 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.6594, Acc=0.271, 
2025-10-11 19:41:21,234 - training.trainer - INFO - Epoch 25, Step 87674: Loss=4.0789, Acc=0.353, 
2025-10-11 19:41:30,399 - training.trainer - INFO - Epoch 25, Step 87774: Loss=6.2379, Acc=0.263, 
2025-10-11 19:41:39,602 - training.trainer - INFO - Epoch 25, Step 87874: Loss=5.6364, Acc=0.188, 
2025-10-11 19:42:01,572 - training.trainer - INFO - Epoch 26/100 completed in 330.35s - Train Loss: 5.5738, Train Acc: 0.267, Val Loss: 5.7595, Val Acc: 0.254
2025-10-11 19:42:11,454 - training.trainer - INFO - Epoch 26, Step 88057: Loss=5.9938, Acc=0.167, 
2025-10-11 19:42:20,799 - training.trainer - INFO - Epoch 26, Step 88157: Loss=5.1724, Acc=0.237, 
2025-10-11 19:42:30,108 - training.trainer - INFO - Epoch 26, Step 88257: Loss=4.7768, Acc=0.323, 
2025-10-11 19:42:39,531 - training.trainer - INFO - Epoch 26, Step 88357: Loss=6.9164, Acc=0.125, 
2025-10-11 19:42:48,762 - training.trainer - INFO - Epoch 26, Step 88457: Loss=6.6236, Acc=0.186, 
2025-10-11 19:42:57,918 - training.trainer - INFO - Epoch 26, Step 88557: Loss=6.3473, Acc=0.190, 
2025-10-11 19:43:07,095 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.3567, Acc=0.308, 
2025-10-11 19:43:16,334 - training.trainer - INFO - Epoch 26, Step 88757: Loss=5.4043, Acc=0.267, 
2025-10-11 19:43:25,509 - training.trainer - INFO - Epoch 26, Step 88857: Loss=5.3021, Acc=0.286, 
2025-10-11 19:43:34,659 - training.trainer - INFO - Epoch 26, Step 88957: Loss=5.6365, Acc=0.242, 
2025-10-11 19:43:43,873 - training.trainer - INFO - Epoch 26, Step 89057: Loss=4.9810, Acc=0.310, 
2025-10-11 19:43:53,136 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.7952, Acc=0.219, 
2025-10-11 19:44:02,240 - training.trainer - INFO - Epoch 26, Step 89257: Loss=4.7529, Acc=0.476, 
2025-10-11 19:44:11,396 - training.trainer - INFO - Epoch 26, Step 89357: Loss=5.9068, Acc=0.191, 
2025-10-11 19:44:20,567 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.8952, Acc=0.265, 
2025-10-11 19:44:29,953 - training.trainer - INFO - Epoch 26, Step 89557: Loss=6.0887, Acc=0.295, 
2025-10-11 19:44:39,147 - training.trainer - INFO - Epoch 26, Step 89657: Loss=5.5203, Acc=0.160, 
2025-10-11 19:44:48,304 - training.trainer - INFO - Epoch 26, Step 89757: Loss=5.6196, Acc=0.256, 
2025-10-11 19:44:57,596 - training.trainer - INFO - Epoch 26, Step 89857: Loss=5.1110, Acc=0.250, 
2025-10-11 19:45:06,806 - training.trainer - INFO - Epoch 26, Step 89957: Loss=5.1637, Acc=0.290, 
2025-10-11 19:45:15,955 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.4144, Acc=0.308, 
2025-10-11 19:45:25,388 - training.trainer - INFO - Epoch 26, Step 90157: Loss=6.3104, Acc=0.229, 
2025-10-11 19:45:34,715 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.7414, Acc=0.269, 
2025-10-11 19:45:43,920 - training.trainer - INFO - Epoch 26, Step 90357: Loss=5.1564, Acc=0.306, 
2025-10-11 19:45:53,121 - training.trainer - INFO - Epoch 26, Step 90457: Loss=5.4417, Acc=0.333, 
2025-10-11 19:46:02,436 - training.trainer - INFO - Epoch 26, Step 90557: Loss=6.0536, Acc=0.186, 
2025-10-11 19:46:11,823 - training.trainer - INFO - Epoch 26, Step 90657: Loss=5.9582, Acc=0.186, 
2025-10-11 19:46:21,224 - training.trainer - INFO - Epoch 26, Step 90757: Loss=5.9164, Acc=0.258, 
2025-10-11 19:46:30,704 - training.trainer - INFO - Epoch 26, Step 90857: Loss=5.3804, Acc=0.222, 
2025-10-11 19:46:40,104 - training.trainer - INFO - Epoch 26, Step 90957: Loss=5.6177, Acc=0.280, 
2025-10-11 19:46:49,477 - training.trainer - INFO - Epoch 26, Step 91057: Loss=5.1703, Acc=0.423, 
2025-10-11 19:46:59,246 - training.trainer - INFO - Epoch 26, Step 91157: Loss=4.3935, Acc=0.250, 
2025-10-11 19:47:08,587 - training.trainer - INFO - Epoch 26, Step 91257: Loss=5.8095, Acc=0.238, 
2025-10-11 19:47:29,722 - training.trainer - INFO - Epoch 27/100 completed in 328.15s - Train Loss: 5.5584, Train Acc: 0.270, Val Loss: 5.7400, Val Acc: 0.255
2025-10-11 19:47:39,109 - training.trainer - INFO - Epoch 27, Step 91440: Loss=4.3372, Acc=0.348, 
2025-10-11 19:47:48,431 - training.trainer - INFO - Epoch 27, Step 91540: Loss=6.3135, Acc=0.219, 
2025-10-11 19:47:57,506 - training.trainer - INFO - Epoch 27, Step 91640: Loss=4.9631, Acc=0.298, 
2025-10-11 19:48:06,696 - training.trainer - INFO - Epoch 27, Step 91740: Loss=6.5776, Acc=0.164, 
2025-10-11 19:48:15,839 - training.trainer - INFO - Epoch 27, Step 91840: Loss=5.9756, Acc=0.205, 
2025-10-11 19:48:25,120 - training.trainer - INFO - Epoch 27, Step 91940: Loss=4.2915, Acc=0.545, 
2025-10-11 19:48:34,240 - training.trainer - INFO - Epoch 27, Step 92040: Loss=5.2048, Acc=0.290, 
2025-10-11 19:48:43,510 - training.trainer - INFO - Epoch 27, Step 92140: Loss=5.7791, Acc=0.276, 
2025-10-11 19:48:52,648 - training.trainer - INFO - Epoch 27, Step 92240: Loss=6.5472, Acc=0.170, 
2025-10-11 19:49:01,857 - training.trainer - INFO - Epoch 27, Step 92340: Loss=6.1742, Acc=0.204, 
2025-10-11 19:49:11,025 - training.trainer - INFO - Epoch 27, Step 92440: Loss=5.3667, Acc=0.400, 
2025-10-11 19:49:20,150 - training.trainer - INFO - Epoch 27, Step 92540: Loss=4.6228, Acc=0.308, 
2025-10-11 19:49:29,288 - training.trainer - INFO - Epoch 27, Step 92640: Loss=4.6665, Acc=0.423, 
2025-10-11 19:49:38,537 - training.trainer - INFO - Epoch 27, Step 92740: Loss=6.0643, Acc=0.205, 
2025-10-11 19:49:47,696 - training.trainer - INFO - Epoch 27, Step 92840: Loss=4.8792, Acc=0.339, 
2025-10-11 19:49:56,800 - training.trainer - INFO - Epoch 27, Step 92940: Loss=6.0654, Acc=0.225, 
2025-10-11 19:50:06,071 - training.trainer - INFO - Epoch 27, Step 93040: Loss=6.4932, Acc=0.190, 
2025-10-11 19:50:15,258 - training.trainer - INFO - Epoch 27, Step 93140: Loss=5.6026, Acc=0.226, 
2025-10-11 19:50:24,515 - training.trainer - INFO - Epoch 27, Step 93240: Loss=5.4548, Acc=0.133, 
2025-10-11 19:50:33,658 - training.trainer - INFO - Epoch 27, Step 93340: Loss=5.0752, Acc=0.281, 
2025-10-11 19:50:42,925 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.2956, Acc=0.206, 
2025-10-11 19:50:52,161 - training.trainer - INFO - Epoch 27, Step 93540: Loss=4.7695, Acc=0.273, 
2025-10-11 19:51:01,327 - training.trainer - INFO - Epoch 27, Step 93640: Loss=4.2747, Acc=0.357, 
2025-10-11 19:51:10,539 - training.trainer - INFO - Epoch 27, Step 93740: Loss=2.6136, Acc=0.615, 
2025-10-11 19:51:19,864 - training.trainer - INFO - Epoch 27, Step 93840: Loss=5.4230, Acc=0.237, 
2025-10-11 19:51:29,037 - training.trainer - INFO - Epoch 27, Step 93940: Loss=3.8868, Acc=0.552, 
2025-10-11 19:51:38,185 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.5448, Acc=0.360, 
2025-10-11 19:51:47,418 - training.trainer - INFO - Epoch 27, Step 94140: Loss=5.9228, Acc=0.214, 
2025-10-11 19:51:56,748 - training.trainer - INFO - Epoch 27, Step 94240: Loss=5.2998, Acc=0.302, 
2025-10-11 19:52:06,128 - training.trainer - INFO - Epoch 27, Step 94340: Loss=5.4525, Acc=0.317, 
2025-10-11 19:52:15,431 - training.trainer - INFO - Epoch 27, Step 94440: Loss=6.3397, Acc=0.256, 
2025-10-11 19:52:24,625 - training.trainer - INFO - Epoch 27, Step 94540: Loss=6.1636, Acc=0.211, 
2025-10-11 19:52:33,985 - training.trainer - INFO - Epoch 27, Step 94640: Loss=6.1053, Acc=0.246, 
2025-10-11 19:52:55,050 - training.trainer - INFO - Epoch 28/100 completed in 325.33s - Train Loss: 5.5455, Train Acc: 0.272, Val Loss: 5.7403, Val Acc: 0.256
2025-10-11 19:53:03,843 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.4746, Acc=0.231, 
2025-10-11 19:53:12,988 - training.trainer - INFO - Epoch 28, Step 94923: Loss=5.0580, Acc=0.324, 
2025-10-11 19:53:22,187 - training.trainer - INFO - Epoch 28, Step 95023: Loss=5.3399, Acc=0.195, 
2025-10-11 19:53:31,597 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.3131, Acc=0.300, 
2025-10-11 19:53:41,123 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.6964, Acc=0.271, 
2025-10-11 19:53:50,491 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.0146, Acc=0.292, 
2025-10-11 19:53:59,878 - training.trainer - INFO - Epoch 28, Step 95423: Loss=4.8101, Acc=0.474, 
2025-10-11 19:54:09,338 - training.trainer - INFO - Epoch 28, Step 95523: Loss=6.0494, Acc=0.200, 
2025-10-11 19:54:18,728 - training.trainer - INFO - Epoch 28, Step 95623: Loss=5.5224, Acc=0.189, 
2025-10-11 19:54:28,030 - training.trainer - INFO - Epoch 28, Step 95723: Loss=5.9330, Acc=0.167, 
2025-10-11 19:54:37,395 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.8533, Acc=0.256, 
2025-10-11 19:54:46,568 - training.trainer - INFO - Epoch 28, Step 95923: Loss=3.8840, Acc=0.533, 
2025-10-11 19:54:55,911 - training.trainer - INFO - Epoch 28, Step 96023: Loss=6.0026, Acc=0.385, 
2025-10-11 19:55:05,267 - training.trainer - INFO - Epoch 28, Step 96123: Loss=4.9347, Acc=0.288, 
2025-10-11 19:55:14,584 - training.trainer - INFO - Epoch 28, Step 96223: Loss=4.9881, Acc=0.348, 
2025-10-11 19:55:23,998 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.9759, Acc=0.231, 
2025-10-11 19:55:33,261 - training.trainer - INFO - Epoch 28, Step 96423: Loss=6.1281, Acc=0.267, 
2025-10-11 19:55:42,783 - training.trainer - INFO - Epoch 28, Step 96523: Loss=5.0579, Acc=0.302, 
2025-10-11 19:55:52,137 - training.trainer - INFO - Epoch 28, Step 96623: Loss=6.1221, Acc=0.242, 
2025-10-11 19:56:01,515 - training.trainer - INFO - Epoch 28, Step 96723: Loss=5.6663, Acc=0.250, 
2025-10-11 19:56:10,990 - training.trainer - INFO - Epoch 28, Step 96823: Loss=5.9620, Acc=0.222, 
2025-10-11 19:56:20,530 - training.trainer - INFO - Epoch 28, Step 96923: Loss=5.7069, Acc=0.250, 
2025-10-11 19:56:30,036 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.2807, Acc=0.263, 
2025-10-11 19:56:39,382 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.6823, Acc=0.250, 
2025-10-11 19:56:48,738 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.7632, Acc=0.270, 
2025-10-11 19:56:58,013 - training.trainer - INFO - Epoch 28, Step 97323: Loss=5.0837, Acc=0.291, 
2025-10-11 19:57:07,224 - training.trainer - INFO - Epoch 28, Step 97423: Loss=5.8205, Acc=0.235, 
2025-10-11 19:57:16,452 - training.trainer - INFO - Epoch 28, Step 97523: Loss=3.2289, Acc=0.519, 
2025-10-11 19:57:25,721 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.7711, Acc=0.233, 
2025-10-11 19:57:35,143 - training.trainer - INFO - Epoch 28, Step 97723: Loss=6.2236, Acc=0.222, 
2025-10-11 19:57:44,402 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.6891, Acc=0.304, 
2025-10-11 19:57:53,898 - training.trainer - INFO - Epoch 28, Step 97923: Loss=5.5870, Acc=0.311, 
2025-10-11 19:58:03,334 - training.trainer - INFO - Epoch 28, Step 98023: Loss=5.4105, Acc=0.270, 
2025-10-11 19:58:25,264 - training.trainer - INFO - Epoch 29/100 completed in 330.21s - Train Loss: 5.5332, Train Acc: 0.273, Val Loss: 5.7437, Val Acc: 0.254
2025-10-11 19:58:35,392 - training.trainer - INFO - Epoch 29, Step 98206: Loss=4.3188, Acc=0.481, 
2025-10-11 19:58:44,735 - training.trainer - INFO - Epoch 29, Step 98306: Loss=4.9647, Acc=0.433, 
2025-10-11 19:58:53,879 - training.trainer - INFO - Epoch 29, Step 98406: Loss=4.7001, Acc=0.333, 
2025-10-11 19:59:03,113 - training.trainer - INFO - Epoch 29, Step 98506: Loss=5.8235, Acc=0.308, 
2025-10-11 19:59:12,354 - training.trainer - INFO - Epoch 29, Step 98606: Loss=5.6693, Acc=0.278, 
2025-10-11 19:59:21,678 - training.trainer - INFO - Epoch 29, Step 98706: Loss=6.4987, Acc=0.222, 
2025-10-11 19:59:30,979 - training.trainer - INFO - Epoch 29, Step 98806: Loss=6.2019, Acc=0.171, 
2025-10-11 19:59:40,291 - training.trainer - INFO - Epoch 29, Step 98906: Loss=6.6294, Acc=0.089, 
2025-10-11 19:59:49,673 - training.trainer - INFO - Epoch 29, Step 99006: Loss=4.8488, Acc=0.364, 
2025-10-11 19:59:59,185 - training.trainer - INFO - Epoch 29, Step 99106: Loss=5.9240, Acc=0.231, 
2025-10-11 20:00:08,555 - training.trainer - INFO - Epoch 29, Step 99206: Loss=5.7889, Acc=0.225, 
2025-10-11 20:00:18,057 - training.trainer - INFO - Epoch 29, Step 99306: Loss=5.7034, Acc=0.250, 
2025-10-11 20:00:27,565 - training.trainer - INFO - Epoch 29, Step 99406: Loss=5.8550, Acc=0.212, 
2025-10-11 20:00:36,887 - training.trainer - INFO - Epoch 29, Step 99506: Loss=4.4079, Acc=0.429, 
2025-10-11 20:00:46,218 - training.trainer - INFO - Epoch 29, Step 99606: Loss=5.5309, Acc=0.243, 
2025-10-11 20:00:55,561 - training.trainer - INFO - Epoch 29, Step 99706: Loss=6.0612, Acc=0.244, 
2025-10-11 20:01:04,835 - training.trainer - INFO - Epoch 29, Step 99806: Loss=6.0140, Acc=0.225, 
2025-10-11 20:01:14,159 - training.trainer - INFO - Epoch 29, Step 99906: Loss=5.8348, Acc=0.267, 
2025-10-11 20:01:23,473 - training.trainer - INFO - Epoch 29, Step 100006: Loss=6.3269, Acc=0.286, 
2025-10-11 20:01:32,799 - training.trainer - INFO - Epoch 29, Step 100106: Loss=4.4720, Acc=0.364, 
2025-10-11 20:01:42,101 - training.trainer - INFO - Epoch 29, Step 100206: Loss=6.1702, Acc=0.265, 
2025-10-11 20:01:51,402 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.5554, Acc=0.207, 
2025-10-11 20:02:00,806 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.3963, Acc=0.283, 
2025-10-11 20:02:10,253 - training.trainer - INFO - Epoch 29, Step 100506: Loss=5.6876, Acc=0.214, 
2025-10-11 20:02:19,715 - training.trainer - INFO - Epoch 29, Step 100606: Loss=6.9959, Acc=0.148, 
2025-10-11 20:02:29,025 - training.trainer - INFO - Epoch 29, Step 100706: Loss=6.1860, Acc=0.233, 
2025-10-11 20:02:38,378 - training.trainer - INFO - Epoch 29, Step 100806: Loss=5.6983, Acc=0.283, 
2025-10-11 20:02:47,662 - training.trainer - INFO - Epoch 29, Step 100906: Loss=5.6489, Acc=0.235, 
2025-10-11 20:02:56,917 - training.trainer - INFO - Epoch 29, Step 101006: Loss=6.0117, Acc=0.256, 
2025-10-11 20:03:06,211 - training.trainer - INFO - Epoch 29, Step 101106: Loss=5.3834, Acc=0.233, 
2025-10-11 20:03:15,470 - training.trainer - INFO - Epoch 29, Step 101206: Loss=4.9909, Acc=0.276, 
2025-10-11 20:03:24,695 - training.trainer - INFO - Epoch 29, Step 101306: Loss=5.6476, Acc=0.192, 
2025-10-11 20:03:34,195 - training.trainer - INFO - Epoch 29, Step 101406: Loss=5.6415, Acc=0.292, 
2025-10-11 20:03:55,449 - training.trainer - INFO - Epoch 30/100 completed in 330.18s - Train Loss: 5.5157, Train Acc: 0.275, Val Loss: 5.7500, Val Acc: 0.256
2025-10-11 20:03:55,840 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-10-11 20:04:04,417 - training.trainer - INFO - Epoch 30, Step 101589: Loss=5.6404, Acc=0.238, 
2025-10-11 20:04:12,538 - training.trainer - INFO - Epoch 30, Step 101689: Loss=6.6968, Acc=0.105, 
2025-10-11 20:04:20,568 - training.trainer - INFO - Epoch 30, Step 101789: Loss=4.9711, Acc=0.300, 
2025-10-11 20:04:28,548 - training.trainer - INFO - Epoch 30, Step 101889: Loss=5.4923, Acc=0.213, 
2025-10-11 20:04:36,595 - training.trainer - INFO - Epoch 30, Step 101989: Loss=4.7568, Acc=0.400, 
2025-10-11 20:04:45,352 - training.trainer - INFO - Epoch 30, Step 102089: Loss=4.5404, Acc=0.441, 
2025-10-11 20:04:54,538 - training.trainer - INFO - Epoch 30, Step 102189: Loss=5.3724, Acc=0.326, 
2025-10-11 20:05:03,927 - training.trainer - INFO - Epoch 30, Step 102289: Loss=4.5439, Acc=0.333, 
2025-10-11 20:05:13,178 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.4129, Acc=0.222, 
2025-10-11 20:05:22,436 - training.trainer - INFO - Epoch 30, Step 102489: Loss=5.3017, Acc=0.323, 
2025-10-11 20:05:31,761 - training.trainer - INFO - Epoch 30, Step 102589: Loss=5.7558, Acc=0.216, 
2025-10-11 20:05:41,146 - training.trainer - INFO - Epoch 30, Step 102689: Loss=5.7997, Acc=0.215, 
2025-10-11 20:05:50,581 - training.trainer - INFO - Epoch 30, Step 102789: Loss=5.7055, Acc=0.269, 
2025-10-11 20:06:00,079 - training.trainer - INFO - Epoch 30, Step 102889: Loss=5.7570, Acc=0.295, 
2025-10-11 20:06:09,615 - training.trainer - INFO - Epoch 30, Step 102989: Loss=4.3359, Acc=0.414, 
2025-10-11 20:06:19,134 - training.trainer - INFO - Epoch 30, Step 103089: Loss=4.8154, Acc=0.382, 
2025-10-11 20:06:28,680 - training.trainer - INFO - Epoch 30, Step 103189: Loss=5.3360, Acc=0.214, 
2025-10-11 20:06:38,122 - training.trainer - INFO - Epoch 30, Step 103289: Loss=5.9989, Acc=0.196, 
2025-10-11 20:06:47,582 - training.trainer - INFO - Epoch 30, Step 103389: Loss=3.5394, Acc=0.500, 
2025-10-11 20:06:57,056 - training.trainer - INFO - Epoch 30, Step 103489: Loss=5.4872, Acc=0.360, 
2025-10-11 20:07:06,443 - training.trainer - INFO - Epoch 30, Step 103589: Loss=5.6458, Acc=0.310, 
2025-10-11 20:07:15,684 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.6641, Acc=0.268, 
2025-10-11 20:07:25,078 - training.trainer - INFO - Epoch 30, Step 103789: Loss=5.2452, Acc=0.556, 
2025-10-11 20:07:34,400 - training.trainer - INFO - Epoch 30, Step 103889: Loss=5.8083, Acc=0.265, 
2025-10-11 20:07:43,619 - training.trainer - INFO - Epoch 30, Step 103989: Loss=4.9121, Acc=0.222, 
2025-10-11 20:07:52,828 - training.trainer - INFO - Epoch 30, Step 104089: Loss=3.6468, Acc=0.529, 
2025-10-11 20:08:02,033 - training.trainer - INFO - Epoch 30, Step 104189: Loss=5.0908, Acc=0.256, 
2025-10-11 20:08:11,284 - training.trainer - INFO - Epoch 30, Step 104289: Loss=5.9638, Acc=0.333, 
2025-10-11 20:08:20,683 - training.trainer - INFO - Epoch 30, Step 104389: Loss=5.0327, Acc=0.300, 
2025-10-11 20:08:29,867 - training.trainer - INFO - Epoch 30, Step 104489: Loss=5.8057, Acc=0.197, 
2025-10-11 20:08:39,215 - training.trainer - INFO - Epoch 30, Step 104589: Loss=5.7425, Acc=0.242, 
2025-10-11 20:08:48,482 - training.trainer - INFO - Epoch 30, Step 104689: Loss=6.3312, Acc=0.171, 
2025-10-11 20:08:57,768 - training.trainer - INFO - Epoch 30, Step 104789: Loss=6.0728, Acc=0.250, 
2025-10-11 20:09:18,518 - training.trainer - INFO - Epoch 31/100 completed in 322.68s - Train Loss: 5.5042, Train Acc: 0.278, Val Loss: 5.7518, Val Acc: 0.258
2025-10-11 20:09:26,770 - training.trainer - INFO - Epoch 31, Step 104972: Loss=5.2878, Acc=0.342, 
2025-10-11 20:09:35,231 - training.trainer - INFO - Epoch 31, Step 105072: Loss=5.3416, Acc=0.220, 
2025-10-11 20:09:43,182 - training.trainer - INFO - Epoch 31, Step 105172: Loss=5.7555, Acc=0.222, 
2025-10-11 20:09:51,049 - training.trainer - INFO - Epoch 31, Step 105272: Loss=5.7009, Acc=0.235, 
2025-10-11 20:09:58,989 - training.trainer - INFO - Epoch 31, Step 105372: Loss=4.3847, Acc=0.316, 
2025-10-11 20:10:06,931 - training.trainer - INFO - Epoch 31, Step 105472: Loss=5.2480, Acc=0.302, 
2025-10-11 20:10:14,761 - training.trainer - INFO - Epoch 31, Step 105572: Loss=6.0957, Acc=0.186, 
2025-10-11 20:10:22,590 - training.trainer - INFO - Epoch 31, Step 105672: Loss=5.6954, Acc=0.263, 
2025-10-11 20:10:31,104 - training.trainer - INFO - Epoch 31, Step 105772: Loss=6.1626, Acc=0.234, 
2025-10-11 20:10:39,059 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.7964, Acc=0.293, 
2025-10-11 20:10:46,867 - training.trainer - INFO - Epoch 31, Step 105972: Loss=5.9800, Acc=0.184, 
2025-10-11 20:10:54,801 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.7438, Acc=0.308, 
2025-10-11 20:11:02,751 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.3129, Acc=0.333, 
2025-10-11 20:11:10,671 - training.trainer - INFO - Epoch 31, Step 106272: Loss=5.6400, Acc=0.292, 
2025-10-11 20:11:18,536 - training.trainer - INFO - Epoch 31, Step 106372: Loss=6.7564, Acc=0.250, 
2025-10-11 20:11:26,506 - training.trainer - INFO - Epoch 31, Step 106472: Loss=5.9964, Acc=0.195, 
2025-10-11 20:11:34,549 - training.trainer - INFO - Epoch 31, Step 106572: Loss=5.2443, Acc=0.385, 
2025-10-11 20:11:42,531 - training.trainer - INFO - Epoch 31, Step 106672: Loss=5.7213, Acc=0.276, 
2025-10-11 20:11:50,473 - training.trainer - INFO - Epoch 31, Step 106772: Loss=5.5515, Acc=0.211, 
2025-10-11 20:11:58,358 - training.trainer - INFO - Epoch 31, Step 106872: Loss=6.0839, Acc=0.308, 
2025-10-11 20:12:06,312 - training.trainer - INFO - Epoch 31, Step 106972: Loss=3.5705, Acc=0.571, 
2025-10-11 20:12:14,151 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.8877, Acc=0.259, 
2025-10-11 20:12:22,484 - training.trainer - INFO - Epoch 31, Step 107172: Loss=5.2020, Acc=0.277, 
2025-10-11 20:12:30,334 - training.trainer - INFO - Epoch 31, Step 107272: Loss=5.1021, Acc=0.268, 
2025-10-11 20:12:38,188 - training.trainer - INFO - Epoch 31, Step 107372: Loss=5.7268, Acc=0.280, 
2025-10-11 20:12:46,091 - training.trainer - INFO - Epoch 31, Step 107472: Loss=5.4907, Acc=0.236, 
2025-10-11 20:12:54,004 - training.trainer - INFO - Epoch 31, Step 107572: Loss=5.5306, Acc=0.476, 
2025-10-11 20:13:02,317 - training.trainer - INFO - Epoch 31, Step 107672: Loss=5.6131, Acc=0.239, 
2025-10-11 20:13:10,307 - training.trainer - INFO - Epoch 31, Step 107772: Loss=5.4629, Acc=0.190, 
2025-10-11 20:13:18,298 - training.trainer - INFO - Epoch 31, Step 107872: Loss=4.4940, Acc=0.412, 
2025-10-11 20:13:26,363 - training.trainer - INFO - Epoch 31, Step 107972: Loss=5.5384, Acc=0.296, 
2025-10-11 20:13:34,293 - training.trainer - INFO - Epoch 31, Step 108072: Loss=4.9954, Acc=0.360, 
2025-10-11 20:13:42,173 - training.trainer - INFO - Epoch 31, Step 108172: Loss=6.3488, Acc=0.161, 
2025-10-11 20:14:02,050 - training.trainer - INFO - Epoch 32/100 completed in 283.53s - Train Loss: 5.4855, Train Acc: 0.282, Val Loss: 5.7586, Val Acc: 0.256
2025-10-11 20:14:10,271 - training.trainer - INFO - Epoch 32, Step 108355: Loss=5.5621, Acc=0.316, 
2025-10-11 20:14:18,113 - training.trainer - INFO - Epoch 32, Step 108455: Loss=5.2300, Acc=0.282, 
2025-10-11 20:14:26,164 - training.trainer - INFO - Epoch 32, Step 108555: Loss=4.1731, Acc=0.475, 
2025-10-11 20:14:34,190 - training.trainer - INFO - Epoch 32, Step 108655: Loss=5.5638, Acc=0.375, 
2025-10-11 20:14:42,728 - training.trainer - INFO - Epoch 32, Step 108755: Loss=5.9172, Acc=0.321, 
2025-10-11 20:14:51,365 - training.trainer - INFO - Epoch 32, Step 108855: Loss=5.6286, Acc=0.250, 
2025-10-11 20:15:00,029 - training.trainer - INFO - Epoch 32, Step 108955: Loss=5.4520, Acc=0.286, 
2025-10-11 20:15:08,874 - training.trainer - INFO - Epoch 32, Step 109055: Loss=5.7757, Acc=0.333, 
2025-10-11 20:15:17,599 - training.trainer - INFO - Epoch 32, Step 109155: Loss=4.6353, Acc=0.435, 
2025-10-11 20:15:26,555 - training.trainer - INFO - Epoch 32, Step 109255: Loss=5.0005, Acc=0.391, 
2025-10-11 20:15:36,088 - training.trainer - INFO - Epoch 32, Step 109355: Loss=4.1445, Acc=0.452, 
2025-10-11 20:15:45,650 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.2664, Acc=0.283, 
2025-10-11 20:15:55,112 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.9937, Acc=0.254, 
2025-10-11 20:16:04,535 - training.trainer - INFO - Epoch 32, Step 109655: Loss=5.6210, Acc=0.133, 
2025-10-11 20:16:13,957 - training.trainer - INFO - Epoch 32, Step 109755: Loss=6.4627, Acc=0.174, 
2025-10-11 20:16:23,312 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.6836, Acc=0.196, 
2025-10-11 20:16:32,589 - training.trainer - INFO - Epoch 32, Step 109955: Loss=6.0977, Acc=0.211, 
2025-10-11 20:16:41,806 - training.trainer - INFO - Epoch 32, Step 110055: Loss=4.3707, Acc=0.500, 
2025-10-11 20:16:51,429 - training.trainer - INFO - Epoch 32, Step 110155: Loss=5.7494, Acc=0.333, 
2025-10-11 20:17:00,809 - training.trainer - INFO - Epoch 32, Step 110255: Loss=5.2539, Acc=0.353, 
2025-10-11 20:17:10,236 - training.trainer - INFO - Epoch 32, Step 110355: Loss=5.5016, Acc=0.304, 
2025-10-11 20:17:19,767 - training.trainer - INFO - Epoch 32, Step 110455: Loss=5.6309, Acc=0.294, 
2025-10-11 20:17:29,107 - training.trainer - INFO - Epoch 32, Step 110555: Loss=6.5239, Acc=0.193, 
2025-10-11 20:17:38,647 - training.trainer - INFO - Epoch 32, Step 110655: Loss=5.4039, Acc=0.250, 
2025-10-11 20:17:48,025 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.0332, Acc=0.324, 
2025-10-11 20:17:57,189 - training.trainer - INFO - Epoch 32, Step 110855: Loss=5.9010, Acc=0.180, 
2025-10-11 20:18:06,450 - training.trainer - INFO - Epoch 32, Step 110955: Loss=4.0102, Acc=0.429, 
2025-10-11 20:18:15,759 - training.trainer - INFO - Epoch 32, Step 111055: Loss=5.7516, Acc=0.318, 
2025-10-11 20:18:25,057 - training.trainer - INFO - Epoch 32, Step 111155: Loss=5.5911, Acc=0.314, 
2025-10-11 20:18:34,310 - training.trainer - INFO - Epoch 32, Step 111255: Loss=5.6029, Acc=0.200, 
2025-10-11 20:18:43,638 - training.trainer - INFO - Epoch 32, Step 111355: Loss=3.6827, Acc=0.500, 
2025-10-11 20:18:53,250 - training.trainer - INFO - Epoch 32, Step 111455: Loss=6.4513, Acc=0.235, 
2025-10-11 20:19:02,620 - training.trainer - INFO - Epoch 32, Step 111555: Loss=5.5509, Acc=0.341, 
2025-10-11 20:19:24,345 - training.trainer - INFO - Epoch 33/100 completed in 322.29s - Train Loss: 5.4782, Train Acc: 0.283, Val Loss: 5.7946, Val Acc: 0.259
2025-10-11 20:19:34,214 - training.trainer - INFO - Epoch 33, Step 111738: Loss=6.2074, Acc=0.211, 
2025-10-11 20:19:43,696 - training.trainer - INFO - Epoch 33, Step 111838: Loss=5.1958, Acc=0.292, 
2025-10-11 20:19:53,078 - training.trainer - INFO - Epoch 33, Step 111938: Loss=4.6338, Acc=0.405, 
2025-10-11 20:20:02,778 - training.trainer - INFO - Epoch 33, Step 112038: Loss=6.3272, Acc=0.128, 
2025-10-11 20:20:12,138 - training.trainer - INFO - Epoch 33, Step 112138: Loss=4.6456, Acc=0.276, 
2025-10-11 20:20:21,307 - training.trainer - INFO - Epoch 33, Step 112238: Loss=4.7921, Acc=0.241, 
2025-10-11 20:20:30,477 - training.trainer - INFO - Epoch 33, Step 112338: Loss=4.9014, Acc=0.500, 
2025-10-11 20:20:39,749 - training.trainer - INFO - Epoch 33, Step 112438: Loss=6.0463, Acc=0.197, 
2025-10-11 20:20:49,004 - training.trainer - INFO - Epoch 33, Step 112538: Loss=5.7124, Acc=0.177, 
2025-10-11 20:20:58,194 - training.trainer - INFO - Epoch 33, Step 112638: Loss=5.1865, Acc=0.294, 
2025-10-11 20:21:07,638 - training.trainer - INFO - Epoch 33, Step 112738: Loss=5.0565, Acc=0.261, 
2025-10-11 20:21:17,093 - training.trainer - INFO - Epoch 33, Step 112838: Loss=5.5552, Acc=0.316, 
2025-10-11 20:21:26,516 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.9118, Acc=0.214, 
2025-10-11 20:21:35,990 - training.trainer - INFO - Epoch 33, Step 113038: Loss=5.4584, Acc=0.129, 
2025-10-11 20:21:45,451 - training.trainer - INFO - Epoch 33, Step 113138: Loss=5.5897, Acc=0.226, 
2025-10-11 20:21:54,868 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.5570, Acc=0.258, 
2025-10-11 20:22:04,424 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.0141, Acc=0.435, 
2025-10-11 20:22:13,920 - training.trainer - INFO - Epoch 33, Step 113438: Loss=4.8710, Acc=0.350, 
2025-10-11 20:22:23,460 - training.trainer - INFO - Epoch 33, Step 113538: Loss=5.9698, Acc=0.180, 
2025-10-11 20:22:32,956 - training.trainer - INFO - Epoch 33, Step 113638: Loss=5.9057, Acc=0.139, 
2025-10-11 20:22:42,486 - training.trainer - INFO - Epoch 33, Step 113738: Loss=5.9998, Acc=0.227, 
2025-10-11 20:22:51,966 - training.trainer - INFO - Epoch 33, Step 113838: Loss=5.3807, Acc=0.308, 
2025-10-11 20:23:01,749 - training.trainer - INFO - Epoch 33, Step 113938: Loss=6.2235, Acc=0.210, 
2025-10-11 20:23:11,294 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.2101, Acc=0.320, 
2025-10-11 20:23:20,496 - training.trainer - INFO - Epoch 33, Step 114138: Loss=6.4097, Acc=0.208, 
2025-10-11 20:23:29,743 - training.trainer - INFO - Epoch 33, Step 114238: Loss=5.8507, Acc=0.296, 
2025-10-11 20:23:39,115 - training.trainer - INFO - Epoch 33, Step 114338: Loss=6.2878, Acc=0.167, 
2025-10-11 20:23:48,589 - training.trainer - INFO - Epoch 33, Step 114438: Loss=5.5831, Acc=0.246, 
2025-10-11 20:23:58,047 - training.trainer - INFO - Epoch 33, Step 114538: Loss=5.7479, Acc=0.229, 
2025-10-11 20:24:07,526 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.6491, Acc=0.254, 
2025-10-11 20:24:17,020 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.8632, Acc=0.188, 
2025-10-11 20:24:26,532 - training.trainer - INFO - Epoch 33, Step 114838: Loss=6.6339, Acc=0.162, 
2025-10-11 20:24:35,829 - training.trainer - INFO - Epoch 33, Step 114938: Loss=4.9901, Acc=0.257, 
2025-10-11 20:24:57,874 - training.trainer - INFO - Epoch 34/100 completed in 333.53s - Train Loss: 5.4647, Train Acc: 0.284, Val Loss: 5.7774, Val Acc: 0.261
2025-10-11 20:25:07,976 - training.trainer - INFO - Epoch 34, Step 115121: Loss=4.9498, Acc=0.393, 
2025-10-11 20:25:17,492 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.9657, Acc=0.190, 
2025-10-11 20:25:26,966 - training.trainer - INFO - Epoch 34, Step 115321: Loss=5.2766, Acc=0.304, 
2025-10-11 20:25:36,209 - training.trainer - INFO - Epoch 34, Step 115421: Loss=4.7827, Acc=0.474, 
2025-10-11 20:25:45,476 - training.trainer - INFO - Epoch 34, Step 115521: Loss=5.0907, Acc=0.286, 
2025-10-11 20:25:54,783 - training.trainer - INFO - Epoch 34, Step 115621: Loss=5.2668, Acc=0.361, 
2025-10-11 20:26:04,084 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.4945, Acc=0.354, 
2025-10-11 20:26:13,324 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.8786, Acc=0.281, 
2025-10-11 20:26:22,603 - training.trainer - INFO - Epoch 34, Step 115921: Loss=5.9793, Acc=0.286, 
2025-10-11 20:26:31,997 - training.trainer - INFO - Epoch 34, Step 116021: Loss=5.5746, Acc=0.286, 
2025-10-11 20:26:41,234 - training.trainer - INFO - Epoch 34, Step 116121: Loss=5.9408, Acc=0.391, 
2025-10-11 20:26:50,472 - training.trainer - INFO - Epoch 34, Step 116221: Loss=5.3554, Acc=0.286, 
2025-10-11 20:26:59,659 - training.trainer - INFO - Epoch 34, Step 116321: Loss=6.2162, Acc=0.182, 
2025-10-11 20:27:08,814 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.6278, Acc=0.317, 
2025-10-11 20:27:18,136 - training.trainer - INFO - Epoch 34, Step 116521: Loss=6.7163, Acc=0.214, 
2025-10-11 20:27:27,534 - training.trainer - INFO - Epoch 34, Step 116621: Loss=5.3990, Acc=0.261, 
2025-10-11 20:27:36,893 - training.trainer - INFO - Epoch 34, Step 116721: Loss=5.9080, Acc=0.281, 
2025-10-11 20:27:46,224 - training.trainer - INFO - Epoch 34, Step 116821: Loss=6.2089, Acc=0.209, 
2025-10-11 20:27:55,448 - training.trainer - INFO - Epoch 34, Step 116921: Loss=6.0250, Acc=0.136, 
2025-10-11 20:28:04,854 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.4311, Acc=0.279, 
2025-10-11 20:28:14,198 - training.trainer - INFO - Epoch 34, Step 117121: Loss=5.0774, Acc=0.371, 
2025-10-11 20:28:23,435 - training.trainer - INFO - Epoch 34, Step 117221: Loss=5.2923, Acc=0.220, 
2025-10-11 20:28:32,715 - training.trainer - INFO - Epoch 34, Step 117321: Loss=4.3504, Acc=0.500, 
2025-10-11 20:28:42,131 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.4684, Acc=0.233, 
2025-10-11 20:28:51,403 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.7942, Acc=0.333, 
2025-10-11 20:29:00,511 - training.trainer - INFO - Epoch 34, Step 117621: Loss=5.9231, Acc=0.243, 
2025-10-11 20:29:09,719 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.0358, Acc=0.346, 
2025-10-11 20:29:18,992 - training.trainer - INFO - Epoch 34, Step 117821: Loss=4.1619, Acc=0.512, 
2025-10-11 20:29:28,402 - training.trainer - INFO - Epoch 34, Step 117921: Loss=5.4685, Acc=0.200, 
2025-10-11 20:29:37,622 - training.trainer - INFO - Epoch 34, Step 118021: Loss=5.8021, Acc=0.273, 
2025-10-11 20:29:46,957 - training.trainer - INFO - Epoch 34, Step 118121: Loss=5.4821, Acc=0.235, 
2025-10-11 20:29:56,230 - training.trainer - INFO - Epoch 34, Step 118221: Loss=5.7809, Acc=0.269, 
2025-10-11 20:30:05,601 - training.trainer - INFO - Epoch 34, Step 118321: Loss=4.9262, Acc=0.226, 
2025-10-11 20:30:26,603 - training.trainer - INFO - Epoch 35/100 completed in 328.73s - Train Loss: 5.4514, Train Acc: 0.287, Val Loss: 5.8232, Val Acc: 0.260
2025-10-11 20:30:26,976 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-10-11 20:30:36,523 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.4273, Acc=0.282, 
2025-10-11 20:30:45,798 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.7542, Acc=0.234, 
2025-10-11 20:30:55,122 - training.trainer - INFO - Epoch 35, Step 118704: Loss=5.4611, Acc=0.286, 
2025-10-11 20:31:04,317 - training.trainer - INFO - Epoch 35, Step 118804: Loss=4.7392, Acc=0.395, 
2025-10-11 20:31:13,477 - training.trainer - INFO - Epoch 35, Step 118904: Loss=6.0482, Acc=0.231, 
2025-10-11 20:31:22,788 - training.trainer - INFO - Epoch 35, Step 119004: Loss=5.4737, Acc=0.361, 
2025-10-11 20:31:32,062 - training.trainer - INFO - Epoch 35, Step 119104: Loss=5.4379, Acc=0.280, 
2025-10-11 20:31:41,290 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.5771, Acc=0.250, 
2025-10-11 20:31:50,501 - training.trainer - INFO - Epoch 35, Step 119304: Loss=5.6163, Acc=0.333, 
2025-10-11 20:31:59,830 - training.trainer - INFO - Epoch 35, Step 119404: Loss=5.7748, Acc=0.216, 
2025-10-11 20:32:09,133 - training.trainer - INFO - Epoch 35, Step 119504: Loss=6.4719, Acc=0.182, 
2025-10-11 20:32:18,392 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.7680, Acc=0.300, 
2025-10-11 20:32:27,714 - training.trainer - INFO - Epoch 35, Step 119704: Loss=5.0666, Acc=0.364, 
2025-10-11 20:32:36,955 - training.trainer - INFO - Epoch 35, Step 119804: Loss=5.3385, Acc=0.349, 
2025-10-11 20:32:46,164 - training.trainer - INFO - Epoch 35, Step 119904: Loss=5.6701, Acc=0.247, 
2025-10-11 20:32:55,319 - training.trainer - INFO - Epoch 35, Step 120004: Loss=5.6905, Acc=0.294, 
2025-10-11 20:33:04,568 - training.trainer - INFO - Epoch 35, Step 120104: Loss=6.1752, Acc=0.192, 
2025-10-11 20:33:13,786 - training.trainer - INFO - Epoch 35, Step 120204: Loss=5.5718, Acc=0.246, 
2025-10-11 20:33:23,096 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.8993, Acc=0.190, 
2025-10-11 20:33:32,367 - training.trainer - INFO - Epoch 35, Step 120404: Loss=5.3886, Acc=0.231, 
2025-10-11 20:33:41,615 - training.trainer - INFO - Epoch 35, Step 120504: Loss=5.2491, Acc=0.264, 
2025-10-11 20:33:50,891 - training.trainer - INFO - Epoch 35, Step 120604: Loss=6.3021, Acc=0.224, 
2025-10-11 20:34:00,139 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.9794, Acc=0.216, 
2025-10-11 20:34:09,492 - training.trainer - INFO - Epoch 35, Step 120804: Loss=4.6441, Acc=0.268, 
2025-10-11 20:34:18,728 - training.trainer - INFO - Epoch 35, Step 120904: Loss=4.9129, Acc=0.438, 
2025-10-11 20:34:28,131 - training.trainer - INFO - Epoch 35, Step 121004: Loss=5.1491, Acc=0.348, 
2025-10-11 20:34:37,490 - training.trainer - INFO - Epoch 35, Step 121104: Loss=5.4563, Acc=0.327, 
2025-10-11 20:34:46,880 - training.trainer - INFO - Epoch 35, Step 121204: Loss=6.6287, Acc=0.115, 
2025-10-11 20:34:56,098 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.5437, Acc=0.385, 
2025-10-11 20:35:05,396 - training.trainer - INFO - Epoch 35, Step 121404: Loss=6.1565, Acc=0.222, 
2025-10-11 20:35:14,724 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.4693, Acc=0.256, 
2025-10-11 20:35:24,009 - training.trainer - INFO - Epoch 35, Step 121604: Loss=5.9652, Acc=0.143, 
2025-10-11 20:35:33,303 - training.trainer - INFO - Epoch 35, Step 121704: Loss=5.5261, Acc=0.305, 
2025-10-11 20:35:53,977 - training.trainer - INFO - Epoch 36/100 completed in 327.00s - Train Loss: 5.4456, Train Acc: 0.287, Val Loss: 5.7795, Val Acc: 0.258
2025-10-11 20:36:02,323 - training.trainer - INFO - Epoch 36, Step 121887: Loss=5.7772, Acc=0.300, 
2025-10-11 20:36:10,290 - training.trainer - INFO - Epoch 36, Step 121987: Loss=5.1090, Acc=0.268, 
2025-10-11 20:36:18,320 - training.trainer - INFO - Epoch 36, Step 122087: Loss=5.8948, Acc=0.200, 
2025-10-11 20:36:26,274 - training.trainer - INFO - Epoch 36, Step 122187: Loss=4.9263, Acc=0.350, 
2025-10-11 20:36:34,312 - training.trainer - INFO - Epoch 36, Step 122287: Loss=5.9330, Acc=0.283, 
2025-10-11 20:36:42,973 - training.trainer - INFO - Epoch 36, Step 122387: Loss=4.9776, Acc=0.333, 
2025-10-11 20:36:52,039 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.5320, Acc=0.188, 
2025-10-11 20:37:00,892 - training.trainer - INFO - Epoch 36, Step 122587: Loss=5.0558, Acc=0.312, 
2025-10-11 20:37:09,060 - training.trainer - INFO - Epoch 36, Step 122687: Loss=5.8894, Acc=0.219, 
2025-10-11 20:37:17,870 - training.trainer - INFO - Epoch 36, Step 122787: Loss=5.0646, Acc=0.333, 
2025-10-11 20:37:26,603 - training.trainer - INFO - Epoch 36, Step 122887: Loss=6.1230, Acc=0.250, 
2025-10-11 20:37:35,348 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.4480, Acc=0.359, 
2025-10-11 20:37:44,208 - training.trainer - INFO - Epoch 36, Step 123087: Loss=5.2477, Acc=0.267, 
2025-10-11 20:37:53,401 - training.trainer - INFO - Epoch 36, Step 123187: Loss=5.9398, Acc=0.219, 
2025-10-11 20:38:02,813 - training.trainer - INFO - Epoch 36, Step 123287: Loss=5.2983, Acc=0.267, 
2025-10-11 20:38:12,283 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.2312, Acc=0.238, 
2025-10-11 20:38:21,632 - training.trainer - INFO - Epoch 36, Step 123487: Loss=6.1277, Acc=0.241, 
2025-10-11 20:38:30,956 - training.trainer - INFO - Epoch 36, Step 123587: Loss=6.4527, Acc=0.200, 
2025-10-11 20:38:40,132 - training.trainer - INFO - Epoch 36, Step 123687: Loss=6.3184, Acc=0.261, 
2025-10-11 20:38:49,416 - training.trainer - INFO - Epoch 36, Step 123787: Loss=4.9581, Acc=0.409, 
2025-10-11 20:38:58,803 - training.trainer - INFO - Epoch 36, Step 123887: Loss=5.6939, Acc=0.305, 
2025-10-11 20:39:08,161 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.6697, Acc=0.269, 
2025-10-11 20:39:17,592 - training.trainer - INFO - Epoch 36, Step 124087: Loss=5.8005, Acc=0.222, 
2025-10-11 20:39:26,825 - training.trainer - INFO - Epoch 36, Step 124187: Loss=6.0425, Acc=0.232, 
2025-10-11 20:39:36,142 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.4085, Acc=0.364, 
2025-10-11 20:39:45,625 - training.trainer - INFO - Epoch 36, Step 124387: Loss=6.0172, Acc=0.185, 
2025-10-11 20:39:54,804 - training.trainer - INFO - Epoch 36, Step 124487: Loss=4.8985, Acc=0.297, 
2025-10-11 20:40:03,990 - training.trainer - INFO - Epoch 36, Step 124587: Loss=5.1736, Acc=0.333, 
2025-10-11 20:40:13,134 - training.trainer - INFO - Epoch 36, Step 124687: Loss=6.0835, Acc=0.190, 
2025-10-11 20:40:22,329 - training.trainer - INFO - Epoch 36, Step 124787: Loss=4.8909, Acc=0.353, 
2025-10-11 20:40:31,525 - training.trainer - INFO - Epoch 36, Step 124887: Loss=4.9831, Acc=0.364, 
2025-10-11 20:40:40,658 - training.trainer - INFO - Epoch 36, Step 124987: Loss=6.5416, Acc=0.138, 
2025-10-11 20:40:49,814 - training.trainer - INFO - Epoch 36, Step 125087: Loss=5.7984, Acc=0.438, 
2025-10-11 20:41:10,785 - training.trainer - INFO - Epoch 37/100 completed in 316.81s - Train Loss: 5.4297, Train Acc: 0.290, Val Loss: 5.7857, Val Acc: 0.259
2025-10-11 20:41:19,307 - training.trainer - INFO - Epoch 37, Step 125270: Loss=4.0033, Acc=0.529, 
2025-10-11 20:41:27,447 - training.trainer - INFO - Epoch 37, Step 125370: Loss=4.7710, Acc=0.433, 
2025-10-11 20:41:36,772 - training.trainer - INFO - Epoch 37, Step 125470: Loss=6.2791, Acc=0.242, 
2025-10-11 20:41:46,103 - training.trainer - INFO - Epoch 37, Step 125570: Loss=6.9800, Acc=0.173, 
2025-10-11 20:41:55,635 - training.trainer - INFO - Epoch 37, Step 125670: Loss=6.3117, Acc=0.175, 
2025-10-11 20:42:04,997 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.4972, Acc=0.280, 
2025-10-11 20:42:14,469 - training.trainer - INFO - Epoch 37, Step 125870: Loss=5.8534, Acc=0.200, 
2025-10-11 20:42:23,716 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.4545, Acc=0.333, 
2025-10-11 20:42:32,985 - training.trainer - INFO - Epoch 37, Step 126070: Loss=5.4882, Acc=0.333, 
2025-10-11 20:42:42,333 - training.trainer - INFO - Epoch 37, Step 126170: Loss=4.6886, Acc=0.361, 
2025-10-11 20:42:51,739 - training.trainer - INFO - Epoch 37, Step 126270: Loss=6.0091, Acc=0.218, 
2025-10-11 20:43:01,082 - training.trainer - INFO - Epoch 37, Step 126370: Loss=5.8196, Acc=0.220, 
2025-10-11 20:43:10,538 - training.trainer - INFO - Epoch 37, Step 126470: Loss=4.7909, Acc=0.353, 
2025-10-11 20:43:19,813 - training.trainer - INFO - Epoch 37, Step 126570: Loss=4.8462, Acc=0.359, 
2025-10-11 20:43:29,041 - training.trainer - INFO - Epoch 37, Step 126670: Loss=5.0680, Acc=0.385, 
2025-10-11 20:43:38,634 - training.trainer - INFO - Epoch 37, Step 126770: Loss=6.1774, Acc=0.222, 
2025-10-11 20:43:47,961 - training.trainer - INFO - Epoch 37, Step 126870: Loss=6.3388, Acc=0.242, 
2025-10-11 20:43:57,318 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.1418, Acc=0.333, 
2025-10-11 20:44:06,766 - training.trainer - INFO - Epoch 37, Step 127070: Loss=5.6940, Acc=0.216, 
2025-10-11 20:44:16,168 - training.trainer - INFO - Epoch 37, Step 127170: Loss=4.4668, Acc=0.469, 
2025-10-11 20:44:25,635 - training.trainer - INFO - Epoch 37, Step 127270: Loss=5.9848, Acc=0.264, 
2025-10-11 20:44:35,135 - training.trainer - INFO - Epoch 37, Step 127370: Loss=4.7707, Acc=0.500, 
2025-10-11 20:44:44,590 - training.trainer - INFO - Epoch 37, Step 127470: Loss=5.9797, Acc=0.256, 
2025-10-11 20:44:54,010 - training.trainer - INFO - Epoch 37, Step 127570: Loss=5.0457, Acc=0.346, 
2025-10-11 20:45:03,202 - training.trainer - INFO - Epoch 37, Step 127670: Loss=6.2623, Acc=0.320, 
2025-10-11 20:45:12,627 - training.trainer - INFO - Epoch 37, Step 127770: Loss=6.5343, Acc=0.200, 
2025-10-11 20:45:22,128 - training.trainer - INFO - Epoch 37, Step 127870: Loss=5.4813, Acc=0.375, 
2025-10-11 20:45:31,572 - training.trainer - INFO - Epoch 37, Step 127970: Loss=5.8714, Acc=0.231, 
2025-10-11 20:45:40,889 - training.trainer - INFO - Epoch 37, Step 128070: Loss=6.1796, Acc=0.238, 
2025-10-11 20:45:50,258 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.7365, Acc=0.184, 
2025-10-11 20:45:59,570 - training.trainer - INFO - Epoch 37, Step 128270: Loss=5.6838, Acc=0.304, 
2025-10-11 20:46:08,761 - training.trainer - INFO - Epoch 37, Step 128370: Loss=6.0596, Acc=0.227, 
2025-10-11 20:46:18,022 - training.trainer - INFO - Epoch 37, Step 128470: Loss=5.2601, Acc=0.282, 
2025-10-11 20:46:39,289 - training.trainer - INFO - Epoch 38/100 completed in 328.50s - Train Loss: 5.4130, Train Acc: 0.292, Val Loss: 5.7631, Val Acc: 0.262
2025-10-11 20:46:49,075 - training.trainer - INFO - Epoch 38, Step 128653: Loss=4.3257, Acc=0.429, 
2025-10-11 20:46:58,402 - training.trainer - INFO - Epoch 38, Step 128753: Loss=5.9084, Acc=0.273, 
2025-10-11 20:47:07,721 - training.trainer - INFO - Epoch 38, Step 128853: Loss=6.0027, Acc=0.270, 
2025-10-11 20:47:17,134 - training.trainer - INFO - Epoch 38, Step 128953: Loss=5.9138, Acc=0.184, 
2025-10-11 20:47:26,535 - training.trainer - INFO - Epoch 38, Step 129053: Loss=5.2642, Acc=0.235, 
2025-10-11 20:47:35,883 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.8982, Acc=0.229, 
2025-10-11 20:47:45,332 - training.trainer - INFO - Epoch 38, Step 129253: Loss=6.0074, Acc=0.205, 
2025-10-11 20:47:54,722 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.7465, Acc=0.262, 
2025-10-11 20:48:04,133 - training.trainer - INFO - Epoch 38, Step 129453: Loss=5.7870, Acc=0.217, 
2025-10-11 20:48:13,225 - training.trainer - INFO - Epoch 38, Step 129553: Loss=5.6119, Acc=0.274, 
2025-10-11 20:48:22,471 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.8116, Acc=0.267, 
2025-10-11 20:48:31,748 - training.trainer - INFO - Epoch 38, Step 129753: Loss=5.8080, Acc=0.308, 
2025-10-11 20:48:40,994 - training.trainer - INFO - Epoch 38, Step 129853: Loss=5.6791, Acc=0.269, 
2025-10-11 20:48:50,408 - training.trainer - INFO - Epoch 38, Step 129953: Loss=4.3976, Acc=0.500, 
2025-10-11 20:48:59,781 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.8487, Acc=0.205, 
2025-10-11 20:49:09,005 - training.trainer - INFO - Epoch 38, Step 130153: Loss=4.0771, Acc=0.500, 
2025-10-11 20:49:18,126 - training.trainer - INFO - Epoch 38, Step 130253: Loss=5.2089, Acc=0.258, 
2025-10-11 20:49:27,360 - training.trainer - INFO - Epoch 38, Step 130353: Loss=5.1415, Acc=0.412, 
2025-10-11 20:49:36,363 - training.trainer - INFO - Epoch 38, Step 130453: Loss=4.8541, Acc=0.273, 
2025-10-11 20:49:45,546 - training.trainer - INFO - Epoch 38, Step 130553: Loss=5.7045, Acc=0.174, 
2025-10-11 20:49:54,686 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.1536, Acc=0.300, 
2025-10-11 20:50:03,982 - training.trainer - INFO - Epoch 38, Step 130753: Loss=5.7105, Acc=0.263, 
2025-10-11 20:50:13,104 - training.trainer - INFO - Epoch 38, Step 130853: Loss=4.4767, Acc=0.524, 
2025-10-11 20:50:22,389 - training.trainer - INFO - Epoch 38, Step 130953: Loss=5.7760, Acc=0.364, 
2025-10-11 20:50:31,673 - training.trainer - INFO - Epoch 38, Step 131053: Loss=4.8999, Acc=0.395, 
2025-10-11 20:50:40,959 - training.trainer - INFO - Epoch 38, Step 131153: Loss=5.6903, Acc=0.280, 
2025-10-11 20:50:50,189 - training.trainer - INFO - Epoch 38, Step 131253: Loss=5.1676, Acc=0.281, 
2025-10-11 20:50:59,441 - training.trainer - INFO - Epoch 38, Step 131353: Loss=5.8671, Acc=0.246, 
2025-10-11 20:51:08,730 - training.trainer - INFO - Epoch 38, Step 131453: Loss=6.3159, Acc=0.206, 
2025-10-11 20:51:17,939 - training.trainer - INFO - Epoch 38, Step 131553: Loss=6.0756, Acc=0.268, 
2025-10-11 20:51:27,121 - training.trainer - INFO - Epoch 38, Step 131653: Loss=4.4088, Acc=0.444, 
2025-10-11 20:51:36,256 - training.trainer - INFO - Epoch 38, Step 131753: Loss=5.6388, Acc=0.232, 
2025-10-11 20:51:45,426 - training.trainer - INFO - Epoch 38, Step 131853: Loss=6.2374, Acc=0.115, 
2025-10-11 20:52:06,435 - training.trainer - INFO - Epoch 39/100 completed in 327.15s - Train Loss: 5.4011, Train Acc: 0.294, Val Loss: 5.7987, Val Acc: 0.261
2025-10-11 20:52:06,436 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-11 20:52:06,436 - training.trainer - INFO - Training completed!
2025-10-11 20:52:06,436 - __main__ - INFO - Training completed successfully!
2025-10-11 20:52:06,602 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-11 20:52:06,862 - __main__ - INFO - Process completed!
2025-10-11 20:52:19,136 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-11 20:52:19,136 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-11 20:52:19,136 - __main__ - INFO - Starting model evaluation
2025-10-11 20:52:19,994 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-11 20:58:33,512 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-11 20:58:33,529 - __main__ - INFO - Process completed!
2025-10-11 20:58:38,187 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-11 20:58:38,187 - __main__ - INFO - Configuration: configs/lsa_t_config_5.yaml
2025-10-11 20:58:38,187 - __main__ - INFO - Starting model evaluation
2025-10-11 20:58:39,180 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-11 21:54:36,190 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-11 21:54:36,208 - __main__ - INFO - Process completed!
2025-10-11 21:54:40,806 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-11 21:54:40,806 - __main__ - INFO - Configuration: configs/lsa_t_config_8.yaml
2025-10-11 21:54:40,807 - __main__ - INFO - Starting model evaluation
2025-10-11 21:54:41,618 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-11 23:37:32,780 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-11 23:37:32,800 - __main__ - INFO - Process completed!
2025-10-11 23:37:37,701 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-11 23:37:37,702 - __main__ - INFO - Configuration: configs/lsa_t_config_16.yaml
2025-10-11 23:37:37,702 - __main__ - INFO - Starting model evaluation
2025-10-11 23:37:38,499 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-12 03:38:36,429 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-12 03:38:36,446 - __main__ - INFO - Process completed!
2025-10-12 03:38:42,974 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-12 03:38:42,974 - __main__ - INFO - Configuration: configs/lsa_t_config_24.yaml
2025-10-12 03:38:42,974 - __main__ - INFO - Starting model evaluation
2025-10-12 03:38:44,480 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-12 09:08:20,454 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-12 09:08:20,470 - __main__ - INFO - Process completed!
2025-10-12 09:08:25,277 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-12 09:08:25,278 - __main__ - INFO - Configuration: configs/lsa_t_config_32.yaml
2025-10-12 09:08:25,278 - __main__ - INFO - Starting model evaluation
2025-10-12 09:08:26,253 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-12 16:25:19,106 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-12 16:25:19,122 - __main__ - INFO - Process completed!
2025-10-12 17:03:46,478 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-12 17:03:46,478 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-12 17:03:46,478 - __main__ - INFO - Starting training pipeline
2025-10-12 17:03:46,503 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-12 17:03:46,528 - __main__ - INFO - GPU: NVIDIA A30
2025-10-12 17:03:46,529 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-12 17:03:46,529 - __main__ - INFO - Loading training data...
2025-10-12 17:03:55,874 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-12 17:03:55,874 - __main__ - INFO - Processing train split...
2025-10-12 17:03:55,981 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-12 17:03:55,982 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-12 17:04:53,235 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-12 17:05:50,579 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-12 17:06:48,208 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-12 17:07:43,885 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-12 17:08:39,501 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-12 17:09:33,865 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-12 17:10:15,940 - __main__ - INFO - Processing val split...
2025-10-12 17:10:16,200 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-12 17:10:16,200 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-12 17:11:01,929 - __main__ - INFO - Processing test split...
2025-10-12 17:11:02,182 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-12 17:11:02,182 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-12 17:11:48,841 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-12 17:11:48,842 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-12 17:11:48,872 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-12 17:11:48,872 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-12 17:11:48,872 - __main__ - INFO - Creating model architecture...
2025-10-12 17:11:49,383 - __main__ - INFO - Model created successfully
2025-10-12 17:11:49,384 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-12 17:11:49,385 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-12 17:11:49,385 - __main__ - INFO - Using device: cuda
2025-10-12 17:11:49,385 - __main__ - INFO - Creating trainer...
2025-10-12 17:11:49,385 - __main__ - INFO - Moving model to cuda...
2025-10-12 17:11:49,853 - __main__ - INFO - Model moved to cuda
2025-10-12 17:11:49,853 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-12 17:11:52,453 - __main__ - INFO - Trainer created successfully
2025-10-12 17:11:52,453 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-12 17:11:52,453 - __main__ - INFO - Starting training...
2025-10-12 17:11:52,453 - __main__ - INFO - Training configuration:
2025-10-12 17:11:52,453 - __main__ - INFO -   - Epochs: 100
2025-10-12 17:11:52,454 - __main__ - INFO -   - Batch size: 2
2025-10-12 17:11:52,454 - __main__ - INFO -   - Learning rate: 3e-5
2025-10-12 17:11:52,454 - __main__ - INFO -   - Training samples: 6765
2025-10-12 17:11:52,454 - __main__ - INFO -   - Validation samples: 845
2025-10-12 17:11:52,454 - training.trainer - INFO - Starting training for 100 epochs
2025-10-12 17:11:52,455 - training.trainer - INFO - Model parameters: 20,366,432
2025-10-12 17:11:52,455 - training.trainer - INFO - Training on device: cuda
2025-10-12 17:12:07,609 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.7844, Acc=0.073, 
2025-10-12 17:12:18,838 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.3512, Acc=0.087, 
2025-10-12 17:12:29,863 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.7589, Acc=0.026, 
2025-10-12 17:12:40,789 - training.trainer - INFO - Epoch 0, Step 399: Loss=7.4184, Acc=0.111, 
2025-10-12 17:12:51,219 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.9475, Acc=0.029, 
2025-10-12 17:13:01,942 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.3506, Acc=0.136, 
2025-10-12 17:13:12,743 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.2062, Acc=0.056, 
2025-10-12 17:13:23,386 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.1899, Acc=0.190, 
2025-10-12 17:13:33,968 - training.trainer - INFO - Epoch 0, Step 899: Loss=7.2010, Acc=0.138, 
2025-10-12 17:13:44,539 - training.trainer - INFO - Epoch 0, Step 999: Loss=6.8516, Acc=0.147, 
2025-10-12 17:13:55,055 - training.trainer - INFO - Epoch 0, Step 1099: Loss=7.0760, Acc=0.172, 
2025-10-12 17:14:05,597 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.7852, Acc=0.222, 
2025-10-12 17:14:16,150 - training.trainer - INFO - Epoch 0, Step 1299: Loss=5.7099, Acc=0.267, 
2025-10-12 17:14:26,694 - training.trainer - INFO - Epoch 0, Step 1399: Loss=6.6157, Acc=0.139, 
2025-10-12 17:14:37,299 - training.trainer - INFO - Epoch 0, Step 1499: Loss=6.8930, Acc=0.114, 
2025-10-12 17:14:47,593 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.8057, Acc=0.122, 
2025-10-12 17:14:57,711 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.0070, Acc=0.294, 
2025-10-12 17:15:07,833 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.0107, Acc=0.250, 
2025-10-12 17:15:17,981 - training.trainer - INFO - Epoch 0, Step 1899: Loss=7.2618, Acc=0.105, 
2025-10-12 17:15:28,433 - training.trainer - INFO - Epoch 0, Step 1999: Loss=6.4817, Acc=0.086, 
2025-10-12 17:15:38,783 - training.trainer - INFO - Epoch 0, Step 2099: Loss=6.9802, Acc=0.094, 
2025-10-12 17:15:48,886 - training.trainer - INFO - Epoch 0, Step 2199: Loss=6.0059, Acc=0.130, 
2025-10-12 17:15:59,267 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.8579, Acc=0.111, 
2025-10-12 17:16:09,669 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.1518, Acc=0.103, 
2025-10-12 17:16:20,179 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.6747, Acc=0.083, 
2025-10-12 17:16:30,383 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.2002, Acc=0.158, 
2025-10-12 17:16:40,791 - training.trainer - INFO - Epoch 0, Step 2699: Loss=7.0127, Acc=0.097, 
2025-10-12 17:16:50,911 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.7281, Acc=0.081, 
2025-10-12 17:17:01,233 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.7723, Acc=0.140, 
2025-10-12 17:17:11,377 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.3219, Acc=0.214, 
2025-10-12 17:17:21,985 - training.trainer - INFO - Epoch 0, Step 3099: Loss=6.1146, Acc=0.261, 
2025-10-12 17:17:32,289 - training.trainer - INFO - Epoch 0, Step 3199: Loss=6.3778, Acc=0.167, 
2025-10-12 17:17:42,377 - training.trainer - INFO - Epoch 0, Step 3299: Loss=6.3358, Acc=0.148, 
2025-10-12 17:18:07,126 - training.trainer - INFO - Epoch 1/100 completed in 374.67s - Train Loss: 6.8564, Train Acc: 0.121, Val Loss: 6.4398, Val Acc: 0.159
2025-10-12 17:18:08,048 - training.trainer - INFO - New best model saved with validation loss: 6.4398
2025-10-12 17:18:08,048 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-12 17:18:18,690 - training.trainer - INFO - Epoch 1, Step 3482: Loss=6.5937, Acc=0.121, 
2025-10-12 17:18:28,857 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.3949, Acc=0.160, 
2025-10-12 17:18:39,004 - training.trainer - INFO - Epoch 1, Step 3682: Loss=5.9717, Acc=0.263, 
2025-10-12 17:18:48,923 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.3968, Acc=0.090, 
2025-10-12 17:18:59,051 - training.trainer - INFO - Epoch 1, Step 3882: Loss=6.5307, Acc=0.208, 
2025-10-12 17:19:09,272 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.6249, Acc=0.146, 
2025-10-12 17:19:19,429 - training.trainer - INFO - Epoch 1, Step 4082: Loss=6.7171, Acc=0.130, 
2025-10-12 17:19:29,355 - training.trainer - INFO - Epoch 1, Step 4182: Loss=7.1044, Acc=0.111, 
2025-10-12 17:19:39,313 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.4774, Acc=0.118, 
2025-10-12 17:19:49,407 - training.trainer - INFO - Epoch 1, Step 4382: Loss=6.1936, Acc=0.174, 
2025-10-12 17:19:59,386 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.4886, Acc=0.231, 
2025-10-12 17:20:09,391 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.5523, Acc=0.149, 
2025-10-12 17:20:19,531 - training.trainer - INFO - Epoch 1, Step 4682: Loss=5.7261, Acc=0.208, 
2025-10-12 17:20:29,494 - training.trainer - INFO - Epoch 1, Step 4782: Loss=5.8954, Acc=0.192, 
2025-10-12 17:20:39,583 - training.trainer - INFO - Epoch 1, Step 4882: Loss=6.2417, Acc=0.218, 
2025-10-12 17:20:49,616 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.8489, Acc=0.148, 
2025-10-12 17:20:59,560 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.2306, Acc=0.200, 
2025-10-12 17:21:09,609 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.3699, Acc=0.188, 
2025-10-12 17:21:19,513 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.8435, Acc=0.060, 
2025-10-12 17:21:29,568 - training.trainer - INFO - Epoch 1, Step 5382: Loss=6.9170, Acc=0.130, 
2025-10-12 17:21:39,697 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.6328, Acc=0.146, 
2025-10-12 17:21:49,747 - training.trainer - INFO - Epoch 1, Step 5582: Loss=6.0605, Acc=0.161, 
2025-10-12 17:21:59,733 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.5403, Acc=0.167, 
2025-10-12 17:22:09,828 - training.trainer - INFO - Epoch 1, Step 5782: Loss=5.5693, Acc=0.217, 
2025-10-12 17:22:19,841 - training.trainer - INFO - Epoch 1, Step 5882: Loss=6.5381, Acc=0.159, 
2025-10-12 17:22:29,938 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.7209, Acc=0.109, 
2025-10-12 17:22:39,963 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.1085, Acc=0.138, 
2025-10-12 17:22:50,096 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.3547, Acc=0.125, 
2025-10-12 17:23:00,190 - training.trainer - INFO - Epoch 1, Step 6282: Loss=5.9409, Acc=0.238, 
2025-10-12 17:23:10,248 - training.trainer - INFO - Epoch 1, Step 6382: Loss=5.8095, Acc=0.200, 
2025-10-12 17:23:20,450 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.2044, Acc=0.177, 
2025-10-12 17:23:30,539 - training.trainer - INFO - Epoch 1, Step 6582: Loss=6.2251, Acc=0.125, 
2025-10-12 17:23:40,714 - training.trainer - INFO - Epoch 1, Step 6682: Loss=5.6571, Acc=0.154, 
2025-10-12 17:24:05,169 - training.trainer - INFO - Epoch 2/100 completed in 357.12s - Train Loss: 6.3679, Train Acc: 0.161, Val Loss: 6.2376, Val Acc: 0.167
2025-10-12 17:24:06,026 - training.trainer - INFO - New best model saved with validation loss: 6.2376
2025-10-12 17:24:06,027 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-12 17:24:16,479 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.7635, Acc=0.147, 
2025-10-12 17:24:26,430 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.5125, Acc=0.154, 
2025-10-12 17:24:36,651 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.3648, Acc=0.119, 
2025-10-12 17:24:46,679 - training.trainer - INFO - Epoch 2, Step 7165: Loss=6.3644, Acc=0.149, 
2025-10-12 17:24:56,770 - training.trainer - INFO - Epoch 2, Step 7265: Loss=6.1019, Acc=0.222, 
2025-10-12 17:25:06,898 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.3875, Acc=0.121, 
2025-10-12 17:25:17,322 - training.trainer - INFO - Epoch 2, Step 7465: Loss=6.1058, Acc=0.256, 
2025-10-12 17:25:27,532 - training.trainer - INFO - Epoch 2, Step 7565: Loss=6.4732, Acc=0.243, 
2025-10-12 17:25:37,577 - training.trainer - INFO - Epoch 2, Step 7665: Loss=5.3363, Acc=0.214, 
2025-10-12 17:25:47,695 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.1966, Acc=0.154, 
2025-10-12 17:25:57,800 - training.trainer - INFO - Epoch 2, Step 7865: Loss=6.8115, Acc=0.107, 
2025-10-12 17:26:08,028 - training.trainer - INFO - Epoch 2, Step 7965: Loss=6.6769, Acc=0.077, 
2025-10-12 17:26:18,164 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.4534, Acc=0.102, 
2025-10-12 17:26:28,388 - training.trainer - INFO - Epoch 2, Step 8165: Loss=6.1409, Acc=0.111, 
2025-10-12 17:26:38,573 - training.trainer - INFO - Epoch 2, Step 8265: Loss=5.9269, Acc=0.190, 
2025-10-12 17:26:48,690 - training.trainer - INFO - Epoch 2, Step 8365: Loss=6.8350, Acc=0.114, 
2025-10-12 17:26:58,930 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.9532, Acc=0.096, 
2025-10-12 17:27:09,205 - training.trainer - INFO - Epoch 2, Step 8565: Loss=5.5716, Acc=0.227, 
2025-10-12 17:27:19,418 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.1798, Acc=0.113, 
2025-10-12 17:27:29,761 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.8524, Acc=0.133, 
2025-10-12 17:27:39,902 - training.trainer - INFO - Epoch 2, Step 8865: Loss=5.9150, Acc=0.194, 
2025-10-12 17:27:50,027 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.3321, Acc=0.136, 
2025-10-12 17:28:00,117 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.2503, Acc=0.333, 
2025-10-12 17:28:10,122 - training.trainer - INFO - Epoch 2, Step 9165: Loss=5.9955, Acc=0.208, 
2025-10-12 17:28:20,210 - training.trainer - INFO - Epoch 2, Step 9265: Loss=5.2952, Acc=0.208, 
2025-10-12 17:28:30,439 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.6097, Acc=0.250, 
2025-10-12 17:28:40,642 - training.trainer - INFO - Epoch 2, Step 9465: Loss=6.0257, Acc=0.158, 
2025-10-12 17:28:50,713 - training.trainer - INFO - Epoch 2, Step 9565: Loss=7.0264, Acc=0.113, 
2025-10-12 17:29:00,880 - training.trainer - INFO - Epoch 2, Step 9665: Loss=6.2530, Acc=0.148, 
2025-10-12 17:29:11,007 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.2621, Acc=0.147, 
2025-10-12 17:29:21,088 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.9881, Acc=0.112, 
2025-10-12 17:29:31,150 - training.trainer - INFO - Epoch 2, Step 9965: Loss=5.9695, Acc=0.250, 
2025-10-12 17:29:41,325 - training.trainer - INFO - Epoch 2, Step 10065: Loss=6.4967, Acc=0.148, 
2025-10-12 17:30:05,381 - training.trainer - INFO - Epoch 3/100 completed in 359.35s - Train Loss: 6.2451, Train Acc: 0.169, Val Loss: 6.1921, Val Acc: 0.171
2025-10-12 17:30:06,256 - training.trainer - INFO - New best model saved with validation loss: 6.1921
2025-10-12 17:30:06,256 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-10-12 17:30:16,753 - training.trainer - INFO - Epoch 3, Step 10248: Loss=6.0351, Acc=0.167, 
2025-10-12 17:30:26,842 - training.trainer - INFO - Epoch 3, Step 10348: Loss=6.5248, Acc=0.229, 
2025-10-12 17:30:36,960 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.6176, Acc=0.082, 
2025-10-12 17:30:47,183 - training.trainer - INFO - Epoch 3, Step 10548: Loss=6.1017, Acc=0.179, 
2025-10-12 17:30:57,313 - training.trainer - INFO - Epoch 3, Step 10648: Loss=6.5511, Acc=0.111, 
2025-10-12 17:31:07,432 - training.trainer - INFO - Epoch 3, Step 10748: Loss=6.4035, Acc=0.200, 
2025-10-12 17:31:17,628 - training.trainer - INFO - Epoch 3, Step 10848: Loss=6.6290, Acc=0.105, 
2025-10-12 17:31:27,948 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.0066, Acc=0.192, 
2025-10-12 17:31:38,183 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.6429, Acc=0.080, 
2025-10-12 17:31:48,302 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.7284, Acc=0.146, 
2025-10-12 17:31:58,596 - training.trainer - INFO - Epoch 3, Step 11248: Loss=6.0517, Acc=0.241, 
2025-10-12 17:32:08,691 - training.trainer - INFO - Epoch 3, Step 11348: Loss=5.9053, Acc=0.148, 
2025-10-12 17:32:18,884 - training.trainer - INFO - Epoch 3, Step 11448: Loss=6.1602, Acc=0.113, 
2025-10-12 17:32:29,059 - training.trainer - INFO - Epoch 3, Step 11548: Loss=6.4295, Acc=0.102, 
2025-10-12 17:32:39,238 - training.trainer - INFO - Epoch 3, Step 11648: Loss=6.3138, Acc=0.132, 
2025-10-12 17:32:49,392 - training.trainer - INFO - Epoch 3, Step 11748: Loss=5.8441, Acc=0.143, 
2025-10-12 17:32:59,510 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.9869, Acc=0.167, 
2025-10-12 17:33:09,678 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.0110, Acc=0.118, 
2025-10-12 17:33:19,707 - training.trainer - INFO - Epoch 3, Step 12048: Loss=6.2866, Acc=0.114, 
2025-10-12 17:33:30,017 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.4840, Acc=0.250, 
2025-10-12 17:33:40,248 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.3900, Acc=0.250, 
2025-10-12 17:33:50,449 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.0424, Acc=0.300, 
2025-10-12 17:34:00,556 - training.trainer - INFO - Epoch 3, Step 12448: Loss=6.2170, Acc=0.120, 
2025-10-12 17:34:10,822 - training.trainer - INFO - Epoch 3, Step 12548: Loss=6.6769, Acc=0.214, 
2025-10-12 17:34:20,860 - training.trainer - INFO - Epoch 3, Step 12648: Loss=6.1760, Acc=0.118, 
2025-10-12 17:34:31,117 - training.trainer - INFO - Epoch 3, Step 12748: Loss=6.1102, Acc=0.108, 
2025-10-12 17:34:41,299 - training.trainer - INFO - Epoch 3, Step 12848: Loss=5.6930, Acc=0.129, 
2025-10-12 17:34:51,481 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.7252, Acc=0.097, 
2025-10-12 17:35:01,485 - training.trainer - INFO - Epoch 3, Step 13048: Loss=6.2047, Acc=0.191, 
2025-10-12 17:35:11,723 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.2810, Acc=0.143, 
2025-10-12 17:35:21,817 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.1682, Acc=0.162, 
2025-10-12 17:35:31,923 - training.trainer - INFO - Epoch 3, Step 13348: Loss=6.4236, Acc=0.200, 
2025-10-12 17:35:42,054 - training.trainer - INFO - Epoch 3, Step 13448: Loss=5.9421, Acc=0.176, 
2025-10-12 17:36:05,914 - training.trainer - INFO - Epoch 4/100 completed in 359.66s - Train Loss: 6.1835, Train Acc: 0.176, Val Loss: 6.1059, Val Acc: 0.184
2025-10-12 17:36:06,931 - training.trainer - INFO - New best model saved with validation loss: 6.1059
2025-10-12 17:36:06,931 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-10-12 17:36:17,373 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.0883, Acc=0.133, 
2025-10-12 17:36:27,568 - training.trainer - INFO - Epoch 4, Step 13731: Loss=6.2522, Acc=0.189, 
2025-10-12 17:36:37,584 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.1727, Acc=0.135, 
2025-10-12 17:36:47,733 - training.trainer - INFO - Epoch 4, Step 13931: Loss=6.1856, Acc=0.172, 
2025-10-12 17:36:57,610 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.9144, Acc=0.412, 
2025-10-12 17:37:07,495 - training.trainer - INFO - Epoch 4, Step 14131: Loss=5.6196, Acc=0.304, 
2025-10-12 17:37:17,411 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.0941, Acc=0.192, 
2025-10-12 17:37:27,593 - training.trainer - INFO - Epoch 4, Step 14331: Loss=4.5564, Acc=0.400, 
2025-10-12 17:37:37,783 - training.trainer - INFO - Epoch 4, Step 14431: Loss=6.4995, Acc=0.111, 
2025-10-12 17:37:47,975 - training.trainer - INFO - Epoch 4, Step 14531: Loss=5.6481, Acc=0.207, 
2025-10-12 17:37:58,130 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.3291, Acc=0.125, 
2025-10-12 17:38:08,292 - training.trainer - INFO - Epoch 4, Step 14731: Loss=5.2893, Acc=0.162, 
2025-10-12 17:38:18,466 - training.trainer - INFO - Epoch 4, Step 14831: Loss=6.0216, Acc=0.111, 
2025-10-12 17:38:28,582 - training.trainer - INFO - Epoch 4, Step 14931: Loss=6.1103, Acc=0.200, 
2025-10-12 17:38:38,714 - training.trainer - INFO - Epoch 4, Step 15031: Loss=4.7999, Acc=0.227, 
2025-10-12 17:38:48,606 - training.trainer - INFO - Epoch 4, Step 15131: Loss=5.7962, Acc=0.241, 
2025-10-12 17:38:58,589 - training.trainer - INFO - Epoch 4, Step 15231: Loss=5.6471, Acc=0.154, 
2025-10-12 17:39:08,782 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.4817, Acc=0.161, 
2025-10-12 17:39:18,766 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.1181, Acc=0.147, 
2025-10-12 17:39:28,798 - training.trainer - INFO - Epoch 4, Step 15531: Loss=5.3969, Acc=0.280, 
2025-10-12 17:39:38,843 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.7780, Acc=0.133, 
2025-10-12 17:39:48,791 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.6959, Acc=0.122, 
2025-10-12 17:39:58,801 - training.trainer - INFO - Epoch 4, Step 15831: Loss=7.0311, Acc=0.149, 
2025-10-12 17:40:08,699 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.1813, Acc=0.250, 
2025-10-12 17:40:18,730 - training.trainer - INFO - Epoch 4, Step 16031: Loss=6.4241, Acc=0.154, 
2025-10-12 17:40:28,675 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.3397, Acc=0.182, 
2025-10-12 17:40:38,716 - training.trainer - INFO - Epoch 4, Step 16231: Loss=6.2444, Acc=0.139, 
2025-10-12 17:40:48,669 - training.trainer - INFO - Epoch 4, Step 16331: Loss=6.2923, Acc=0.159, 
2025-10-12 17:40:58,658 - training.trainer - INFO - Epoch 4, Step 16431: Loss=6.5092, Acc=0.186, 
2025-10-12 17:41:08,756 - training.trainer - INFO - Epoch 4, Step 16531: Loss=5.1360, Acc=0.222, 
2025-10-12 17:41:18,955 - training.trainer - INFO - Epoch 4, Step 16631: Loss=6.5825, Acc=0.116, 
2025-10-12 17:41:29,120 - training.trainer - INFO - Epoch 4, Step 16731: Loss=5.6650, Acc=0.154, 
2025-10-12 17:41:39,087 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.8613, Acc=0.179, 
2025-10-12 17:42:02,931 - training.trainer - INFO - Epoch 5/100 completed in 356.00s - Train Loss: 6.1387, Train Acc: 0.183, Val Loss: 6.0865, Val Acc: 0.191
2025-10-12 17:42:03,408 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-12 17:42:04,393 - training.trainer - INFO - New best model saved with validation loss: 6.0865
2025-10-12 17:42:04,394 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-12 17:42:14,822 - training.trainer - INFO - Epoch 5, Step 17014: Loss=6.3274, Acc=0.125, 
2025-10-12 17:42:24,894 - training.trainer - INFO - Epoch 5, Step 17114: Loss=5.3691, Acc=0.235, 
2025-10-12 17:42:35,003 - training.trainer - INFO - Epoch 5, Step 17214: Loss=5.9408, Acc=0.167, 
2025-10-12 17:42:45,126 - training.trainer - INFO - Epoch 5, Step 17314: Loss=5.9524, Acc=0.235, 
2025-10-12 17:42:55,228 - training.trainer - INFO - Epoch 5, Step 17414: Loss=6.0938, Acc=0.167, 
2025-10-12 17:43:05,258 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.3153, Acc=0.135, 
2025-10-12 17:43:15,344 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.0598, Acc=0.184, 
2025-10-12 17:43:25,335 - training.trainer - INFO - Epoch 5, Step 17714: Loss=6.7371, Acc=0.107, 
2025-10-12 17:43:35,471 - training.trainer - INFO - Epoch 5, Step 17814: Loss=5.7176, Acc=0.214, 
2025-10-12 17:43:45,638 - training.trainer - INFO - Epoch 5, Step 17914: Loss=5.3401, Acc=0.333, 
2025-10-12 17:43:55,710 - training.trainer - INFO - Epoch 5, Step 18014: Loss=7.0220, Acc=0.163, 
2025-10-12 17:44:05,748 - training.trainer - INFO - Epoch 5, Step 18114: Loss=5.9327, Acc=0.312, 
2025-10-12 17:44:15,792 - training.trainer - INFO - Epoch 5, Step 18214: Loss=7.0992, Acc=0.091, 
2025-10-12 17:44:25,823 - training.trainer - INFO - Epoch 5, Step 18314: Loss=5.7290, Acc=0.143, 
2025-10-12 17:44:35,963 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.6457, Acc=0.194, 
2025-10-12 17:44:46,100 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.4608, Acc=0.214, 
2025-10-12 17:44:56,257 - training.trainer - INFO - Epoch 5, Step 18614: Loss=5.9778, Acc=0.193, 
2025-10-12 17:45:06,478 - training.trainer - INFO - Epoch 5, Step 18714: Loss=5.7927, Acc=0.205, 
2025-10-12 17:45:16,514 - training.trainer - INFO - Epoch 5, Step 18814: Loss=5.4665, Acc=0.316, 
2025-10-12 17:45:26,659 - training.trainer - INFO - Epoch 5, Step 18914: Loss=5.6628, Acc=0.196, 
2025-10-12 17:45:36,883 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.3787, Acc=0.183, 
2025-10-12 17:45:46,909 - training.trainer - INFO - Epoch 5, Step 19114: Loss=6.5637, Acc=0.167, 
2025-10-12 17:45:56,883 - training.trainer - INFO - Epoch 5, Step 19214: Loss=6.4657, Acc=0.173, 
2025-10-12 17:46:06,931 - training.trainer - INFO - Epoch 5, Step 19314: Loss=5.8985, Acc=0.206, 
2025-10-12 17:46:17,030 - training.trainer - INFO - Epoch 5, Step 19414: Loss=5.7838, Acc=0.196, 
2025-10-12 17:46:27,283 - training.trainer - INFO - Epoch 5, Step 19514: Loss=6.5567, Acc=0.082, 
2025-10-12 17:46:37,445 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.1055, Acc=0.212, 
2025-10-12 17:46:47,863 - training.trainer - INFO - Epoch 5, Step 19714: Loss=4.0957, Acc=0.562, 
2025-10-12 17:46:58,014 - training.trainer - INFO - Epoch 5, Step 19814: Loss=5.7645, Acc=0.261, 
2025-10-12 17:47:08,252 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.8659, Acc=0.188, 
2025-10-12 17:47:18,371 - training.trainer - INFO - Epoch 5, Step 20014: Loss=6.4125, Acc=0.115, 
2025-10-12 17:47:28,511 - training.trainer - INFO - Epoch 5, Step 20114: Loss=4.6177, Acc=0.318, 
2025-10-12 17:47:38,658 - training.trainer - INFO - Epoch 5, Step 20214: Loss=6.0231, Acc=0.185, 
2025-10-12 17:48:02,576 - training.trainer - INFO - Epoch 6/100 completed in 358.18s - Train Loss: 6.0940, Train Acc: 0.188, Val Loss: 6.0402, Val Acc: 0.189
2025-10-12 17:48:03,478 - training.trainer - INFO - New best model saved with validation loss: 6.0402
2025-10-12 17:48:03,478 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-10-12 17:48:14,221 - training.trainer - INFO - Epoch 6, Step 20397: Loss=5.9573, Acc=0.122, 
2025-10-12 17:48:24,490 - training.trainer - INFO - Epoch 6, Step 20497: Loss=5.8420, Acc=0.237, 
2025-10-12 17:48:34,595 - training.trainer - INFO - Epoch 6, Step 20597: Loss=6.7915, Acc=0.154, 
2025-10-12 17:48:44,740 - training.trainer - INFO - Epoch 6, Step 20697: Loss=5.6959, Acc=0.322, 
2025-10-12 17:48:55,021 - training.trainer - INFO - Epoch 6, Step 20797: Loss=5.9203, Acc=0.200, 
2025-10-12 17:49:05,223 - training.trainer - INFO - Epoch 6, Step 20897: Loss=6.3095, Acc=0.189, 
2025-10-12 17:49:15,408 - training.trainer - INFO - Epoch 6, Step 20997: Loss=5.6122, Acc=0.250, 
2025-10-12 17:49:25,683 - training.trainer - INFO - Epoch 6, Step 21097: Loss=5.5433, Acc=0.300, 
2025-10-12 17:49:35,803 - training.trainer - INFO - Epoch 6, Step 21197: Loss=5.9638, Acc=0.250, 
2025-10-12 17:49:46,008 - training.trainer - INFO - Epoch 6, Step 21297: Loss=5.6592, Acc=0.267, 
2025-10-12 17:49:56,207 - training.trainer - INFO - Epoch 6, Step 21397: Loss=6.7461, Acc=0.233, 
2025-10-12 17:50:06,310 - training.trainer - INFO - Epoch 6, Step 21497: Loss=6.1147, Acc=0.161, 
2025-10-12 17:50:16,428 - training.trainer - INFO - Epoch 6, Step 21597: Loss=5.8291, Acc=0.250, 
2025-10-12 17:50:26,396 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.3951, Acc=0.135, 
2025-10-12 17:50:36,433 - training.trainer - INFO - Epoch 6, Step 21797: Loss=6.2745, Acc=0.169, 
2025-10-12 17:50:46,667 - training.trainer - INFO - Epoch 6, Step 21897: Loss=6.1420, Acc=0.205, 
2025-10-12 17:50:56,871 - training.trainer - INFO - Epoch 6, Step 21997: Loss=5.5131, Acc=0.222, 
2025-10-12 17:51:07,216 - training.trainer - INFO - Epoch 6, Step 22097: Loss=6.5491, Acc=0.185, 
2025-10-12 17:51:17,475 - training.trainer - INFO - Epoch 6, Step 22197: Loss=5.2553, Acc=0.375, 
2025-10-12 17:51:27,683 - training.trainer - INFO - Epoch 6, Step 22297: Loss=6.2953, Acc=0.150, 
2025-10-12 17:51:37,828 - training.trainer - INFO - Epoch 6, Step 22397: Loss=5.6174, Acc=0.179, 
2025-10-12 17:51:48,057 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.3832, Acc=0.138, 
2025-10-12 17:51:58,269 - training.trainer - INFO - Epoch 6, Step 22597: Loss=6.0830, Acc=0.178, 
2025-10-12 17:52:08,484 - training.trainer - INFO - Epoch 6, Step 22697: Loss=5.8832, Acc=0.188, 
2025-10-12 17:52:18,414 - training.trainer - INFO - Epoch 6, Step 22797: Loss=6.6590, Acc=0.111, 
2025-10-12 17:52:28,437 - training.trainer - INFO - Epoch 6, Step 22897: Loss=6.1960, Acc=0.234, 
2025-10-12 17:52:38,543 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.2262, Acc=0.109, 
2025-10-12 17:52:48,456 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.5534, Acc=0.155, 
2025-10-12 17:52:58,615 - training.trainer - INFO - Epoch 6, Step 23197: Loss=5.8086, Acc=0.250, 
2025-10-12 17:53:08,720 - training.trainer - INFO - Epoch 6, Step 23297: Loss=6.0000, Acc=0.182, 
2025-10-12 17:53:18,904 - training.trainer - INFO - Epoch 6, Step 23397: Loss=6.1708, Acc=0.154, 
2025-10-12 17:53:28,943 - training.trainer - INFO - Epoch 6, Step 23497: Loss=5.3585, Acc=0.233, 
2025-10-12 17:53:39,027 - training.trainer - INFO - Epoch 6, Step 23597: Loss=5.6994, Acc=0.119, 
2025-10-12 17:54:02,806 - training.trainer - INFO - Epoch 7/100 completed in 359.33s - Train Loss: 6.0611, Train Acc: 0.193, Val Loss: 6.0131, Val Acc: 0.201
2025-10-12 17:54:03,706 - training.trainer - INFO - New best model saved with validation loss: 6.0131
2025-10-12 17:54:03,706 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-10-12 17:54:14,482 - training.trainer - INFO - Epoch 7, Step 23780: Loss=5.1702, Acc=0.257, 
2025-10-12 17:54:24,738 - training.trainer - INFO - Epoch 7, Step 23880: Loss=6.9733, Acc=0.107, 
2025-10-12 17:54:35,009 - training.trainer - INFO - Epoch 7, Step 23980: Loss=6.1848, Acc=0.175, 
2025-10-12 17:54:45,154 - training.trainer - INFO - Epoch 7, Step 24080: Loss=6.1573, Acc=0.188, 
2025-10-12 17:54:55,308 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.8655, Acc=0.262, 
2025-10-12 17:55:05,527 - training.trainer - INFO - Epoch 7, Step 24280: Loss=5.7654, Acc=0.200, 
2025-10-12 17:55:15,896 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.5952, Acc=0.120, 
2025-10-12 17:55:26,143 - training.trainer - INFO - Epoch 7, Step 24480: Loss=5.2602, Acc=0.292, 
2025-10-12 17:55:36,267 - training.trainer - INFO - Epoch 7, Step 24580: Loss=5.1106, Acc=0.389, 
2025-10-12 17:55:46,402 - training.trainer - INFO - Epoch 7, Step 24680: Loss=5.8537, Acc=0.188, 
2025-10-12 17:55:56,260 - training.trainer - INFO - Epoch 7, Step 24780: Loss=6.4094, Acc=0.083, 
2025-10-12 17:56:06,194 - training.trainer - INFO - Epoch 7, Step 24880: Loss=6.5431, Acc=0.143, 
2025-10-12 17:56:16,059 - training.trainer - INFO - Epoch 7, Step 24980: Loss=5.7013, Acc=0.294, 
2025-10-12 17:56:26,246 - training.trainer - INFO - Epoch 7, Step 25080: Loss=5.9069, Acc=0.263, 
2025-10-12 17:56:36,433 - training.trainer - INFO - Epoch 7, Step 25180: Loss=6.5278, Acc=0.093, 
2025-10-12 17:56:46,636 - training.trainer - INFO - Epoch 7, Step 25280: Loss=6.0527, Acc=0.172, 
2025-10-12 17:56:56,821 - training.trainer - INFO - Epoch 7, Step 25380: Loss=4.5054, Acc=0.222, 
2025-10-12 17:57:06,637 - training.trainer - INFO - Epoch 7, Step 25480: Loss=6.4784, Acc=0.171, 
2025-10-12 17:57:15,429 - training.trainer - INFO - Epoch 7, Step 25580: Loss=6.1738, Acc=0.135, 
2025-10-12 17:57:24,895 - training.trainer - INFO - Epoch 7, Step 25680: Loss=6.8299, Acc=0.188, 
2025-10-12 17:57:34,322 - training.trainer - INFO - Epoch 7, Step 25780: Loss=5.6194, Acc=0.190, 
2025-10-12 17:57:44,550 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.8327, Acc=0.087, 
2025-10-12 17:57:54,639 - training.trainer - INFO - Epoch 7, Step 25980: Loss=5.8069, Acc=0.235, 
2025-10-12 17:58:04,878 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.4010, Acc=0.214, 
2025-10-12 17:58:15,077 - training.trainer - INFO - Epoch 7, Step 26180: Loss=6.2396, Acc=0.172, 
2025-10-12 17:58:25,321 - training.trainer - INFO - Epoch 7, Step 26280: Loss=5.9540, Acc=0.148, 
2025-10-12 17:58:35,552 - training.trainer - INFO - Epoch 7, Step 26380: Loss=6.1783, Acc=0.243, 
2025-10-12 17:58:45,766 - training.trainer - INFO - Epoch 7, Step 26480: Loss=5.4372, Acc=0.241, 
2025-10-12 17:58:55,771 - training.trainer - INFO - Epoch 7, Step 26580: Loss=6.3234, Acc=0.194, 
2025-10-12 17:59:05,815 - training.trainer - INFO - Epoch 7, Step 26680: Loss=5.9659, Acc=0.149, 
2025-10-12 17:59:15,937 - training.trainer - INFO - Epoch 7, Step 26780: Loss=5.3256, Acc=0.292, 
2025-10-12 17:59:26,103 - training.trainer - INFO - Epoch 7, Step 26880: Loss=6.4836, Acc=0.109, 
2025-10-12 17:59:36,238 - training.trainer - INFO - Epoch 7, Step 26980: Loss=5.3240, Acc=0.200, 
2025-10-12 17:59:59,793 - training.trainer - INFO - Epoch 8/100 completed in 356.09s - Train Loss: 6.0280, Train Acc: 0.198, Val Loss: 5.9736, Val Acc: 0.202
2025-10-12 18:00:00,675 - training.trainer - INFO - New best model saved with validation loss: 5.9736
2025-10-12 18:00:00,675 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-10-12 18:00:11,514 - training.trainer - INFO - Epoch 8, Step 27163: Loss=5.7056, Acc=0.240, 
2025-10-12 18:00:21,808 - training.trainer - INFO - Epoch 8, Step 27263: Loss=5.8191, Acc=0.238, 
2025-10-12 18:00:31,966 - training.trainer - INFO - Epoch 8, Step 27363: Loss=5.7738, Acc=0.219, 
2025-10-12 18:00:42,199 - training.trainer - INFO - Epoch 8, Step 27463: Loss=4.9815, Acc=0.273, 
2025-10-12 18:00:52,261 - training.trainer - INFO - Epoch 8, Step 27563: Loss=6.5113, Acc=0.152, 
2025-10-12 18:01:02,330 - training.trainer - INFO - Epoch 8, Step 27663: Loss=5.9333, Acc=0.160, 
2025-10-12 18:01:12,464 - training.trainer - INFO - Epoch 8, Step 27763: Loss=3.8698, Acc=0.357, 
2025-10-12 18:01:22,593 - training.trainer - INFO - Epoch 8, Step 27863: Loss=7.0648, Acc=0.208, 
2025-10-12 18:01:32,683 - training.trainer - INFO - Epoch 8, Step 27963: Loss=5.7779, Acc=0.152, 
2025-10-12 18:01:42,816 - training.trainer - INFO - Epoch 8, Step 28063: Loss=5.6679, Acc=0.160, 
2025-10-12 18:01:52,959 - training.trainer - INFO - Epoch 8, Step 28163: Loss=6.0634, Acc=0.176, 
2025-10-12 18:02:02,998 - training.trainer - INFO - Epoch 8, Step 28263: Loss=6.9270, Acc=0.121, 
2025-10-12 18:02:13,101 - training.trainer - INFO - Epoch 8, Step 28363: Loss=5.8761, Acc=0.211, 
2025-10-12 18:02:23,106 - training.trainer - INFO - Epoch 8, Step 28463: Loss=6.2126, Acc=0.160, 
2025-10-12 18:02:33,230 - training.trainer - INFO - Epoch 8, Step 28563: Loss=6.8392, Acc=0.194, 
2025-10-12 18:02:43,177 - training.trainer - INFO - Epoch 8, Step 28663: Loss=5.3389, Acc=0.333, 
2025-10-12 18:02:53,181 - training.trainer - INFO - Epoch 8, Step 28763: Loss=6.2103, Acc=0.098, 
2025-10-12 18:03:03,324 - training.trainer - INFO - Epoch 8, Step 28863: Loss=5.9546, Acc=0.192, 
2025-10-12 18:03:13,367 - training.trainer - INFO - Epoch 8, Step 28963: Loss=5.9265, Acc=0.258, 
2025-10-12 18:03:23,275 - training.trainer - INFO - Epoch 8, Step 29063: Loss=6.3441, Acc=0.212, 
2025-10-12 18:03:33,280 - training.trainer - INFO - Epoch 8, Step 29163: Loss=5.2660, Acc=0.214, 
2025-10-12 18:03:43,420 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.0239, Acc=0.138, 
2025-10-12 18:03:53,460 - training.trainer - INFO - Epoch 8, Step 29363: Loss=5.8842, Acc=0.240, 
2025-10-12 18:04:03,461 - training.trainer - INFO - Epoch 8, Step 29463: Loss=6.5331, Acc=0.167, 
2025-10-12 18:04:13,603 - training.trainer - INFO - Epoch 8, Step 29563: Loss=5.8923, Acc=0.250, 
2025-10-12 18:04:23,582 - training.trainer - INFO - Epoch 8, Step 29663: Loss=6.2010, Acc=0.250, 
2025-10-12 18:04:33,546 - training.trainer - INFO - Epoch 8, Step 29763: Loss=6.0252, Acc=0.175, 
2025-10-12 18:04:43,555 - training.trainer - INFO - Epoch 8, Step 29863: Loss=5.9309, Acc=0.206, 
2025-10-12 18:04:53,585 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.6683, Acc=0.138, 
2025-10-12 18:05:03,554 - training.trainer - INFO - Epoch 8, Step 30063: Loss=5.0868, Acc=0.269, 
2025-10-12 18:05:13,619 - training.trainer - INFO - Epoch 8, Step 30163: Loss=6.9225, Acc=0.150, 
2025-10-12 18:05:24,076 - training.trainer - INFO - Epoch 8, Step 30263: Loss=6.9429, Acc=0.080, 
2025-10-12 18:05:34,405 - training.trainer - INFO - Epoch 8, Step 30363: Loss=5.4801, Acc=0.192, 
2025-10-12 18:05:56,287 - training.trainer - INFO - Epoch 9/100 completed in 355.61s - Train Loss: 5.9895, Train Acc: 0.204, Val Loss: 5.9538, Val Acc: 0.209
2025-10-12 18:05:57,092 - training.trainer - INFO - New best model saved with validation loss: 5.9538
2025-10-12 18:05:57,092 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-10-12 18:06:06,242 - training.trainer - INFO - Epoch 9, Step 30546: Loss=6.4287, Acc=0.140, 
2025-10-12 18:06:14,910 - training.trainer - INFO - Epoch 9, Step 30646: Loss=5.4232, Acc=0.176, 
2025-10-12 18:06:23,452 - training.trainer - INFO - Epoch 9, Step 30746: Loss=6.3349, Acc=0.186, 
2025-10-12 18:06:32,048 - training.trainer - INFO - Epoch 9, Step 30846: Loss=5.9077, Acc=0.180, 
2025-10-12 18:06:41,269 - training.trainer - INFO - Epoch 9, Step 30946: Loss=5.5371, Acc=0.183, 
2025-10-12 18:06:51,280 - training.trainer - INFO - Epoch 9, Step 31046: Loss=6.2582, Acc=0.238, 
2025-10-12 18:07:01,413 - training.trainer - INFO - Epoch 9, Step 31146: Loss=6.1528, Acc=0.239, 
2025-10-12 18:07:11,420 - training.trainer - INFO - Epoch 9, Step 31246: Loss=5.6255, Acc=0.250, 
2025-10-12 18:07:21,704 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.2922, Acc=0.083, 
2025-10-12 18:07:32,075 - training.trainer - INFO - Epoch 9, Step 31446: Loss=6.1068, Acc=0.174, 
2025-10-12 18:07:42,354 - training.trainer - INFO - Epoch 9, Step 31546: Loss=6.3148, Acc=0.182, 
2025-10-12 18:07:52,512 - training.trainer - INFO - Epoch 9, Step 31646: Loss=6.0698, Acc=0.231, 
2025-10-12 18:08:03,034 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.2600, Acc=0.303, 
2025-10-12 18:08:13,411 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.6826, Acc=0.140, 
2025-10-12 18:08:23,757 - training.trainer - INFO - Epoch 9, Step 31946: Loss=5.9607, Acc=0.175, 
2025-10-12 18:08:33,757 - training.trainer - INFO - Epoch 9, Step 32046: Loss=5.5141, Acc=0.282, 
2025-10-12 18:08:43,854 - training.trainer - INFO - Epoch 9, Step 32146: Loss=5.8322, Acc=0.152, 
2025-10-12 18:08:54,202 - training.trainer - INFO - Epoch 9, Step 32246: Loss=6.4022, Acc=0.171, 
2025-10-12 18:09:04,350 - training.trainer - INFO - Epoch 9, Step 32346: Loss=4.9458, Acc=0.306, 
2025-10-12 18:09:14,460 - training.trainer - INFO - Epoch 9, Step 32446: Loss=5.7017, Acc=0.227, 
2025-10-12 18:09:24,639 - training.trainer - INFO - Epoch 9, Step 32546: Loss=6.2881, Acc=0.200, 
2025-10-12 18:09:35,019 - training.trainer - INFO - Epoch 9, Step 32646: Loss=5.5724, Acc=0.154, 
2025-10-12 18:09:45,219 - training.trainer - INFO - Epoch 9, Step 32746: Loss=6.6536, Acc=0.179, 
2025-10-12 18:09:55,224 - training.trainer - INFO - Epoch 9, Step 32846: Loss=6.9364, Acc=0.205, 
2025-10-12 18:10:05,535 - training.trainer - INFO - Epoch 9, Step 32946: Loss=5.1890, Acc=0.304, 
2025-10-12 18:10:15,939 - training.trainer - INFO - Epoch 9, Step 33046: Loss=6.4171, Acc=0.206, 
2025-10-12 18:10:26,130 - training.trainer - INFO - Epoch 9, Step 33146: Loss=5.6875, Acc=0.216, 
2025-10-12 18:10:36,323 - training.trainer - INFO - Epoch 9, Step 33246: Loss=6.4001, Acc=0.100, 
2025-10-12 18:10:46,674 - training.trainer - INFO - Epoch 9, Step 33346: Loss=4.6116, Acc=0.414, 
2025-10-12 18:10:57,001 - training.trainer - INFO - Epoch 9, Step 33446: Loss=6.2520, Acc=0.175, 
2025-10-12 18:11:06,938 - training.trainer - INFO - Epoch 9, Step 33546: Loss=6.1059, Acc=0.115, 
2025-10-12 18:11:16,797 - training.trainer - INFO - Epoch 9, Step 33646: Loss=5.8910, Acc=0.250, 
2025-10-12 18:11:26,755 - training.trainer - INFO - Epoch 9, Step 33746: Loss=4.7058, Acc=0.300, 
2025-10-12 18:11:49,877 - training.trainer - INFO - Epoch 10/100 completed in 352.78s - Train Loss: 5.9678, Train Acc: 0.207, Val Loss: 5.9125, Val Acc: 0.212
2025-10-12 18:11:50,397 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-12 18:11:51,562 - training.trainer - INFO - New best model saved with validation loss: 5.9125
2025-10-12 18:11:51,562 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-12 18:12:02,040 - training.trainer - INFO - Epoch 10, Step 33929: Loss=5.8529, Acc=0.143, 
2025-10-12 18:12:12,033 - training.trainer - INFO - Epoch 10, Step 34029: Loss=6.4617, Acc=0.200, 
2025-10-12 18:12:21,999 - training.trainer - INFO - Epoch 10, Step 34129: Loss=5.7616, Acc=0.244, 
2025-10-12 18:12:31,936 - training.trainer - INFO - Epoch 10, Step 34229: Loss=6.1436, Acc=0.178, 
2025-10-12 18:12:41,811 - training.trainer - INFO - Epoch 10, Step 34329: Loss=5.6107, Acc=0.297, 
2025-10-12 18:12:51,766 - training.trainer - INFO - Epoch 10, Step 34429: Loss=5.7819, Acc=0.161, 
2025-10-12 18:13:01,879 - training.trainer - INFO - Epoch 10, Step 34529: Loss=4.9468, Acc=0.286, 
2025-10-12 18:13:11,894 - training.trainer - INFO - Epoch 10, Step 34629: Loss=6.0848, Acc=0.171, 
2025-10-12 18:13:22,210 - training.trainer - INFO - Epoch 10, Step 34729: Loss=5.8128, Acc=0.235, 
2025-10-12 18:13:32,499 - training.trainer - INFO - Epoch 10, Step 34829: Loss=5.2679, Acc=0.286, 
2025-10-12 18:13:42,605 - training.trainer - INFO - Epoch 10, Step 34929: Loss=5.4022, Acc=0.240, 
2025-10-12 18:13:52,800 - training.trainer - INFO - Epoch 10, Step 35029: Loss=5.5435, Acc=0.263, 
2025-10-12 18:14:02,785 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.3756, Acc=0.153, 
2025-10-12 18:14:12,787 - training.trainer - INFO - Epoch 10, Step 35229: Loss=6.3114, Acc=0.167, 
2025-10-12 18:14:22,668 - training.trainer - INFO - Epoch 10, Step 35329: Loss=6.4532, Acc=0.178, 
2025-10-12 18:14:32,707 - training.trainer - INFO - Epoch 10, Step 35429: Loss=6.0306, Acc=0.176, 
2025-10-12 18:14:42,606 - training.trainer - INFO - Epoch 10, Step 35529: Loss=5.5938, Acc=0.259, 
2025-10-12 18:14:52,647 - training.trainer - INFO - Epoch 10, Step 35629: Loss=5.0585, Acc=0.316, 
2025-10-12 18:15:02,628 - training.trainer - INFO - Epoch 10, Step 35729: Loss=5.8364, Acc=0.250, 
2025-10-12 18:15:12,657 - training.trainer - INFO - Epoch 10, Step 35829: Loss=5.0135, Acc=0.188, 
2025-10-12 18:15:22,755 - training.trainer - INFO - Epoch 10, Step 35929: Loss=6.1580, Acc=0.147, 
2025-10-12 18:15:32,921 - training.trainer - INFO - Epoch 10, Step 36029: Loss=5.8095, Acc=0.167, 
2025-10-12 18:15:43,199 - training.trainer - INFO - Epoch 10, Step 36129: Loss=4.7492, Acc=0.286, 
2025-10-12 18:15:53,401 - training.trainer - INFO - Epoch 10, Step 36229: Loss=6.4319, Acc=0.198, 
2025-10-12 18:16:03,641 - training.trainer - INFO - Epoch 10, Step 36329: Loss=6.1206, Acc=0.294, 
2025-10-12 18:16:13,952 - training.trainer - INFO - Epoch 10, Step 36429: Loss=6.7160, Acc=0.163, 
2025-10-12 18:16:24,036 - training.trainer - INFO - Epoch 10, Step 36529: Loss=5.4260, Acc=0.333, 
2025-10-12 18:16:34,164 - training.trainer - INFO - Epoch 10, Step 36629: Loss=5.2824, Acc=0.391, 
2025-10-12 18:16:44,413 - training.trainer - INFO - Epoch 10, Step 36729: Loss=6.1500, Acc=0.133, 
2025-10-12 18:16:54,599 - training.trainer - INFO - Epoch 10, Step 36829: Loss=6.6118, Acc=0.157, 
2025-10-12 18:17:05,035 - training.trainer - INFO - Epoch 10, Step 36929: Loss=6.4448, Acc=0.111, 
2025-10-12 18:17:15,347 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.5688, Acc=0.185, 
2025-10-12 18:17:25,580 - training.trainer - INFO - Epoch 10, Step 37129: Loss=6.4668, Acc=0.131, 
2025-10-12 18:17:47,725 - training.trainer - INFO - Epoch 11/100 completed in 356.16s - Train Loss: 5.9361, Train Acc: 0.211, Val Loss: 5.8905, Val Acc: 0.217
2025-10-12 18:17:48,669 - training.trainer - INFO - New best model saved with validation loss: 5.8905
2025-10-12 18:17:48,670 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_11.pt
2025-10-12 18:17:59,101 - training.trainer - INFO - Epoch 11, Step 37312: Loss=6.4508, Acc=0.186, 
2025-10-12 18:18:09,527 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.5674, Acc=0.148, 
2025-10-12 18:18:19,799 - training.trainer - INFO - Epoch 11, Step 37512: Loss=5.9257, Acc=0.125, 
2025-10-12 18:18:29,973 - training.trainer - INFO - Epoch 11, Step 37612: Loss=6.3669, Acc=0.195, 
2025-10-12 18:18:40,185 - training.trainer - INFO - Epoch 11, Step 37712: Loss=5.2126, Acc=0.300, 
2025-10-12 18:18:50,478 - training.trainer - INFO - Epoch 11, Step 37812: Loss=6.3972, Acc=0.185, 
2025-10-12 18:19:00,878 - training.trainer - INFO - Epoch 11, Step 37912: Loss=5.0616, Acc=0.235, 
2025-10-12 18:19:11,164 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.0856, Acc=0.278, 
2025-10-12 18:19:21,331 - training.trainer - INFO - Epoch 11, Step 38112: Loss=5.9307, Acc=0.200, 
2025-10-12 18:19:31,424 - training.trainer - INFO - Epoch 11, Step 38212: Loss=6.7609, Acc=0.182, 
2025-10-12 18:19:41,679 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.6195, Acc=0.133, 
2025-10-12 18:19:51,912 - training.trainer - INFO - Epoch 11, Step 38412: Loss=6.1835, Acc=0.100, 
2025-10-12 18:20:02,007 - training.trainer - INFO - Epoch 11, Step 38512: Loss=5.6981, Acc=0.217, 
2025-10-12 18:20:12,140 - training.trainer - INFO - Epoch 11, Step 38612: Loss=5.8459, Acc=0.229, 
2025-10-12 18:20:22,179 - training.trainer - INFO - Epoch 11, Step 38712: Loss=5.0995, Acc=0.344, 
2025-10-12 18:20:32,365 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.7240, Acc=0.130, 
2025-10-12 18:20:42,580 - training.trainer - INFO - Epoch 11, Step 38912: Loss=5.2584, Acc=0.277, 
2025-10-12 18:20:52,766 - training.trainer - INFO - Epoch 11, Step 39012: Loss=5.7849, Acc=0.157, 
2025-10-12 18:21:02,888 - training.trainer - INFO - Epoch 11, Step 39112: Loss=6.1949, Acc=0.297, 
2025-10-12 18:21:13,248 - training.trainer - INFO - Epoch 11, Step 39212: Loss=6.2493, Acc=0.217, 
2025-10-12 18:21:23,383 - training.trainer - INFO - Epoch 11, Step 39312: Loss=4.7841, Acc=0.346, 
2025-10-12 18:21:33,556 - training.trainer - INFO - Epoch 11, Step 39412: Loss=5.3189, Acc=0.326, 
2025-10-12 18:21:43,706 - training.trainer - INFO - Epoch 11, Step 39512: Loss=5.8055, Acc=0.289, 
2025-10-12 18:21:53,907 - training.trainer - INFO - Epoch 11, Step 39612: Loss=5.7887, Acc=0.250, 
2025-10-12 18:22:04,030 - training.trainer - INFO - Epoch 11, Step 39712: Loss=5.5990, Acc=0.188, 
2025-10-12 18:22:14,188 - training.trainer - INFO - Epoch 11, Step 39812: Loss=6.0703, Acc=0.203, 
2025-10-12 18:22:24,345 - training.trainer - INFO - Epoch 11, Step 39912: Loss=4.2886, Acc=0.440, 
2025-10-12 18:22:34,517 - training.trainer - INFO - Epoch 11, Step 40012: Loss=6.1651, Acc=0.206, 
2025-10-12 18:22:44,634 - training.trainer - INFO - Epoch 11, Step 40112: Loss=4.2373, Acc=0.333, 
2025-10-12 18:22:54,789 - training.trainer - INFO - Epoch 11, Step 40212: Loss=5.9406, Acc=0.160, 
2025-10-12 18:23:04,979 - training.trainer - INFO - Epoch 11, Step 40312: Loss=5.7630, Acc=0.200, 
2025-10-12 18:23:15,088 - training.trainer - INFO - Epoch 11, Step 40412: Loss=6.8216, Acc=0.102, 
2025-10-12 18:23:25,067 - training.trainer - INFO - Epoch 11, Step 40512: Loss=6.5194, Acc=0.195, 
2025-10-12 18:23:47,213 - training.trainer - INFO - Epoch 12/100 completed in 358.54s - Train Loss: 5.9068, Train Acc: 0.216, Val Loss: 5.8645, Val Acc: 0.225
2025-10-12 18:23:48,057 - training.trainer - INFO - New best model saved with validation loss: 5.8645
2025-10-12 18:23:48,057 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_12.pt
2025-10-12 18:23:58,734 - training.trainer - INFO - Epoch 12, Step 40695: Loss=4.9638, Acc=0.294, 
2025-10-12 18:24:08,981 - training.trainer - INFO - Epoch 12, Step 40795: Loss=5.8528, Acc=0.196, 
2025-10-12 18:24:19,099 - training.trainer - INFO - Epoch 12, Step 40895: Loss=3.8361, Acc=0.385, 
2025-10-12 18:24:29,264 - training.trainer - INFO - Epoch 12, Step 40995: Loss=6.2117, Acc=0.169, 
2025-10-12 18:24:39,433 - training.trainer - INFO - Epoch 12, Step 41095: Loss=4.3491, Acc=0.414, 
2025-10-12 18:24:49,625 - training.trainer - INFO - Epoch 12, Step 41195: Loss=5.3417, Acc=0.296, 
2025-10-12 18:24:59,649 - training.trainer - INFO - Epoch 12, Step 41295: Loss=5.8000, Acc=0.176, 
2025-10-12 18:25:09,806 - training.trainer - INFO - Epoch 12, Step 41395: Loss=6.2880, Acc=0.186, 
2025-10-12 18:25:19,988 - training.trainer - INFO - Epoch 12, Step 41495: Loss=6.5308, Acc=0.147, 
2025-10-12 18:25:30,008 - training.trainer - INFO - Epoch 12, Step 41595: Loss=6.2038, Acc=0.193, 
2025-10-12 18:25:39,830 - training.trainer - INFO - Epoch 12, Step 41695: Loss=6.2966, Acc=0.125, 
2025-10-12 18:25:49,696 - training.trainer - INFO - Epoch 12, Step 41795: Loss=6.3021, Acc=0.143, 
2025-10-12 18:25:59,768 - training.trainer - INFO - Epoch 12, Step 41895: Loss=5.5953, Acc=0.235, 
2025-10-12 18:26:10,030 - training.trainer - INFO - Epoch 12, Step 41995: Loss=5.8376, Acc=0.278, 
2025-10-12 18:26:20,143 - training.trainer - INFO - Epoch 12, Step 42095: Loss=6.4193, Acc=0.159, 
2025-10-12 18:26:29,988 - training.trainer - INFO - Epoch 12, Step 42195: Loss=5.8905, Acc=0.206, 
2025-10-12 18:26:39,869 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.0370, Acc=0.256, 
2025-10-12 18:26:50,008 - training.trainer - INFO - Epoch 12, Step 42395: Loss=6.4960, Acc=0.158, 
2025-10-12 18:27:00,085 - training.trainer - INFO - Epoch 12, Step 42495: Loss=5.9771, Acc=0.148, 
2025-10-12 18:27:10,260 - training.trainer - INFO - Epoch 12, Step 42595: Loss=4.9198, Acc=0.304, 
2025-10-12 18:27:20,296 - training.trainer - INFO - Epoch 12, Step 42695: Loss=5.4252, Acc=0.238, 
2025-10-12 18:27:30,265 - training.trainer - INFO - Epoch 12, Step 42795: Loss=6.0377, Acc=0.219, 
2025-10-12 18:27:40,270 - training.trainer - INFO - Epoch 12, Step 42895: Loss=5.1728, Acc=0.300, 
2025-10-12 18:27:50,328 - training.trainer - INFO - Epoch 12, Step 42995: Loss=5.0384, Acc=0.276, 
2025-10-12 18:28:00,227 - training.trainer - INFO - Epoch 12, Step 43095: Loss=6.1416, Acc=0.176, 
2025-10-12 18:28:10,329 - training.trainer - INFO - Epoch 12, Step 43195: Loss=6.6654, Acc=0.205, 
2025-10-12 18:28:20,683 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.6757, Acc=0.173, 
2025-10-12 18:28:30,856 - training.trainer - INFO - Epoch 12, Step 43395: Loss=6.0103, Acc=0.208, 
2025-10-12 18:28:40,879 - training.trainer - INFO - Epoch 12, Step 43495: Loss=5.7655, Acc=0.265, 
2025-10-12 18:28:50,766 - training.trainer - INFO - Epoch 12, Step 43595: Loss=5.3958, Acc=0.238, 
2025-10-12 18:29:00,873 - training.trainer - INFO - Epoch 12, Step 43695: Loss=6.6120, Acc=0.156, 
2025-10-12 18:29:10,826 - training.trainer - INFO - Epoch 12, Step 43795: Loss=5.9128, Acc=0.190, 
2025-10-12 18:29:21,096 - training.trainer - INFO - Epoch 12, Step 43895: Loss=6.4925, Acc=0.117, 
2025-10-12 18:29:44,736 - training.trainer - INFO - Epoch 13/100 completed in 356.68s - Train Loss: 5.8923, Train Acc: 0.220, Val Loss: 5.8456, Val Acc: 0.226
2025-10-12 18:29:45,865 - training.trainer - INFO - New best model saved with validation loss: 5.8456
2025-10-12 18:29:45,866 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-10-12 18:29:56,486 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.7747, Acc=0.129, 
2025-10-12 18:30:06,879 - training.trainer - INFO - Epoch 13, Step 44178: Loss=5.9978, Acc=0.114, 
2025-10-12 18:30:16,963 - training.trainer - INFO - Epoch 13, Step 44278: Loss=6.5625, Acc=0.156, 
2025-10-12 18:30:27,310 - training.trainer - INFO - Epoch 13, Step 44378: Loss=6.3312, Acc=0.143, 
2025-10-12 18:30:37,488 - training.trainer - INFO - Epoch 13, Step 44478: Loss=5.4809, Acc=0.290, 
2025-10-12 18:30:47,627 - training.trainer - INFO - Epoch 13, Step 44578: Loss=4.9429, Acc=0.312, 
2025-10-12 18:30:57,781 - training.trainer - INFO - Epoch 13, Step 44678: Loss=6.0234, Acc=0.140, 
2025-10-12 18:31:07,869 - training.trainer - INFO - Epoch 13, Step 44778: Loss=6.2208, Acc=0.141, 
2025-10-12 18:31:18,011 - training.trainer - INFO - Epoch 13, Step 44878: Loss=6.1620, Acc=0.171, 
2025-10-12 18:31:28,038 - training.trainer - INFO - Epoch 13, Step 44978: Loss=6.2631, Acc=0.143, 
2025-10-12 18:31:38,044 - training.trainer - INFO - Epoch 13, Step 45078: Loss=5.7768, Acc=0.175, 
2025-10-12 18:31:47,914 - training.trainer - INFO - Epoch 13, Step 45178: Loss=6.5722, Acc=0.141, 
2025-10-12 18:31:57,784 - training.trainer - INFO - Epoch 13, Step 45278: Loss=5.8366, Acc=0.250, 
2025-10-12 18:32:07,712 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.0890, Acc=0.184, 
2025-10-12 18:32:17,797 - training.trainer - INFO - Epoch 13, Step 45478: Loss=5.5067, Acc=0.289, 
2025-10-12 18:32:27,977 - training.trainer - INFO - Epoch 13, Step 45578: Loss=6.2233, Acc=0.217, 
2025-10-12 18:32:38,114 - training.trainer - INFO - Epoch 13, Step 45678: Loss=4.9513, Acc=0.344, 
2025-10-12 18:32:48,332 - training.trainer - INFO - Epoch 13, Step 45778: Loss=5.8576, Acc=0.229, 
2025-10-12 18:32:58,683 - training.trainer - INFO - Epoch 13, Step 45878: Loss=5.5649, Acc=0.321, 
2025-10-12 18:33:08,959 - training.trainer - INFO - Epoch 13, Step 45978: Loss=6.9909, Acc=0.153, 
2025-10-12 18:33:19,189 - training.trainer - INFO - Epoch 13, Step 46078: Loss=6.3859, Acc=0.100, 
2025-10-12 18:33:29,660 - training.trainer - INFO - Epoch 13, Step 46178: Loss=5.9281, Acc=0.140, 
2025-10-12 18:33:39,964 - training.trainer - INFO - Epoch 13, Step 46278: Loss=5.1758, Acc=0.232, 
2025-10-12 18:33:50,320 - training.trainer - INFO - Epoch 13, Step 46378: Loss=5.5420, Acc=0.229, 
2025-10-12 18:34:00,591 - training.trainer - INFO - Epoch 13, Step 46478: Loss=5.8851, Acc=0.256, 
2025-10-12 18:34:10,768 - training.trainer - INFO - Epoch 13, Step 46578: Loss=6.5485, Acc=0.123, 
2025-10-12 18:34:20,924 - training.trainer - INFO - Epoch 13, Step 46678: Loss=6.3047, Acc=0.159, 
2025-10-12 18:34:31,057 - training.trainer - INFO - Epoch 13, Step 46778: Loss=6.7392, Acc=0.189, 
2025-10-12 18:34:41,082 - training.trainer - INFO - Epoch 13, Step 46878: Loss=5.7573, Acc=0.263, 
2025-10-12 18:34:51,079 - training.trainer - INFO - Epoch 13, Step 46978: Loss=6.3883, Acc=0.132, 
2025-10-12 18:35:01,044 - training.trainer - INFO - Epoch 13, Step 47078: Loss=5.4420, Acc=0.273, 
2025-10-12 18:35:10,989 - training.trainer - INFO - Epoch 13, Step 47178: Loss=6.2014, Acc=0.211, 
2025-10-12 18:35:21,139 - training.trainer - INFO - Epoch 13, Step 47278: Loss=5.5325, Acc=0.238, 
2025-10-12 18:35:43,165 - training.trainer - INFO - Epoch 14/100 completed in 357.30s - Train Loss: 5.8653, Train Acc: 0.224, Val Loss: 5.8476, Val Acc: 0.224
2025-10-12 18:35:52,717 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.6454, Acc=0.164, 
2025-10-12 18:36:02,373 - training.trainer - INFO - Epoch 14, Step 47561: Loss=6.3819, Acc=0.206, 
2025-10-12 18:36:11,841 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.7530, Acc=0.259, 
2025-10-12 18:36:20,304 - training.trainer - INFO - Epoch 14, Step 47761: Loss=5.9488, Acc=0.167, 
2025-10-12 18:36:28,957 - training.trainer - INFO - Epoch 14, Step 47861: Loss=5.9088, Acc=0.277, 
2025-10-12 18:36:37,640 - training.trainer - INFO - Epoch 14, Step 47961: Loss=5.4882, Acc=0.250, 
2025-10-12 18:36:47,238 - training.trainer - INFO - Epoch 14, Step 48061: Loss=5.8946, Acc=0.167, 
2025-10-12 18:36:57,195 - training.trainer - INFO - Epoch 14, Step 48161: Loss=4.2135, Acc=0.474, 
2025-10-12 18:37:07,119 - training.trainer - INFO - Epoch 14, Step 48261: Loss=5.9100, Acc=0.115, 
2025-10-12 18:37:16,939 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.8433, Acc=0.260, 
2025-10-12 18:37:26,950 - training.trainer - INFO - Epoch 14, Step 48461: Loss=6.1185, Acc=0.179, 
2025-10-12 18:37:36,978 - training.trainer - INFO - Epoch 14, Step 48561: Loss=6.0195, Acc=0.229, 
2025-10-12 18:37:47,040 - training.trainer - INFO - Epoch 14, Step 48661: Loss=5.5160, Acc=0.278, 
2025-10-12 18:37:57,229 - training.trainer - INFO - Epoch 14, Step 48761: Loss=6.3868, Acc=0.214, 
2025-10-12 18:38:07,328 - training.trainer - INFO - Epoch 14, Step 48861: Loss=6.1676, Acc=0.219, 
2025-10-12 18:38:17,345 - training.trainer - INFO - Epoch 14, Step 48961: Loss=6.2792, Acc=0.188, 
2025-10-12 18:38:27,566 - training.trainer - INFO - Epoch 14, Step 49061: Loss=6.1432, Acc=0.200, 
2025-10-12 18:38:37,733 - training.trainer - INFO - Epoch 14, Step 49161: Loss=6.2554, Acc=0.170, 
2025-10-12 18:38:47,919 - training.trainer - INFO - Epoch 14, Step 49261: Loss=5.7648, Acc=0.275, 
2025-10-12 18:38:58,081 - training.trainer - INFO - Epoch 14, Step 49361: Loss=5.2359, Acc=0.312, 
2025-10-12 18:39:08,094 - training.trainer - INFO - Epoch 14, Step 49461: Loss=6.0713, Acc=0.250, 
2025-10-12 18:39:18,078 - training.trainer - INFO - Epoch 14, Step 49561: Loss=5.5178, Acc=0.273, 
2025-10-12 18:39:28,100 - training.trainer - INFO - Epoch 14, Step 49661: Loss=6.1336, Acc=0.262, 
2025-10-12 18:39:38,261 - training.trainer - INFO - Epoch 14, Step 49761: Loss=6.0783, Acc=0.167, 
2025-10-12 18:39:48,503 - training.trainer - INFO - Epoch 14, Step 49861: Loss=6.2999, Acc=0.167, 
2025-10-12 18:39:58,680 - training.trainer - INFO - Epoch 14, Step 49961: Loss=6.1978, Acc=0.212, 
2025-10-12 18:40:08,772 - training.trainer - INFO - Epoch 14, Step 50061: Loss=6.3312, Acc=0.205, 
2025-10-12 18:40:18,890 - training.trainer - INFO - Epoch 14, Step 50161: Loss=6.2605, Acc=0.195, 
2025-10-12 18:40:29,352 - training.trainer - INFO - Epoch 14, Step 50261: Loss=6.5641, Acc=0.273, 
2025-10-12 18:40:39,690 - training.trainer - INFO - Epoch 14, Step 50361: Loss=5.4451, Acc=0.421, 
2025-10-12 18:40:49,903 - training.trainer - INFO - Epoch 14, Step 50461: Loss=6.0637, Acc=0.200, 
2025-10-12 18:41:00,052 - training.trainer - INFO - Epoch 14, Step 50561: Loss=5.6311, Acc=0.184, 
2025-10-12 18:41:10,090 - training.trainer - INFO - Epoch 14, Step 50661: Loss=6.8336, Acc=0.258, 
2025-10-12 18:41:32,354 - training.trainer - INFO - Epoch 15/100 completed in 349.19s - Train Loss: 5.8359, Train Acc: 0.229, Val Loss: 5.8197, Val Acc: 0.234
2025-10-12 18:41:32,752 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-12 18:41:33,584 - training.trainer - INFO - New best model saved with validation loss: 5.8197
2025-10-12 18:41:33,584 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-12 18:41:42,934 - training.trainer - INFO - Epoch 15, Step 50844: Loss=5.7275, Acc=0.182, 
2025-10-12 18:41:51,738 - training.trainer - INFO - Epoch 15, Step 50944: Loss=6.0348, Acc=0.228, 
2025-10-12 18:42:00,485 - training.trainer - INFO - Epoch 15, Step 51044: Loss=5.9007, Acc=0.190, 
2025-10-12 18:42:09,731 - training.trainer - INFO - Epoch 15, Step 51144: Loss=6.0399, Acc=0.261, 
2025-10-12 18:42:19,401 - training.trainer - INFO - Epoch 15, Step 51244: Loss=6.6767, Acc=0.104, 
2025-10-12 18:42:29,549 - training.trainer - INFO - Epoch 15, Step 51344: Loss=6.1552, Acc=0.226, 
2025-10-12 18:42:39,668 - training.trainer - INFO - Epoch 15, Step 51444: Loss=4.1302, Acc=0.320, 
2025-10-12 18:42:50,047 - training.trainer - INFO - Epoch 15, Step 51544: Loss=5.5196, Acc=0.203, 
2025-10-12 18:43:00,290 - training.trainer - INFO - Epoch 15, Step 51644: Loss=5.9137, Acc=0.172, 
2025-10-12 18:43:10,550 - training.trainer - INFO - Epoch 15, Step 51744: Loss=4.9302, Acc=0.286, 
2025-10-12 18:43:20,770 - training.trainer - INFO - Epoch 15, Step 51844: Loss=5.9947, Acc=0.194, 
2025-10-12 18:43:31,060 - training.trainer - INFO - Epoch 15, Step 51944: Loss=6.2657, Acc=0.188, 
2025-10-12 18:43:41,362 - training.trainer - INFO - Epoch 15, Step 52044: Loss=5.7406, Acc=0.263, 
2025-10-12 18:43:51,397 - training.trainer - INFO - Epoch 15, Step 52144: Loss=5.3673, Acc=0.195, 
2025-10-12 18:44:01,557 - training.trainer - INFO - Epoch 15, Step 52244: Loss=5.9445, Acc=0.381, 
2025-10-12 18:44:11,939 - training.trainer - INFO - Epoch 15, Step 52344: Loss=5.6512, Acc=0.275, 
2025-10-12 18:44:22,138 - training.trainer - INFO - Epoch 15, Step 52444: Loss=6.2537, Acc=0.174, 
2025-10-12 18:44:32,242 - training.trainer - INFO - Epoch 15, Step 52544: Loss=6.0012, Acc=0.200, 
2025-10-12 18:44:42,183 - training.trainer - INFO - Epoch 15, Step 52644: Loss=4.7424, Acc=0.333, 
2025-10-12 18:44:52,518 - training.trainer - INFO - Epoch 15, Step 52744: Loss=5.5720, Acc=0.320, 
2025-10-12 18:45:02,647 - training.trainer - INFO - Epoch 15, Step 52844: Loss=5.4899, Acc=0.200, 
2025-10-12 18:45:12,510 - training.trainer - INFO - Epoch 15, Step 52944: Loss=6.3794, Acc=0.154, 
2025-10-12 18:45:22,411 - training.trainer - INFO - Epoch 15, Step 53044: Loss=6.3082, Acc=0.176, 
2025-10-12 18:45:32,564 - training.trainer - INFO - Epoch 15, Step 53144: Loss=6.2114, Acc=0.186, 
2025-10-12 18:45:42,701 - training.trainer - INFO - Epoch 15, Step 53244: Loss=5.4013, Acc=0.250, 
2025-10-12 18:45:52,710 - training.trainer - INFO - Epoch 15, Step 53344: Loss=6.2607, Acc=0.211, 
2025-10-12 18:46:02,918 - training.trainer - INFO - Epoch 15, Step 53444: Loss=5.3466, Acc=0.250, 
2025-10-12 18:46:13,192 - training.trainer - INFO - Epoch 15, Step 53544: Loss=5.1090, Acc=0.292, 
2025-10-12 18:46:23,450 - training.trainer - INFO - Epoch 15, Step 53644: Loss=6.1299, Acc=0.212, 
2025-10-12 18:46:33,473 - training.trainer - INFO - Epoch 15, Step 53744: Loss=6.4315, Acc=0.178, 
2025-10-12 18:46:43,526 - training.trainer - INFO - Epoch 15, Step 53844: Loss=5.9573, Acc=0.207, 
2025-10-12 18:46:53,539 - training.trainer - INFO - Epoch 15, Step 53944: Loss=6.2296, Acc=0.188, 
2025-10-12 18:47:03,742 - training.trainer - INFO - Epoch 15, Step 54044: Loss=6.0552, Acc=0.129, 
2025-10-12 18:47:27,379 - training.trainer - INFO - Epoch 16/100 completed in 353.79s - Train Loss: 5.8156, Train Acc: 0.232, Val Loss: 5.8052, Val Acc: 0.236
2025-10-12 18:47:28,525 - training.trainer - INFO - New best model saved with validation loss: 5.8052
2025-10-12 18:47:28,525 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_16.pt
2025-10-12 18:47:39,101 - training.trainer - INFO - Epoch 16, Step 54227: Loss=5.7391, Acc=0.208, 
2025-10-12 18:47:49,424 - training.trainer - INFO - Epoch 16, Step 54327: Loss=6.8764, Acc=0.111, 
2025-10-12 18:47:59,765 - training.trainer - INFO - Epoch 16, Step 54427: Loss=5.6322, Acc=0.217, 
2025-10-12 18:48:09,677 - training.trainer - INFO - Epoch 16, Step 54527: Loss=5.5913, Acc=0.222, 
2025-10-12 18:48:19,738 - training.trainer - INFO - Epoch 16, Step 54627: Loss=5.3969, Acc=0.333, 
2025-10-12 18:48:29,802 - training.trainer - INFO - Epoch 16, Step 54727: Loss=5.6240, Acc=0.300, 
2025-10-12 18:48:39,748 - training.trainer - INFO - Epoch 16, Step 54827: Loss=6.5712, Acc=0.200, 
2025-10-12 18:48:49,737 - training.trainer - INFO - Epoch 16, Step 54927: Loss=6.6831, Acc=0.268, 
2025-10-12 18:48:59,684 - training.trainer - INFO - Epoch 16, Step 55027: Loss=6.0786, Acc=0.212, 
2025-10-12 18:49:09,788 - training.trainer - INFO - Epoch 16, Step 55127: Loss=5.5389, Acc=0.300, 
2025-10-12 18:49:19,718 - training.trainer - INFO - Epoch 16, Step 55227: Loss=5.0473, Acc=0.192, 
2025-10-12 18:49:29,665 - training.trainer - INFO - Epoch 16, Step 55327: Loss=5.6703, Acc=0.235, 
2025-10-12 18:49:39,504 - training.trainer - INFO - Epoch 16, Step 55427: Loss=5.3514, Acc=0.279, 
2025-10-12 18:49:49,403 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.9477, Acc=0.241, 
2025-10-12 18:49:59,349 - training.trainer - INFO - Epoch 16, Step 55627: Loss=6.2311, Acc=0.152, 
2025-10-12 18:50:09,142 - training.trainer - INFO - Epoch 16, Step 55727: Loss=6.0116, Acc=0.158, 
2025-10-12 18:50:18,955 - training.trainer - INFO - Epoch 16, Step 55827: Loss=4.7211, Acc=0.233, 
2025-10-12 18:50:28,776 - training.trainer - INFO - Epoch 16, Step 55927: Loss=5.7677, Acc=0.290, 
2025-10-12 18:50:38,635 - training.trainer - INFO - Epoch 16, Step 56027: Loss=5.7748, Acc=0.146, 
2025-10-12 18:50:48,507 - training.trainer - INFO - Epoch 16, Step 56127: Loss=5.4775, Acc=0.213, 
2025-10-12 18:50:58,607 - training.trainer - INFO - Epoch 16, Step 56227: Loss=4.8883, Acc=0.241, 
2025-10-12 18:51:08,497 - training.trainer - INFO - Epoch 16, Step 56327: Loss=6.3248, Acc=0.190, 
2025-10-12 18:51:18,338 - training.trainer - INFO - Epoch 16, Step 56427: Loss=5.6804, Acc=0.206, 
2025-10-12 18:51:28,209 - training.trainer - INFO - Epoch 16, Step 56527: Loss=5.8333, Acc=0.194, 
2025-10-12 18:51:38,054 - training.trainer - INFO - Epoch 16, Step 56627: Loss=5.0224, Acc=0.318, 
2025-10-12 18:51:47,994 - training.trainer - INFO - Epoch 16, Step 56727: Loss=5.2415, Acc=0.185, 
2025-10-12 18:51:58,138 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.7818, Acc=0.250, 
2025-10-12 18:52:08,188 - training.trainer - INFO - Epoch 16, Step 56927: Loss=5.7043, Acc=0.226, 
2025-10-12 18:52:18,228 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.9187, Acc=0.185, 
2025-10-12 18:52:28,229 - training.trainer - INFO - Epoch 16, Step 57127: Loss=5.8216, Acc=0.180, 
2025-10-12 18:52:38,175 - training.trainer - INFO - Epoch 16, Step 57227: Loss=5.4393, Acc=0.250, 
2025-10-12 18:52:48,219 - training.trainer - INFO - Epoch 16, Step 57327: Loss=5.1749, Acc=0.182, 
2025-10-12 18:52:58,478 - training.trainer - INFO - Epoch 16, Step 57427: Loss=5.3802, Acc=0.296, 
2025-10-12 18:53:21,690 - training.trainer - INFO - Epoch 17/100 completed in 353.16s - Train Loss: 5.7979, Train Acc: 0.234, Val Loss: 5.8051, Val Acc: 0.235
2025-10-12 18:53:22,830 - training.trainer - INFO - New best model saved with validation loss: 5.8051
2025-10-12 18:53:22,830 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_17.pt
2025-10-12 18:53:33,351 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.2894, Acc=0.217, 
2025-10-12 18:53:43,470 - training.trainer - INFO - Epoch 17, Step 57710: Loss=4.0494, Acc=0.480, 
2025-10-12 18:53:53,437 - training.trainer - INFO - Epoch 17, Step 57810: Loss=4.9540, Acc=0.292, 
2025-10-12 18:54:03,314 - training.trainer - INFO - Epoch 17, Step 57910: Loss=6.5618, Acc=0.205, 
2025-10-12 18:54:13,390 - training.trainer - INFO - Epoch 17, Step 58010: Loss=5.0932, Acc=0.244, 
2025-10-12 18:54:23,612 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.5311, Acc=0.268, 
2025-10-12 18:54:33,702 - training.trainer - INFO - Epoch 17, Step 58210: Loss=5.3647, Acc=0.206, 
2025-10-12 18:54:43,612 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.7200, Acc=0.292, 
2025-10-12 18:54:53,659 - training.trainer - INFO - Epoch 17, Step 58410: Loss=6.1248, Acc=0.119, 
2025-10-12 18:55:03,567 - training.trainer - INFO - Epoch 17, Step 58510: Loss=6.1602, Acc=0.179, 
2025-10-12 18:55:13,553 - training.trainer - INFO - Epoch 17, Step 58610: Loss=6.3727, Acc=0.171, 
2025-10-12 18:55:23,504 - training.trainer - INFO - Epoch 17, Step 58710: Loss=5.5504, Acc=0.231, 
2025-10-12 18:55:33,516 - training.trainer - INFO - Epoch 17, Step 58810: Loss=4.1421, Acc=0.462, 
2025-10-12 18:55:43,673 - training.trainer - INFO - Epoch 17, Step 58910: Loss=6.0170, Acc=0.268, 
2025-10-12 18:55:53,902 - training.trainer - INFO - Epoch 17, Step 59010: Loss=5.7249, Acc=0.180, 
2025-10-12 18:56:03,870 - training.trainer - INFO - Epoch 17, Step 59110: Loss=6.3893, Acc=0.208, 
2025-10-12 18:56:14,006 - training.trainer - INFO - Epoch 17, Step 59210: Loss=5.0581, Acc=0.333, 
2025-10-12 18:56:24,157 - training.trainer - INFO - Epoch 17, Step 59310: Loss=5.4865, Acc=0.300, 
2025-10-12 18:56:34,282 - training.trainer - INFO - Epoch 17, Step 59410: Loss=5.9262, Acc=0.226, 
2025-10-12 18:56:44,261 - training.trainer - INFO - Epoch 17, Step 59510: Loss=5.4148, Acc=0.333, 
2025-10-12 18:56:54,196 - training.trainer - INFO - Epoch 17, Step 59610: Loss=6.3252, Acc=0.250, 
2025-10-12 18:57:04,113 - training.trainer - INFO - Epoch 17, Step 59710: Loss=6.2660, Acc=0.159, 
2025-10-12 18:57:13,940 - training.trainer - INFO - Epoch 17, Step 59810: Loss=5.3843, Acc=0.282, 
2025-10-12 18:57:23,906 - training.trainer - INFO - Epoch 17, Step 59910: Loss=5.8445, Acc=0.231, 
2025-10-12 18:57:33,967 - training.trainer - INFO - Epoch 17, Step 60010: Loss=5.9075, Acc=0.218, 
2025-10-12 18:57:43,845 - training.trainer - INFO - Epoch 17, Step 60110: Loss=6.5956, Acc=0.200, 
2025-10-12 18:57:53,874 - training.trainer - INFO - Epoch 17, Step 60210: Loss=5.7824, Acc=0.244, 
2025-10-12 18:58:04,002 - training.trainer - INFO - Epoch 17, Step 60310: Loss=6.5912, Acc=0.102, 
2025-10-12 18:58:14,098 - training.trainer - INFO - Epoch 17, Step 60410: Loss=5.4651, Acc=0.350, 
2025-10-12 18:58:24,308 - training.trainer - INFO - Epoch 17, Step 60510: Loss=6.1471, Acc=0.145, 
2025-10-12 18:58:34,548 - training.trainer - INFO - Epoch 17, Step 60610: Loss=6.4005, Acc=0.114, 
2025-10-12 18:58:44,775 - training.trainer - INFO - Epoch 17, Step 60710: Loss=5.5071, Acc=0.129, 
2025-10-12 18:58:54,868 - training.trainer - INFO - Epoch 17, Step 60810: Loss=4.7435, Acc=0.361, 
2025-10-12 18:59:18,159 - training.trainer - INFO - Epoch 18/100 completed in 355.33s - Train Loss: 5.7730, Train Acc: 0.238, Val Loss: 5.7731, Val Acc: 0.242
2025-10-12 18:59:19,203 - training.trainer - INFO - New best model saved with validation loss: 5.7731
2025-10-12 18:59:19,203 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-10-12 18:59:29,791 - training.trainer - INFO - Epoch 18, Step 60993: Loss=6.3867, Acc=0.100, 
2025-10-12 18:59:39,975 - training.trainer - INFO - Epoch 18, Step 61093: Loss=6.2182, Acc=0.222, 
2025-10-12 18:59:50,266 - training.trainer - INFO - Epoch 18, Step 61193: Loss=6.5334, Acc=0.172, 
2025-10-12 19:00:00,428 - training.trainer - INFO - Epoch 18, Step 61293: Loss=5.9853, Acc=0.212, 
2025-10-12 19:00:10,761 - training.trainer - INFO - Epoch 18, Step 61393: Loss=4.5949, Acc=0.412, 
2025-10-12 19:00:20,849 - training.trainer - INFO - Epoch 18, Step 61493: Loss=5.9216, Acc=0.250, 
2025-10-12 19:00:30,907 - training.trainer - INFO - Epoch 18, Step 61593: Loss=5.7474, Acc=0.158, 
2025-10-12 19:00:41,154 - training.trainer - INFO - Epoch 18, Step 61693: Loss=6.3840, Acc=0.193, 
2025-10-12 19:00:51,360 - training.trainer - INFO - Epoch 18, Step 61793: Loss=6.3747, Acc=0.122, 
2025-10-12 19:01:01,342 - training.trainer - INFO - Epoch 18, Step 61893: Loss=5.3274, Acc=0.283, 
2025-10-12 19:01:11,312 - training.trainer - INFO - Epoch 18, Step 61993: Loss=5.5798, Acc=0.184, 
2025-10-12 19:01:21,251 - training.trainer - INFO - Epoch 18, Step 62093: Loss=5.6899, Acc=0.200, 
2025-10-12 19:01:31,105 - training.trainer - INFO - Epoch 18, Step 62193: Loss=7.2154, Acc=0.179, 
2025-10-12 19:01:40,987 - training.trainer - INFO - Epoch 18, Step 62293: Loss=6.2631, Acc=0.233, 
2025-10-12 19:01:50,937 - training.trainer - INFO - Epoch 18, Step 62393: Loss=6.3441, Acc=0.150, 
2025-10-12 19:02:00,964 - training.trainer - INFO - Epoch 18, Step 62493: Loss=5.8472, Acc=0.231, 
2025-10-12 19:02:11,013 - training.trainer - INFO - Epoch 18, Step 62593: Loss=5.4845, Acc=0.306, 
2025-10-12 19:02:21,126 - training.trainer - INFO - Epoch 18, Step 62693: Loss=5.8193, Acc=0.212, 
2025-10-12 19:02:31,277 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.1259, Acc=0.250, 
2025-10-12 19:02:41,382 - training.trainer - INFO - Epoch 18, Step 62893: Loss=5.5676, Acc=0.261, 
2025-10-12 19:02:51,565 - training.trainer - INFO - Epoch 18, Step 62993: Loss=5.6905, Acc=0.190, 
2025-10-12 19:03:01,494 - training.trainer - INFO - Epoch 18, Step 63093: Loss=6.3654, Acc=0.236, 
2025-10-12 19:03:11,426 - training.trainer - INFO - Epoch 18, Step 63193: Loss=5.3207, Acc=0.281, 
2025-10-12 19:03:21,441 - training.trainer - INFO - Epoch 18, Step 63293: Loss=5.3145, Acc=0.242, 
2025-10-12 19:03:31,627 - training.trainer - INFO - Epoch 18, Step 63393: Loss=5.4351, Acc=0.200, 
2025-10-12 19:03:41,789 - training.trainer - INFO - Epoch 18, Step 63493: Loss=6.0147, Acc=0.235, 
2025-10-12 19:03:51,750 - training.trainer - INFO - Epoch 18, Step 63593: Loss=5.8012, Acc=0.333, 
2025-10-12 19:04:01,891 - training.trainer - INFO - Epoch 18, Step 63693: Loss=6.4356, Acc=0.206, 
2025-10-12 19:04:11,991 - training.trainer - INFO - Epoch 18, Step 63793: Loss=5.9324, Acc=0.195, 
2025-10-12 19:04:22,130 - training.trainer - INFO - Epoch 18, Step 63893: Loss=5.7116, Acc=0.270, 
2025-10-12 19:04:32,245 - training.trainer - INFO - Epoch 18, Step 63993: Loss=5.0079, Acc=0.360, 
2025-10-12 19:04:42,448 - training.trainer - INFO - Epoch 18, Step 64093: Loss=6.0681, Acc=0.200, 
2025-10-12 19:04:52,571 - training.trainer - INFO - Epoch 18, Step 64193: Loss=5.9129, Acc=0.244, 
2025-10-12 19:05:14,856 - training.trainer - INFO - Epoch 19/100 completed in 355.65s - Train Loss: 5.7497, Train Acc: 0.240, Val Loss: 5.7752, Val Acc: 0.242
2025-10-12 19:05:25,379 - training.trainer - INFO - Epoch 19, Step 64376: Loss=5.9482, Acc=0.261, 
2025-10-12 19:05:35,503 - training.trainer - INFO - Epoch 19, Step 64476: Loss=6.7680, Acc=0.259, 
2025-10-12 19:05:45,525 - training.trainer - INFO - Epoch 19, Step 64576: Loss=6.1869, Acc=0.191, 
2025-10-12 19:05:55,647 - training.trainer - INFO - Epoch 19, Step 64676: Loss=5.6622, Acc=0.289, 
2025-10-12 19:06:05,767 - training.trainer - INFO - Epoch 19, Step 64776: Loss=5.7656, Acc=0.211, 
2025-10-12 19:06:15,874 - training.trainer - INFO - Epoch 19, Step 64876: Loss=5.9941, Acc=0.186, 
2025-10-12 19:06:26,009 - training.trainer - INFO - Epoch 19, Step 64976: Loss=5.4683, Acc=0.280, 
2025-10-12 19:06:36,187 - training.trainer - INFO - Epoch 19, Step 65076: Loss=5.9456, Acc=0.133, 
2025-10-12 19:06:46,308 - training.trainer - INFO - Epoch 19, Step 65176: Loss=5.9781, Acc=0.182, 
2025-10-12 19:06:56,444 - training.trainer - INFO - Epoch 19, Step 65276: Loss=6.0394, Acc=0.222, 
2025-10-12 19:07:06,409 - training.trainer - INFO - Epoch 19, Step 65376: Loss=4.4928, Acc=0.286, 
2025-10-12 19:07:16,519 - training.trainer - INFO - Epoch 19, Step 65476: Loss=6.7958, Acc=0.200, 
2025-10-12 19:07:26,740 - training.trainer - INFO - Epoch 19, Step 65576: Loss=6.7303, Acc=0.143, 
2025-10-12 19:07:36,940 - training.trainer - INFO - Epoch 19, Step 65676: Loss=5.9496, Acc=0.206, 
2025-10-12 19:07:47,089 - training.trainer - INFO - Epoch 19, Step 65776: Loss=5.6144, Acc=0.222, 
2025-10-12 19:07:57,281 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.9830, Acc=0.196, 
2025-10-12 19:08:07,510 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.5021, Acc=0.179, 
2025-10-12 19:08:17,656 - training.trainer - INFO - Epoch 19, Step 66076: Loss=5.4851, Acc=0.236, 
2025-10-12 19:08:27,765 - training.trainer - INFO - Epoch 19, Step 66176: Loss=5.6861, Acc=0.182, 
2025-10-12 19:08:37,847 - training.trainer - INFO - Epoch 19, Step 66276: Loss=6.1465, Acc=0.183, 
2025-10-12 19:08:47,849 - training.trainer - INFO - Epoch 19, Step 66376: Loss=5.8192, Acc=0.200, 
2025-10-12 19:08:57,979 - training.trainer - INFO - Epoch 19, Step 66476: Loss=5.8405, Acc=0.156, 
2025-10-12 19:09:08,133 - training.trainer - INFO - Epoch 19, Step 66576: Loss=6.0845, Acc=0.222, 
2025-10-12 19:09:18,266 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.8750, Acc=0.211, 
2025-10-12 19:09:28,516 - training.trainer - INFO - Epoch 19, Step 66776: Loss=6.2260, Acc=0.235, 
2025-10-12 19:09:38,720 - training.trainer - INFO - Epoch 19, Step 66876: Loss=5.9701, Acc=0.233, 
2025-10-12 19:09:48,843 - training.trainer - INFO - Epoch 19, Step 66976: Loss=6.2102, Acc=0.169, 
2025-10-12 19:09:58,912 - training.trainer - INFO - Epoch 19, Step 67076: Loss=5.8273, Acc=0.192, 
2025-10-12 19:10:09,076 - training.trainer - INFO - Epoch 19, Step 67176: Loss=5.8437, Acc=0.188, 
2025-10-12 19:10:19,306 - training.trainer - INFO - Epoch 19, Step 67276: Loss=6.3054, Acc=0.200, 
2025-10-12 19:10:29,436 - training.trainer - INFO - Epoch 19, Step 67376: Loss=5.7928, Acc=0.179, 
2025-10-12 19:10:39,557 - training.trainer - INFO - Epoch 19, Step 67476: Loss=4.8962, Acc=0.500, 
2025-10-12 19:10:49,788 - training.trainer - INFO - Epoch 19, Step 67576: Loss=5.2064, Acc=0.214, 
2025-10-12 19:11:12,508 - training.trainer - INFO - Epoch 20/100 completed in 357.65s - Train Loss: 5.7373, Train Acc: 0.242, Val Loss: 5.7721, Val Acc: 0.243
2025-10-12 19:11:13,063 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-12 19:11:14,185 - training.trainer - INFO - New best model saved with validation loss: 5.7721
2025-10-12 19:11:14,186 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-12 19:11:24,771 - training.trainer - INFO - Epoch 20, Step 67759: Loss=4.9831, Acc=0.341, 
2025-10-12 19:11:34,648 - training.trainer - INFO - Epoch 20, Step 67859: Loss=5.5997, Acc=0.317, 
2025-10-12 19:11:44,613 - training.trainer - INFO - Epoch 20, Step 67959: Loss=6.1226, Acc=0.196, 
2025-10-12 19:11:54,427 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.3670, Acc=0.250, 
2025-10-12 19:12:04,424 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.9901, Acc=0.182, 
2025-10-12 19:12:14,500 - training.trainer - INFO - Epoch 20, Step 68259: Loss=4.7022, Acc=0.381, 
2025-10-12 19:12:24,443 - training.trainer - INFO - Epoch 20, Step 68359: Loss=5.7463, Acc=0.276, 
2025-10-12 19:12:34,474 - training.trainer - INFO - Epoch 20, Step 68459: Loss=5.8942, Acc=0.200, 
2025-10-12 19:12:44,504 - training.trainer - INFO - Epoch 20, Step 68559: Loss=6.2892, Acc=0.158, 
2025-10-12 19:12:53,889 - training.trainer - INFO - Epoch 20, Step 68659: Loss=5.1892, Acc=0.312, 
2025-10-12 19:13:03,371 - training.trainer - INFO - Epoch 20, Step 68759: Loss=6.4293, Acc=0.162, 
2025-10-12 19:13:13,560 - training.trainer - INFO - Epoch 20, Step 68859: Loss=5.0539, Acc=0.357, 
2025-10-12 19:13:23,794 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.1579, Acc=0.259, 
2025-10-12 19:13:33,487 - training.trainer - INFO - Epoch 20, Step 69059: Loss=6.1146, Acc=0.194, 
2025-10-12 19:13:42,838 - training.trainer - INFO - Epoch 20, Step 69159: Loss=6.3951, Acc=0.167, 
2025-10-12 19:13:52,098 - training.trainer - INFO - Epoch 20, Step 69259: Loss=3.8240, Acc=0.476, 
2025-10-12 19:14:01,525 - training.trainer - INFO - Epoch 20, Step 69359: Loss=6.8061, Acc=0.111, 
2025-10-12 19:14:10,927 - training.trainer - INFO - Epoch 20, Step 69459: Loss=5.4564, Acc=0.250, 
2025-10-12 19:14:20,270 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.0647, Acc=0.278, 
2025-10-12 19:14:29,449 - training.trainer - INFO - Epoch 20, Step 69659: Loss=6.5178, Acc=0.222, 
2025-10-12 19:14:38,872 - training.trainer - INFO - Epoch 20, Step 69759: Loss=6.1644, Acc=0.167, 
2025-10-12 19:14:48,388 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.6260, Acc=0.212, 
2025-10-12 19:14:58,393 - training.trainer - INFO - Epoch 20, Step 69959: Loss=6.2046, Acc=0.222, 
2025-10-12 19:15:08,576 - training.trainer - INFO - Epoch 20, Step 70059: Loss=4.9565, Acc=0.357, 
2025-10-12 19:15:18,814 - training.trainer - INFO - Epoch 20, Step 70159: Loss=6.1963, Acc=0.212, 
2025-10-12 19:15:28,754 - training.trainer - INFO - Epoch 20, Step 70259: Loss=6.4372, Acc=0.172, 
2025-10-12 19:15:38,957 - training.trainer - INFO - Epoch 20, Step 70359: Loss=6.2038, Acc=0.250, 
2025-10-12 19:15:49,213 - training.trainer - INFO - Epoch 20, Step 70459: Loss=5.3435, Acc=0.310, 
2025-10-12 19:15:59,303 - training.trainer - INFO - Epoch 20, Step 70559: Loss=5.6940, Acc=0.259, 
2025-10-12 19:16:09,476 - training.trainer - INFO - Epoch 20, Step 70659: Loss=6.3520, Acc=0.208, 
2025-10-12 19:16:19,507 - training.trainer - INFO - Epoch 20, Step 70759: Loss=4.6883, Acc=0.435, 
2025-10-12 19:16:29,686 - training.trainer - INFO - Epoch 20, Step 70859: Loss=5.7430, Acc=0.190, 
2025-10-12 19:16:39,973 - training.trainer - INFO - Epoch 20, Step 70959: Loss=5.2164, Acc=0.391, 
2025-10-12 19:17:02,052 - training.trainer - INFO - Epoch 21/100 completed in 347.87s - Train Loss: 5.7223, Train Acc: 0.247, Val Loss: 5.7843, Val Acc: 0.241
2025-10-12 19:17:12,648 - training.trainer - INFO - Epoch 21, Step 71142: Loss=5.9711, Acc=0.254, 
2025-10-12 19:17:22,722 - training.trainer - INFO - Epoch 21, Step 71242: Loss=5.7635, Acc=0.226, 
2025-10-12 19:17:32,868 - training.trainer - INFO - Epoch 21, Step 71342: Loss=4.6622, Acc=0.312, 
2025-10-12 19:17:43,100 - training.trainer - INFO - Epoch 21, Step 71442: Loss=5.3540, Acc=0.302, 
2025-10-12 19:17:53,336 - training.trainer - INFO - Epoch 21, Step 71542: Loss=5.9975, Acc=0.212, 
2025-10-12 19:18:03,485 - training.trainer - INFO - Epoch 21, Step 71642: Loss=6.2513, Acc=0.180, 
2025-10-12 19:18:13,582 - training.trainer - INFO - Epoch 21, Step 71742: Loss=6.1203, Acc=0.160, 
2025-10-12 19:18:23,695 - training.trainer - INFO - Epoch 21, Step 71842: Loss=5.8084, Acc=0.222, 
2025-10-12 19:18:33,862 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.6556, Acc=0.200, 
2025-10-12 19:18:43,919 - training.trainer - INFO - Epoch 21, Step 72042: Loss=5.3996, Acc=0.250, 
2025-10-12 19:18:54,137 - training.trainer - INFO - Epoch 21, Step 72142: Loss=5.2111, Acc=0.231, 
2025-10-12 19:19:04,206 - training.trainer - INFO - Epoch 21, Step 72242: Loss=6.2193, Acc=0.174, 
2025-10-12 19:19:14,296 - training.trainer - INFO - Epoch 21, Step 72342: Loss=6.1279, Acc=0.250, 
2025-10-12 19:19:24,590 - training.trainer - INFO - Epoch 21, Step 72442: Loss=5.0379, Acc=0.250, 
2025-10-12 19:19:34,832 - training.trainer - INFO - Epoch 21, Step 72542: Loss=4.2886, Acc=0.458, 
2025-10-12 19:19:44,974 - training.trainer - INFO - Epoch 21, Step 72642: Loss=6.2989, Acc=0.140, 
2025-10-12 19:19:55,155 - training.trainer - INFO - Epoch 21, Step 72742: Loss=6.1177, Acc=0.209, 
2025-10-12 19:20:05,273 - training.trainer - INFO - Epoch 21, Step 72842: Loss=6.3970, Acc=0.156, 
2025-10-12 19:20:15,354 - training.trainer - INFO - Epoch 21, Step 72942: Loss=5.0794, Acc=0.400, 
2025-10-12 19:20:25,458 - training.trainer - INFO - Epoch 21, Step 73042: Loss=6.7147, Acc=0.171, 
2025-10-12 19:20:35,502 - training.trainer - INFO - Epoch 21, Step 73142: Loss=4.7453, Acc=0.467, 
2025-10-12 19:20:45,482 - training.trainer - INFO - Epoch 21, Step 73242: Loss=6.3647, Acc=0.190, 
2025-10-12 19:20:55,606 - training.trainer - INFO - Epoch 21, Step 73342: Loss=5.4186, Acc=0.308, 
2025-10-12 19:21:05,717 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.6731, Acc=0.267, 
2025-10-12 19:21:15,890 - training.trainer - INFO - Epoch 21, Step 73542: Loss=6.0126, Acc=0.233, 
2025-10-12 19:21:25,982 - training.trainer - INFO - Epoch 21, Step 73642: Loss=6.2248, Acc=0.280, 
2025-10-12 19:21:36,053 - training.trainer - INFO - Epoch 21, Step 73742: Loss=5.3877, Acc=0.353, 
2025-10-12 19:21:46,285 - training.trainer - INFO - Epoch 21, Step 73842: Loss=6.4027, Acc=0.225, 
2025-10-12 19:21:56,392 - training.trainer - INFO - Epoch 21, Step 73942: Loss=5.8569, Acc=0.175, 
2025-10-12 19:22:06,440 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.6893, Acc=0.206, 
2025-10-12 19:22:16,544 - training.trainer - INFO - Epoch 21, Step 74142: Loss=6.2337, Acc=0.256, 
2025-10-12 19:22:26,749 - training.trainer - INFO - Epoch 21, Step 74242: Loss=6.0014, Acc=0.133, 
2025-10-12 19:22:36,960 - training.trainer - INFO - Epoch 21, Step 74342: Loss=5.7135, Acc=0.317, 
2025-10-12 19:22:59,059 - training.trainer - INFO - Epoch 22/100 completed in 357.01s - Train Loss: 5.6985, Train Acc: 0.249, Val Loss: 5.7953, Val Acc: 0.243
2025-10-12 19:23:09,117 - training.trainer - INFO - Epoch 22, Step 74525: Loss=6.0122, Acc=0.193, 
2025-10-12 19:23:18,706 - training.trainer - INFO - Epoch 22, Step 74625: Loss=3.3738, Acc=0.667, 
2025-10-12 19:23:28,235 - training.trainer - INFO - Epoch 22, Step 74725: Loss=5.1266, Acc=0.353, 
2025-10-12 19:23:37,799 - training.trainer - INFO - Epoch 22, Step 74825: Loss=6.6426, Acc=0.167, 
2025-10-12 19:23:47,277 - training.trainer - INFO - Epoch 22, Step 74925: Loss=5.7888, Acc=0.241, 
2025-10-12 19:23:56,875 - training.trainer - INFO - Epoch 22, Step 75025: Loss=5.9408, Acc=0.212, 
2025-10-12 19:24:07,021 - training.trainer - INFO - Epoch 22, Step 75125: Loss=6.0622, Acc=0.163, 
2025-10-12 19:24:17,082 - training.trainer - INFO - Epoch 22, Step 75225: Loss=6.0839, Acc=0.156, 
2025-10-12 19:24:27,111 - training.trainer - INFO - Epoch 22, Step 75325: Loss=4.5263, Acc=0.269, 
2025-10-12 19:24:36,924 - training.trainer - INFO - Epoch 22, Step 75425: Loss=5.2685, Acc=0.250, 
2025-10-12 19:24:46,739 - training.trainer - INFO - Epoch 22, Step 75525: Loss=4.8684, Acc=0.370, 
2025-10-12 19:24:56,548 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.4158, Acc=0.213, 
2025-10-12 19:25:06,420 - training.trainer - INFO - Epoch 22, Step 75725: Loss=5.8575, Acc=0.261, 
2025-10-12 19:25:16,295 - training.trainer - INFO - Epoch 22, Step 75825: Loss=6.1851, Acc=0.185, 
2025-10-12 19:25:26,120 - training.trainer - INFO - Epoch 22, Step 75925: Loss=6.0762, Acc=0.214, 
2025-10-12 19:25:36,369 - training.trainer - INFO - Epoch 22, Step 76025: Loss=5.6545, Acc=0.292, 
2025-10-12 19:25:46,448 - training.trainer - INFO - Epoch 22, Step 76125: Loss=6.4122, Acc=0.200, 
2025-10-12 19:25:56,371 - training.trainer - INFO - Epoch 22, Step 76225: Loss=6.1655, Acc=0.220, 
2025-10-12 19:26:06,292 - training.trainer - INFO - Epoch 22, Step 76325: Loss=4.5518, Acc=0.419, 
2025-10-12 19:26:16,272 - training.trainer - INFO - Epoch 22, Step 76425: Loss=5.6728, Acc=0.235, 
2025-10-12 19:26:26,199 - training.trainer - INFO - Epoch 22, Step 76525: Loss=6.0125, Acc=0.200, 
2025-10-12 19:26:36,086 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.1531, Acc=0.429, 
2025-10-12 19:26:45,958 - training.trainer - INFO - Epoch 22, Step 76725: Loss=5.2614, Acc=0.273, 
2025-10-12 19:26:55,789 - training.trainer - INFO - Epoch 22, Step 76825: Loss=5.6439, Acc=0.324, 
2025-10-12 19:27:05,655 - training.trainer - INFO - Epoch 22, Step 76925: Loss=5.0163, Acc=0.333, 
2025-10-12 19:27:15,519 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.8056, Acc=0.213, 
2025-10-12 19:27:25,435 - training.trainer - INFO - Epoch 22, Step 77125: Loss=5.9830, Acc=0.214, 
2025-10-12 19:27:35,492 - training.trainer - INFO - Epoch 22, Step 77225: Loss=4.3318, Acc=0.405, 
2025-10-12 19:27:45,415 - training.trainer - INFO - Epoch 22, Step 77325: Loss=5.8714, Acc=0.210, 
2025-10-12 19:27:55,436 - training.trainer - INFO - Epoch 22, Step 77425: Loss=6.0158, Acc=0.240, 
2025-10-12 19:28:05,558 - training.trainer - INFO - Epoch 22, Step 77525: Loss=5.7044, Acc=0.186, 
2025-10-12 19:28:15,568 - training.trainer - INFO - Epoch 22, Step 77625: Loss=5.1090, Acc=0.273, 
2025-10-12 19:28:25,559 - training.trainer - INFO - Epoch 22, Step 77725: Loss=6.0563, Acc=0.237, 
2025-10-12 19:28:47,790 - training.trainer - INFO - Epoch 23/100 completed in 348.73s - Train Loss: 5.6838, Train Acc: 0.251, Val Loss: 5.7724, Val Acc: 0.245
2025-10-12 19:28:57,998 - training.trainer - INFO - Epoch 23, Step 77908: Loss=6.1691, Acc=0.172, 
2025-10-12 19:29:08,181 - training.trainer - INFO - Epoch 23, Step 78008: Loss=6.4108, Acc=0.147, 
2025-10-12 19:29:18,046 - training.trainer - INFO - Epoch 23, Step 78108: Loss=5.1419, Acc=0.270, 
2025-10-12 19:29:28,012 - training.trainer - INFO - Epoch 23, Step 78208: Loss=6.0431, Acc=0.227, 
2025-10-12 19:29:38,151 - training.trainer - INFO - Epoch 23, Step 78308: Loss=5.9329, Acc=0.231, 
2025-10-12 19:29:47,995 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.1580, Acc=0.394, 
2025-10-12 19:29:57,757 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.9027, Acc=0.233, 
2025-10-12 19:30:07,589 - training.trainer - INFO - Epoch 23, Step 78608: Loss=5.7484, Acc=0.286, 
2025-10-12 19:30:17,413 - training.trainer - INFO - Epoch 23, Step 78708: Loss=6.7247, Acc=0.195, 
2025-10-12 19:30:27,241 - training.trainer - INFO - Epoch 23, Step 78808: Loss=4.6804, Acc=0.407, 
2025-10-12 19:30:37,023 - training.trainer - INFO - Epoch 23, Step 78908: Loss=6.1771, Acc=0.155, 
2025-10-12 19:30:46,757 - training.trainer - INFO - Epoch 23, Step 79008: Loss=6.2592, Acc=0.170, 
2025-10-12 19:30:56,602 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.5995, Acc=0.273, 
2025-10-12 19:31:06,476 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.7837, Acc=0.143, 
2025-10-12 19:31:16,389 - training.trainer - INFO - Epoch 23, Step 79308: Loss=5.9827, Acc=0.246, 
2025-10-12 19:31:26,270 - training.trainer - INFO - Epoch 23, Step 79408: Loss=6.4089, Acc=0.172, 
2025-10-12 19:31:36,236 - training.trainer - INFO - Epoch 23, Step 79508: Loss=6.1861, Acc=0.273, 
2025-10-12 19:31:46,031 - training.trainer - INFO - Epoch 23, Step 79608: Loss=5.7758, Acc=0.220, 
2025-10-12 19:31:55,956 - training.trainer - INFO - Epoch 23, Step 79708: Loss=6.0370, Acc=0.212, 
2025-10-12 19:32:05,813 - training.trainer - INFO - Epoch 23, Step 79808: Loss=5.5641, Acc=0.140, 
2025-10-12 19:32:15,771 - training.trainer - INFO - Epoch 23, Step 79908: Loss=6.2029, Acc=0.231, 
2025-10-12 19:32:25,758 - training.trainer - INFO - Epoch 23, Step 80008: Loss=5.8203, Acc=0.308, 
2025-10-12 19:32:35,582 - training.trainer - INFO - Epoch 23, Step 80108: Loss=4.1713, Acc=0.368, 
2025-10-12 19:32:45,472 - training.trainer - INFO - Epoch 23, Step 80208: Loss=5.9727, Acc=0.293, 
2025-10-12 19:32:55,216 - training.trainer - INFO - Epoch 23, Step 80308: Loss=5.8491, Acc=0.164, 
2025-10-12 19:33:05,027 - training.trainer - INFO - Epoch 23, Step 80408: Loss=6.3035, Acc=0.184, 
2025-10-12 19:33:14,804 - training.trainer - INFO - Epoch 23, Step 80508: Loss=5.9692, Acc=0.260, 
2025-10-12 19:33:24,677 - training.trainer - INFO - Epoch 23, Step 80608: Loss=4.6393, Acc=0.375, 
2025-10-12 19:33:34,508 - training.trainer - INFO - Epoch 23, Step 80708: Loss=4.7427, Acc=0.421, 
2025-10-12 19:33:44,267 - training.trainer - INFO - Epoch 23, Step 80808: Loss=5.8257, Acc=0.213, 
2025-10-12 19:33:54,004 - training.trainer - INFO - Epoch 23, Step 80908: Loss=4.8244, Acc=0.562, 
2025-10-12 19:34:03,954 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.6423, Acc=0.212, 
2025-10-12 19:34:13,801 - training.trainer - INFO - Epoch 23, Step 81108: Loss=5.4574, Acc=0.324, 
2025-10-12 19:34:35,803 - training.trainer - INFO - Epoch 24/100 completed in 348.01s - Train Loss: 5.6683, Train Acc: 0.252, Val Loss: 5.7657, Val Acc: 0.246
2025-10-12 19:34:36,574 - training.trainer - INFO - New best model saved with validation loss: 5.7657
2025-10-12 19:34:36,574 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_24.pt
2025-10-12 19:34:45,528 - training.trainer - INFO - Epoch 24, Step 81291: Loss=5.7687, Acc=0.205, 
2025-10-12 19:34:54,146 - training.trainer - INFO - Epoch 24, Step 81391: Loss=5.5607, Acc=0.296, 
2025-10-12 19:35:02,834 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.3911, Acc=0.138, 
2025-10-12 19:35:11,444 - training.trainer - INFO - Epoch 24, Step 81591: Loss=5.2411, Acc=0.179, 
2025-10-12 19:35:19,979 - training.trainer - INFO - Epoch 24, Step 81691: Loss=5.3230, Acc=0.240, 
2025-10-12 19:35:28,505 - training.trainer - INFO - Epoch 24, Step 81791: Loss=6.3573, Acc=0.235, 
2025-10-12 19:35:37,625 - training.trainer - INFO - Epoch 24, Step 81891: Loss=5.2719, Acc=0.263, 
2025-10-12 19:35:47,060 - training.trainer - INFO - Epoch 24, Step 81991: Loss=5.7300, Acc=0.256, 
2025-10-12 19:35:56,369 - training.trainer - INFO - Epoch 24, Step 82091: Loss=6.7784, Acc=0.174, 
2025-10-12 19:36:05,401 - training.trainer - INFO - Epoch 24, Step 82191: Loss=6.0225, Acc=0.300, 
2025-10-12 19:36:14,711 - training.trainer - INFO - Epoch 24, Step 82291: Loss=5.4769, Acc=0.239, 
2025-10-12 19:36:24,045 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.2306, Acc=0.286, 
2025-10-12 19:36:33,417 - training.trainer - INFO - Epoch 24, Step 82491: Loss=5.7415, Acc=0.308, 
2025-10-12 19:36:42,700 - training.trainer - INFO - Epoch 24, Step 82591: Loss=4.4894, Acc=0.478, 
2025-10-12 19:36:52,565 - training.trainer - INFO - Epoch 24, Step 82691: Loss=6.3242, Acc=0.162, 
2025-10-12 19:37:02,782 - training.trainer - INFO - Epoch 24, Step 82791: Loss=4.8055, Acc=0.375, 
2025-10-12 19:37:13,181 - training.trainer - INFO - Epoch 24, Step 82891: Loss=6.3389, Acc=0.172, 
2025-10-12 19:37:23,539 - training.trainer - INFO - Epoch 24, Step 82991: Loss=5.6536, Acc=0.259, 
2025-10-12 19:37:33,837 - training.trainer - INFO - Epoch 24, Step 83091: Loss=6.1723, Acc=0.169, 
2025-10-12 19:37:43,939 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.8174, Acc=0.417, 
2025-10-12 19:37:53,860 - training.trainer - INFO - Epoch 24, Step 83291: Loss=4.2072, Acc=0.429, 
2025-10-12 19:38:03,912 - training.trainer - INFO - Epoch 24, Step 83391: Loss=5.6872, Acc=0.222, 
2025-10-12 19:38:14,166 - training.trainer - INFO - Epoch 24, Step 83491: Loss=6.5432, Acc=0.202, 
2025-10-12 19:38:24,275 - training.trainer - INFO - Epoch 24, Step 83591: Loss=5.0557, Acc=0.364, 
2025-10-12 19:38:34,250 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.5727, Acc=0.237, 
2025-10-12 19:38:44,242 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.2515, Acc=0.259, 
2025-10-12 19:38:54,280 - training.trainer - INFO - Epoch 24, Step 83891: Loss=6.2076, Acc=0.188, 
2025-10-12 19:39:04,290 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.9029, Acc=0.200, 
2025-10-12 19:39:14,360 - training.trainer - INFO - Epoch 24, Step 84091: Loss=5.8539, Acc=0.191, 
2025-10-12 19:39:24,523 - training.trainer - INFO - Epoch 24, Step 84191: Loss=4.8734, Acc=0.261, 
2025-10-12 19:39:34,774 - training.trainer - INFO - Epoch 24, Step 84291: Loss=5.9846, Acc=0.200, 
2025-10-12 19:39:44,899 - training.trainer - INFO - Epoch 24, Step 84391: Loss=4.9369, Acc=0.333, 
2025-10-12 19:39:54,981 - training.trainer - INFO - Epoch 24, Step 84491: Loss=5.7434, Acc=0.229, 
2025-10-12 19:40:18,123 - training.trainer - INFO - Epoch 25/100 completed in 341.55s - Train Loss: 5.6524, Train Acc: 0.255, Val Loss: 5.7864, Val Acc: 0.250
2025-10-12 19:40:18,658 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-12 19:40:29,318 - training.trainer - INFO - Epoch 25, Step 84674: Loss=4.5895, Acc=0.344, 
2025-10-12 19:40:39,468 - training.trainer - INFO - Epoch 25, Step 84774: Loss=6.0078, Acc=0.300, 
2025-10-12 19:40:49,640 - training.trainer - INFO - Epoch 25, Step 84874: Loss=6.5362, Acc=0.196, 
2025-10-12 19:40:59,943 - training.trainer - INFO - Epoch 25, Step 84974: Loss=5.4510, Acc=0.346, 
2025-10-12 19:41:10,149 - training.trainer - INFO - Epoch 25, Step 85074: Loss=3.9342, Acc=0.462, 
2025-10-12 19:41:20,621 - training.trainer - INFO - Epoch 25, Step 85174: Loss=5.7356, Acc=0.196, 
2025-10-12 19:41:30,915 - training.trainer - INFO - Epoch 25, Step 85274: Loss=5.1739, Acc=0.300, 
2025-10-12 19:41:41,005 - training.trainer - INFO - Epoch 25, Step 85374: Loss=6.0266, Acc=0.250, 
2025-10-12 19:41:51,229 - training.trainer - INFO - Epoch 25, Step 85474: Loss=5.3799, Acc=0.208, 
2025-10-12 19:42:01,454 - training.trainer - INFO - Epoch 25, Step 85574: Loss=6.5002, Acc=0.182, 
2025-10-12 19:42:11,325 - training.trainer - INFO - Epoch 25, Step 85674: Loss=5.3292, Acc=0.385, 
2025-10-12 19:42:21,248 - training.trainer - INFO - Epoch 25, Step 85774: Loss=5.9820, Acc=0.242, 
2025-10-12 19:42:31,077 - training.trainer - INFO - Epoch 25, Step 85874: Loss=4.9758, Acc=0.240, 
2025-10-12 19:42:40,953 - training.trainer - INFO - Epoch 25, Step 85974: Loss=5.6477, Acc=0.200, 
2025-10-12 19:42:50,972 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.9740, Acc=0.213, 
2025-10-12 19:43:00,936 - training.trainer - INFO - Epoch 25, Step 86174: Loss=5.8311, Acc=0.250, 
2025-10-12 19:43:10,937 - training.trainer - INFO - Epoch 25, Step 86274: Loss=5.2837, Acc=0.353, 
2025-10-12 19:43:20,902 - training.trainer - INFO - Epoch 25, Step 86374: Loss=5.9147, Acc=0.233, 
2025-10-12 19:43:30,831 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.5270, Acc=0.314, 
2025-10-12 19:43:40,829 - training.trainer - INFO - Epoch 25, Step 86574: Loss=5.6301, Acc=0.250, 
2025-10-12 19:43:50,820 - training.trainer - INFO - Epoch 25, Step 86674: Loss=5.9164, Acc=0.279, 
2025-10-12 19:44:00,804 - training.trainer - INFO - Epoch 25, Step 86774: Loss=6.7144, Acc=0.120, 
2025-10-12 19:44:10,847 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.2345, Acc=0.200, 
2025-10-12 19:44:20,803 - training.trainer - INFO - Epoch 25, Step 86974: Loss=6.0928, Acc=0.250, 
2025-10-12 19:44:30,909 - training.trainer - INFO - Epoch 25, Step 87074: Loss=6.9722, Acc=0.190, 
2025-10-12 19:44:40,869 - training.trainer - INFO - Epoch 25, Step 87174: Loss=5.9174, Acc=0.234, 
2025-10-12 19:44:51,064 - training.trainer - INFO - Epoch 25, Step 87274: Loss=6.7524, Acc=0.200, 
2025-10-12 19:45:01,108 - training.trainer - INFO - Epoch 25, Step 87374: Loss=5.5746, Acc=0.289, 
2025-10-12 19:45:10,913 - training.trainer - INFO - Epoch 25, Step 87474: Loss=5.9414, Acc=0.170, 
2025-10-12 19:45:20,795 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.3432, Acc=0.306, 
2025-10-12 19:45:30,743 - training.trainer - INFO - Epoch 25, Step 87674: Loss=4.4191, Acc=0.481, 
2025-10-12 19:45:40,610 - training.trainer - INFO - Epoch 25, Step 87774: Loss=5.5645, Acc=0.283, 
2025-10-12 19:45:50,622 - training.trainer - INFO - Epoch 25, Step 87874: Loss=5.1359, Acc=0.156, 
2025-10-12 19:46:13,626 - training.trainer - INFO - Epoch 26/100 completed in 354.97s - Train Loss: 5.6306, Train Acc: 0.258, Val Loss: 5.7927, Val Acc: 0.249
2025-10-12 19:46:24,261 - training.trainer - INFO - Epoch 26, Step 88057: Loss=4.6709, Acc=0.429, 
2025-10-12 19:46:34,481 - training.trainer - INFO - Epoch 26, Step 88157: Loss=7.2306, Acc=0.186, 
2025-10-12 19:46:44,668 - training.trainer - INFO - Epoch 26, Step 88257: Loss=5.1045, Acc=0.333, 
2025-10-12 19:46:54,773 - training.trainer - INFO - Epoch 26, Step 88357: Loss=4.0831, Acc=0.394, 
2025-10-12 19:47:04,833 - training.trainer - INFO - Epoch 26, Step 88457: Loss=5.8457, Acc=0.200, 
2025-10-12 19:47:14,709 - training.trainer - INFO - Epoch 26, Step 88557: Loss=5.4327, Acc=0.275, 
2025-10-12 19:47:24,729 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.6201, Acc=0.282, 
2025-10-12 19:47:34,851 - training.trainer - INFO - Epoch 26, Step 88757: Loss=6.1751, Acc=0.133, 
2025-10-12 19:47:45,071 - training.trainer - INFO - Epoch 26, Step 88857: Loss=5.4365, Acc=0.237, 
2025-10-12 19:47:55,307 - training.trainer - INFO - Epoch 26, Step 88957: Loss=5.7842, Acc=0.275, 
2025-10-12 19:48:05,463 - training.trainer - INFO - Epoch 26, Step 89057: Loss=5.1777, Acc=0.286, 
2025-10-12 19:48:15,434 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.2191, Acc=0.316, 
2025-10-12 19:48:25,367 - training.trainer - INFO - Epoch 26, Step 89257: Loss=4.0164, Acc=0.500, 
2025-10-12 19:48:35,433 - training.trainer - INFO - Epoch 26, Step 89357: Loss=5.8105, Acc=0.294, 
2025-10-12 19:48:45,465 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.7962, Acc=0.214, 
2025-10-12 19:48:55,661 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.4054, Acc=0.206, 
2025-10-12 19:49:05,838 - training.trainer - INFO - Epoch 26, Step 89657: Loss=6.3791, Acc=0.357, 
2025-10-12 19:49:15,929 - training.trainer - INFO - Epoch 26, Step 89757: Loss=6.3717, Acc=0.195, 
2025-10-12 19:49:25,984 - training.trainer - INFO - Epoch 26, Step 89857: Loss=6.1108, Acc=0.207, 
2025-10-12 19:49:36,003 - training.trainer - INFO - Epoch 26, Step 89957: Loss=5.5397, Acc=0.238, 
2025-10-12 19:49:46,002 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.8003, Acc=0.346, 
2025-10-12 19:49:56,056 - training.trainer - INFO - Epoch 26, Step 90157: Loss=5.7580, Acc=0.350, 
2025-10-12 19:50:06,102 - training.trainer - INFO - Epoch 26, Step 90257: Loss=6.0378, Acc=0.220, 
2025-10-12 19:50:16,087 - training.trainer - INFO - Epoch 26, Step 90357: Loss=6.7152, Acc=0.129, 
2025-10-12 19:50:26,180 - training.trainer - INFO - Epoch 26, Step 90457: Loss=5.9984, Acc=0.217, 
2025-10-12 19:50:36,224 - training.trainer - INFO - Epoch 26, Step 90557: Loss=5.1506, Acc=0.304, 
2025-10-12 19:50:46,327 - training.trainer - INFO - Epoch 26, Step 90657: Loss=6.0267, Acc=0.200, 
2025-10-12 19:50:56,425 - training.trainer - INFO - Epoch 26, Step 90757: Loss=4.9083, Acc=0.241, 
2025-10-12 19:51:06,617 - training.trainer - INFO - Epoch 26, Step 90857: Loss=5.6772, Acc=0.228, 
2025-10-12 19:51:16,668 - training.trainer - INFO - Epoch 26, Step 90957: Loss=5.8755, Acc=0.263, 
2025-10-12 19:51:26,674 - training.trainer - INFO - Epoch 26, Step 91057: Loss=5.2192, Acc=0.308, 
2025-10-12 19:51:36,870 - training.trainer - INFO - Epoch 26, Step 91157: Loss=4.2601, Acc=0.417, 
2025-10-12 19:51:47,067 - training.trainer - INFO - Epoch 26, Step 91257: Loss=5.2836, Acc=0.269, 
2025-10-12 19:52:08,963 - training.trainer - INFO - Epoch 27/100 completed in 355.34s - Train Loss: 5.6185, Train Acc: 0.260, Val Loss: 5.7520, Val Acc: 0.248
2025-10-12 19:52:09,740 - training.trainer - INFO - New best model saved with validation loss: 5.7520
2025-10-12 19:52:09,741 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_27.pt
2025-10-12 19:52:18,942 - training.trainer - INFO - Epoch 27, Step 91440: Loss=5.5271, Acc=0.200, 
2025-10-12 19:52:27,562 - training.trainer - INFO - Epoch 27, Step 91540: Loss=5.6388, Acc=0.189, 
2025-10-12 19:52:36,092 - training.trainer - INFO - Epoch 27, Step 91640: Loss=5.0029, Acc=0.360, 
2025-10-12 19:52:44,678 - training.trainer - INFO - Epoch 27, Step 91740: Loss=6.3498, Acc=0.175, 
2025-10-12 19:52:53,346 - training.trainer - INFO - Epoch 27, Step 91840: Loss=5.5143, Acc=0.235, 
2025-10-12 19:53:02,077 - training.trainer - INFO - Epoch 27, Step 91940: Loss=5.9830, Acc=0.151, 
2025-10-12 19:53:10,820 - training.trainer - INFO - Epoch 27, Step 92040: Loss=5.6688, Acc=0.172, 
2025-10-12 19:53:19,444 - training.trainer - INFO - Epoch 27, Step 92140: Loss=6.3765, Acc=0.152, 
2025-10-12 19:53:28,111 - training.trainer - INFO - Epoch 27, Step 92240: Loss=5.2221, Acc=0.348, 
2025-10-12 19:53:36,806 - training.trainer - INFO - Epoch 27, Step 92340: Loss=5.6469, Acc=0.250, 
2025-10-12 19:53:45,527 - training.trainer - INFO - Epoch 27, Step 92440: Loss=6.0522, Acc=0.280, 
2025-10-12 19:53:54,426 - training.trainer - INFO - Epoch 27, Step 92540: Loss=5.5844, Acc=0.250, 
2025-10-12 19:54:04,666 - training.trainer - INFO - Epoch 27, Step 92640: Loss=5.5574, Acc=0.250, 
2025-10-12 19:54:14,731 - training.trainer - INFO - Epoch 27, Step 92740: Loss=5.2513, Acc=0.400, 
2025-10-12 19:54:24,965 - training.trainer - INFO - Epoch 27, Step 92840: Loss=5.2993, Acc=0.268, 
2025-10-12 19:54:35,017 - training.trainer - INFO - Epoch 27, Step 92940: Loss=6.0990, Acc=0.140, 
2025-10-12 19:54:45,126 - training.trainer - INFO - Epoch 27, Step 93040: Loss=3.5646, Acc=0.500, 
2025-10-12 19:54:55,240 - training.trainer - INFO - Epoch 27, Step 93140: Loss=4.9447, Acc=0.357, 
2025-10-12 19:55:05,538 - training.trainer - INFO - Epoch 27, Step 93240: Loss=6.0490, Acc=0.109, 
2025-10-12 19:55:15,821 - training.trainer - INFO - Epoch 27, Step 93340: Loss=6.0907, Acc=0.218, 
2025-10-12 19:55:26,058 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.3216, Acc=0.333, 
2025-10-12 19:55:36,244 - training.trainer - INFO - Epoch 27, Step 93540: Loss=5.8701, Acc=0.205, 
2025-10-12 19:55:46,386 - training.trainer - INFO - Epoch 27, Step 93640: Loss=5.6904, Acc=0.273, 
2025-10-12 19:55:56,524 - training.trainer - INFO - Epoch 27, Step 93740: Loss=5.4396, Acc=0.286, 
2025-10-12 19:56:06,576 - training.trainer - INFO - Epoch 27, Step 93840: Loss=5.0283, Acc=0.375, 
2025-10-12 19:56:16,816 - training.trainer - INFO - Epoch 27, Step 93940: Loss=6.1192, Acc=0.155, 
2025-10-12 19:56:26,972 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.0664, Acc=0.429, 
2025-10-12 19:56:37,133 - training.trainer - INFO - Epoch 27, Step 94140: Loss=5.0667, Acc=0.286, 
2025-10-12 19:56:47,442 - training.trainer - INFO - Epoch 27, Step 94240: Loss=5.9262, Acc=0.217, 
2025-10-12 19:56:57,534 - training.trainer - INFO - Epoch 27, Step 94340: Loss=6.1043, Acc=0.190, 
2025-10-12 19:57:07,528 - training.trainer - INFO - Epoch 27, Step 94440: Loss=3.9390, Acc=0.407, 
2025-10-12 19:57:17,544 - training.trainer - INFO - Epoch 27, Step 94540: Loss=4.3576, Acc=0.333, 
2025-10-12 19:57:27,548 - training.trainer - INFO - Epoch 27, Step 94640: Loss=4.6257, Acc=0.429, 
2025-10-12 19:57:49,761 - training.trainer - INFO - Epoch 28/100 completed in 340.02s - Train Loss: 5.6051, Train Acc: 0.262, Val Loss: 5.7494, Val Acc: 0.254
2025-10-12 19:57:50,744 - training.trainer - INFO - New best model saved with validation loss: 5.7494
2025-10-12 19:57:50,744 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_28.pt
2025-10-12 19:58:00,069 - training.trainer - INFO - Epoch 28, Step 94823: Loss=5.6107, Acc=0.240, 
2025-10-12 19:58:08,759 - training.trainer - INFO - Epoch 28, Step 94923: Loss=6.1218, Acc=0.188, 
2025-10-12 19:58:18,468 - training.trainer - INFO - Epoch 28, Step 95023: Loss=5.6557, Acc=0.200, 
2025-10-12 19:58:28,630 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.7797, Acc=0.214, 
2025-10-12 19:58:38,813 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.4554, Acc=0.323, 
2025-10-12 19:58:49,044 - training.trainer - INFO - Epoch 28, Step 95323: Loss=6.2768, Acc=0.149, 
2025-10-12 19:58:58,962 - training.trainer - INFO - Epoch 28, Step 95423: Loss=4.9303, Acc=0.320, 
2025-10-12 19:59:08,865 - training.trainer - INFO - Epoch 28, Step 95523: Loss=6.1617, Acc=0.245, 
2025-10-12 19:59:18,829 - training.trainer - INFO - Epoch 28, Step 95623: Loss=3.9401, Acc=0.348, 
2025-10-12 19:59:28,690 - training.trainer - INFO - Epoch 28, Step 95723: Loss=4.7762, Acc=0.211, 
2025-10-12 19:59:38,628 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.3458, Acc=0.304, 
2025-10-12 19:59:48,638 - training.trainer - INFO - Epoch 28, Step 95923: Loss=5.4816, Acc=0.278, 
2025-10-12 19:59:58,615 - training.trainer - INFO - Epoch 28, Step 96023: Loss=6.2604, Acc=0.192, 
2025-10-12 20:00:08,547 - training.trainer - INFO - Epoch 28, Step 96123: Loss=6.0212, Acc=0.220, 
2025-10-12 20:00:18,506 - training.trainer - INFO - Epoch 28, Step 96223: Loss=5.2632, Acc=0.292, 
2025-10-12 20:00:28,623 - training.trainer - INFO - Epoch 28, Step 96323: Loss=6.5278, Acc=0.169, 
2025-10-12 20:00:38,706 - training.trainer - INFO - Epoch 28, Step 96423: Loss=5.7163, Acc=0.353, 
2025-10-12 20:00:48,642 - training.trainer - INFO - Epoch 28, Step 96523: Loss=5.3917, Acc=0.286, 
2025-10-12 20:00:58,598 - training.trainer - INFO - Epoch 28, Step 96623: Loss=6.0719, Acc=0.238, 
2025-10-12 20:01:08,559 - training.trainer - INFO - Epoch 28, Step 96723: Loss=6.4261, Acc=0.280, 
2025-10-12 20:01:18,551 - training.trainer - INFO - Epoch 28, Step 96823: Loss=6.2510, Acc=0.212, 
2025-10-12 20:01:28,578 - training.trainer - INFO - Epoch 28, Step 96923: Loss=5.3822, Acc=0.190, 
2025-10-12 20:01:38,538 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.9452, Acc=0.240, 
2025-10-12 20:01:48,551 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.8301, Acc=0.227, 
2025-10-12 20:01:58,773 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.9911, Acc=0.200, 
2025-10-12 20:02:08,906 - training.trainer - INFO - Epoch 28, Step 97323: Loss=5.4182, Acc=0.185, 
2025-10-12 20:02:19,048 - training.trainer - INFO - Epoch 28, Step 97423: Loss=5.9755, Acc=0.179, 
2025-10-12 20:02:29,236 - training.trainer - INFO - Epoch 28, Step 97523: Loss=5.4722, Acc=0.310, 
2025-10-12 20:02:39,474 - training.trainer - INFO - Epoch 28, Step 97623: Loss=6.0644, Acc=0.229, 
2025-10-12 20:02:49,693 - training.trainer - INFO - Epoch 28, Step 97723: Loss=5.4196, Acc=0.233, 
2025-10-12 20:03:00,054 - training.trainer - INFO - Epoch 28, Step 97823: Loss=4.1933, Acc=0.354, 
2025-10-12 20:03:10,295 - training.trainer - INFO - Epoch 28, Step 97923: Loss=5.4519, Acc=0.280, 
2025-10-12 20:03:20,319 - training.trainer - INFO - Epoch 28, Step 98023: Loss=4.6165, Acc=0.409, 
2025-10-12 20:03:43,322 - training.trainer - INFO - Epoch 29/100 completed in 352.58s - Train Loss: 5.5852, Train Acc: 0.264, Val Loss: 5.7510, Val Acc: 0.252
2025-10-12 20:03:53,863 - training.trainer - INFO - Epoch 29, Step 98206: Loss=5.6861, Acc=0.243, 
2025-10-12 20:04:03,816 - training.trainer - INFO - Epoch 29, Step 98306: Loss=4.2572, Acc=0.321, 
2025-10-12 20:04:13,921 - training.trainer - INFO - Epoch 29, Step 98406: Loss=4.8986, Acc=0.407, 
2025-10-12 20:04:24,119 - training.trainer - INFO - Epoch 29, Step 98506: Loss=4.8375, Acc=0.316, 
2025-10-12 20:04:34,279 - training.trainer - INFO - Epoch 29, Step 98606: Loss=5.5846, Acc=0.154, 
2025-10-12 20:04:44,442 - training.trainer - INFO - Epoch 29, Step 98706: Loss=6.0706, Acc=0.233, 
2025-10-12 20:04:54,745 - training.trainer - INFO - Epoch 29, Step 98806: Loss=5.6405, Acc=0.250, 
2025-10-12 20:05:04,980 - training.trainer - INFO - Epoch 29, Step 98906: Loss=4.9567, Acc=0.333, 
2025-10-12 20:05:15,250 - training.trainer - INFO - Epoch 29, Step 99006: Loss=5.0134, Acc=0.267, 
2025-10-12 20:05:25,368 - training.trainer - INFO - Epoch 29, Step 99106: Loss=6.4023, Acc=0.164, 
2025-10-12 20:05:35,666 - training.trainer - INFO - Epoch 29, Step 99206: Loss=4.9985, Acc=0.353, 
2025-10-12 20:05:45,730 - training.trainer - INFO - Epoch 29, Step 99306: Loss=4.1116, Acc=0.452, 
2025-10-12 20:05:55,821 - training.trainer - INFO - Epoch 29, Step 99406: Loss=6.2633, Acc=0.172, 
2025-10-12 20:06:05,807 - training.trainer - INFO - Epoch 29, Step 99506: Loss=5.2671, Acc=0.391, 
2025-10-12 20:06:15,813 - training.trainer - INFO - Epoch 29, Step 99606: Loss=5.4105, Acc=0.412, 
2025-10-12 20:06:25,814 - training.trainer - INFO - Epoch 29, Step 99706: Loss=6.5457, Acc=0.176, 
2025-10-12 20:06:35,873 - training.trainer - INFO - Epoch 29, Step 99806: Loss=5.5758, Acc=0.353, 
2025-10-12 20:06:45,827 - training.trainer - INFO - Epoch 29, Step 99906: Loss=4.2659, Acc=0.421, 
2025-10-12 20:06:56,028 - training.trainer - INFO - Epoch 29, Step 100006: Loss=6.0215, Acc=0.158, 
2025-10-12 20:07:06,052 - training.trainer - INFO - Epoch 29, Step 100106: Loss=5.8939, Acc=0.267, 
2025-10-12 20:07:16,227 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.8921, Acc=0.256, 
2025-10-12 20:07:26,485 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.7096, Acc=0.281, 
2025-10-12 20:07:36,568 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.2388, Acc=0.182, 
2025-10-12 20:07:46,643 - training.trainer - INFO - Epoch 29, Step 100506: Loss=5.9425, Acc=0.192, 
2025-10-12 20:07:56,741 - training.trainer - INFO - Epoch 29, Step 100606: Loss=5.3750, Acc=0.333, 
2025-10-12 20:08:06,883 - training.trainer - INFO - Epoch 29, Step 100706: Loss=5.8859, Acc=0.222, 
2025-10-12 20:08:16,982 - training.trainer - INFO - Epoch 29, Step 100806: Loss=4.5538, Acc=0.333, 
2025-10-12 20:08:27,045 - training.trainer - INFO - Epoch 29, Step 100906: Loss=6.5616, Acc=0.207, 
2025-10-12 20:08:37,099 - training.trainer - INFO - Epoch 29, Step 101006: Loss=5.0544, Acc=0.292, 
2025-10-12 20:08:47,167 - training.trainer - INFO - Epoch 29, Step 101106: Loss=4.0927, Acc=0.529, 
2025-10-12 20:08:57,234 - training.trainer - INFO - Epoch 29, Step 101206: Loss=5.8844, Acc=0.185, 
2025-10-12 20:09:07,634 - training.trainer - INFO - Epoch 29, Step 101306: Loss=5.4066, Acc=0.246, 
2025-10-12 20:09:17,718 - training.trainer - INFO - Epoch 29, Step 101406: Loss=4.3454, Acc=0.429, 
2025-10-12 20:09:40,111 - training.trainer - INFO - Epoch 30/100 completed in 356.79s - Train Loss: 5.5722, Train Acc: 0.267, Val Loss: 5.7796, Val Acc: 0.252
2025-10-12 20:09:40,676 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-10-12 20:09:51,108 - training.trainer - INFO - Epoch 30, Step 101589: Loss=5.4894, Acc=0.273, 
2025-10-12 20:10:01,208 - training.trainer - INFO - Epoch 30, Step 101689: Loss=5.9232, Acc=0.288, 
2025-10-12 20:10:11,472 - training.trainer - INFO - Epoch 30, Step 101789: Loss=4.5289, Acc=0.385, 
2025-10-12 20:10:21,943 - training.trainer - INFO - Epoch 30, Step 101889: Loss=4.6487, Acc=0.333, 
2025-10-12 20:10:32,131 - training.trainer - INFO - Epoch 30, Step 101989: Loss=5.6303, Acc=0.260, 
2025-10-12 20:10:42,329 - training.trainer - INFO - Epoch 30, Step 102089: Loss=5.6044, Acc=0.280, 
2025-10-12 20:10:52,423 - training.trainer - INFO - Epoch 30, Step 102189: Loss=5.3164, Acc=0.318, 
2025-10-12 20:11:02,447 - training.trainer - INFO - Epoch 30, Step 102289: Loss=6.0575, Acc=0.296, 
2025-10-12 20:11:12,384 - training.trainer - INFO - Epoch 30, Step 102389: Loss=6.2677, Acc=0.250, 
2025-10-12 20:11:22,352 - training.trainer - INFO - Epoch 30, Step 102489: Loss=4.9740, Acc=0.360, 
2025-10-12 20:11:32,640 - training.trainer - INFO - Epoch 30, Step 102589: Loss=4.7099, Acc=0.389, 
2025-10-12 20:11:42,762 - training.trainer - INFO - Epoch 30, Step 102689: Loss=4.8460, Acc=0.474, 
2025-10-12 20:11:52,780 - training.trainer - INFO - Epoch 30, Step 102789: Loss=6.5261, Acc=0.182, 
2025-10-12 20:12:02,821 - training.trainer - INFO - Epoch 30, Step 102889: Loss=6.0240, Acc=0.207, 
2025-10-12 20:12:13,021 - training.trainer - INFO - Epoch 30, Step 102989: Loss=6.2696, Acc=0.182, 
2025-10-12 20:12:23,062 - training.trainer - INFO - Epoch 30, Step 103089: Loss=5.7901, Acc=0.295, 
2025-10-12 20:12:32,954 - training.trainer - INFO - Epoch 30, Step 103189: Loss=4.5952, Acc=0.296, 
2025-10-12 20:12:43,086 - training.trainer - INFO - Epoch 30, Step 103289: Loss=4.7864, Acc=0.273, 
2025-10-12 20:12:53,300 - training.trainer - INFO - Epoch 30, Step 103389: Loss=5.8651, Acc=0.186, 
2025-10-12 20:13:03,526 - training.trainer - INFO - Epoch 30, Step 103489: Loss=4.8902, Acc=0.308, 
2025-10-12 20:13:13,720 - training.trainer - INFO - Epoch 30, Step 103589: Loss=5.6314, Acc=0.281, 
2025-10-12 20:13:23,948 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.6634, Acc=0.188, 
2025-10-12 20:13:34,249 - training.trainer - INFO - Epoch 30, Step 103789: Loss=5.8272, Acc=0.280, 
2025-10-12 20:13:44,593 - training.trainer - INFO - Epoch 30, Step 103889: Loss=6.4546, Acc=0.269, 
2025-10-12 20:13:54,690 - training.trainer - INFO - Epoch 30, Step 103989: Loss=5.4385, Acc=0.259, 
2025-10-12 20:14:04,525 - training.trainer - INFO - Epoch 30, Step 104089: Loss=4.3571, Acc=0.529, 
2025-10-12 20:14:14,416 - training.trainer - INFO - Epoch 30, Step 104189: Loss=6.0155, Acc=0.208, 
2025-10-12 20:14:24,639 - training.trainer - INFO - Epoch 30, Step 104289: Loss=6.2261, Acc=0.161, 
2025-10-12 20:14:34,895 - training.trainer - INFO - Epoch 30, Step 104389: Loss=5.3897, Acc=0.312, 
2025-10-12 20:14:44,712 - training.trainer - INFO - Epoch 30, Step 104489: Loss=5.3160, Acc=0.312, 
2025-10-12 20:14:54,744 - training.trainer - INFO - Epoch 30, Step 104589: Loss=3.2350, Acc=0.520, 
2025-10-12 20:15:04,614 - training.trainer - INFO - Epoch 30, Step 104689: Loss=4.9141, Acc=0.348, 
2025-10-12 20:15:14,608 - training.trainer - INFO - Epoch 30, Step 104789: Loss=4.9576, Acc=0.211, 
2025-10-12 20:15:37,499 - training.trainer - INFO - Epoch 31/100 completed in 356.82s - Train Loss: 5.5575, Train Acc: 0.268, Val Loss: 5.7494, Val Acc: 0.255
2025-10-12 20:15:47,896 - training.trainer - INFO - Epoch 31, Step 104972: Loss=5.7963, Acc=0.213, 
2025-10-12 20:15:57,847 - training.trainer - INFO - Epoch 31, Step 105072: Loss=6.0683, Acc=0.192, 
2025-10-12 20:16:07,876 - training.trainer - INFO - Epoch 31, Step 105172: Loss=5.7709, Acc=0.317, 
2025-10-12 20:16:17,846 - training.trainer - INFO - Epoch 31, Step 105272: Loss=6.6639, Acc=0.152, 
2025-10-12 20:16:27,832 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.2280, Acc=0.294, 
2025-10-12 20:16:37,813 - training.trainer - INFO - Epoch 31, Step 105472: Loss=5.1873, Acc=0.308, 
2025-10-12 20:16:47,820 - training.trainer - INFO - Epoch 31, Step 105572: Loss=3.9317, Acc=0.455, 
2025-10-12 20:16:57,824 - training.trainer - INFO - Epoch 31, Step 105672: Loss=5.7678, Acc=0.348, 
2025-10-12 20:17:07,897 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.2895, Acc=0.292, 
2025-10-12 20:17:17,994 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.6079, Acc=0.234, 
2025-10-12 20:17:28,267 - training.trainer - INFO - Epoch 31, Step 105972: Loss=2.4274, Acc=0.882, 
2025-10-12 20:17:38,355 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.1581, Acc=0.423, 
2025-10-12 20:17:48,465 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.2106, Acc=0.346, 
2025-10-12 20:17:58,668 - training.trainer - INFO - Epoch 31, Step 106272: Loss=5.4392, Acc=0.216, 
2025-10-12 20:18:08,880 - training.trainer - INFO - Epoch 31, Step 106372: Loss=6.5573, Acc=0.172, 
2025-10-12 20:18:18,926 - training.trainer - INFO - Epoch 31, Step 106472: Loss=5.8640, Acc=0.282, 
2025-10-12 20:18:29,051 - training.trainer - INFO - Epoch 31, Step 106572: Loss=5.8937, Acc=0.179, 
2025-10-12 20:18:39,183 - training.trainer - INFO - Epoch 31, Step 106672: Loss=6.1389, Acc=0.140, 
2025-10-12 20:18:49,463 - training.trainer - INFO - Epoch 31, Step 106772: Loss=6.0045, Acc=0.238, 
2025-10-12 20:18:59,830 - training.trainer - INFO - Epoch 31, Step 106872: Loss=6.1418, Acc=0.350, 
2025-10-12 20:19:10,069 - training.trainer - INFO - Epoch 31, Step 106972: Loss=6.4568, Acc=0.132, 
2025-10-12 20:19:20,276 - training.trainer - INFO - Epoch 31, Step 107072: Loss=5.2105, Acc=0.312, 
2025-10-12 20:19:30,469 - training.trainer - INFO - Epoch 31, Step 107172: Loss=4.2539, Acc=0.414, 
2025-10-12 20:19:40,607 - training.trainer - INFO - Epoch 31, Step 107272: Loss=5.5311, Acc=0.233, 
2025-10-12 20:19:50,719 - training.trainer - INFO - Epoch 31, Step 107372: Loss=6.3836, Acc=0.125, 
2025-10-12 20:20:00,832 - training.trainer - INFO - Epoch 31, Step 107472: Loss=6.2092, Acc=0.200, 
2025-10-12 20:20:10,916 - training.trainer - INFO - Epoch 31, Step 107572: Loss=5.2476, Acc=0.370, 
2025-10-12 20:20:20,896 - training.trainer - INFO - Epoch 31, Step 107672: Loss=4.4972, Acc=0.517, 
2025-10-12 20:20:30,925 - training.trainer - INFO - Epoch 31, Step 107772: Loss=3.0730, Acc=0.556, 
2025-10-12 20:20:41,018 - training.trainer - INFO - Epoch 31, Step 107872: Loss=6.2821, Acc=0.153, 
2025-10-12 20:20:51,100 - training.trainer - INFO - Epoch 31, Step 107972: Loss=4.9255, Acc=0.412, 
2025-10-12 20:21:01,341 - training.trainer - INFO - Epoch 31, Step 108072: Loss=5.2387, Acc=0.370, 
2025-10-12 20:21:11,530 - training.trainer - INFO - Epoch 31, Step 108172: Loss=6.0066, Acc=0.200, 
2025-10-12 20:21:34,125 - training.trainer - INFO - Epoch 32/100 completed in 356.63s - Train Loss: 5.5429, Train Acc: 0.270, Val Loss: 5.7232, Val Acc: 0.256
2025-10-12 20:21:35,284 - training.trainer - INFO - New best model saved with validation loss: 5.7232
2025-10-12 20:21:35,284 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_32.pt
2025-10-12 20:21:45,790 - training.trainer - INFO - Epoch 32, Step 108355: Loss=6.4764, Acc=0.231, 
2025-10-12 20:21:55,975 - training.trainer - INFO - Epoch 32, Step 108455: Loss=5.0498, Acc=0.346, 
2025-10-12 20:22:06,171 - training.trainer - INFO - Epoch 32, Step 108555: Loss=5.8926, Acc=0.314, 
2025-10-12 20:22:16,363 - training.trainer - INFO - Epoch 32, Step 108655: Loss=5.7212, Acc=0.220, 
2025-10-12 20:22:26,376 - training.trainer - INFO - Epoch 32, Step 108755: Loss=4.7458, Acc=0.333, 
2025-10-12 20:22:36,175 - training.trainer - INFO - Epoch 32, Step 108855: Loss=4.1188, Acc=0.481, 
2025-10-12 20:22:46,147 - training.trainer - INFO - Epoch 32, Step 108955: Loss=3.6403, Acc=0.455, 
2025-10-12 20:22:56,043 - training.trainer - INFO - Epoch 32, Step 109055: Loss=5.8714, Acc=0.250, 
2025-10-12 20:23:05,954 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.5427, Acc=0.267, 
2025-10-12 20:23:15,932 - training.trainer - INFO - Epoch 32, Step 109255: Loss=5.8034, Acc=0.203, 
2025-10-12 20:23:25,789 - training.trainer - INFO - Epoch 32, Step 109355: Loss=5.7860, Acc=0.222, 
2025-10-12 20:23:35,676 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.9896, Acc=0.250, 
2025-10-12 20:23:45,594 - training.trainer - INFO - Epoch 32, Step 109555: Loss=4.9772, Acc=0.200, 
2025-10-12 20:23:55,499 - training.trainer - INFO - Epoch 32, Step 109655: Loss=6.0665, Acc=0.154, 
2025-10-12 20:24:05,413 - training.trainer - INFO - Epoch 32, Step 109755: Loss=5.6354, Acc=0.160, 
2025-10-12 20:24:15,438 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.6907, Acc=0.205, 
2025-10-12 20:24:25,366 - training.trainer - INFO - Epoch 32, Step 109955: Loss=5.5444, Acc=0.300, 
2025-10-12 20:24:35,233 - training.trainer - INFO - Epoch 32, Step 110055: Loss=5.4647, Acc=0.409, 
2025-10-12 20:24:45,208 - training.trainer - INFO - Epoch 32, Step 110155: Loss=5.0486, Acc=0.238, 
2025-10-12 20:24:55,246 - training.trainer - INFO - Epoch 32, Step 110255: Loss=5.5721, Acc=0.263, 
2025-10-12 20:25:05,161 - training.trainer - INFO - Epoch 32, Step 110355: Loss=5.4279, Acc=0.235, 
2025-10-12 20:25:15,116 - training.trainer - INFO - Epoch 32, Step 110455: Loss=6.3431, Acc=0.192, 
2025-10-12 20:25:25,072 - training.trainer - INFO - Epoch 32, Step 110555: Loss=5.5810, Acc=0.250, 
2025-10-12 20:25:35,055 - training.trainer - INFO - Epoch 32, Step 110655: Loss=4.5995, Acc=0.250, 
2025-10-12 20:25:44,940 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.7524, Acc=0.212, 
2025-10-12 20:25:55,032 - training.trainer - INFO - Epoch 32, Step 110855: Loss=5.9104, Acc=0.176, 
2025-10-12 20:26:04,980 - training.trainer - INFO - Epoch 32, Step 110955: Loss=5.2140, Acc=0.286, 
2025-10-12 20:26:14,864 - training.trainer - INFO - Epoch 32, Step 111055: Loss=5.7593, Acc=0.275, 
2025-10-12 20:26:24,817 - training.trainer - INFO - Epoch 32, Step 111155: Loss=6.1351, Acc=0.179, 
2025-10-12 20:26:34,841 - training.trainer - INFO - Epoch 32, Step 111255: Loss=6.0348, Acc=0.148, 
2025-10-12 20:26:44,841 - training.trainer - INFO - Epoch 32, Step 111355: Loss=5.5818, Acc=0.400, 
2025-10-12 20:26:54,786 - training.trainer - INFO - Epoch 32, Step 111455: Loss=5.6417, Acc=0.200, 
2025-10-12 20:27:04,755 - training.trainer - INFO - Epoch 32, Step 111555: Loss=6.6142, Acc=0.118, 
2025-10-12 20:27:27,371 - training.trainer - INFO - Epoch 33/100 completed in 352.09s - Train Loss: 5.5328, Train Acc: 0.273, Val Loss: 5.7444, Val Acc: 0.256
2025-10-12 20:27:36,197 - training.trainer - INFO - Epoch 33, Step 111738: Loss=5.0484, Acc=0.333, 
2025-10-12 20:27:44,726 - training.trainer - INFO - Epoch 33, Step 111838: Loss=3.5376, Acc=0.500, 
2025-10-12 20:27:53,253 - training.trainer - INFO - Epoch 33, Step 111938: Loss=5.8455, Acc=0.250, 
2025-10-12 20:28:01,780 - training.trainer - INFO - Epoch 33, Step 112038: Loss=5.9049, Acc=0.175, 
2025-10-12 20:28:10,292 - training.trainer - INFO - Epoch 33, Step 112138: Loss=6.1298, Acc=0.205, 
2025-10-12 20:28:18,858 - training.trainer - INFO - Epoch 33, Step 112238: Loss=6.2385, Acc=0.194, 
2025-10-12 20:28:27,308 - training.trainer - INFO - Epoch 33, Step 112338: Loss=5.4957, Acc=0.282, 
2025-10-12 20:28:35,834 - training.trainer - INFO - Epoch 33, Step 112438: Loss=6.2660, Acc=0.192, 
2025-10-12 20:28:44,337 - training.trainer - INFO - Epoch 33, Step 112538: Loss=5.7180, Acc=0.222, 
2025-10-12 20:28:52,883 - training.trainer - INFO - Epoch 33, Step 112638: Loss=5.1081, Acc=0.333, 
2025-10-12 20:29:01,461 - training.trainer - INFO - Epoch 33, Step 112738: Loss=5.2596, Acc=0.250, 
2025-10-12 20:29:09,975 - training.trainer - INFO - Epoch 33, Step 112838: Loss=5.7020, Acc=0.333, 
2025-10-12 20:29:18,562 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.9087, Acc=0.262, 
2025-10-12 20:29:27,101 - training.trainer - INFO - Epoch 33, Step 113038: Loss=3.3362, Acc=0.588, 
2025-10-12 20:29:35,734 - training.trainer - INFO - Epoch 33, Step 113138: Loss=5.9612, Acc=0.262, 
2025-10-12 20:29:44,274 - training.trainer - INFO - Epoch 33, Step 113238: Loss=6.0171, Acc=0.229, 
2025-10-12 20:29:52,773 - training.trainer - INFO - Epoch 33, Step 113338: Loss=5.6710, Acc=0.267, 
2025-10-12 20:30:01,279 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.8680, Acc=0.219, 
2025-10-12 20:30:09,909 - training.trainer - INFO - Epoch 33, Step 113538: Loss=5.7479, Acc=0.306, 
2025-10-12 20:30:19,534 - training.trainer - INFO - Epoch 33, Step 113638: Loss=6.4770, Acc=0.205, 
2025-10-12 20:30:29,502 - training.trainer - INFO - Epoch 33, Step 113738: Loss=6.5602, Acc=0.136, 
2025-10-12 20:30:39,578 - training.trainer - INFO - Epoch 33, Step 113838: Loss=5.3160, Acc=0.303, 
2025-10-12 20:30:49,532 - training.trainer - INFO - Epoch 33, Step 113938: Loss=6.2860, Acc=0.250, 
2025-10-12 20:30:59,513 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.1198, Acc=0.222, 
2025-10-12 20:31:09,543 - training.trainer - INFO - Epoch 33, Step 114138: Loss=5.3098, Acc=0.321, 
2025-10-12 20:31:19,455 - training.trainer - INFO - Epoch 33, Step 114238: Loss=6.6655, Acc=0.113, 
2025-10-12 20:31:29,372 - training.trainer - INFO - Epoch 33, Step 114338: Loss=4.8359, Acc=0.308, 
2025-10-12 20:31:39,262 - training.trainer - INFO - Epoch 33, Step 114438: Loss=6.1509, Acc=0.256, 
2025-10-12 20:31:49,151 - training.trainer - INFO - Epoch 33, Step 114538: Loss=5.6048, Acc=0.229, 
2025-10-12 20:31:59,029 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.4515, Acc=0.250, 
2025-10-12 20:32:08,859 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.3654, Acc=0.250, 
2025-10-12 20:32:18,712 - training.trainer - INFO - Epoch 33, Step 114838: Loss=6.0864, Acc=0.237, 
2025-10-12 20:32:28,589 - training.trainer - INFO - Epoch 33, Step 114938: Loss=5.6626, Acc=0.188, 
2025-10-12 20:32:50,357 - training.trainer - INFO - Epoch 34/100 completed in 322.99s - Train Loss: 5.5134, Train Acc: 0.276, Val Loss: 5.7431, Val Acc: 0.255
2025-10-12 20:33:00,473 - training.trainer - INFO - Epoch 34, Step 115121: Loss=5.7711, Acc=0.233, 
2025-10-12 20:33:10,369 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.3235, Acc=0.245, 
2025-10-12 20:33:20,221 - training.trainer - INFO - Epoch 34, Step 115321: Loss=4.0192, Acc=0.429, 
2025-10-12 20:33:30,202 - training.trainer - INFO - Epoch 34, Step 115421: Loss=5.2161, Acc=0.273, 
2025-10-12 20:33:40,075 - training.trainer - INFO - Epoch 34, Step 115521: Loss=4.9854, Acc=0.290, 
2025-10-12 20:33:49,958 - training.trainer - INFO - Epoch 34, Step 115621: Loss=4.5671, Acc=0.360, 
2025-10-12 20:33:59,887 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.8418, Acc=0.308, 
2025-10-12 20:34:09,961 - training.trainer - INFO - Epoch 34, Step 115821: Loss=5.7067, Acc=0.244, 
2025-10-12 20:34:19,950 - training.trainer - INFO - Epoch 34, Step 115921: Loss=5.2521, Acc=0.327, 
2025-10-12 20:34:29,791 - training.trainer - INFO - Epoch 34, Step 116021: Loss=6.5568, Acc=0.163, 
2025-10-12 20:34:39,648 - training.trainer - INFO - Epoch 34, Step 116121: Loss=5.3526, Acc=0.200, 
2025-10-12 20:34:49,753 - training.trainer - INFO - Epoch 34, Step 116221: Loss=6.0179, Acc=0.197, 
2025-10-12 20:34:59,877 - training.trainer - INFO - Epoch 34, Step 116321: Loss=5.0027, Acc=0.368, 
2025-10-12 20:35:10,044 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.8499, Acc=0.226, 
2025-10-12 20:35:20,364 - training.trainer - INFO - Epoch 34, Step 116521: Loss=6.3970, Acc=0.286, 
2025-10-12 20:35:30,592 - training.trainer - INFO - Epoch 34, Step 116621: Loss=5.6508, Acc=0.235, 
2025-10-12 20:35:40,769 - training.trainer - INFO - Epoch 34, Step 116721: Loss=6.0106, Acc=0.283, 
2025-10-12 20:35:50,978 - training.trainer - INFO - Epoch 34, Step 116821: Loss=6.4076, Acc=0.172, 
2025-10-12 20:36:00,908 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.4665, Acc=0.267, 
2025-10-12 20:36:10,858 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.7170, Acc=0.235, 
2025-10-12 20:36:20,818 - training.trainer - INFO - Epoch 34, Step 117121: Loss=4.4818, Acc=0.571, 
2025-10-12 20:36:30,588 - training.trainer - INFO - Epoch 34, Step 117221: Loss=5.3882, Acc=0.323, 
2025-10-12 20:36:40,626 - training.trainer - INFO - Epoch 34, Step 117321: Loss=5.6131, Acc=0.273, 
2025-10-12 20:36:50,702 - training.trainer - INFO - Epoch 34, Step 117421: Loss=4.6436, Acc=0.357, 
2025-10-12 20:37:00,881 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.0413, Acc=0.333, 
2025-10-12 20:37:10,853 - training.trainer - INFO - Epoch 34, Step 117621: Loss=6.3571, Acc=0.174, 
2025-10-12 20:37:20,837 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.9863, Acc=0.227, 
2025-10-12 20:37:30,937 - training.trainer - INFO - Epoch 34, Step 117821: Loss=4.6151, Acc=0.361, 
2025-10-12 20:37:40,968 - training.trainer - INFO - Epoch 34, Step 117921: Loss=6.2868, Acc=0.175, 
2025-10-12 20:37:50,964 - training.trainer - INFO - Epoch 34, Step 118021: Loss=5.7526, Acc=0.222, 
2025-10-12 20:38:00,939 - training.trainer - INFO - Epoch 34, Step 118121: Loss=4.4051, Acc=0.440, 
2025-10-12 20:38:10,904 - training.trainer - INFO - Epoch 34, Step 118221: Loss=5.8059, Acc=0.226, 
2025-10-12 20:38:20,897 - training.trainer - INFO - Epoch 34, Step 118321: Loss=5.5877, Acc=0.292, 
2025-10-12 20:38:44,008 - training.trainer - INFO - Epoch 35/100 completed in 353.65s - Train Loss: 5.5029, Train Acc: 0.276, Val Loss: 5.7331, Val Acc: 0.258
2025-10-12 20:38:44,388 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-10-12 20:38:54,287 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.8228, Acc=0.286, 
2025-10-12 20:39:04,142 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.8153, Acc=0.318, 
2025-10-12 20:39:14,348 - training.trainer - INFO - Epoch 35, Step 118704: Loss=5.6529, Acc=0.246, 
2025-10-12 20:39:24,357 - training.trainer - INFO - Epoch 35, Step 118804: Loss=5.7952, Acc=0.137, 
2025-10-12 20:39:34,525 - training.trainer - INFO - Epoch 35, Step 118904: Loss=6.4799, Acc=0.127, 
2025-10-12 20:39:44,722 - training.trainer - INFO - Epoch 35, Step 119004: Loss=5.0907, Acc=0.208, 
2025-10-12 20:39:54,959 - training.trainer - INFO - Epoch 35, Step 119104: Loss=5.6486, Acc=0.309, 
2025-10-12 20:40:05,213 - training.trainer - INFO - Epoch 35, Step 119204: Loss=5.3534, Acc=0.348, 
2025-10-12 20:40:15,401 - training.trainer - INFO - Epoch 35, Step 119304: Loss=5.4298, Acc=0.260, 
2025-10-12 20:40:25,605 - training.trainer - INFO - Epoch 35, Step 119404: Loss=5.7601, Acc=0.250, 
2025-10-12 20:40:35,852 - training.trainer - INFO - Epoch 35, Step 119504: Loss=5.7990, Acc=0.286, 
2025-10-12 20:40:45,931 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.3346, Acc=0.160, 
2025-10-12 20:40:55,846 - training.trainer - INFO - Epoch 35, Step 119704: Loss=5.0516, Acc=0.333, 
2025-10-12 20:41:05,810 - training.trainer - INFO - Epoch 35, Step 119804: Loss=5.2594, Acc=0.256, 
2025-10-12 20:41:15,861 - training.trainer - INFO - Epoch 35, Step 119904: Loss=5.5891, Acc=0.333, 
2025-10-12 20:41:26,021 - training.trainer - INFO - Epoch 35, Step 120004: Loss=5.2790, Acc=0.222, 
2025-10-12 20:41:36,402 - training.trainer - INFO - Epoch 35, Step 120104: Loss=5.7395, Acc=0.188, 
2025-10-12 20:41:46,306 - training.trainer - INFO - Epoch 35, Step 120204: Loss=6.0104, Acc=0.221, 
2025-10-12 20:41:56,210 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.0632, Acc=0.370, 
2025-10-12 20:42:06,156 - training.trainer - INFO - Epoch 35, Step 120404: Loss=5.1925, Acc=0.250, 
2025-10-12 20:42:16,136 - training.trainer - INFO - Epoch 35, Step 120504: Loss=4.7433, Acc=0.452, 
2025-10-12 20:42:25,969 - training.trainer - INFO - Epoch 35, Step 120604: Loss=6.2819, Acc=0.167, 
2025-10-12 20:42:35,803 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.4411, Acc=0.321, 
2025-10-12 20:42:45,728 - training.trainer - INFO - Epoch 35, Step 120804: Loss=4.9441, Acc=0.375, 
2025-10-12 20:42:55,682 - training.trainer - INFO - Epoch 35, Step 120904: Loss=6.3145, Acc=0.200, 
2025-10-12 20:43:05,534 - training.trainer - INFO - Epoch 35, Step 121004: Loss=5.6169, Acc=0.294, 
2025-10-12 20:43:15,383 - training.trainer - INFO - Epoch 35, Step 121104: Loss=5.8535, Acc=0.224, 
2025-10-12 20:43:25,206 - training.trainer - INFO - Epoch 35, Step 121204: Loss=5.7182, Acc=0.260, 
2025-10-12 20:43:35,103 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.7385, Acc=0.261, 
2025-10-12 20:43:44,975 - training.trainer - INFO - Epoch 35, Step 121404: Loss=5.3500, Acc=0.250, 
2025-10-12 20:43:54,988 - training.trainer - INFO - Epoch 35, Step 121504: Loss=6.2215, Acc=0.207, 
2025-10-12 20:44:05,038 - training.trainer - INFO - Epoch 35, Step 121604: Loss=6.2542, Acc=0.188, 
2025-10-12 20:44:15,281 - training.trainer - INFO - Epoch 35, Step 121704: Loss=5.5448, Acc=0.344, 
2025-10-12 20:44:37,271 - training.trainer - INFO - Epoch 36/100 completed in 352.88s - Train Loss: 5.4951, Train Acc: 0.279, Val Loss: 5.7789, Val Acc: 0.259
2025-10-12 20:44:48,058 - training.trainer - INFO - Epoch 36, Step 121887: Loss=5.8673, Acc=0.122, 
2025-10-12 20:44:58,291 - training.trainer - INFO - Epoch 36, Step 121987: Loss=6.2805, Acc=0.250, 
2025-10-12 20:45:08,365 - training.trainer - INFO - Epoch 36, Step 122087: Loss=5.5327, Acc=0.257, 
2025-10-12 20:45:18,419 - training.trainer - INFO - Epoch 36, Step 122187: Loss=4.6737, Acc=0.346, 
2025-10-12 20:45:28,622 - training.trainer - INFO - Epoch 36, Step 122287: Loss=5.8265, Acc=0.232, 
2025-10-12 20:45:38,804 - training.trainer - INFO - Epoch 36, Step 122387: Loss=5.3966, Acc=0.327, 
2025-10-12 20:45:48,919 - training.trainer - INFO - Epoch 36, Step 122487: Loss=6.0478, Acc=0.255, 
2025-10-12 20:45:59,127 - training.trainer - INFO - Epoch 36, Step 122587: Loss=6.1704, Acc=0.175, 
2025-10-12 20:46:09,225 - training.trainer - INFO - Epoch 36, Step 122687: Loss=5.8153, Acc=0.232, 
2025-10-12 20:46:19,239 - training.trainer - INFO - Epoch 36, Step 122787: Loss=5.6421, Acc=0.216, 
2025-10-12 20:46:29,102 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.8756, Acc=0.239, 
2025-10-12 20:46:39,065 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.3197, Acc=0.250, 
2025-10-12 20:46:48,873 - training.trainer - INFO - Epoch 36, Step 123087: Loss=5.8740, Acc=0.200, 
2025-10-12 20:46:58,684 - training.trainer - INFO - Epoch 36, Step 123187: Loss=4.8686, Acc=0.281, 
2025-10-12 20:47:08,740 - training.trainer - INFO - Epoch 36, Step 123287: Loss=5.3744, Acc=0.250, 
2025-10-12 20:47:18,617 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.7119, Acc=0.240, 
2025-10-12 20:47:28,497 - training.trainer - INFO - Epoch 36, Step 123487: Loss=6.0181, Acc=0.400, 
2025-10-12 20:47:38,437 - training.trainer - INFO - Epoch 36, Step 123587: Loss=2.9951, Acc=0.773, 
2025-10-12 20:47:48,344 - training.trainer - INFO - Epoch 36, Step 123687: Loss=6.1665, Acc=0.257, 
2025-10-12 20:47:58,258 - training.trainer - INFO - Epoch 36, Step 123787: Loss=4.8092, Acc=0.391, 
2025-10-12 20:48:08,256 - training.trainer - INFO - Epoch 36, Step 123887: Loss=5.1001, Acc=0.358, 
2025-10-12 20:48:18,436 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.5229, Acc=0.368, 
2025-10-12 20:48:28,512 - training.trainer - INFO - Epoch 36, Step 124087: Loss=6.3183, Acc=0.173, 
2025-10-12 20:48:38,341 - training.trainer - INFO - Epoch 36, Step 124187: Loss=5.5914, Acc=0.316, 
2025-10-12 20:48:48,445 - training.trainer - INFO - Epoch 36, Step 124287: Loss=5.9814, Acc=0.237, 
2025-10-12 20:48:58,316 - training.trainer - INFO - Epoch 36, Step 124387: Loss=6.0875, Acc=0.260, 
2025-10-12 20:49:08,116 - training.trainer - INFO - Epoch 36, Step 124487: Loss=5.4007, Acc=0.300, 
2025-10-12 20:49:18,071 - training.trainer - INFO - Epoch 36, Step 124587: Loss=5.1902, Acc=0.351, 
2025-10-12 20:49:28,012 - training.trainer - INFO - Epoch 36, Step 124687: Loss=6.1580, Acc=0.267, 
2025-10-12 20:49:38,069 - training.trainer - INFO - Epoch 36, Step 124787: Loss=4.9047, Acc=0.359, 
2025-10-12 20:49:47,985 - training.trainer - INFO - Epoch 36, Step 124887: Loss=6.0838, Acc=0.196, 
2025-10-12 20:49:57,818 - training.trainer - INFO - Epoch 36, Step 124987: Loss=5.7541, Acc=0.350, 
2025-10-12 20:50:07,683 - training.trainer - INFO - Epoch 36, Step 125087: Loss=5.1054, Acc=0.290, 
2025-10-12 20:50:29,458 - training.trainer - INFO - Epoch 37/100 completed in 352.19s - Train Loss: 5.4842, Train Acc: 0.280, Val Loss: 5.7468, Val Acc: 0.255
2025-10-12 20:50:38,393 - training.trainer - INFO - Epoch 37, Step 125270: Loss=4.4819, Acc=0.345, 
2025-10-12 20:50:46,871 - training.trainer - INFO - Epoch 37, Step 125370: Loss=4.9369, Acc=0.286, 
2025-10-12 20:50:56,023 - training.trainer - INFO - Epoch 37, Step 125470: Loss=3.6567, Acc=0.417, 
2025-10-12 20:51:05,225 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.3930, Acc=0.296, 
2025-10-12 20:51:14,549 - training.trainer - INFO - Epoch 37, Step 125670: Loss=5.7718, Acc=0.220, 
2025-10-12 20:51:24,202 - training.trainer - INFO - Epoch 37, Step 125770: Loss=4.2101, Acc=0.400, 
2025-10-12 20:51:34,420 - training.trainer - INFO - Epoch 37, Step 125870: Loss=6.3407, Acc=0.189, 
2025-10-12 20:51:44,302 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.8439, Acc=0.233, 
2025-10-12 20:51:54,181 - training.trainer - INFO - Epoch 37, Step 126070: Loss=5.3624, Acc=0.241, 
2025-10-12 20:52:04,198 - training.trainer - INFO - Epoch 37, Step 126170: Loss=4.5891, Acc=0.424, 
2025-10-12 20:52:14,381 - training.trainer - INFO - Epoch 37, Step 126270: Loss=6.1735, Acc=0.269, 
2025-10-12 20:52:24,812 - training.trainer - INFO - Epoch 37, Step 126370: Loss=5.8563, Acc=0.212, 
2025-10-12 20:52:34,817 - training.trainer - INFO - Epoch 37, Step 126470: Loss=5.5777, Acc=0.267, 
2025-10-12 20:52:44,815 - training.trainer - INFO - Epoch 37, Step 126570: Loss=5.0452, Acc=0.375, 
2025-10-12 20:52:54,920 - training.trainer - INFO - Epoch 37, Step 126670: Loss=5.3832, Acc=0.390, 
2025-10-12 20:53:04,778 - training.trainer - INFO - Epoch 37, Step 126770: Loss=5.3117, Acc=0.387, 
2025-10-12 20:53:14,662 - training.trainer - INFO - Epoch 37, Step 126870: Loss=4.8087, Acc=0.467, 
2025-10-12 20:53:24,749 - training.trainer - INFO - Epoch 37, Step 126970: Loss=5.4750, Acc=0.273, 
2025-10-12 20:53:35,066 - training.trainer - INFO - Epoch 37, Step 127070: Loss=5.0859, Acc=0.421, 
2025-10-12 20:53:45,439 - training.trainer - INFO - Epoch 37, Step 127170: Loss=4.2764, Acc=0.438, 
2025-10-12 20:53:55,674 - training.trainer - INFO - Epoch 37, Step 127270: Loss=3.8173, Acc=0.548, 
2025-10-12 20:54:05,966 - training.trainer - INFO - Epoch 37, Step 127370: Loss=6.2432, Acc=0.214, 
2025-10-12 20:54:16,328 - training.trainer - INFO - Epoch 37, Step 127470: Loss=4.3641, Acc=0.500, 
2025-10-12 20:54:26,680 - training.trainer - INFO - Epoch 37, Step 127570: Loss=5.8721, Acc=0.273, 
2025-10-12 20:54:36,807 - training.trainer - INFO - Epoch 37, Step 127670: Loss=5.0370, Acc=0.231, 
2025-10-12 20:54:47,057 - training.trainer - INFO - Epoch 37, Step 127770: Loss=5.3411, Acc=0.222, 
2025-10-12 20:54:57,274 - training.trainer - INFO - Epoch 37, Step 127870: Loss=5.3815, Acc=0.208, 
2025-10-12 20:55:07,426 - training.trainer - INFO - Epoch 37, Step 127970: Loss=5.7086, Acc=0.216, 
2025-10-12 20:55:17,627 - training.trainer - INFO - Epoch 37, Step 128070: Loss=6.1777, Acc=0.268, 
2025-10-12 20:55:27,731 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.5076, Acc=0.275, 
2025-10-12 20:55:37,835 - training.trainer - INFO - Epoch 37, Step 128270: Loss=4.9070, Acc=0.364, 
2025-10-12 20:55:48,140 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.1001, Acc=0.298, 
2025-10-12 20:55:58,281 - training.trainer - INFO - Epoch 37, Step 128470: Loss=6.2472, Acc=0.143, 
2025-10-12 20:56:21,171 - training.trainer - INFO - Epoch 38/100 completed in 351.71s - Train Loss: 5.4685, Train Acc: 0.283, Val Loss: 5.7448, Val Acc: 0.256
2025-10-12 20:56:31,381 - training.trainer - INFO - Epoch 38, Step 128653: Loss=5.4121, Acc=0.233, 
2025-10-12 20:56:41,563 - training.trainer - INFO - Epoch 38, Step 128753: Loss=4.5322, Acc=0.529, 
2025-10-12 20:56:51,609 - training.trainer - INFO - Epoch 38, Step 128853: Loss=6.0245, Acc=0.216, 
2025-10-12 20:57:01,751 - training.trainer - INFO - Epoch 38, Step 128953: Loss=6.2657, Acc=0.191, 
2025-10-12 20:57:11,840 - training.trainer - INFO - Epoch 38, Step 129053: Loss=6.6290, Acc=0.135, 
2025-10-12 20:57:22,006 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.5464, Acc=0.333, 
2025-10-12 20:57:32,356 - training.trainer - INFO - Epoch 38, Step 129253: Loss=4.9614, Acc=0.458, 
2025-10-12 20:57:42,479 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.9623, Acc=0.300, 
2025-10-12 20:57:52,523 - training.trainer - INFO - Epoch 38, Step 129453: Loss=5.7457, Acc=0.227, 
2025-10-12 20:58:02,547 - training.trainer - INFO - Epoch 38, Step 129553: Loss=5.4240, Acc=0.250, 
2025-10-12 20:58:12,613 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.8304, Acc=0.178, 
2025-10-12 20:58:22,647 - training.trainer - INFO - Epoch 38, Step 129753: Loss=6.0173, Acc=0.278, 
2025-10-12 20:58:32,778 - training.trainer - INFO - Epoch 38, Step 129853: Loss=5.4201, Acc=0.312, 
2025-10-12 20:58:42,833 - training.trainer - INFO - Epoch 38, Step 129953: Loss=6.1720, Acc=0.204, 
2025-10-12 20:58:52,888 - training.trainer - INFO - Epoch 38, Step 130053: Loss=6.2760, Acc=0.164, 
2025-10-12 20:59:03,100 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.5736, Acc=0.250, 
2025-10-12 20:59:13,323 - training.trainer - INFO - Epoch 38, Step 130253: Loss=5.4367, Acc=0.267, 
2025-10-12 20:59:23,443 - training.trainer - INFO - Epoch 38, Step 130353: Loss=5.3561, Acc=0.333, 
2025-10-12 20:59:33,670 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.9794, Acc=0.250, 
2025-10-12 20:59:43,671 - training.trainer - INFO - Epoch 38, Step 130553: Loss=5.7417, Acc=0.207, 
2025-10-12 20:59:53,605 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.9873, Acc=0.196, 
2025-10-12 21:00:03,625 - training.trainer - INFO - Epoch 38, Step 130753: Loss=6.3721, Acc=0.150, 
2025-10-12 21:00:13,806 - training.trainer - INFO - Epoch 38, Step 130853: Loss=4.3876, Acc=0.533, 
2025-10-12 21:00:23,833 - training.trainer - INFO - Epoch 38, Step 130953: Loss=4.7965, Acc=0.391, 
2025-10-12 21:00:33,889 - training.trainer - INFO - Epoch 38, Step 131053: Loss=5.4309, Acc=0.255, 
2025-10-12 21:00:44,129 - training.trainer - INFO - Epoch 38, Step 131153: Loss=5.9218, Acc=0.263, 
2025-10-12 21:00:54,138 - training.trainer - INFO - Epoch 38, Step 131253: Loss=6.5515, Acc=0.203, 
2025-10-12 21:01:04,149 - training.trainer - INFO - Epoch 38, Step 131353: Loss=5.9062, Acc=0.182, 
2025-10-12 21:01:14,237 - training.trainer - INFO - Epoch 38, Step 131453: Loss=5.9167, Acc=0.294, 
2025-10-12 21:01:24,319 - training.trainer - INFO - Epoch 38, Step 131553: Loss=5.7000, Acc=0.258, 
2025-10-12 21:01:34,323 - training.trainer - INFO - Epoch 38, Step 131653: Loss=5.9010, Acc=0.174, 
2025-10-12 21:01:44,469 - training.trainer - INFO - Epoch 38, Step 131753: Loss=6.0981, Acc=0.200, 
2025-10-12 21:01:54,619 - training.trainer - INFO - Epoch 38, Step 131853: Loss=6.1036, Acc=0.250, 
2025-10-12 21:02:17,486 - training.trainer - INFO - Epoch 39/100 completed in 356.31s - Train Loss: 5.4596, Train Acc: 0.284, Val Loss: 5.7659, Val Acc: 0.257
2025-10-12 21:02:28,188 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.2904, Acc=0.286, 
2025-10-12 21:02:38,359 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.0087, Acc=0.345, 
2025-10-12 21:02:48,563 - training.trainer - INFO - Epoch 39, Step 132236: Loss=5.0203, Acc=0.304, 
2025-10-12 21:02:58,906 - training.trainer - INFO - Epoch 39, Step 132336: Loss=5.3643, Acc=0.407, 
2025-10-12 21:03:09,147 - training.trainer - INFO - Epoch 39, Step 132436: Loss=3.1834, Acc=0.529, 
2025-10-12 21:03:19,392 - training.trainer - INFO - Epoch 39, Step 132536: Loss=6.3449, Acc=0.129, 
2025-10-12 21:03:29,647 - training.trainer - INFO - Epoch 39, Step 132636: Loss=5.7411, Acc=0.224, 
2025-10-12 21:03:39,843 - training.trainer - INFO - Epoch 39, Step 132736: Loss=5.6479, Acc=0.222, 
2025-10-12 21:03:50,014 - training.trainer - INFO - Epoch 39, Step 132836: Loss=5.2029, Acc=0.333, 
2025-10-12 21:04:00,205 - training.trainer - INFO - Epoch 39, Step 132936: Loss=5.0279, Acc=0.357, 
2025-10-12 21:04:10,244 - training.trainer - INFO - Epoch 39, Step 133036: Loss=4.0657, Acc=0.474, 
2025-10-12 21:04:20,344 - training.trainer - INFO - Epoch 39, Step 133136: Loss=5.4207, Acc=0.277, 
2025-10-12 21:04:30,543 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.1992, Acc=0.269, 
2025-10-12 21:04:40,697 - training.trainer - INFO - Epoch 39, Step 133336: Loss=5.9492, Acc=0.262, 
2025-10-12 21:04:50,696 - training.trainer - INFO - Epoch 39, Step 133436: Loss=5.8003, Acc=0.250, 
2025-10-12 21:05:00,752 - training.trainer - INFO - Epoch 39, Step 133536: Loss=5.3617, Acc=0.304, 
2025-10-12 21:05:10,975 - training.trainer - INFO - Epoch 39, Step 133636: Loss=5.7939, Acc=0.300, 
2025-10-12 21:05:21,174 - training.trainer - INFO - Epoch 39, Step 133736: Loss=3.0289, Acc=0.621, 
2025-10-12 21:05:31,616 - training.trainer - INFO - Epoch 39, Step 133836: Loss=4.9730, Acc=0.256, 
2025-10-12 21:05:41,987 - training.trainer - INFO - Epoch 39, Step 133936: Loss=5.5366, Acc=0.255, 
2025-10-12 21:05:52,382 - training.trainer - INFO - Epoch 39, Step 134036: Loss=4.7971, Acc=0.400, 
2025-10-12 21:06:02,699 - training.trainer - INFO - Epoch 39, Step 134136: Loss=5.6590, Acc=0.346, 
2025-10-12 21:06:12,755 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.8409, Acc=0.353, 
2025-10-12 21:06:22,574 - training.trainer - INFO - Epoch 39, Step 134336: Loss=5.2286, Acc=0.389, 
2025-10-12 21:06:32,756 - training.trainer - INFO - Epoch 39, Step 134436: Loss=5.4615, Acc=0.367, 
2025-10-12 21:06:43,118 - training.trainer - INFO - Epoch 39, Step 134536: Loss=4.7300, Acc=0.400, 
2025-10-12 21:06:52,855 - training.trainer - INFO - Epoch 39, Step 134636: Loss=6.1449, Acc=0.260, 
2025-10-12 21:07:02,689 - training.trainer - INFO - Epoch 39, Step 134736: Loss=5.1169, Acc=0.324, 
2025-10-12 21:07:12,568 - training.trainer - INFO - Epoch 39, Step 134836: Loss=6.1045, Acc=0.290, 
2025-10-12 21:07:22,648 - training.trainer - INFO - Epoch 39, Step 134936: Loss=5.8632, Acc=0.310, 
2025-10-12 21:07:32,510 - training.trainer - INFO - Epoch 39, Step 135036: Loss=6.1332, Acc=0.226, 
2025-10-12 21:07:42,424 - training.trainer - INFO - Epoch 39, Step 135136: Loss=5.1120, Acc=0.298, 
2025-10-12 21:07:52,411 - training.trainer - INFO - Epoch 39, Step 135236: Loss=5.3276, Acc=0.281, 
2025-10-12 21:08:14,752 - training.trainer - INFO - Epoch 40/100 completed in 357.26s - Train Loss: 5.4458, Train Acc: 0.286, Val Loss: 5.7521, Val Acc: 0.258
2025-10-12 21:08:15,203 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-10-12 21:08:25,594 - training.trainer - INFO - Epoch 40, Step 135419: Loss=5.5363, Acc=0.289, 
2025-10-12 21:08:35,604 - training.trainer - INFO - Epoch 40, Step 135519: Loss=5.1565, Acc=0.414, 
2025-10-12 21:08:45,435 - training.trainer - INFO - Epoch 40, Step 135619: Loss=5.1559, Acc=0.385, 
2025-10-12 21:08:55,346 - training.trainer - INFO - Epoch 40, Step 135719: Loss=5.5504, Acc=0.276, 
2025-10-12 21:09:05,278 - training.trainer - INFO - Epoch 40, Step 135819: Loss=5.8424, Acc=0.267, 
2025-10-12 21:09:15,438 - training.trainer - INFO - Epoch 40, Step 135919: Loss=6.3121, Acc=0.224, 
2025-10-12 21:09:25,584 - training.trainer - INFO - Epoch 40, Step 136019: Loss=6.2297, Acc=0.192, 
2025-10-12 21:09:35,800 - training.trainer - INFO - Epoch 40, Step 136119: Loss=4.4623, Acc=0.455, 
2025-10-12 21:09:45,976 - training.trainer - INFO - Epoch 40, Step 136219: Loss=5.2051, Acc=0.280, 
2025-10-12 21:09:56,029 - training.trainer - INFO - Epoch 40, Step 136319: Loss=2.1736, Acc=0.824, 
2025-10-12 21:10:06,258 - training.trainer - INFO - Epoch 40, Step 136419: Loss=5.7147, Acc=0.241, 
2025-10-12 21:10:16,475 - training.trainer - INFO - Epoch 40, Step 136519: Loss=4.0767, Acc=0.571, 
2025-10-12 21:10:26,638 - training.trainer - INFO - Epoch 40, Step 136619: Loss=5.7671, Acc=0.308, 
2025-10-12 21:10:36,714 - training.trainer - INFO - Epoch 40, Step 136719: Loss=5.7475, Acc=0.283, 
2025-10-12 21:10:46,710 - training.trainer - INFO - Epoch 40, Step 136819: Loss=5.0854, Acc=0.237, 
2025-10-12 21:10:56,708 - training.trainer - INFO - Epoch 40, Step 136919: Loss=4.9392, Acc=0.361, 
2025-10-12 21:11:06,601 - training.trainer - INFO - Epoch 40, Step 137019: Loss=5.0952, Acc=0.333, 
2025-10-12 21:11:16,527 - training.trainer - INFO - Epoch 40, Step 137119: Loss=4.3696, Acc=0.407, 
2025-10-12 21:11:26,423 - training.trainer - INFO - Epoch 40, Step 137219: Loss=5.7415, Acc=0.333, 
2025-10-12 21:11:36,284 - training.trainer - INFO - Epoch 40, Step 137319: Loss=5.8367, Acc=0.250, 
2025-10-12 21:11:46,129 - training.trainer - INFO - Epoch 40, Step 137419: Loss=5.2794, Acc=0.304, 
2025-10-12 21:11:56,017 - training.trainer - INFO - Epoch 40, Step 137519: Loss=4.3946, Acc=0.407, 
2025-10-12 21:12:06,089 - training.trainer - INFO - Epoch 40, Step 137619: Loss=6.1950, Acc=0.200, 
2025-10-12 21:12:16,194 - training.trainer - INFO - Epoch 40, Step 137719: Loss=4.7970, Acc=0.289, 
2025-10-12 21:12:26,476 - training.trainer - INFO - Epoch 40, Step 137819: Loss=5.5981, Acc=0.243, 
2025-10-12 21:12:36,491 - training.trainer - INFO - Epoch 40, Step 137919: Loss=6.0280, Acc=0.158, 
2025-10-12 21:12:46,280 - training.trainer - INFO - Epoch 40, Step 138019: Loss=5.7989, Acc=0.239, 
2025-10-12 21:12:56,522 - training.trainer - INFO - Epoch 40, Step 138119: Loss=6.0333, Acc=0.294, 
2025-10-12 21:13:06,798 - training.trainer - INFO - Epoch 40, Step 138219: Loss=5.3872, Acc=0.300, 
2025-10-12 21:13:16,690 - training.trainer - INFO - Epoch 40, Step 138319: Loss=5.4363, Acc=0.357, 
2025-10-12 21:13:26,611 - training.trainer - INFO - Epoch 40, Step 138419: Loss=6.0088, Acc=0.250, 
2025-10-12 21:13:36,549 - training.trainer - INFO - Epoch 40, Step 138519: Loss=5.6955, Acc=0.236, 
2025-10-12 21:13:46,488 - training.trainer - INFO - Epoch 40, Step 138619: Loss=5.1654, Acc=0.378, 
2025-10-12 21:14:08,237 - training.trainer - INFO - Epoch 41/100 completed in 353.03s - Train Loss: 5.4324, Train Acc: 0.288, Val Loss: 5.7451, Val Acc: 0.258
2025-10-12 21:14:17,115 - training.trainer - INFO - Epoch 41, Step 138802: Loss=5.1462, Acc=0.265, 
2025-10-12 21:14:25,568 - training.trainer - INFO - Epoch 41, Step 138902: Loss=5.5822, Acc=0.179, 
2025-10-12 21:14:34,050 - training.trainer - INFO - Epoch 41, Step 139002: Loss=5.4165, Acc=0.370, 
2025-10-12 21:14:42,592 - training.trainer - INFO - Epoch 41, Step 139102: Loss=5.6113, Acc=0.190, 
2025-10-12 21:14:51,067 - training.trainer - INFO - Epoch 41, Step 139202: Loss=6.1147, Acc=0.276, 
2025-10-12 21:14:59,542 - training.trainer - INFO - Epoch 41, Step 139302: Loss=5.6460, Acc=0.326, 
2025-10-12 21:15:08,029 - training.trainer - INFO - Epoch 41, Step 139402: Loss=5.5728, Acc=0.224, 
2025-10-12 21:15:16,572 - training.trainer - INFO - Epoch 41, Step 139502: Loss=5.7990, Acc=0.268, 
2025-10-12 21:15:25,044 - training.trainer - INFO - Epoch 41, Step 139602: Loss=5.6882, Acc=0.242, 
2025-10-12 21:15:33,515 - training.trainer - INFO - Epoch 41, Step 139702: Loss=5.8957, Acc=0.219, 
2025-10-12 21:15:42,117 - training.trainer - INFO - Epoch 41, Step 139802: Loss=5.3827, Acc=0.273, 
2025-10-12 21:15:50,551 - training.trainer - INFO - Epoch 41, Step 139902: Loss=3.8413, Acc=0.412, 
2025-10-12 21:15:59,821 - training.trainer - INFO - Epoch 41, Step 140002: Loss=4.8277, Acc=0.375, 
2025-10-12 21:16:09,462 - training.trainer - INFO - Epoch 41, Step 140102: Loss=4.5786, Acc=0.392, 
2025-10-12 21:16:18,989 - training.trainer - INFO - Epoch 41, Step 140202: Loss=5.9523, Acc=0.360, 
2025-10-12 21:16:28,881 - training.trainer - INFO - Epoch 41, Step 140302: Loss=5.7181, Acc=0.234, 
2025-10-12 21:16:38,962 - training.trainer - INFO - Epoch 41, Step 140402: Loss=5.2870, Acc=0.267, 
2025-10-12 21:16:49,018 - training.trainer - INFO - Epoch 41, Step 140502: Loss=4.6815, Acc=0.293, 
2025-10-12 21:16:59,207 - training.trainer - INFO - Epoch 41, Step 140602: Loss=6.2285, Acc=0.172, 
2025-10-12 21:17:09,655 - training.trainer - INFO - Epoch 41, Step 140702: Loss=5.5091, Acc=0.326, 
2025-10-12 21:17:19,974 - training.trainer - INFO - Epoch 41, Step 140802: Loss=5.7347, Acc=0.226, 
2025-10-12 21:17:30,287 - training.trainer - INFO - Epoch 41, Step 140902: Loss=5.4784, Acc=0.311, 
2025-10-12 21:17:40,762 - training.trainer - INFO - Epoch 41, Step 141002: Loss=5.4863, Acc=0.244, 
2025-10-12 21:17:51,139 - training.trainer - INFO - Epoch 41, Step 141102: Loss=6.2662, Acc=0.323, 
2025-10-12 21:18:01,463 - training.trainer - INFO - Epoch 41, Step 141202: Loss=6.5245, Acc=0.184, 
2025-10-12 21:18:11,503 - training.trainer - INFO - Epoch 41, Step 141302: Loss=5.5963, Acc=0.333, 
2025-10-12 21:18:21,489 - training.trainer - INFO - Epoch 41, Step 141402: Loss=4.4841, Acc=0.320, 
2025-10-12 21:18:31,684 - training.trainer - INFO - Epoch 41, Step 141502: Loss=5.7836, Acc=0.326, 
2025-10-12 21:18:41,787 - training.trainer - INFO - Epoch 41, Step 141602: Loss=4.2191, Acc=0.526, 
2025-10-12 21:18:51,882 - training.trainer - INFO - Epoch 41, Step 141702: Loss=4.6031, Acc=0.391, 
2025-10-12 21:19:01,944 - training.trainer - INFO - Epoch 41, Step 141802: Loss=6.3744, Acc=0.149, 
2025-10-12 21:19:12,077 - training.trainer - INFO - Epoch 41, Step 141902: Loss=4.4739, Acc=0.489, 
2025-10-12 21:19:22,078 - training.trainer - INFO - Epoch 41, Step 142002: Loss=6.0336, Acc=0.246, 
2025-10-12 21:19:44,207 - training.trainer - INFO - Epoch 42/100 completed in 335.97s - Train Loss: 5.4156, Train Acc: 0.290, Val Loss: 5.7720, Val Acc: 0.260
2025-10-12 21:19:54,690 - training.trainer - INFO - Epoch 42, Step 142185: Loss=4.9005, Acc=0.333, 
2025-10-12 21:20:04,875 - training.trainer - INFO - Epoch 42, Step 142285: Loss=5.6042, Acc=0.267, 
2025-10-12 21:20:15,104 - training.trainer - INFO - Epoch 42, Step 142385: Loss=4.8613, Acc=0.421, 
2025-10-12 21:20:25,308 - training.trainer - INFO - Epoch 42, Step 142485: Loss=4.2673, Acc=0.436, 
2025-10-12 21:20:35,431 - training.trainer - INFO - Epoch 42, Step 142585: Loss=5.3949, Acc=0.357, 
2025-10-12 21:20:45,782 - training.trainer - INFO - Epoch 42, Step 142685: Loss=5.3283, Acc=0.407, 
2025-10-12 21:20:56,073 - training.trainer - INFO - Epoch 42, Step 142785: Loss=5.9365, Acc=0.231, 
2025-10-12 21:21:06,372 - training.trainer - INFO - Epoch 42, Step 142885: Loss=5.8106, Acc=0.200, 
2025-10-12 21:21:16,688 - training.trainer - INFO - Epoch 42, Step 142985: Loss=6.0320, Acc=0.283, 
2025-10-12 21:21:26,951 - training.trainer - INFO - Epoch 42, Step 143085: Loss=5.9701, Acc=0.188, 
2025-10-12 21:21:37,194 - training.trainer - INFO - Epoch 42, Step 143185: Loss=4.7044, Acc=0.367, 
2025-10-12 21:21:47,322 - training.trainer - INFO - Epoch 42, Step 143285: Loss=4.6736, Acc=0.318, 
2025-10-12 21:21:57,635 - training.trainer - INFO - Epoch 42, Step 143385: Loss=5.7036, Acc=0.178, 
2025-10-12 21:22:07,858 - training.trainer - INFO - Epoch 42, Step 143485: Loss=4.7596, Acc=0.414, 
2025-10-12 21:22:18,079 - training.trainer - INFO - Epoch 42, Step 143585: Loss=5.7702, Acc=0.185, 
2025-10-12 21:22:28,231 - training.trainer - INFO - Epoch 42, Step 143685: Loss=5.2506, Acc=0.350, 
2025-10-12 21:22:38,500 - training.trainer - INFO - Epoch 42, Step 143785: Loss=4.5769, Acc=0.368, 
2025-10-12 21:22:48,712 - training.trainer - INFO - Epoch 42, Step 143885: Loss=5.9580, Acc=0.195, 
2025-10-12 21:22:58,890 - training.trainer - INFO - Epoch 42, Step 143985: Loss=5.5528, Acc=0.310, 
2025-10-12 21:23:08,947 - training.trainer - INFO - Epoch 42, Step 144085: Loss=5.1961, Acc=0.351, 
2025-10-12 21:23:19,086 - training.trainer - INFO - Epoch 42, Step 144185: Loss=5.9757, Acc=0.245, 
2025-10-12 21:23:29,128 - training.trainer - INFO - Epoch 42, Step 144285: Loss=4.6979, Acc=0.296, 
2025-10-12 21:23:39,237 - training.trainer - INFO - Epoch 42, Step 144385: Loss=5.4020, Acc=0.261, 
2025-10-12 21:23:49,682 - training.trainer - INFO - Epoch 42, Step 144485: Loss=6.6064, Acc=0.121, 
2025-10-12 21:24:00,009 - training.trainer - INFO - Epoch 42, Step 144585: Loss=4.8784, Acc=0.333, 
2025-10-12 21:24:10,408 - training.trainer - INFO - Epoch 42, Step 144685: Loss=6.2174, Acc=0.182, 
2025-10-12 21:24:20,817 - training.trainer - INFO - Epoch 42, Step 144785: Loss=5.4435, Acc=0.250, 
2025-10-12 21:24:31,035 - training.trainer - INFO - Epoch 42, Step 144885: Loss=6.0215, Acc=0.258, 
2025-10-12 21:24:41,011 - training.trainer - INFO - Epoch 42, Step 144985: Loss=5.1329, Acc=0.326, 
2025-10-12 21:24:51,103 - training.trainer - INFO - Epoch 42, Step 145085: Loss=3.0289, Acc=0.683, 
2025-10-12 21:25:01,229 - training.trainer - INFO - Epoch 42, Step 145185: Loss=4.6409, Acc=0.387, 
2025-10-12 21:25:11,279 - training.trainer - INFO - Epoch 42, Step 145285: Loss=4.7421, Acc=0.344, 
2025-10-12 21:25:21,456 - training.trainer - INFO - Epoch 42, Step 145385: Loss=4.8411, Acc=0.323, 
2025-10-12 21:25:42,977 - training.trainer - INFO - Epoch 43/100 completed in 358.77s - Train Loss: 5.4073, Train Acc: 0.291, Val Loss: 5.7617, Val Acc: 0.260
2025-10-12 21:25:51,989 - training.trainer - INFO - Epoch 43, Step 145568: Loss=4.2913, Acc=0.333, 
2025-10-12 21:26:01,166 - training.trainer - INFO - Epoch 43, Step 145668: Loss=5.3970, Acc=0.231, 
2025-10-12 21:26:10,023 - training.trainer - INFO - Epoch 43, Step 145768: Loss=5.2539, Acc=0.212, 
2025-10-12 21:26:18,635 - training.trainer - INFO - Epoch 43, Step 145868: Loss=5.1676, Acc=0.300, 
2025-10-12 21:26:27,209 - training.trainer - INFO - Epoch 43, Step 145968: Loss=6.1170, Acc=0.250, 
2025-10-12 21:26:36,451 - training.trainer - INFO - Epoch 43, Step 146068: Loss=5.3855, Acc=0.321, 
2025-10-12 21:26:45,894 - training.trainer - INFO - Epoch 43, Step 146168: Loss=4.4351, Acc=0.364, 
2025-10-12 21:26:55,483 - training.trainer - INFO - Epoch 43, Step 146268: Loss=5.4059, Acc=0.319, 
2025-10-12 21:27:05,431 - training.trainer - INFO - Epoch 43, Step 146368: Loss=4.5186, Acc=0.414, 
2025-10-12 21:27:15,200 - training.trainer - INFO - Epoch 43, Step 146468: Loss=5.0341, Acc=0.310, 
2025-10-12 21:27:25,112 - training.trainer - INFO - Epoch 43, Step 146568: Loss=5.8316, Acc=0.300, 
2025-10-12 21:27:35,305 - training.trainer - INFO - Epoch 43, Step 146668: Loss=6.0359, Acc=0.204, 
2025-10-12 21:27:45,443 - training.trainer - INFO - Epoch 43, Step 146768: Loss=5.2198, Acc=0.302, 
2025-10-12 21:27:55,518 - training.trainer - INFO - Epoch 43, Step 146868: Loss=6.0785, Acc=0.205, 
2025-10-12 21:28:05,658 - training.trainer - INFO - Epoch 43, Step 146968: Loss=5.4856, Acc=0.361, 
2025-10-12 21:28:15,879 - training.trainer - INFO - Epoch 43, Step 147068: Loss=5.3954, Acc=0.279, 
2025-10-12 21:28:25,951 - training.trainer - INFO - Epoch 43, Step 147168: Loss=5.4120, Acc=0.333, 
2025-10-12 21:28:35,796 - training.trainer - INFO - Epoch 43, Step 147268: Loss=3.0318, Acc=0.529, 
2025-10-12 21:28:45,789 - training.trainer - INFO - Epoch 43, Step 147368: Loss=5.4510, Acc=0.200, 
2025-10-12 21:28:56,007 - training.trainer - INFO - Epoch 43, Step 147468: Loss=5.5876, Acc=0.245, 
2025-10-12 21:29:06,103 - training.trainer - INFO - Epoch 43, Step 147568: Loss=6.3910, Acc=0.250, 
2025-10-12 21:29:16,389 - training.trainer - INFO - Epoch 43, Step 147668: Loss=5.4445, Acc=0.293, 
2025-10-12 21:29:26,386 - training.trainer - INFO - Epoch 43, Step 147768: Loss=6.1164, Acc=0.205, 
2025-10-12 21:29:36,430 - training.trainer - INFO - Epoch 43, Step 147868: Loss=5.3172, Acc=0.286, 
2025-10-12 21:29:46,502 - training.trainer - INFO - Epoch 43, Step 147968: Loss=4.8478, Acc=0.250, 
2025-10-12 21:29:56,500 - training.trainer - INFO - Epoch 43, Step 148068: Loss=5.0791, Acc=0.269, 
2025-10-12 21:30:06,354 - training.trainer - INFO - Epoch 43, Step 148168: Loss=5.2611, Acc=0.265, 
2025-10-12 21:30:16,285 - training.trainer - INFO - Epoch 43, Step 148268: Loss=5.8627, Acc=0.196, 
2025-10-12 21:30:26,264 - training.trainer - INFO - Epoch 43, Step 148368: Loss=5.8451, Acc=0.297, 
2025-10-12 21:30:36,487 - training.trainer - INFO - Epoch 43, Step 148468: Loss=3.5813, Acc=0.520, 
2025-10-12 21:30:46,598 - training.trainer - INFO - Epoch 43, Step 148568: Loss=3.9137, Acc=0.500, 
2025-10-12 21:30:56,644 - training.trainer - INFO - Epoch 43, Step 148668: Loss=5.4865, Acc=0.261, 
2025-10-12 21:31:06,445 - training.trainer - INFO - Epoch 43, Step 148768: Loss=5.4270, Acc=0.219, 
2025-10-12 21:31:28,034 - training.trainer - INFO - Epoch 44/100 completed in 345.06s - Train Loss: 5.3982, Train Acc: 0.293, Val Loss: 5.7582, Val Acc: 0.262
2025-10-12 21:31:36,941 - training.trainer - INFO - Epoch 44, Step 148951: Loss=5.6118, Acc=0.208, 
2025-10-12 21:31:45,458 - training.trainer - INFO - Epoch 44, Step 149051: Loss=5.2721, Acc=0.325, 
2025-10-12 21:31:54,105 - training.trainer - INFO - Epoch 44, Step 149151: Loss=5.8067, Acc=0.267, 
2025-10-12 21:32:03,341 - training.trainer - INFO - Epoch 44, Step 149251: Loss=5.5641, Acc=0.261, 
2025-10-12 21:32:12,822 - training.trainer - INFO - Epoch 44, Step 149351: Loss=6.5294, Acc=0.154, 
2025-10-12 21:32:22,084 - training.trainer - INFO - Epoch 44, Step 149451: Loss=4.3256, Acc=0.333, 
2025-10-12 21:32:30,932 - training.trainer - INFO - Epoch 44, Step 149551: Loss=6.0173, Acc=0.184, 
2025-10-12 21:32:39,779 - training.trainer - INFO - Epoch 44, Step 149651: Loss=5.0922, Acc=0.235, 
2025-10-12 21:32:48,657 - training.trainer - INFO - Epoch 44, Step 149751: Loss=5.6886, Acc=0.435, 
2025-10-12 21:32:57,436 - training.trainer - INFO - Epoch 44, Step 149851: Loss=6.0310, Acc=0.205, 
2025-10-12 21:33:06,223 - training.trainer - INFO - Epoch 44, Step 149951: Loss=4.5394, Acc=0.455, 
2025-10-12 21:33:15,487 - training.trainer - INFO - Epoch 44, Step 150051: Loss=5.1094, Acc=0.258, 
2025-10-12 21:33:25,486 - training.trainer - INFO - Epoch 44, Step 150151: Loss=4.8938, Acc=0.280, 
2025-10-12 21:33:35,630 - training.trainer - INFO - Epoch 44, Step 150251: Loss=6.3265, Acc=0.212, 
2025-10-12 21:33:45,837 - training.trainer - INFO - Epoch 44, Step 150351: Loss=4.4227, Acc=0.294, 
2025-10-12 21:33:55,975 - training.trainer - INFO - Epoch 44, Step 150451: Loss=5.3026, Acc=0.308, 
2025-10-12 21:34:06,193 - training.trainer - INFO - Epoch 44, Step 150551: Loss=6.1145, Acc=0.219, 
2025-10-12 21:34:16,413 - training.trainer - INFO - Epoch 44, Step 150651: Loss=5.1846, Acc=0.273, 
2025-10-12 21:34:26,527 - training.trainer - INFO - Epoch 44, Step 150751: Loss=4.8536, Acc=0.394, 
2025-10-12 21:34:36,510 - training.trainer - INFO - Epoch 44, Step 150851: Loss=4.8011, Acc=0.345, 
2025-10-12 21:34:46,696 - training.trainer - INFO - Epoch 44, Step 150951: Loss=5.2370, Acc=0.300, 
2025-10-12 21:34:56,933 - training.trainer - INFO - Epoch 44, Step 151051: Loss=5.1645, Acc=0.286, 
2025-10-12 21:35:06,740 - training.trainer - INFO - Epoch 44, Step 151151: Loss=5.9503, Acc=0.235, 
2025-10-12 21:35:16,262 - training.trainer - INFO - Epoch 44, Step 151251: Loss=5.2152, Acc=0.310, 
2025-10-12 21:35:26,265 - training.trainer - INFO - Epoch 44, Step 151351: Loss=4.5617, Acc=0.306, 
2025-10-12 21:35:36,338 - training.trainer - INFO - Epoch 44, Step 151451: Loss=5.1437, Acc=0.393, 
2025-10-12 21:35:46,521 - training.trainer - INFO - Epoch 44, Step 151551: Loss=3.3086, Acc=0.586, 
2025-10-12 21:35:56,853 - training.trainer - INFO - Epoch 44, Step 151651: Loss=3.4716, Acc=0.647, 
2025-10-12 21:36:07,040 - training.trainer - INFO - Epoch 44, Step 151751: Loss=5.7620, Acc=0.219, 
2025-10-12 21:36:17,157 - training.trainer - INFO - Epoch 44, Step 151851: Loss=5.2473, Acc=0.176, 
2025-10-12 21:36:27,269 - training.trainer - INFO - Epoch 44, Step 151951: Loss=5.4216, Acc=0.320, 
2025-10-12 21:36:37,393 - training.trainer - INFO - Epoch 44, Step 152051: Loss=5.1520, Acc=0.286, 
2025-10-12 21:36:47,133 - training.trainer - INFO - Epoch 44, Step 152151: Loss=5.3122, Acc=0.281, 
2025-10-12 21:37:10,011 - training.trainer - INFO - Epoch 45/100 completed in 341.98s - Train Loss: 5.3841, Train Acc: 0.295, Val Loss: 5.7678, Val Acc: 0.261
2025-10-12 21:37:10,481 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_45.pt
2025-10-12 21:37:20,989 - training.trainer - INFO - Epoch 45, Step 152334: Loss=5.3633, Acc=0.300, 
2025-10-12 21:37:31,133 - training.trainer - INFO - Epoch 45, Step 152434: Loss=5.7219, Acc=0.312, 
2025-10-12 21:37:41,261 - training.trainer - INFO - Epoch 45, Step 152534: Loss=4.6421, Acc=0.364, 
2025-10-12 21:37:51,326 - training.trainer - INFO - Epoch 45, Step 152634: Loss=5.8153, Acc=0.250, 
2025-10-12 21:38:01,518 - training.trainer - INFO - Epoch 45, Step 152734: Loss=2.5333, Acc=0.583, 
2025-10-12 21:38:11,597 - training.trainer - INFO - Epoch 45, Step 152834: Loss=5.0554, Acc=0.292, 
2025-10-12 21:38:21,756 - training.trainer - INFO - Epoch 45, Step 152934: Loss=5.6615, Acc=0.271, 
2025-10-12 21:38:31,915 - training.trainer - INFO - Epoch 45, Step 153034: Loss=5.7973, Acc=0.205, 
2025-10-12 21:38:42,080 - training.trainer - INFO - Epoch 45, Step 153134: Loss=4.4909, Acc=0.556, 
2025-10-12 21:38:52,175 - training.trainer - INFO - Epoch 45, Step 153234: Loss=5.4656, Acc=0.240, 
2025-10-12 21:39:02,503 - training.trainer - INFO - Epoch 45, Step 153334: Loss=5.4990, Acc=0.244, 
2025-10-12 21:39:12,496 - training.trainer - INFO - Epoch 45, Step 153434: Loss=5.3122, Acc=0.315, 
2025-10-12 21:39:22,422 - training.trainer - INFO - Epoch 45, Step 153534: Loss=5.8343, Acc=0.205, 
2025-10-12 21:39:32,466 - training.trainer - INFO - Epoch 45, Step 153634: Loss=6.8493, Acc=0.167, 
2025-10-12 21:39:42,622 - training.trainer - INFO - Epoch 45, Step 153734: Loss=5.3442, Acc=0.311, 
2025-10-12 21:39:52,643 - training.trainer - INFO - Epoch 45, Step 153834: Loss=5.6315, Acc=0.250, 
2025-10-12 21:40:02,738 - training.trainer - INFO - Epoch 45, Step 153934: Loss=6.2232, Acc=0.156, 
2025-10-12 21:40:12,814 - training.trainer - INFO - Epoch 45, Step 154034: Loss=4.7771, Acc=0.389, 
2025-10-12 21:40:22,970 - training.trainer - INFO - Epoch 45, Step 154134: Loss=5.7129, Acc=0.237, 
2025-10-12 21:40:33,050 - training.trainer - INFO - Epoch 45, Step 154234: Loss=5.7138, Acc=0.231, 
2025-10-12 21:40:43,262 - training.trainer - INFO - Epoch 45, Step 154334: Loss=4.6846, Acc=0.406, 
2025-10-12 21:40:53,357 - training.trainer - INFO - Epoch 45, Step 154434: Loss=5.2030, Acc=0.387, 
2025-10-12 21:41:03,550 - training.trainer - INFO - Epoch 45, Step 154534: Loss=5.5941, Acc=0.182, 
2025-10-12 21:41:13,699 - training.trainer - INFO - Epoch 45, Step 154634: Loss=5.6072, Acc=0.267, 
2025-10-12 21:41:23,882 - training.trainer - INFO - Epoch 45, Step 154734: Loss=5.8348, Acc=0.121, 
2025-10-12 21:41:33,989 - training.trainer - INFO - Epoch 45, Step 154834: Loss=4.8286, Acc=0.393, 
2025-10-12 21:41:44,128 - training.trainer - INFO - Epoch 45, Step 154934: Loss=6.2384, Acc=0.220, 
2025-10-12 21:41:54,383 - training.trainer - INFO - Epoch 45, Step 155034: Loss=3.0765, Acc=0.455, 
2025-10-12 21:42:04,546 - training.trainer - INFO - Epoch 45, Step 155134: Loss=5.9853, Acc=0.250, 
2025-10-12 21:42:14,697 - training.trainer - INFO - Epoch 45, Step 155234: Loss=5.5387, Acc=0.289, 
2025-10-12 21:42:24,940 - training.trainer - INFO - Epoch 45, Step 155334: Loss=5.3642, Acc=0.296, 
2025-10-12 21:42:35,229 - training.trainer - INFO - Epoch 45, Step 155434: Loss=4.9466, Acc=0.450, 
2025-10-12 21:42:45,407 - training.trainer - INFO - Epoch 45, Step 155534: Loss=5.0488, Acc=0.292, 
2025-10-12 21:43:07,110 - training.trainer - INFO - Epoch 46/100 completed in 356.63s - Train Loss: 5.3706, Train Acc: 0.297, Val Loss: 5.7623, Val Acc: 0.261
2025-10-12 21:43:16,070 - training.trainer - INFO - Epoch 46, Step 155717: Loss=5.4913, Acc=0.317, 
2025-10-12 21:43:24,664 - training.trainer - INFO - Epoch 46, Step 155817: Loss=5.3791, Acc=0.273, 
2025-10-12 21:43:33,317 - training.trainer - INFO - Epoch 46, Step 155917: Loss=5.8283, Acc=0.279, 
2025-10-12 21:43:41,843 - training.trainer - INFO - Epoch 46, Step 156017: Loss=4.8826, Acc=0.241, 
2025-10-12 21:43:50,420 - training.trainer - INFO - Epoch 46, Step 156117: Loss=3.8023, Acc=0.600, 
2025-10-12 21:43:59,050 - training.trainer - INFO - Epoch 46, Step 156217: Loss=6.0246, Acc=0.263, 
2025-10-12 21:44:07,870 - training.trainer - INFO - Epoch 46, Step 156317: Loss=3.8483, Acc=0.654, 
2025-10-12 21:44:17,253 - training.trainer - INFO - Epoch 46, Step 156417: Loss=4.7094, Acc=0.321, 
2025-10-12 21:44:26,416 - training.trainer - INFO - Epoch 46, Step 156517: Loss=5.6184, Acc=0.273, 
2025-10-12 21:44:35,340 - training.trainer - INFO - Epoch 46, Step 156617: Loss=5.7048, Acc=0.304, 
2025-10-12 21:44:44,703 - training.trainer - INFO - Epoch 46, Step 156717: Loss=5.8304, Acc=0.191, 
2025-10-12 21:44:54,165 - training.trainer - INFO - Epoch 46, Step 156817: Loss=5.7154, Acc=0.138, 
2025-10-12 21:45:03,706 - training.trainer - INFO - Epoch 46, Step 156917: Loss=4.6095, Acc=0.367, 
2025-10-12 21:45:13,797 - training.trainer - INFO - Epoch 46, Step 157017: Loss=5.7563, Acc=0.200, 
2025-10-12 21:45:24,025 - training.trainer - INFO - Epoch 46, Step 157117: Loss=5.2723, Acc=0.368, 
2025-10-12 21:45:33,983 - training.trainer - INFO - Epoch 46, Step 157217: Loss=5.4468, Acc=0.326, 
2025-10-12 21:45:43,827 - training.trainer - INFO - Epoch 46, Step 157317: Loss=4.5822, Acc=0.217, 
2025-10-12 21:45:54,102 - training.trainer - INFO - Epoch 46, Step 157417: Loss=4.7923, Acc=0.500, 
2025-10-12 21:46:04,403 - training.trainer - INFO - Epoch 46, Step 157517: Loss=5.1283, Acc=0.293, 
2025-10-12 21:46:14,731 - training.trainer - INFO - Epoch 46, Step 157617: Loss=6.0296, Acc=0.227, 
2025-10-12 21:46:25,023 - training.trainer - INFO - Epoch 46, Step 157717: Loss=5.1494, Acc=0.364, 
2025-10-12 21:46:35,053 - training.trainer - INFO - Epoch 46, Step 157817: Loss=5.3199, Acc=0.333, 
2025-10-12 21:46:45,340 - training.trainer - INFO - Epoch 46, Step 157917: Loss=6.1744, Acc=0.176, 
2025-10-12 21:46:55,553 - training.trainer - INFO - Epoch 46, Step 158017: Loss=5.5692, Acc=0.241, 
2025-10-12 21:47:05,646 - training.trainer - INFO - Epoch 46, Step 158117: Loss=5.0718, Acc=0.243, 
2025-10-12 21:47:15,925 - training.trainer - INFO - Epoch 46, Step 158217: Loss=5.8870, Acc=0.268, 
2025-10-12 21:47:26,247 - training.trainer - INFO - Epoch 46, Step 158317: Loss=4.8410, Acc=0.467, 
2025-10-12 21:47:36,302 - training.trainer - INFO - Epoch 46, Step 158417: Loss=5.5382, Acc=0.280, 
2025-10-12 21:47:46,174 - training.trainer - INFO - Epoch 46, Step 158517: Loss=4.9539, Acc=0.333, 
2025-10-12 21:47:56,160 - training.trainer - INFO - Epoch 46, Step 158617: Loss=4.9678, Acc=0.400, 
2025-10-12 21:48:06,186 - training.trainer - INFO - Epoch 46, Step 158717: Loss=5.3683, Acc=0.350, 
2025-10-12 21:48:16,084 - training.trainer - INFO - Epoch 46, Step 158817: Loss=5.8343, Acc=0.228, 
2025-10-12 21:48:26,271 - training.trainer - INFO - Epoch 46, Step 158917: Loss=5.9942, Acc=0.333, 
2025-10-12 21:48:48,671 - training.trainer - INFO - Epoch 47/100 completed in 341.56s - Train Loss: 5.3555, Train Acc: 0.299, Val Loss: 5.7836, Val Acc: 0.259
2025-10-12 21:48:48,671 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-12 21:48:48,671 - training.trainer - INFO - Training completed!
2025-10-12 21:48:48,674 - __main__ - INFO - Training completed successfully!
2025-10-12 21:48:48,827 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-12 21:48:49,125 - __main__ - INFO - Process completed!
2025-10-12 21:49:07,701 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-12 21:49:07,701 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-12 21:49:07,701 - __main__ - INFO - Starting model evaluation
2025-10-12 21:49:08,637 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-12 21:57:22,930 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-12 21:57:22,954 - __main__ - INFO - Process completed!
2025-10-12 21:57:29,282 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-12 21:57:29,282 - __main__ - INFO - Configuration: configs/lsa_t_config_5.yaml
2025-10-12 21:57:29,282 - __main__ - INFO - Starting model evaluation
2025-10-12 21:57:30,227 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-12 23:13:23,441 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-12 23:13:23,465 - __main__ - INFO - Process completed!
2025-10-12 23:13:28,551 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-12 23:13:28,551 - __main__ - INFO - Configuration: configs/lsa_t_config_8.yaml
2025-10-12 23:13:28,551 - __main__ - INFO - Starting model evaluation
2025-10-12 23:13:29,402 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-13 00:59:27,812 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-13 00:59:27,829 - __main__ - INFO - Process completed!
2025-10-13 00:59:32,854 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 00:59:32,855 - __main__ - INFO - Configuration: configs/lsa_t_config_16.yaml
2025-10-13 00:59:32,855 - __main__ - INFO - Starting model evaluation
2025-10-13 00:59:33,937 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-13 05:06:49,331 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-13 05:06:49,355 - __main__ - INFO - Process completed!
2025-10-13 05:06:54,743 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 05:06:54,744 - __main__ - INFO - Configuration: configs/lsa_t_config_24.yaml
2025-10-13 05:06:54,744 - __main__ - INFO - Starting model evaluation
2025-10-13 05:06:55,565 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-13 12:26:47,699 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-13 12:26:47,719 - __main__ - INFO - Process completed!
2025-10-13 12:26:59,954 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 12:26:59,954 - __main__ - INFO - Configuration: configs/lsa_t_config_32.yaml
2025-10-13 12:26:59,954 - __main__ - INFO - Starting model evaluation
2025-10-13 12:27:01,098 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-13 21:25:06,993 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-13 21:25:07,014 - __main__ - INFO - Process completed!
2025-10-13 23:25:33,993 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-13 23:25:33,994 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-13 23:25:33,994 - __main__ - INFO - Starting training pipeline
2025-10-13 23:25:34,021 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-13 23:25:34,051 - __main__ - INFO - GPU: NVIDIA A30
2025-10-13 23:25:34,051 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-13 23:25:34,051 - __main__ - INFO - Loading training data...
2025-10-13 23:25:44,798 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-13 23:25:44,799 - __main__ - INFO - Processing train split...
2025-10-13 23:25:44,905 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-13 23:25:44,905 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-13 23:26:41,975 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-13 23:27:39,482 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-13 23:28:37,665 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-13 23:29:33,945 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-13 23:30:30,151 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-13 23:31:24,943 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-13 23:32:07,335 - __main__ - INFO - Processing val split...
2025-10-13 23:32:07,627 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-13 23:32:07,627 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-13 23:32:53,713 - __main__ - INFO - Processing test split...
2025-10-13 23:32:53,994 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-13 23:32:53,994 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-13 23:33:29,337 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-13 23:33:29,337 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-13 23:33:29,355 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-13 23:33:29,355 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-13 23:33:29,355 - __main__ - INFO - Creating model architecture...
2025-10-13 23:33:29,742 - __main__ - INFO - Model created successfully
2025-10-13 23:33:29,745 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-13 23:33:29,745 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-13 23:33:29,745 - __main__ - INFO - Using device: cuda
2025-10-13 23:33:29,745 - __main__ - INFO - Creating trainer...
2025-10-13 23:33:29,745 - __main__ - INFO - Moving model to cuda...
2025-10-13 23:33:30,074 - __main__ - INFO - Model moved to cuda
2025-10-13 23:33:30,074 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-13 23:33:32,558 - __main__ - INFO - Trainer created successfully
2025-10-13 23:33:32,559 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-13 23:33:32,559 - __main__ - INFO - Starting training...
2025-10-13 23:33:32,559 - __main__ - INFO - Training configuration:
2025-10-13 23:33:32,559 - __main__ - INFO -   - Epochs: 100
2025-10-13 23:33:32,559 - __main__ - INFO -   - Batch size: 2
2025-10-13 23:33:32,559 - __main__ - INFO -   - Learning rate: 3e-5
2025-10-13 23:33:32,559 - __main__ - INFO -   - Training samples: 6765
2025-10-13 23:33:32,559 - __main__ - INFO -   - Validation samples: 845
2025-10-13 23:33:32,560 - training.trainer - INFO - Starting training for 100 epochs
2025-10-13 23:33:32,560 - training.trainer - INFO - Model parameters: 21,794,400
2025-10-13 23:33:32,560 - training.trainer - INFO - Training on device: cuda
2025-10-13 23:33:39,700 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 23:33:39,700 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-13 23:33:39,700 - __main__ - INFO - Starting model evaluation
2025-10-13 23:33:40,163 - __main__ - ERROR - No trained model found at checkpoints/lsa_t/best_model.pt
2025-10-13 23:33:40,174 - __main__ - INFO - Process completed!
2025-10-13 23:33:44,713 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 23:33:44,714 - __main__ - INFO - Configuration: configs/lsa_t_config_5.yaml
2025-10-13 23:33:44,714 - __main__ - INFO - Starting model evaluation
2025-10-13 23:33:45,188 - __main__ - ERROR - No trained model found at checkpoints/lsa_t/best_model.pt
2025-10-13 23:33:45,198 - __main__ - INFO - Process completed!
2025-10-13 23:33:49,414 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 23:33:49,415 - __main__ - INFO - Configuration: configs/lsa_t_config_8.yaml
2025-10-13 23:33:49,415 - __main__ - INFO - Starting model evaluation
2025-10-13 23:33:49,811 - __main__ - ERROR - No trained model found at checkpoints/lsa_t/best_model.pt
2025-10-13 23:33:49,820 - __main__ - INFO - Process completed!
2025-10-13 23:33:53,728 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 23:33:53,728 - __main__ - INFO - Configuration: configs/lsa_t_config_16.yaml
2025-10-13 23:33:53,728 - __main__ - INFO - Starting model evaluation
2025-10-13 23:33:54,150 - __main__ - ERROR - No trained model found at checkpoints/lsa_t/best_model.pt
2025-10-13 23:33:54,161 - __main__ - INFO - Process completed!
2025-10-13 23:33:58,714 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 23:33:58,714 - __main__ - INFO - Configuration: configs/lsa_t_config_24.yaml
2025-10-13 23:33:58,714 - __main__ - INFO - Starting model evaluation
2025-10-13 23:33:59,158 - __main__ - ERROR - No trained model found at checkpoints/lsa_t/best_model.pt
2025-10-13 23:33:59,168 - __main__ - INFO - Process completed!
2025-10-13 23:34:03,342 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-13 23:34:03,342 - __main__ - INFO - Configuration: configs/lsa_t_config_32.yaml
2025-10-13 23:34:03,342 - __main__ - INFO - Starting model evaluation
2025-10-13 23:34:03,799 - __main__ - ERROR - No trained model found at checkpoints/lsa_t/best_model.pt
2025-10-13 23:34:03,808 - __main__ - INFO - Process completed!
2025-10-14 17:59:01,975 - __main__ - INFO - Starting Sign Language Translation - Mode: train
2025-10-14 17:59:01,976 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-14 17:59:01,976 - __main__ - INFO - Starting training pipeline
2025-10-14 17:59:02,008 - __main__ - INFO - Initial GPU check: CUDA available = True
2025-10-14 17:59:02,032 - __main__ - INFO - GPU: NVIDIA A30
2025-10-14 17:59:02,033 - __main__ - INFO - GPU Memory: 23.5 GB
2025-10-14 17:59:02,033 - __main__ - INFO - Loading training data...
2025-10-14 17:59:28,537 - __main__ - INFO - Extracting texts for vocabulary creation from ALL dataset splits...
2025-10-14 17:59:28,538 - __main__ - INFO - Processing train split...
2025-10-14 17:59:28,646 - __main__ - INFO - Processing ALL 6765 samples from train split...
2025-10-14 17:59:28,646 - __main__ - INFO -   Processed 0/6765 samples from train...
2025-10-14 18:00:18,336 - __main__ - INFO -   Processed 1000/6765 samples from train...
2025-10-14 18:01:07,884 - __main__ - INFO -   Processed 2000/6765 samples from train...
2025-10-14 18:01:57,951 - __main__ - INFO -   Processed 3000/6765 samples from train...
2025-10-14 18:02:46,919 - __main__ - INFO -   Processed 4000/6765 samples from train...
2025-10-14 18:03:35,755 - __main__ - INFO -   Processed 5000/6765 samples from train...
2025-10-14 18:04:24,152 - __main__ - INFO -   Processed 6000/6765 samples from train...
2025-10-14 18:05:01,152 - __main__ - INFO - Processing val split...
2025-10-14 18:05:01,390 - __main__ - INFO - Processing ALL 845 samples from val split...
2025-10-14 18:05:01,391 - __main__ - INFO -   Processed 0/845 samples from val...
2025-10-14 18:05:42,401 - __main__ - INFO - Processing test split...
2025-10-14 18:05:42,631 - __main__ - INFO - Processing ALL 847 samples from test split...
2025-10-14 18:05:42,631 - __main__ - INFO -   Processed 0/847 samples from test...
2025-10-14 18:06:24,372 - __main__ - INFO - Extracted 8457 transcriptions from ALL splits for vocabulary
2025-10-14 18:06:24,373 - __main__ - INFO - Creating vocabulary from training texts...
2025-10-14 18:06:24,398 - __main__ - INFO - Vocabulary created successfully with 13664 words
2025-10-14 18:06:24,398 - __main__ - INFO - Special tokens: PAD=0, UNK=3, SOS=1, EOS=2
2025-10-14 18:06:24,398 - __main__ - INFO - Creating model architecture...
2025-10-14 18:06:24,950 - __main__ - INFO - Model created successfully
2025-10-14 18:06:24,950 - __main__ - INFO - üöÄ Using GPU: NVIDIA A30
2025-10-14 18:06:24,950 - __main__ - INFO - üíæ GPU Memory: 23.5 GB
2025-10-14 18:06:24,950 - __main__ - INFO - Using device: cuda
2025-10-14 18:06:24,950 - __main__ - INFO - Creating trainer...
2025-10-14 18:06:24,951 - __main__ - INFO - Moving model to cuda...
2025-10-14 18:06:25,708 - __main__ - INFO - Model moved to cuda
2025-10-14 18:06:25,708 - __main__ - INFO - Model parameters are on: cuda:0
2025-10-14 18:06:27,223 - __main__ - INFO - Trainer created successfully
2025-10-14 18:06:27,223 - __main__ - INFO - Trainer model parameters are on: cuda:0
2025-10-14 18:06:27,223 - __main__ - INFO - Starting training...
2025-10-14 18:06:27,224 - __main__ - INFO - Training configuration:
2025-10-14 18:06:27,224 - __main__ - INFO -   - Epochs: 100
2025-10-14 18:06:27,224 - __main__ - INFO -   - Batch size: 2
2025-10-14 18:06:27,224 - __main__ - INFO -   - Learning rate: 3e-5
2025-10-14 18:06:27,224 - __main__ - INFO -   - Training samples: 6765
2025-10-14 18:06:27,224 - __main__ - INFO -   - Validation samples: 845
2025-10-14 18:06:27,224 - training.trainer - INFO - Starting training for 100 epochs
2025-10-14 18:06:27,224 - training.trainer - INFO - Model parameters: 21,794,400
2025-10-14 18:06:27,225 - training.trainer - INFO - Training on device: cuda
2025-10-14 18:06:38,718 - training.trainer - INFO - Epoch 0, Step 99: Loss=8.8166, Acc=0.091, 
2025-10-14 18:06:48,214 - training.trainer - INFO - Epoch 0, Step 199: Loss=8.2538, Acc=0.037, 
2025-10-14 18:06:57,434 - training.trainer - INFO - Epoch 0, Step 299: Loss=7.7454, Acc=0.047, 
2025-10-14 18:07:06,695 - training.trainer - INFO - Epoch 0, Step 399: Loss=6.9663, Acc=0.107, 
2025-10-14 18:07:16,269 - training.trainer - INFO - Epoch 0, Step 499: Loss=6.5177, Acc=0.125, 
2025-10-14 18:07:25,213 - training.trainer - INFO - Epoch 0, Step 599: Loss=7.1749, Acc=0.033, 
2025-10-14 18:07:34,084 - training.trainer - INFO - Epoch 0, Step 699: Loss=6.3395, Acc=0.158, 
2025-10-14 18:07:43,172 - training.trainer - INFO - Epoch 0, Step 799: Loss=6.5751, Acc=0.067, 
2025-10-14 18:07:52,245 - training.trainer - INFO - Epoch 0, Step 899: Loss=7.0990, Acc=0.160, 
2025-10-14 18:08:01,140 - training.trainer - INFO - Epoch 0, Step 999: Loss=6.8655, Acc=0.132, 
2025-10-14 18:08:09,829 - training.trainer - INFO - Epoch 0, Step 1099: Loss=7.2194, Acc=0.093, 
2025-10-14 18:08:18,559 - training.trainer - INFO - Epoch 0, Step 1199: Loss=6.8133, Acc=0.192, 
2025-10-14 18:08:27,689 - training.trainer - INFO - Epoch 0, Step 1299: Loss=6.5699, Acc=0.074, 
2025-10-14 18:08:36,374 - training.trainer - INFO - Epoch 0, Step 1399: Loss=5.7442, Acc=0.190, 
2025-10-14 18:08:45,046 - training.trainer - INFO - Epoch 0, Step 1499: Loss=7.0515, Acc=0.121, 
2025-10-14 18:08:53,995 - training.trainer - INFO - Epoch 0, Step 1599: Loss=6.4330, Acc=0.200, 
2025-10-14 18:09:02,855 - training.trainer - INFO - Epoch 0, Step 1699: Loss=6.7887, Acc=0.132, 
2025-10-14 18:09:11,461 - training.trainer - INFO - Epoch 0, Step 1799: Loss=6.6046, Acc=0.104, 
2025-10-14 18:09:20,137 - training.trainer - INFO - Epoch 0, Step 1899: Loss=6.6075, Acc=0.090, 
2025-10-14 18:09:28,739 - training.trainer - INFO - Epoch 0, Step 1999: Loss=7.0089, Acc=0.108, 
2025-10-14 18:09:37,443 - training.trainer - INFO - Epoch 0, Step 2099: Loss=7.2290, Acc=0.250, 
2025-10-14 18:09:45,902 - training.trainer - INFO - Epoch 0, Step 2199: Loss=5.8695, Acc=0.167, 
2025-10-14 18:09:54,619 - training.trainer - INFO - Epoch 0, Step 2299: Loss=6.7800, Acc=0.122, 
2025-10-14 18:10:03,208 - training.trainer - INFO - Epoch 0, Step 2399: Loss=6.4780, Acc=0.196, 
2025-10-14 18:10:11,750 - training.trainer - INFO - Epoch 0, Step 2499: Loss=6.7559, Acc=0.179, 
2025-10-14 18:10:20,525 - training.trainer - INFO - Epoch 0, Step 2599: Loss=6.9735, Acc=0.111, 
2025-10-14 18:10:29,220 - training.trainer - INFO - Epoch 0, Step 2699: Loss=6.8535, Acc=0.148, 
2025-10-14 18:10:37,832 - training.trainer - INFO - Epoch 0, Step 2799: Loss=6.0926, Acc=0.238, 
2025-10-14 18:10:46,308 - training.trainer - INFO - Epoch 0, Step 2899: Loss=6.8378, Acc=0.162, 
2025-10-14 18:10:55,112 - training.trainer - INFO - Epoch 0, Step 2999: Loss=6.6056, Acc=0.101, 
2025-10-14 18:11:03,806 - training.trainer - INFO - Epoch 0, Step 3099: Loss=5.9885, Acc=0.136, 
2025-10-14 18:11:12,644 - training.trainer - INFO - Epoch 0, Step 3199: Loss=5.5391, Acc=0.235, 
2025-10-14 18:11:21,433 - training.trainer - INFO - Epoch 0, Step 3299: Loss=5.7463, Acc=0.130, 
2025-10-14 18:11:45,562 - training.trainer - INFO - Epoch 1/100 completed in 318.34s - Train Loss: 6.8255, Train Acc: 0.128, Val Loss: 6.3481, Val Acc: 0.166
2025-10-14 18:11:46,352 - training.trainer - INFO - New best model saved with validation loss: 6.3481
2025-10-14 18:11:46,352 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_1.pt
2025-10-14 18:11:55,727 - training.trainer - INFO - Epoch 1, Step 3482: Loss=7.1810, Acc=0.103, 
2025-10-14 18:12:04,353 - training.trainer - INFO - Epoch 1, Step 3582: Loss=6.6871, Acc=0.214, 
2025-10-14 18:12:12,812 - training.trainer - INFO - Epoch 1, Step 3682: Loss=6.0091, Acc=0.217, 
2025-10-14 18:12:21,274 - training.trainer - INFO - Epoch 1, Step 3782: Loss=6.3428, Acc=0.125, 
2025-10-14 18:12:29,859 - training.trainer - INFO - Epoch 1, Step 3882: Loss=5.6619, Acc=0.250, 
2025-10-14 18:12:38,509 - training.trainer - INFO - Epoch 1, Step 3982: Loss=6.2775, Acc=0.222, 
2025-10-14 18:12:47,075 - training.trainer - INFO - Epoch 1, Step 4082: Loss=7.3445, Acc=0.070, 
2025-10-14 18:12:55,543 - training.trainer - INFO - Epoch 1, Step 4182: Loss=6.3516, Acc=0.109, 
2025-10-14 18:13:04,046 - training.trainer - INFO - Epoch 1, Step 4282: Loss=6.6792, Acc=0.073, 
2025-10-14 18:13:12,729 - training.trainer - INFO - Epoch 1, Step 4382: Loss=5.7358, Acc=0.259, 
2025-10-14 18:13:21,340 - training.trainer - INFO - Epoch 1, Step 4482: Loss=6.3420, Acc=0.125, 
2025-10-14 18:13:29,816 - training.trainer - INFO - Epoch 1, Step 4582: Loss=6.6462, Acc=0.139, 
2025-10-14 18:13:38,529 - training.trainer - INFO - Epoch 1, Step 4682: Loss=5.9925, Acc=0.167, 
2025-10-14 18:13:47,174 - training.trainer - INFO - Epoch 1, Step 4782: Loss=6.6620, Acc=0.122, 
2025-10-14 18:13:55,646 - training.trainer - INFO - Epoch 1, Step 4882: Loss=5.5362, Acc=0.312, 
2025-10-14 18:14:04,346 - training.trainer - INFO - Epoch 1, Step 4982: Loss=6.1329, Acc=0.171, 
2025-10-14 18:14:13,255 - training.trainer - INFO - Epoch 1, Step 5082: Loss=6.4819, Acc=0.212, 
2025-10-14 18:14:21,827 - training.trainer - INFO - Epoch 1, Step 5182: Loss=6.4164, Acc=0.163, 
2025-10-14 18:14:30,360 - training.trainer - INFO - Epoch 1, Step 5282: Loss=6.6315, Acc=0.158, 
2025-10-14 18:14:38,720 - training.trainer - INFO - Epoch 1, Step 5382: Loss=5.9223, Acc=0.200, 
2025-10-14 18:14:47,540 - training.trainer - INFO - Epoch 1, Step 5482: Loss=6.1964, Acc=0.176, 
2025-10-14 18:14:56,136 - training.trainer - INFO - Epoch 1, Step 5582: Loss=6.1250, Acc=0.238, 
2025-10-14 18:15:04,524 - training.trainer - INFO - Epoch 1, Step 5682: Loss=6.0694, Acc=0.143, 
2025-10-14 18:15:12,843 - training.trainer - INFO - Epoch 1, Step 5782: Loss=5.1725, Acc=0.357, 
2025-10-14 18:15:21,350 - training.trainer - INFO - Epoch 1, Step 5882: Loss=5.8675, Acc=0.220, 
2025-10-14 18:15:29,942 - training.trainer - INFO - Epoch 1, Step 5982: Loss=6.6723, Acc=0.200, 
2025-10-14 18:15:38,552 - training.trainer - INFO - Epoch 1, Step 6082: Loss=6.8248, Acc=0.100, 
2025-10-14 18:15:46,947 - training.trainer - INFO - Epoch 1, Step 6182: Loss=6.2104, Acc=0.190, 
2025-10-14 18:15:55,384 - training.trainer - INFO - Epoch 1, Step 6282: Loss=5.8787, Acc=0.200, 
2025-10-14 18:16:03,954 - training.trainer - INFO - Epoch 1, Step 6382: Loss=5.9283, Acc=0.179, 
2025-10-14 18:16:12,486 - training.trainer - INFO - Epoch 1, Step 6482: Loss=6.2734, Acc=0.167, 
2025-10-14 18:16:20,962 - training.trainer - INFO - Epoch 1, Step 6582: Loss=5.6859, Acc=0.190, 
2025-10-14 18:16:29,527 - training.trainer - INFO - Epoch 1, Step 6682: Loss=6.0894, Acc=0.224, 
2025-10-14 18:16:54,565 - training.trainer - INFO - Epoch 2/100 completed in 308.21s - Train Loss: 6.3207, Train Acc: 0.166, Val Loss: 6.1970, Val Acc: 0.176
2025-10-14 18:16:55,309 - training.trainer - INFO - New best model saved with validation loss: 6.1970
2025-10-14 18:16:55,309 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_2.pt
2025-10-14 18:17:04,108 - training.trainer - INFO - Epoch 2, Step 6865: Loss=6.5621, Acc=0.150, 
2025-10-14 18:17:12,847 - training.trainer - INFO - Epoch 2, Step 6965: Loss=6.4327, Acc=0.135, 
2025-10-14 18:17:21,369 - training.trainer - INFO - Epoch 2, Step 7065: Loss=6.7633, Acc=0.111, 
2025-10-14 18:17:29,938 - training.trainer - INFO - Epoch 2, Step 7165: Loss=5.4626, Acc=0.300, 
2025-10-14 18:17:38,831 - training.trainer - INFO - Epoch 2, Step 7265: Loss=5.9221, Acc=0.294, 
2025-10-14 18:17:46,728 - training.trainer - INFO - Epoch 2, Step 7365: Loss=6.5734, Acc=0.190, 
2025-10-14 18:17:54,676 - training.trainer - INFO - Epoch 2, Step 7465: Loss=7.0312, Acc=0.118, 
2025-10-14 18:18:02,667 - training.trainer - INFO - Epoch 2, Step 7565: Loss=6.5623, Acc=0.123, 
2025-10-14 18:18:10,605 - training.trainer - INFO - Epoch 2, Step 7665: Loss=6.1127, Acc=0.205, 
2025-10-14 18:18:18,467 - training.trainer - INFO - Epoch 2, Step 7765: Loss=6.6793, Acc=0.143, 
2025-10-14 18:18:26,530 - training.trainer - INFO - Epoch 2, Step 7865: Loss=5.9995, Acc=0.250, 
2025-10-14 18:18:34,601 - training.trainer - INFO - Epoch 2, Step 7965: Loss=5.6085, Acc=0.214, 
2025-10-14 18:18:42,609 - training.trainer - INFO - Epoch 2, Step 8065: Loss=6.1911, Acc=0.115, 
2025-10-14 18:18:50,645 - training.trainer - INFO - Epoch 2, Step 8165: Loss=5.8582, Acc=0.179, 
2025-10-14 18:18:58,609 - training.trainer - INFO - Epoch 2, Step 8265: Loss=5.9471, Acc=0.182, 
2025-10-14 18:19:06,860 - training.trainer - INFO - Epoch 2, Step 8365: Loss=5.8877, Acc=0.171, 
2025-10-14 18:19:14,827 - training.trainer - INFO - Epoch 2, Step 8465: Loss=6.3933, Acc=0.173, 
2025-10-14 18:19:22,844 - training.trainer - INFO - Epoch 2, Step 8565: Loss=6.2279, Acc=0.171, 
2025-10-14 18:19:31,003 - training.trainer - INFO - Epoch 2, Step 8665: Loss=6.2672, Acc=0.136, 
2025-10-14 18:19:38,910 - training.trainer - INFO - Epoch 2, Step 8765: Loss=6.0647, Acc=0.179, 
2025-10-14 18:19:46,829 - training.trainer - INFO - Epoch 2, Step 8865: Loss=6.6413, Acc=0.103, 
2025-10-14 18:19:54,983 - training.trainer - INFO - Epoch 2, Step 8965: Loss=6.5952, Acc=0.160, 
2025-10-14 18:20:02,760 - training.trainer - INFO - Epoch 2, Step 9065: Loss=6.3247, Acc=0.143, 
2025-10-14 18:20:11,085 - training.trainer - INFO - Epoch 2, Step 9165: Loss=6.4335, Acc=0.096, 
2025-10-14 18:20:19,030 - training.trainer - INFO - Epoch 2, Step 9265: Loss=6.2559, Acc=0.216, 
2025-10-14 18:20:26,977 - training.trainer - INFO - Epoch 2, Step 9365: Loss=6.5862, Acc=0.176, 
2025-10-14 18:20:34,964 - training.trainer - INFO - Epoch 2, Step 9465: Loss=5.1613, Acc=0.345, 
2025-10-14 18:20:43,035 - training.trainer - INFO - Epoch 2, Step 9565: Loss=6.2615, Acc=0.136, 
2025-10-14 18:20:51,002 - training.trainer - INFO - Epoch 2, Step 9665: Loss=5.8288, Acc=0.188, 
2025-10-14 18:20:59,030 - training.trainer - INFO - Epoch 2, Step 9765: Loss=6.3458, Acc=0.161, 
2025-10-14 18:21:06,952 - training.trainer - INFO - Epoch 2, Step 9865: Loss=6.3034, Acc=0.118, 
2025-10-14 18:21:14,869 - training.trainer - INFO - Epoch 2, Step 9965: Loss=5.5415, Acc=0.226, 
2025-10-14 18:21:22,916 - training.trainer - INFO - Epoch 2, Step 10065: Loss=6.1011, Acc=0.150, 
2025-10-14 18:21:44,966 - training.trainer - INFO - Epoch 3/100 completed in 289.66s - Train Loss: 6.1987, Train Acc: 0.177, Val Loss: 6.1160, Val Acc: 0.181
2025-10-14 18:21:45,795 - training.trainer - INFO - New best model saved with validation loss: 6.1160
2025-10-14 18:21:45,796 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_3.pt
2025-10-14 18:21:54,070 - training.trainer - INFO - Epoch 3, Step 10248: Loss=5.8956, Acc=0.286, 
2025-10-14 18:22:02,135 - training.trainer - INFO - Epoch 3, Step 10348: Loss=6.5571, Acc=0.179, 
2025-10-14 18:22:10,078 - training.trainer - INFO - Epoch 3, Step 10448: Loss=6.7601, Acc=0.091, 
2025-10-14 18:22:18,183 - training.trainer - INFO - Epoch 3, Step 10548: Loss=5.3902, Acc=0.207, 
2025-10-14 18:22:26,130 - training.trainer - INFO - Epoch 3, Step 10648: Loss=5.6537, Acc=0.312, 
2025-10-14 18:22:34,273 - training.trainer - INFO - Epoch 3, Step 10748: Loss=6.0581, Acc=0.193, 
2025-10-14 18:22:42,159 - training.trainer - INFO - Epoch 3, Step 10848: Loss=5.8688, Acc=0.180, 
2025-10-14 18:22:49,988 - training.trainer - INFO - Epoch 3, Step 10948: Loss=6.5117, Acc=0.133, 
2025-10-14 18:22:57,795 - training.trainer - INFO - Epoch 3, Step 11048: Loss=6.6718, Acc=0.195, 
2025-10-14 18:23:05,397 - training.trainer - INFO - Epoch 3, Step 11148: Loss=6.0784, Acc=0.185, 
2025-10-14 18:23:12,936 - training.trainer - INFO - Epoch 3, Step 11248: Loss=5.6262, Acc=0.318, 
2025-10-14 18:23:20,327 - training.trainer - INFO - Epoch 3, Step 11348: Loss=7.3122, Acc=0.133, 
2025-10-14 18:23:27,774 - training.trainer - INFO - Epoch 3, Step 11448: Loss=5.6341, Acc=0.257, 
2025-10-14 18:23:35,261 - training.trainer - INFO - Epoch 3, Step 11548: Loss=6.1606, Acc=0.138, 
2025-10-14 18:23:42,842 - training.trainer - INFO - Epoch 3, Step 11648: Loss=5.8939, Acc=0.180, 
2025-10-14 18:23:50,401 - training.trainer - INFO - Epoch 3, Step 11748: Loss=6.3914, Acc=0.087, 
2025-10-14 18:23:57,819 - training.trainer - INFO - Epoch 3, Step 11848: Loss=5.8793, Acc=0.200, 
2025-10-14 18:24:05,348 - training.trainer - INFO - Epoch 3, Step 11948: Loss=6.4461, Acc=0.197, 
2025-10-14 18:24:12,898 - training.trainer - INFO - Epoch 3, Step 12048: Loss=7.3657, Acc=0.120, 
2025-10-14 18:24:20,600 - training.trainer - INFO - Epoch 3, Step 12148: Loss=6.1061, Acc=0.133, 
2025-10-14 18:24:28,746 - training.trainer - INFO - Epoch 3, Step 12248: Loss=6.1380, Acc=0.175, 
2025-10-14 18:24:36,772 - training.trainer - INFO - Epoch 3, Step 12348: Loss=6.8592, Acc=0.155, 
2025-10-14 18:24:44,952 - training.trainer - INFO - Epoch 3, Step 12448: Loss=5.9234, Acc=0.229, 
2025-10-14 18:24:52,972 - training.trainer - INFO - Epoch 3, Step 12548: Loss=5.2154, Acc=0.143, 
2025-10-14 18:25:00,975 - training.trainer - INFO - Epoch 3, Step 12648: Loss=5.1195, Acc=0.217, 
2025-10-14 18:25:08,965 - training.trainer - INFO - Epoch 3, Step 12748: Loss=5.9908, Acc=0.171, 
2025-10-14 18:25:17,019 - training.trainer - INFO - Epoch 3, Step 12848: Loss=6.2987, Acc=0.173, 
2025-10-14 18:25:24,879 - training.trainer - INFO - Epoch 3, Step 12948: Loss=6.6191, Acc=0.125, 
2025-10-14 18:25:32,995 - training.trainer - INFO - Epoch 3, Step 13048: Loss=5.9050, Acc=0.160, 
2025-10-14 18:25:41,104 - training.trainer - INFO - Epoch 3, Step 13148: Loss=6.3411, Acc=0.154, 
2025-10-14 18:25:49,035 - training.trainer - INFO - Epoch 3, Step 13248: Loss=6.8236, Acc=0.086, 
2025-10-14 18:25:56,963 - training.trainer - INFO - Epoch 3, Step 13348: Loss=6.3167, Acc=0.262, 
2025-10-14 18:26:05,083 - training.trainer - INFO - Epoch 3, Step 13448: Loss=6.0223, Acc=0.138, 
2025-10-14 18:26:27,259 - training.trainer - INFO - Epoch 4/100 completed in 281.46s - Train Loss: 6.1274, Train Acc: 0.186, Val Loss: 6.0424, Val Acc: 0.194
2025-10-14 18:26:27,998 - training.trainer - INFO - New best model saved with validation loss: 6.0424
2025-10-14 18:26:27,998 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_4.pt
2025-10-14 18:26:36,506 - training.trainer - INFO - Epoch 4, Step 13631: Loss=6.2995, Acc=0.204, 
2025-10-14 18:26:44,400 - training.trainer - INFO - Epoch 4, Step 13731: Loss=5.6845, Acc=0.211, 
2025-10-14 18:26:52,466 - training.trainer - INFO - Epoch 4, Step 13831: Loss=6.1669, Acc=0.160, 
2025-10-14 18:27:00,602 - training.trainer - INFO - Epoch 4, Step 13931: Loss=5.7151, Acc=0.156, 
2025-10-14 18:27:08,361 - training.trainer - INFO - Epoch 4, Step 14031: Loss=5.7090, Acc=0.190, 
2025-10-14 18:27:16,280 - training.trainer - INFO - Epoch 4, Step 14131: Loss=6.3119, Acc=0.143, 
2025-10-14 18:27:24,206 - training.trainer - INFO - Epoch 4, Step 14231: Loss=6.0240, Acc=0.188, 
2025-10-14 18:27:32,153 - training.trainer - INFO - Epoch 4, Step 14331: Loss=6.1612, Acc=0.200, 
2025-10-14 18:27:40,294 - training.trainer - INFO - Epoch 4, Step 14431: Loss=5.2109, Acc=0.263, 
2025-10-14 18:27:48,417 - training.trainer - INFO - Epoch 4, Step 14531: Loss=6.2926, Acc=0.219, 
2025-10-14 18:27:56,672 - training.trainer - INFO - Epoch 4, Step 14631: Loss=6.5681, Acc=0.209, 
2025-10-14 18:28:04,936 - training.trainer - INFO - Epoch 4, Step 14731: Loss=6.2695, Acc=0.091, 
2025-10-14 18:28:13,255 - training.trainer - INFO - Epoch 4, Step 14831: Loss=5.9538, Acc=0.289, 
2025-10-14 18:28:21,238 - training.trainer - INFO - Epoch 4, Step 14931: Loss=5.8251, Acc=0.261, 
2025-10-14 18:28:29,354 - training.trainer - INFO - Epoch 4, Step 15031: Loss=5.8636, Acc=0.186, 
2025-10-14 18:28:37,511 - training.trainer - INFO - Epoch 4, Step 15131: Loss=6.1582, Acc=0.138, 
2025-10-14 18:28:45,554 - training.trainer - INFO - Epoch 4, Step 15231: Loss=5.7393, Acc=0.293, 
2025-10-14 18:28:53,476 - training.trainer - INFO - Epoch 4, Step 15331: Loss=6.2378, Acc=0.150, 
2025-10-14 18:29:01,608 - training.trainer - INFO - Epoch 4, Step 15431: Loss=6.5676, Acc=0.172, 
2025-10-14 18:29:09,707 - training.trainer - INFO - Epoch 4, Step 15531: Loss=6.4197, Acc=0.138, 
2025-10-14 18:29:18,014 - training.trainer - INFO - Epoch 4, Step 15631: Loss=6.0576, Acc=0.167, 
2025-10-14 18:29:26,177 - training.trainer - INFO - Epoch 4, Step 15731: Loss=6.8312, Acc=0.176, 
2025-10-14 18:29:34,207 - training.trainer - INFO - Epoch 4, Step 15831: Loss=5.7392, Acc=0.174, 
2025-10-14 18:29:42,320 - training.trainer - INFO - Epoch 4, Step 15931: Loss=6.2034, Acc=0.205, 
2025-10-14 18:29:50,413 - training.trainer - INFO - Epoch 4, Step 16031: Loss=5.4851, Acc=0.286, 
2025-10-14 18:29:58,402 - training.trainer - INFO - Epoch 4, Step 16131: Loss=6.0584, Acc=0.237, 
2025-10-14 18:30:06,667 - training.trainer - INFO - Epoch 4, Step 16231: Loss=5.0823, Acc=0.333, 
2025-10-14 18:30:14,669 - training.trainer - INFO - Epoch 4, Step 16331: Loss=5.7532, Acc=0.147, 
2025-10-14 18:30:22,756 - training.trainer - INFO - Epoch 4, Step 16431: Loss=7.5264, Acc=0.152, 
2025-10-14 18:30:31,042 - training.trainer - INFO - Epoch 4, Step 16531: Loss=6.0793, Acc=0.125, 
2025-10-14 18:30:39,065 - training.trainer - INFO - Epoch 4, Step 16631: Loss=5.7869, Acc=0.273, 
2025-10-14 18:30:47,061 - training.trainer - INFO - Epoch 4, Step 16731: Loss=4.9731, Acc=0.400, 
2025-10-14 18:30:55,338 - training.trainer - INFO - Epoch 4, Step 16831: Loss=6.4377, Acc=0.189, 
2025-10-14 18:31:17,901 - training.trainer - INFO - Epoch 5/100 completed in 289.90s - Train Loss: 6.0806, Train Acc: 0.193, Val Loss: 5.9993, Val Acc: 0.200
2025-10-14 18:31:18,317 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-14 18:31:19,169 - training.trainer - INFO - New best model saved with validation loss: 5.9993
2025-10-14 18:31:19,169 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_5.pt
2025-10-14 18:31:28,678 - training.trainer - INFO - Epoch 5, Step 17014: Loss=5.2925, Acc=0.316, 
2025-10-14 18:31:37,817 - training.trainer - INFO - Epoch 5, Step 17114: Loss=6.1945, Acc=0.200, 
2025-10-14 18:31:46,803 - training.trainer - INFO - Epoch 5, Step 17214: Loss=5.2762, Acc=0.355, 
2025-10-14 18:31:55,939 - training.trainer - INFO - Epoch 5, Step 17314: Loss=6.6167, Acc=0.194, 
2025-10-14 18:32:04,495 - training.trainer - INFO - Epoch 5, Step 17414: Loss=5.5889, Acc=0.179, 
2025-10-14 18:32:12,693 - training.trainer - INFO - Epoch 5, Step 17514: Loss=6.3610, Acc=0.174, 
2025-10-14 18:32:20,805 - training.trainer - INFO - Epoch 5, Step 17614: Loss=6.6913, Acc=0.302, 
2025-10-14 18:32:28,816 - training.trainer - INFO - Epoch 5, Step 17714: Loss=5.4511, Acc=0.277, 
2025-10-14 18:32:36,849 - training.trainer - INFO - Epoch 5, Step 17814: Loss=5.3832, Acc=0.208, 
2025-10-14 18:32:45,368 - training.trainer - INFO - Epoch 5, Step 17914: Loss=6.0001, Acc=0.206, 
2025-10-14 18:32:54,066 - training.trainer - INFO - Epoch 5, Step 18014: Loss=6.2273, Acc=0.186, 
2025-10-14 18:33:02,808 - training.trainer - INFO - Epoch 5, Step 18114: Loss=6.7816, Acc=0.133, 
2025-10-14 18:33:11,692 - training.trainer - INFO - Epoch 5, Step 18214: Loss=5.7865, Acc=0.256, 
2025-10-14 18:33:20,923 - training.trainer - INFO - Epoch 5, Step 18314: Loss=6.9520, Acc=0.127, 
2025-10-14 18:33:29,860 - training.trainer - INFO - Epoch 5, Step 18414: Loss=5.7550, Acc=0.244, 
2025-10-14 18:33:39,397 - training.trainer - INFO - Epoch 5, Step 18514: Loss=6.3079, Acc=0.162, 
2025-10-14 18:33:48,998 - training.trainer - INFO - Epoch 5, Step 18614: Loss=7.0515, Acc=0.227, 
2025-10-14 18:33:58,506 - training.trainer - INFO - Epoch 5, Step 18714: Loss=6.0894, Acc=0.320, 
2025-10-14 18:34:08,082 - training.trainer - INFO - Epoch 5, Step 18814: Loss=6.2204, Acc=0.318, 
2025-10-14 18:34:17,396 - training.trainer - INFO - Epoch 5, Step 18914: Loss=6.7606, Acc=0.136, 
2025-10-14 18:34:26,952 - training.trainer - INFO - Epoch 5, Step 19014: Loss=6.7116, Acc=0.227, 
2025-10-14 18:34:36,370 - training.trainer - INFO - Epoch 5, Step 19114: Loss=5.8657, Acc=0.180, 
2025-10-14 18:34:45,733 - training.trainer - INFO - Epoch 5, Step 19214: Loss=5.8809, Acc=0.152, 
2025-10-14 18:34:55,099 - training.trainer - INFO - Epoch 5, Step 19314: Loss=6.2751, Acc=0.132, 
2025-10-14 18:35:04,571 - training.trainer - INFO - Epoch 5, Step 19414: Loss=5.6114, Acc=0.162, 
2025-10-14 18:35:14,119 - training.trainer - INFO - Epoch 5, Step 19514: Loss=5.4168, Acc=0.250, 
2025-10-14 18:35:23,756 - training.trainer - INFO - Epoch 5, Step 19614: Loss=6.3368, Acc=0.138, 
2025-10-14 18:35:33,240 - training.trainer - INFO - Epoch 5, Step 19714: Loss=6.1120, Acc=0.179, 
2025-10-14 18:35:42,258 - training.trainer - INFO - Epoch 5, Step 19814: Loss=6.1639, Acc=0.180, 
2025-10-14 18:35:51,582 - training.trainer - INFO - Epoch 5, Step 19914: Loss=5.9291, Acc=0.222, 
2025-10-14 18:36:00,863 - training.trainer - INFO - Epoch 5, Step 20014: Loss=5.8016, Acc=0.136, 
2025-10-14 18:36:09,349 - training.trainer - INFO - Epoch 5, Step 20114: Loss=6.3074, Acc=0.143, 
2025-10-14 18:36:18,367 - training.trainer - INFO - Epoch 5, Step 20214: Loss=5.9269, Acc=0.243, 
2025-10-14 18:36:43,853 - training.trainer - INFO - Epoch 6/100 completed in 324.68s - Train Loss: 6.0336, Train Acc: 0.201, Val Loss: 5.9739, Val Acc: 0.210
2025-10-14 18:36:44,715 - training.trainer - INFO - New best model saved with validation loss: 5.9739
2025-10-14 18:36:44,715 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_6.pt
2025-10-14 18:36:53,938 - training.trainer - INFO - Epoch 6, Step 20397: Loss=6.0898, Acc=0.158, 
2025-10-14 18:37:02,305 - training.trainer - INFO - Epoch 6, Step 20497: Loss=5.9732, Acc=0.143, 
2025-10-14 18:37:10,765 - training.trainer - INFO - Epoch 6, Step 20597: Loss=5.9482, Acc=0.267, 
2025-10-14 18:37:19,278 - training.trainer - INFO - Epoch 6, Step 20697: Loss=5.7988, Acc=0.396, 
2025-10-14 18:37:27,900 - training.trainer - INFO - Epoch 6, Step 20797: Loss=6.3008, Acc=0.167, 
2025-10-14 18:37:36,531 - training.trainer - INFO - Epoch 6, Step 20897: Loss=7.0148, Acc=0.088, 
2025-10-14 18:37:45,272 - training.trainer - INFO - Epoch 6, Step 20997: Loss=6.0286, Acc=0.235, 
2025-10-14 18:37:53,769 - training.trainer - INFO - Epoch 6, Step 21097: Loss=4.7955, Acc=0.312, 
2025-10-14 18:38:02,028 - training.trainer - INFO - Epoch 6, Step 21197: Loss=6.5170, Acc=0.125, 
2025-10-14 18:38:10,588 - training.trainer - INFO - Epoch 6, Step 21297: Loss=5.0819, Acc=0.350, 
2025-10-14 18:38:18,849 - training.trainer - INFO - Epoch 6, Step 21397: Loss=6.6422, Acc=0.156, 
2025-10-14 18:38:27,132 - training.trainer - INFO - Epoch 6, Step 21497: Loss=5.4802, Acc=0.179, 
2025-10-14 18:38:35,312 - training.trainer - INFO - Epoch 6, Step 21597: Loss=6.5915, Acc=0.217, 
2025-10-14 18:38:43,552 - training.trainer - INFO - Epoch 6, Step 21697: Loss=6.3034, Acc=0.143, 
2025-10-14 18:38:52,009 - training.trainer - INFO - Epoch 6, Step 21797: Loss=5.3168, Acc=0.167, 
2025-10-14 18:39:00,381 - training.trainer - INFO - Epoch 6, Step 21897: Loss=5.6686, Acc=0.143, 
2025-10-14 18:39:08,610 - training.trainer - INFO - Epoch 6, Step 21997: Loss=6.5844, Acc=0.159, 
2025-10-14 18:39:17,007 - training.trainer - INFO - Epoch 6, Step 22097: Loss=6.5392, Acc=0.286, 
2025-10-14 18:39:25,524 - training.trainer - INFO - Epoch 6, Step 22197: Loss=6.1854, Acc=0.182, 
2025-10-14 18:39:33,559 - training.trainer - INFO - Epoch 6, Step 22297: Loss=5.8365, Acc=0.240, 
2025-10-14 18:39:41,735 - training.trainer - INFO - Epoch 6, Step 22397: Loss=5.2399, Acc=0.353, 
2025-10-14 18:39:50,126 - training.trainer - INFO - Epoch 6, Step 22497: Loss=6.0129, Acc=0.165, 
2025-10-14 18:39:58,461 - training.trainer - INFO - Epoch 6, Step 22597: Loss=5.1776, Acc=0.323, 
2025-10-14 18:40:06,691 - training.trainer - INFO - Epoch 6, Step 22697: Loss=5.7695, Acc=0.259, 
2025-10-14 18:40:15,021 - training.trainer - INFO - Epoch 6, Step 22797: Loss=6.0290, Acc=0.219, 
2025-10-14 18:40:23,260 - training.trainer - INFO - Epoch 6, Step 22897: Loss=5.4903, Acc=0.208, 
2025-10-14 18:40:31,821 - training.trainer - INFO - Epoch 6, Step 22997: Loss=6.0453, Acc=0.190, 
2025-10-14 18:40:40,167 - training.trainer - INFO - Epoch 6, Step 23097: Loss=6.4168, Acc=0.115, 
2025-10-14 18:40:48,513 - training.trainer - INFO - Epoch 6, Step 23197: Loss=6.3301, Acc=0.161, 
2025-10-14 18:40:56,951 - training.trainer - INFO - Epoch 6, Step 23297: Loss=5.5011, Acc=0.250, 
2025-10-14 18:41:05,336 - training.trainer - INFO - Epoch 6, Step 23397: Loss=6.0984, Acc=0.111, 
2025-10-14 18:41:13,898 - training.trainer - INFO - Epoch 6, Step 23497: Loss=6.4364, Acc=0.146, 
2025-10-14 18:41:21,962 - training.trainer - INFO - Epoch 6, Step 23597: Loss=6.0792, Acc=0.250, 
2025-10-14 18:41:43,216 - training.trainer - INFO - Epoch 7/100 completed in 298.50s - Train Loss: 5.9950, Train Acc: 0.207, Val Loss: 5.9135, Val Acc: 0.218
2025-10-14 18:41:44,007 - training.trainer - INFO - New best model saved with validation loss: 5.9135
2025-10-14 18:41:44,007 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_7.pt
2025-10-14 18:41:52,503 - training.trainer - INFO - Epoch 7, Step 23780: Loss=6.4922, Acc=0.145, 
2025-10-14 18:42:00,548 - training.trainer - INFO - Epoch 7, Step 23880: Loss=5.9206, Acc=0.185, 
2025-10-14 18:42:08,563 - training.trainer - INFO - Epoch 7, Step 23980: Loss=5.7690, Acc=0.167, 
2025-10-14 18:42:16,486 - training.trainer - INFO - Epoch 7, Step 24080: Loss=4.7206, Acc=0.273, 
2025-10-14 18:42:24,478 - training.trainer - INFO - Epoch 7, Step 24180: Loss=5.6231, Acc=0.310, 
2025-10-14 18:42:32,663 - training.trainer - INFO - Epoch 7, Step 24280: Loss=6.1020, Acc=0.170, 
2025-10-14 18:42:40,580 - training.trainer - INFO - Epoch 7, Step 24380: Loss=6.5044, Acc=0.152, 
2025-10-14 18:42:48,673 - training.trainer - INFO - Epoch 7, Step 24480: Loss=6.0676, Acc=0.203, 
2025-10-14 18:42:57,370 - training.trainer - INFO - Epoch 7, Step 24580: Loss=6.6761, Acc=0.173, 
2025-10-14 18:43:05,644 - training.trainer - INFO - Epoch 7, Step 24680: Loss=5.2507, Acc=0.289, 
2025-10-14 18:43:14,165 - training.trainer - INFO - Epoch 7, Step 24780: Loss=5.7594, Acc=0.171, 
2025-10-14 18:43:22,715 - training.trainer - INFO - Epoch 7, Step 24880: Loss=6.7348, Acc=0.138, 
2025-10-14 18:43:31,329 - training.trainer - INFO - Epoch 7, Step 24980: Loss=6.3789, Acc=0.208, 
2025-10-14 18:43:40,072 - training.trainer - INFO - Epoch 7, Step 25080: Loss=5.9553, Acc=0.242, 
2025-10-14 18:43:48,768 - training.trainer - INFO - Epoch 7, Step 25180: Loss=6.0311, Acc=0.312, 
2025-10-14 18:43:57,616 - training.trainer - INFO - Epoch 7, Step 25280: Loss=6.6550, Acc=0.164, 
2025-10-14 18:44:06,227 - training.trainer - INFO - Epoch 7, Step 25380: Loss=5.5298, Acc=0.225, 
2025-10-14 18:44:14,775 - training.trainer - INFO - Epoch 7, Step 25480: Loss=5.2731, Acc=0.294, 
2025-10-14 18:44:23,394 - training.trainer - INFO - Epoch 7, Step 25580: Loss=6.8885, Acc=0.117, 
2025-10-14 18:44:32,007 - training.trainer - INFO - Epoch 7, Step 25680: Loss=6.0328, Acc=0.169, 
2025-10-14 18:44:40,824 - training.trainer - INFO - Epoch 7, Step 25780: Loss=6.2303, Acc=0.250, 
2025-10-14 18:44:49,689 - training.trainer - INFO - Epoch 7, Step 25880: Loss=6.8956, Acc=0.231, 
2025-10-14 18:44:58,116 - training.trainer - INFO - Epoch 7, Step 25980: Loss=6.2896, Acc=0.149, 
2025-10-14 18:45:06,720 - training.trainer - INFO - Epoch 7, Step 26080: Loss=6.0224, Acc=0.238, 
2025-10-14 18:45:15,087 - training.trainer - INFO - Epoch 7, Step 26180: Loss=6.2907, Acc=0.125, 
2025-10-14 18:45:23,808 - training.trainer - INFO - Epoch 7, Step 26280: Loss=5.4367, Acc=0.250, 
2025-10-14 18:45:32,207 - training.trainer - INFO - Epoch 7, Step 26380: Loss=5.2517, Acc=0.143, 
2025-10-14 18:45:40,834 - training.trainer - INFO - Epoch 7, Step 26480: Loss=6.0050, Acc=0.233, 
2025-10-14 18:45:49,389 - training.trainer - INFO - Epoch 7, Step 26580: Loss=5.8969, Acc=0.200, 
2025-10-14 18:45:58,197 - training.trainer - INFO - Epoch 7, Step 26680: Loss=6.3866, Acc=0.154, 
2025-10-14 18:46:06,804 - training.trainer - INFO - Epoch 7, Step 26780: Loss=4.8725, Acc=0.452, 
2025-10-14 18:46:15,272 - training.trainer - INFO - Epoch 7, Step 26880: Loss=5.9031, Acc=0.146, 
2025-10-14 18:46:24,115 - training.trainer - INFO - Epoch 7, Step 26980: Loss=6.8215, Acc=0.216, 
2025-10-14 18:46:48,865 - training.trainer - INFO - Epoch 8/100 completed in 304.86s - Train Loss: 5.9563, Train Acc: 0.213, Val Loss: 5.8878, Val Acc: 0.221
2025-10-14 18:46:49,604 - training.trainer - INFO - New best model saved with validation loss: 5.8878
2025-10-14 18:46:49,604 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_8.pt
2025-10-14 18:46:58,337 - training.trainer - INFO - Epoch 8, Step 27163: Loss=6.4665, Acc=0.138, 
2025-10-14 18:47:07,076 - training.trainer - INFO - Epoch 8, Step 27263: Loss=4.9578, Acc=0.400, 
2025-10-14 18:47:15,102 - training.trainer - INFO - Epoch 8, Step 27363: Loss=6.1743, Acc=0.170, 
2025-10-14 18:47:23,079 - training.trainer - INFO - Epoch 8, Step 27463: Loss=6.6949, Acc=0.167, 
2025-10-14 18:47:31,261 - training.trainer - INFO - Epoch 8, Step 27563: Loss=5.4069, Acc=0.318, 
2025-10-14 18:47:39,368 - training.trainer - INFO - Epoch 8, Step 27663: Loss=5.2821, Acc=0.417, 
2025-10-14 18:47:47,450 - training.trainer - INFO - Epoch 8, Step 27763: Loss=6.3998, Acc=0.136, 
2025-10-14 18:47:55,718 - training.trainer - INFO - Epoch 8, Step 27863: Loss=6.3994, Acc=0.094, 
2025-10-14 18:48:03,713 - training.trainer - INFO - Epoch 8, Step 27963: Loss=5.8049, Acc=0.226, 
2025-10-14 18:48:11,979 - training.trainer - INFO - Epoch 8, Step 28063: Loss=6.0148, Acc=0.191, 
2025-10-14 18:48:20,119 - training.trainer - INFO - Epoch 8, Step 28163: Loss=6.5328, Acc=0.171, 
2025-10-14 18:48:27,877 - training.trainer - INFO - Epoch 8, Step 28263: Loss=5.8239, Acc=0.353, 
2025-10-14 18:48:36,042 - training.trainer - INFO - Epoch 8, Step 28363: Loss=5.9029, Acc=0.259, 
2025-10-14 18:48:44,135 - training.trainer - INFO - Epoch 8, Step 28463: Loss=6.3282, Acc=0.111, 
2025-10-14 18:48:52,041 - training.trainer - INFO - Epoch 8, Step 28563: Loss=5.5337, Acc=0.211, 
2025-10-14 18:49:00,026 - training.trainer - INFO - Epoch 8, Step 28663: Loss=6.5202, Acc=0.170, 
2025-10-14 18:49:07,835 - training.trainer - INFO - Epoch 8, Step 28763: Loss=5.5715, Acc=0.200, 
2025-10-14 18:49:15,787 - training.trainer - INFO - Epoch 8, Step 28863: Loss=5.9268, Acc=0.234, 
2025-10-14 18:49:23,962 - training.trainer - INFO - Epoch 8, Step 28963: Loss=6.5409, Acc=0.154, 
2025-10-14 18:49:31,860 - training.trainer - INFO - Epoch 8, Step 29063: Loss=5.6788, Acc=0.170, 
2025-10-14 18:49:39,763 - training.trainer - INFO - Epoch 8, Step 29163: Loss=5.9807, Acc=0.205, 
2025-10-14 18:49:47,786 - training.trainer - INFO - Epoch 8, Step 29263: Loss=6.0742, Acc=0.133, 
2025-10-14 18:49:55,888 - training.trainer - INFO - Epoch 8, Step 29363: Loss=6.0021, Acc=0.188, 
2025-10-14 18:50:03,947 - training.trainer - INFO - Epoch 8, Step 29463: Loss=5.6946, Acc=0.241, 
2025-10-14 18:50:11,728 - training.trainer - INFO - Epoch 8, Step 29563: Loss=6.0315, Acc=0.194, 
2025-10-14 18:50:19,788 - training.trainer - INFO - Epoch 8, Step 29663: Loss=5.9858, Acc=0.138, 
2025-10-14 18:50:27,838 - training.trainer - INFO - Epoch 8, Step 29763: Loss=6.3912, Acc=0.154, 
2025-10-14 18:50:35,924 - training.trainer - INFO - Epoch 8, Step 29863: Loss=5.7384, Acc=0.227, 
2025-10-14 18:50:43,757 - training.trainer - INFO - Epoch 8, Step 29963: Loss=6.1804, Acc=0.185, 
2025-10-14 18:50:51,811 - training.trainer - INFO - Epoch 8, Step 30063: Loss=5.8538, Acc=0.261, 
2025-10-14 18:50:59,935 - training.trainer - INFO - Epoch 8, Step 30163: Loss=5.7489, Acc=0.163, 
2025-10-14 18:51:07,931 - training.trainer - INFO - Epoch 8, Step 30263: Loss=5.9965, Acc=0.161, 
2025-10-14 18:51:16,076 - training.trainer - INFO - Epoch 8, Step 30363: Loss=5.0555, Acc=0.188, 
2025-10-14 18:51:38,171 - training.trainer - INFO - Epoch 9/100 completed in 288.57s - Train Loss: 5.9191, Train Acc: 0.219, Val Loss: 5.8739, Val Acc: 0.220
2025-10-14 18:51:39,005 - training.trainer - INFO - New best model saved with validation loss: 5.8739
2025-10-14 18:51:39,005 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_9.pt
2025-10-14 18:51:47,555 - training.trainer - INFO - Epoch 9, Step 30546: Loss=6.3458, Acc=0.182, 
2025-10-14 18:51:55,552 - training.trainer - INFO - Epoch 9, Step 30646: Loss=5.8024, Acc=0.250, 
2025-10-14 18:52:03,714 - training.trainer - INFO - Epoch 9, Step 30746: Loss=5.9482, Acc=0.262, 
2025-10-14 18:52:12,148 - training.trainer - INFO - Epoch 9, Step 30846: Loss=5.9068, Acc=0.226, 
2025-10-14 18:52:20,877 - training.trainer - INFO - Epoch 9, Step 30946: Loss=6.4679, Acc=0.138, 
2025-10-14 18:52:29,491 - training.trainer - INFO - Epoch 9, Step 31046: Loss=5.2437, Acc=0.308, 
2025-10-14 18:52:38,633 - training.trainer - INFO - Epoch 9, Step 31146: Loss=5.6941, Acc=0.269, 
2025-10-14 18:52:47,692 - training.trainer - INFO - Epoch 9, Step 31246: Loss=5.7435, Acc=0.161, 
2025-10-14 18:52:56,760 - training.trainer - INFO - Epoch 9, Step 31346: Loss=6.2939, Acc=0.239, 
2025-10-14 18:53:05,812 - training.trainer - INFO - Epoch 9, Step 31446: Loss=6.1572, Acc=0.208, 
2025-10-14 18:53:15,017 - training.trainer - INFO - Epoch 9, Step 31546: Loss=5.4434, Acc=0.292, 
2025-10-14 18:53:24,086 - training.trainer - INFO - Epoch 9, Step 31646: Loss=5.6533, Acc=0.217, 
2025-10-14 18:53:33,192 - training.trainer - INFO - Epoch 9, Step 31746: Loss=5.9223, Acc=0.276, 
2025-10-14 18:53:42,453 - training.trainer - INFO - Epoch 9, Step 31846: Loss=6.1901, Acc=0.197, 
2025-10-14 18:53:51,531 - training.trainer - INFO - Epoch 9, Step 31946: Loss=6.3079, Acc=0.156, 
2025-10-14 18:54:00,625 - training.trainer - INFO - Epoch 9, Step 32046: Loss=6.3176, Acc=0.130, 
2025-10-14 18:54:09,760 - training.trainer - INFO - Epoch 9, Step 32146: Loss=5.2789, Acc=0.194, 
2025-10-14 18:54:17,972 - training.trainer - INFO - Epoch 9, Step 32246: Loss=6.1132, Acc=0.207, 
2025-10-14 18:54:26,593 - training.trainer - INFO - Epoch 9, Step 32346: Loss=5.7891, Acc=0.211, 
2025-10-14 18:54:35,559 - training.trainer - INFO - Epoch 9, Step 32446: Loss=6.4703, Acc=0.143, 
2025-10-14 18:54:44,510 - training.trainer - INFO - Epoch 9, Step 32546: Loss=5.8528, Acc=0.200, 
2025-10-14 18:54:53,634 - training.trainer - INFO - Epoch 9, Step 32646: Loss=6.4818, Acc=0.162, 
2025-10-14 18:55:02,849 - training.trainer - INFO - Epoch 9, Step 32746: Loss=5.2839, Acc=0.250, 
2025-10-14 18:55:11,892 - training.trainer - INFO - Epoch 9, Step 32846: Loss=5.9901, Acc=0.258, 
2025-10-14 18:55:21,101 - training.trainer - INFO - Epoch 9, Step 32946: Loss=5.5873, Acc=0.188, 
2025-10-14 18:55:30,185 - training.trainer - INFO - Epoch 9, Step 33046: Loss=5.6039, Acc=0.333, 
2025-10-14 18:55:39,465 - training.trainer - INFO - Epoch 9, Step 33146: Loss=5.5106, Acc=0.306, 
2025-10-14 18:55:48,666 - training.trainer - INFO - Epoch 9, Step 33246: Loss=5.5822, Acc=0.279, 
2025-10-14 18:55:57,846 - training.trainer - INFO - Epoch 9, Step 33346: Loss=5.9556, Acc=0.117, 
2025-10-14 18:56:07,088 - training.trainer - INFO - Epoch 9, Step 33446: Loss=5.4172, Acc=0.300, 
2025-10-14 18:56:16,067 - training.trainer - INFO - Epoch 9, Step 33546: Loss=6.5288, Acc=0.154, 
2025-10-14 18:56:24,992 - training.trainer - INFO - Epoch 9, Step 33646: Loss=6.2825, Acc=0.222, 
2025-10-14 18:56:33,310 - training.trainer - INFO - Epoch 9, Step 33746: Loss=5.5102, Acc=0.333, 
2025-10-14 18:56:54,757 - training.trainer - INFO - Epoch 10/100 completed in 315.75s - Train Loss: 5.8798, Train Acc: 0.222, Val Loss: 5.8471, Val Acc: 0.226
2025-10-14 18:56:55,133 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-14 18:56:55,899 - training.trainer - INFO - New best model saved with validation loss: 5.8471
2025-10-14 18:56:55,900 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_10.pt
2025-10-14 18:57:04,442 - training.trainer - INFO - Epoch 10, Step 33929: Loss=6.7694, Acc=0.169, 
2025-10-14 18:57:12,494 - training.trainer - INFO - Epoch 10, Step 34029: Loss=6.4578, Acc=0.116, 
2025-10-14 18:57:20,561 - training.trainer - INFO - Epoch 10, Step 34129: Loss=6.2475, Acc=0.118, 
2025-10-14 18:57:28,688 - training.trainer - INFO - Epoch 10, Step 34229: Loss=5.7602, Acc=0.265, 
2025-10-14 18:57:36,786 - training.trainer - INFO - Epoch 10, Step 34329: Loss=5.7771, Acc=0.206, 
2025-10-14 18:57:44,640 - training.trainer - INFO - Epoch 10, Step 34429: Loss=5.7684, Acc=0.231, 
2025-10-14 18:57:52,643 - training.trainer - INFO - Epoch 10, Step 34529: Loss=6.3652, Acc=0.095, 
2025-10-14 18:58:00,563 - training.trainer - INFO - Epoch 10, Step 34629: Loss=5.6503, Acc=0.200, 
2025-10-14 18:58:08,365 - training.trainer - INFO - Epoch 10, Step 34729: Loss=6.2034, Acc=0.143, 
2025-10-14 18:58:16,428 - training.trainer - INFO - Epoch 10, Step 34829: Loss=5.5864, Acc=0.333, 
2025-10-14 18:58:24,418 - training.trainer - INFO - Epoch 10, Step 34929: Loss=5.1158, Acc=0.292, 
2025-10-14 18:58:32,280 - training.trainer - INFO - Epoch 10, Step 35029: Loss=6.2017, Acc=0.200, 
2025-10-14 18:58:40,318 - training.trainer - INFO - Epoch 10, Step 35129: Loss=6.4551, Acc=0.250, 
2025-10-14 18:58:48,503 - training.trainer - INFO - Epoch 10, Step 35229: Loss=6.3497, Acc=0.148, 
2025-10-14 18:58:56,649 - training.trainer - INFO - Epoch 10, Step 35329: Loss=5.7421, Acc=0.257, 
2025-10-14 18:59:04,703 - training.trainer - INFO - Epoch 10, Step 35429: Loss=5.8210, Acc=0.283, 
2025-10-14 18:59:12,797 - training.trainer - INFO - Epoch 10, Step 35529: Loss=6.3260, Acc=0.214, 
2025-10-14 18:59:20,741 - training.trainer - INFO - Epoch 10, Step 35629: Loss=6.1313, Acc=0.182, 
2025-10-14 18:59:28,943 - training.trainer - INFO - Epoch 10, Step 35729: Loss=5.7841, Acc=0.233, 
2025-10-14 18:59:36,931 - training.trainer - INFO - Epoch 10, Step 35829: Loss=5.3064, Acc=0.250, 
2025-10-14 18:59:44,882 - training.trainer - INFO - Epoch 10, Step 35929: Loss=5.6442, Acc=0.206, 
2025-10-14 18:59:52,671 - training.trainer - INFO - Epoch 10, Step 36029: Loss=5.7637, Acc=0.229, 
2025-10-14 19:00:00,494 - training.trainer - INFO - Epoch 10, Step 36129: Loss=5.1231, Acc=0.303, 
2025-10-14 19:00:08,440 - training.trainer - INFO - Epoch 10, Step 36229: Loss=5.9509, Acc=0.143, 
2025-10-14 19:00:16,216 - training.trainer - INFO - Epoch 10, Step 36329: Loss=6.6857, Acc=0.143, 
2025-10-14 19:00:24,040 - training.trainer - INFO - Epoch 10, Step 36429: Loss=5.9990, Acc=0.222, 
2025-10-14 19:00:31,931 - training.trainer - INFO - Epoch 10, Step 36529: Loss=6.2705, Acc=0.229, 
2025-10-14 19:00:39,638 - training.trainer - INFO - Epoch 10, Step 36629: Loss=5.7654, Acc=0.148, 
2025-10-14 19:00:47,420 - training.trainer - INFO - Epoch 10, Step 36729: Loss=6.3731, Acc=0.212, 
2025-10-14 19:00:55,367 - training.trainer - INFO - Epoch 10, Step 36829: Loss=5.8030, Acc=0.238, 
2025-10-14 19:01:03,068 - training.trainer - INFO - Epoch 10, Step 36929: Loss=6.0381, Acc=0.150, 
2025-10-14 19:01:10,885 - training.trainer - INFO - Epoch 10, Step 37029: Loss=5.6289, Acc=0.222, 
2025-10-14 19:01:19,103 - training.trainer - INFO - Epoch 10, Step 37129: Loss=5.8493, Acc=0.246, 
2025-10-14 19:01:42,137 - training.trainer - INFO - Epoch 11/100 completed in 286.24s - Train Loss: 5.8527, Train Acc: 0.228, Val Loss: 5.8739, Val Acc: 0.228
2025-10-14 19:01:51,049 - training.trainer - INFO - Epoch 11, Step 37312: Loss=5.0461, Acc=0.296, 
2025-10-14 19:01:59,434 - training.trainer - INFO - Epoch 11, Step 37412: Loss=6.0116, Acc=0.245, 
2025-10-14 19:02:07,816 - training.trainer - INFO - Epoch 11, Step 37512: Loss=5.6037, Acc=0.268, 
2025-10-14 19:02:15,829 - training.trainer - INFO - Epoch 11, Step 37612: Loss=4.3636, Acc=0.429, 
2025-10-14 19:02:24,171 - training.trainer - INFO - Epoch 11, Step 37712: Loss=5.5219, Acc=0.213, 
2025-10-14 19:02:32,369 - training.trainer - INFO - Epoch 11, Step 37812: Loss=6.0519, Acc=0.222, 
2025-10-14 19:02:40,702 - training.trainer - INFO - Epoch 11, Step 37912: Loss=5.9101, Acc=0.195, 
2025-10-14 19:02:48,823 - training.trainer - INFO - Epoch 11, Step 38012: Loss=5.5963, Acc=0.245, 
2025-10-14 19:02:56,926 - training.trainer - INFO - Epoch 11, Step 38112: Loss=5.3513, Acc=0.348, 
2025-10-14 19:03:05,050 - training.trainer - INFO - Epoch 11, Step 38212: Loss=6.1819, Acc=0.196, 
2025-10-14 19:03:13,490 - training.trainer - INFO - Epoch 11, Step 38312: Loss=6.1358, Acc=0.250, 
2025-10-14 19:03:21,887 - training.trainer - INFO - Epoch 11, Step 38412: Loss=5.5106, Acc=0.219, 
2025-10-14 19:03:30,195 - training.trainer - INFO - Epoch 11, Step 38512: Loss=7.0064, Acc=0.133, 
2025-10-14 19:03:38,301 - training.trainer - INFO - Epoch 11, Step 38612: Loss=4.8217, Acc=0.200, 
2025-10-14 19:03:46,609 - training.trainer - INFO - Epoch 11, Step 38712: Loss=5.4707, Acc=0.205, 
2025-10-14 19:03:55,047 - training.trainer - INFO - Epoch 11, Step 38812: Loss=5.5603, Acc=0.175, 
2025-10-14 19:04:03,391 - training.trainer - INFO - Epoch 11, Step 38912: Loss=6.6710, Acc=0.175, 
2025-10-14 19:04:11,865 - training.trainer - INFO - Epoch 11, Step 39012: Loss=5.5223, Acc=0.265, 
2025-10-14 19:04:20,336 - training.trainer - INFO - Epoch 11, Step 39112: Loss=6.4851, Acc=0.191, 
2025-10-14 19:04:28,840 - training.trainer - INFO - Epoch 11, Step 39212: Loss=6.5924, Acc=0.138, 
2025-10-14 19:04:37,113 - training.trainer - INFO - Epoch 11, Step 39312: Loss=6.5658, Acc=0.200, 
2025-10-14 19:04:45,572 - training.trainer - INFO - Epoch 11, Step 39412: Loss=5.5303, Acc=0.417, 
2025-10-14 19:04:54,085 - training.trainer - INFO - Epoch 11, Step 39512: Loss=6.5708, Acc=0.121, 
2025-10-14 19:05:02,472 - training.trainer - INFO - Epoch 11, Step 39612: Loss=5.8320, Acc=0.254, 
2025-10-14 19:05:10,992 - training.trainer - INFO - Epoch 11, Step 39712: Loss=4.9982, Acc=0.250, 
2025-10-14 19:05:19,295 - training.trainer - INFO - Epoch 11, Step 39812: Loss=6.4279, Acc=0.140, 
2025-10-14 19:05:27,798 - training.trainer - INFO - Epoch 11, Step 39912: Loss=5.5069, Acc=0.265, 
2025-10-14 19:05:36,198 - training.trainer - INFO - Epoch 11, Step 40012: Loss=5.8929, Acc=0.217, 
2025-10-14 19:05:44,472 - training.trainer - INFO - Epoch 11, Step 40112: Loss=5.0958, Acc=0.250, 
2025-10-14 19:05:53,025 - training.trainer - INFO - Epoch 11, Step 40212: Loss=4.9295, Acc=0.278, 
2025-10-14 19:06:01,398 - training.trainer - INFO - Epoch 11, Step 40312: Loss=5.6368, Acc=0.200, 
2025-10-14 19:06:09,720 - training.trainer - INFO - Epoch 11, Step 40412: Loss=5.7975, Acc=0.333, 
2025-10-14 19:06:18,222 - training.trainer - INFO - Epoch 11, Step 40512: Loss=5.9363, Acc=0.194, 
2025-10-14 19:06:42,748 - training.trainer - INFO - Epoch 12/100 completed in 300.61s - Train Loss: 5.8274, Train Acc: 0.231, Val Loss: 5.8692, Val Acc: 0.233
2025-10-14 19:06:51,651 - training.trainer - INFO - Epoch 12, Step 40695: Loss=5.0153, Acc=0.306, 
2025-10-14 19:07:00,328 - training.trainer - INFO - Epoch 12, Step 40795: Loss=6.4839, Acc=0.182, 
2025-10-14 19:07:08,873 - training.trainer - INFO - Epoch 12, Step 40895: Loss=6.3464, Acc=0.218, 
2025-10-14 19:07:17,388 - training.trainer - INFO - Epoch 12, Step 40995: Loss=6.5492, Acc=0.103, 
2025-10-14 19:07:26,079 - training.trainer - INFO - Epoch 12, Step 41095: Loss=6.0726, Acc=0.219, 
2025-10-14 19:07:34,687 - training.trainer - INFO - Epoch 12, Step 41195: Loss=5.5309, Acc=0.219, 
2025-10-14 19:07:43,120 - training.trainer - INFO - Epoch 12, Step 41295: Loss=6.3501, Acc=0.158, 
2025-10-14 19:07:51,458 - training.trainer - INFO - Epoch 12, Step 41395: Loss=5.8790, Acc=0.190, 
2025-10-14 19:07:59,906 - training.trainer - INFO - Epoch 12, Step 41495: Loss=5.7005, Acc=0.195, 
2025-10-14 19:08:08,413 - training.trainer - INFO - Epoch 12, Step 41595: Loss=5.8926, Acc=0.145, 
2025-10-14 19:08:16,922 - training.trainer - INFO - Epoch 12, Step 41695: Loss=6.2127, Acc=0.346, 
2025-10-14 19:08:25,384 - training.trainer - INFO - Epoch 12, Step 41795: Loss=6.5875, Acc=0.156, 
2025-10-14 19:08:34,040 - training.trainer - INFO - Epoch 12, Step 41895: Loss=5.6777, Acc=0.348, 
2025-10-14 19:08:42,490 - training.trainer - INFO - Epoch 12, Step 41995: Loss=6.2813, Acc=0.118, 
2025-10-14 19:08:51,050 - training.trainer - INFO - Epoch 12, Step 42095: Loss=5.0241, Acc=0.267, 
2025-10-14 19:08:59,444 - training.trainer - INFO - Epoch 12, Step 42195: Loss=6.2300, Acc=0.176, 
2025-10-14 19:09:07,960 - training.trainer - INFO - Epoch 12, Step 42295: Loss=5.5495, Acc=0.300, 
2025-10-14 19:09:16,513 - training.trainer - INFO - Epoch 12, Step 42395: Loss=5.8397, Acc=0.387, 
2025-10-14 19:09:25,173 - training.trainer - INFO - Epoch 12, Step 42495: Loss=6.3413, Acc=0.141, 
2025-10-14 19:09:33,807 - training.trainer - INFO - Epoch 12, Step 42595: Loss=5.4348, Acc=0.222, 
2025-10-14 19:09:42,290 - training.trainer - INFO - Epoch 12, Step 42695: Loss=5.3947, Acc=0.276, 
2025-10-14 19:09:50,995 - training.trainer - INFO - Epoch 12, Step 42795: Loss=5.9937, Acc=0.242, 
2025-10-14 19:09:59,776 - training.trainer - INFO - Epoch 12, Step 42895: Loss=5.6740, Acc=0.170, 
2025-10-14 19:10:08,423 - training.trainer - INFO - Epoch 12, Step 42995: Loss=6.3702, Acc=0.146, 
2025-10-14 19:10:16,982 - training.trainer - INFO - Epoch 12, Step 43095: Loss=5.8538, Acc=0.364, 
2025-10-14 19:10:25,392 - training.trainer - INFO - Epoch 12, Step 43195: Loss=5.4447, Acc=0.294, 
2025-10-14 19:10:33,726 - training.trainer - INFO - Epoch 12, Step 43295: Loss=6.9038, Acc=0.192, 
2025-10-14 19:10:42,244 - training.trainer - INFO - Epoch 12, Step 43395: Loss=5.7113, Acc=0.200, 
2025-10-14 19:10:50,724 - training.trainer - INFO - Epoch 12, Step 43495: Loss=6.4124, Acc=0.222, 
2025-10-14 19:10:59,174 - training.trainer - INFO - Epoch 12, Step 43595: Loss=6.3988, Acc=0.148, 
2025-10-14 19:11:07,466 - training.trainer - INFO - Epoch 12, Step 43695: Loss=5.2510, Acc=0.292, 
2025-10-14 19:11:15,677 - training.trainer - INFO - Epoch 12, Step 43795: Loss=6.0634, Acc=0.175, 
2025-10-14 19:11:24,027 - training.trainer - INFO - Epoch 12, Step 43895: Loss=5.8125, Acc=0.321, 
2025-10-14 19:11:47,801 - training.trainer - INFO - Epoch 13/100 completed in 305.05s - Train Loss: 5.8012, Train Acc: 0.233, Val Loss: 5.8434, Val Acc: 0.239
2025-10-14 19:11:48,624 - training.trainer - INFO - New best model saved with validation loss: 5.8434
2025-10-14 19:11:48,625 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_13.pt
2025-10-14 19:11:57,430 - training.trainer - INFO - Epoch 13, Step 44078: Loss=6.5614, Acc=0.159, 
2025-10-14 19:12:05,692 - training.trainer - INFO - Epoch 13, Step 44178: Loss=5.6396, Acc=0.143, 
2025-10-14 19:12:14,291 - training.trainer - INFO - Epoch 13, Step 44278: Loss=6.7932, Acc=0.190, 
2025-10-14 19:12:22,630 - training.trainer - INFO - Epoch 13, Step 44378: Loss=6.0175, Acc=0.167, 
2025-10-14 19:12:30,987 - training.trainer - INFO - Epoch 13, Step 44478: Loss=5.8145, Acc=0.265, 
2025-10-14 19:12:39,636 - training.trainer - INFO - Epoch 13, Step 44578: Loss=5.9203, Acc=0.303, 
2025-10-14 19:12:47,978 - training.trainer - INFO - Epoch 13, Step 44678: Loss=5.8266, Acc=0.214, 
2025-10-14 19:12:56,235 - training.trainer - INFO - Epoch 13, Step 44778: Loss=6.2195, Acc=0.136, 
2025-10-14 19:13:04,994 - training.trainer - INFO - Epoch 13, Step 44878: Loss=5.3963, Acc=0.194, 
2025-10-14 19:13:13,320 - training.trainer - INFO - Epoch 13, Step 44978: Loss=6.2830, Acc=0.179, 
2025-10-14 19:13:22,071 - training.trainer - INFO - Epoch 13, Step 45078: Loss=6.3299, Acc=0.162, 
2025-10-14 19:13:30,515 - training.trainer - INFO - Epoch 13, Step 45178: Loss=5.9586, Acc=0.182, 
2025-10-14 19:13:38,752 - training.trainer - INFO - Epoch 13, Step 45278: Loss=5.3217, Acc=0.310, 
2025-10-14 19:13:47,062 - training.trainer - INFO - Epoch 13, Step 45378: Loss=6.1498, Acc=0.263, 
2025-10-14 19:13:55,414 - training.trainer - INFO - Epoch 13, Step 45478: Loss=6.6763, Acc=0.176, 
2025-10-14 19:14:03,959 - training.trainer - INFO - Epoch 13, Step 45578: Loss=5.7185, Acc=0.258, 
2025-10-14 19:14:12,211 - training.trainer - INFO - Epoch 13, Step 45678: Loss=5.6497, Acc=0.273, 
2025-10-14 19:14:20,699 - training.trainer - INFO - Epoch 13, Step 45778: Loss=6.5132, Acc=0.129, 
2025-10-14 19:14:29,105 - training.trainer - INFO - Epoch 13, Step 45878: Loss=6.0133, Acc=0.189, 
2025-10-14 19:14:37,458 - training.trainer - INFO - Epoch 13, Step 45978: Loss=6.2679, Acc=0.233, 
2025-10-14 19:14:46,123 - training.trainer - INFO - Epoch 13, Step 46078: Loss=5.8193, Acc=0.257, 
2025-10-14 19:14:54,748 - training.trainer - INFO - Epoch 13, Step 46178: Loss=6.7130, Acc=0.118, 
2025-10-14 19:15:03,160 - training.trainer - INFO - Epoch 13, Step 46278: Loss=5.9487, Acc=0.150, 
2025-10-14 19:15:11,512 - training.trainer - INFO - Epoch 13, Step 46378: Loss=5.8317, Acc=0.220, 
2025-10-14 19:15:20,041 - training.trainer - INFO - Epoch 13, Step 46478: Loss=5.9621, Acc=0.179, 
2025-10-14 19:15:28,491 - training.trainer - INFO - Epoch 13, Step 46578: Loss=5.4154, Acc=0.212, 
2025-10-14 19:15:37,024 - training.trainer - INFO - Epoch 13, Step 46678: Loss=5.9975, Acc=0.226, 
2025-10-14 19:15:45,453 - training.trainer - INFO - Epoch 13, Step 46778: Loss=5.4137, Acc=0.311, 
2025-10-14 19:15:53,925 - training.trainer - INFO - Epoch 13, Step 46878: Loss=5.9406, Acc=0.217, 
2025-10-14 19:16:02,271 - training.trainer - INFO - Epoch 13, Step 46978: Loss=5.8390, Acc=0.234, 
2025-10-14 19:16:10,757 - training.trainer - INFO - Epoch 13, Step 47078: Loss=4.6760, Acc=0.353, 
2025-10-14 19:16:19,280 - training.trainer - INFO - Epoch 13, Step 47178: Loss=5.9075, Acc=0.286, 
2025-10-14 19:16:27,940 - training.trainer - INFO - Epoch 13, Step 47278: Loss=5.3253, Acc=0.158, 
2025-10-14 19:16:52,190 - training.trainer - INFO - Epoch 14/100 completed in 303.57s - Train Loss: 5.7754, Train Acc: 0.238, Val Loss: 5.8130, Val Acc: 0.239
2025-10-14 19:16:52,932 - training.trainer - INFO - New best model saved with validation loss: 5.8130
2025-10-14 19:16:52,932 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_14.pt
2025-10-14 19:17:01,836 - training.trainer - INFO - Epoch 14, Step 47461: Loss=5.0774, Acc=0.389, 
2025-10-14 19:17:10,253 - training.trainer - INFO - Epoch 14, Step 47561: Loss=5.4578, Acc=0.281, 
2025-10-14 19:17:18,885 - training.trainer - INFO - Epoch 14, Step 47661: Loss=5.5638, Acc=0.158, 
2025-10-14 19:17:27,755 - training.trainer - INFO - Epoch 14, Step 47761: Loss=5.7729, Acc=0.245, 
2025-10-14 19:17:36,392 - training.trainer - INFO - Epoch 14, Step 47861: Loss=5.7754, Acc=0.256, 
2025-10-14 19:17:44,907 - training.trainer - INFO - Epoch 14, Step 47961: Loss=5.4692, Acc=0.385, 
2025-10-14 19:17:53,362 - training.trainer - INFO - Epoch 14, Step 48061: Loss=4.7191, Acc=0.298, 
2025-10-14 19:18:02,104 - training.trainer - INFO - Epoch 14, Step 48161: Loss=5.8803, Acc=0.111, 
2025-10-14 19:18:10,909 - training.trainer - INFO - Epoch 14, Step 48261: Loss=5.7890, Acc=0.375, 
2025-10-14 19:18:19,450 - training.trainer - INFO - Epoch 14, Step 48361: Loss=5.5370, Acc=0.244, 
2025-10-14 19:18:28,058 - training.trainer - INFO - Epoch 14, Step 48461: Loss=5.4227, Acc=0.304, 
2025-10-14 19:18:36,485 - training.trainer - INFO - Epoch 14, Step 48561: Loss=6.5376, Acc=0.132, 
2025-10-14 19:18:44,296 - training.trainer - INFO - Epoch 14, Step 48661: Loss=4.7781, Acc=0.429, 
2025-10-14 19:18:52,428 - training.trainer - INFO - Epoch 14, Step 48761: Loss=5.6224, Acc=0.286, 
2025-10-14 19:19:00,404 - training.trainer - INFO - Epoch 14, Step 48861: Loss=5.2575, Acc=0.195, 
2025-10-14 19:19:08,481 - training.trainer - INFO - Epoch 14, Step 48961: Loss=6.2650, Acc=0.167, 
2025-10-14 19:19:16,028 - training.trainer - INFO - Epoch 14, Step 49061: Loss=4.3991, Acc=0.360, 
2025-10-14 19:19:23,646 - training.trainer - INFO - Epoch 14, Step 49161: Loss=6.1505, Acc=0.197, 
2025-10-14 19:19:31,362 - training.trainer - INFO - Epoch 14, Step 49261: Loss=6.0552, Acc=0.315, 
2025-10-14 19:19:38,996 - training.trainer - INFO - Epoch 14, Step 49361: Loss=6.6444, Acc=0.195, 
2025-10-14 19:19:46,474 - training.trainer - INFO - Epoch 14, Step 49461: Loss=5.0942, Acc=0.400, 
2025-10-14 19:19:54,077 - training.trainer - INFO - Epoch 14, Step 49561: Loss=5.8957, Acc=0.233, 
2025-10-14 19:20:01,783 - training.trainer - INFO - Epoch 14, Step 49661: Loss=6.0967, Acc=0.115, 
2025-10-14 19:20:10,698 - training.trainer - INFO - Epoch 14, Step 49761: Loss=6.3090, Acc=0.180, 
2025-10-14 19:20:19,794 - training.trainer - INFO - Epoch 14, Step 49861: Loss=4.6169, Acc=0.375, 
2025-10-14 19:20:28,990 - training.trainer - INFO - Epoch 14, Step 49961: Loss=5.3866, Acc=0.225, 
2025-10-14 19:20:38,382 - training.trainer - INFO - Epoch 14, Step 50061: Loss=5.4806, Acc=0.261, 
2025-10-14 19:20:47,614 - training.trainer - INFO - Epoch 14, Step 50161: Loss=6.4617, Acc=0.204, 
2025-10-14 19:20:56,729 - training.trainer - INFO - Epoch 14, Step 50261: Loss=6.3707, Acc=0.200, 
2025-10-14 19:21:05,807 - training.trainer - INFO - Epoch 14, Step 50361: Loss=6.0478, Acc=0.172, 
2025-10-14 19:21:14,911 - training.trainer - INFO - Epoch 14, Step 50461: Loss=6.1522, Acc=0.217, 
2025-10-14 19:21:23,894 - training.trainer - INFO - Epoch 14, Step 50561: Loss=6.7191, Acc=0.100, 
2025-10-14 19:21:33,018 - training.trainer - INFO - Epoch 14, Step 50661: Loss=5.5378, Acc=0.290, 
2025-10-14 19:21:56,243 - training.trainer - INFO - Epoch 15/100 completed in 303.31s - Train Loss: 5.7561, Train Acc: 0.239, Val Loss: 5.8113, Val Acc: 0.241
2025-10-14 19:21:56,693 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-14 19:21:57,469 - training.trainer - INFO - New best model saved with validation loss: 5.8113
2025-10-14 19:21:57,469 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_15.pt
2025-10-14 19:22:05,865 - training.trainer - INFO - Epoch 15, Step 50844: Loss=5.4254, Acc=0.292, 
2025-10-14 19:22:13,822 - training.trainer - INFO - Epoch 15, Step 50944: Loss=5.6003, Acc=0.268, 
2025-10-14 19:22:22,014 - training.trainer - INFO - Epoch 15, Step 51044: Loss=6.0532, Acc=0.220, 
2025-10-14 19:22:30,046 - training.trainer - INFO - Epoch 15, Step 51144: Loss=5.4888, Acc=0.192, 
2025-10-14 19:22:38,318 - training.trainer - INFO - Epoch 15, Step 51244: Loss=6.0540, Acc=0.182, 
2025-10-14 19:22:46,324 - training.trainer - INFO - Epoch 15, Step 51344: Loss=5.0758, Acc=0.179, 
2025-10-14 19:22:54,524 - training.trainer - INFO - Epoch 15, Step 51444: Loss=4.6221, Acc=0.393, 
2025-10-14 19:23:02,574 - training.trainer - INFO - Epoch 15, Step 51544: Loss=5.7488, Acc=0.136, 
2025-10-14 19:23:10,779 - training.trainer - INFO - Epoch 15, Step 51644: Loss=6.2263, Acc=0.152, 
2025-10-14 19:23:18,994 - training.trainer - INFO - Epoch 15, Step 51744: Loss=6.2518, Acc=0.159, 
2025-10-14 19:23:26,993 - training.trainer - INFO - Epoch 15, Step 51844: Loss=5.5621, Acc=0.246, 
2025-10-14 19:23:35,534 - training.trainer - INFO - Epoch 15, Step 51944: Loss=5.6792, Acc=0.250, 
2025-10-14 19:23:43,560 - training.trainer - INFO - Epoch 15, Step 52044: Loss=4.9269, Acc=0.400, 
2025-10-14 19:23:51,564 - training.trainer - INFO - Epoch 15, Step 52144: Loss=6.1299, Acc=0.183, 
2025-10-14 19:23:59,594 - training.trainer - INFO - Epoch 15, Step 52244: Loss=6.4546, Acc=0.161, 
2025-10-14 19:24:07,961 - training.trainer - INFO - Epoch 15, Step 52344: Loss=5.2762, Acc=0.364, 
2025-10-14 19:24:16,069 - training.trainer - INFO - Epoch 15, Step 52444: Loss=6.2029, Acc=0.200, 
2025-10-14 19:24:24,266 - training.trainer - INFO - Epoch 15, Step 52544: Loss=4.9067, Acc=0.286, 
2025-10-14 19:24:32,471 - training.trainer - INFO - Epoch 15, Step 52644: Loss=5.4424, Acc=0.167, 
2025-10-14 19:24:40,533 - training.trainer - INFO - Epoch 15, Step 52744: Loss=6.0691, Acc=0.196, 
2025-10-14 19:24:48,870 - training.trainer - INFO - Epoch 15, Step 52844: Loss=5.8986, Acc=0.203, 
2025-10-14 19:24:57,155 - training.trainer - INFO - Epoch 15, Step 52944: Loss=6.0805, Acc=0.364, 
2025-10-14 19:25:05,233 - training.trainer - INFO - Epoch 15, Step 53044: Loss=4.6053, Acc=0.333, 
2025-10-14 19:25:13,295 - training.trainer - INFO - Epoch 15, Step 53144: Loss=4.8400, Acc=0.304, 
2025-10-14 19:25:21,478 - training.trainer - INFO - Epoch 15, Step 53244: Loss=6.1701, Acc=0.192, 
2025-10-14 19:25:29,515 - training.trainer - INFO - Epoch 15, Step 53344: Loss=5.8622, Acc=0.250, 
2025-10-14 19:25:37,876 - training.trainer - INFO - Epoch 15, Step 53444: Loss=5.7473, Acc=0.224, 
2025-10-14 19:25:46,100 - training.trainer - INFO - Epoch 15, Step 53544: Loss=5.8149, Acc=0.250, 
2025-10-14 19:25:54,224 - training.trainer - INFO - Epoch 15, Step 53644: Loss=5.5900, Acc=0.158, 
2025-10-14 19:26:02,476 - training.trainer - INFO - Epoch 15, Step 53744: Loss=5.5453, Acc=0.238, 
2025-10-14 19:26:10,509 - training.trainer - INFO - Epoch 15, Step 53844: Loss=6.6837, Acc=0.190, 
2025-10-14 19:26:18,767 - training.trainer - INFO - Epoch 15, Step 53944: Loss=5.6134, Acc=0.286, 
2025-10-14 19:26:26,795 - training.trainer - INFO - Epoch 15, Step 54044: Loss=6.0055, Acc=0.149, 
2025-10-14 19:26:47,977 - training.trainer - INFO - Epoch 16/100 completed in 290.51s - Train Loss: 5.7304, Train Acc: 0.244, Val Loss: 5.8156, Val Acc: 0.244
2025-10-14 19:26:56,476 - training.trainer - INFO - Epoch 16, Step 54227: Loss=5.9992, Acc=0.213, 
2025-10-14 19:27:04,594 - training.trainer - INFO - Epoch 16, Step 54327: Loss=5.9941, Acc=0.271, 
2025-10-14 19:27:13,176 - training.trainer - INFO - Epoch 16, Step 54427: Loss=6.0168, Acc=0.232, 
2025-10-14 19:27:21,338 - training.trainer - INFO - Epoch 16, Step 54527: Loss=6.1248, Acc=0.205, 
2025-10-14 19:27:29,418 - training.trainer - INFO - Epoch 16, Step 54627: Loss=5.8420, Acc=0.286, 
2025-10-14 19:27:37,260 - training.trainer - INFO - Epoch 16, Step 54727: Loss=6.1028, Acc=0.208, 
2025-10-14 19:27:45,211 - training.trainer - INFO - Epoch 16, Step 54827: Loss=6.0548, Acc=0.125, 
2025-10-14 19:27:53,258 - training.trainer - INFO - Epoch 16, Step 54927: Loss=4.2974, Acc=0.367, 
2025-10-14 19:28:01,168 - training.trainer - INFO - Epoch 16, Step 55027: Loss=5.3185, Acc=0.267, 
2025-10-14 19:28:09,187 - training.trainer - INFO - Epoch 16, Step 55127: Loss=5.3370, Acc=0.273, 
2025-10-14 19:28:17,339 - training.trainer - INFO - Epoch 16, Step 55227: Loss=4.7679, Acc=0.429, 
2025-10-14 19:28:25,598 - training.trainer - INFO - Epoch 16, Step 55327: Loss=4.8816, Acc=0.344, 
2025-10-14 19:28:33,842 - training.trainer - INFO - Epoch 16, Step 55427: Loss=5.8355, Acc=0.158, 
2025-10-14 19:28:42,391 - training.trainer - INFO - Epoch 16, Step 55527: Loss=5.4700, Acc=0.209, 
2025-10-14 19:28:50,443 - training.trainer - INFO - Epoch 16, Step 55627: Loss=5.9801, Acc=0.279, 
2025-10-14 19:28:58,614 - training.trainer - INFO - Epoch 16, Step 55727: Loss=5.9214, Acc=0.120, 
2025-10-14 19:29:06,747 - training.trainer - INFO - Epoch 16, Step 55827: Loss=5.6646, Acc=0.182, 
2025-10-14 19:29:14,682 - training.trainer - INFO - Epoch 16, Step 55927: Loss=3.4807, Acc=0.542, 
2025-10-14 19:29:22,806 - training.trainer - INFO - Epoch 16, Step 56027: Loss=5.6372, Acc=0.184, 
2025-10-14 19:29:30,854 - training.trainer - INFO - Epoch 16, Step 56127: Loss=5.9100, Acc=0.286, 
2025-10-14 19:29:38,912 - training.trainer - INFO - Epoch 16, Step 56227: Loss=5.3608, Acc=0.323, 
2025-10-14 19:29:47,753 - training.trainer - INFO - Epoch 16, Step 56327: Loss=5.7583, Acc=0.192, 
2025-10-14 19:29:56,864 - training.trainer - INFO - Epoch 16, Step 56427: Loss=3.0486, Acc=0.692, 
2025-10-14 19:30:06,123 - training.trainer - INFO - Epoch 16, Step 56527: Loss=5.7238, Acc=0.351, 
2025-10-14 19:30:15,332 - training.trainer - INFO - Epoch 16, Step 56627: Loss=6.3451, Acc=0.215, 
2025-10-14 19:30:24,460 - training.trainer - INFO - Epoch 16, Step 56727: Loss=4.7363, Acc=0.308, 
2025-10-14 19:30:33,572 - training.trainer - INFO - Epoch 16, Step 56827: Loss=5.7508, Acc=0.278, 
2025-10-14 19:30:42,883 - training.trainer - INFO - Epoch 16, Step 56927: Loss=4.7501, Acc=0.310, 
2025-10-14 19:30:51,780 - training.trainer - INFO - Epoch 16, Step 57027: Loss=5.9523, Acc=0.177, 
2025-10-14 19:31:01,153 - training.trainer - INFO - Epoch 16, Step 57127: Loss=6.4004, Acc=0.208, 
2025-10-14 19:31:10,402 - training.trainer - INFO - Epoch 16, Step 57227: Loss=6.3578, Acc=0.200, 
2025-10-14 19:31:19,474 - training.trainer - INFO - Epoch 16, Step 57327: Loss=5.3881, Acc=0.231, 
2025-10-14 19:31:28,704 - training.trainer - INFO - Epoch 16, Step 57427: Loss=5.4194, Acc=0.320, 
2025-10-14 19:31:51,566 - training.trainer - INFO - Epoch 17/100 completed in 303.59s - Train Loss: 5.7166, Train Acc: 0.246, Val Loss: 5.8295, Val Acc: 0.248
2025-10-14 19:32:00,082 - training.trainer - INFO - Epoch 17, Step 57610: Loss=5.7022, Acc=0.242, 
2025-10-14 19:32:07,990 - training.trainer - INFO - Epoch 17, Step 57710: Loss=6.0706, Acc=0.222, 
2025-10-14 19:32:16,069 - training.trainer - INFO - Epoch 17, Step 57810: Loss=6.2907, Acc=0.240, 
2025-10-14 19:32:24,251 - training.trainer - INFO - Epoch 17, Step 57910: Loss=6.3211, Acc=0.250, 
2025-10-14 19:32:32,487 - training.trainer - INFO - Epoch 17, Step 58010: Loss=6.0320, Acc=0.244, 
2025-10-14 19:32:40,620 - training.trainer - INFO - Epoch 17, Step 58110: Loss=5.1479, Acc=0.296, 
2025-10-14 19:32:48,849 - training.trainer - INFO - Epoch 17, Step 58210: Loss=6.2549, Acc=0.219, 
2025-10-14 19:32:57,068 - training.trainer - INFO - Epoch 17, Step 58310: Loss=5.6971, Acc=0.233, 
2025-10-14 19:33:05,896 - training.trainer - INFO - Epoch 17, Step 58410: Loss=5.2094, Acc=0.324, 
2025-10-14 19:33:14,006 - training.trainer - INFO - Epoch 17, Step 58510: Loss=5.9615, Acc=0.268, 
2025-10-14 19:33:22,204 - training.trainer - INFO - Epoch 17, Step 58610: Loss=5.9310, Acc=0.227, 
2025-10-14 19:33:30,417 - training.trainer - INFO - Epoch 17, Step 58710: Loss=5.7647, Acc=0.297, 
2025-10-14 19:33:38,532 - training.trainer - INFO - Epoch 17, Step 58810: Loss=5.0122, Acc=0.278, 
2025-10-14 19:33:46,638 - training.trainer - INFO - Epoch 17, Step 58910: Loss=6.3304, Acc=0.267, 
2025-10-14 19:33:54,784 - training.trainer - INFO - Epoch 17, Step 59010: Loss=4.8569, Acc=0.353, 
2025-10-14 19:34:02,879 - training.trainer - INFO - Epoch 17, Step 59110: Loss=4.9177, Acc=0.480, 
2025-10-14 19:34:11,039 - training.trainer - INFO - Epoch 17, Step 59210: Loss=4.8637, Acc=0.444, 
2025-10-14 19:34:19,143 - training.trainer - INFO - Epoch 17, Step 59310: Loss=6.1127, Acc=0.226, 
2025-10-14 19:34:27,420 - training.trainer - INFO - Epoch 17, Step 59410: Loss=5.5814, Acc=0.346, 
2025-10-14 19:34:35,567 - training.trainer - INFO - Epoch 17, Step 59510: Loss=5.8215, Acc=0.194, 
2025-10-14 19:34:43,530 - training.trainer - INFO - Epoch 17, Step 59610: Loss=6.0929, Acc=0.281, 
2025-10-14 19:34:51,602 - training.trainer - INFO - Epoch 17, Step 59710: Loss=6.2930, Acc=0.182, 
2025-10-14 19:34:59,905 - training.trainer - INFO - Epoch 17, Step 59810: Loss=5.6832, Acc=0.226, 
2025-10-14 19:35:08,256 - training.trainer - INFO - Epoch 17, Step 59910: Loss=6.5100, Acc=0.174, 
2025-10-14 19:35:16,992 - training.trainer - INFO - Epoch 17, Step 60010: Loss=6.0824, Acc=0.163, 
2025-10-14 19:35:25,710 - training.trainer - INFO - Epoch 17, Step 60110: Loss=4.7800, Acc=0.339, 
2025-10-14 19:35:33,743 - training.trainer - INFO - Epoch 17, Step 60210: Loss=6.0564, Acc=0.175, 
2025-10-14 19:35:42,254 - training.trainer - INFO - Epoch 17, Step 60310: Loss=5.5987, Acc=0.175, 
2025-10-14 19:35:50,460 - training.trainer - INFO - Epoch 17, Step 60410: Loss=3.6400, Acc=0.529, 
2025-10-14 19:35:58,738 - training.trainer - INFO - Epoch 17, Step 60510: Loss=4.4382, Acc=0.400, 
2025-10-14 19:36:07,109 - training.trainer - INFO - Epoch 17, Step 60610: Loss=5.1259, Acc=0.300, 
2025-10-14 19:36:15,242 - training.trainer - INFO - Epoch 17, Step 60710: Loss=5.5022, Acc=0.281, 
2025-10-14 19:36:23,289 - training.trainer - INFO - Epoch 17, Step 60810: Loss=5.9626, Acc=0.333, 
2025-10-14 19:36:43,014 - training.trainer - INFO - Epoch 18/100 completed in 291.45s - Train Loss: 5.6960, Train Acc: 0.249, Val Loss: 5.7853, Val Acc: 0.248
2025-10-14 19:36:43,823 - training.trainer - INFO - New best model saved with validation loss: 5.7853
2025-10-14 19:36:43,823 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_18.pt
2025-10-14 19:36:52,395 - training.trainer - INFO - Epoch 18, Step 60993: Loss=4.9610, Acc=0.353, 
2025-10-14 19:37:00,500 - training.trainer - INFO - Epoch 18, Step 61093: Loss=5.6663, Acc=0.250, 
2025-10-14 19:37:08,428 - training.trainer - INFO - Epoch 18, Step 61193: Loss=5.9458, Acc=0.111, 
2025-10-14 19:37:16,440 - training.trainer - INFO - Epoch 18, Step 61293: Loss=5.9142, Acc=0.212, 
2025-10-14 19:37:24,276 - training.trainer - INFO - Epoch 18, Step 61393: Loss=5.8384, Acc=0.186, 
2025-10-14 19:37:32,256 - training.trainer - INFO - Epoch 18, Step 61493: Loss=4.9295, Acc=0.310, 
2025-10-14 19:37:40,257 - training.trainer - INFO - Epoch 18, Step 61593: Loss=5.8636, Acc=0.186, 
2025-10-14 19:37:48,570 - training.trainer - INFO - Epoch 18, Step 61693: Loss=4.4263, Acc=0.381, 
2025-10-14 19:37:56,607 - training.trainer - INFO - Epoch 18, Step 61793: Loss=5.5655, Acc=0.241, 
2025-10-14 19:38:04,630 - training.trainer - INFO - Epoch 18, Step 61893: Loss=5.9532, Acc=0.235, 
2025-10-14 19:38:12,867 - training.trainer - INFO - Epoch 18, Step 61993: Loss=6.2254, Acc=0.206, 
2025-10-14 19:38:21,861 - training.trainer - INFO - Epoch 18, Step 62093: Loss=4.4888, Acc=0.250, 
2025-10-14 19:38:31,118 - training.trainer - INFO - Epoch 18, Step 62193: Loss=5.1482, Acc=0.321, 
2025-10-14 19:38:39,714 - training.trainer - INFO - Epoch 18, Step 62293: Loss=6.6092, Acc=0.209, 
2025-10-14 19:38:47,898 - training.trainer - INFO - Epoch 18, Step 62393: Loss=5.7815, Acc=0.321, 
2025-10-14 19:38:56,074 - training.trainer - INFO - Epoch 18, Step 62493: Loss=6.5792, Acc=0.121, 
2025-10-14 19:39:04,237 - training.trainer - INFO - Epoch 18, Step 62593: Loss=6.1365, Acc=0.115, 
2025-10-14 19:39:12,499 - training.trainer - INFO - Epoch 18, Step 62693: Loss=4.7674, Acc=0.381, 
2025-10-14 19:39:20,713 - training.trainer - INFO - Epoch 18, Step 62793: Loss=5.8961, Acc=0.240, 
2025-10-14 19:39:29,016 - training.trainer - INFO - Epoch 18, Step 62893: Loss=4.8835, Acc=0.265, 
2025-10-14 19:39:37,172 - training.trainer - INFO - Epoch 18, Step 62993: Loss=5.9921, Acc=0.205, 
2025-10-14 19:39:45,373 - training.trainer - INFO - Epoch 18, Step 63093: Loss=6.4507, Acc=0.308, 
2025-10-14 19:39:53,678 - training.trainer - INFO - Epoch 18, Step 63193: Loss=5.0691, Acc=0.393, 
2025-10-14 19:40:02,010 - training.trainer - INFO - Epoch 18, Step 63293: Loss=5.6988, Acc=0.238, 
2025-10-14 19:40:10,328 - training.trainer - INFO - Epoch 18, Step 63393: Loss=6.1733, Acc=0.231, 
2025-10-14 19:40:19,223 - training.trainer - INFO - Epoch 18, Step 63493: Loss=5.9108, Acc=0.226, 
2025-10-14 19:40:27,969 - training.trainer - INFO - Epoch 18, Step 63593: Loss=5.4775, Acc=0.297, 
2025-10-14 19:40:36,461 - training.trainer - INFO - Epoch 18, Step 63693: Loss=6.2343, Acc=0.280, 
2025-10-14 19:40:44,646 - training.trainer - INFO - Epoch 18, Step 63793: Loss=6.0088, Acc=0.212, 
2025-10-14 19:40:52,976 - training.trainer - INFO - Epoch 18, Step 63893: Loss=5.2575, Acc=0.302, 
2025-10-14 19:41:01,168 - training.trainer - INFO - Epoch 18, Step 63993: Loss=6.5238, Acc=0.134, 
2025-10-14 19:41:09,608 - training.trainer - INFO - Epoch 18, Step 64093: Loss=5.8662, Acc=0.220, 
2025-10-14 19:41:17,938 - training.trainer - INFO - Epoch 18, Step 64193: Loss=5.8059, Acc=0.241, 
2025-10-14 19:41:39,786 - training.trainer - INFO - Epoch 19/100 completed in 295.96s - Train Loss: 5.6719, Train Acc: 0.253, Val Loss: 5.8005, Val Acc: 0.245
2025-10-14 19:41:48,176 - training.trainer - INFO - Epoch 19, Step 64376: Loss=6.3175, Acc=0.184, 
2025-10-14 19:41:56,481 - training.trainer - INFO - Epoch 19, Step 64476: Loss=5.5998, Acc=0.292, 
2025-10-14 19:42:04,755 - training.trainer - INFO - Epoch 19, Step 64576: Loss=6.2843, Acc=0.217, 
2025-10-14 19:42:13,197 - training.trainer - INFO - Epoch 19, Step 64676: Loss=5.6295, Acc=0.167, 
2025-10-14 19:42:21,283 - training.trainer - INFO - Epoch 19, Step 64776: Loss=3.9019, Acc=0.455, 
2025-10-14 19:42:29,651 - training.trainer - INFO - Epoch 19, Step 64876: Loss=6.0002, Acc=0.212, 
2025-10-14 19:42:38,015 - training.trainer - INFO - Epoch 19, Step 64976: Loss=6.6509, Acc=0.158, 
2025-10-14 19:42:46,430 - training.trainer - INFO - Epoch 19, Step 65076: Loss=6.4859, Acc=0.141, 
2025-10-14 19:42:54,840 - training.trainer - INFO - Epoch 19, Step 65176: Loss=5.7312, Acc=0.148, 
2025-10-14 19:43:03,043 - training.trainer - INFO - Epoch 19, Step 65276: Loss=5.8325, Acc=0.256, 
2025-10-14 19:43:11,201 - training.trainer - INFO - Epoch 19, Step 65376: Loss=5.2509, Acc=0.295, 
2025-10-14 19:43:19,615 - training.trainer - INFO - Epoch 19, Step 65476: Loss=5.9333, Acc=0.350, 
2025-10-14 19:43:28,056 - training.trainer - INFO - Epoch 19, Step 65576: Loss=5.0465, Acc=0.318, 
2025-10-14 19:43:36,265 - training.trainer - INFO - Epoch 19, Step 65676: Loss=4.9875, Acc=0.280, 
2025-10-14 19:43:44,583 - training.trainer - INFO - Epoch 19, Step 65776: Loss=4.3472, Acc=0.490, 
2025-10-14 19:43:52,909 - training.trainer - INFO - Epoch 19, Step 65876: Loss=5.8158, Acc=0.192, 
2025-10-14 19:44:01,205 - training.trainer - INFO - Epoch 19, Step 65976: Loss=5.0437, Acc=0.448, 
2025-10-14 19:44:09,515 - training.trainer - INFO - Epoch 19, Step 66076: Loss=5.8756, Acc=0.280, 
2025-10-14 19:44:17,852 - training.trainer - INFO - Epoch 19, Step 66176: Loss=6.0322, Acc=0.268, 
2025-10-14 19:44:26,352 - training.trainer - INFO - Epoch 19, Step 66276: Loss=6.4905, Acc=0.214, 
2025-10-14 19:44:35,749 - training.trainer - INFO - Epoch 19, Step 66376: Loss=5.4446, Acc=0.290, 
2025-10-14 19:44:45,029 - training.trainer - INFO - Epoch 19, Step 66476: Loss=5.9648, Acc=0.222, 
2025-10-14 19:44:53,581 - training.trainer - INFO - Epoch 19, Step 66576: Loss=6.0805, Acc=0.333, 
2025-10-14 19:45:01,880 - training.trainer - INFO - Epoch 19, Step 66676: Loss=5.3424, Acc=0.286, 
2025-10-14 19:45:10,042 - training.trainer - INFO - Epoch 19, Step 66776: Loss=6.5305, Acc=0.125, 
2025-10-14 19:45:18,088 - training.trainer - INFO - Epoch 19, Step 66876: Loss=4.9052, Acc=0.367, 
2025-10-14 19:45:26,446 - training.trainer - INFO - Epoch 19, Step 66976: Loss=5.1940, Acc=0.370, 
2025-10-14 19:45:34,586 - training.trainer - INFO - Epoch 19, Step 67076: Loss=6.0189, Acc=0.281, 
2025-10-14 19:45:42,663 - training.trainer - INFO - Epoch 19, Step 67176: Loss=5.8552, Acc=0.214, 
2025-10-14 19:45:50,980 - training.trainer - INFO - Epoch 19, Step 67276: Loss=6.1394, Acc=0.175, 
2025-10-14 19:45:59,508 - training.trainer - INFO - Epoch 19, Step 67376: Loss=5.8470, Acc=0.294, 
2025-10-14 19:46:07,826 - training.trainer - INFO - Epoch 19, Step 67476: Loss=5.3088, Acc=0.320, 
2025-10-14 19:46:15,958 - training.trainer - INFO - Epoch 19, Step 67576: Loss=6.1391, Acc=0.226, 
2025-10-14 19:46:37,722 - training.trainer - INFO - Epoch 20/100 completed in 297.93s - Train Loss: 5.6560, Train Acc: 0.256, Val Loss: 5.8206, Val Acc: 0.249
2025-10-14 19:46:38,118 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_20.pt
2025-10-14 19:46:47,821 - training.trainer - INFO - Epoch 20, Step 67759: Loss=5.3377, Acc=0.250, 
2025-10-14 19:46:57,087 - training.trainer - INFO - Epoch 20, Step 67859: Loss=4.6483, Acc=0.346, 
2025-10-14 19:47:05,795 - training.trainer - INFO - Epoch 20, Step 67959: Loss=5.3924, Acc=0.268, 
2025-10-14 19:47:14,041 - training.trainer - INFO - Epoch 20, Step 68059: Loss=5.6396, Acc=0.236, 
2025-10-14 19:47:22,140 - training.trainer - INFO - Epoch 20, Step 68159: Loss=5.8023, Acc=0.225, 
2025-10-14 19:47:30,263 - training.trainer - INFO - Epoch 20, Step 68259: Loss=5.8616, Acc=0.204, 
2025-10-14 19:47:38,602 - training.trainer - INFO - Epoch 20, Step 68359: Loss=5.7253, Acc=0.316, 
2025-10-14 19:47:46,717 - training.trainer - INFO - Epoch 20, Step 68459: Loss=5.2906, Acc=0.342, 
2025-10-14 19:47:55,079 - training.trainer - INFO - Epoch 20, Step 68559: Loss=6.2221, Acc=0.183, 
2025-10-14 19:48:03,529 - training.trainer - INFO - Epoch 20, Step 68659: Loss=4.6744, Acc=0.348, 
2025-10-14 19:48:11,707 - training.trainer - INFO - Epoch 20, Step 68759: Loss=5.2486, Acc=0.306, 
2025-10-14 19:48:19,982 - training.trainer - INFO - Epoch 20, Step 68859: Loss=5.8883, Acc=0.250, 
2025-10-14 19:48:28,175 - training.trainer - INFO - Epoch 20, Step 68959: Loss=5.0659, Acc=0.343, 
2025-10-14 19:48:36,326 - training.trainer - INFO - Epoch 20, Step 69059: Loss=5.2222, Acc=0.225, 
2025-10-14 19:48:44,922 - training.trainer - INFO - Epoch 20, Step 69159: Loss=5.7797, Acc=0.316, 
2025-10-14 19:48:52,926 - training.trainer - INFO - Epoch 20, Step 69259: Loss=6.5484, Acc=0.182, 
2025-10-14 19:49:01,018 - training.trainer - INFO - Epoch 20, Step 69359: Loss=5.7657, Acc=0.286, 
2025-10-14 19:49:09,331 - training.trainer - INFO - Epoch 20, Step 69459: Loss=5.8037, Acc=0.210, 
2025-10-14 19:49:17,408 - training.trainer - INFO - Epoch 20, Step 69559: Loss=5.7429, Acc=0.214, 
2025-10-14 19:49:25,699 - training.trainer - INFO - Epoch 20, Step 69659: Loss=5.3567, Acc=0.357, 
2025-10-14 19:49:33,778 - training.trainer - INFO - Epoch 20, Step 69759: Loss=5.7217, Acc=0.175, 
2025-10-14 19:49:41,887 - training.trainer - INFO - Epoch 20, Step 69859: Loss=5.7931, Acc=0.172, 
2025-10-14 19:49:50,156 - training.trainer - INFO - Epoch 20, Step 69959: Loss=5.4089, Acc=0.276, 
2025-10-14 19:49:58,352 - training.trainer - INFO - Epoch 20, Step 70059: Loss=5.7411, Acc=0.222, 
2025-10-14 19:50:06,647 - training.trainer - INFO - Epoch 20, Step 70159: Loss=3.6581, Acc=0.609, 
2025-10-14 19:50:15,763 - training.trainer - INFO - Epoch 20, Step 70259: Loss=4.9376, Acc=0.324, 
2025-10-14 19:50:24,572 - training.trainer - INFO - Epoch 20, Step 70359: Loss=5.6624, Acc=0.304, 
2025-10-14 19:50:32,784 - training.trainer - INFO - Epoch 20, Step 70459: Loss=4.8020, Acc=0.320, 
2025-10-14 19:50:41,090 - training.trainer - INFO - Epoch 20, Step 70559: Loss=6.3476, Acc=0.213, 
2025-10-14 19:50:49,372 - training.trainer - INFO - Epoch 20, Step 70659: Loss=5.6027, Acc=0.400, 
2025-10-14 19:50:57,530 - training.trainer - INFO - Epoch 20, Step 70759: Loss=5.6531, Acc=0.195, 
2025-10-14 19:51:05,712 - training.trainer - INFO - Epoch 20, Step 70859: Loss=6.1714, Acc=0.196, 
2025-10-14 19:51:13,814 - training.trainer - INFO - Epoch 20, Step 70959: Loss=4.7552, Acc=0.400, 
2025-10-14 19:51:35,449 - training.trainer - INFO - Epoch 21/100 completed in 297.33s - Train Loss: 5.6381, Train Acc: 0.257, Val Loss: 5.8492, Val Acc: 0.251
2025-10-14 19:51:43,726 - training.trainer - INFO - Epoch 21, Step 71142: Loss=5.4823, Acc=0.304, 
2025-10-14 19:51:51,960 - training.trainer - INFO - Epoch 21, Step 71242: Loss=6.4003, Acc=0.196, 
2025-10-14 19:52:00,495 - training.trainer - INFO - Epoch 21, Step 71342: Loss=5.8305, Acc=0.288, 
2025-10-14 19:52:08,588 - training.trainer - INFO - Epoch 21, Step 71442: Loss=5.6258, Acc=0.268, 
2025-10-14 19:52:16,742 - training.trainer - INFO - Epoch 21, Step 71542: Loss=4.9254, Acc=0.310, 
2025-10-14 19:52:24,965 - training.trainer - INFO - Epoch 21, Step 71642: Loss=5.4771, Acc=0.271, 
2025-10-14 19:52:33,188 - training.trainer - INFO - Epoch 21, Step 71742: Loss=5.9452, Acc=0.184, 
2025-10-14 19:52:41,196 - training.trainer - INFO - Epoch 21, Step 71842: Loss=4.7469, Acc=0.385, 
2025-10-14 19:52:49,558 - training.trainer - INFO - Epoch 21, Step 71942: Loss=5.5388, Acc=0.333, 
2025-10-14 19:52:57,503 - training.trainer - INFO - Epoch 21, Step 72042: Loss=5.6921, Acc=0.213, 
2025-10-14 19:53:05,309 - training.trainer - INFO - Epoch 21, Step 72142: Loss=5.5257, Acc=0.300, 
2025-10-14 19:53:13,451 - training.trainer - INFO - Epoch 21, Step 72242: Loss=5.5399, Acc=0.169, 
2025-10-14 19:53:21,521 - training.trainer - INFO - Epoch 21, Step 72342: Loss=5.1704, Acc=0.345, 
2025-10-14 19:53:29,669 - training.trainer - INFO - Epoch 21, Step 72442: Loss=5.4460, Acc=0.185, 
2025-10-14 19:53:37,736 - training.trainer - INFO - Epoch 21, Step 72542: Loss=5.9014, Acc=0.273, 
2025-10-14 19:53:45,889 - training.trainer - INFO - Epoch 21, Step 72642: Loss=4.2237, Acc=0.393, 
2025-10-14 19:53:54,059 - training.trainer - INFO - Epoch 21, Step 72742: Loss=6.5969, Acc=0.135, 
2025-10-14 19:54:02,216 - training.trainer - INFO - Epoch 21, Step 72842: Loss=5.5005, Acc=0.276, 
2025-10-14 19:54:10,340 - training.trainer - INFO - Epoch 21, Step 72942: Loss=5.8171, Acc=0.245, 
2025-10-14 19:54:18,564 - training.trainer - INFO - Epoch 21, Step 73042: Loss=5.2175, Acc=0.250, 
2025-10-14 19:54:26,777 - training.trainer - INFO - Epoch 21, Step 73142: Loss=5.7659, Acc=0.250, 
2025-10-14 19:54:35,044 - training.trainer - INFO - Epoch 21, Step 73242: Loss=5.8084, Acc=0.271, 
2025-10-14 19:54:43,077 - training.trainer - INFO - Epoch 21, Step 73342: Loss=5.6991, Acc=0.333, 
2025-10-14 19:54:51,081 - training.trainer - INFO - Epoch 21, Step 73442: Loss=5.2325, Acc=0.237, 
2025-10-14 19:54:59,406 - training.trainer - INFO - Epoch 21, Step 73542: Loss=5.7729, Acc=0.203, 
2025-10-14 19:55:07,756 - training.trainer - INFO - Epoch 21, Step 73642: Loss=5.3083, Acc=0.333, 
2025-10-14 19:55:15,765 - training.trainer - INFO - Epoch 21, Step 73742: Loss=5.3725, Acc=0.222, 
2025-10-14 19:55:23,342 - training.trainer - INFO - Epoch 21, Step 73842: Loss=5.0612, Acc=0.316, 
2025-10-14 19:55:31,130 - training.trainer - INFO - Epoch 21, Step 73942: Loss=6.1483, Acc=0.195, 
2025-10-14 19:55:38,705 - training.trainer - INFO - Epoch 21, Step 74042: Loss=5.2379, Acc=0.217, 
2025-10-14 19:55:46,320 - training.trainer - INFO - Epoch 21, Step 74142: Loss=4.7357, Acc=0.294, 
2025-10-14 19:55:53,838 - training.trainer - INFO - Epoch 21, Step 74242: Loss=6.4300, Acc=0.143, 
2025-10-14 19:56:01,604 - training.trainer - INFO - Epoch 21, Step 74342: Loss=3.4029, Acc=0.520, 
2025-10-14 19:56:21,056 - training.trainer - INFO - Epoch 22/100 completed in 285.61s - Train Loss: 5.6212, Train Acc: 0.260, Val Loss: 5.8115, Val Acc: 0.254
2025-10-14 19:56:29,087 - training.trainer - INFO - Epoch 22, Step 74525: Loss=5.8435, Acc=0.282, 
2025-10-14 19:56:37,120 - training.trainer - INFO - Epoch 22, Step 74625: Loss=5.9551, Acc=0.211, 
2025-10-14 19:56:45,125 - training.trainer - INFO - Epoch 22, Step 74725: Loss=3.8698, Acc=0.500, 
2025-10-14 19:56:53,249 - training.trainer - INFO - Epoch 22, Step 74825: Loss=5.7205, Acc=0.244, 
2025-10-14 19:57:01,134 - training.trainer - INFO - Epoch 22, Step 74925: Loss=6.0159, Acc=0.195, 
2025-10-14 19:57:09,130 - training.trainer - INFO - Epoch 22, Step 75025: Loss=5.7683, Acc=0.151, 
2025-10-14 19:57:17,120 - training.trainer - INFO - Epoch 22, Step 75125: Loss=4.6250, Acc=0.241, 
2025-10-14 19:57:25,035 - training.trainer - INFO - Epoch 22, Step 75225: Loss=5.6187, Acc=0.302, 
2025-10-14 19:57:33,092 - training.trainer - INFO - Epoch 22, Step 75325: Loss=5.6282, Acc=0.217, 
2025-10-14 19:57:40,865 - training.trainer - INFO - Epoch 22, Step 75425: Loss=6.0445, Acc=0.233, 
2025-10-14 19:57:48,936 - training.trainer - INFO - Epoch 22, Step 75525: Loss=5.4943, Acc=0.235, 
2025-10-14 19:57:56,959 - training.trainer - INFO - Epoch 22, Step 75625: Loss=5.6593, Acc=0.179, 
2025-10-14 19:58:05,041 - training.trainer - INFO - Epoch 22, Step 75725: Loss=5.1853, Acc=0.348, 
2025-10-14 19:58:12,901 - training.trainer - INFO - Epoch 22, Step 75825: Loss=5.7745, Acc=0.227, 
2025-10-14 19:58:20,975 - training.trainer - INFO - Epoch 22, Step 75925: Loss=6.0759, Acc=0.146, 
2025-10-14 19:58:28,868 - training.trainer - INFO - Epoch 22, Step 76025: Loss=6.2927, Acc=0.231, 
2025-10-14 19:58:36,749 - training.trainer - INFO - Epoch 22, Step 76125: Loss=5.2224, Acc=0.286, 
2025-10-14 19:58:44,779 - training.trainer - INFO - Epoch 22, Step 76225: Loss=6.1336, Acc=0.219, 
2025-10-14 19:58:52,682 - training.trainer - INFO - Epoch 22, Step 76325: Loss=6.7341, Acc=0.121, 
2025-10-14 19:59:00,751 - training.trainer - INFO - Epoch 22, Step 76425: Loss=5.2372, Acc=0.265, 
2025-10-14 19:59:08,992 - training.trainer - INFO - Epoch 22, Step 76525: Loss=6.0268, Acc=0.200, 
2025-10-14 19:59:16,955 - training.trainer - INFO - Epoch 22, Step 76625: Loss=5.8523, Acc=0.194, 
2025-10-14 19:59:25,025 - training.trainer - INFO - Epoch 22, Step 76725: Loss=5.7940, Acc=0.269, 
2025-10-14 19:59:32,964 - training.trainer - INFO - Epoch 22, Step 76825: Loss=5.1814, Acc=0.235, 
2025-10-14 19:59:41,070 - training.trainer - INFO - Epoch 22, Step 76925: Loss=5.7975, Acc=0.237, 
2025-10-14 19:59:49,624 - training.trainer - INFO - Epoch 22, Step 77025: Loss=5.3204, Acc=0.300, 
2025-10-14 19:59:58,065 - training.trainer - INFO - Epoch 22, Step 77125: Loss=4.6113, Acc=0.400, 
2025-10-14 20:00:06,533 - training.trainer - INFO - Epoch 22, Step 77225: Loss=6.2698, Acc=0.189, 
2025-10-14 20:00:15,154 - training.trainer - INFO - Epoch 22, Step 77325: Loss=5.3707, Acc=0.320, 
2025-10-14 20:00:23,702 - training.trainer - INFO - Epoch 22, Step 77425: Loss=5.8879, Acc=0.273, 
2025-10-14 20:00:32,348 - training.trainer - INFO - Epoch 22, Step 77525: Loss=6.4456, Acc=0.174, 
2025-10-14 20:00:40,814 - training.trainer - INFO - Epoch 22, Step 77625: Loss=6.1641, Acc=0.150, 
2025-10-14 20:00:49,493 - training.trainer - INFO - Epoch 22, Step 77725: Loss=6.1649, Acc=0.255, 
2025-10-14 20:01:13,889 - training.trainer - INFO - Epoch 23/100 completed in 292.83s - Train Loss: 5.6026, Train Acc: 0.263, Val Loss: 5.8060, Val Acc: 0.253
2025-10-14 20:01:23,155 - training.trainer - INFO - Epoch 23, Step 77908: Loss=5.8867, Acc=0.213, 
2025-10-14 20:01:31,754 - training.trainer - INFO - Epoch 23, Step 78008: Loss=3.7005, Acc=0.472, 
2025-10-14 20:01:40,321 - training.trainer - INFO - Epoch 23, Step 78108: Loss=6.3810, Acc=0.212, 
2025-10-14 20:01:48,733 - training.trainer - INFO - Epoch 23, Step 78208: Loss=6.0205, Acc=0.241, 
2025-10-14 20:01:57,335 - training.trainer - INFO - Epoch 23, Step 78308: Loss=5.7885, Acc=0.227, 
2025-10-14 20:02:06,002 - training.trainer - INFO - Epoch 23, Step 78408: Loss=5.6824, Acc=0.333, 
2025-10-14 20:02:14,716 - training.trainer - INFO - Epoch 23, Step 78508: Loss=5.9820, Acc=0.250, 
2025-10-14 20:02:23,342 - training.trainer - INFO - Epoch 23, Step 78608: Loss=6.8399, Acc=0.111, 
2025-10-14 20:02:31,807 - training.trainer - INFO - Epoch 23, Step 78708: Loss=5.4494, Acc=0.250, 
2025-10-14 20:02:40,483 - training.trainer - INFO - Epoch 23, Step 78808: Loss=6.6634, Acc=0.104, 
2025-10-14 20:02:49,098 - training.trainer - INFO - Epoch 23, Step 78908: Loss=5.7781, Acc=0.200, 
2025-10-14 20:02:57,713 - training.trainer - INFO - Epoch 23, Step 79008: Loss=5.6268, Acc=0.240, 
2025-10-14 20:03:06,257 - training.trainer - INFO - Epoch 23, Step 79108: Loss=5.0264, Acc=0.294, 
2025-10-14 20:03:14,745 - training.trainer - INFO - Epoch 23, Step 79208: Loss=5.7139, Acc=0.231, 
2025-10-14 20:03:23,213 - training.trainer - INFO - Epoch 23, Step 79308: Loss=5.3411, Acc=0.333, 
2025-10-14 20:03:31,672 - training.trainer - INFO - Epoch 23, Step 79408: Loss=4.7393, Acc=0.381, 
2025-10-14 20:03:40,220 - training.trainer - INFO - Epoch 23, Step 79508: Loss=5.9398, Acc=0.250, 
2025-10-14 20:03:48,587 - training.trainer - INFO - Epoch 23, Step 79608: Loss=6.9030, Acc=0.152, 
2025-10-14 20:03:57,285 - training.trainer - INFO - Epoch 23, Step 79708: Loss=6.2976, Acc=0.304, 
2025-10-14 20:04:05,683 - training.trainer - INFO - Epoch 23, Step 79808: Loss=6.1424, Acc=0.200, 
2025-10-14 20:04:14,091 - training.trainer - INFO - Epoch 23, Step 79908: Loss=5.5825, Acc=0.262, 
2025-10-14 20:04:22,494 - training.trainer - INFO - Epoch 23, Step 80008: Loss=6.0622, Acc=0.250, 
2025-10-14 20:04:31,214 - training.trainer - INFO - Epoch 23, Step 80108: Loss=6.2957, Acc=0.205, 
2025-10-14 20:04:39,814 - training.trainer - INFO - Epoch 23, Step 80208: Loss=4.3216, Acc=0.462, 
2025-10-14 20:04:48,331 - training.trainer - INFO - Epoch 23, Step 80308: Loss=5.8832, Acc=0.214, 
2025-10-14 20:04:56,795 - training.trainer - INFO - Epoch 23, Step 80408: Loss=6.1817, Acc=0.217, 
2025-10-14 20:05:05,257 - training.trainer - INFO - Epoch 23, Step 80508: Loss=6.0115, Acc=0.204, 
2025-10-14 20:05:13,815 - training.trainer - INFO - Epoch 23, Step 80608: Loss=4.0256, Acc=0.500, 
2025-10-14 20:05:22,408 - training.trainer - INFO - Epoch 23, Step 80708: Loss=5.8081, Acc=0.145, 
2025-10-14 20:05:30,863 - training.trainer - INFO - Epoch 23, Step 80808: Loss=6.2460, Acc=0.231, 
2025-10-14 20:05:39,452 - training.trainer - INFO - Epoch 23, Step 80908: Loss=4.4638, Acc=0.381, 
2025-10-14 20:05:47,920 - training.trainer - INFO - Epoch 23, Step 81008: Loss=5.4757, Acc=0.297, 
2025-10-14 20:05:56,364 - training.trainer - INFO - Epoch 23, Step 81108: Loss=4.9606, Acc=0.292, 
2025-10-14 20:06:20,821 - training.trainer - INFO - Epoch 24/100 completed in 306.93s - Train Loss: 5.5829, Train Acc: 0.266, Val Loss: 5.8139, Val Acc: 0.255
2025-10-14 20:06:29,581 - training.trainer - INFO - Epoch 24, Step 81291: Loss=5.9837, Acc=0.221, 
2025-10-14 20:06:37,920 - training.trainer - INFO - Epoch 24, Step 81391: Loss=6.6825, Acc=0.227, 
2025-10-14 20:06:46,131 - training.trainer - INFO - Epoch 24, Step 81491: Loss=5.7807, Acc=0.190, 
2025-10-14 20:06:54,578 - training.trainer - INFO - Epoch 24, Step 81591: Loss=6.0870, Acc=0.222, 
2025-10-14 20:07:02,552 - training.trainer - INFO - Epoch 24, Step 81691: Loss=5.9309, Acc=0.306, 
2025-10-14 20:07:10,971 - training.trainer - INFO - Epoch 24, Step 81791: Loss=5.4183, Acc=0.286, 
2025-10-14 20:07:19,296 - training.trainer - INFO - Epoch 24, Step 81891: Loss=3.6630, Acc=0.500, 
2025-10-14 20:07:27,906 - training.trainer - INFO - Epoch 24, Step 81991: Loss=6.1619, Acc=0.206, 
2025-10-14 20:07:36,213 - training.trainer - INFO - Epoch 24, Step 82091: Loss=6.0623, Acc=0.225, 
2025-10-14 20:07:44,502 - training.trainer - INFO - Epoch 24, Step 82191: Loss=5.7617, Acc=0.130, 
2025-10-14 20:07:52,943 - training.trainer - INFO - Epoch 24, Step 82291: Loss=5.7570, Acc=0.212, 
2025-10-14 20:08:01,323 - training.trainer - INFO - Epoch 24, Step 82391: Loss=5.6557, Acc=0.258, 
2025-10-14 20:08:09,736 - training.trainer - INFO - Epoch 24, Step 82491: Loss=5.9093, Acc=0.222, 
2025-10-14 20:08:18,289 - training.trainer - INFO - Epoch 24, Step 82591: Loss=6.5619, Acc=0.200, 
2025-10-14 20:08:26,676 - training.trainer - INFO - Epoch 24, Step 82691: Loss=5.8652, Acc=0.289, 
2025-10-14 20:08:35,278 - training.trainer - INFO - Epoch 24, Step 82791: Loss=5.1534, Acc=0.267, 
2025-10-14 20:08:43,606 - training.trainer - INFO - Epoch 24, Step 82891: Loss=5.8856, Acc=0.261, 
2025-10-14 20:08:52,144 - training.trainer - INFO - Epoch 24, Step 82991: Loss=4.5789, Acc=0.474, 
2025-10-14 20:09:00,784 - training.trainer - INFO - Epoch 24, Step 83091: Loss=5.8103, Acc=0.200, 
2025-10-14 20:09:09,462 - training.trainer - INFO - Epoch 24, Step 83191: Loss=5.8948, Acc=0.279, 
2025-10-14 20:09:18,022 - training.trainer - INFO - Epoch 24, Step 83291: Loss=5.8026, Acc=0.200, 
2025-10-14 20:09:26,533 - training.trainer - INFO - Epoch 24, Step 83391: Loss=5.2790, Acc=0.284, 
2025-10-14 20:09:35,249 - training.trainer - INFO - Epoch 24, Step 83491: Loss=5.5758, Acc=0.300, 
2025-10-14 20:09:43,896 - training.trainer - INFO - Epoch 24, Step 83591: Loss=6.6397, Acc=0.125, 
2025-10-14 20:09:52,440 - training.trainer - INFO - Epoch 24, Step 83691: Loss=5.7329, Acc=0.320, 
2025-10-14 20:10:00,811 - training.trainer - INFO - Epoch 24, Step 83791: Loss=5.0328, Acc=0.346, 
2025-10-14 20:10:09,435 - training.trainer - INFO - Epoch 24, Step 83891: Loss=4.5679, Acc=0.231, 
2025-10-14 20:10:17,950 - training.trainer - INFO - Epoch 24, Step 83991: Loss=5.4829, Acc=0.340, 
2025-10-14 20:10:26,244 - training.trainer - INFO - Epoch 24, Step 84091: Loss=4.2362, Acc=0.556, 
2025-10-14 20:10:35,065 - training.trainer - INFO - Epoch 24, Step 84191: Loss=4.7520, Acc=0.417, 
2025-10-14 20:10:43,504 - training.trainer - INFO - Epoch 24, Step 84291: Loss=5.2990, Acc=0.391, 
2025-10-14 20:10:51,858 - training.trainer - INFO - Epoch 24, Step 84391: Loss=4.6562, Acc=0.385, 
2025-10-14 20:11:00,400 - training.trainer - INFO - Epoch 24, Step 84491: Loss=5.8572, Acc=0.241, 
2025-10-14 20:11:24,917 - training.trainer - INFO - Epoch 25/100 completed in 304.10s - Train Loss: 5.5718, Train Acc: 0.269, Val Loss: 5.7800, Val Acc: 0.254
2025-10-14 20:11:25,315 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-14 20:11:26,057 - training.trainer - INFO - New best model saved with validation loss: 5.7800
2025-10-14 20:11:26,057 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_25.pt
2025-10-14 20:11:35,055 - training.trainer - INFO - Epoch 25, Step 84674: Loss=4.8442, Acc=0.391, 
2025-10-14 20:11:43,528 - training.trainer - INFO - Epoch 25, Step 84774: Loss=5.9840, Acc=0.167, 
2025-10-14 20:11:52,004 - training.trainer - INFO - Epoch 25, Step 84874: Loss=5.7138, Acc=0.200, 
2025-10-14 20:12:00,630 - training.trainer - INFO - Epoch 25, Step 84974: Loss=5.5593, Acc=0.273, 
2025-10-14 20:12:09,325 - training.trainer - INFO - Epoch 25, Step 85074: Loss=5.4367, Acc=0.194, 
2025-10-14 20:12:17,725 - training.trainer - INFO - Epoch 25, Step 85174: Loss=4.5484, Acc=0.400, 
2025-10-14 20:12:26,455 - training.trainer - INFO - Epoch 25, Step 85274: Loss=5.4282, Acc=0.278, 
2025-10-14 20:12:34,981 - training.trainer - INFO - Epoch 25, Step 85374: Loss=4.9105, Acc=0.412, 
2025-10-14 20:12:43,687 - training.trainer - INFO - Epoch 25, Step 85474: Loss=3.7846, Acc=0.500, 
2025-10-14 20:12:52,387 - training.trainer - INFO - Epoch 25, Step 85574: Loss=5.6233, Acc=0.290, 
2025-10-14 20:13:01,079 - training.trainer - INFO - Epoch 25, Step 85674: Loss=6.1506, Acc=0.194, 
2025-10-14 20:13:09,702 - training.trainer - INFO - Epoch 25, Step 85774: Loss=5.4120, Acc=0.289, 
2025-10-14 20:13:18,552 - training.trainer - INFO - Epoch 25, Step 85874: Loss=5.4531, Acc=0.289, 
2025-10-14 20:13:27,245 - training.trainer - INFO - Epoch 25, Step 85974: Loss=5.5880, Acc=0.283, 
2025-10-14 20:13:36,092 - training.trainer - INFO - Epoch 25, Step 86074: Loss=5.8011, Acc=0.213, 
2025-10-14 20:13:44,686 - training.trainer - INFO - Epoch 25, Step 86174: Loss=4.2187, Acc=0.500, 
2025-10-14 20:13:53,157 - training.trainer - INFO - Epoch 25, Step 86274: Loss=6.2127, Acc=0.267, 
2025-10-14 20:14:01,233 - training.trainer - INFO - Epoch 25, Step 86374: Loss=5.3228, Acc=0.216, 
2025-10-14 20:14:09,256 - training.trainer - INFO - Epoch 25, Step 86474: Loss=5.9917, Acc=0.235, 
2025-10-14 20:14:16,903 - training.trainer - INFO - Epoch 25, Step 86574: Loss=5.9456, Acc=0.308, 
2025-10-14 20:14:24,503 - training.trainer - INFO - Epoch 25, Step 86674: Loss=5.2582, Acc=0.268, 
2025-10-14 20:14:31,953 - training.trainer - INFO - Epoch 25, Step 86774: Loss=6.0093, Acc=0.275, 
2025-10-14 20:14:39,561 - training.trainer - INFO - Epoch 25, Step 86874: Loss=6.0062, Acc=0.222, 
2025-10-14 20:14:47,113 - training.trainer - INFO - Epoch 25, Step 86974: Loss=5.7359, Acc=0.176, 
2025-10-14 20:14:54,882 - training.trainer - INFO - Epoch 25, Step 87074: Loss=5.9432, Acc=0.345, 
2025-10-14 20:15:02,574 - training.trainer - INFO - Epoch 25, Step 87174: Loss=6.2551, Acc=0.186, 
2025-10-14 20:15:10,197 - training.trainer - INFO - Epoch 25, Step 87274: Loss=4.4668, Acc=0.368, 
2025-10-14 20:15:17,911 - training.trainer - INFO - Epoch 25, Step 87374: Loss=5.6939, Acc=0.314, 
2025-10-14 20:15:26,059 - training.trainer - INFO - Epoch 25, Step 87474: Loss=5.3814, Acc=0.289, 
2025-10-14 20:15:34,086 - training.trainer - INFO - Epoch 25, Step 87574: Loss=5.8913, Acc=0.276, 
2025-10-14 20:15:41,970 - training.trainer - INFO - Epoch 25, Step 87674: Loss=4.8909, Acc=0.462, 
2025-10-14 20:15:49,942 - training.trainer - INFO - Epoch 25, Step 87774: Loss=5.7480, Acc=0.250, 
2025-10-14 20:15:57,869 - training.trainer - INFO - Epoch 25, Step 87874: Loss=6.0875, Acc=0.234, 
2025-10-14 20:16:19,541 - training.trainer - INFO - Epoch 26/100 completed in 293.48s - Train Loss: 5.5519, Train Acc: 0.271, Val Loss: 5.8341, Val Acc: 0.254
2025-10-14 20:16:27,737 - training.trainer - INFO - Epoch 26, Step 88057: Loss=4.9627, Acc=0.250, 
2025-10-14 20:16:35,578 - training.trainer - INFO - Epoch 26, Step 88157: Loss=5.7828, Acc=0.320, 
2025-10-14 20:16:43,699 - training.trainer - INFO - Epoch 26, Step 88257: Loss=5.2634, Acc=0.353, 
2025-10-14 20:16:51,462 - training.trainer - INFO - Epoch 26, Step 88357: Loss=5.4203, Acc=0.236, 
2025-10-14 20:16:59,431 - training.trainer - INFO - Epoch 26, Step 88457: Loss=5.2384, Acc=0.364, 
2025-10-14 20:17:07,351 - training.trainer - INFO - Epoch 26, Step 88557: Loss=5.8286, Acc=0.182, 
2025-10-14 20:17:15,141 - training.trainer - INFO - Epoch 26, Step 88657: Loss=5.2847, Acc=0.276, 
2025-10-14 20:17:23,086 - training.trainer - INFO - Epoch 26, Step 88757: Loss=4.9835, Acc=0.375, 
2025-10-14 20:17:31,096 - training.trainer - INFO - Epoch 26, Step 88857: Loss=5.4047, Acc=0.314, 
2025-10-14 20:17:39,002 - training.trainer - INFO - Epoch 26, Step 88957: Loss=4.7000, Acc=0.333, 
2025-10-14 20:17:47,257 - training.trainer - INFO - Epoch 26, Step 89057: Loss=6.0604, Acc=0.329, 
2025-10-14 20:17:55,531 - training.trainer - INFO - Epoch 26, Step 89157: Loss=5.3234, Acc=0.327, 
2025-10-14 20:18:03,944 - training.trainer - INFO - Epoch 26, Step 89257: Loss=4.7649, Acc=0.379, 
2025-10-14 20:18:12,189 - training.trainer - INFO - Epoch 26, Step 89357: Loss=6.2826, Acc=0.154, 
2025-10-14 20:18:20,335 - training.trainer - INFO - Epoch 26, Step 89457: Loss=5.7448, Acc=0.229, 
2025-10-14 20:18:28,152 - training.trainer - INFO - Epoch 26, Step 89557: Loss=5.4219, Acc=0.234, 
2025-10-14 20:18:36,142 - training.trainer - INFO - Epoch 26, Step 89657: Loss=5.4297, Acc=0.227, 
2025-10-14 20:18:44,202 - training.trainer - INFO - Epoch 26, Step 89757: Loss=5.5067, Acc=0.227, 
2025-10-14 20:18:52,220 - training.trainer - INFO - Epoch 26, Step 89857: Loss=5.2340, Acc=0.255, 
2025-10-14 20:19:00,157 - training.trainer - INFO - Epoch 26, Step 89957: Loss=3.6478, Acc=0.500, 
2025-10-14 20:19:08,250 - training.trainer - INFO - Epoch 26, Step 90057: Loss=5.3266, Acc=0.333, 
2025-10-14 20:19:16,290 - training.trainer - INFO - Epoch 26, Step 90157: Loss=6.0602, Acc=0.256, 
2025-10-14 20:19:24,272 - training.trainer - INFO - Epoch 26, Step 90257: Loss=5.3477, Acc=0.327, 
2025-10-14 20:19:32,258 - training.trainer - INFO - Epoch 26, Step 90357: Loss=5.6874, Acc=0.195, 
2025-10-14 20:19:40,380 - training.trainer - INFO - Epoch 26, Step 90457: Loss=5.9457, Acc=0.163, 
2025-10-14 20:19:48,407 - training.trainer - INFO - Epoch 26, Step 90557: Loss=4.3278, Acc=0.338, 
2025-10-14 20:19:56,449 - training.trainer - INFO - Epoch 26, Step 90657: Loss=4.9803, Acc=0.280, 
2025-10-14 20:20:04,611 - training.trainer - INFO - Epoch 26, Step 90757: Loss=6.3334, Acc=0.188, 
2025-10-14 20:20:12,325 - training.trainer - INFO - Epoch 26, Step 90857: Loss=5.1565, Acc=0.143, 
2025-10-14 20:20:20,340 - training.trainer - INFO - Epoch 26, Step 90957: Loss=6.0981, Acc=0.194, 
2025-10-14 20:20:28,574 - training.trainer - INFO - Epoch 26, Step 91057: Loss=5.6048, Acc=0.333, 
2025-10-14 20:20:36,626 - training.trainer - INFO - Epoch 26, Step 91157: Loss=5.1792, Acc=0.273, 
2025-10-14 20:20:44,654 - training.trainer - INFO - Epoch 26, Step 91257: Loss=5.9299, Acc=0.257, 
2025-10-14 20:21:07,581 - training.trainer - INFO - Epoch 27/100 completed in 288.04s - Train Loss: 5.5449, Train Acc: 0.273, Val Loss: 5.8371, Val Acc: 0.258
2025-10-14 20:21:15,929 - training.trainer - INFO - Epoch 27, Step 91440: Loss=5.5624, Acc=0.228, 
2025-10-14 20:21:23,899 - training.trainer - INFO - Epoch 27, Step 91540: Loss=3.9617, Acc=0.522, 
2025-10-14 20:21:31,949 - training.trainer - INFO - Epoch 27, Step 91640: Loss=6.3200, Acc=0.242, 
2025-10-14 20:21:40,002 - training.trainer - INFO - Epoch 27, Step 91740: Loss=5.1129, Acc=0.385, 
2025-10-14 20:21:47,708 - training.trainer - INFO - Epoch 27, Step 91840: Loss=5.5831, Acc=0.190, 
2025-10-14 20:21:55,672 - training.trainer - INFO - Epoch 27, Step 91940: Loss=5.9061, Acc=0.258, 
2025-10-14 20:22:04,196 - training.trainer - INFO - Epoch 27, Step 92040: Loss=5.0711, Acc=0.348, 
2025-10-14 20:22:13,216 - training.trainer - INFO - Epoch 27, Step 92140: Loss=5.5486, Acc=0.286, 
2025-10-14 20:22:22,140 - training.trainer - INFO - Epoch 27, Step 92240: Loss=5.3119, Acc=0.314, 
2025-10-14 20:22:31,081 - training.trainer - INFO - Epoch 27, Step 92340: Loss=4.1808, Acc=0.375, 
2025-10-14 20:22:40,193 - training.trainer - INFO - Epoch 27, Step 92440: Loss=6.2202, Acc=0.308, 
2025-10-14 20:22:49,428 - training.trainer - INFO - Epoch 27, Step 92540: Loss=5.8831, Acc=0.225, 
2025-10-14 20:22:58,492 - training.trainer - INFO - Epoch 27, Step 92640: Loss=5.1558, Acc=0.240, 
2025-10-14 20:23:07,471 - training.trainer - INFO - Epoch 27, Step 92740: Loss=5.7378, Acc=0.250, 
2025-10-14 20:23:16,625 - training.trainer - INFO - Epoch 27, Step 92840: Loss=4.7852, Acc=0.278, 
2025-10-14 20:23:25,838 - training.trainer - INFO - Epoch 27, Step 92940: Loss=5.9521, Acc=0.217, 
2025-10-14 20:23:34,998 - training.trainer - INFO - Epoch 27, Step 93040: Loss=4.6516, Acc=0.250, 
2025-10-14 20:23:44,194 - training.trainer - INFO - Epoch 27, Step 93140: Loss=4.6418, Acc=0.350, 
2025-10-14 20:23:53,376 - training.trainer - INFO - Epoch 27, Step 93240: Loss=5.8999, Acc=0.214, 
2025-10-14 20:24:02,619 - training.trainer - INFO - Epoch 27, Step 93340: Loss=6.2618, Acc=0.162, 
2025-10-14 20:24:11,871 - training.trainer - INFO - Epoch 27, Step 93440: Loss=5.5530, Acc=0.176, 
2025-10-14 20:24:20,788 - training.trainer - INFO - Epoch 27, Step 93540: Loss=5.5859, Acc=0.293, 
2025-10-14 20:24:29,706 - training.trainer - INFO - Epoch 27, Step 93640: Loss=4.8064, Acc=0.333, 
2025-10-14 20:24:38,874 - training.trainer - INFO - Epoch 27, Step 93740: Loss=5.2844, Acc=0.222, 
2025-10-14 20:24:47,756 - training.trainer - INFO - Epoch 27, Step 93840: Loss=5.5941, Acc=0.227, 
2025-10-14 20:24:56,657 - training.trainer - INFO - Epoch 27, Step 93940: Loss=5.3126, Acc=0.389, 
2025-10-14 20:25:05,711 - training.trainer - INFO - Epoch 27, Step 94040: Loss=5.3014, Acc=0.280, 
2025-10-14 20:25:14,788 - training.trainer - INFO - Epoch 27, Step 94140: Loss=4.2467, Acc=0.375, 
2025-10-14 20:25:23,715 - training.trainer - INFO - Epoch 27, Step 94240: Loss=6.0412, Acc=0.133, 
2025-10-14 20:25:32,643 - training.trainer - INFO - Epoch 27, Step 94340: Loss=4.9752, Acc=0.308, 
2025-10-14 20:25:41,446 - training.trainer - INFO - Epoch 27, Step 94440: Loss=5.6870, Acc=0.242, 
2025-10-14 20:25:50,435 - training.trainer - INFO - Epoch 27, Step 94540: Loss=5.8264, Acc=0.242, 
2025-10-14 20:25:59,394 - training.trainer - INFO - Epoch 27, Step 94640: Loss=5.3157, Acc=0.279, 
2025-10-14 20:26:21,313 - training.trainer - INFO - Epoch 28/100 completed in 313.73s - Train Loss: 5.5218, Train Acc: 0.275, Val Loss: 5.8216, Val Acc: 0.259
2025-10-14 20:26:29,619 - training.trainer - INFO - Epoch 28, Step 94823: Loss=4.9558, Acc=0.367, 
2025-10-14 20:26:37,617 - training.trainer - INFO - Epoch 28, Step 94923: Loss=5.8156, Acc=0.318, 
2025-10-14 20:26:45,703 - training.trainer - INFO - Epoch 28, Step 95023: Loss=2.9807, Acc=0.667, 
2025-10-14 20:26:53,674 - training.trainer - INFO - Epoch 28, Step 95123: Loss=5.7600, Acc=0.161, 
2025-10-14 20:27:01,785 - training.trainer - INFO - Epoch 28, Step 95223: Loss=5.3899, Acc=0.393, 
2025-10-14 20:27:10,000 - training.trainer - INFO - Epoch 28, Step 95323: Loss=5.9954, Acc=0.214, 
2025-10-14 20:27:18,019 - training.trainer - INFO - Epoch 28, Step 95423: Loss=3.0082, Acc=0.645, 
2025-10-14 20:27:25,863 - training.trainer - INFO - Epoch 28, Step 95523: Loss=5.0679, Acc=0.385, 
2025-10-14 20:27:33,915 - training.trainer - INFO - Epoch 28, Step 95623: Loss=4.8791, Acc=0.391, 
2025-10-14 20:27:42,053 - training.trainer - INFO - Epoch 28, Step 95723: Loss=5.0021, Acc=0.388, 
2025-10-14 20:27:50,721 - training.trainer - INFO - Epoch 28, Step 95823: Loss=5.1064, Acc=0.381, 
2025-10-14 20:27:59,470 - training.trainer - INFO - Epoch 28, Step 95923: Loss=3.7794, Acc=0.440, 
2025-10-14 20:28:08,514 - training.trainer - INFO - Epoch 28, Step 96023: Loss=4.6003, Acc=0.364, 
2025-10-14 20:28:17,412 - training.trainer - INFO - Epoch 28, Step 96123: Loss=5.0294, Acc=0.292, 
2025-10-14 20:28:26,399 - training.trainer - INFO - Epoch 28, Step 96223: Loss=5.1486, Acc=0.385, 
2025-10-14 20:28:35,237 - training.trainer - INFO - Epoch 28, Step 96323: Loss=5.5919, Acc=0.286, 
2025-10-14 20:28:44,145 - training.trainer - INFO - Epoch 28, Step 96423: Loss=5.7565, Acc=0.200, 
2025-10-14 20:28:52,091 - training.trainer - INFO - Epoch 28, Step 96523: Loss=6.3386, Acc=0.259, 
2025-10-14 20:29:00,091 - training.trainer - INFO - Epoch 28, Step 96623: Loss=6.0077, Acc=0.153, 
2025-10-14 20:29:08,053 - training.trainer - INFO - Epoch 28, Step 96723: Loss=6.0564, Acc=0.200, 
2025-10-14 20:29:15,997 - training.trainer - INFO - Epoch 28, Step 96823: Loss=5.5102, Acc=0.346, 
2025-10-14 20:29:23,890 - training.trainer - INFO - Epoch 28, Step 96923: Loss=4.9988, Acc=0.316, 
2025-10-14 20:29:31,743 - training.trainer - INFO - Epoch 28, Step 97023: Loss=5.3886, Acc=0.304, 
2025-10-14 20:29:39,720 - training.trainer - INFO - Epoch 28, Step 97123: Loss=5.9131, Acc=0.235, 
2025-10-14 20:29:47,539 - training.trainer - INFO - Epoch 28, Step 97223: Loss=5.0198, Acc=0.353, 
2025-10-14 20:29:55,319 - training.trainer - INFO - Epoch 28, Step 97323: Loss=5.7904, Acc=0.265, 
2025-10-14 20:30:03,355 - training.trainer - INFO - Epoch 28, Step 97423: Loss=4.2823, Acc=0.471, 
2025-10-14 20:30:11,206 - training.trainer - INFO - Epoch 28, Step 97523: Loss=6.1215, Acc=0.243, 
2025-10-14 20:30:19,119 - training.trainer - INFO - Epoch 28, Step 97623: Loss=5.4909, Acc=0.324, 
2025-10-14 20:30:27,087 - training.trainer - INFO - Epoch 28, Step 97723: Loss=6.1799, Acc=0.226, 
2025-10-14 20:30:35,477 - training.trainer - INFO - Epoch 28, Step 97823: Loss=5.1744, Acc=0.278, 
2025-10-14 20:30:43,940 - training.trainer - INFO - Epoch 28, Step 97923: Loss=4.2618, Acc=0.484, 
2025-10-14 20:30:51,819 - training.trainer - INFO - Epoch 28, Step 98023: Loss=5.3507, Acc=0.306, 
2025-10-14 20:31:13,970 - training.trainer - INFO - Epoch 29/100 completed in 292.66s - Train Loss: 5.5067, Train Acc: 0.278, Val Loss: 5.8568, Val Acc: 0.260
2025-10-14 20:31:22,322 - training.trainer - INFO - Epoch 29, Step 98206: Loss=6.8044, Acc=0.169, 
2025-10-14 20:31:30,165 - training.trainer - INFO - Epoch 29, Step 98306: Loss=5.8900, Acc=0.188, 
2025-10-14 20:31:38,548 - training.trainer - INFO - Epoch 29, Step 98406: Loss=5.3394, Acc=0.289, 
2025-10-14 20:31:46,332 - training.trainer - INFO - Epoch 29, Step 98506: Loss=5.2396, Acc=0.321, 
2025-10-14 20:31:54,042 - training.trainer - INFO - Epoch 29, Step 98606: Loss=6.8557, Acc=0.183, 
2025-10-14 20:32:01,585 - training.trainer - INFO - Epoch 29, Step 98706: Loss=4.8898, Acc=0.438, 
2025-10-14 20:32:09,109 - training.trainer - INFO - Epoch 29, Step 98806: Loss=5.7794, Acc=0.159, 
2025-10-14 20:32:16,596 - training.trainer - INFO - Epoch 29, Step 98906: Loss=4.9825, Acc=0.327, 
2025-10-14 20:32:24,352 - training.trainer - INFO - Epoch 29, Step 99006: Loss=5.9321, Acc=0.271, 
2025-10-14 20:32:32,091 - training.trainer - INFO - Epoch 29, Step 99106: Loss=4.6813, Acc=0.450, 
2025-10-14 20:32:39,855 - training.trainer - INFO - Epoch 29, Step 99206: Loss=4.8913, Acc=0.303, 
2025-10-14 20:32:47,502 - training.trainer - INFO - Epoch 29, Step 99306: Loss=5.5817, Acc=0.222, 
2025-10-14 20:32:55,100 - training.trainer - INFO - Epoch 29, Step 99406: Loss=5.1564, Acc=0.333, 
2025-10-14 20:33:02,872 - training.trainer - INFO - Epoch 29, Step 99506: Loss=5.0541, Acc=0.256, 
2025-10-14 20:33:10,403 - training.trainer - INFO - Epoch 29, Step 99606: Loss=5.6548, Acc=0.137, 
2025-10-14 20:33:18,154 - training.trainer - INFO - Epoch 29, Step 99706: Loss=3.6938, Acc=0.571, 
2025-10-14 20:33:26,617 - training.trainer - INFO - Epoch 29, Step 99806: Loss=5.9925, Acc=0.189, 
2025-10-14 20:33:35,224 - training.trainer - INFO - Epoch 29, Step 99906: Loss=6.1495, Acc=0.242, 
2025-10-14 20:33:44,342 - training.trainer - INFO - Epoch 29, Step 100006: Loss=6.1555, Acc=0.182, 
2025-10-14 20:33:53,395 - training.trainer - INFO - Epoch 29, Step 100106: Loss=6.0888, Acc=0.327, 
2025-10-14 20:34:02,585 - training.trainer - INFO - Epoch 29, Step 100206: Loss=5.6190, Acc=0.224, 
2025-10-14 20:34:11,758 - training.trainer - INFO - Epoch 29, Step 100306: Loss=5.1197, Acc=0.360, 
2025-10-14 20:34:20,631 - training.trainer - INFO - Epoch 29, Step 100406: Loss=5.3262, Acc=0.176, 
2025-10-14 20:34:28,722 - training.trainer - INFO - Epoch 29, Step 100506: Loss=4.0681, Acc=0.382, 
2025-10-14 20:34:36,824 - training.trainer - INFO - Epoch 29, Step 100606: Loss=5.0013, Acc=0.238, 
2025-10-14 20:34:44,728 - training.trainer - INFO - Epoch 29, Step 100706: Loss=4.9262, Acc=0.311, 
2025-10-14 20:34:52,849 - training.trainer - INFO - Epoch 29, Step 100806: Loss=5.4287, Acc=0.188, 
2025-10-14 20:35:00,973 - training.trainer - INFO - Epoch 29, Step 100906: Loss=5.7192, Acc=0.244, 
2025-10-14 20:35:09,005 - training.trainer - INFO - Epoch 29, Step 101006: Loss=6.6193, Acc=0.165, 
2025-10-14 20:35:17,016 - training.trainer - INFO - Epoch 29, Step 101106: Loss=4.9247, Acc=0.350, 
2025-10-14 20:35:24,934 - training.trainer - INFO - Epoch 29, Step 101206: Loss=5.9368, Acc=0.175, 
2025-10-14 20:35:33,062 - training.trainer - INFO - Epoch 29, Step 101306: Loss=4.2344, Acc=0.423, 
2025-10-14 20:35:40,889 - training.trainer - INFO - Epoch 29, Step 101406: Loss=6.0586, Acc=0.167, 
2025-10-14 20:36:03,015 - training.trainer - INFO - Epoch 30/100 completed in 289.04s - Train Loss: 5.4903, Train Acc: 0.280, Val Loss: 5.8607, Val Acc: 0.258
2025-10-14 20:36:03,402 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_30.pt
2025-10-14 20:36:11,840 - training.trainer - INFO - Epoch 30, Step 101589: Loss=3.4236, Acc=0.577, 
2025-10-14 20:36:19,925 - training.trainer - INFO - Epoch 30, Step 101689: Loss=6.2750, Acc=0.261, 
2025-10-14 20:36:28,127 - training.trainer - INFO - Epoch 30, Step 101789: Loss=5.3859, Acc=0.306, 
2025-10-14 20:36:36,044 - training.trainer - INFO - Epoch 30, Step 101889: Loss=4.4141, Acc=0.468, 
2025-10-14 20:36:44,072 - training.trainer - INFO - Epoch 30, Step 101989: Loss=4.1647, Acc=0.421, 
2025-10-14 20:36:52,036 - training.trainer - INFO - Epoch 30, Step 102089: Loss=4.8510, Acc=0.400, 
2025-10-14 20:37:00,246 - training.trainer - INFO - Epoch 30, Step 102189: Loss=5.2905, Acc=0.179, 
2025-10-14 20:37:08,243 - training.trainer - INFO - Epoch 30, Step 102289: Loss=5.3035, Acc=0.250, 
2025-10-14 20:37:16,226 - training.trainer - INFO - Epoch 30, Step 102389: Loss=5.5368, Acc=0.241, 
2025-10-14 20:37:24,221 - training.trainer - INFO - Epoch 30, Step 102489: Loss=6.0175, Acc=0.292, 
2025-10-14 20:37:32,434 - training.trainer - INFO - Epoch 30, Step 102589: Loss=5.6679, Acc=0.136, 
2025-10-14 20:37:40,306 - training.trainer - INFO - Epoch 30, Step 102689: Loss=6.2821, Acc=0.158, 
2025-10-14 20:37:48,389 - training.trainer - INFO - Epoch 30, Step 102789: Loss=6.2237, Acc=0.179, 
2025-10-14 20:37:56,547 - training.trainer - INFO - Epoch 30, Step 102889: Loss=5.3095, Acc=0.321, 
2025-10-14 20:38:05,557 - training.trainer - INFO - Epoch 30, Step 102989: Loss=6.4271, Acc=0.200, 
2025-10-14 20:38:14,524 - training.trainer - INFO - Epoch 30, Step 103089: Loss=5.6803, Acc=0.246, 
2025-10-14 20:38:23,684 - training.trainer - INFO - Epoch 30, Step 103189: Loss=5.2893, Acc=0.194, 
2025-10-14 20:38:32,867 - training.trainer - INFO - Epoch 30, Step 103289: Loss=5.8927, Acc=0.214, 
2025-10-14 20:38:41,628 - training.trainer - INFO - Epoch 30, Step 103389: Loss=6.3250, Acc=0.231, 
2025-10-14 20:38:49,713 - training.trainer - INFO - Epoch 30, Step 103489: Loss=5.6105, Acc=0.300, 
2025-10-14 20:38:57,776 - training.trainer - INFO - Epoch 30, Step 103589: Loss=6.3768, Acc=0.200, 
2025-10-14 20:39:05,799 - training.trainer - INFO - Epoch 30, Step 103689: Loss=5.8943, Acc=0.364, 
2025-10-14 20:39:13,972 - training.trainer - INFO - Epoch 30, Step 103789: Loss=5.3202, Acc=0.312, 
2025-10-14 20:39:22,079 - training.trainer - INFO - Epoch 30, Step 103889: Loss=6.1841, Acc=0.250, 
2025-10-14 20:39:30,257 - training.trainer - INFO - Epoch 30, Step 103989: Loss=5.8987, Acc=0.188, 
2025-10-14 20:39:38,379 - training.trainer - INFO - Epoch 30, Step 104089: Loss=5.3981, Acc=0.312, 
2025-10-14 20:39:46,372 - training.trainer - INFO - Epoch 30, Step 104189: Loss=6.1871, Acc=0.182, 
2025-10-14 20:39:54,386 - training.trainer - INFO - Epoch 30, Step 104289: Loss=5.9139, Acc=0.220, 
2025-10-14 20:40:02,172 - training.trainer - INFO - Epoch 30, Step 104389: Loss=5.9868, Acc=0.320, 
2025-10-14 20:40:10,304 - training.trainer - INFO - Epoch 30, Step 104489: Loss=5.8843, Acc=0.257, 
2025-10-14 20:40:18,229 - training.trainer - INFO - Epoch 30, Step 104589: Loss=6.3854, Acc=0.214, 
2025-10-14 20:40:26,278 - training.trainer - INFO - Epoch 30, Step 104689: Loss=5.3980, Acc=0.194, 
2025-10-14 20:40:34,185 - training.trainer - INFO - Epoch 30, Step 104789: Loss=4.1720, Acc=0.304, 
2025-10-14 20:40:55,956 - training.trainer - INFO - Epoch 31/100 completed in 292.55s - Train Loss: 5.4730, Train Acc: 0.283, Val Loss: 5.8290, Val Acc: 0.262
2025-10-14 20:41:04,475 - training.trainer - INFO - Epoch 31, Step 104972: Loss=5.3363, Acc=0.310, 
2025-10-14 20:41:12,468 - training.trainer - INFO - Epoch 31, Step 105072: Loss=5.0886, Acc=0.353, 
2025-10-14 20:41:20,619 - training.trainer - INFO - Epoch 31, Step 105172: Loss=4.6603, Acc=0.366, 
2025-10-14 20:41:28,667 - training.trainer - INFO - Epoch 31, Step 105272: Loss=4.3485, Acc=0.379, 
2025-10-14 20:41:36,656 - training.trainer - INFO - Epoch 31, Step 105372: Loss=5.0535, Acc=0.209, 
2025-10-14 20:41:44,672 - training.trainer - INFO - Epoch 31, Step 105472: Loss=5.2934, Acc=0.289, 
2025-10-14 20:41:52,640 - training.trainer - INFO - Epoch 31, Step 105572: Loss=6.0783, Acc=0.132, 
2025-10-14 20:42:00,927 - training.trainer - INFO - Epoch 31, Step 105672: Loss=6.0917, Acc=0.269, 
2025-10-14 20:42:08,856 - training.trainer - INFO - Epoch 31, Step 105772: Loss=5.4236, Acc=0.194, 
2025-10-14 20:42:17,173 - training.trainer - INFO - Epoch 31, Step 105872: Loss=5.2539, Acc=0.323, 
2025-10-14 20:42:25,253 - training.trainer - INFO - Epoch 31, Step 105972: Loss=5.5493, Acc=0.244, 
2025-10-14 20:42:33,328 - training.trainer - INFO - Epoch 31, Step 106072: Loss=5.0402, Acc=0.368, 
2025-10-14 20:42:41,338 - training.trainer - INFO - Epoch 31, Step 106172: Loss=5.8095, Acc=0.211, 
2025-10-14 20:42:49,580 - training.trainer - INFO - Epoch 31, Step 106272: Loss=6.3388, Acc=0.158, 
2025-10-14 20:42:57,707 - training.trainer - INFO - Epoch 31, Step 106372: Loss=5.9993, Acc=0.170, 
2025-10-14 20:43:05,722 - training.trainer - INFO - Epoch 31, Step 106472: Loss=4.5292, Acc=0.320, 
2025-10-14 20:43:13,804 - training.trainer - INFO - Epoch 31, Step 106572: Loss=4.5418, Acc=0.321, 
2025-10-14 20:43:22,067 - training.trainer - INFO - Epoch 31, Step 106672: Loss=4.5727, Acc=0.385, 
2025-10-14 20:43:30,837 - training.trainer - INFO - Epoch 31, Step 106772: Loss=5.7840, Acc=0.242, 
2025-10-14 20:43:39,519 - training.trainer - INFO - Epoch 31, Step 106872: Loss=5.4958, Acc=0.250, 
2025-10-14 20:43:48,148 - training.trainer - INFO - Epoch 31, Step 106972: Loss=4.6839, Acc=0.353, 
2025-10-14 20:43:56,529 - training.trainer - INFO - Epoch 31, Step 107072: Loss=6.1222, Acc=0.286, 
2025-10-14 20:44:04,758 - training.trainer - INFO - Epoch 31, Step 107172: Loss=5.9162, Acc=0.260, 
2025-10-14 20:44:12,919 - training.trainer - INFO - Epoch 31, Step 107272: Loss=6.0179, Acc=0.224, 
2025-10-14 20:44:21,155 - training.trainer - INFO - Epoch 31, Step 107372: Loss=5.9275, Acc=0.242, 
2025-10-14 20:44:29,204 - training.trainer - INFO - Epoch 31, Step 107472: Loss=6.0337, Acc=0.125, 
2025-10-14 20:44:37,294 - training.trainer - INFO - Epoch 31, Step 107572: Loss=4.9189, Acc=0.342, 
2025-10-14 20:44:45,656 - training.trainer - INFO - Epoch 31, Step 107672: Loss=6.0675, Acc=0.233, 
2025-10-14 20:44:53,836 - training.trainer - INFO - Epoch 31, Step 107772: Loss=5.9890, Acc=0.233, 
2025-10-14 20:45:02,770 - training.trainer - INFO - Epoch 31, Step 107872: Loss=5.6228, Acc=0.333, 
2025-10-14 20:45:11,350 - training.trainer - INFO - Epoch 31, Step 107972: Loss=5.8935, Acc=0.276, 
2025-10-14 20:45:20,141 - training.trainer - INFO - Epoch 31, Step 108072: Loss=5.2755, Acc=0.333, 
2025-10-14 20:45:28,912 - training.trainer - INFO - Epoch 31, Step 108172: Loss=4.6733, Acc=0.400, 
2025-10-14 20:45:51,332 - training.trainer - INFO - Epoch 32/100 completed in 295.38s - Train Loss: 5.4636, Train Acc: 0.284, Val Loss: 5.8299, Val Acc: 0.265
2025-10-14 20:46:00,049 - training.trainer - INFO - Epoch 32, Step 108355: Loss=3.7490, Acc=0.423, 
2025-10-14 20:46:08,619 - training.trainer - INFO - Epoch 32, Step 108455: Loss=3.9056, Acc=0.474, 
2025-10-14 20:46:16,962 - training.trainer - INFO - Epoch 32, Step 108555: Loss=5.6260, Acc=0.368, 
2025-10-14 20:46:25,256 - training.trainer - INFO - Epoch 32, Step 108655: Loss=6.0558, Acc=0.200, 
2025-10-14 20:46:33,696 - training.trainer - INFO - Epoch 32, Step 108755: Loss=5.6235, Acc=0.273, 
2025-10-14 20:46:41,941 - training.trainer - INFO - Epoch 32, Step 108855: Loss=5.3521, Acc=0.281, 
2025-10-14 20:46:50,116 - training.trainer - INFO - Epoch 32, Step 108955: Loss=4.6005, Acc=0.423, 
2025-10-14 20:46:58,419 - training.trainer - INFO - Epoch 32, Step 109055: Loss=4.6516, Acc=0.333, 
2025-10-14 20:47:06,601 - training.trainer - INFO - Epoch 32, Step 109155: Loss=5.8010, Acc=0.265, 
2025-10-14 20:47:14,852 - training.trainer - INFO - Epoch 32, Step 109255: Loss=2.7978, Acc=0.783, 
2025-10-14 20:47:23,166 - training.trainer - INFO - Epoch 32, Step 109355: Loss=5.7359, Acc=0.250, 
2025-10-14 20:47:31,528 - training.trainer - INFO - Epoch 32, Step 109455: Loss=5.7176, Acc=0.245, 
2025-10-14 20:47:39,698 - training.trainer - INFO - Epoch 32, Step 109555: Loss=5.7550, Acc=0.406, 
2025-10-14 20:47:48,251 - training.trainer - INFO - Epoch 32, Step 109655: Loss=4.7565, Acc=0.412, 
2025-10-14 20:47:57,240 - training.trainer - INFO - Epoch 32, Step 109755: Loss=5.5307, Acc=0.176, 
2025-10-14 20:48:06,374 - training.trainer - INFO - Epoch 32, Step 109855: Loss=5.5904, Acc=0.348, 
2025-10-14 20:48:15,459 - training.trainer - INFO - Epoch 32, Step 109955: Loss=5.4150, Acc=0.275, 
2025-10-14 20:48:24,662 - training.trainer - INFO - Epoch 32, Step 110055: Loss=4.2550, Acc=0.417, 
2025-10-14 20:48:33,981 - training.trainer - INFO - Epoch 32, Step 110155: Loss=6.3419, Acc=0.241, 
2025-10-14 20:48:43,357 - training.trainer - INFO - Epoch 32, Step 110255: Loss=3.6869, Acc=0.385, 
2025-10-14 20:48:52,776 - training.trainer - INFO - Epoch 32, Step 110355: Loss=5.9900, Acc=0.286, 
2025-10-14 20:49:02,239 - training.trainer - INFO - Epoch 32, Step 110455: Loss=6.2409, Acc=0.114, 
2025-10-14 20:49:11,485 - training.trainer - INFO - Epoch 32, Step 110555: Loss=5.9559, Acc=0.167, 
2025-10-14 20:49:20,027 - training.trainer - INFO - Epoch 32, Step 110655: Loss=5.6687, Acc=0.195, 
2025-10-14 20:49:28,500 - training.trainer - INFO - Epoch 32, Step 110755: Loss=5.2170, Acc=0.400, 
2025-10-14 20:49:37,590 - training.trainer - INFO - Epoch 32, Step 110855: Loss=4.8140, Acc=0.393, 
2025-10-14 20:49:46,683 - training.trainer - INFO - Epoch 32, Step 110955: Loss=5.3308, Acc=0.261, 
2025-10-14 20:49:55,694 - training.trainer - INFO - Epoch 32, Step 111055: Loss=4.8860, Acc=0.286, 
2025-10-14 20:50:04,695 - training.trainer - INFO - Epoch 32, Step 111155: Loss=5.4773, Acc=0.333, 
2025-10-14 20:50:13,695 - training.trainer - INFO - Epoch 32, Step 111255: Loss=4.5110, Acc=0.417, 
2025-10-14 20:50:22,533 - training.trainer - INFO - Epoch 32, Step 111355: Loss=5.6890, Acc=0.227, 
2025-10-14 20:50:31,622 - training.trainer - INFO - Epoch 32, Step 111455: Loss=6.0796, Acc=0.225, 
2025-10-14 20:50:40,658 - training.trainer - INFO - Epoch 32, Step 111555: Loss=4.5327, Acc=0.353, 
2025-10-14 20:51:01,655 - training.trainer - INFO - Epoch 33/100 completed in 310.32s - Train Loss: 5.4484, Train Acc: 0.287, Val Loss: 5.8754, Val Acc: 0.264
2025-10-14 20:51:10,042 - training.trainer - INFO - Epoch 33, Step 111738: Loss=6.0832, Acc=0.146, 
2025-10-14 20:51:18,177 - training.trainer - INFO - Epoch 33, Step 111838: Loss=5.8254, Acc=0.235, 
2025-10-14 20:51:26,287 - training.trainer - INFO - Epoch 33, Step 111938: Loss=4.4492, Acc=0.417, 
2025-10-14 20:51:34,493 - training.trainer - INFO - Epoch 33, Step 112038: Loss=5.9758, Acc=0.256, 
2025-10-14 20:51:42,835 - training.trainer - INFO - Epoch 33, Step 112138: Loss=5.2066, Acc=0.343, 
2025-10-14 20:51:50,876 - training.trainer - INFO - Epoch 33, Step 112238: Loss=5.3293, Acc=0.365, 
2025-10-14 20:51:59,085 - training.trainer - INFO - Epoch 33, Step 112338: Loss=5.5007, Acc=0.292, 
2025-10-14 20:52:07,099 - training.trainer - INFO - Epoch 33, Step 112438: Loss=6.1306, Acc=0.158, 
2025-10-14 20:52:15,119 - training.trainer - INFO - Epoch 33, Step 112538: Loss=6.2284, Acc=0.111, 
2025-10-14 20:52:23,256 - training.trainer - INFO - Epoch 33, Step 112638: Loss=5.6663, Acc=0.341, 
2025-10-14 20:52:31,549 - training.trainer - INFO - Epoch 33, Step 112738: Loss=5.8252, Acc=0.256, 
2025-10-14 20:52:39,728 - training.trainer - INFO - Epoch 33, Step 112838: Loss=4.2805, Acc=0.480, 
2025-10-14 20:52:47,867 - training.trainer - INFO - Epoch 33, Step 112938: Loss=5.3765, Acc=0.298, 
2025-10-14 20:52:55,998 - training.trainer - INFO - Epoch 33, Step 113038: Loss=5.1684, Acc=0.314, 
2025-10-14 20:53:03,949 - training.trainer - INFO - Epoch 33, Step 113138: Loss=5.7935, Acc=0.231, 
2025-10-14 20:53:12,571 - training.trainer - INFO - Epoch 33, Step 113238: Loss=5.9428, Acc=0.250, 
2025-10-14 20:53:21,597 - training.trainer - INFO - Epoch 33, Step 113338: Loss=6.0168, Acc=0.246, 
2025-10-14 20:53:29,990 - training.trainer - INFO - Epoch 33, Step 113438: Loss=5.7613, Acc=0.354, 
2025-10-14 20:53:38,259 - training.trainer - INFO - Epoch 33, Step 113538: Loss=5.4998, Acc=0.226, 
2025-10-14 20:53:46,513 - training.trainer - INFO - Epoch 33, Step 113638: Loss=4.5697, Acc=0.444, 
2025-10-14 20:53:54,796 - training.trainer - INFO - Epoch 33, Step 113738: Loss=5.2012, Acc=0.290, 
2025-10-14 20:54:02,979 - training.trainer - INFO - Epoch 33, Step 113838: Loss=6.1035, Acc=0.296, 
2025-10-14 20:54:11,069 - training.trainer - INFO - Epoch 33, Step 113938: Loss=4.9287, Acc=0.429, 
2025-10-14 20:54:19,075 - training.trainer - INFO - Epoch 33, Step 114038: Loss=5.1767, Acc=0.257, 
2025-10-14 20:54:27,143 - training.trainer - INFO - Epoch 33, Step 114138: Loss=5.5144, Acc=0.295, 
2025-10-14 20:54:35,211 - training.trainer - INFO - Epoch 33, Step 114238: Loss=4.9734, Acc=0.389, 
2025-10-14 20:54:43,509 - training.trainer - INFO - Epoch 33, Step 114338: Loss=5.5360, Acc=0.250, 
2025-10-14 20:54:52,078 - training.trainer - INFO - Epoch 33, Step 114438: Loss=5.7979, Acc=0.194, 
2025-10-14 20:55:00,327 - training.trainer - INFO - Epoch 33, Step 114538: Loss=5.5313, Acc=0.375, 
2025-10-14 20:55:08,589 - training.trainer - INFO - Epoch 33, Step 114638: Loss=5.4278, Acc=0.429, 
2025-10-14 20:55:16,580 - training.trainer - INFO - Epoch 33, Step 114738: Loss=5.4380, Acc=0.277, 
2025-10-14 20:55:25,535 - training.trainer - INFO - Epoch 33, Step 114838: Loss=5.5786, Acc=0.167, 
2025-10-14 20:55:34,626 - training.trainer - INFO - Epoch 33, Step 114938: Loss=5.7355, Acc=0.222, 
2025-10-14 20:55:58,721 - training.trainer - INFO - Epoch 34/100 completed in 297.06s - Train Loss: 5.4357, Train Acc: 0.289, Val Loss: 5.8455, Val Acc: 0.260
2025-10-14 20:56:07,628 - training.trainer - INFO - Epoch 34, Step 115121: Loss=5.5255, Acc=0.294, 
2025-10-14 20:56:16,814 - training.trainer - INFO - Epoch 34, Step 115221: Loss=5.8712, Acc=0.216, 
2025-10-14 20:56:25,437 - training.trainer - INFO - Epoch 34, Step 115321: Loss=5.9119, Acc=0.180, 
2025-10-14 20:56:34,429 - training.trainer - INFO - Epoch 34, Step 115421: Loss=4.9661, Acc=0.238, 
2025-10-14 20:56:43,395 - training.trainer - INFO - Epoch 34, Step 115521: Loss=6.0434, Acc=0.267, 
2025-10-14 20:56:51,592 - training.trainer - INFO - Epoch 34, Step 115621: Loss=4.7927, Acc=0.367, 
2025-10-14 20:56:59,764 - training.trainer - INFO - Epoch 34, Step 115721: Loss=5.1232, Acc=0.303, 
2025-10-14 20:57:08,292 - training.trainer - INFO - Epoch 34, Step 115821: Loss=4.8962, Acc=0.328, 
2025-10-14 20:57:16,698 - training.trainer - INFO - Epoch 34, Step 115921: Loss=3.7627, Acc=0.500, 
2025-10-14 20:57:25,585 - training.trainer - INFO - Epoch 34, Step 116021: Loss=6.1580, Acc=0.205, 
2025-10-14 20:57:33,610 - training.trainer - INFO - Epoch 34, Step 116121: Loss=6.1785, Acc=0.280, 
2025-10-14 20:57:41,830 - training.trainer - INFO - Epoch 34, Step 116221: Loss=3.8505, Acc=0.500, 
2025-10-14 20:57:49,969 - training.trainer - INFO - Epoch 34, Step 116321: Loss=5.0612, Acc=0.291, 
2025-10-14 20:57:58,202 - training.trainer - INFO - Epoch 34, Step 116421: Loss=5.5436, Acc=0.278, 
2025-10-14 20:58:06,441 - training.trainer - INFO - Epoch 34, Step 116521: Loss=5.7142, Acc=0.231, 
2025-10-14 20:58:14,530 - training.trainer - INFO - Epoch 34, Step 116621: Loss=5.2012, Acc=0.214, 
2025-10-14 20:58:22,511 - training.trainer - INFO - Epoch 34, Step 116721: Loss=5.8882, Acc=0.281, 
2025-10-14 20:58:30,792 - training.trainer - INFO - Epoch 34, Step 116821: Loss=6.1481, Acc=0.208, 
2025-10-14 20:58:38,964 - training.trainer - INFO - Epoch 34, Step 116921: Loss=5.2898, Acc=0.263, 
2025-10-14 20:58:47,191 - training.trainer - INFO - Epoch 34, Step 117021: Loss=5.3906, Acc=0.209, 
2025-10-14 20:58:55,222 - training.trainer - INFO - Epoch 34, Step 117121: Loss=5.9311, Acc=0.153, 
2025-10-14 20:59:03,454 - training.trainer - INFO - Epoch 34, Step 117221: Loss=5.4500, Acc=0.357, 
2025-10-14 20:59:11,773 - training.trainer - INFO - Epoch 34, Step 117321: Loss=5.1826, Acc=0.241, 
2025-10-14 20:59:20,186 - training.trainer - INFO - Epoch 34, Step 117421: Loss=5.6648, Acc=0.310, 
2025-10-14 20:59:28,138 - training.trainer - INFO - Epoch 34, Step 117521: Loss=5.9958, Acc=0.233, 
2025-10-14 20:59:36,451 - training.trainer - INFO - Epoch 34, Step 117621: Loss=5.0290, Acc=0.435, 
2025-10-14 20:59:44,463 - training.trainer - INFO - Epoch 34, Step 117721: Loss=5.3445, Acc=0.302, 
2025-10-14 20:59:52,485 - training.trainer - INFO - Epoch 34, Step 117821: Loss=6.4790, Acc=0.170, 
2025-10-14 21:00:00,658 - training.trainer - INFO - Epoch 34, Step 117921: Loss=6.1846, Acc=0.119, 
2025-10-14 21:00:08,694 - training.trainer - INFO - Epoch 34, Step 118021: Loss=5.3593, Acc=0.340, 
2025-10-14 21:00:16,983 - training.trainer - INFO - Epoch 34, Step 118121: Loss=6.3745, Acc=0.198, 
2025-10-14 21:00:25,233 - training.trainer - INFO - Epoch 34, Step 118221: Loss=5.3062, Acc=0.400, 
2025-10-14 21:00:33,445 - training.trainer - INFO - Epoch 34, Step 118321: Loss=5.4735, Acc=0.240, 
2025-10-14 21:00:56,293 - training.trainer - INFO - Epoch 35/100 completed in 297.57s - Train Loss: 5.4223, Train Acc: 0.291, Val Loss: 5.8651, Val Acc: 0.261
2025-10-14 21:00:56,740 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_35.pt
2025-10-14 21:01:05,295 - training.trainer - INFO - Epoch 35, Step 118504: Loss=5.1694, Acc=0.345, 
2025-10-14 21:01:13,628 - training.trainer - INFO - Epoch 35, Step 118604: Loss=5.3371, Acc=0.343, 
2025-10-14 21:01:21,646 - training.trainer - INFO - Epoch 35, Step 118704: Loss=5.4788, Acc=0.206, 
2025-10-14 21:01:29,906 - training.trainer - INFO - Epoch 35, Step 118804: Loss=5.1852, Acc=0.303, 
2025-10-14 21:01:38,299 - training.trainer - INFO - Epoch 35, Step 118904: Loss=5.9584, Acc=0.206, 
2025-10-14 21:01:46,369 - training.trainer - INFO - Epoch 35, Step 119004: Loss=3.3483, Acc=0.588, 
2025-10-14 21:01:54,852 - training.trainer - INFO - Epoch 35, Step 119104: Loss=5.9580, Acc=0.194, 
2025-10-14 21:02:03,160 - training.trainer - INFO - Epoch 35, Step 119204: Loss=3.3689, Acc=0.615, 
2025-10-14 21:02:11,396 - training.trainer - INFO - Epoch 35, Step 119304: Loss=4.8441, Acc=0.263, 
2025-10-14 21:02:19,377 - training.trainer - INFO - Epoch 35, Step 119404: Loss=4.8303, Acc=0.379, 
2025-10-14 21:02:27,556 - training.trainer - INFO - Epoch 35, Step 119504: Loss=5.3528, Acc=0.273, 
2025-10-14 21:02:35,676 - training.trainer - INFO - Epoch 35, Step 119604: Loss=5.2948, Acc=0.375, 
2025-10-14 21:02:43,787 - training.trainer - INFO - Epoch 35, Step 119704: Loss=5.0146, Acc=0.316, 
2025-10-14 21:02:51,768 - training.trainer - INFO - Epoch 35, Step 119804: Loss=5.7331, Acc=0.277, 
2025-10-14 21:02:59,792 - training.trainer - INFO - Epoch 35, Step 119904: Loss=5.6880, Acc=0.219, 
2025-10-14 21:03:07,862 - training.trainer - INFO - Epoch 35, Step 120004: Loss=6.0615, Acc=0.250, 
2025-10-14 21:03:16,323 - training.trainer - INFO - Epoch 35, Step 120104: Loss=6.3071, Acc=0.297, 
2025-10-14 21:03:24,324 - training.trainer - INFO - Epoch 35, Step 120204: Loss=4.5786, Acc=0.395, 
2025-10-14 21:03:32,347 - training.trainer - INFO - Epoch 35, Step 120304: Loss=5.6399, Acc=0.250, 
2025-10-14 21:03:40,207 - training.trainer - INFO - Epoch 35, Step 120404: Loss=6.7505, Acc=0.172, 
2025-10-14 21:03:48,270 - training.trainer - INFO - Epoch 35, Step 120504: Loss=5.2715, Acc=0.231, 
2025-10-14 21:03:56,160 - training.trainer - INFO - Epoch 35, Step 120604: Loss=5.5978, Acc=0.231, 
2025-10-14 21:04:04,731 - training.trainer - INFO - Epoch 35, Step 120704: Loss=5.5091, Acc=0.256, 
2025-10-14 21:04:12,980 - training.trainer - INFO - Epoch 35, Step 120804: Loss=5.1224, Acc=0.321, 
2025-10-14 21:04:21,303 - training.trainer - INFO - Epoch 35, Step 120904: Loss=6.6448, Acc=0.200, 
2025-10-14 21:04:30,124 - training.trainer - INFO - Epoch 35, Step 121004: Loss=5.4497, Acc=0.289, 
2025-10-14 21:04:38,403 - training.trainer - INFO - Epoch 35, Step 121104: Loss=5.2679, Acc=0.250, 
2025-10-14 21:04:46,949 - training.trainer - INFO - Epoch 35, Step 121204: Loss=5.8622, Acc=0.208, 
2025-10-14 21:04:56,167 - training.trainer - INFO - Epoch 35, Step 121304: Loss=5.1300, Acc=0.350, 
2025-10-14 21:05:04,678 - training.trainer - INFO - Epoch 35, Step 121404: Loss=4.5615, Acc=0.250, 
2025-10-14 21:05:12,927 - training.trainer - INFO - Epoch 35, Step 121504: Loss=5.0048, Acc=0.333, 
2025-10-14 21:05:21,076 - training.trainer - INFO - Epoch 35, Step 121604: Loss=6.1952, Acc=0.346, 
2025-10-14 21:05:29,610 - training.trainer - INFO - Epoch 35, Step 121704: Loss=4.4725, Acc=0.464, 
2025-10-14 21:05:50,950 - training.trainer - INFO - Epoch 36/100 completed in 294.21s - Train Loss: 5.4082, Train Acc: 0.292, Val Loss: 5.8430, Val Acc: 0.264
2025-10-14 21:05:59,241 - training.trainer - INFO - Epoch 36, Step 121887: Loss=4.7453, Acc=0.292, 
2025-10-14 21:06:07,239 - training.trainer - INFO - Epoch 36, Step 121987: Loss=5.0450, Acc=0.400, 
2025-10-14 21:06:15,312 - training.trainer - INFO - Epoch 36, Step 122087: Loss=5.0382, Acc=0.344, 
2025-10-14 21:06:23,454 - training.trainer - INFO - Epoch 36, Step 122187: Loss=5.9174, Acc=0.239, 
2025-10-14 21:06:32,116 - training.trainer - INFO - Epoch 36, Step 122287: Loss=5.6462, Acc=0.216, 
2025-10-14 21:06:41,119 - training.trainer - INFO - Epoch 36, Step 122387: Loss=4.5857, Acc=0.385, 
2025-10-14 21:06:50,305 - training.trainer - INFO - Epoch 36, Step 122487: Loss=5.8884, Acc=0.368, 
2025-10-14 21:06:59,323 - training.trainer - INFO - Epoch 36, Step 122587: Loss=5.2344, Acc=0.348, 
2025-10-14 21:07:08,593 - training.trainer - INFO - Epoch 36, Step 122687: Loss=4.9578, Acc=0.414, 
2025-10-14 21:07:16,767 - training.trainer - INFO - Epoch 36, Step 122787: Loss=4.7574, Acc=0.278, 
2025-10-14 21:07:24,911 - training.trainer - INFO - Epoch 36, Step 122887: Loss=5.5823, Acc=0.244, 
2025-10-14 21:07:33,959 - training.trainer - INFO - Epoch 36, Step 122987: Loss=5.7009, Acc=0.412, 
2025-10-14 21:07:43,310 - training.trainer - INFO - Epoch 36, Step 123087: Loss=4.1722, Acc=0.417, 
2025-10-14 21:07:52,539 - training.trainer - INFO - Epoch 36, Step 123187: Loss=5.2945, Acc=0.450, 
2025-10-14 21:08:01,446 - training.trainer - INFO - Epoch 36, Step 123287: Loss=4.8448, Acc=0.333, 
2025-10-14 21:08:10,251 - training.trainer - INFO - Epoch 36, Step 123387: Loss=5.1172, Acc=0.302, 
2025-10-14 21:08:19,181 - training.trainer - INFO - Epoch 36, Step 123487: Loss=5.4919, Acc=0.294, 
2025-10-14 21:08:28,324 - training.trainer - INFO - Epoch 36, Step 123587: Loss=5.5978, Acc=0.333, 
2025-10-14 21:08:37,382 - training.trainer - INFO - Epoch 36, Step 123687: Loss=5.6517, Acc=0.171, 
2025-10-14 21:08:46,233 - training.trainer - INFO - Epoch 36, Step 123787: Loss=6.0928, Acc=0.246, 
2025-10-14 21:08:54,971 - training.trainer - INFO - Epoch 36, Step 123887: Loss=6.6644, Acc=0.197, 
2025-10-14 21:09:03,586 - training.trainer - INFO - Epoch 36, Step 123987: Loss=5.8181, Acc=0.259, 
2025-10-14 21:09:12,320 - training.trainer - INFO - Epoch 36, Step 124087: Loss=5.0559, Acc=0.296, 
2025-10-14 21:09:21,002 - training.trainer - INFO - Epoch 36, Step 124187: Loss=5.8741, Acc=0.234, 
2025-10-14 21:09:29,912 - training.trainer - INFO - Epoch 36, Step 124287: Loss=4.9395, Acc=0.267, 
2025-10-14 21:09:38,618 - training.trainer - INFO - Epoch 36, Step 124387: Loss=5.9629, Acc=0.273, 
2025-10-14 21:09:47,348 - training.trainer - INFO - Epoch 36, Step 124487: Loss=5.2276, Acc=0.312, 
2025-10-14 21:09:56,068 - training.trainer - INFO - Epoch 36, Step 124587: Loss=5.1932, Acc=0.317, 
2025-10-14 21:10:05,183 - training.trainer - INFO - Epoch 36, Step 124687: Loss=4.7664, Acc=0.286, 
2025-10-14 21:10:14,303 - training.trainer - INFO - Epoch 36, Step 124787: Loss=5.0128, Acc=0.250, 
2025-10-14 21:10:23,599 - training.trainer - INFO - Epoch 36, Step 124887: Loss=4.1224, Acc=0.533, 
2025-10-14 21:10:32,863 - training.trainer - INFO - Epoch 36, Step 124987: Loss=5.0321, Acc=0.333, 
2025-10-14 21:10:42,080 - training.trainer - INFO - Epoch 36, Step 125087: Loss=5.3664, Acc=0.280, 
2025-10-14 21:11:04,517 - training.trainer - INFO - Epoch 37/100 completed in 313.57s - Train Loss: 5.3892, Train Acc: 0.295, Val Loss: 5.8572, Val Acc: 0.264
2025-10-14 21:11:13,114 - training.trainer - INFO - Epoch 37, Step 125270: Loss=5.7738, Acc=0.196, 
2025-10-14 21:11:21,280 - training.trainer - INFO - Epoch 37, Step 125370: Loss=5.5247, Acc=0.233, 
2025-10-14 21:11:29,604 - training.trainer - INFO - Epoch 37, Step 125470: Loss=5.6706, Acc=0.250, 
2025-10-14 21:11:37,969 - training.trainer - INFO - Epoch 37, Step 125570: Loss=5.9716, Acc=0.178, 
2025-10-14 21:11:46,291 - training.trainer - INFO - Epoch 37, Step 125670: Loss=5.9998, Acc=0.205, 
2025-10-14 21:11:54,739 - training.trainer - INFO - Epoch 37, Step 125770: Loss=5.7965, Acc=0.291, 
2025-10-14 21:12:03,031 - training.trainer - INFO - Epoch 37, Step 125870: Loss=4.8355, Acc=0.393, 
2025-10-14 21:12:11,539 - training.trainer - INFO - Epoch 37, Step 125970: Loss=5.9284, Acc=0.268, 
2025-10-14 21:12:19,611 - training.trainer - INFO - Epoch 37, Step 126070: Loss=4.8974, Acc=0.385, 
2025-10-14 21:12:27,733 - training.trainer - INFO - Epoch 37, Step 126170: Loss=6.3510, Acc=0.186, 
2025-10-14 21:12:35,923 - training.trainer - INFO - Epoch 37, Step 126270: Loss=4.9866, Acc=0.300, 
2025-10-14 21:12:44,200 - training.trainer - INFO - Epoch 37, Step 126370: Loss=6.2689, Acc=0.241, 
2025-10-14 21:12:52,254 - training.trainer - INFO - Epoch 37, Step 126470: Loss=5.6337, Acc=0.273, 
2025-10-14 21:13:00,414 - training.trainer - INFO - Epoch 37, Step 126570: Loss=4.9483, Acc=0.294, 
2025-10-14 21:13:08,816 - training.trainer - INFO - Epoch 37, Step 126670: Loss=6.6384, Acc=0.190, 
2025-10-14 21:13:17,212 - training.trainer - INFO - Epoch 37, Step 126770: Loss=6.1419, Acc=0.184, 
2025-10-14 21:13:25,409 - training.trainer - INFO - Epoch 37, Step 126870: Loss=5.7113, Acc=0.214, 
2025-10-14 21:13:33,776 - training.trainer - INFO - Epoch 37, Step 126970: Loss=6.1485, Acc=0.195, 
2025-10-14 21:13:41,917 - training.trainer - INFO - Epoch 37, Step 127070: Loss=4.6900, Acc=0.231, 
2025-10-14 21:13:50,166 - training.trainer - INFO - Epoch 37, Step 127170: Loss=4.2008, Acc=0.448, 
2025-10-14 21:13:58,312 - training.trainer - INFO - Epoch 37, Step 127270: Loss=4.3122, Acc=0.375, 
2025-10-14 21:14:06,496 - training.trainer - INFO - Epoch 37, Step 127370: Loss=5.9116, Acc=0.300, 
2025-10-14 21:14:14,726 - training.trainer - INFO - Epoch 37, Step 127470: Loss=6.4304, Acc=0.235, 
2025-10-14 21:14:22,947 - training.trainer - INFO - Epoch 37, Step 127570: Loss=6.0548, Acc=0.241, 
2025-10-14 21:14:30,975 - training.trainer - INFO - Epoch 37, Step 127670: Loss=4.7420, Acc=0.323, 
2025-10-14 21:14:39,220 - training.trainer - INFO - Epoch 37, Step 127770: Loss=2.8138, Acc=0.630, 
2025-10-14 21:14:47,492 - training.trainer - INFO - Epoch 37, Step 127870: Loss=5.9562, Acc=0.316, 
2025-10-14 21:14:55,733 - training.trainer - INFO - Epoch 37, Step 127970: Loss=4.9437, Acc=0.324, 
2025-10-14 21:15:03,984 - training.trainer - INFO - Epoch 37, Step 128070: Loss=5.0710, Acc=0.303, 
2025-10-14 21:15:12,203 - training.trainer - INFO - Epoch 37, Step 128170: Loss=5.0173, Acc=0.357, 
2025-10-14 21:15:20,306 - training.trainer - INFO - Epoch 37, Step 128270: Loss=5.6350, Acc=0.346, 
2025-10-14 21:15:28,637 - training.trainer - INFO - Epoch 37, Step 128370: Loss=5.3786, Acc=0.281, 
2025-10-14 21:15:37,001 - training.trainer - INFO - Epoch 37, Step 128470: Loss=4.9378, Acc=0.303, 
2025-10-14 21:15:58,869 - training.trainer - INFO - Epoch 38/100 completed in 294.35s - Train Loss: 5.3828, Train Acc: 0.297, Val Loss: 5.8543, Val Acc: 0.263
2025-10-14 21:16:07,549 - training.trainer - INFO - Epoch 38, Step 128653: Loss=4.7286, Acc=0.379, 
2025-10-14 21:16:15,891 - training.trainer - INFO - Epoch 38, Step 128753: Loss=5.6627, Acc=0.300, 
2025-10-14 21:16:24,155 - training.trainer - INFO - Epoch 38, Step 128853: Loss=5.2582, Acc=0.292, 
2025-10-14 21:16:32,726 - training.trainer - INFO - Epoch 38, Step 128953: Loss=4.6876, Acc=0.412, 
2025-10-14 21:16:40,855 - training.trainer - INFO - Epoch 38, Step 129053: Loss=4.5146, Acc=0.333, 
2025-10-14 21:16:49,413 - training.trainer - INFO - Epoch 38, Step 129153: Loss=5.4069, Acc=0.321, 
2025-10-14 21:16:57,828 - training.trainer - INFO - Epoch 38, Step 129253: Loss=5.7209, Acc=0.258, 
2025-10-14 21:17:06,526 - training.trainer - INFO - Epoch 38, Step 129353: Loss=5.9311, Acc=0.300, 
2025-10-14 21:17:15,547 - training.trainer - INFO - Epoch 38, Step 129453: Loss=5.4764, Acc=0.250, 
2025-10-14 21:17:24,161 - training.trainer - INFO - Epoch 38, Step 129553: Loss=6.1318, Acc=0.273, 
2025-10-14 21:17:32,936 - training.trainer - INFO - Epoch 38, Step 129653: Loss=5.8485, Acc=0.174, 
2025-10-14 21:17:41,718 - training.trainer - INFO - Epoch 38, Step 129753: Loss=5.4292, Acc=0.216, 
2025-10-14 21:17:50,056 - training.trainer - INFO - Epoch 38, Step 129853: Loss=5.4049, Acc=0.244, 
2025-10-14 21:17:58,500 - training.trainer - INFO - Epoch 38, Step 129953: Loss=4.4636, Acc=0.391, 
2025-10-14 21:18:07,620 - training.trainer - INFO - Epoch 38, Step 130053: Loss=5.4587, Acc=0.242, 
2025-10-14 21:18:16,977 - training.trainer - INFO - Epoch 38, Step 130153: Loss=5.1152, Acc=0.421, 
2025-10-14 21:18:26,210 - training.trainer - INFO - Epoch 38, Step 130253: Loss=5.8968, Acc=0.209, 
2025-10-14 21:18:35,186 - training.trainer - INFO - Epoch 38, Step 130353: Loss=5.7933, Acc=0.200, 
2025-10-14 21:18:44,447 - training.trainer - INFO - Epoch 38, Step 130453: Loss=5.3559, Acc=0.346, 
2025-10-14 21:18:53,609 - training.trainer - INFO - Epoch 38, Step 130553: Loss=5.7819, Acc=0.270, 
2025-10-14 21:19:02,841 - training.trainer - INFO - Epoch 38, Step 130653: Loss=5.9825, Acc=0.200, 
2025-10-14 21:19:11,008 - training.trainer - INFO - Epoch 38, Step 130753: Loss=5.4724, Acc=0.333, 
2025-10-14 21:19:19,270 - training.trainer - INFO - Epoch 38, Step 130853: Loss=6.3144, Acc=0.281, 
2025-10-14 21:19:27,351 - training.trainer - INFO - Epoch 38, Step 130953: Loss=5.7913, Acc=0.281, 
2025-10-14 21:19:35,573 - training.trainer - INFO - Epoch 38, Step 131053: Loss=3.9953, Acc=0.400, 
2025-10-14 21:19:43,748 - training.trainer - INFO - Epoch 38, Step 131153: Loss=6.0214, Acc=0.194, 
2025-10-14 21:19:51,977 - training.trainer - INFO - Epoch 38, Step 131253: Loss=5.5353, Acc=0.304, 
2025-10-14 21:20:00,029 - training.trainer - INFO - Epoch 38, Step 131353: Loss=5.1484, Acc=0.244, 
2025-10-14 21:20:08,336 - training.trainer - INFO - Epoch 38, Step 131453: Loss=6.8169, Acc=0.262, 
2025-10-14 21:20:16,273 - training.trainer - INFO - Epoch 38, Step 131553: Loss=5.9985, Acc=0.188, 
2025-10-14 21:20:24,396 - training.trainer - INFO - Epoch 38, Step 131653: Loss=5.4448, Acc=0.306, 
2025-10-14 21:20:32,588 - training.trainer - INFO - Epoch 38, Step 131753: Loss=6.0415, Acc=0.333, 
2025-10-14 21:20:40,847 - training.trainer - INFO - Epoch 38, Step 131853: Loss=5.5498, Acc=0.226, 
2025-10-14 21:21:02,954 - training.trainer - INFO - Epoch 39/100 completed in 304.08s - Train Loss: 5.3680, Train Acc: 0.299, Val Loss: 5.8548, Val Acc: 0.263
2025-10-14 21:21:11,517 - training.trainer - INFO - Epoch 39, Step 132036: Loss=5.9978, Acc=0.270, 
2025-10-14 21:21:19,596 - training.trainer - INFO - Epoch 39, Step 132136: Loss=5.7499, Acc=0.250, 
2025-10-14 21:21:27,668 - training.trainer - INFO - Epoch 39, Step 132236: Loss=6.0673, Acc=0.295, 
2025-10-14 21:21:35,683 - training.trainer - INFO - Epoch 39, Step 132336: Loss=5.9070, Acc=0.250, 
2025-10-14 21:21:43,750 - training.trainer - INFO - Epoch 39, Step 132436: Loss=5.2910, Acc=0.238, 
2025-10-14 21:21:51,771 - training.trainer - INFO - Epoch 39, Step 132536: Loss=5.7143, Acc=0.296, 
2025-10-14 21:22:00,115 - training.trainer - INFO - Epoch 39, Step 132636: Loss=4.7236, Acc=0.351, 
2025-10-14 21:22:08,331 - training.trainer - INFO - Epoch 39, Step 132736: Loss=5.0724, Acc=0.297, 
2025-10-14 21:22:16,515 - training.trainer - INFO - Epoch 39, Step 132836: Loss=4.1917, Acc=0.395, 
2025-10-14 21:22:24,839 - training.trainer - INFO - Epoch 39, Step 132936: Loss=5.2260, Acc=0.364, 
2025-10-14 21:22:33,065 - training.trainer - INFO - Epoch 39, Step 133036: Loss=5.7461, Acc=0.258, 
2025-10-14 21:22:41,172 - training.trainer - INFO - Epoch 39, Step 133136: Loss=6.1802, Acc=0.180, 
2025-10-14 21:22:49,280 - training.trainer - INFO - Epoch 39, Step 133236: Loss=5.5478, Acc=0.317, 
2025-10-14 21:22:57,458 - training.trainer - INFO - Epoch 39, Step 133336: Loss=3.3594, Acc=0.632, 
2025-10-14 21:23:05,640 - training.trainer - INFO - Epoch 39, Step 133436: Loss=4.6617, Acc=0.414, 
2025-10-14 21:23:14,108 - training.trainer - INFO - Epoch 39, Step 133536: Loss=6.3510, Acc=0.159, 
2025-10-14 21:23:22,227 - training.trainer - INFO - Epoch 39, Step 133636: Loss=5.5064, Acc=0.241, 
2025-10-14 21:23:30,212 - training.trainer - INFO - Epoch 39, Step 133736: Loss=5.5092, Acc=0.364, 
2025-10-14 21:23:38,453 - training.trainer - INFO - Epoch 39, Step 133836: Loss=5.4488, Acc=0.312, 
2025-10-14 21:23:46,687 - training.trainer - INFO - Epoch 39, Step 133936: Loss=3.1786, Acc=0.571, 
2025-10-14 21:23:54,986 - training.trainer - INFO - Epoch 39, Step 134036: Loss=5.4545, Acc=0.324, 
2025-10-14 21:24:03,102 - training.trainer - INFO - Epoch 39, Step 134136: Loss=6.1339, Acc=0.190, 
2025-10-14 21:24:11,252 - training.trainer - INFO - Epoch 39, Step 134236: Loss=5.8323, Acc=0.304, 
2025-10-14 21:24:19,443 - training.trainer - INFO - Epoch 39, Step 134336: Loss=6.0194, Acc=0.194, 
2025-10-14 21:24:27,464 - training.trainer - INFO - Epoch 39, Step 134436: Loss=5.0058, Acc=0.303, 
2025-10-14 21:24:35,383 - training.trainer - INFO - Epoch 39, Step 134536: Loss=5.5495, Acc=0.262, 
2025-10-14 21:24:43,507 - training.trainer - INFO - Epoch 39, Step 134636: Loss=5.8093, Acc=0.281, 
2025-10-14 21:24:51,614 - training.trainer - INFO - Epoch 39, Step 134736: Loss=4.9182, Acc=0.407, 
2025-10-14 21:24:59,729 - training.trainer - INFO - Epoch 39, Step 134836: Loss=4.9421, Acc=0.306, 
2025-10-14 21:25:08,022 - training.trainer - INFO - Epoch 39, Step 134936: Loss=5.9744, Acc=0.191, 
2025-10-14 21:25:16,308 - training.trainer - INFO - Epoch 39, Step 135036: Loss=5.5844, Acc=0.379, 
2025-10-14 21:25:24,512 - training.trainer - INFO - Epoch 39, Step 135136: Loss=4.2720, Acc=0.647, 
2025-10-14 21:25:32,619 - training.trainer - INFO - Epoch 39, Step 135236: Loss=4.9325, Acc=0.286, 
2025-10-14 21:25:54,699 - training.trainer - INFO - Epoch 40/100 completed in 291.74s - Train Loss: 5.3503, Train Acc: 0.303, Val Loss: 5.8978, Val Acc: 0.265
2025-10-14 21:25:55,068 - training.trainer - INFO - Checkpoint saved: checkpoints/lsa_t//checkpoint_epoch_40.pt
2025-10-14 21:25:55,070 - training.trainer - INFO - Early stopping triggered after 15 epochs without improvement
2025-10-14 21:25:55,071 - training.trainer - INFO - Training completed!
2025-10-14 21:25:55,071 - __main__ - INFO - Training completed successfully!
2025-10-14 21:25:55,206 - __main__ - INFO - Final model saved to models/lsa_t/final_model.pt
2025-10-14 21:25:55,501 - __main__ - INFO - Process completed!
2025-10-14 21:26:12,811 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-14 21:26:12,811 - __main__ - INFO - Configuration: configs/lsa_t_config.yaml
2025-10-14 21:26:12,811 - __main__ - INFO - Starting model evaluation
2025-10-14 21:26:14,307 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-14 21:33:13,815 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-14 21:33:13,841 - __main__ - INFO - Process completed!
2025-10-14 21:33:18,000 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-14 21:33:18,000 - __main__ - INFO - Configuration: configs/lsa_t_config_5.yaml
2025-10-14 21:33:18,000 - __main__ - INFO - Starting model evaluation
2025-10-14 21:33:19,022 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-14 22:41:12,972 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-14 22:41:12,991 - __main__ - INFO - Process completed!
2025-10-14 22:41:16,855 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-14 22:41:16,855 - __main__ - INFO - Configuration: configs/lsa_t_config_8.yaml
2025-10-14 22:41:16,855 - __main__ - INFO - Starting model evaluation
2025-10-14 22:41:17,871 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-15 00:27:34,015 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-15 00:27:34,045 - __main__ - INFO - Process completed!
2025-10-15 00:27:38,662 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-15 00:27:38,662 - __main__ - INFO - Configuration: configs/lsa_t_config_16.yaml
2025-10-15 00:27:38,663 - __main__ - INFO - Starting model evaluation
2025-10-15 00:27:39,745 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-15 03:30:35,909 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-15 03:30:35,937 - __main__ - INFO - Process completed!
2025-10-15 03:30:40,492 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-15 03:30:40,493 - __main__ - INFO - Configuration: configs/lsa_t_config_24.yaml
2025-10-15 03:30:40,493 - __main__ - INFO - Starting model evaluation
2025-10-15 03:30:41,199 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-15 08:49:02,134 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-15 08:49:02,498 - __main__ - INFO - Process completed!
2025-10-15 08:49:20,079 - __main__ - INFO - Starting Sign Language Translation - Mode: evaluate
2025-10-15 08:49:20,079 - __main__ - INFO - Configuration: configs/lsa_t_config_32.yaml
2025-10-15 08:49:20,080 - __main__ - INFO - Starting model evaluation
2025-10-15 08:49:21,802 - __main__ - INFO - Loaded model from checkpoints/lsa_t/best_model.pt
2025-10-15 17:19:21,117 - __main__ - INFO - Evaluation results saved to results/lsa_t/evaluation_results.yaml
2025-10-15 17:19:21,619 - __main__ - INFO - Process completed!
